


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchrl.modules package &mdash; torchrl 0.4 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Actor" href="generated/torchrl.modules.tensordict_module.Actor.html" />
    <link rel="prev" title="set_gym_backend" href="generated/torchrl.envs.set_gym_backend.html" />
  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  0.4
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-0.html">Get started with Environments, TED and transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-1.html">Get started with TorchRL’s modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-2.html">Getting started with model optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-3.html">Get started with data collection and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-4.html">Get started with logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-5.html">Get started with your own first training loop</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/coding_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/torchrl_demo.html">Introduction to TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/multiagent_ppo.html">Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/torchrl_envs.html">TorchRL envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/pretrained_models.html">Using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/dqn_with_rnn.html">Recurrent DQN: Training recurrent policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/rb_tutorial.html">Using Replay Buffers</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/multiagent_competitive_ddpg.html">Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/coding_ddpg.html">TorchRL objectives: Coding a DDPG loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/coding_dqn.html">TorchRL trainer: A DQN example</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="index.html">API Reference</a> &gt;</li>
        
      <li>torchrl.modules package</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/reference/modules.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          <div class="pytorch-call-to-action-links">
            <div id="tutorial-type">reference/modules</div>

            <div id="google-colab-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-colab.svg"/>
              <div class="call-to-action-desktop-view">Run in Google Colab</div>
              <div class="call-to-action-mobile-view">Colab</div>
            </div>
            <div id="download-notebook-link">
              <img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
              <div class="call-to-action-desktop-view">Download Notebook</div>
              <div class="call-to-action-mobile-view">Notebook</div>
            </div>
            <div id="github-view-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
              <div class="call-to-action-desktop-view">View on GitHub</div>
              <div class="call-to-action-mobile-view">GitHub</div>
            </div>
          </div>

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="torchrl-modules-package">
<h1>torchrl.modules package<a class="headerlink" href="#torchrl-modules-package" title="Permalink to this heading">¶</a></h1>
<section id="tensordict-modules-actors-exploration-value-models-and-generative-models">
<span id="ref-modules"></span><h2>TensorDict modules: Actors, exploration, value models and generative models<a class="headerlink" href="#tensordict-modules-actors-exploration-value-models-and-generative-models" title="Permalink to this heading">¶</a></h2>
<p id="tdmodules">TorchRL offers a series of module wrappers aimed at making it easy to build
RL models from the ground up. These wrappers are exclusively based on
<code class="xref py py-class docutils literal notranslate"><span class="pre">tensordict.nn.TensorDictModule</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">tensordict.nn.TensorDictSequential</span></code>.
They can loosely be split in three categories:
policies (actors), including exploration strategies,
value model and simulation models (in model-based contexts).</p>
<p>The main features are:</p>
<ul class="simple">
<li><p>Integration of the specs in your model to ensure that the model output matches
what your environment expects as input;</p></li>
<li><p>Probabilistic modules that can automatically sample from a chosen distribution
and/or return the distribution of interest;</p></li>
<li><p>Custom containers for Q-Value learning, model-based agents and others.</p></li>
</ul>
<section id="tensordictmodules-and-safemodules">
<h3>TensorDictModules and SafeModules<a class="headerlink" href="#tensordictmodules-and-safemodules" title="Permalink to this heading">¶</a></h3>
<p>TorchRL <a class="reference internal" href="generated/torchrl.modules.tensordict_module.SafeModule.html#torchrl.modules.tensordict_module.SafeModule" title="torchrl.modules.tensordict_module.SafeModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">SafeModule</span></code></a> allows you to
check the you model output matches what is to be expected for the environment.
This should be used whenever your model is to be recycled across multiple
environments for instance, and when you want to make sure that the outputs
(e.g. the action) always satisfies the bounds imposed by the environment.
Here is an example of how to use that feature with the
<a class="reference internal" href="generated/torchrl.modules.tensordict_module.Actor.html#torchrl.modules.tensordict_module.Actor" title="torchrl.modules.tensordict_module.Actor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Actor</span></code></a> class:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">action_spec</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_spec</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">action_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">policy</span> <span class="o">=</span> <span class="n">Actor</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">],</span> <span class="n">spec</span><span class="o">=</span><span class="n">action_spec</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">safe</span></code> flag ensures that the output is always within the bounds of the
<code class="docutils literal notranslate"><span class="pre">action_spec</span></code> domain: if the network output violates these bounds it will be
projected (in a L1-manner) into the desired domain.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.Actor.html#torchrl.modules.tensordict_module.Actor" title="torchrl.modules.tensordict_module.Actor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Actor</span></code></a>(*args, **kwargs)</p></td>
<td><p>General class for deterministic actors in RL.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.MultiStepActorWrapper.html#torchrl.modules.tensordict_module.MultiStepActorWrapper" title="torchrl.modules.tensordict_module.MultiStepActorWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiStepActorWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>A wrapper around a multi-action actor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.SafeModule.html#torchrl.modules.tensordict_module.SafeModule" title="torchrl.modules.tensordict_module.SafeModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SafeModule</span></code></a>(*args, **kwargs)</p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tensordict.nn.TensorDictModule</span></code> subclass that accepts a <a class="reference internal" href="generated/torchrl.data.TensorSpec.html#torchrl.data.TensorSpec" title="torchrl.data.TensorSpec"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorSpec</span></code></a> as argument to control the output domain.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.SafeSequential.html#torchrl.modules.tensordict_module.SafeSequential" title="torchrl.modules.tensordict_module.SafeSequential"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SafeSequential</span></code></a>(*args, **kwargs)</p></td>
<td><p>A safe sequence of TensorDictModules.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.TanhModule.html#torchrl.modules.tensordict_module.TanhModule" title="torchrl.modules.tensordict_module.TanhModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TanhModule</span></code></a>(*args, **kwargs)</p></td>
<td><p>A Tanh module for deterministic policies with bounded action space.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="exploration-wrappers">
<h3>Exploration wrappers<a class="headerlink" href="#exploration-wrappers" title="Permalink to this heading">¶</a></h3>
<p>To efficiently explore the environment, TorchRL proposes a series of wrappers
that will override the action sampled by the policy by a noisier version.
Their behaviour is controlled by <a class="reference internal" href="generated/torchrl.envs.utils.exploration_mode.html#torchrl.envs.utils.exploration_mode" title="torchrl.envs.utils.exploration_mode"><code class="xref py py-func docutils literal notranslate"><span class="pre">exploration_mode()</span></code></a>:
if the exploration is set to <code class="docutils literal notranslate"><span class="pre">&quot;random&quot;</span></code>, the exploration is active. In all
other cases, the action written in the tensordict is simply the network output.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.AdditiveGaussianWrapper.html#torchrl.modules.tensordict_module.AdditiveGaussianWrapper" title="torchrl.modules.tensordict_module.AdditiveGaussianWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AdditiveGaussianWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>Additive Gaussian PO wrapper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.EGreedyModule.html#torchrl.modules.tensordict_module.EGreedyModule" title="torchrl.modules.tensordict_module.EGreedyModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EGreedyModule</span></code></a>(*args, **kwargs)</p></td>
<td><p>Epsilon-Greedy exploration module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.EGreedyWrapper.html#torchrl.modules.tensordict_module.EGreedyWrapper" title="torchrl.modules.tensordict_module.EGreedyWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EGreedyWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>[Deprecated] Epsilon-Greedy PO wrapper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.OrnsteinUhlenbeckProcessWrapper.html#torchrl.modules.tensordict_module.OrnsteinUhlenbeckProcessWrapper" title="torchrl.modules.tensordict_module.OrnsteinUhlenbeckProcessWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OrnsteinUhlenbeckProcessWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>Ornstein-Uhlenbeck exploration policy wrapper.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="probabilistic-actors">
<h3>Probabilistic actors<a class="headerlink" href="#probabilistic-actors" title="Permalink to this heading">¶</a></h3>
<p>Some algorithms such as PPO require a probabilistic policy to be implemented.
In TorchRL, these policies take the form of a model, followed by a distribution
constructor.</p>
<blockquote>
<div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>The choice of a probabilistic or regular actor class depends on the algorithm
that is being implemented. On-policy algorithms usually require a probabilistic
actor, off-policy usually have a deterministic actor with an extra exploration
strategy. There are, however, many exceptions to this rule.</p>
</div>
</div></blockquote>
<p>The model reads an input (typically some observation from the environment)
and outputs the parameters of a distribution, while the distribution constructor
reads these parameters and gets a random sample from the distribution and/or
provides a <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.Distribution</span></code> object.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensordict.nn</span> <span class="kn">import</span> <span class="n">NormalParamExtractor</span><span class="p">,</span> <span class="n">TensorDictSequential</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">Normal</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">action_spec</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_spec</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">action_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span> <span class="n">NormalParamExtractor</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># build the first module, which maps the observation on the mean and sd of the normal distribution</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">TensorDictModule</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">],</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;loc&quot;</span><span class="p">,</span> <span class="s2">&quot;scale&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># build the distribution constructor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prob_module</span> <span class="o">=</span> <span class="n">SafeProbabilisticModule</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;loc&quot;</span><span class="p">,</span> <span class="s2">&quot;scale&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">distribution_class</span><span class="o">=</span><span class="n">Normal</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">return_log_prob</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">spec</span><span class="o">=</span><span class="n">action_spec</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">policy</span> <span class="o">=</span> <span class="n">TensorDictSequential</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">prob_module</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># execute a rollout</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">policy</span><span class="p">)</span>
</pre></div>
</div>
<p>To facilitate the construction of probabilistic policies, we provide a dedicated
<a class="reference internal" href="generated/torchrl.modules.tensordict_module.ProbabilisticActor.html#torchrl.modules.tensordict_module.ProbabilisticActor" title="torchrl.modules.tensordict_module.ProbabilisticActor"><code class="xref py py-class docutils literal notranslate"><span class="pre">ProbabilisticActor</span></code></a>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">policy</span> <span class="o">=</span> <span class="n">ProbabilisticActor</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">model</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;loc&quot;</span><span class="p">,</span> <span class="s2">&quot;scale&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">distribution_class</span><span class="o">=</span><span class="n">Normal</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">return_log_prob</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">spec</span><span class="o">=</span><span class="n">action_spec</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<p>which alleviates the need to specify a constructor and putting it with the
module in a sequence.</p>
<p>Outputs of this policy will contain a <code class="docutils literal notranslate"><span class="pre">&quot;loc&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;scale&quot;</span></code> entries, an
<code class="docutils literal notranslate"><span class="pre">&quot;action&quot;</span></code> sampled according to the normal distribution and the log-probability
of this action.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.ProbabilisticActor.html#torchrl.modules.tensordict_module.ProbabilisticActor" title="torchrl.modules.tensordict_module.ProbabilisticActor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ProbabilisticActor</span></code></a>(*args, **kwargs)</p></td>
<td><p>General class for probabilistic actors in RL.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.SafeProbabilisticModule.html#torchrl.modules.tensordict_module.SafeProbabilisticModule" title="torchrl.modules.tensordict_module.SafeProbabilisticModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SafeProbabilisticModule</span></code></a>(*args, **kwargs)</p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tensordict.nn.ProbabilisticTensorDictModule</span></code> subclass that accepts a <code class="xref py py-class docutils literal notranslate"><span class="pre">TensorSpec</span></code> as argument to control the output domain.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential.html#torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential" title="torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SafeProbabilisticTensorDictSequential</span></code></a>(*args, ...)</p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tensordict.nn.ProbabilisticTensorDictSequential</span></code> subclass that accepts a <code class="xref py py-class docutils literal notranslate"><span class="pre">TensorSpec</span></code> as argument to control the output domain.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="q-value-actors">
<h3>Q-Value actors<a class="headerlink" href="#q-value-actors" title="Permalink to this heading">¶</a></h3>
<p>Q-Value actors are a special type of policy that does not directly predict an action
from an observation, but picks the action that maximised the value (or <em>quality</em>)
of a (s,a) -&gt; v map. This map can be a table or a function.
For discrete action spaces with continuous (or near-continuous such as pixels)
states, it is customary to use a non-linear model such as a neural network for
the map.
The semantic of the Q-Value network is hopefully quite simple: we just need to
feed a tensor-to-tensor map that given a certain state (the input tensor),
outputs a list of action values to choose from. The wrapper will write the
resulting action in the input tensordict along with the list of action values.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensordict</span> <span class="kn">import</span> <span class="n">TensorDict</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensordict.nn.functional_modules</span> <span class="kn">import</span> <span class="n">make_functional</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torchrl.data</span> <span class="kn">import</span> <span class="n">OneHotDiscreteTensorSpec</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torchrl.modules.tensordict_module.actors</span> <span class="kn">import</span> <span class="n">QValueActor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">td</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">({</span><span class="s1">&#39;observation&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)},</span> <span class="p">[</span><span class="mi">5</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># we have 4 actions to choose from</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">action_spec</span> <span class="o">=</span> <span class="n">OneHotDiscreteTensorSpec</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># the model reads a state of dimension 3 and outputs 4 values, one for each action available</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qvalue_actor</span> <span class="o">=</span> <span class="n">QValueActor</span><span class="p">(</span><span class="n">module</span><span class="o">=</span><span class="n">module</span><span class="p">,</span> <span class="n">spec</span><span class="o">=</span><span class="n">action_spec</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qvalue_actor</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
<span class="go">TensorDict(</span>
<span class="go">    fields={</span>
<span class="go">        action: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="go">        action_value: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="go">        chosen_action_value: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="go">        observation: Tensor(shape=torch.Size([5, 3]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="go">    batch_size=torch.Size([5]),</span>
<span class="go">    device=None,</span>
<span class="go">    is_shared=False)</span>
</pre></div>
</div>
<p>Distributional Q-learning is slightly different: in this case, the value network
does not output a scalar value for each state-action value.
Instead, the value space is divided in a an arbitrary number of “bins”. The
value network outputs a probability that the state-action value belongs to one bin
or another.
Hence, for a state space of dimension M, an action space of dimension N and a number of bins B,
the value network encodes a <span class="math notranslate nohighlight">\(\mathbb{R}^{M} \rightarrow \mathbb{R}^{N \times B}\)</span>
map. The following example shows how this works in TorchRL with the <a class="reference internal" href="generated/torchrl.modules.tensordict_module.DistributionalQValueActor.html#torchrl.modules.tensordict_module.DistributionalQValueActor" title="torchrl.modules.tensordict_module.DistributionalQValueActor"><code class="xref py py-class docutils literal notranslate"><span class="pre">DistributionalQValueActor</span></code></a>
class:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensordict</span> <span class="kn">import</span> <span class="n">TensorDict</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torchrl.data</span> <span class="kn">import</span> <span class="n">OneHotDiscreteTensorSpec</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torchrl.modules</span> <span class="kn">import</span> <span class="n">DistributionalQValueActor</span><span class="p">,</span> <span class="n">MLP</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">td</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">({</span><span class="s1">&#39;observation&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">)},</span> <span class="p">[</span><span class="mi">5</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nbins</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># our model reads the observation and outputs a stack of 4 logits (one for each action) of size nbins=3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">out_features</span><span class="o">=</span><span class="p">(</span><span class="n">nbins</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">depth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">action_spec</span> <span class="o">=</span> <span class="n">OneHotDiscreteTensorSpec</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qvalue_actor</span> <span class="o">=</span> <span class="n">DistributionalQValueActor</span><span class="p">(</span><span class="n">module</span><span class="o">=</span><span class="n">module</span><span class="p">,</span> <span class="n">spec</span><span class="o">=</span><span class="n">action_spec</span><span class="p">,</span> <span class="n">support</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">nbins</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">td</span> <span class="o">=</span> <span class="n">qvalue_actor</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
<span class="go">TensorDict(</span>
<span class="go">    fields={</span>
<span class="go">        action: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="go">        action_value: Tensor(shape=torch.Size([5, 3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="go">        observation: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="go">    batch_size=torch.Size([5]),</span>
<span class="go">    device=None,</span>
<span class="go">    is_shared=False)</span>
</pre></div>
</div>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.QValueActor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">QValueActor</span></code></a>(*args, **kwargs)</p></td>
<td><p>A Q-Value actor class.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.QValueModule.html#torchrl.modules.tensordict_module.QValueModule" title="torchrl.modules.tensordict_module.QValueModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">QValueModule</span></code></a>(*args, **kwargs)</p></td>
<td><p>Q-Value TensorDictModule for Q-value policies.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.DistributionalQValueActor.html#torchrl.modules.tensordict_module.DistributionalQValueActor" title="torchrl.modules.tensordict_module.DistributionalQValueActor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DistributionalQValueActor</span></code></a>(*args, **kwargs)</p></td>
<td><p>A Distributional DQN actor class.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.DistributionalQValueModule.html#torchrl.modules.tensordict_module.DistributionalQValueModule" title="torchrl.modules.tensordict_module.DistributionalQValueModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DistributionalQValueModule</span></code></a>(*args, **kwargs)</p></td>
<td><p>Distributional Q-Value hook for Q-value policies.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="value-operators-and-joined-models">
<h3>Value operators and joined models<a class="headerlink" href="#value-operators-and-joined-models" title="Permalink to this heading">¶</a></h3>
<p>TorchRL provides a series of value operators that wrap value networks to
soften the interface with the rest of the library.
The basic building block is <a class="reference internal" href="generated/torchrl.modules.tensordict_module.ValueOperator.html#torchrl.modules.tensordict_module.ValueOperator" title="torchrl.modules.tensordict_module.ValueOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchrl.modules.tensordict_module.ValueOperator</span></code></a>:
given an input state (and possibly action), it will automatically write a <code class="docutils literal notranslate"><span class="pre">&quot;state_value&quot;</span></code>
(or <code class="docutils literal notranslate"><span class="pre">&quot;state_action_value&quot;</span></code>) in the tensordict, depending on what the input is.
As such, this class accounts for both value and quality networks.
Three classes are also proposed to group together a policy and a value network.
The <a class="reference internal" href="generated/torchrl.modules.tensordict_module.ActorCriticOperator.html#torchrl.modules.tensordict_module.ActorCriticOperator" title="torchrl.modules.tensordict_module.ActorCriticOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">ActorCriticOperator</span></code></a> is an joined actor-quality network with shared parameters:
it reads an observation, pass it through a
common backbone, writes a hidden state, feeds this hidden state to the policy,
then takes the hidden state and the action and provides the quality of the state-action
pair.
The <a class="reference internal" href="generated/torchrl.modules.tensordict_module.ActorValueOperator.html#torchrl.modules.tensordict_module.ActorValueOperator" title="torchrl.modules.tensordict_module.ActorValueOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">ActorValueOperator</span></code></a> is a joined actor-value network with shared parameters:
it reads an observation, pass it through a
common backbone, writes a hidden state, feeds this hidden state to the policy
and value modules to output an action and a state value.
Finally, the <a class="reference internal" href="generated/torchrl.modules.tensordict_module.ActorCriticWrapper.html#torchrl.modules.tensordict_module.ActorCriticWrapper" title="torchrl.modules.tensordict_module.ActorCriticWrapper"><code class="xref py py-class docutils literal notranslate"><span class="pre">ActorCriticWrapper</span></code></a> is a joined actor and value network
without shared parameters. It is mainly intended as a replacement for
<a class="reference internal" href="generated/torchrl.modules.tensordict_module.ActorValueOperator.html#torchrl.modules.tensordict_module.ActorValueOperator" title="torchrl.modules.tensordict_module.ActorValueOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">ActorValueOperator</span></code></a> when a script needs to account for both options.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">actor</span> <span class="o">=</span> <span class="n">make_actor</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value</span> <span class="o">=</span> <span class="n">make_value</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">shared_params</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">common</span> <span class="o">=</span> <span class="n">make_common</span><span class="p">()</span>
<span class="gp">... </span>    <span class="n">model</span> <span class="o">=</span> <span class="n">ActorValueOperator</span><span class="p">(</span><span class="n">common</span><span class="p">,</span> <span class="n">actor</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
<span class="gp">... </span><span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">model</span> <span class="o">=</span> <span class="n">ActorValueOperator</span><span class="p">(</span><span class="n">actor</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">policy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_policy_operator</span><span class="p">()</span>  <span class="c1"># will work in both cases</span>
</pre></div>
</div>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.ActorCriticOperator.html#torchrl.modules.tensordict_module.ActorCriticOperator" title="torchrl.modules.tensordict_module.ActorCriticOperator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ActorCriticOperator</span></code></a>(*args, **kwargs)</p></td>
<td><p>Actor-critic operator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.ActorCriticWrapper.html#torchrl.modules.tensordict_module.ActorCriticWrapper" title="torchrl.modules.tensordict_module.ActorCriticWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ActorCriticWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>Actor-value operator without common module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.ActorValueOperator.html#torchrl.modules.tensordict_module.ActorValueOperator" title="torchrl.modules.tensordict_module.ActorValueOperator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ActorValueOperator</span></code></a>(*args, **kwargs)</p></td>
<td><p>Actor-value operator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.ValueOperator.html#torchrl.modules.tensordict_module.ValueOperator" title="torchrl.modules.tensordict_module.ValueOperator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ValueOperator</span></code></a>(*args, **kwargs)</p></td>
<td><p>General class for value functions in RL.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper.html#torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper" title="torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DecisionTransformerInferenceWrapper</span></code></a>(*args, ...)</p></td>
<td><p>Inference Action Wrapper for the Decision Transformer.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="domain-specific-tensordict-modules">
<h3>Domain-specific TensorDict modules<a class="headerlink" href="#domain-specific-tensordict-modules" title="Permalink to this heading">¶</a></h3>
<p>These modules include dedicated solutions for MBRL or RLHF pipelines.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.LMHeadActorValueOperator.html#torchrl.modules.tensordict_module.LMHeadActorValueOperator" title="torchrl.modules.tensordict_module.LMHeadActorValueOperator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LMHeadActorValueOperator</span></code></a>(*args, **kwargs)</p></td>
<td><p>Builds an Actor-Value operator from an huggingface-like <a href="#id1"><span class="problematic" id="id2">*</span></a>LMHeadModel.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.tensordict_module.WorldModelWrapper.html#torchrl.modules.tensordict_module.WorldModelWrapper" title="torchrl.modules.tensordict_module.WorldModelWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">WorldModelWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>World model wrapper.</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="hooks">
<h2>Hooks<a class="headerlink" href="#hooks" title="Permalink to this heading">¶</a></h2>
<p>The Q-value hooks are used by the <a class="reference internal" href="generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.QValueActor"><code class="xref py py-class docutils literal notranslate"><span class="pre">QValueActor</span></code></a> and <a class="reference internal" href="generated/torchrl.modules.tensordict_module.DistributionalQValueActor.html#torchrl.modules.tensordict_module.DistributionalQValueActor" title="torchrl.modules.tensordict_module.DistributionalQValueActor"><code class="xref py py-class docutils literal notranslate"><span class="pre">DistributionalQValueActor</span></code></a>
modules and those should be preferred in general as they are easier to create
and use.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.QValueHook.html#torchrl.modules.QValueHook" title="torchrl.modules.QValueHook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">QValueHook</span></code></a>(action_space[, var_nums, ...])</p></td>
<td><p>Q-Value hook for Q-value policies.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.DistributionalQValueHook.html#torchrl.modules.DistributionalQValueHook" title="torchrl.modules.DistributionalQValueHook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DistributionalQValueHook</span></code></a>(action_space, support)</p></td>
<td><p>Distributional Q-Value hook for Q-value policies.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="models">
<h2>Models<a class="headerlink" href="#models" title="Permalink to this heading">¶</a></h2>
<p>TorchRL provides a series of useful “regular” (ie non-tensordict) nn.Module
classes for RL usage.</p>
<section id="regular-modules">
<h3>Regular modules<a class="headerlink" href="#regular-modules" title="Permalink to this heading">¶</a></h3>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.MLP.html#torchrl.modules.MLP" title="torchrl.modules.MLP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MLP</span></code></a>(in_features, out_features, depth, ...)</p></td>
<td><p>A multi-layer perceptron.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.ConvNet.html#torchrl.modules.ConvNet" title="torchrl.modules.ConvNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ConvNet</span></code></a>(in_features, depth, num_cells, ...)</p></td>
<td><p>A convolutional neural network.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.Conv3dNet.html#torchrl.modules.Conv3dNet" title="torchrl.modules.Conv3dNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Conv3dNet</span></code></a>(in_features, depth, num_cells, ...)</p></td>
<td><p>A 3D-convolutional neural network.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.SqueezeLayer.html#torchrl.modules.SqueezeLayer" title="torchrl.modules.SqueezeLayer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SqueezeLayer</span></code></a>([dims])</p></td>
<td><p>Squeezing layer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.Squeeze2dLayer.html#torchrl.modules.Squeeze2dLayer" title="torchrl.modules.Squeeze2dLayer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Squeeze2dLayer</span></code></a>()</p></td>
<td><p>Squeezing layer for convolutional neural networks.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="algorithm-specific-modules">
<h3>Algorithm-specific modules<a class="headerlink" href="#algorithm-specific-modules" title="Permalink to this heading">¶</a></h3>
<p>These networks implement sub-networks that have shown to be useful for specific
algorithms, such as DQN, DDPG or Dreamer.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.DTActor.html#torchrl.modules.DTActor" title="torchrl.modules.DTActor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DTActor</span></code></a>(state_dim, action_dim[, ...])</p></td>
<td><p>Decision Transformer Actor class.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.DdpgCnnActor.html#torchrl.modules.DdpgCnnActor" title="torchrl.modules.DdpgCnnActor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DdpgCnnActor</span></code></a>(action_dim[, conv_net_kwargs, ...])</p></td>
<td><p>DDPG Convolutional Actor class.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.DdpgCnnQNet.html#torchrl.modules.DdpgCnnQNet" title="torchrl.modules.DdpgCnnQNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DdpgCnnQNet</span></code></a>([conv_net_kwargs, ...])</p></td>
<td><p>DDPG Convolutional Q-value class.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.DdpgMlpActor.html#torchrl.modules.DdpgMlpActor" title="torchrl.modules.DdpgMlpActor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DdpgMlpActor</span></code></a>(action_dim[, mlp_net_kwargs, ...])</p></td>
<td><p>DDPG Actor class.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.DdpgMlpQNet.html#torchrl.modules.DdpgMlpQNet" title="torchrl.modules.DdpgMlpQNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DdpgMlpQNet</span></code></a>([mlp_net_kwargs_net1, ...])</p></td>
<td><p>DDPG Q-value MLP class.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.DecisionTransformer.html#torchrl.modules.DecisionTransformer" title="torchrl.modules.DecisionTransformer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DecisionTransformer</span></code></a>(state_dim, action_dim[, ...])</p></td>
<td><p>Online Decion Transformer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.DistributionalDQNnet.html#torchrl.modules.DistributionalDQNnet" title="torchrl.modules.DistributionalDQNnet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DistributionalDQNnet</span></code></a>(*args, **kwargs)</p></td>
<td><p>Distributional Deep Q-Network softmax layer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.DreamerActor.html#torchrl.modules.DreamerActor" title="torchrl.modules.DreamerActor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DreamerActor</span></code></a>(out_features[, depth, ...])</p></td>
<td><p>Dreamer actor network.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.DuelingCnnDQNet.html#torchrl.modules.DuelingCnnDQNet" title="torchrl.modules.DuelingCnnDQNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DuelingCnnDQNet</span></code></a>(out_features[, ...])</p></td>
<td><p>Dueling CNN Q-network.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.GRUCell.html#torchrl.modules.GRUCell" title="torchrl.modules.GRUCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GRUCell</span></code></a>(input_size, hidden_size[, bias, ...])</p></td>
<td><p>A gated recurrent unit (GRU) cell that performs the same operation as nn.LSTMCell but is fully coded in Python.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.GRU.html#torchrl.modules.GRU" title="torchrl.modules.GRU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GRU</span></code></a>(input_size, hidden_size[, num_layers, ...])</p></td>
<td><p>A PyTorch module for executing multiple steps of a multi-layer GRU.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.GRUModule.html#torchrl.modules.GRUModule" title="torchrl.modules.GRUModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GRUModule</span></code></a>(*args, **kwargs)</p></td>
<td><p>An embedder for an GRU module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.LSTMCell.html#torchrl.modules.LSTMCell" title="torchrl.modules.LSTMCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LSTMCell</span></code></a>(input_size, hidden_size[, bias, ...])</p></td>
<td><p>A long short-term memory (LSTM) cell that performs the same operation as nn.LSTMCell but is fully coded in Python.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.LSTM.html#torchrl.modules.LSTM" title="torchrl.modules.LSTM"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LSTM</span></code></a>(input_size, hidden_size[, num_layers, ...])</p></td>
<td><p>A PyTorch module for executing multiple steps of a multi-layer LSTM.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.LSTMModule.html#torchrl.modules.LSTMModule" title="torchrl.modules.LSTMModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LSTMModule</span></code></a>(*args, **kwargs)</p></td>
<td><p>An embedder for an LSTM module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.ObsDecoder.html#torchrl.modules.ObsDecoder" title="torchrl.modules.ObsDecoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ObsDecoder</span></code></a>([channels, num_layers, ...])</p></td>
<td><p>Observation decoder network.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.ObsEncoder.html#torchrl.modules.ObsEncoder" title="torchrl.modules.ObsEncoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ObsEncoder</span></code></a>([channels, num_layers, depth])</p></td>
<td><p>Observation encoder network.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.OnlineDTActor.html#torchrl.modules.OnlineDTActor" title="torchrl.modules.OnlineDTActor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OnlineDTActor</span></code></a>(state_dim, action_dim[, ...])</p></td>
<td><p>Online Decision Transformer Actor class.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.RSSMPosterior.html#torchrl.modules.RSSMPosterior" title="torchrl.modules.RSSMPosterior"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RSSMPosterior</span></code></a>([hidden_dim, state_dim, scale_lb])</p></td>
<td><p>The posterior network of the RSSM.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.RSSMPrior.html#torchrl.modules.RSSMPrior" title="torchrl.modules.RSSMPrior"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RSSMPrior</span></code></a>(action_spec[, hidden_dim, ...])</p></td>
<td><p>The prior network of the RSSM.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="multi-agent-specific-modules">
<h3>Multi-agent-specific modules<a class="headerlink" href="#multi-agent-specific-modules" title="Permalink to this heading">¶</a></h3>
<p>These networks implement models that can be used in
multi-agent contexts.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.MultiAgentMLP.html#torchrl.modules.MultiAgentMLP" title="torchrl.modules.MultiAgentMLP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiAgentMLP</span></code></a>(n_agent_inputs, ...)</p></td>
<td><p>Mult-agent MLP.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.MultiAgentConvNet.html#torchrl.modules.MultiAgentConvNet" title="torchrl.modules.MultiAgentConvNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiAgentConvNet</span></code></a>(n_agents, centralised, ...)</p></td>
<td><p>Multi-agent CNN.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.QMixer.html#torchrl.modules.QMixer" title="torchrl.modules.QMixer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">QMixer</span></code></a>(state_shape, mixing_embed_dim, ...)</p></td>
<td><p>QMix mixer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.VDNMixer.html#torchrl.modules.VDNMixer" title="torchrl.modules.VDNMixer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VDNMixer</span></code></a>(n_agents, device)</p></td>
<td><p>Value-Decomposition Network mixer.</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="exploration">
<h2>Exploration<a class="headerlink" href="#exploration" title="Permalink to this heading">¶</a></h2>
<p>Noisy linear layers are a popular way of exploring the environment without
altering the actions, but by integrating the stochasticity in the weight
configuration.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.NoisyLinear.html#torchrl.modules.NoisyLinear" title="torchrl.modules.NoisyLinear"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NoisyLinear</span></code></a>(in_features, out_features[, ...])</p></td>
<td><p>Noisy Linear Layer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.NoisyLazyLinear.html#torchrl.modules.NoisyLazyLinear" title="torchrl.modules.NoisyLazyLinear"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NoisyLazyLinear</span></code></a>(out_features[, bias, ...])</p></td>
<td><p>Noisy Lazy Linear Layer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.reset_noise.html#torchrl.modules.reset_noise" title="torchrl.modules.reset_noise"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_noise</span></code></a>(layer)</p></td>
<td><p>Resets the noise of noisy layers.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="planners">
<h2>Planners<a class="headerlink" href="#planners" title="Permalink to this heading">¶</a></h2>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.CEMPlanner.html#torchrl.modules.CEMPlanner" title="torchrl.modules.CEMPlanner"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CEMPlanner</span></code></a>(*args, **kwargs)</p></td>
<td><p>CEMPlanner Module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.MPCPlannerBase.html#torchrl.modules.MPCPlannerBase" title="torchrl.modules.MPCPlannerBase"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MPCPlannerBase</span></code></a>(*args, **kwargs)</p></td>
<td><p>MPCPlannerBase abstract Module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.MPPIPlanner.html#torchrl.modules.MPPIPlanner" title="torchrl.modules.MPPIPlanner"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MPPIPlanner</span></code></a>(*args, **kwargs)</p></td>
<td><p>MPPI Planner Module.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="distributions">
<h2>Distributions<a class="headerlink" href="#distributions" title="Permalink to this heading">¶</a></h2>
<p>Some distributions are typically used in RL scripts.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.Delta.html#torchrl.modules.Delta" title="torchrl.modules.Delta"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Delta</span></code></a>(param[, atol, rtol, batch_shape, ...])</p></td>
<td><p>Delta distribution.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.IndependentNormal.html#torchrl.modules.IndependentNormal" title="torchrl.modules.IndependentNormal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">IndependentNormal</span></code></a>(loc, scale[, upscale, ...])</p></td>
<td><p>Implements a Normal distribution with location scaling.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.NormalParamWrapper.html#torchrl.modules.NormalParamWrapper" title="torchrl.modules.NormalParamWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NormalParamWrapper</span></code></a>(operator[, ...])</p></td>
<td><p>A wrapper for normal distribution parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.TanhNormal.html#torchrl.modules.TanhNormal" title="torchrl.modules.TanhNormal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TanhNormal</span></code></a>(loc, scale[, upscale, min, max, ...])</p></td>
<td><p>Implements a TanhNormal distribution with location scaling.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.TruncatedNormal.html#torchrl.modules.TruncatedNormal" title="torchrl.modules.TruncatedNormal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TruncatedNormal</span></code></a>(loc, scale[, upscale, min, ...])</p></td>
<td><p>Implements a Truncated Normal distribution with location scaling.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.TanhDelta.html#torchrl.modules.TanhDelta" title="torchrl.modules.TanhDelta"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TanhDelta</span></code></a>(param[, min, max, event_dims, ...])</p></td>
<td><p>Implements a Tanh transformed_in Delta distribution.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.OneHotCategorical.html#torchrl.modules.OneHotCategorical" title="torchrl.modules.OneHotCategorical"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OneHotCategorical</span></code></a>([logits, probs, grad_method])</p></td>
<td><p>One-hot categorical distribution.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.MaskedCategorical.html#torchrl.modules.MaskedCategorical" title="torchrl.modules.MaskedCategorical"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MaskedCategorical</span></code></a>([logits, probs, mask, ...])</p></td>
<td><p>MaskedCategorical distribution.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.MaskedOneHotCategorical.html#torchrl.modules.MaskedOneHotCategorical" title="torchrl.modules.MaskedOneHotCategorical"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MaskedOneHotCategorical</span></code></a>([logits, probs, ...])</p></td>
<td><p>MaskedCategorical distribution.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="utils">
<h2>Utils<a class="headerlink" href="#utils" title="Permalink to this heading">¶</a></h2>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.utils.mappings.html#torchrl.modules.utils.mappings" title="torchrl.modules.utils.mappings"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mappings</span></code></a>(key)</p></td>
<td><p>Given an input string, returns a surjective function f(x): R -&gt; R^+.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.modules.utils.inv_softplus.html#torchrl.modules.utils.inv_softplus" title="torchrl.modules.utils.inv_softplus"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inv_softplus</span></code></a>(bias)</p></td>
<td><p>Inverse softplus function.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.utils.biased_softplus.html#torchrl.modules.utils.biased_softplus" title="torchrl.modules.utils.biased_softplus"><code class="xref py py-obj docutils literal notranslate"><span class="pre">biased_softplus</span></code></a>(bias[, min_val])</p></td>
<td><p>A biased softplus module.</p></td>
</tr>
</tbody>
</table>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.modules.VmapModule.html#torchrl.modules.VmapModule" title="torchrl.modules.VmapModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VmapModule</span></code></a>(*args, **kwargs)</p></td>
<td><p>A TensorDictModule wrapper to vmap over the input.</p></td>
</tr>
</tbody>
</table>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="generated/torchrl.modules.tensordict_module.Actor.html" class="btn btn-neutral float-right" title="Actor" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="generated/torchrl.envs.set_gym_backend.html" class="btn btn-neutral" title="set_gym_backend" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">torchrl.modules package</a><ul>
<li><a class="reference internal" href="#tensordict-modules-actors-exploration-value-models-and-generative-models">TensorDict modules: Actors, exploration, value models and generative models</a><ul>
<li><a class="reference internal" href="#tensordictmodules-and-safemodules">TensorDictModules and SafeModules</a></li>
<li><a class="reference internal" href="#exploration-wrappers">Exploration wrappers</a></li>
<li><a class="reference internal" href="#probabilistic-actors">Probabilistic actors</a></li>
<li><a class="reference internal" href="#q-value-actors">Q-Value actors</a></li>
<li><a class="reference internal" href="#value-operators-and-joined-models">Value operators and joined models</a></li>
<li><a class="reference internal" href="#domain-specific-tensordict-modules">Domain-specific TensorDict modules</a></li>
</ul>
</li>
<li><a class="reference internal" href="#hooks">Hooks</a></li>
<li><a class="reference internal" href="#models">Models</a><ul>
<li><a class="reference internal" href="#regular-modules">Regular modules</a></li>
<li><a class="reference internal" href="#algorithm-specific-modules">Algorithm-specific modules</a></li>
<li><a class="reference internal" href="#multi-agent-specific-modules">Multi-agent-specific modules</a></li>
</ul>
</li>
<li><a class="reference internal" href="#exploration">Exploration</a></li>
<li><a class="reference internal" href="#planners">Planners</a></li>
<li><a class="reference internal" href="#distributions">Distributions</a></li>
<li><a class="reference internal" href="#utils">Utils</a><ul>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/design-tabs.js"></script>
         <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>

        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>
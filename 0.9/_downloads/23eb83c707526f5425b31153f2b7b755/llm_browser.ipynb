{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# TorchRL LLM: Building Tool-Enabled Environments\n\n**Author**: [Vincent Moens](https://github.com/vmoens)\n\n\nThis tutorial demonstrates how to build and compose LLM environments with tool capabilities\nin TorchRL. We'll show how to create a complete environment that can execute tools,\nformat responses, and handle interactions between the LLM and external tools.\n\nThe tutorial uses web browsing as a concrete example, but the concepts apply to any\ntool integration in TorchRL's LLM framework.\n\nMain takeaways:\n\n- Understanding TorchRL's LLM environment composition\n- Creating and appending tool transforms\n- Formatting tool responses and LLM interactions\n- Handling tool execution and state management\n\nPrerequisites: Basic familiarity with TorchRL's environment concepts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation\n\nFirst, install TorchRL with LLM support. If you're running this in a Jupyter\nnotebook, you can install the packages using:\n\n```bash\n%pip install \"torchrl[llm]\"    # Install TorchRL with all LLM dependencies\n```\nThe `torchrl[llm]` package includes all necessary dependencies for LLM functionality,\nincluding transformers, vllm, and playwright for browser automation.\n\nAfter installation, you'll need to set up the browser automation components:\n\n```bash\n!playwright install            # Install browser binaries\n```\nNote: The `!` and `%pip` prefixes are specific to Jupyter notebooks. In a regular\nterminal, use these commands without the prefixes.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n\nTorchRL's LLM interface is built around composable environments and transforms.\nThe key components are:\n\n1. A base environment (ChatEnv)\n2. Tool execution transforms\n3. Data loading transforms\n4. Reward computation transforms\n\nLet's import the necessary components and set up our environment.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nimport warnings\n\nimport torch\n\nfrom tensordict import set_list_to_stack, TensorDict\nfrom torchrl import torchrl_logger\nfrom torchrl.data import CompositeSpec, Unbounded\nfrom torchrl.envs import Transform\nfrom torchrl.envs.llm import ChatEnv\nfrom torchrl.envs.llm.transforms.browser import BrowserTransform\nfrom transformers import AutoTokenizer\n\nwarnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Basic Environment Configuration\n\nWe'll create a ChatEnv and configure it with browser automation capabilities.\nFirst, we enable list-to-stack conversion for TensorDict, which is required\nfor proper batch handling in LLM environments.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Enable list-to-stack conversion for TensorDict\nset_list_to_stack(True).set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we'll create the tokenizer and base environment. The environment requires\na batch size, even if we're only running a single instance.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\")\nenv = ChatEnv(\n    batch_size=(1,),\n    tokenizer=tokenizer,\n    apply_template=True,\n    system_prompt=(\n        \"You are a helpful assistant that can use tools to accomplish tasks. \"\n        \"Tools will be executed and their responses will be added to our conversation.\"\n    ),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we'll add the browser transform with safety configurations. This transform\nenables web browsing capabilities with domain restrictions for security.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "browser_transform = BrowserTransform(\n    allowed_domains=[\"google.com\", \"github.com\"],\n    headless=False,  # Set to False to see the browser actions\n)\nenv = env.append_transform(browser_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also design a transform to assign rewards to the environment.\nFor example, we can parse the result of the browser transform to assign a reward\nwhenever specific goals are achieved. Very simply, in this example, we will assign\na reward of 2 if the LLM finds the answer to the question (Paris), a reward of 1 if it\nreaches the desired website, and a reward of 0 otherwise.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class RewardTransform(Transform):\n    \"\"\"A transform that assigns rewards based on the LLM's responses.\n\n    This transform parses the browser responses in the environment's history and assigns\n    rewards based on specific achievements:\n\n    - Finding the correct answer (Paris): reward = 2.0\n    - Successfully reaching Google: reward = 1.0\n    - Otherwise: reward = 0.0\n\n    \"\"\"\n\n    def _call(self, tensordict: TensorDict) -> TensorDict:\n        \"\"\"Process the tensordict and assign rewards based on the LLM's response.\n\n        Args:\n            tensordict (TensorDict): The tensordict containing the environment state.\n                Must have a \"history\" key containing the conversation history.\n\n        Returns:\n            TensorDict: The tensordict with an added \"reward\" key containing the\n                computed reward with shape (B, 1) where B is the batch size.\n        \"\"\"\n        # ChatEnv has created a history item. We just pick up the last item,\n        # and check if `\"Paris\"` is in the response.\n        # We use index 0 because we are in a single-instance environment.\n        history = tensordict[0][\"history\"]\n        last_item = history[-1]\n        if \"Paris\" in last_item.content:\n            torchrl_logger.info(\"Found the answer to the question: Paris\")\n            # Recall that rewards have a trailing singleton dimension.\n            tensordict[\"reward\"] = torch.full((1, 1), 2.0)\n        # Check if we successfully reached the website\n        elif (\n            \"google.com\" in last_item.content\n            and \"executed successfully\" in last_item.content\n        ):\n            torchrl_logger.info(\"Reached the website google.com\")\n            tensordict[\"reward\"] = torch.full((1, 1), 1.0)\n        else:\n            tensordict[\"reward\"] = torch.full((1, 1), 0.0)\n        return tensordict\n\n    def transform_reward_spec(self, reward_spec: CompositeSpec) -> CompositeSpec:\n        \"\"\"Transform the reward spec to include our custom reward.\n\n        This method is required to override the reward spec since the environment\n        is initially reward-agnostic.\n\n        Args:\n            reward_spec (CompositeSpec): The original reward spec from the environment.\n\n        Returns:\n            CompositeSpec: The transformed reward spec with our custom reward definition.\n                The reward will have shape (B, 1) where B is the batch size.\n        \"\"\"\n        reward_spec[\"reward\"] = Unbounded(\n            shape=reward_spec.shape + (1,), dtype=torch.float32\n        )\n        return reward_spec\n\n\n# We append the reward transform to the environment.\nenv = env.append_transform(RewardTransform())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Tool Execution Helper\n\nTo make our interaction with tools more organized, we'll create a helper function\nthat executes tool actions and displays the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def execute_tool_action(\n    env: ChatEnv,\n    current_state: TensorDict,\n    action: str,\n    verbose: bool = True,\n) -> tuple[TensorDict, TensorDict]:\n    \"\"\"Execute a tool action and show the formatted interaction.\"\"\"\n    s = current_state.set(\"text_response\", [action])\n    s, s_ = env.step_and_maybe_reset(s)\n\n    if verbose:\n        print(\"\\nLLM Action:\")\n        print(\"-----------\")\n        print(action)\n        print(\"\\nEnvironment Response:\")\n        print(\"--------------------\")\n        torchrl_logger.info(s_[\"history\"].apply_chat_template(tokenizer=env.tokenizer))\n\n    return s, s_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Starting the Interaction\n\nLet's begin by initializing the environment with a question and navigating\nto a search engine. Note that the tensordict used as input to the environment\nmust share the same batch size as the environment. The text query is put in a list\nof length 1, such that it is compatible with the environment's batch size.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reset = env.reset(\n    TensorDict(\n        text=[\"What is the capital of France?\"],\n        batch_size=(1,),\n    )\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we'll navigate to Google using the browser transform. The transform\nexpects actions in a specific JSON format wrapped in tool tags.\nIn practice, this action should be the output of our LLM which\nwill write the response string in the `\"text_response\"` key.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s, s_ = execute_tool_action(\n    env,\n    reset,\n    \"\"\"\n    Let me search for that:\n    <tool>browser\n    {\n        \"action\": \"navigate\",\n        \"url\": \"https://google.com\"\n    }\n    </tool><|im_end|>\n    \"\"\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Performing the Search\n\nWith the browser open, we can now type our query and execute the search.\nFirst, we'll type the search query into Google's search box.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s, s_ = execute_tool_action(\n    env,\n    s_,\n    \"\"\"\n    Let me type the search query:\n    <tool>browser\n    {\n        \"action\": \"type\",\n        \"selector\": \"[name='q']\",\n        \"text\": \"What is the capital of France?\"\n    }\n    </tool><|im_end|>\n    \"\"\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we'll click the search button to execute the search. Note how we\nuse CSS selectors to identify elements on the page.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s, s_ = execute_tool_action(\n    env,\n    s_,\n    \"\"\"\n    Now let me click the search button:\n    <tool>browser\n    {\n        \"action\": \"click\",\n        \"selector\": \"[name='btnK']\"\n    }\n    </tool><|im_end|>\n    \"\"\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Extracting Results\n\nFinally, we'll extract the search results from the page. The browser transform\ncan extract both text content and HTML from specified elements.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s, s_ = execute_tool_action(\n    env,\n    s_,\n    \"\"\"\n    Let me extract the results:\n    <tool>browser\n    {\n        \"action\": \"extract\",\n        \"selector\": \"#search\",\n        \"extract_type\": \"text\"\n    }\n    </tool><|im_end|>\n    \"\"\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's close the environment.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nThis tutorial demonstrates how to build and compose LLM environments with tool capabilities\nin TorchRL. We've shown how to create a complete environment that can execute tools,\nformat responses, and handle interactions between the LLM and external tools.\n\nThe key concepts are:\n\n1. Understanding TorchRL's LLM environment composition\n2. Creating and appending tool transforms\n3. Formatting tool responses and LLM interactions\n4. Handling tool execution and state management\n5. Integrating with LLM wrappers (vLLM, Transformers)\n\nSee the `ref_llms` tutorial for more information on how to build tool-enabled\nenvironments with TorchRL.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
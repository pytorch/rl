{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb434aa2",
   "metadata": {},
   "source": [
    "[<img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\">](https://colab.research.google.com/github/pytorch/rl/blob/main/tutorials/tensordict.ipynb)\n",
    "\n",
    "# TensorDict tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c9af6f",
   "metadata": {},
   "source": [
    "`TensorDict` is a new tensor structure introduced in TorchRL. \n",
    "\n",
    "With RL, you need to be able to deal with multiple tensors such as actions, observations and reward. `TensorDict` makes it more convenient to deal with multiple tensors at the same time for operations such as casting to device, reshaping, stacking etc.\n",
    "\n",
    "Furthermore, different RL algorithms can deal with different input and outputs. The `TensorDict` class makes it possible to abstract away the differences between these algorithmes. \n",
    "\n",
    "TensorDict combines the convinience of using `dict`s to organize your data with the power of pytorch tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583b5222",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install functorch\n",
    "!pip install torchrl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a68c0",
   "metadata": {},
   "source": [
    "## Improving the modularity of codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176ca112",
   "metadata": {},
   "source": [
    "Let's suppose we have 2 datasets: Dataset A which has images and labels and Dataset B which has images, segmentation maps and labels. \n",
    "\n",
    "Suppose we want to train a common algorithm over these two datasets (i.e. an algorithm that would ignore the mask or infer it when needed). \n",
    "\n",
    "In classical pytorch we would need to do the following:\n",
    "```python\n",
    "#Method A\n",
    "for i in range(optim_steps):\n",
    "    images, labels = get_data_A()\n",
    "    loss = loss_module(images, labels)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "````\n",
    "\n",
    "```python\n",
    "#Method B\n",
    "for i in range(optim_steps):\n",
    "    images, masks, labels = get_data_B()\n",
    "    loss = loss_module(images, labels)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "```\n",
    "\n",
    "We can see that this limits the reusability of code. A lot of code has to be rewriten because of the modality difference between the 2 datasets.\n",
    "The idea of TensorDict is to do the following:\n",
    "\n",
    "```python\n",
    "# General Method\n",
    "for i in range(optim_steps):\n",
    "    tensordict = get_data()\n",
    "    loss = loss_module(tensordict)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "```\n",
    "\n",
    "We can now reuse the same training loop across datasets and losses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9f630f",
   "metadata": {},
   "source": [
    "#### Can't I do this with a python dict?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc5f579",
   "metadata": {},
   "source": [
    "One could argue that you could achieve the same results with a dataset that outputs a pytorch dict. \n",
    "```python\n",
    "class DictDataset(Dataset):\n",
    "    ...\n",
    "    \n",
    "    def __getitem__(self, idx)\n",
    "        \n",
    "    ...\n",
    "    \n",
    "        return {\"images\": image, \"masks\": mask}\n",
    "    \n",
    "```\n",
    "\n",
    "However to achieve this you would need to write a complicated collate function that make sure that every modality is agregated properly.\n",
    "\n",
    "```python\n",
    "\n",
    "def collate_dict_fn(dict_list):\n",
    "    final_dict = {}\n",
    "    for key in dict_list[0].keys():\n",
    "        final_dict[key]= []\n",
    "        for single_dict in dict_list:\n",
    "            final_dict[key].append(single_dict[key])\n",
    "        final_dict[key] = torch.stack(final_dict[key], dim=0)\n",
    "    return final_dict\n",
    "\n",
    "\n",
    "dataloader = Dataloader(DictDataset(), collate_fn = collate_dict_fn)\n",
    "\n",
    "````\n",
    "With TensorDicts this is now much simpler:\n",
    "\n",
    "```python\n",
    "class DictDataset(Dataset):\n",
    "    ...\n",
    "    \n",
    "    def __getitem__(self, idx)\n",
    "        \n",
    "        ...\n",
    "    \n",
    "        return TensorDict({\"images\": image, \"masks\": mask})\n",
    "```\n",
    "\n",
    "\n",
    "Here, the collate function is as simple as:\n",
    "```python\n",
    "collate_tensordict_fn = lambda tds : torch.stack(tds, dim=0)\n",
    "\n",
    "dataloader = Dataloader(DictDataset(), collate_fn = collate_tensordict_fn)\n",
    "```\n",
    "This is even more useful when considering nested structures (Which `TensorDict`supports).\n",
    "\n",
    "TensorDict inherits multiple properties from `torch.Tensor` and `dict` that we will detail furtherdown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a951e2e1",
   "metadata": {},
   "source": [
    "## `TensorDict` structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f94ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.data import TensorDict\n",
    "from torchrl.data.tensordict.tensordict import UnsqueezedTensorDict, ViewedTensorDict, PermutedTensorDict, LazyStackedTensorDict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc6d6f0",
   "metadata": {},
   "source": [
    "TensorDict is a Datastructure indexed by either keys or numerical indices. The values can either be tensors, memory-mapped tensors or `TensorDict`. The values need to share the same memory location (device or shared memory). They can however have different dtypes.\n",
    "\n",
    "Another essential property of TensorDict is the `batch_size` (or `shape`) which is defined as the n-first dimensions of the tensors. It must be common across values, and it must be set explicitly when instantiating a `TensorDict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac1afa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caramba!\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(3, 4)\n",
    "b = torch.zeros(3, 4, 5)\n",
    "\n",
    "# works\n",
    "tensordict = TensorDict({\"a\": a, \"b\": b}, batch_size=[3, 4])\n",
    "tensordict = TensorDict({\"a\": a, \"b\": b}, batch_size=[3])\n",
    "tensordict = TensorDict({\"a\": a, \"b\": b}, batch_size=[])\n",
    "\n",
    "# does not work\n",
    "try:\n",
    "    tensordict = TensorDict({\"a\": a, \"b\": b}, batch_size=[3, 4, 5])\n",
    "except:\n",
    "    print(\"caramba!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bc7e09",
   "metadata": {},
   "source": [
    "Nested `TensorDict`have therefore the following property: the parent `TensorDict` needs to have a batch_size included in the childs `TensorDict` batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1128846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32),\n",
      "        b: TensorDict(\n",
      "            fields={\n",
      "                c: Tensor(torch.Size([3, 4, 5, 1]), dtype=torch.int32),\n",
      "                d: Tensor(torch.Size([3, 4, 5, 6]), dtype=torch.float32)},\n",
      "            batch_size=torch.Size([3, 4, 5]),\n",
      "            device=cpu,\n",
      "            is_shared=False)},\n",
      "    batch_size=torch.Size([3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(3, 4)\n",
    "b = TensorDict(\n",
    "    {\n",
    "    \"c\": torch.zeros(3, 4, 5, dtype=torch.int32),\n",
    "    \"d\": torch.zeros(3, 4, 5, 6, dtype=torch.float32)\n",
    "    },\n",
    "    batch_size=[3, 4, 5]\n",
    ")\n",
    "tensordict = TensorDict({\"a\": a, \"b\": b}, batch_size=[3, 4])\n",
    "print(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a2e595",
   "metadata": {},
   "source": [
    "`TensorDict` does not support algebraic operations by design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0971a213",
   "metadata": {},
   "source": [
    "## `TensorDict` dictionary features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fe60e5",
   "metadata": {},
   "source": [
    "`TensorDict` shares a lot of features with python dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c630ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(3, 4, 5)\n",
    "b = torch.zeros(3, 4)\n",
    "tensordict = TensorDict({\"a\": a, \"b\": b}, batch_size=[3, 4])\n",
    "print(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aadf93",
   "metadata": {},
   "source": [
    "### `get(key)`\n",
    "If we want to access a certain key, we can index the tensordict or alternatively use the `get` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72cb7188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get and __getitem__ match: True\n",
      "torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "print(\"get and __getitem__ match:\", tensordict[\"a\"] is tensordict.get(\"a\") is a)\n",
    "print(tensordict[\"a\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1831f512",
   "metadata": {},
   "source": [
    "The `get` method also supports default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdad5e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tensordict.get(\"foo\", torch.ones(3))\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fd45ff",
   "metadata": {},
   "source": [
    "### `set(key, value)`\n",
    "The `set()` method can be used to set new values. Regular indexing also does the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81baa167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "td[\"c\"] is c: True\n",
      "td[\"d\"] is d: True\n"
     ]
    }
   ],
   "source": [
    "c = torch.zeros((3, 4, 2, 2))\n",
    "tensordict.set(\"c\", c)\n",
    "print(f\"td[\\\"c\\\"] is c: {c is tensordict['c']}\")\n",
    "\n",
    "d = torch.zeros((3, 4, 2, 2))\n",
    "tensordict[\"d\"] = d\n",
    "print(f\"td[\\\"d\\\"] is d: {d is tensordict['d']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96076395",
   "metadata": {},
   "source": [
    "### `keys()`\n",
    "We can access the keys of a tensordict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99501c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensordict[\"c\"] = torch.zeros(tensordict.shape)\n",
    "tensordict.set(\"d\", torch.ones(tensordict.shape))\n",
    "assert (tensordict[\"c\"] == 0).all()\n",
    "assert (tensordict[\"d\"] == 1).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a55f0",
   "metadata": {},
   "source": [
    "### `values()`\n",
    "The values of a `TensorDict` can be retrieved with the `values()` function. \n",
    "Note that, unlike python `dict`s, the `values()` method returns a generator and not a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e6c0a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([3, 4, 1])\n",
      "torch.Size([3, 4, 1])\n",
      "torch.Size([3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "for value in tensordict.values():\n",
    "    print(value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde2f9c",
   "metadata": {},
   "source": [
    "### `update(tensordict_or_dict)`\n",
    "The `update` method can be used to update a TensorDict with another one (or with a dict):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d53656d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is now equal to 1: True\n",
      "d is now equal to 2: True\n"
     ]
    }
   ],
   "source": [
    "tensordict.update({\"a\": torch.ones((3, 4, 5)), \"d\": 2*torch.ones((3, 4, 2))})\n",
    "# Also works with tensordict.update(TensorDict({\"a\":torch.ones((3, 4, 5)), \"c\":torch.ones((3, 4, 2))}, batch_size=[3,4]))\n",
    "print(f\"a is now equal to 1: {(tensordict['a'] == 1).all()}\")\n",
    "print(f\"d is now equal to 2: {(tensordict['d'] == 2).all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2d338c",
   "metadata": {},
   "source": [
    "### `del`\n",
    "TensorDict also support keys deletion with the `del` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3167e6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before dict_keys(['a', 'b', 'c', 'd'])\n",
      "after dict_keys(['a', 'b', 'd'])\n"
     ]
    }
   ],
   "source": [
    "print(\"before\", tensordict.keys())\n",
    "del tensordict[\"c\"]\n",
    "print(\"after\", tensordict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026b17e9",
   "metadata": {},
   "source": [
    "## TensorDict tensor features\n",
    "On many regards, TensorDict is a Tensor-like class: a great deal of tensor operation also work on tensordicts, making it easy to cast them across multiple tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74546249",
   "metadata": {},
   "source": [
    "### Batch size\n",
    "`TensorDict` has a batch size which is shared across all tensors. The batch size can be [], unidimensional or multidimensional according to your needs, but it must be shared across tensors.\n",
    "Indeed, you cannot have items that don't share the batch size inside the same TensorDict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "700432af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our TensorDict is of size torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\": torch.zeros(3, 4, 5), \"b\": torch.zeros(3, 4)}, batch_size=[3, 4])\n",
    "print(f\"Our TensorDict is of size {tensordict.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6eb84b",
   "metadata": {},
   "source": [
    "The batch size can be changed if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a92ddb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caramba! We got this error: batch dimension mismatch, got self.batch_size=torch.Size([3, 4]) and tensor.shape[:self.batch_dims]=torch.Size([4, 3]) with tensor tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.]]])\n"
     ]
    }
   ],
   "source": [
    "# we cannot add tensors that violate the batch size:\n",
    "try:\n",
    "    tensordict.update({\"c\": torch.zeros(4, 3, 1)})\n",
    "except RuntimeError as err:\n",
    "    print(f\"Caramba! We got this error: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8648b51",
   "metadata": {},
   "source": [
    "but it must comply with the tensor shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd5ac381",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensordict.batch_size = [3]\n",
    "assert tensordict.batch_size == torch.Size([3])\n",
    "tensordict.batch_size = [3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a83fca62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caramba! We got this error: the tensor a has shape torch.Size([3, 4, 5]) which is incompatible with the new shape torch.Size([4, 4]).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tensordict.batch_size = [4, 4]\n",
    "except RuntimeError as err:\n",
    "    print(f\"Caramba! We got this error: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bec7cc",
   "metadata": {},
   "source": [
    "We can also fill the values of a TensorDict sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "355c3973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([10, 3, 4]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "tensordict = TensorDict({}, [10])\n",
    "for i in range(10):\n",
    "    tensordict[i] = TensorDict({\"a\": torch.randn(3, 4)}, [])\n",
    "print(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b2b2ee",
   "metadata": {},
   "source": [
    "If all values are not filled, they get the default value of zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a00368cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensordict = TensorDict({}, [10])\n",
    "for i in range(2):\n",
    "    tensordict[i] = TensorDict({\"a\": torch.randn(3, 4)}, [])\n",
    "assert (tensordict[9][\"a\"] == torch.zeros((3,4))).all()\n",
    "tensordict = TensorDict({\"a\": torch.zeros(3, 4, 5), \"b\": torch.zeros(3, 4)}, batch_size=[3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c329c2",
   "metadata": {},
   "source": [
    "### Devices\n",
    "TensorDict can be sent to the desired devices like a pytorch tensor with `td.cuda()` or `td.to(device)` with `device`the desired device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b167e5e6",
   "metadata": {},
   "source": [
    "### Memory sharing via physical memory usage\n",
    "When on cpu, one can use either `tensordict.memmap_()` or `tensordict.share_memory_()` to send a `tensordict` to represent it as a memory-mapped collection of tensors or put it in shared memory resp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8c5480",
   "metadata": {},
   "source": [
    "### Tensor operations\n",
    "We can perform tensor operations among the batch dimensions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86426df",
   "metadata": {},
   "source": [
    "#### Cloning\n",
    "TensorDict supports cloning. Cloning returns the same TensorDict class than the original item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96010e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content is identical (True) but duplicated (True)\n"
     ]
    }
   ],
   "source": [
    "tensordict_clone = tensordict.clone()\n",
    "print(f\"Content is identical ({(tensordict['a'] == tensordict_clone['a']).all()}) but duplicated ({tensordict['a'] is not tensordict_clone['a']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa5397",
   "metadata": {},
   "source": [
    "#### Slicing and indexing\n",
    "Slicing and indexing is supported along the batch dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5f1dd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([4, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([4, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([4]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "698c7d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([2, 4, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([2, 4, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([2, 4]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0737916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([3, 2, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([3, 2, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([3, 2]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb307673",
   "metadata": {},
   "source": [
    "#### Setting values with indexing\n",
    "In general, `tensodict[tuple_index] = new_tensordict` will work as long as the batch sizes match.\n",
    "\n",
    "If one wants to build a tensordict that keeps track of the original tensordict, the `get_sub_tensordict` method can be used: in that case, a `SubTensorDict` instance will be returned. This class will store a pointer to the original tensordict as well as the desired index such that tensor modifications can be achieved easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dcc2d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensordict = TensorDict({\"a\": torch.zeros(3, 4, 5), \"b\": torch.zeros(3, 4)}, batch_size=[3, 4])\n",
    "subtd = tensordict.get_sub_tensordict((slice(None), torch.tensor([1, 3])))  #Â a SubTensorDict keeps track of the original one: it does not create a copy in memory of the original data\n",
    "tensordict.fill_(\"a\", -1)\n",
    "assert (subtd[\"a\"] == -1).all(), subtd[\"a\"]  # the \"a\" key-value pair has changed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc44ed9b",
   "metadata": {},
   "source": [
    "We can set values easily just by indexing the tensordict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73b2c8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "         [[-1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1.]]]),\n",
       " tensor([[[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td2 = TensorDict({\"a\": torch.zeros(2, 4, 5), \"b\": torch.zeros(2, 4)}, batch_size=[2, 4])\n",
    "tensordict[:-1] = td2\n",
    "tensordict[\"a\"], tensordict[\"b\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79634420",
   "metadata": {},
   "source": [
    "#### Masking\n",
    "We mask `TensorDict` as we mask tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ef55592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([6, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([6, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([6]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.BoolTensor([[1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0]])\n",
    "tensordict[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2633c494",
   "metadata": {},
   "source": [
    "#### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4e47ba",
   "metadata": {},
   "source": [
    "TensorDict supports stacking. By default, stacking is done in a lazy fashion, returning a `LazyStackedTensorDict` item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c1c63b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LazyStackedTensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([2, 3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([2, 3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([2, 3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "every tensordict is awesome!\n"
     ]
    }
   ],
   "source": [
    "# Stack\n",
    "clonned_tensordict = tensordict.clone()\n",
    "staked_tensordict = torch.stack([tensordict, clonned_tensordict], dim=0)\n",
    "print(staked_tensordict)\n",
    "\n",
    "# indexing a lazy stack returns the original tensordicts\n",
    "if staked_tensordict[0] is tensordict and staked_tensordict[1] is clonned_tensordict:\n",
    "    print(\"every tensordict is awesome!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0df64e7",
   "metadata": {},
   "source": [
    "If we want to have a contiguous tensordict, we can call `.to_tensordict()` or `.contiguous()`. It is recommended to perform this operation before accessing the values of the stacked tensordict for efficiency purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c63a51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(staked_tensordict.contiguous(), TensorDict)\n",
    "assert isinstance(staked_tensordict.to_tensordict(), TensorDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4223378",
   "metadata": {},
   "source": [
    "#### Unbind\n",
    "TensorDict can be unbound along a dim over the tensordict batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8a8c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tensordict = tensordict.unbind(0)\n",
    "assert type(list_tensordict) == tuple\n",
    "assert len(list_tensordict) == 3\n",
    "assert (torch.stack(list_tensordict, dim=0).contiguous() == tensordict).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef05faf",
   "metadata": {},
   "source": [
    "#### Cat\n",
    "TensorDict supports cat to concatenate among a dim. The dim must be lower than the `batch_dims` (i.e. the length of the batch_size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df18bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cat\n",
    "list_tensordict = tensordict.unbind(0)\n",
    "assert torch.cat(list_tensordict, dim=0).shape[0] == 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714b58f5",
   "metadata": {},
   "source": [
    "#### View\n",
    "Support for the view operation returning a `ViewedTensorDict`. Use `to_tensordict` to comeback to retrieve TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c3f6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(tensordict.view(-1)) == ViewedTensorDict\n",
    "assert tensordict.view(-1).shape[0] == 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc0de22",
   "metadata": {},
   "source": [
    "#### Permute\n",
    "We can permute the dims of `TensorDict`. Permute is a Lazy operation that returns PermutedTensorDict. Use `to_tensordict` to convert to `TensorDict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0277b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(tensordict.permute(1,0)) == PermutedTensorDict\n",
    "assert tensordict.permute(1,0).batch_size == torch.Size([4, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c11078",
   "metadata": {},
   "source": [
    "#### Reshape\n",
    "Reshape allows reshaping the `TensorDict` batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17241cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tensordict.reshape(-1).batch_size == torch.Size([12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585b3659",
   "metadata": {},
   "source": [
    "#### Squeeze and Unsqueeze\n",
    "Tensordict also supports squeeze and unsqueeze. Unsqueeze is a lazy operation that returns UnsqueezedTensorDict. Use `to_tensordict` to retrieve a tensordict after unsqueeze.\n",
    "Calling `unsqueeze(dim).squeeze(dim)` returns the original tensordict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1cda445",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsqueezed_tensordict = tensordict.unsqueeze(0)\n",
    "assert type(unsqueezed_tensordict) == UnsqueezedTensorDict\n",
    "assert unsqueezed_tensordict.batch_size == torch.Size([1, 3, 4])\n",
    "\n",
    "assert type(unsqueezed_tensordict.squeeze(0)) == TensorDict\n",
    "assert unsqueezed_tensordict.squeeze(0) is tensordict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ccd34a",
   "metadata": {},
   "source": [
    "Have fun with TensorDict!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

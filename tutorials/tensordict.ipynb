{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3a5154f",
   "metadata": {},
   "source": [
    "# TensorDict tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a11582",
   "metadata": {},
   "source": [
    "`TensorDict` is a new tensor structure introduced in TorchRL. \n",
    "\n",
    "With RL, you need to be able to deal with multiple tensors such as actions, observations and reward. `TensorDict` aims at making it more convenient to deal with multiple tensors at the same time. \n",
    "\n",
    "Furthermore, different RL algorithms can deal with different input and outputs. The `TensorDict` class makes it possible to abstract away the differences between these algorithmes. \n",
    "\n",
    "TensorDict combines the convinience of using `dict`s to organize your data with the power of pytorch tensors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb92ff75",
   "metadata": {},
   "source": [
    "#### Improving the modularity of codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ff018d",
   "metadata": {},
   "source": [
    "Let's suppose we have 2 datasets: Dataset A which has images and labels and Dataset B which has images, segmentation maps and labels. \n",
    "\n",
    "Suppose we want to train a common algorithm over these two datasets (i.e. an algorithm that would ignore the mask or infer it when needed). \n",
    "\n",
    "In classical pytorch we would need to do the following:\n",
    "```python\n",
    "#Method A\n",
    "for i in range(optim_steps):\n",
    "    images, labels = get_data_A()\n",
    "    loss = loss_module(images, labels)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "````\n",
    "\n",
    "```python\n",
    "#Method B\n",
    "for i in range(optim_steps):\n",
    "    images, masks, labels = get_data_B()\n",
    "    loss = loss_module(images, labels)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "```\n",
    "\n",
    "We can see that this limits the reusability of code. A lot of code has to be rewriten because of the modality difference between the 2 datasets.\n",
    "The idea of TensorDict is to do the following:\n",
    "\n",
    "```python\n",
    "# General Method\n",
    "for i in range(optim_steps):\n",
    "    tensordict = get_data()\n",
    "    loss = loss_module(tensordict)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "```\n",
    "\n",
    "\n",
    "Now we can reuse the same training loop across datasets and losses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30ea024",
   "metadata": {},
   "source": [
    "#### Can't i do this with a python dict?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421504b0",
   "metadata": {},
   "source": [
    "One could argue that you could achieve the same results with a dataset that outputs a pytorch dict. \n",
    "```python\n",
    "class DictDataset(Dataset):\n",
    "    ...\n",
    "    \n",
    "    def __getitem__(self, idx)\n",
    "        \n",
    "    ...\n",
    "    \n",
    "        return {\"images\": image, \"masks\": mask}\n",
    "    \n",
    "```\n",
    "\n",
    "However to achieve this you would need to write a complicated collate function that make sure that every modality is agregated properly.\n",
    "\n",
    "```python\n",
    "\n",
    "def collate_dict_fn(dict_list):\n",
    "    final_dict = {}\n",
    "    for key in dict_list[0].keys():\n",
    "        final_dict[key]= []\n",
    "        for single_dict in dict_list:\n",
    "            final_dict[key].append(single_dict[key])\n",
    "        final_dict[key] = torch.stack(final_dict[key], dim=0)\n",
    "    return final_dict\n",
    "\n",
    "\n",
    "dataloader = Dataloader(DictDataset(), collate_fn = collate_dict_fn)\n",
    "\n",
    "````\n",
    "With TensorDicts this is now much simpler:\n",
    "\n",
    "```python\n",
    "class DictDataset(Dataset):\n",
    "    ...\n",
    "    \n",
    "    def __getitem__(self, idx)\n",
    "        \n",
    "        ...\n",
    "    \n",
    "        return TensorDict({\"images\": image, \"masks\": mask})\n",
    "```\n",
    "\n",
    "\n",
    "Here, the collate function is as simple as:\n",
    "```python\n",
    "collate_tensordict_fn = lambda tds : torch.stack(tds, dim=0)\n",
    "\n",
    "dataloader = Dataloader(DictDataset(), collate_fn = collate_tensordict_fn)\n",
    "```\n",
    "This is even more useful when considering nested structures (Which `TensorDict`supports).\n",
    "\n",
    "TensorDict inherits multiple properties from `torch.Tensor` and `dict` that we will detail furtherdown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d19b48",
   "metadata": {},
   "source": [
    "## `TensorDict` structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d70309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.data import TensorDict\n",
    "from torchrl.data.tensordict.tensordict import UnsqueezedTensorDict, ViewedTensorDict, PermutedTensorDict, LazyStackedTensorDict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcde37f1",
   "metadata": {},
   "source": [
    "TensorDict is a Datastructure indexed by keys. The values can either be tensors, memmap-tensors or `TensorDict`. The values need to share the same device and the same shared memory. They can however have different dtypes.\n",
    "\n",
    "Another essential property of TensorDict is the batch_size. It is required when setting a `TensorDict`. We define as batch_size the n-first dimensions common to all values.\n",
    "\n",
    "Nested `TensorDict`have therefore the following property. The parent `TensorDict` needs to have a batch_size included in the childs `TensorDict` batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b19a178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32),\n",
      "        b: TensorDict(\n",
      "            fields={\n",
      "                c: Tensor(torch.Size([3, 4, 5, 1]), dtype=torch.int32),\n",
      "                d: Tensor(torch.Size([3, 4, 5, 6]), dtype=torch.float32)},\n",
      "            batch_size=torch.Size([3, 4]),\n",
      "            device=cpu,\n",
      "            is_shared=False)},\n",
      "    batch_size=torch.Size([3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(3, 4)\n",
    "b = TensorDict(\n",
    "    {\n",
    "    \"c\": torch.zeros(3, 4, 5, dtype=torch.int32),\n",
    "    \"d\": torch.zeros(3, 4, 5, 6, dtype=torch.float32)\n",
    "    },\n",
    "    batch_size=[3, 4, 5]\n",
    ")\n",
    "tensordict = TensorDict({\"a\": a, \"b\": b}, batch_size=[3, 4])\n",
    "print(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c35850",
   "metadata": {},
   "source": [
    "`TensorDict` does not support algebraic operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9757b",
   "metadata": {},
   "source": [
    "## `TensorDict` dictionary features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e16dd3",
   "metadata": {},
   "source": [
    "`TensorDict` shares a lot of features with python dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7666b1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(3, 4, 5)\n",
    "b = torch.zeros(3, 4)\n",
    "tensordict = TensorDict({\"a\": a, \"b\": b}, batch_size=[3, 4])\n",
    "print(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a85675",
   "metadata": {},
   "source": [
    "### `get(key)`\n",
    "If we want to access a certain key, we can index the tensordict or alternatively use the `get` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a04f627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "print(tensordict[\"a\"] is tensordict.get(\"a\") is a)\n",
    "print(tensordict[\"a\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae1797e",
   "metadata": {},
   "source": [
    "The `get` method also supports default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92e337a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tensordict.get(\"foo\", torch.ones(3))\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78af582",
   "metadata": {},
   "source": [
    "## `set(key, value)`\n",
    "The `set()` method can be used to set new values. Regular indexing also does the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37b50113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "td[\"c\"] is c: True\n",
      "td[\"d\"] is d: True\n"
     ]
    }
   ],
   "source": [
    "c = torch.zeros((3, 4, 2, 2))\n",
    "tensordict.set(\"c\", c)\n",
    "print(f\"td[\\\"c\\\"] is c: {c is tensordict['c']}\")\n",
    "\n",
    "d = torch.zeros((3, 4, 2, 2))\n",
    "tensordict[\"d\"] = d\n",
    "print(f\"td[\\\"d\\\"] is d: {d is tensordict['d']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c4378b",
   "metadata": {},
   "source": [
    "## Other methods:\n",
    "### `keys`\n",
    "We can access the keys of a tensordict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beeec142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n",
      "d\n"
     ]
    }
   ],
   "source": [
    "for key in tensordict.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65bf899",
   "metadata": {},
   "source": [
    "### `values`\n",
    "The values of a `TensorDict` can be retrieved with the `values()` function. Note that, unlike python `dict`s, the `values()` method returns a generator and not a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a5c4a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([3, 4, 1])\n",
      "torch.Size([3, 4, 2, 2])\n",
      "torch.Size([3, 4, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "for value in tensordict.values():\n",
    "    print(value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7caa1",
   "metadata": {},
   "source": [
    "### TensorDict.update()\n",
    "The `update` method can be used to update a TensorDict with another one (or with a dict):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "389a93a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is now equal to 1: True\n",
      "d is now equal to 2: True\n"
     ]
    }
   ],
   "source": [
    "tensordict.update({\"a\": torch.ones((3, 4, 5)), \"d\": 2*torch.ones((3, 4, 2))})\n",
    "# Also works with tensordict.update(TensorDict({\"a\":torch.ones((3, 4, 5)), \"c\":torch.ones((3, 4, 2))}, batch_size=[3,4]))\n",
    "print(f\"a is now equal to 1: {(tensordict['a'] == 1).all()}\")\n",
    "print(f\"d is now equal to 2: {(tensordict['d'] == 2).all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fac501",
   "metadata": {},
   "source": [
    "### TensorDict del key\n",
    "TensorDict also support keys deletion with the `del` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc8b5969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['a', 'b', 'd'])\n"
     ]
    }
   ],
   "source": [
    "del tensordict[\"c\"]\n",
    "print(tensordict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89409f8",
   "metadata": {},
   "source": [
    "## TensorDict as a Tensor-like object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30849ba6",
   "metadata": {},
   "source": [
    "But wait? Can't we do this with a classical dict? \n",
    "Well, we would like the TensorDict to keep some nice Pytorch properties. TensorDict combines the advantages of the Python dictionary and of a Pytorch Tensor.\n",
    "TensorDict has a batch size. It is not inferred automatically by looking at the tensors, but must be set when creating the TensorDict.\n",
    "\n",
    "TensorDict is a tensor container where all tensors are stored in akey-value pair fashion and where each element shares at least the following features:\n",
    "- device;\n",
    "- memory location (shared, memory-mapped array, ...);\n",
    "- batch size (i.e. n^th first dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7979949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\": torch.zeros(3, 4, 5), \"b\": torch.zeros(3, 4)}, batch_size=[3, 4])\n",
    "print(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e50762",
   "metadata": {},
   "source": [
    "#### Batch size\n",
    "`TensorDict` has a batch size which is shared across all tensors. The batch size can be [], unidimensional or multidimensional according to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f64a25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our TensorDict is of size torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Our TensorDict is of size {tensordict.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4befca",
   "metadata": {},
   "source": [
    "You cannot have items that don't share the batch size inside the same TensorDict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a22ddfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caramba! We got this error: batch dimension mismatch, got self.batch_size=torch.Size([3, 4]) and tensor.shape[:self.batch_dims]=torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# we cannot add tensors that violate the batch size:\n",
    "try:\n",
    "    tensordict.update({\"c\": torch.zeros(4, 3, 1)})\n",
    "except RuntimeError as err:\n",
    "    print(f\"Caramba! We got this error: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161dce00",
   "metadata": {},
   "source": [
    "When changing the batch_size, it needs to comply with the `TensorDict` batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0665796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensordict.batch_size = [3]\n",
    "assert tensordict.batch_size == torch.Size([3])\n",
    "tensordict.batch_size = [3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "230ed6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caramba! We got this error: the tensor a has shape torch.Size([3, 4, 5]) which is incompatible with the new shape torch.Size([4, 4]).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tensordict.batch_size = [4, 4]\n",
    "except RuntimeError as err:\n",
    "    print(f\"Caramba! We got this error: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b066ad3",
   "metadata": {},
   "source": [
    "We can also fill the values of a TensorDict sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d32e73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([10, 3, 4]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "tensordict = TensorDict({}, [10])\n",
    "for i in range(10):\n",
    "    tensordict[i] = TensorDict({\"a\": torch.randn(3, 4)}, [])\n",
    "print(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674f8f3e",
   "metadata": {},
   "source": [
    "If all values are not filled, they get the default value of zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cc5077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensordict = TensorDict({}, [10])\n",
    "for i in range(2):\n",
    "    tensordict[i] = TensorDict({\"a\": torch.randn(3, 4)}, [])\n",
    "assert (tensordict[9][\"a\"] == torch.zeros((3,4))).all()\n",
    "tensordict = TensorDict({\"a\": torch.zeros(3, 4, 5), \"b\": torch.zeros(3, 4)}, batch_size=[3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ecdb9",
   "metadata": {},
   "source": [
    "#### Devices\n",
    "TensorDict can be sent to the desired devices like a pytorch tensor with `td.cuda()` or `td.to(device)` with `device`the desired device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720bf7d8",
   "metadata": {},
   "source": [
    "#### Memory sharing via physical memory usage\n",
    "When on cpu, one can use either `tensordict.memmap_()` or `tensordict.share_memory_()` to send a `tensordict` to represent it as a memory-mapped collection of tensors or put it in shared memory resp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeedaeed",
   "metadata": {},
   "source": [
    "### Tensor operations\n",
    "We can perform tensor operations among the batch dimensions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cfc1de",
   "metadata": {},
   "source": [
    "#### Cloning\n",
    "TensorDict supports cloning. Cloning returns the same TensorDict class than the original item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "072f2d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redefining a tensor in the clone does not impact the original tensordict:  tensor(False)\n"
     ]
    }
   ],
   "source": [
    "tensordict_clone = tensordict.clone()\n",
    "tensordict_clone[\"a\"] = torch.ones(*tensordict.shape, 5)\n",
    "print(\"redefining a tensor in the clone does not impact the original tensordict: \", (tensordict[\"a\"] == tensordict_clone[\"a\"]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52cef13",
   "metadata": {},
   "source": [
    "#### Slicing and indexing\n",
    "Slicing and indexing is supported along the batch dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e2bc389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([4, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([4, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([4]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e84e80a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([2, 4, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([2, 4, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([2, 4]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a32e56ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([3, 2, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([3, 2, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([3, 2]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a06026",
   "metadata": {},
   "source": [
    "#### Setting values with indexing\n",
    "We can also edit certain tensor features by deliminting certain indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6663bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtd = tensordict[:, torch.tensor([1, 3])]  #Â a SubTensorDict keeps track of the original one: it does not create a copy in memory of the original data\n",
    "tensordict.fill_(\"a\", -1)\n",
    "assert (subtd[\"a\"] == -1).all()  # the \"a\" key-value pair has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b17a8460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "         [[-1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1.]]]),\n",
       " tensor([[[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td2 = TensorDict({\"a\": torch.zeros(2, 4, 5), \"b\": torch.zeros(2, 4)}, batch_size=[2, 4])\n",
    "tensordict[:-1] = td2\n",
    "tensordict[\"a\"], tensordict[\"b\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5549b892",
   "metadata": {},
   "source": [
    "We can set values easily just by indexing the tensordict:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95cf4a0",
   "metadata": {},
   "source": [
    "#### Masking\n",
    "We mask `TensorDict` as we mask tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26d55e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([6, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([6, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([6]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.BoolTensor([[1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0]])\n",
    "tensordict[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c196db",
   "metadata": {},
   "source": [
    "#### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a0201",
   "metadata": {},
   "source": [
    "TensorDict supports stacking, stacking is done in a lazy fashion, returning a `LazyStackedTensorDict` item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec1beb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LazyStackedTensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([2, 3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([2, 3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([2, 3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "every tensordict is awesome!\n"
     ]
    }
   ],
   "source": [
    "#Stack\n",
    "clonned_tensordict = tensordict.clone()\n",
    "staked_tensordict = torch.stack([tensordict, clonned_tensordict], dim=0)\n",
    "print(staked_tensordict)\n",
    "if staked_tensordict[0] is tensordict and staked_tensordict[1] is clonned_tensordict:\n",
    "    print(\"every tensordict is awesome!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07e11fe",
   "metadata": {},
   "source": [
    "If we want to have a contiguous tensordict, we can call `.to_tensordict()` or `.contiguous()`. It is recommended to perform this operation before accessing the values of the stacked tensordict for efficiency purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38fa47d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(staked_tensordict.contiguous(), TensorDict)\n",
    "assert isinstance(staked_tensordict.to_tensordict(), TensorDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b2a33",
   "metadata": {},
   "source": [
    "#### Unbind\n",
    "TensorDict can unbind among a dim over the tensordict batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf2d1705",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tensordict = tensordict.unbind(0)\n",
    "assert type(list_tensordict) == tuple\n",
    "assert len(list_tensordict) == 3\n",
    "assert (torch.stack(list_tensordict, dim=0).contiguous() == tensordict).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f38fb01",
   "metadata": {},
   "source": [
    "#### Cat\n",
    "TensorDict supports cat to concatenate among a dim. The dim must be in the batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ecd0f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cat\n",
    "list_tensordict = tensordict.unbind(0)\n",
    "assert torch.cat(list_tensordict, dim=0).shape[0] == 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c479f4ad",
   "metadata": {},
   "source": [
    "#### View\n",
    "Support for the view operation returning a `ViewedTensorDict`. Use `to_tensordict` to comeback to retrieve TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a2f37b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(tensordict.view(-1)) == ViewedTensorDict\n",
    "assert tensordict.view(-1).shape[0] == 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a29f9",
   "metadata": {},
   "source": [
    "#### Permute\n",
    "We can permute the dims of `TensorDict`. Permute is a Lazy operation that returns PermutedTensorDict. Use `to_tensordict` to convert to `TensorDict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "020886bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(tensordict.permute(1,0)) == PermutedTensorDict\n",
    "assert tensordict.permute(1,0).batch_size == torch.Size([4, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01096d6d",
   "metadata": {},
   "source": [
    "#### Reshape\n",
    "Reshape allows reshaping the `TensorDict` batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a076a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tensordict.reshape(-1).batch_size == torch.Size([12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fbd2e0",
   "metadata": {},
   "source": [
    "#### Squeeze and Unsqueeze\n",
    "Tensordict also supports squeeze and unsqueeze. Unsqueeze is a lazy operation that returns UnsqueezedTensorDict. Use `to_tensordict` to retrieve a tensordict after unsqueeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93869ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsqueezed_tensordict = tensordict.unsqueeze(0)\n",
    "assert type(unsqueezed_tensordict) == UnsqueezedTensorDict\n",
    "assert unsqueezed_tensordict.batch_size == torch.Size([1, 3, 4])\n",
    "\n",
    "assert type(unsqueezed_tensordict.squeeze(0)) == TensorDict\n",
    "assert unsqueezed_tensordict.squeeze(0) is tensordict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

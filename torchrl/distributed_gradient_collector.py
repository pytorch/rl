# Copyright (c) Meta Platforms, Inc. and affiliates.
#
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.

r"""Distributed gradient-collector using torch.distributed backend."""


import os
import logging
import warnings
from datetime import timedelta
from torch.utils.data import IterableDataset
from typing import Callable, Dict, Iterator, List, OrderedDict, Union, Optional
from torch.optim import Optimizer, Adam


import torch
import torch.nn as nn
from torchrl._utils import VERBOSE
from tensordict import TensorDict
from tensordict.tensordict import TensorDictBase
from torchrl.data.replay_buffers import ReplayBuffer
from torchrl.collectors import MultiaSyncDataCollector
from torchrl.collectors.collectors import (
    DataCollectorBase,
    DEFAULT_EXPLORATION_TYPE,
    MultiSyncDataCollector,
    SyncDataCollector,
)
from torchrl.objectives import LossModule
from torchrl.collectors.utils import split_trajectories
from torchrl.envs import EnvBase, EnvCreator

TCP_PORT = os.environ.get("TCP_PORT", "10003")
MAX_TIME_TO_CONNECT = 1000


def _run_gradient_worker(
        loss_module: LossModule,
        verbose=True,
):
    # Alternatively we can send a create_model function and a create_loss function
    pass


class DistributedGradientCollector:
    """Distributed gradient collector with torch.distributed backend..

        This Python class serves as a solution to instantiate and coordinate multiple
    gradient workers in a distributed cluster. This class is an iterable that yields
    TensorDicts with gradients until a target number of collected frames is reached.
    """

    _VERBOSE = VERBOSE  # for debugging

    def __init__(
        self,
        params,
        *,
        backend="gloo",
        launcher="mp",  # For now, only support multiprocessing
        tcp_port=None,
    ):
        self.num_workers = 2
        rank = torch.distributed.get_rank()
        self._init_workers()

        if tcp_port is None:
            self.tcp_port = os.environ.get("TCP_PORT", TCP_PORT)
        else:
            self.tcp_port = str(tcp_port)

    def _init_workers(self):
        # Init both the local and remote workers
        IPAddr = "localhost"
        if self._VERBOSE:
            print("Server IP address:", IPAddr)
        self.IPAddr = IPAddr
        os.environ["MASTER_ADDR"] = str(self.IPAddr)
        os.environ["MASTER_PORT"] = str(self.tcp_port)

        self.jobs = []
        for i in range(self.num_workers):
            if self._VERBOSE:
                print("Submitting job")
            job = self._init_worker_dist_mp(i)
            if self._VERBOSE:
                print("job launched")
            self.jobs.append(job)
        self._init_master_dist()

    def _init_master_dist(
        self,
        world_size,
        backend,
    ):
        if self._VERBOSE:
            print(
                f"launching main node with tcp port '{self.tcp_port}' and "
                f"IP '{self.IPAddr}'. rank: 0, world_size: {world_size}, backend={backend}."
            )
        os.environ["MASTER_ADDR"] = str(self.IPAddr)
        os.environ["MASTER_PORT"] = str(self.tcp_port)

        TCP_PORT = self.tcp_port
        torch.distributed.init_process_group(
            backend,
            rank=0,
            world_size=world_size,
            timeout=timedelta(MAX_TIME_TO_CONNECT),
            init_method=f"tcp://{self.IPAddr}:{TCP_PORT}",
        )
        if self._VERBOSE:
            print("main initiated! Launching store...", end="\t")

    def _init_worker_dist_mp(self, rank):
        return None

    def _get_params_and_grads(self, model):
        # Equivalent to creating the local storage where grads will be sent
        pass

    def iterator(self):
        # If this is an iterable, then data must be generated by the workers
        yield self._iterator_dist()

    def _iterator_dist(self):
        if self._VERBOSE:
            print("iterating...")

    def compute_gradients(self, data: TensorDict):
        # Split the data, send it to the workers, receiving grads and averaging them
        pass

    def update_policy_weights_(self, worker_rank=None) -> None:
        """Updates the weights of the worker nodes.

        Args:
            worker_rank (int, optional): if provided, only this worker weights
                will be updated.
        """

    def state_dict(self) -> OrderedDict:
        raise NotImplementedError

    def load_state_dict(self, state_dict: OrderedDict) -> None:
        raise NotImplementedError

    def shutdown(self):
        if self._VERBOSE:
            print("gradient collector shut down")

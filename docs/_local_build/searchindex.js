Search.setIndex({"docnames": ["index", "reference/collectors", "reference/collectors_basics", "reference/collectors_distributed", "reference/collectors_replay", "reference/collectors_single", "reference/collectors_weightsync", "reference/config", "reference/cudnn_persistent_rnn", "reference/cudnn_rnn_determinism", "reference/data", "reference/data_datasets", "reference/data_replaybuffers", "reference/data_samplers", "reference/data_specs", "reference/data_storage", "reference/envs", "reference/envs_api", "reference/envs_libraries", "reference/envs_multiagent", "reference/envs_recorders", "reference/envs_transforms", "reference/envs_vectorized", "reference/generated/knowledge_base/DEBUGGING_RL", "reference/generated/knowledge_base/GYM", "reference/generated/knowledge_base/HABITAT", "reference/generated/knowledge_base/MUJOCO_INSTALLATION", "reference/generated/knowledge_base/PRO-TIPS", "reference/generated/knowledge_base/RESOURCES", "reference/generated/knowledge_base/VERSIONING_ISSUES", "reference/generated/knowledge_base/VIDEO_CUSTOMISATION", "reference/generated/torchrl.auto_unwrap_transformed_env", "reference/generated/torchrl.collectors.AsyncCollector", "reference/generated/torchrl.collectors.BaseCollector", "reference/generated/torchrl.collectors.Collector", "reference/generated/torchrl.collectors.MultiAsyncCollector", "reference/generated/torchrl.collectors.MultiCollector", "reference/generated/torchrl.collectors.MultiProcessedWeightUpdater", "reference/generated/torchrl.collectors.MultiSyncCollector", "reference/generated/torchrl.collectors.RayWeightUpdater", "reference/generated/torchrl.collectors.VanillaWeightUpdater", "reference/generated/torchrl.collectors.WeightUpdaterBase", "reference/generated/torchrl.collectors.distributed.DistributedCollector", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedSyncCollector", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedWeightUpdater", "reference/generated/torchrl.collectors.distributed.RPCCollector", "reference/generated/torchrl.collectors.distributed.RPCDataCollector", "reference/generated/torchrl.collectors.distributed.RPCWeightUpdater", "reference/generated/torchrl.collectors.distributed.RayCollector", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher", "reference/generated/torchrl.collectors.llm.LLMCollector", "reference/generated/torchrl.collectors.llm.RayLLMCollector", "reference/generated/torchrl.collectors.llm.vLLMUpdater", "reference/generated/torchrl.collectors.llm.vLLMUpdaterV2", "reference/generated/torchrl.collectors.utils.split_trajectories", "reference/generated/torchrl.data.Binary", "reference/generated/torchrl.data.Bounded", "reference/generated/torchrl.data.Categorical", "reference/generated/torchrl.data.Composite", "reference/generated/torchrl.data.MultiCategorical", "reference/generated/torchrl.data.MultiOneHot", "reference/generated/torchrl.data.NonTensor", "reference/generated/torchrl.data.OneHot", "reference/generated/torchrl.data.PrioritizedReplayBuffer", "reference/generated/torchrl.data.RayReplayBuffer", "reference/generated/torchrl.data.RemoteTensorDictReplayBuffer", "reference/generated/torchrl.data.ReplayBuffer", "reference/generated/torchrl.data.ReplayBufferEnsemble", "reference/generated/torchrl.data.Stacked", "reference/generated/torchrl.data.StackedComposite", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer", "reference/generated/torchrl.data.TensorDictReplayBuffer", "reference/generated/torchrl.data.TensorSpec", "reference/generated/torchrl.data.Unbounded", "reference/generated/torchrl.data.UnboundedContinuous", "reference/generated/torchrl.data.UnboundedDiscrete", "reference/generated/torchrl.data.datasets.AtariDQNExperienceReplay", "reference/generated/torchrl.data.datasets.D4RLExperienceReplay", "reference/generated/torchrl.data.datasets.GenDGRLExperienceReplay", "reference/generated/torchrl.data.datasets.MinariExperienceReplay", "reference/generated/torchrl.data.datasets.OpenMLExperienceReplay", "reference/generated/torchrl.data.datasets.OpenXExperienceReplay", "reference/generated/torchrl.data.datasets.RobosetExperienceReplay", "reference/generated/torchrl.data.datasets.VD4RLExperienceReplay", "reference/generated/torchrl.data.llm.ContentBase", "reference/generated/torchrl.data.llm.History", "reference/generated/torchrl.data.llm.TopKRewardSelector", "reference/generated/torchrl.data.llm.add_chat_template", "reference/generated/torchrl.data.replay_buffers.CompressedListStorage", "reference/generated/torchrl.data.replay_buffers.CompressedListStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.FlatStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.H5StorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.ImmutableDatasetWriter", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage", "reference/generated/torchrl.data.replay_buffers.LazyStackStorage", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage", "reference/generated/torchrl.data.replay_buffers.ListStorage", "reference/generated/torchrl.data.replay_buffers.ListStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.NestedStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler", "reference/generated/torchrl.data.replay_buffers.PrioritizedSliceSampler", "reference/generated/torchrl.data.replay_buffers.RandomSampler", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.Sampler", "reference/generated/torchrl.data.replay_buffers.SamplerEnsemble", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.SliceSampler", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.Storage", "reference/generated/torchrl.data.replay_buffers.StorageCheckpointerBase", "reference/generated/torchrl.data.replay_buffers.StorageEnsemble", "reference/generated/torchrl.data.replay_buffers.StorageEnsembleCheckpointer", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.TensorStorage", "reference/generated/torchrl.data.replay_buffers.TensorStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.Writer", "reference/generated/torchrl.data.replay_buffers.WriterEnsemble", "reference/generated/torchrl.envs.AsyncEnvPool", "reference/generated/torchrl.envs.BraxEnv", "reference/generated/torchrl.envs.BraxWrapper", "reference/generated/torchrl.envs.ChessEnv", "reference/generated/torchrl.envs.DMControlEnv", "reference/generated/torchrl.envs.DMControlWrapper", "reference/generated/torchrl.envs.EnvBase", "reference/generated/torchrl.envs.EnvCreator", "reference/generated/torchrl.envs.EnvMetaData", "reference/generated/torchrl.envs.GymEnv", "reference/generated/torchrl.envs.GymLikeEnv", "reference/generated/torchrl.envs.GymWrapper", "reference/generated/torchrl.envs.HabitatEnv", "reference/generated/torchrl.envs.IsaacGymEnv", "reference/generated/torchrl.envs.IsaacGymWrapper", "reference/generated/torchrl.envs.IsaacLabWrapper", "reference/generated/torchrl.envs.JumanjiEnv", "reference/generated/torchrl.envs.JumanjiWrapper", "reference/generated/torchrl.envs.LLMHashingEnv", "reference/generated/torchrl.envs.MOGymEnv", "reference/generated/torchrl.envs.MOGymWrapper", "reference/generated/torchrl.envs.MarlGroupMapType", "reference/generated/torchrl.envs.MeltingpotEnv", "reference/generated/torchrl.envs.MeltingpotWrapper", "reference/generated/torchrl.envs.ModelBasedEnvBase", "reference/generated/torchrl.envs.MultiThreadedEnv", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper", "reference/generated/torchrl.envs.OpenMLEnv", "reference/generated/torchrl.envs.OpenSpielEnv", "reference/generated/torchrl.envs.OpenSpielWrapper", "reference/generated/torchrl.envs.ParallelEnv", "reference/generated/torchrl.envs.PendulumEnv", "reference/generated/torchrl.envs.PettingZooEnv", "reference/generated/torchrl.envs.PettingZooWrapper", "reference/generated/torchrl.envs.ProcessorAsyncEnvPool", "reference/generated/torchrl.envs.RoboHiveEnv", "reference/generated/torchrl.envs.SMACv2Env", "reference/generated/torchrl.envs.SMACv2Wrapper", "reference/generated/torchrl.envs.SerialEnv", "reference/generated/torchrl.envs.ThreadingAsyncEnvPool", "reference/generated/torchrl.envs.TicTacToeEnv", "reference/generated/torchrl.envs.UnityMLAgentsEnv", "reference/generated/torchrl.envs.UnityMLAgentsWrapper", "reference/generated/torchrl.envs.VmasEnv", "reference/generated/torchrl.envs.VmasWrapper", "reference/generated/torchrl.envs.check_env_specs", "reference/generated/torchrl.envs.check_marl_grouping", "reference/generated/torchrl.envs.exploration_type", "reference/generated/torchrl.envs.get_available_libraries", "reference/generated/torchrl.envs.gym_backend", "reference/generated/torchrl.envs.llm.ChatEnv", "reference/generated/torchrl.envs.llm.DatasetChatEnv", "reference/generated/torchrl.envs.llm.GSM8KEnv", "reference/generated/torchrl.envs.llm.GSM8KPrepareQuestion", "reference/generated/torchrl.envs.llm.GSM8KRewardParser", "reference/generated/torchrl.envs.llm.IFEvalEnv", "reference/generated/torchrl.envs.llm.IFEvalScoreData", "reference/generated/torchrl.envs.llm.IfEvalScorer", "reference/generated/torchrl.envs.llm.LLMEnv", "reference/generated/torchrl.envs.llm.LLMHashingEnv", "reference/generated/torchrl.envs.llm.MLGymWrapper", "reference/generated/torchrl.envs.llm.make_gsm8k_env", "reference/generated/torchrl.envs.llm.make_mlgym", "reference/generated/torchrl.envs.llm.transforms.AddThinkingPrompt", "reference/generated/torchrl.envs.llm.transforms.BrowserTransform", "reference/generated/torchrl.envs.llm.transforms.DataLoadingPrimer", "reference/generated/torchrl.envs.llm.transforms.ExecuteToolsInOrder", "reference/generated/torchrl.envs.llm.transforms.JSONCallParser", "reference/generated/torchrl.envs.llm.transforms.KLComputation", "reference/generated/torchrl.envs.llm.transforms.KLRewardTransform", "reference/generated/torchrl.envs.llm.transforms.MCPToolTransform", "reference/generated/torchrl.envs.llm.transforms.PolicyVersion", "reference/generated/torchrl.envs.llm.transforms.PythonExecutorService", "reference/generated/torchrl.envs.llm.transforms.PythonInterpreter", "reference/generated/torchrl.envs.llm.transforms.RayDataLoadingPrimer", "reference/generated/torchrl.envs.llm.transforms.RetrieveKL", "reference/generated/torchrl.envs.llm.transforms.RetrieveLogProb", "reference/generated/torchrl.envs.llm.transforms.SimpleToolTransform", "reference/generated/torchrl.envs.llm.transforms.TemplateTransform", "reference/generated/torchrl.envs.llm.transforms.Tokenizer", "reference/generated/torchrl.envs.llm.transforms.ToolCall", "reference/generated/torchrl.envs.llm.transforms.ToolRegistry", "reference/generated/torchrl.envs.llm.transforms.ToolService", "reference/generated/torchrl.envs.llm.transforms.XMLBlockParser", "reference/generated/torchrl.envs.llm.transforms.as_nested_tensor", "reference/generated/torchrl.envs.llm.transforms.as_padded_tensor", "reference/generated/torchrl.envs.make_composite_from_td", "reference/generated/torchrl.envs.model_based.dreamer.DreamerDecoder", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv", "reference/generated/torchrl.envs.register_gym_spec_conversion", "reference/generated/torchrl.envs.set_exploration_type", "reference/generated/torchrl.envs.set_gym_backend", "reference/generated/torchrl.envs.step_mdp", "reference/generated/torchrl.envs.terminated_or_truncated", "reference/generated/torchrl.envs.transforms.ActionDiscretizer", "reference/generated/torchrl.envs.transforms.ActionMask", "reference/generated/torchrl.envs.transforms.AutoResetEnv", "reference/generated/torchrl.envs.transforms.AutoResetTransform", "reference/generated/torchrl.envs.transforms.BatchSizeTransform", "reference/generated/torchrl.envs.transforms.BinarizeReward", "reference/generated/torchrl.envs.transforms.BurnInTransform", "reference/generated/torchrl.envs.transforms.CatFrames", "reference/generated/torchrl.envs.transforms.CatTensors", "reference/generated/torchrl.envs.transforms.CenterCrop", "reference/generated/torchrl.envs.transforms.ClipTransform", "reference/generated/torchrl.envs.transforms.Compose", "reference/generated/torchrl.envs.transforms.ConditionalPolicySwitch", "reference/generated/torchrl.envs.transforms.ConditionalSkip", "reference/generated/torchrl.envs.transforms.Crop", "reference/generated/torchrl.envs.transforms.DTypeCastTransform", "reference/generated/torchrl.envs.transforms.DeviceCastTransform", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection", "reference/generated/torchrl.envs.transforms.DoubleToFloat", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform", "reference/generated/torchrl.envs.transforms.ExcludeTransform", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck", "reference/generated/torchrl.envs.transforms.FlattenObservation", "reference/generated/torchrl.envs.transforms.FrameSkipTransform", "reference/generated/torchrl.envs.transforms.GrayScale", "reference/generated/torchrl.envs.transforms.Hash", "reference/generated/torchrl.envs.transforms.InitTracker", "reference/generated/torchrl.envs.transforms.KLRewardTransform", "reference/generated/torchrl.envs.transforms.LineariseRewards", "reference/generated/torchrl.envs.transforms.ModuleTransform", "reference/generated/torchrl.envs.transforms.MultiAction", "reference/generated/torchrl.envs.transforms.NoopResetEnv", "reference/generated/torchrl.envs.transforms.ObservationNorm", "reference/generated/torchrl.envs.transforms.ObservationTransform", "reference/generated/torchrl.envs.transforms.PermuteTransform", "reference/generated/torchrl.envs.transforms.PinMemoryTransform", "reference/generated/torchrl.envs.transforms.R3MTransform", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict", "reference/generated/torchrl.envs.transforms.RemoveEmptySpecs", "reference/generated/torchrl.envs.transforms.RenameTransform", "reference/generated/torchrl.envs.transforms.Resize", "reference/generated/torchrl.envs.transforms.Reward2GoTransform", "reference/generated/torchrl.envs.transforms.RewardClipping", "reference/generated/torchrl.envs.transforms.RewardScaling", "reference/generated/torchrl.envs.transforms.RewardSum", "reference/generated/torchrl.envs.transforms.SelectTransform", "reference/generated/torchrl.envs.transforms.SignTransform", "reference/generated/torchrl.envs.transforms.SqueezeTransform", "reference/generated/torchrl.envs.transforms.Stack", "reference/generated/torchrl.envs.transforms.StepCounter", "reference/generated/torchrl.envs.transforms.TargetReturn", "reference/generated/torchrl.envs.transforms.TensorDictPrimer", "reference/generated/torchrl.envs.transforms.TimeMaxPool", "reference/generated/torchrl.envs.transforms.Timer", "reference/generated/torchrl.envs.transforms.ToTensorImage", "reference/generated/torchrl.envs.transforms.Tokenizer", "reference/generated/torchrl.envs.transforms.TrajCounter", "reference/generated/torchrl.envs.transforms.Transform", "reference/generated/torchrl.envs.transforms.TransformedEnv", "reference/generated/torchrl.envs.transforms.UnaryTransform", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform", "reference/generated/torchrl.envs.transforms.VC1Transform", "reference/generated/torchrl.envs.transforms.VIPRewardTransform", "reference/generated/torchrl.envs.transforms.VIPTransform", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform", "reference/generated/torchrl.envs.transforms.VecNorm", "reference/generated/torchrl.envs.transforms.VecNormV2", "reference/generated/torchrl.envs.transforms.gSDENoise", "reference/generated/torchrl.implement_for", "reference/generated/torchrl.modules.ActorCriticOperator", "reference/generated/torchrl.modules.ActorCriticWrapper", "reference/generated/torchrl.modules.ActorValueOperator", "reference/generated/torchrl.modules.AdditiveGaussianModule", "reference/generated/torchrl.modules.ConsistentDropoutModule", "reference/generated/torchrl.modules.ConvNet", "reference/generated/torchrl.modules.DTActor", "reference/generated/torchrl.modules.DdpgCnnActor", "reference/generated/torchrl.modules.DdpgCnnQNet", "reference/generated/torchrl.modules.DdpgMlpActor", "reference/generated/torchrl.modules.DdpgMlpQNet", "reference/generated/torchrl.modules.DecisionTransformer", "reference/generated/torchrl.modules.Delta", "reference/generated/torchrl.modules.DistributionalDQNnet", "reference/generated/torchrl.modules.DistributionalQValueActor", "reference/generated/torchrl.modules.DistributionalQValueModule", "reference/generated/torchrl.modules.DreamerActor", "reference/generated/torchrl.modules.DuelingCnnDQNet", "reference/generated/torchrl.modules.EGreedyModule", "reference/generated/torchrl.modules.GRUModule", "reference/generated/torchrl.modules.IndependentNormal", "reference/generated/torchrl.modules.LSTMModule", "reference/generated/torchrl.modules.MLP", "reference/generated/torchrl.modules.MaskedCategorical", "reference/generated/torchrl.modules.NormalParamExtractor", "reference/generated/torchrl.modules.ObsDecoder", "reference/generated/torchrl.modules.ObsEncoder", "reference/generated/torchrl.modules.OneHotCategorical", "reference/generated/torchrl.modules.OnlineDTActor", "reference/generated/torchrl.modules.OrnsteinUhlenbeckProcessModule", "reference/generated/torchrl.modules.QValueActor", "reference/generated/torchrl.modules.QValueModule", "reference/generated/torchrl.modules.RSSMPosterior", "reference/generated/torchrl.modules.RSSMPrior", "reference/generated/torchrl.modules.RSSMRollout", "reference/generated/torchrl.modules.ReparamGradientStrategy", "reference/generated/torchrl.modules.TanhDelta", "reference/generated/torchrl.modules.TanhNormal", "reference/generated/torchrl.modules.TruncatedNormal", "reference/generated/torchrl.modules.ValueOperator", "reference/generated/torchrl.modules.WorldModelWrapper", "reference/generated/torchrl.modules.llm.AsyncVLLM", "reference/generated/torchrl.modules.llm.ChatHistory", "reference/generated/torchrl.modules.llm.LLMWrapperBase", "reference/generated/torchrl.modules.llm.LogProbs", "reference/generated/torchrl.modules.llm.Masks", "reference/generated/torchrl.modules.llm.RemoteTransformersWrapper", "reference/generated/torchrl.modules.llm.Text", "reference/generated/torchrl.modules.llm.Tokens", "reference/generated/torchrl.modules.llm.TransformersWrapper", "reference/generated/torchrl.modules.llm.make_async_vllm_engine", "reference/generated/torchrl.modules.llm.make_vllm_worker", "reference/generated/torchrl.modules.llm.stateless_init_process_group", "reference/generated/torchrl.modules.llm.stateless_init_process_group_async", "reference/generated/torchrl.modules.llm.vLLMWrapper", "reference/generated/torchrl.modules.models.utils.SquashDims", "reference/generated/torchrl.modules.set_exploration_modules_spec_from_env", "reference/generated/torchrl.modules.tensordict_module.Actor", "reference/generated/torchrl.modules.tensordict_module.MultiStepActorWrapper", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor", "reference/generated/torchrl.modules.tensordict_module.RandomPolicy", "reference/generated/torchrl.modules.tensordict_module.SafeModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential", "reference/generated/torchrl.modules.tensordict_module.SafeSequential", "reference/generated/torchrl.modules.tensordict_module.TanhModule", "reference/generated/torchrl.objectives.A2CLoss", "reference/generated/torchrl.objectives.CQLLoss", "reference/generated/torchrl.objectives.ClipPPOLoss", "reference/generated/torchrl.objectives.CrossQLoss", "reference/generated/torchrl.objectives.DDPGLoss", "reference/generated/torchrl.objectives.DQNLoss", "reference/generated/torchrl.objectives.DTLoss", "reference/generated/torchrl.objectives.DiscreteCQLLoss", "reference/generated/torchrl.objectives.DiscreteIQLLoss", "reference/generated/torchrl.objectives.DiscreteSACLoss", "reference/generated/torchrl.objectives.DistributionalDQNLoss", "reference/generated/torchrl.objectives.DreamerActorLoss", "reference/generated/torchrl.objectives.DreamerModelLoss", "reference/generated/torchrl.objectives.DreamerValueLoss", "reference/generated/torchrl.objectives.GAILLoss", "reference/generated/torchrl.objectives.IQLLoss", "reference/generated/torchrl.objectives.KLPENPPOLoss", "reference/generated/torchrl.objectives.LossModule", "reference/generated/torchrl.objectives.OnlineDTLoss", "reference/generated/torchrl.objectives.PPOLoss", "reference/generated/torchrl.objectives.REDQLoss", "reference/generated/torchrl.objectives.ReinforceLoss", "reference/generated/torchrl.objectives.SACLoss", "reference/generated/torchrl.objectives.TD3BCLoss", "reference/generated/torchrl.objectives.TD3Loss", "reference/generated/torchrl.objectives.ValueEstimators", "reference/generated/torchrl.objectives.add_random_module", "reference/generated/torchrl.objectives.llm.CISPOLoss", "reference/generated/torchrl.objectives.llm.CISPOLossOutput", "reference/generated/torchrl.objectives.llm.DAPO", "reference/generated/torchrl.objectives.llm.DAPOLossOutput", "reference/generated/torchrl.objectives.llm.GRPOLoss", "reference/generated/torchrl.objectives.llm.GRPOLossOutput", "reference/generated/torchrl.objectives.llm.LLMLossOutput", "reference/generated/torchrl.objectives.llm.MCAdvantage", "reference/generated/torchrl.objectives.llm.SFTLoss", "reference/generated/torchrl.objectives.llm.SFTLossOutput", "reference/generated/torchrl.objectives.value.GAE", "reference/generated/torchrl.objectives.value.TD0Estimator", "reference/generated/torchrl.objectives.value.TD1Estimator", "reference/generated/torchrl.objectives.value.TDLambdaEstimator", "reference/generated/torchrl.objectives.value.ValueEstimatorBase", "reference/generated/torchrl.record.PixelRenderTransform", "reference/generated/torchrl.record.TensorDictRecorder", "reference/generated/torchrl.record.VideoRecorder", "reference/generated/torchrl.record.loggers.Logger", "reference/generated/torchrl.record.loggers.csv.CSVLogger", "reference/generated/torchrl.record.loggers.generate_exp_name", "reference/generated/torchrl.record.loggers.get_logger", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger", "reference/generated/torchrl.record.loggers.trackio.TrackioLogger", "reference/generated/torchrl.record.loggers.wandb.WandbLogger", "reference/generated/torchrl.services.RayService", "reference/generated/torchrl.services.ServiceBase", "reference/generated/torchrl.services.get_services", "reference/generated/torchrl.set_auto_unwrap_transformed_env", "reference/generated/torchrl.trainers.BatchSubSampler", "reference/generated/torchrl.trainers.ClearCudaCache", "reference/generated/torchrl.trainers.CountFramesLog", "reference/generated/torchrl.trainers.LogScalar", "reference/generated/torchrl.trainers.LogValidationReward", "reference/generated/torchrl.trainers.OptimizerHook", "reference/generated/torchrl.trainers.ReplayBufferTrainer", "reference/generated/torchrl.trainers.RewardNormalizer", "reference/generated/torchrl.trainers.SelectKeys", "reference/generated/torchrl.trainers.TargetNetUpdaterHook", "reference/generated/torchrl.trainers.Trainer", "reference/generated/torchrl.trainers.TrainerHookBase", "reference/generated/torchrl.trainers.UTDRHook", "reference/generated/torchrl.trainers.UpdateWeights", "reference/generated/torchrl.trainers.algorithms.PPOTrainer", "reference/generated/torchrl.trainers.algorithms.SACTrainer", "reference/generated/torchrl.trainers.algorithms.configs.collectors.AsyncCollectorConfig", "reference/generated/torchrl.trainers.algorithms.configs.collectors.CollectorConfig", "reference/generated/torchrl.trainers.algorithms.configs.collectors.MultiAsyncCollectorConfig", "reference/generated/torchrl.trainers.algorithms.configs.collectors.MultiSyncCollectorConfig", "reference/generated/torchrl.trainers.algorithms.configs.common.ConfigBase", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyMemmapStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyStackStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyTensorStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.ListStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.PrioritizedSamplerConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.RandomSamplerConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.ReplayBufferConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.RoundRobinWriterConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.SamplerWithoutReplacementConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerWithoutReplacementConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleWriterConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorDictReplayBufferConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs.BatchedEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs.EnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs.TransformedEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.BraxEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.DMControlEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.EnvLibsConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.GymEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.HabitatEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.IsaacGymEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.JumanjiEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MOGymEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MeltingpotEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MultiThreadedEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenMLEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenSpielEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.PettingZooEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.RoboHiveEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.SMACv2EnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.UnityMLAgentsEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.VmasEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.CSVLoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.LoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.TensorboardLoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.WandbLoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.ConvNetConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.MLPConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.ModelConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.NetworkConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.TanhNormalModelConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.TensorDictModuleConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.ValueModelConfig", "reference/generated/torchrl.trainers.algorithms.configs.objectives.LossConfig", "reference/generated/torchrl.trainers.algorithms.configs.objectives.PPOLossConfig", "reference/generated/torchrl.trainers.algorithms.configs.trainers.PPOTrainerConfig", "reference/generated/torchrl.trainers.algorithms.configs.trainers.TrainerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionDiscretizerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionMaskConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.AutoResetTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BatchSizeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BinarizeRewardConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BurnInTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatFramesConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatTensorsConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CenterCropConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ClipTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ComposeConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalPolicySwitchConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalSkipConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CropConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DTypeCastTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DeviceCastTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DiscreteActionProjectionConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DoubleToFloatConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.EndOfLifeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ExcludeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FiniteTensorDictCheckConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FlattenObservationConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FrameSkipTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.GrayScaleConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.HashConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.InitTrackerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.KLRewardTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.LineariseRewardsConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiActionConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiStepTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.NoopResetEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ObservationNormConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PermuteTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PinMemoryTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.R3MTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RandomCropTensorDictConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RemoveEmptySpecsConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RenameTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ResizeConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.Reward2GoTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardClippingConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardScalingConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardSumConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SelectTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SignTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SqueezeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StackConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StepCounterConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TargetReturnConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TensorDictPrimerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimeMaxPoolConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ToTensorImageConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TokenizerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TrajCounterConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnaryTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnsqueezeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VC1TransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPRewardTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecGymEnvTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormV2Config", "reference/generated/torchrl.trainers.algorithms.configs.utils.ASGDConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdadeltaConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdagradConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamWConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamaxConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.LBFGSConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.LionConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.NAdamConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.RAdamConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.RMSpropConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.RpropConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.SGDConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.SparseAdamConfig", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy", "reference/generated/torchrl.trainers.helpers.make_dqn_loss", "reference/generated/torchrl.trainers.helpers.make_replay_buffer", "reference/generated/torchrl.trainers.helpers.make_target_updater", "reference/generated/torchrl.trainers.helpers.make_trainer", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor", "reference/generated/torchrl.trainers.helpers.sync_async_collector", "reference/generated/torchrl.trainers.helpers.sync_sync_collector", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor", "reference/generated/torchrl.weight_update.DistributedTransport", "reference/generated/torchrl.weight_update.DistributedWeightSyncScheme", "reference/generated/torchrl.weight_update.MPTransport", "reference/generated/torchrl.weight_update.MultiProcessWeightSyncScheme", "reference/generated/torchrl.weight_update.NoWeightSyncScheme", "reference/generated/torchrl.weight_update.RPCTransport", "reference/generated/torchrl.weight_update.RPCWeightSyncScheme", "reference/generated/torchrl.weight_update.RayModuleTransformScheme", "reference/generated/torchrl.weight_update.RayTransport", "reference/generated/torchrl.weight_update.RayWeightSyncScheme", "reference/generated/torchrl.weight_update.SharedMemTransport", "reference/generated/torchrl.weight_update.SharedMemWeightSyncScheme", "reference/generated/torchrl.weight_update.TransportBackend", "reference/generated/torchrl.weight_update.WeightStrategy", "reference/generated/torchrl.weight_update.WeightSyncScheme", "reference/generated/torchrl.weight_update.llm.VLLMCollectiveTransport", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferTransport", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightSender", "reference/generated/torchrl.weight_update.llm.VLLMWeightReceiver", "reference/generated/torchrl.weight_update.llm.VLLMWeightSender", "reference/generated/torchrl.weight_update.llm.VLLMWeightSyncScheme", "reference/generated/torchrl.weight_update.llm.get_model_metadata", "reference/generated/tutorials/README", "reference/index", "reference/knowledge_base", "reference/llms", "reference/llms_collectors", "reference/llms_data", "reference/llms_envs", "reference/llms_modules", "reference/llms_objectives", "reference/llms_transforms", "reference/modules", "reference/modules_actors", "reference/modules_critics", "reference/modules_distributions", "reference/modules_exploration", "reference/modules_models", "reference/modules_utils", "reference/objectives", "reference/objectives_actorcritic", "reference/objectives_common", "reference/objectives_offline", "reference/objectives_other", "reference/objectives_policy", "reference/objectives_value", "reference/services", "reference/trainers", "reference/trainers_basics", "reference/trainers_hooks", "reference/trainers_loggers", "reference/utils", "sg_execution_times", "tutorials/coding_ddpg", "tutorials/coding_dqn", "tutorials/coding_ppo", "tutorials/dqn_with_rnn", "tutorials/export", "tutorials/getting-started-0", "tutorials/getting-started-1", "tutorials/getting-started-2", "tutorials/getting-started-3", "tutorials/getting-started-4", "tutorials/getting-started-5", "tutorials/index", "tutorials/llm_browser", "tutorials/llm_wrappers", "tutorials/multi_task", "tutorials/multiagent_competitive_ddpg", "tutorials/multiagent_ppo", "tutorials/pendulum", "tutorials/pretrained_models", "tutorials/rb_tutorial", "tutorials/sg_execution_times", "tutorials/torchrl_demo", "tutorials/torchrl_envs"], "filenames": ["index.rst", "reference/collectors.rst", "reference/collectors_basics.rst", "reference/collectors_distributed.rst", "reference/collectors_replay.rst", "reference/collectors_single.rst", "reference/collectors_weightsync.rst", "reference/config.rst", "reference/cudnn_persistent_rnn.rst", "reference/cudnn_rnn_determinism.rst", "reference/data.rst", "reference/data_datasets.rst", "reference/data_replaybuffers.rst", "reference/data_samplers.rst", "reference/data_specs.rst", "reference/data_storage.rst", "reference/envs.rst", "reference/envs_api.rst", "reference/envs_libraries.rst", "reference/envs_multiagent.rst", "reference/envs_recorders.rst", "reference/envs_transforms.rst", "reference/envs_vectorized.rst", "reference/generated/knowledge_base/DEBUGGING_RL.rst", "reference/generated/knowledge_base/GYM.rst", "reference/generated/knowledge_base/HABITAT.rst", "reference/generated/knowledge_base/MUJOCO_INSTALLATION.rst", "reference/generated/knowledge_base/PRO-TIPS.rst", "reference/generated/knowledge_base/RESOURCES.rst", "reference/generated/knowledge_base/VERSIONING_ISSUES.rst", "reference/generated/knowledge_base/VIDEO_CUSTOMISATION.rst", "reference/generated/torchrl.auto_unwrap_transformed_env.rst", "reference/generated/torchrl.collectors.AsyncCollector.rst", "reference/generated/torchrl.collectors.BaseCollector.rst", "reference/generated/torchrl.collectors.Collector.rst", "reference/generated/torchrl.collectors.MultiAsyncCollector.rst", "reference/generated/torchrl.collectors.MultiCollector.rst", "reference/generated/torchrl.collectors.MultiProcessedWeightUpdater.rst", "reference/generated/torchrl.collectors.MultiSyncCollector.rst", "reference/generated/torchrl.collectors.RayWeightUpdater.rst", "reference/generated/torchrl.collectors.VanillaWeightUpdater.rst", "reference/generated/torchrl.collectors.WeightUpdaterBase.rst", "reference/generated/torchrl.collectors.distributed.DistributedCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedSyncCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedWeightUpdater.rst", "reference/generated/torchrl.collectors.distributed.RPCCollector.rst", "reference/generated/torchrl.collectors.distributed.RPCDataCollector.rst", "reference/generated/torchrl.collectors.distributed.RPCWeightUpdater.rst", "reference/generated/torchrl.collectors.distributed.RayCollector.rst", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher.rst", "reference/generated/torchrl.collectors.llm.LLMCollector.rst", "reference/generated/torchrl.collectors.llm.RayLLMCollector.rst", "reference/generated/torchrl.collectors.llm.vLLMUpdater.rst", "reference/generated/torchrl.collectors.llm.vLLMUpdaterV2.rst", "reference/generated/torchrl.collectors.utils.split_trajectories.rst", "reference/generated/torchrl.data.Binary.rst", "reference/generated/torchrl.data.Bounded.rst", "reference/generated/torchrl.data.Categorical.rst", "reference/generated/torchrl.data.Composite.rst", "reference/generated/torchrl.data.MultiCategorical.rst", "reference/generated/torchrl.data.MultiOneHot.rst", "reference/generated/torchrl.data.NonTensor.rst", "reference/generated/torchrl.data.OneHot.rst", "reference/generated/torchrl.data.PrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.RayReplayBuffer.rst", "reference/generated/torchrl.data.RemoteTensorDictReplayBuffer.rst", "reference/generated/torchrl.data.ReplayBuffer.rst", "reference/generated/torchrl.data.ReplayBufferEnsemble.rst", "reference/generated/torchrl.data.Stacked.rst", "reference/generated/torchrl.data.StackedComposite.rst", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.TensorDictReplayBuffer.rst", "reference/generated/torchrl.data.TensorSpec.rst", "reference/generated/torchrl.data.Unbounded.rst", "reference/generated/torchrl.data.UnboundedContinuous.rst", "reference/generated/torchrl.data.UnboundedDiscrete.rst", "reference/generated/torchrl.data.datasets.AtariDQNExperienceReplay.rst", "reference/generated/torchrl.data.datasets.D4RLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.GenDGRLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.MinariExperienceReplay.rst", "reference/generated/torchrl.data.datasets.OpenMLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.OpenXExperienceReplay.rst", "reference/generated/torchrl.data.datasets.RobosetExperienceReplay.rst", "reference/generated/torchrl.data.datasets.VD4RLExperienceReplay.rst", "reference/generated/torchrl.data.llm.ContentBase.rst", "reference/generated/torchrl.data.llm.History.rst", "reference/generated/torchrl.data.llm.TopKRewardSelector.rst", "reference/generated/torchrl.data.llm.add_chat_template.rst", "reference/generated/torchrl.data.replay_buffers.CompressedListStorage.rst", "reference/generated/torchrl.data.replay_buffers.CompressedListStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.FlatStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.H5StorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.ImmutableDatasetWriter.rst", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage.rst", "reference/generated/torchrl.data.replay_buffers.LazyStackStorage.rst", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.ListStorage.rst", "reference/generated/torchrl.data.replay_buffers.ListStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.NestedStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler.rst", "reference/generated/torchrl.data.replay_buffers.PrioritizedSliceSampler.rst", "reference/generated/torchrl.data.replay_buffers.RandomSampler.rst", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.Sampler.rst", "reference/generated/torchrl.data.replay_buffers.SamplerEnsemble.rst", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.SliceSampler.rst", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.Storage.rst", "reference/generated/torchrl.data.replay_buffers.StorageCheckpointerBase.rst", "reference/generated/torchrl.data.replay_buffers.StorageEnsemble.rst", "reference/generated/torchrl.data.replay_buffers.StorageEnsembleCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.TensorStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.Writer.rst", "reference/generated/torchrl.data.replay_buffers.WriterEnsemble.rst", "reference/generated/torchrl.envs.AsyncEnvPool.rst", "reference/generated/torchrl.envs.BraxEnv.rst", "reference/generated/torchrl.envs.BraxWrapper.rst", "reference/generated/torchrl.envs.ChessEnv.rst", "reference/generated/torchrl.envs.DMControlEnv.rst", "reference/generated/torchrl.envs.DMControlWrapper.rst", "reference/generated/torchrl.envs.EnvBase.rst", "reference/generated/torchrl.envs.EnvCreator.rst", "reference/generated/torchrl.envs.EnvMetaData.rst", "reference/generated/torchrl.envs.GymEnv.rst", "reference/generated/torchrl.envs.GymLikeEnv.rst", "reference/generated/torchrl.envs.GymWrapper.rst", "reference/generated/torchrl.envs.HabitatEnv.rst", "reference/generated/torchrl.envs.IsaacGymEnv.rst", "reference/generated/torchrl.envs.IsaacGymWrapper.rst", "reference/generated/torchrl.envs.IsaacLabWrapper.rst", "reference/generated/torchrl.envs.JumanjiEnv.rst", "reference/generated/torchrl.envs.JumanjiWrapper.rst", "reference/generated/torchrl.envs.LLMHashingEnv.rst", "reference/generated/torchrl.envs.MOGymEnv.rst", "reference/generated/torchrl.envs.MOGymWrapper.rst", "reference/generated/torchrl.envs.MarlGroupMapType.rst", "reference/generated/torchrl.envs.MeltingpotEnv.rst", "reference/generated/torchrl.envs.MeltingpotWrapper.rst", "reference/generated/torchrl.envs.ModelBasedEnvBase.rst", "reference/generated/torchrl.envs.MultiThreadedEnv.rst", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper.rst", "reference/generated/torchrl.envs.OpenMLEnv.rst", "reference/generated/torchrl.envs.OpenSpielEnv.rst", "reference/generated/torchrl.envs.OpenSpielWrapper.rst", "reference/generated/torchrl.envs.ParallelEnv.rst", "reference/generated/torchrl.envs.PendulumEnv.rst", "reference/generated/torchrl.envs.PettingZooEnv.rst", "reference/generated/torchrl.envs.PettingZooWrapper.rst", "reference/generated/torchrl.envs.ProcessorAsyncEnvPool.rst", "reference/generated/torchrl.envs.RoboHiveEnv.rst", "reference/generated/torchrl.envs.SMACv2Env.rst", "reference/generated/torchrl.envs.SMACv2Wrapper.rst", "reference/generated/torchrl.envs.SerialEnv.rst", "reference/generated/torchrl.envs.ThreadingAsyncEnvPool.rst", "reference/generated/torchrl.envs.TicTacToeEnv.rst", "reference/generated/torchrl.envs.UnityMLAgentsEnv.rst", "reference/generated/torchrl.envs.UnityMLAgentsWrapper.rst", "reference/generated/torchrl.envs.VmasEnv.rst", "reference/generated/torchrl.envs.VmasWrapper.rst", "reference/generated/torchrl.envs.check_env_specs.rst", "reference/generated/torchrl.envs.check_marl_grouping.rst", "reference/generated/torchrl.envs.exploration_type.rst", "reference/generated/torchrl.envs.get_available_libraries.rst", "reference/generated/torchrl.envs.gym_backend.rst", "reference/generated/torchrl.envs.llm.ChatEnv.rst", "reference/generated/torchrl.envs.llm.DatasetChatEnv.rst", "reference/generated/torchrl.envs.llm.GSM8KEnv.rst", "reference/generated/torchrl.envs.llm.GSM8KPrepareQuestion.rst", "reference/generated/torchrl.envs.llm.GSM8KRewardParser.rst", "reference/generated/torchrl.envs.llm.IFEvalEnv.rst", "reference/generated/torchrl.envs.llm.IFEvalScoreData.rst", "reference/generated/torchrl.envs.llm.IfEvalScorer.rst", "reference/generated/torchrl.envs.llm.LLMEnv.rst", "reference/generated/torchrl.envs.llm.LLMHashingEnv.rst", "reference/generated/torchrl.envs.llm.MLGymWrapper.rst", "reference/generated/torchrl.envs.llm.make_gsm8k_env.rst", "reference/generated/torchrl.envs.llm.make_mlgym.rst", "reference/generated/torchrl.envs.llm.transforms.AddThinkingPrompt.rst", "reference/generated/torchrl.envs.llm.transforms.BrowserTransform.rst", "reference/generated/torchrl.envs.llm.transforms.DataLoadingPrimer.rst", "reference/generated/torchrl.envs.llm.transforms.ExecuteToolsInOrder.rst", "reference/generated/torchrl.envs.llm.transforms.JSONCallParser.rst", "reference/generated/torchrl.envs.llm.transforms.KLComputation.rst", "reference/generated/torchrl.envs.llm.transforms.KLRewardTransform.rst", "reference/generated/torchrl.envs.llm.transforms.MCPToolTransform.rst", "reference/generated/torchrl.envs.llm.transforms.PolicyVersion.rst", "reference/generated/torchrl.envs.llm.transforms.PythonExecutorService.rst", "reference/generated/torchrl.envs.llm.transforms.PythonInterpreter.rst", "reference/generated/torchrl.envs.llm.transforms.RayDataLoadingPrimer.rst", "reference/generated/torchrl.envs.llm.transforms.RetrieveKL.rst", "reference/generated/torchrl.envs.llm.transforms.RetrieveLogProb.rst", "reference/generated/torchrl.envs.llm.transforms.SimpleToolTransform.rst", "reference/generated/torchrl.envs.llm.transforms.TemplateTransform.rst", "reference/generated/torchrl.envs.llm.transforms.Tokenizer.rst", "reference/generated/torchrl.envs.llm.transforms.ToolCall.rst", "reference/generated/torchrl.envs.llm.transforms.ToolRegistry.rst", "reference/generated/torchrl.envs.llm.transforms.ToolService.rst", "reference/generated/torchrl.envs.llm.transforms.XMLBlockParser.rst", "reference/generated/torchrl.envs.llm.transforms.as_nested_tensor.rst", "reference/generated/torchrl.envs.llm.transforms.as_padded_tensor.rst", "reference/generated/torchrl.envs.make_composite_from_td.rst", "reference/generated/torchrl.envs.model_based.dreamer.DreamerDecoder.rst", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv.rst", "reference/generated/torchrl.envs.register_gym_spec_conversion.rst", "reference/generated/torchrl.envs.set_exploration_type.rst", "reference/generated/torchrl.envs.set_gym_backend.rst", "reference/generated/torchrl.envs.step_mdp.rst", "reference/generated/torchrl.envs.terminated_or_truncated.rst", "reference/generated/torchrl.envs.transforms.ActionDiscretizer.rst", "reference/generated/torchrl.envs.transforms.ActionMask.rst", "reference/generated/torchrl.envs.transforms.AutoResetEnv.rst", "reference/generated/torchrl.envs.transforms.AutoResetTransform.rst", "reference/generated/torchrl.envs.transforms.BatchSizeTransform.rst", "reference/generated/torchrl.envs.transforms.BinarizeReward.rst", "reference/generated/torchrl.envs.transforms.BurnInTransform.rst", "reference/generated/torchrl.envs.transforms.CatFrames.rst", "reference/generated/torchrl.envs.transforms.CatTensors.rst", "reference/generated/torchrl.envs.transforms.CenterCrop.rst", "reference/generated/torchrl.envs.transforms.ClipTransform.rst", "reference/generated/torchrl.envs.transforms.Compose.rst", "reference/generated/torchrl.envs.transforms.ConditionalPolicySwitch.rst", "reference/generated/torchrl.envs.transforms.ConditionalSkip.rst", "reference/generated/torchrl.envs.transforms.Crop.rst", "reference/generated/torchrl.envs.transforms.DTypeCastTransform.rst", "reference/generated/torchrl.envs.transforms.DeviceCastTransform.rst", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection.rst", "reference/generated/torchrl.envs.transforms.DoubleToFloat.rst", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform.rst", "reference/generated/torchrl.envs.transforms.ExcludeTransform.rst", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck.rst", "reference/generated/torchrl.envs.transforms.FlattenObservation.rst", "reference/generated/torchrl.envs.transforms.FrameSkipTransform.rst", "reference/generated/torchrl.envs.transforms.GrayScale.rst", "reference/generated/torchrl.envs.transforms.Hash.rst", "reference/generated/torchrl.envs.transforms.InitTracker.rst", "reference/generated/torchrl.envs.transforms.KLRewardTransform.rst", "reference/generated/torchrl.envs.transforms.LineariseRewards.rst", "reference/generated/torchrl.envs.transforms.ModuleTransform.rst", "reference/generated/torchrl.envs.transforms.MultiAction.rst", "reference/generated/torchrl.envs.transforms.NoopResetEnv.rst", "reference/generated/torchrl.envs.transforms.ObservationNorm.rst", "reference/generated/torchrl.envs.transforms.ObservationTransform.rst", "reference/generated/torchrl.envs.transforms.PermuteTransform.rst", "reference/generated/torchrl.envs.transforms.PinMemoryTransform.rst", "reference/generated/torchrl.envs.transforms.R3MTransform.rst", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict.rst", "reference/generated/torchrl.envs.transforms.RemoveEmptySpecs.rst", "reference/generated/torchrl.envs.transforms.RenameTransform.rst", "reference/generated/torchrl.envs.transforms.Resize.rst", "reference/generated/torchrl.envs.transforms.Reward2GoTransform.rst", "reference/generated/torchrl.envs.transforms.RewardClipping.rst", "reference/generated/torchrl.envs.transforms.RewardScaling.rst", "reference/generated/torchrl.envs.transforms.RewardSum.rst", "reference/generated/torchrl.envs.transforms.SelectTransform.rst", "reference/generated/torchrl.envs.transforms.SignTransform.rst", "reference/generated/torchrl.envs.transforms.SqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.Stack.rst", "reference/generated/torchrl.envs.transforms.StepCounter.rst", "reference/generated/torchrl.envs.transforms.TargetReturn.rst", "reference/generated/torchrl.envs.transforms.TensorDictPrimer.rst", "reference/generated/torchrl.envs.transforms.TimeMaxPool.rst", "reference/generated/torchrl.envs.transforms.Timer.rst", "reference/generated/torchrl.envs.transforms.ToTensorImage.rst", "reference/generated/torchrl.envs.transforms.Tokenizer.rst", "reference/generated/torchrl.envs.transforms.TrajCounter.rst", "reference/generated/torchrl.envs.transforms.Transform.rst", "reference/generated/torchrl.envs.transforms.TransformedEnv.rst", "reference/generated/torchrl.envs.transforms.UnaryTransform.rst", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.VC1Transform.rst", "reference/generated/torchrl.envs.transforms.VIPRewardTransform.rst", "reference/generated/torchrl.envs.transforms.VIPTransform.rst", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform.rst", "reference/generated/torchrl.envs.transforms.VecNorm.rst", "reference/generated/torchrl.envs.transforms.VecNormV2.rst", "reference/generated/torchrl.envs.transforms.gSDENoise.rst", "reference/generated/torchrl.implement_for.rst", "reference/generated/torchrl.modules.ActorCriticOperator.rst", "reference/generated/torchrl.modules.ActorCriticWrapper.rst", "reference/generated/torchrl.modules.ActorValueOperator.rst", "reference/generated/torchrl.modules.AdditiveGaussianModule.rst", "reference/generated/torchrl.modules.ConsistentDropoutModule.rst", "reference/generated/torchrl.modules.ConvNet.rst", "reference/generated/torchrl.modules.DTActor.rst", "reference/generated/torchrl.modules.DdpgCnnActor.rst", "reference/generated/torchrl.modules.DdpgCnnQNet.rst", "reference/generated/torchrl.modules.DdpgMlpActor.rst", "reference/generated/torchrl.modules.DdpgMlpQNet.rst", "reference/generated/torchrl.modules.DecisionTransformer.rst", "reference/generated/torchrl.modules.Delta.rst", "reference/generated/torchrl.modules.DistributionalDQNnet.rst", "reference/generated/torchrl.modules.DistributionalQValueActor.rst", "reference/generated/torchrl.modules.DistributionalQValueModule.rst", "reference/generated/torchrl.modules.DreamerActor.rst", "reference/generated/torchrl.modules.DuelingCnnDQNet.rst", "reference/generated/torchrl.modules.EGreedyModule.rst", "reference/generated/torchrl.modules.GRUModule.rst", "reference/generated/torchrl.modules.IndependentNormal.rst", "reference/generated/torchrl.modules.LSTMModule.rst", "reference/generated/torchrl.modules.MLP.rst", "reference/generated/torchrl.modules.MaskedCategorical.rst", "reference/generated/torchrl.modules.NormalParamExtractor.rst", "reference/generated/torchrl.modules.ObsDecoder.rst", "reference/generated/torchrl.modules.ObsEncoder.rst", "reference/generated/torchrl.modules.OneHotCategorical.rst", "reference/generated/torchrl.modules.OnlineDTActor.rst", "reference/generated/torchrl.modules.OrnsteinUhlenbeckProcessModule.rst", "reference/generated/torchrl.modules.QValueActor.rst", "reference/generated/torchrl.modules.QValueModule.rst", "reference/generated/torchrl.modules.RSSMPosterior.rst", "reference/generated/torchrl.modules.RSSMPrior.rst", "reference/generated/torchrl.modules.RSSMRollout.rst", "reference/generated/torchrl.modules.ReparamGradientStrategy.rst", "reference/generated/torchrl.modules.TanhDelta.rst", "reference/generated/torchrl.modules.TanhNormal.rst", "reference/generated/torchrl.modules.TruncatedNormal.rst", "reference/generated/torchrl.modules.ValueOperator.rst", "reference/generated/torchrl.modules.WorldModelWrapper.rst", "reference/generated/torchrl.modules.llm.AsyncVLLM.rst", "reference/generated/torchrl.modules.llm.ChatHistory.rst", "reference/generated/torchrl.modules.llm.LLMWrapperBase.rst", "reference/generated/torchrl.modules.llm.LogProbs.rst", "reference/generated/torchrl.modules.llm.Masks.rst", "reference/generated/torchrl.modules.llm.RemoteTransformersWrapper.rst", "reference/generated/torchrl.modules.llm.Text.rst", "reference/generated/torchrl.modules.llm.Tokens.rst", "reference/generated/torchrl.modules.llm.TransformersWrapper.rst", "reference/generated/torchrl.modules.llm.make_async_vllm_engine.rst", "reference/generated/torchrl.modules.llm.make_vllm_worker.rst", "reference/generated/torchrl.modules.llm.stateless_init_process_group.rst", "reference/generated/torchrl.modules.llm.stateless_init_process_group_async.rst", "reference/generated/torchrl.modules.llm.vLLMWrapper.rst", "reference/generated/torchrl.modules.models.utils.SquashDims.rst", "reference/generated/torchrl.modules.set_exploration_modules_spec_from_env.rst", "reference/generated/torchrl.modules.tensordict_module.Actor.rst", "reference/generated/torchrl.modules.tensordict_module.MultiStepActorWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor.rst", "reference/generated/torchrl.modules.tensordict_module.RandomPolicy.rst", "reference/generated/torchrl.modules.tensordict_module.SafeModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential.rst", "reference/generated/torchrl.modules.tensordict_module.SafeSequential.rst", "reference/generated/torchrl.modules.tensordict_module.TanhModule.rst", "reference/generated/torchrl.objectives.A2CLoss.rst", "reference/generated/torchrl.objectives.CQLLoss.rst", "reference/generated/torchrl.objectives.ClipPPOLoss.rst", "reference/generated/torchrl.objectives.CrossQLoss.rst", "reference/generated/torchrl.objectives.DDPGLoss.rst", "reference/generated/torchrl.objectives.DQNLoss.rst", "reference/generated/torchrl.objectives.DTLoss.rst", "reference/generated/torchrl.objectives.DiscreteCQLLoss.rst", "reference/generated/torchrl.objectives.DiscreteIQLLoss.rst", "reference/generated/torchrl.objectives.DiscreteSACLoss.rst", "reference/generated/torchrl.objectives.DistributionalDQNLoss.rst", "reference/generated/torchrl.objectives.DreamerActorLoss.rst", "reference/generated/torchrl.objectives.DreamerModelLoss.rst", "reference/generated/torchrl.objectives.DreamerValueLoss.rst", "reference/generated/torchrl.objectives.GAILLoss.rst", "reference/generated/torchrl.objectives.IQLLoss.rst", "reference/generated/torchrl.objectives.KLPENPPOLoss.rst", "reference/generated/torchrl.objectives.LossModule.rst", "reference/generated/torchrl.objectives.OnlineDTLoss.rst", "reference/generated/torchrl.objectives.PPOLoss.rst", "reference/generated/torchrl.objectives.REDQLoss.rst", "reference/generated/torchrl.objectives.ReinforceLoss.rst", "reference/generated/torchrl.objectives.SACLoss.rst", "reference/generated/torchrl.objectives.TD3BCLoss.rst", "reference/generated/torchrl.objectives.TD3Loss.rst", "reference/generated/torchrl.objectives.ValueEstimators.rst", "reference/generated/torchrl.objectives.add_random_module.rst", "reference/generated/torchrl.objectives.llm.CISPOLoss.rst", "reference/generated/torchrl.objectives.llm.CISPOLossOutput.rst", "reference/generated/torchrl.objectives.llm.DAPO.rst", "reference/generated/torchrl.objectives.llm.DAPOLossOutput.rst", "reference/generated/torchrl.objectives.llm.GRPOLoss.rst", "reference/generated/torchrl.objectives.llm.GRPOLossOutput.rst", "reference/generated/torchrl.objectives.llm.LLMLossOutput.rst", "reference/generated/torchrl.objectives.llm.MCAdvantage.rst", "reference/generated/torchrl.objectives.llm.SFTLoss.rst", "reference/generated/torchrl.objectives.llm.SFTLossOutput.rst", "reference/generated/torchrl.objectives.value.GAE.rst", "reference/generated/torchrl.objectives.value.TD0Estimator.rst", "reference/generated/torchrl.objectives.value.TD1Estimator.rst", "reference/generated/torchrl.objectives.value.TDLambdaEstimator.rst", "reference/generated/torchrl.objectives.value.ValueEstimatorBase.rst", "reference/generated/torchrl.record.PixelRenderTransform.rst", "reference/generated/torchrl.record.TensorDictRecorder.rst", "reference/generated/torchrl.record.VideoRecorder.rst", "reference/generated/torchrl.record.loggers.Logger.rst", "reference/generated/torchrl.record.loggers.csv.CSVLogger.rst", "reference/generated/torchrl.record.loggers.generate_exp_name.rst", "reference/generated/torchrl.record.loggers.get_logger.rst", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger.rst", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger.rst", "reference/generated/torchrl.record.loggers.trackio.TrackioLogger.rst", "reference/generated/torchrl.record.loggers.wandb.WandbLogger.rst", "reference/generated/torchrl.services.RayService.rst", "reference/generated/torchrl.services.ServiceBase.rst", "reference/generated/torchrl.services.get_services.rst", "reference/generated/torchrl.set_auto_unwrap_transformed_env.rst", "reference/generated/torchrl.trainers.BatchSubSampler.rst", "reference/generated/torchrl.trainers.ClearCudaCache.rst", "reference/generated/torchrl.trainers.CountFramesLog.rst", "reference/generated/torchrl.trainers.LogScalar.rst", "reference/generated/torchrl.trainers.LogValidationReward.rst", "reference/generated/torchrl.trainers.OptimizerHook.rst", "reference/generated/torchrl.trainers.ReplayBufferTrainer.rst", "reference/generated/torchrl.trainers.RewardNormalizer.rst", "reference/generated/torchrl.trainers.SelectKeys.rst", "reference/generated/torchrl.trainers.TargetNetUpdaterHook.rst", "reference/generated/torchrl.trainers.Trainer.rst", "reference/generated/torchrl.trainers.TrainerHookBase.rst", "reference/generated/torchrl.trainers.UTDRHook.rst", "reference/generated/torchrl.trainers.UpdateWeights.rst", "reference/generated/torchrl.trainers.algorithms.PPOTrainer.rst", "reference/generated/torchrl.trainers.algorithms.SACTrainer.rst", "reference/generated/torchrl.trainers.algorithms.configs.collectors.AsyncCollectorConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.collectors.CollectorConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.collectors.MultiAsyncCollectorConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.collectors.MultiSyncCollectorConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.common.ConfigBase.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyMemmapStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyStackStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyTensorStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.ListStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.PrioritizedSamplerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.RandomSamplerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.ReplayBufferConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.RoundRobinWriterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.SamplerWithoutReplacementConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerWithoutReplacementConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleWriterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorDictReplayBufferConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs.BatchedEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs.EnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs.TransformedEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.BraxEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.DMControlEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.EnvLibsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.GymEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.HabitatEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.IsaacGymEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.JumanjiEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MOGymEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MeltingpotEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MultiThreadedEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenMLEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenSpielEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.PettingZooEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.RoboHiveEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.SMACv2EnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.UnityMLAgentsEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.VmasEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.CSVLoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.LoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.TensorboardLoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.WandbLoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.ConvNetConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.MLPConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.ModelConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.NetworkConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.TanhNormalModelConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.TensorDictModuleConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.ValueModelConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.objectives.LossConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.objectives.PPOLossConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.trainers.PPOTrainerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.trainers.TrainerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionDiscretizerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionMaskConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.AutoResetTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BatchSizeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BinarizeRewardConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BurnInTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatFramesConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatTensorsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CenterCropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ClipTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ComposeConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalPolicySwitchConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalSkipConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DTypeCastTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DeviceCastTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DiscreteActionProjectionConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DoubleToFloatConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.EndOfLifeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ExcludeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FiniteTensorDictCheckConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FlattenObservationConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FrameSkipTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.GrayScaleConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.HashConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.InitTrackerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.KLRewardTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.LineariseRewardsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiActionConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiStepTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.NoopResetEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ObservationNormConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PermuteTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PinMemoryTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.R3MTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RandomCropTensorDictConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RemoveEmptySpecsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RenameTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ResizeConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.Reward2GoTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardClippingConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardScalingConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardSumConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SelectTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SignTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SqueezeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StackConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StepCounterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TargetReturnConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TensorDictPrimerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimeMaxPoolConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ToTensorImageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TokenizerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TrajCounterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnaryTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnsqueezeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VC1TransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPRewardTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecGymEnvTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormV2Config.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.ASGDConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdadeltaConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdagradConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamWConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamaxConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.LBFGSConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.LionConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.NAdamConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.RAdamConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.RMSpropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.RpropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.SGDConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.SparseAdamConfig.rst", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip.rst", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout.rst", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_dqn_loss.rst", "reference/generated/torchrl.trainers.helpers.make_replay_buffer.rst", "reference/generated/torchrl.trainers.helpers.make_target_updater.rst", "reference/generated/torchrl.trainers.helpers.make_trainer.rst", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor.rst", "reference/generated/torchrl.trainers.helpers.sync_async_collector.rst", "reference/generated/torchrl.trainers.helpers.sync_sync_collector.rst", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor.rst", "reference/generated/torchrl.weight_update.DistributedTransport.rst", "reference/generated/torchrl.weight_update.DistributedWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.MPTransport.rst", "reference/generated/torchrl.weight_update.MultiProcessWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.NoWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.RPCTransport.rst", "reference/generated/torchrl.weight_update.RPCWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.RayModuleTransformScheme.rst", "reference/generated/torchrl.weight_update.RayTransport.rst", "reference/generated/torchrl.weight_update.RayWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.SharedMemTransport.rst", "reference/generated/torchrl.weight_update.SharedMemWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.TransportBackend.rst", "reference/generated/torchrl.weight_update.WeightStrategy.rst", "reference/generated/torchrl.weight_update.WeightSyncScheme.rst", "reference/generated/torchrl.weight_update.llm.VLLMCollectiveTransport.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferTransport.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightSender.rst", "reference/generated/torchrl.weight_update.llm.VLLMWeightReceiver.rst", "reference/generated/torchrl.weight_update.llm.VLLMWeightSender.rst", "reference/generated/torchrl.weight_update.llm.VLLMWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.llm.get_model_metadata.rst", "reference/generated/tutorials/README.rst", "reference/index.rst", "reference/knowledge_base.rst", "reference/llms.rst", "reference/llms_collectors.rst", "reference/llms_data.rst", "reference/llms_envs.rst", "reference/llms_modules.rst", "reference/llms_objectives.rst", "reference/llms_transforms.rst", "reference/modules.rst", "reference/modules_actors.rst", "reference/modules_critics.rst", "reference/modules_distributions.rst", "reference/modules_exploration.rst", "reference/modules_models.rst", "reference/modules_utils.rst", "reference/objectives.rst", "reference/objectives_actorcritic.rst", "reference/objectives_common.rst", "reference/objectives_offline.rst", "reference/objectives_other.rst", "reference/objectives_policy.rst", "reference/objectives_value.rst", "reference/services.rst", "reference/trainers.rst", "reference/trainers_basics.rst", "reference/trainers_hooks.rst", "reference/trainers_loggers.rst", "reference/utils.rst", "sg_execution_times.rst", "tutorials/coding_ddpg.rst", "tutorials/coding_dqn.rst", "tutorials/coding_ppo.rst", "tutorials/dqn_with_rnn.rst", "tutorials/export.rst", "tutorials/getting-started-0.rst", "tutorials/getting-started-1.rst", "tutorials/getting-started-2.rst", "tutorials/getting-started-3.rst", "tutorials/getting-started-4.rst", "tutorials/getting-started-5.rst", "tutorials/index.rst", "tutorials/llm_browser.rst", "tutorials/llm_wrappers.rst", "tutorials/multi_task.rst", "tutorials/multiagent_competitive_ddpg.rst", "tutorials/multiagent_ppo.rst", "tutorials/pendulum.rst", "tutorials/pretrained_models.rst", "tutorials/rb_tutorial.rst", "tutorials/sg_execution_times.rst", "tutorials/torchrl_demo.rst", "tutorials/torchrl_envs.rst"], "titles": ["TorchRL", "torchrl.collectors package", "Collector Basics", "Distributed Collectors", "Collectors and Replay Buffers", "Single Node Collectors", "Weight Synchronization", "TorchRL Configuration System", "&lt;no title&gt;", "&lt;no title&gt;", "torchrl.data package", "Datasets", "Replay Buffers", "Sampling Strategies", "TensorSpec System", "Storage Backends", "torchrl.envs package", "Environment API", "Library Wrappers", "Multi-agent Environments", "Recorders", "Transforms", "Vectorized and Parallel Environments", "Things to consider when debugging RL", "Working with gym", "Working with <code class=\"docutils literal notranslate\"><span class=\"pre\">habitat-lab</span></code>", "Working with MuJoCo-based environments", "Common PyTorch errors and solutions", "Useful resources", "Versioning Issues", "Customising Video Renders", "auto_unwrap_transformed_env", "AsyncCollector", "BaseCollector", "Collector", "MultiAsyncCollector", "MultiCollector", "MultiProcessedWeightUpdater", "MultiSyncCollector", "RayWeightUpdater", "VanillaWeightUpdater", "WeightUpdaterBase", "DistributedCollector", "DistributedDataCollector", "DistributedSyncCollector", "DistributedSyncDataCollector", "DistributedWeightUpdater", "RPCCollector", "RPCDataCollector", "RPCWeightUpdater", "RayCollector", "submitit_delayed_launcher", "LLMCollector", "RayLLMCollector", "vLLMUpdater", "vLLMUpdaterV2", "split_trajectories", "Binary", "Bounded", "Categorical", "Composite", "MultiCategorical", "MultiOneHot", "NonTensor", "OneHot", "PrioritizedReplayBuffer", "RayReplayBuffer", "RemoteTensorDictReplayBuffer", "ReplayBuffer", "ReplayBufferEnsemble", "Stacked", "StackedComposite", "TensorDictPrioritizedReplayBuffer", "TensorDictReplayBuffer", "TensorSpec", "Unbounded", "UnboundedContinuous", "UnboundedDiscrete", "AtariDQNExperienceReplay", "D4RLExperienceReplay", "GenDGRLExperienceReplay", "MinariExperienceReplay", "OpenMLExperienceReplay", "OpenXExperienceReplay", "RobosetExperienceReplay", "VD4RLExperienceReplay", "ContentBase", "History", "TopKRewardSelector", "add_chat_template", "CompressedListStorage", "CompressedListStorageCheckpointer", "FlatStorageCheckpointer", "H5StorageCheckpointer", "ImmutableDatasetWriter", "LazyMemmapStorage", "LazyStackStorage", "LazyTensorStorage", "ListStorage", "ListStorageCheckpointer", "NestedStorageCheckpointer", "PrioritizedSampler", "PrioritizedSliceSampler", "RandomSampler", "RoundRobinWriter", "Sampler", "SamplerEnsemble", "SamplerWithoutReplacement", "SliceSampler", "SliceSamplerWithoutReplacement", "Storage", "StorageCheckpointerBase", "StorageEnsemble", "StorageEnsembleCheckpointer", "TensorDictMaxValueWriter", "TensorDictRoundRobinWriter", "TensorStorage", "TensorStorageCheckpointer", "Writer", "WriterEnsemble", "AsyncEnvPool", "BraxEnv", "BraxWrapper", "ChessEnv", "DMControlEnv", "DMControlWrapper", "EnvBase", "EnvCreator", "EnvMetaData", "GymEnv", "GymLikeEnv", "GymWrapper", "HabitatEnv", "IsaacGymEnv", "IsaacGymWrapper", "IsaacLabWrapper", "JumanjiEnv", "JumanjiWrapper", "LLMHashingEnv", "MOGymEnv", "MOGymWrapper", "MarlGroupMapType", "MeltingpotEnv", "MeltingpotWrapper", "ModelBasedEnvBase", "MultiThreadedEnv", "MultiThreadedEnvWrapper", "OpenMLEnv", "OpenSpielEnv", "OpenSpielWrapper", "ParallelEnv", "PendulumEnv", "PettingZooEnv", "PettingZooWrapper", "ProcessorAsyncEnvPool", "RoboHiveEnv", "SMACv2Env", "SMACv2Wrapper", "SerialEnv", "ThreadingAsyncEnvPool", "TicTacToeEnv", "UnityMLAgentsEnv", "UnityMLAgentsWrapper", "VmasEnv", "VmasWrapper", "check_env_specs", "check_marl_grouping", "exploration_type", "get_available_libraries", "gym_backend", "ChatEnv", "DatasetChatEnv", "GSM8KEnv", "GSM8KPrepareQuestion", "GSM8KRewardParser", "IFEvalEnv", "IFEvalScoreData", "IfEvalScorer", "LLMEnv", "LLMHashingEnv", "MLGymWrapper", "make_gsm8k_env", "make_mlgym", "AddThinkingPrompt", "BrowserTransform", "DataLoadingPrimer", "ExecuteToolsInOrder", "JSONCallParser", "KLComputation", "KLRewardTransform", "MCPToolTransform", "PolicyVersion", "PythonExecutorService", "PythonInterpreter", "RayDataLoadingPrimer", "RetrieveKL", "RetrieveLogProb", "SimpleToolTransform", "TemplateTransform", "Tokenizer", "ToolCall", "ToolRegistry", "ToolService", "XMLBlockParser", "as_nested_tensor", "as_padded_tensor", "make_composite_from_td", "DreamerDecoder", "DreamerEnv", "register_gym_spec_conversion", "set_exploration_type", "set_gym_backend", "step_mdp", "terminated_or_truncated", "ActionDiscretizer", "ActionMask", "AutoResetEnv", "AutoResetTransform", "BatchSizeTransform", "BinarizeReward", "BurnInTransform", "CatFrames", "CatTensors", "CenterCrop", "ClipTransform", "Compose", "ConditionalPolicySwitch", "ConditionalSkip", "Crop", "DTypeCastTransform", "DeviceCastTransform", "DiscreteActionProjection", "DoubleToFloat", "EndOfLifeTransform", "ExcludeTransform", "FiniteTensorDictCheck", "FlattenObservation", "FrameSkipTransform", "GrayScale", "Hash", "InitTracker", "KLRewardTransform", "LineariseRewards", "ModuleTransform", "MultiAction", "NoopResetEnv", "ObservationNorm", "ObservationTransform", "PermuteTransform", "PinMemoryTransform", "R3MTransform", "RandomCropTensorDict", "RemoveEmptySpecs", "RenameTransform", "Resize", "Reward2GoTransform", "RewardClipping", "RewardScaling", "RewardSum", "SelectTransform", "SignTransform", "SqueezeTransform", "Stack", "StepCounter", "TargetReturn", "TensorDictPrimer", "TimeMaxPool", "Timer", "ToTensorImage", "Tokenizer", "TrajCounter", "Transform", "TransformedEnv", "UnaryTransform", "UnsqueezeTransform", "VC1Transform", "VIPRewardTransform", "VIPTransform", "VecGymEnvTransform", "VecNorm", "VecNormV2", "gSDENoise", "implement_for", "ActorCriticOperator", "ActorCriticWrapper", "ActorValueOperator", "AdditiveGaussianModule", "ConsistentDropoutModule", "ConvNet", "DTActor", "DdpgCnnActor", "DdpgCnnQNet", "DdpgMlpActor", "DdpgMlpQNet", "DecisionTransformer", "Delta", "DistributionalDQNnet", "DistributionalQValueActor", "DistributionalQValueModule", "DreamerActor", "DuelingCnnDQNet", "EGreedyModule", "GRUModule", "IndependentNormal", "LSTMModule", "MLP", "MaskedCategorical", "NormalParamExtractor", "ObsDecoder", "ObsEncoder", "OneHotCategorical", "OnlineDTActor", "OrnsteinUhlenbeckProcessModule", "QValueActor", "QValueModule", "RSSMPosterior", "RSSMPrior", "RSSMRollout", "ReparamGradientStrategy", "TanhDelta", "TanhNormal", "TruncatedNormal", "ValueOperator", "WorldModelWrapper", "AsyncVLLM", "ChatHistory", "LLMWrapperBase", "LogProbs", "Masks", "RemoteTransformersWrapper", "Text", "Tokens", "TransformersWrapper", "make_async_vllm_engine", "make_vllm_worker", "stateless_init_process_group", "stateless_init_process_group_async", "vLLMWrapper", "SquashDims", "set_exploration_modules_spec_from_env", "Actor", "MultiStepActorWrapper", "ProbabilisticActor", "RandomPolicy", "SafeModule", "SafeProbabilisticModule", "SafeProbabilisticTensorDictSequential", "SafeSequential", "TanhModule", "A2CLoss", "CQLLoss", "ClipPPOLoss", "CrossQLoss", "DDPGLoss", "DQNLoss", "DTLoss", "DiscreteCQLLoss", "DiscreteIQLLoss", "DiscreteSACLoss", "DistributionalDQNLoss", "DreamerActorLoss", "DreamerModelLoss", "DreamerValueLoss", "GAILLoss", "IQLLoss", "KLPENPPOLoss", "LossModule", "OnlineDTLoss", "PPOLoss", "REDQLoss", "ReinforceLoss", "SACLoss", "TD3BCLoss", "TD3Loss", "ValueEstimators", "add_random_module", "CISPOLoss", "CISPOLossOutput", "DAPO", "DAPOLossOutput", "GRPOLoss", "GRPOLossOutput", "LLMLossOutput", "MCAdvantage", "SFTLoss", "SFTLossOutput", "GAE", "TD0Estimator", "TD1Estimator", "TDLambdaEstimator", "ValueEstimatorBase", "PixelRenderTransform", "TensorDictRecorder", "VideoRecorder", "Logger", "CSVLogger", "generate_exp_name", "get_logger", "MLFlowLogger", "TensorboardLogger", "TrackioLogger", "WandbLogger", "RayService", "ServiceBase", "get_services", "set_auto_unwrap_transformed_env", "BatchSubSampler", "ClearCudaCache", "CountFramesLog", "LogScalar", "LogValidationReward", "OptimizerHook", "ReplayBufferTrainer", "RewardNormalizer", "SelectKeys", "TargetNetUpdaterHook", "Trainer", "TrainerHookBase", "UTDRHook", "UpdateWeights", "PPOTrainer", "SACTrainer", "torchrl.trainers.algorithms.configs.collectors.AsyncCollectorConfig", "torchrl.trainers.algorithms.configs.collectors.CollectorConfig", "torchrl.trainers.algorithms.configs.collectors.MultiAsyncCollectorConfig", "torchrl.trainers.algorithms.configs.collectors.MultiSyncCollectorConfig", "torchrl.trainers.algorithms.configs.common.ConfigBase", "torchrl.trainers.algorithms.configs.data.LazyMemmapStorageConfig", "torchrl.trainers.algorithms.configs.data.LazyStackStorageConfig", "torchrl.trainers.algorithms.configs.data.LazyTensorStorageConfig", "torchrl.trainers.algorithms.configs.data.ListStorageConfig", "torchrl.trainers.algorithms.configs.data.PrioritizedSamplerConfig", "torchrl.trainers.algorithms.configs.data.RandomSamplerConfig", "torchrl.trainers.algorithms.configs.data.ReplayBufferConfig", "torchrl.trainers.algorithms.configs.data.RoundRobinWriterConfig", "torchrl.trainers.algorithms.configs.data.SamplerWithoutReplacementConfig", "torchrl.trainers.algorithms.configs.data.SliceSamplerConfig", "torchrl.trainers.algorithms.configs.data.SliceSamplerWithoutReplacementConfig", "torchrl.trainers.algorithms.configs.data.StorageEnsembleConfig", "torchrl.trainers.algorithms.configs.data.StorageEnsembleWriterConfig", "torchrl.trainers.algorithms.configs.data.TensorDictReplayBufferConfig", "torchrl.trainers.algorithms.configs.data.TensorStorageConfig", "torchrl.trainers.algorithms.configs.envs.BatchedEnvConfig", "torchrl.trainers.algorithms.configs.envs.EnvConfig", "torchrl.trainers.algorithms.configs.envs.TransformedEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.BraxEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.DMControlEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.EnvLibsConfig", "torchrl.trainers.algorithms.configs.envs_libs.GymEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.HabitatEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.IsaacGymEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.JumanjiEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.MOGymEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.MeltingpotEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.MultiThreadedEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.OpenMLEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.OpenSpielEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.PettingZooEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.RoboHiveEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.SMACv2EnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.UnityMLAgentsEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.VmasEnvConfig", "torchrl.trainers.algorithms.configs.logging.CSVLoggerConfig", "torchrl.trainers.algorithms.configs.logging.LoggerConfig", "torchrl.trainers.algorithms.configs.logging.TensorboardLoggerConfig", "torchrl.trainers.algorithms.configs.logging.WandbLoggerConfig", "torchrl.trainers.algorithms.configs.modules.ConvNetConfig", "torchrl.trainers.algorithms.configs.modules.MLPConfig", "torchrl.trainers.algorithms.configs.modules.ModelConfig", "torchrl.trainers.algorithms.configs.modules.NetworkConfig", "torchrl.trainers.algorithms.configs.modules.TanhNormalModelConfig", "torchrl.trainers.algorithms.configs.modules.TensorDictModuleConfig", "torchrl.trainers.algorithms.configs.modules.ValueModelConfig", "torchrl.trainers.algorithms.configs.objectives.LossConfig", "torchrl.trainers.algorithms.configs.objectives.PPOLossConfig", "torchrl.trainers.algorithms.configs.trainers.PPOTrainerConfig", "torchrl.trainers.algorithms.configs.trainers.TrainerConfig", "torchrl.trainers.algorithms.configs.transforms.ActionDiscretizerConfig", "torchrl.trainers.algorithms.configs.transforms.ActionMaskConfig", "torchrl.trainers.algorithms.configs.transforms.AutoResetTransformConfig", "torchrl.trainers.algorithms.configs.transforms.BatchSizeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.BinarizeRewardConfig", "torchrl.trainers.algorithms.configs.transforms.BurnInTransformConfig", "torchrl.trainers.algorithms.configs.transforms.CatFramesConfig", "torchrl.trainers.algorithms.configs.transforms.CatTensorsConfig", "torchrl.trainers.algorithms.configs.transforms.CenterCropConfig", "torchrl.trainers.algorithms.configs.transforms.ClipTransformConfig", "torchrl.trainers.algorithms.configs.transforms.ComposeConfig", "torchrl.trainers.algorithms.configs.transforms.ConditionalPolicySwitchConfig", "torchrl.trainers.algorithms.configs.transforms.ConditionalSkipConfig", "torchrl.trainers.algorithms.configs.transforms.CropConfig", "torchrl.trainers.algorithms.configs.transforms.DTypeCastTransformConfig", "torchrl.trainers.algorithms.configs.transforms.DeviceCastTransformConfig", "torchrl.trainers.algorithms.configs.transforms.DiscreteActionProjectionConfig", "torchrl.trainers.algorithms.configs.transforms.DoubleToFloatConfig", "torchrl.trainers.algorithms.configs.transforms.EndOfLifeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.ExcludeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.FiniteTensorDictCheckConfig", "torchrl.trainers.algorithms.configs.transforms.FlattenObservationConfig", "torchrl.trainers.algorithms.configs.transforms.FrameSkipTransformConfig", "torchrl.trainers.algorithms.configs.transforms.GrayScaleConfig", "torchrl.trainers.algorithms.configs.transforms.HashConfig", "torchrl.trainers.algorithms.configs.transforms.InitTrackerConfig", "torchrl.trainers.algorithms.configs.transforms.KLRewardTransformConfig", "torchrl.trainers.algorithms.configs.transforms.LineariseRewardsConfig", "torchrl.trainers.algorithms.configs.transforms.MultiActionConfig", "torchrl.trainers.algorithms.configs.transforms.MultiStepTransformConfig", "torchrl.trainers.algorithms.configs.transforms.NoopResetEnvConfig", "torchrl.trainers.algorithms.configs.transforms.ObservationNormConfig", "torchrl.trainers.algorithms.configs.transforms.PermuteTransformConfig", "torchrl.trainers.algorithms.configs.transforms.PinMemoryTransformConfig", "torchrl.trainers.algorithms.configs.transforms.R3MTransformConfig", "torchrl.trainers.algorithms.configs.transforms.RandomCropTensorDictConfig", "torchrl.trainers.algorithms.configs.transforms.RemoveEmptySpecsConfig", "torchrl.trainers.algorithms.configs.transforms.RenameTransformConfig", "torchrl.trainers.algorithms.configs.transforms.ResizeConfig", "torchrl.trainers.algorithms.configs.transforms.Reward2GoTransformConfig", "torchrl.trainers.algorithms.configs.transforms.RewardClippingConfig", "torchrl.trainers.algorithms.configs.transforms.RewardScalingConfig", "torchrl.trainers.algorithms.configs.transforms.RewardSumConfig", "torchrl.trainers.algorithms.configs.transforms.SelectTransformConfig", "torchrl.trainers.algorithms.configs.transforms.SignTransformConfig", "torchrl.trainers.algorithms.configs.transforms.SqueezeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.StackConfig", "torchrl.trainers.algorithms.configs.transforms.StepCounterConfig", "torchrl.trainers.algorithms.configs.transforms.TargetReturnConfig", "torchrl.trainers.algorithms.configs.transforms.TensorDictPrimerConfig", "torchrl.trainers.algorithms.configs.transforms.TimeMaxPoolConfig", "torchrl.trainers.algorithms.configs.transforms.TimerConfig", "torchrl.trainers.algorithms.configs.transforms.ToTensorImageConfig", "torchrl.trainers.algorithms.configs.transforms.TokenizerConfig", "torchrl.trainers.algorithms.configs.transforms.TrajCounterConfig", "torchrl.trainers.algorithms.configs.transforms.TransformConfig", "torchrl.trainers.algorithms.configs.transforms.UnaryTransformConfig", "torchrl.trainers.algorithms.configs.transforms.UnsqueezeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VC1TransformConfig", "torchrl.trainers.algorithms.configs.transforms.VIPRewardTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VIPTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VecGymEnvTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VecNormConfig", "torchrl.trainers.algorithms.configs.transforms.VecNormV2Config", "torchrl.trainers.algorithms.configs.utils.ASGDConfig", "torchrl.trainers.algorithms.configs.utils.AdadeltaConfig", "torchrl.trainers.algorithms.configs.utils.AdagradConfig", "torchrl.trainers.algorithms.configs.utils.AdamConfig", "torchrl.trainers.algorithms.configs.utils.AdamWConfig", "torchrl.trainers.algorithms.configs.utils.AdamaxConfig", "torchrl.trainers.algorithms.configs.utils.LBFGSConfig", "torchrl.trainers.algorithms.configs.utils.LionConfig", "torchrl.trainers.algorithms.configs.utils.NAdamConfig", "torchrl.trainers.algorithms.configs.utils.RAdamConfig", "torchrl.trainers.algorithms.configs.utils.RMSpropConfig", "torchrl.trainers.algorithms.configs.utils.RpropConfig", "torchrl.trainers.algorithms.configs.utils.SGDConfig", "torchrl.trainers.algorithms.configs.utils.SparseAdamConfig", "correct_for_frame_skip", "get_stats_random_rollout", "make_collector_offpolicy", "make_collector_onpolicy", "make_dqn_loss", "make_replay_buffer", "make_target_updater", "make_trainer", "parallel_env_constructor", "sync_async_collector", "sync_sync_collector", "transformed_env_constructor", "DistributedTransport", "DistributedWeightSyncScheme", "MPTransport", "MultiProcessWeightSyncScheme", "NoWeightSyncScheme", "RPCTransport", "RPCWeightSyncScheme", "RayModuleTransformScheme", "RayTransport", "RayWeightSyncScheme", "SharedMemTransport", "SharedMemWeightSyncScheme", "TransportBackend", "WeightStrategy", "WeightSyncScheme", "VLLMCollectiveTransport", "VLLMDoubleBufferSyncScheme", "VLLMDoubleBufferTransport", "VLLMDoubleBufferWeightReceiver", "VLLMDoubleBufferWeightSender", "VLLMWeightReceiver", "VLLMWeightSender", "VLLMWeightSyncScheme", "get_model_metadata", "README Tutos", "API Reference", "Knowledge Base", "LLM Interface", "LLM Collectors", "Data Structures", "LLM Environments", "LLM Wrappers", "LLM Objectives", "LLM Transforms", "torchrl.modules package", "Actor Modules", "Value Networks and Critics", "Distribution Classes", "Exploration Strategies", "World Models and Model-Based RL", "Utilities and Helpers", "torchrl.objectives package", "Actor-Critic Methods", "Common Components", "Offline RL Methods", "Other Loss Modules", "Policy Gradient Methods", "Value-Based Methods", "Service Registry", "torchrl.trainers package", "Trainer Basics", "Training Hooks", "Loggers", "torchrl._utils package", "Computation times", "TorchRL objectives: Coding a DDPG loss", "TorchRL trainer: A DQN example", "Reinforcement Learning (PPO) with TorchRL Tutorial", "Recurrent DQN: Training recurrent policies", "Exporting TorchRL modules", "Get started with Environments, TED and transforms", "Get started with TorchRL\u2019s modules", "Getting started with model optimization", "Get started with data collection and storage", "Get started with logging", "Get started with your own first training loop", "README Tutos", "TorchRL LLM: Building Tool-Enabled Environments", "LLM Wrappers in TorchRL", "Task-specific policy in multi-task environments", "Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial", "Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial", "Pendulum: Writing your environment and transforms with TorchRL", "Using pretrained models", "Using Replay Buffers", "Computation times", "Introduction to TorchRL", "TorchRL envs"], "terms": {"an": [0, 2, 6, 12, 16, 17, 18, 19, 20, 21, 22, 24, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 94, 95, 96, 97, 98, 102, 104, 106, 108, 109, 110, 112, 114, 115, 116, 118, 119, 120, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 137, 138, 144, 145, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 165, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 214, 215, 217, 218, 220, 221, 223, 229, 231, 232, 235, 239, 243, 245, 246, 250, 251, 252, 253, 255, 264, 265, 266, 267, 268, 270, 271, 272, 275, 278, 279, 280, 283, 284, 285, 288, 290, 291, 292, 293, 295, 297, 298, 301, 302, 304, 305, 312, 313, 320, 323, 324, 325, 326, 327, 328, 330, 331, 332, 333, 335, 336, 337, 338, 341, 342, 345, 346, 349, 350, 351, 352, 354, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 396, 401, 404, 410, 411, 416, 417, 420, 421, 556, 563, 564, 565, 566, 570, 578, 593, 594, 622, 623, 626, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 640, 641, 643, 644], "open": [0, 24, 26, 83, 86, 87, 95, 176, 282, 325, 327, 328, 330, 331, 335, 336, 377, 379, 381, 382, 385, 623, 634, 635, 637, 638, 643], "sourc": [0, 2, 4, 23, 26, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "reinforc": [0, 7, 15, 22, 28, 80, 142, 143, 170, 171, 221, 280, 290, 291, 292, 293, 298, 312, 349, 350, 352, 355, 356, 357, 359, 364, 370, 371, 372, 420, 594, 606, 608, 611, 621, 623, 627, 628, 633, 635, 639, 642, 643], "learn": [0, 7, 15, 19, 22, 26, 27, 28, 42, 80, 81, 82, 84, 85, 86, 87, 101, 102, 126, 142, 143, 147, 150, 158, 170, 171, 176, 177, 221, 280, 290, 291, 292, 293, 298, 312, 325, 327, 328, 330, 331, 349, 350, 351, 352, 355, 356, 357, 359, 363, 364, 368, 369, 370, 371, 372, 377, 379, 380, 381, 382, 385, 420, 421, 594, 606, 608, 611, 621, 622, 623, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 639, 641, 642, 643, 644], "rl": [0, 2, 6, 10, 11, 12, 16, 18, 22, 24, 27, 29, 32, 34, 35, 38, 78, 135, 144, 170, 221, 264, 322, 332, 337, 340, 342, 349, 351, 365, 366, 368, 370, 380, 406, 591, 592, 593, 601, 602, 604, 607, 608, 614, 622, 623, 624, 626, 630, 633, 637, 638, 640, 641, 644], "librari": [0, 2, 3, 6, 10, 16, 17, 20, 22, 24, 25, 26, 27, 28, 29, 30, 35, 36, 38, 42, 44, 47, 123, 124, 125, 134, 145, 168, 177, 190, 324, 404, 592, 593, 620, 622, 623, 624, 626, 627, 628, 630, 637, 638, 639, 644], "pytorch": [0, 2, 3, 6, 19, 20, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 81, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 175, 178, 179, 180, 221, 267, 268, 317, 416, 580, 582, 591, 593, 604, 622, 624, 625, 629, 633, 637, 638, 639, 643, 644], "you": [0, 2, 5, 6, 7, 12, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 54, 80, 87, 88, 89, 120, 123, 126, 130, 134, 138, 141, 142, 143, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 221, 242, 271, 279, 280, 326, 332, 337, 345, 368, 376, 378, 380, 383, 384, 401, 405, 589, 593, 594, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "can": [0, 2, 3, 4, 6, 7, 8, 12, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 101, 102, 107, 108, 109, 114, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 134, 136, 137, 138, 141, 142, 143, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 202, 209, 211, 213, 214, 215, 217, 218, 220, 221, 224, 225, 227, 229, 231, 232, 233, 236, 239, 244, 245, 246, 250, 251, 255, 258, 262, 263, 264, 265, 269, 270, 271, 272, 273, 275, 277, 279, 280, 282, 286, 287, 288, 290, 297, 298, 301, 302, 303, 304, 306, 307, 312, 313, 314, 320, 321, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 337, 339, 340, 341, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 401, 402, 403, 405, 409, 410, 420, 468, 564, 565, 566, 568, 570, 571, 573, 574, 576, 577, 578, 579, 580, 581, 583, 588, 589, 593, 594, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "directli": [0, 6, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 69, 78, 81, 88, 120, 121, 122, 123, 126, 129, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 246, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 273, 275, 276, 278, 279, 280, 324, 329, 345, 366, 372, 376, 378, 380, 383, 384, 566, 568, 570, 573, 574, 576, 577, 581, 583, 589, 594, 623, 624, 625, 626, 627, 637, 638, 639, 641], "from": [0, 1, 2, 4, 5, 6, 7, 10, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 96, 97, 98, 101, 102, 106, 107, 108, 109, 110, 112, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 206, 208, 211, 212, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 239, 240, 241, 242, 246, 248, 250, 251, 252, 253, 254, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 277, 278, 279, 280, 282, 283, 284, 285, 287, 290, 291, 292, 293, 294, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 315, 316, 317, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 393, 402, 406, 409, 412, 416, 418, 419, 420, 421, 431, 432, 436, 475, 555, 556, 560, 562, 563, 566, 567, 568, 569, 570, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 593, 594, 601, 608, 615, 616, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644], "pypi": [0, 643], "see": [0, 1, 3, 17, 18, 19, 21, 22, 25, 26, 27, 28, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 96, 102, 108, 109, 120, 123, 126, 130, 133, 135, 137, 138, 142, 143, 145, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 225, 227, 244, 250, 265, 268, 270, 271, 272, 275, 277, 279, 280, 281, 283, 285, 287, 288, 302, 303, 304, 305, 307, 317, 321, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 344, 345, 351, 352, 363, 365, 366, 368, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 401, 402, 412, 420, 568, 570, 573, 574, 576, 577, 578, 581, 583, 589, 592, 594, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 634, 637, 638, 639, 641, 643, 644], "more": [0, 2, 6, 9, 17, 21, 22, 23, 25, 27, 28, 32, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 49, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 101, 102, 114, 120, 123, 126, 129, 130, 131, 133, 134, 137, 138, 142, 143, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 268, 271, 275, 280, 281, 282, 286, 287, 297, 298, 305, 307, 317, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 344, 345, 349, 359, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 401, 402, 411, 589, 592, 593, 594, 608, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 634, 635, 636, 637, 638, 639, 640, 643, 644], "about": [0, 21, 24, 26, 28, 42, 44, 47, 49, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 81, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 183, 195, 326, 332, 337, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 637, 638, 639, 641, 643, 644], "instruct": [0, 6, 25, 26, 29, 51, 79, 87, 135, 172, 177, 231, 233, 567, 570, 578, 594, 622, 623, 624, 625, 634, 637, 638, 641], "dedic": [0, 3, 6, 19, 42, 44, 47, 50, 68, 69, 72, 73, 150, 158, 283, 284, 285, 324, 577, 594, 622, 627, 629, 630, 632, 636, 638], "section": [0, 7, 17, 23, 126, 592, 623, 626, 627, 632, 637, 638], "below": [0, 1, 6, 17, 22, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 68, 72, 73, 75, 86, 87, 88, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 227, 244, 250, 265, 270, 271, 272, 275, 277, 288, 303, 305, 317, 321, 325, 326, 327, 328, 330, 331, 332, 337, 342, 344, 351, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 412, 622, 623, 624, 625, 626, 627, 637, 639], "pip": [0, 29, 82, 190, 626, 627, 628, 629, 630, 631, 632, 634, 638, 643, 644], "provid": [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 15, 16, 17, 18, 19, 21, 22, 24, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 98, 101, 102, 103, 106, 108, 109, 117, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 218, 220, 221, 222, 223, 224, 228, 229, 232, 236, 239, 243, 245, 246, 248, 250, 251, 254, 255, 258, 259, 264, 265, 266, 269, 270, 272, 274, 275, 277, 278, 279, 280, 282, 288, 294, 295, 298, 301, 302, 304, 305, 306, 313, 314, 315, 316, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 337, 340, 341, 342, 345, 348, 349, 350, 351, 352, 353, 354, 356, 358, 359, 360, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 397, 402, 403, 406, 412, 418, 419, 426, 556, 562, 568, 570, 588, 593, 594, 596, 598, 608, 615, 616, 622, 623, 624, 625, 626, 627, 628, 630, 631, 635, 636, 637, 638, 639, 640, 641, 643, 644], "python": [0, 5, 7, 22, 24, 25, 26, 29, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 146, 161, 162, 170, 190, 192, 193, 208, 211, 302, 304, 306, 592, 594, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "first": [0, 1, 2, 5, 6, 9, 17, 18, 19, 20, 22, 23, 24, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 95, 97, 102, 108, 109, 114, 116, 120, 123, 126, 129, 130, 131, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 186, 217, 218, 221, 222, 226, 227, 236, 244, 246, 250, 251, 267, 268, 272, 275, 280, 282, 288, 295, 297, 298, 302, 304, 305, 306, 309, 313, 324, 331, 340, 342, 344, 345, 351, 361, 365, 366, 368, 376, 378, 380, 384, 392, 393, 414, 576, 621, 622, 623, 624, 625, 626, 627, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644], "low": [0, 6, 18, 58, 60, 74, 75, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 183, 206, 214, 224, 231, 239, 242, 265, 273, 298, 319, 320, 321, 342, 345, 348, 368, 486, 622, 623, 624, 625, 626, 637, 638, 639, 643, 644], "high": [0, 1, 18, 22, 28, 58, 60, 72, 75, 86, 87, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 183, 206, 214, 224, 231, 239, 242, 245, 265, 273, 298, 319, 320, 321, 325, 327, 328, 330, 331, 342, 345, 348, 368, 377, 379, 381, 382, 385, 386, 486, 588, 616, 622, 623, 624, 625, 635, 637, 638, 639, 641, 643, 644], "level": [0, 6, 19, 21, 22, 23, 35, 36, 38, 51, 60, 65, 66, 68, 69, 71, 86, 87, 90, 129, 131, 176, 188, 196, 221, 263, 271, 302, 304, 325, 327, 328, 330, 331, 358, 365, 371, 377, 379, 381, 382, 385, 616, 622, 623, 626, 630, 643], "abstract": [0, 19, 27, 41, 74, 78, 82, 118, 126, 247, 390, 403, 407, 417, 426, 579, 581, 624, 626, 639, 643], "ar": [0, 1, 2, 3, 5, 6, 7, 9, 10, 12, 17, 18, 19, 20, 21, 22, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 96, 97, 98, 100, 101, 102, 106, 107, 108, 109, 110, 112, 114, 116, 120, 123, 126, 127, 129, 130, 131, 137, 138, 141, 142, 143, 144, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 208, 212, 213, 214, 216, 217, 218, 220, 221, 224, 225, 227, 229, 230, 231, 232, 233, 235, 236, 239, 241, 242, 244, 245, 248, 250, 255, 258, 262, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 278, 279, 280, 286, 293, 295, 297, 301, 302, 304, 306, 307, 310, 313, 316, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 337, 341, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 401, 402, 403, 404, 405, 412, 416, 418, 419, 420, 421, 562, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 581, 583, 587, 589, 594, 601, 608, 615, 620, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "intend": [0, 6, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 220, 231, 366, 643], "effici": [0, 1, 3, 6, 9, 10, 11, 12, 23, 27, 39, 91, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 192, 332, 352, 418, 570, 575, 594, 596, 608, 615, 622, 623, 624, 625, 626, 629, 630, 632, 636, 637, 638, 640, 641, 643], "modular": [0, 7, 78, 189, 347, 601, 616, 626, 641, 643], "document": [0, 6, 24, 26, 30, 32, 35, 36, 38, 42, 44, 47, 50, 83, 88, 120, 123, 126, 130, 135, 138, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 326, 332, 337, 376, 378, 380, 383, 384, 591, 592, 615, 623, 625, 626, 627, 630, 633, 643], "properli": [0, 4, 5, 21, 22, 52, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 195, 196, 212, 227, 302, 304, 386, 594, 624, 625, 631, 637, 638, 639, 643], "test": [0, 7, 20, 22, 24, 52, 120, 121, 122, 123, 126, 130, 136, 137, 138, 142, 143, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 183, 185, 270, 275, 315, 316, 410, 562, 583, 584, 587, 588, 594, 615, 624, 625, 626, 640, 643], "The": [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 93, 101, 102, 106, 108, 109, 110, 114, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 136, 137, 138, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 205, 208, 209, 212, 213, 214, 217, 218, 220, 221, 225, 226, 227, 229, 232, 233, 234, 239, 242, 243, 244, 246, 248, 250, 255, 257, 258, 259, 262, 263, 264, 265, 267, 270, 271, 272, 275, 277, 278, 279, 280, 283, 286, 290, 291, 292, 293, 294, 297, 298, 302, 304, 306, 307, 312, 313, 314, 315, 316, 317, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 342, 344, 345, 347, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 395, 398, 399, 400, 401, 402, 403, 405, 406, 411, 418, 419, 420, 421, 463, 473, 475, 562, 564, 565, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 586, 587, 589, 594, 596, 597, 598, 615, 616, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 637, 638, 639, 640, 641, 643, 644], "code": [0, 6, 17, 18, 22, 24, 26, 27, 35, 38, 60, 71, 83, 120, 123, 126, 130, 135, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 189, 190, 192, 193, 250, 272, 275, 326, 342, 345, 347, 594, 615, 621, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641, 642, 643, 644], "aim": [0, 21, 26, 70, 71, 250, 275, 277, 305, 555, 593, 622, 623, 643], "support": [0, 2, 3, 4, 7, 10, 16, 18, 19, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 82, 85, 86, 87, 89, 95, 97, 110, 112, 116, 117, 119, 120, 121, 122, 123, 129, 131, 136, 145, 147, 150, 152, 155, 168, 176, 178, 184, 189, 199, 218, 221, 233, 239, 246, 265, 266, 269, 272, 273, 280, 297, 298, 320, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 342, 344, 347, 359, 366, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 398, 404, 568, 570, 573, 574, 576, 578, 579, 580, 581, 583, 589, 594, 596, 601, 608, 615, 616, 624, 625, 627, 628, 634, 635, 638, 639, 641, 643, 644], "research": [0, 26, 28, 142, 143, 635, 643], "most": [0, 4, 6, 12, 17, 21, 26, 27, 35, 36, 38, 63, 101, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 231, 278, 326, 332, 337, 615, 622, 624, 626, 627, 628, 629, 630, 631, 632, 639, 643, 644], "written": [0, 4, 13, 17, 22, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 93, 95, 102, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 183, 212, 213, 214, 221, 233, 236, 241, 242, 258, 263, 266, 267, 272, 278, 282, 287, 312, 322, 325, 327, 328, 330, 331, 340, 342, 344, 345, 349, 351, 365, 368, 370, 377, 379, 380, 381, 382, 385, 391, 392, 393, 418, 594, 622, 625, 626, 628, 636, 639, 643], "highli": [0, 15, 332, 351, 368, 627, 643, 644], "wai": [0, 1, 2, 4, 5, 19, 21, 22, 23, 50, 60, 69, 71, 78, 81, 114, 134, 171, 172, 175, 195, 221, 225, 250, 253, 270, 271, 277, 278, 302, 304, 326, 332, 337, 368, 386, 387, 388, 389, 421, 594, 615, 622, 623, 624, 626, 627, 629, 630, 636, 637, 638, 639, 640, 641, 643, 644], "easili": [0, 2, 7, 17, 18, 22, 26, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 615, 622, 623, 624, 627, 628, 629, 632, 637, 638, 643, 644], "swap": [0, 2, 16, 17, 129, 278, 624, 626, 640, 643], "compon": [0, 2, 6, 7, 10, 12, 19, 21, 22, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 95, 96, 97, 98, 110, 112, 116, 171, 297, 298, 314, 324, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 411, 416, 592, 608, 622, 623, 624, 625, 626, 628, 629, 632, 634, 636, 637, 638, 639, 640, 643], "transform": [0, 3, 4, 6, 10, 12, 16, 17, 18, 20, 22, 23, 27, 32, 34, 35, 36, 38, 40, 41, 42, 44, 47, 50, 52, 53, 54, 55, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 93, 100, 112, 117, 120, 123, 126, 127, 130, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 207, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 287, 289, 290, 294, 299, 302, 304, 311, 317, 320, 325, 327, 328, 329, 330, 331, 332, 337, 341, 348, 355, 367, 377, 379, 381, 382, 383, 384, 385, 391, 393, 412, 419, 420, 433, 438, 439, 440, 444, 475, 566, 574, 575, 576, 592, 596, 615, 621, 623, 625, 626, 628, 630, 631, 632, 633, 634, 640, 642], "them": [0, 6, 12, 19, 26, 28, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 114, 119, 120, 123, 126, 127, 130, 134, 138, 141, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 199, 229, 232, 239, 242, 265, 269, 272, 273, 279, 280, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 338, 341, 348, 350, 352, 358, 364, 365, 369, 371, 372, 373, 387, 388, 389, 393, 567, 570, 577, 579, 584, 585, 586, 615, 622, 623, 625, 626, 627, 628, 630, 631, 635, 636, 637, 638, 639, 640, 641, 643, 644], "write": [0, 17, 27, 32, 34, 35, 36, 38, 52, 56, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 112, 119, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 213, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 248, 249, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 274, 275, 276, 278, 279, 322, 325, 327, 328, 330, 331, 340, 344, 345, 347, 352, 353, 354, 356, 357, 358, 364, 369, 371, 372, 373, 377, 379, 381, 382, 383, 385, 390, 393, 583, 584, 586, 594, 615, 616, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 636, 637, 638, 640, 641, 642, 643, 644], "new": [0, 2, 6, 7, 18, 21, 23, 27, 32, 34, 35, 36, 38, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 101, 102, 107, 120, 123, 126, 130, 138, 145, 150, 151, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 212, 213, 218, 243, 258, 262, 271, 272, 279, 280, 295, 302, 304, 312, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 344, 345, 349, 350, 351, 354, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 401, 419, 568, 570, 573, 574, 576, 577, 578, 581, 583, 585, 589, 594, 622, 624, 627, 629, 635, 637, 638, 639, 643, 644], "ones": [0, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 86, 87, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 222, 225, 226, 229, 230, 232, 246, 250, 255, 262, 265, 271, 272, 275, 277, 280, 306, 325, 326, 327, 328, 330, 331, 332, 337, 343, 344, 349, 350, 351, 352, 353, 364, 365, 368, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 594, 622, 624, 626, 635, 637, 638, 639, 641, 643, 644], "littl": [0, 4, 5, 17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272, 349, 351, 365, 368, 370, 624, 625, 626, 630, 641, 643, 644], "effort": [0, 16, 17, 18, 324, 639, 641, 643], "thi": [0, 2, 3, 4, 5, 6, 7, 8, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 100, 101, 102, 106, 107, 108, 109, 110, 112, 114, 116, 117, 119, 120, 121, 122, 123, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 147, 150, 151, 152, 153, 154, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 208, 209, 211, 212, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 243, 244, 246, 249, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 320, 321, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 401, 402, 403, 404, 405, 406, 408, 409, 410, 412, 416, 418, 419, 420, 421, 426, 475, 555, 556, 562, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 593, 594, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "repo": [0, 25, 79, 221, 266, 275, 593, 626, 638, 643], "attempt": [0, 32, 34, 35, 36, 38, 42, 44, 47, 50, 86, 87, 88, 95, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 325, 326, 327, 328, 330, 331, 332, 337, 345, 354, 357, 364, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 629, 643], "align": [0, 643], "exist": [0, 19, 23, 32, 34, 35, 36, 38, 42, 50, 52, 53, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 222, 230, 243, 270, 271, 272, 282, 295, 325, 326, 327, 328, 330, 331, 332, 337, 345, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 403, 404, 556, 566, 575, 615, 637, 638, 643, 644], "ecosystem": [0, 626, 630, 643], "ha": [0, 2, 4, 6, 7, 18, 21, 22, 23, 24, 26, 27, 29, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 97, 101, 102, 106, 108, 114, 116, 120, 123, 126, 127, 130, 134, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 218, 221, 243, 244, 263, 264, 265, 266, 267, 269, 270, 271, 272, 286, 298, 302, 304, 320, 325, 326, 327, 328, 330, 331, 332, 337, 341, 345, 349, 352, 365, 366, 368, 370, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 393, 420, 475, 567, 575, 594, 622, 623, 624, 625, 626, 627, 630, 631, 634, 636, 637, 638, 639, 640, 641, 643, 644], "dataset": [0, 10, 65, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 94, 102, 106, 108, 109, 147, 170, 171, 172, 175, 176, 177, 178, 181, 185, 194, 279, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 393, 592, 594, 622, 623, 627, 640, 641, 643, 644], "pillar": [0, 643], "environ": [0, 1, 2, 3, 4, 6, 16, 20, 24, 27, 29, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 66, 70, 71, 74, 75, 76, 77, 88, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 208, 214, 215, 217, 218, 220, 221, 222, 226, 227, 229, 230, 231, 232, 237, 244, 245, 246, 250, 251, 252, 255, 258, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 278, 279, 280, 286, 287, 302, 304, 317, 326, 332, 337, 339, 341, 356, 360, 383, 386, 387, 388, 389, 390, 391, 393, 405, 406, 408, 410, 420, 421, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 475, 555, 556, 557, 558, 562, 563, 564, 565, 566, 592, 593, 600, 615, 621, 626, 628, 629, 630, 631, 633, 640, 641, 642], "model": [0, 2, 3, 6, 17, 19, 27, 28, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 55, 86, 87, 88, 89, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 229, 250, 265, 275, 277, 281, 283, 284, 285, 288, 289, 294, 296, 305, 311, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 344, 349, 350, 351, 352, 354, 355, 356, 357, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 403, 416, 468, 470, 472, 557, 558, 559, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 586, 588, 589, 590, 592, 593, 594, 596, 601, 621, 624, 627, 630, 633, 635, 637, 638, 639, 641, 642, 644], "data": [0, 1, 2, 3, 4, 6, 13, 15, 16, 17, 18, 19, 20, 21, 22, 27, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 135, 136, 137, 138, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 165, 170, 171, 172, 175, 176, 177, 178, 179, 180, 182, 185, 188, 189, 190, 191, 194, 195, 196, 199, 202, 206, 213, 215, 218, 220, 221, 226, 229, 230, 232, 234, 236, 239, 241, 246, 252, 255, 262, 263, 265, 269, 271, 272, 273, 278, 280, 297, 301, 302, 304, 312, 313, 322, 325, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336, 337, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 377, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 391, 393, 401, 406, 409, 412, 416, 418, 419, 420, 421, 422, 423, 424, 425, 475, 557, 562, 564, 565, 566, 569, 575, 582, 587, 592, 594, 597, 601, 615, 616, 621, 625, 626, 627, 628, 629, 633, 634, 635, 639, 640, 641, 642, 644], "util": [0, 11, 17, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 56, 68, 86, 87, 88, 108, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 143, 150, 151, 152, 153, 154, 158, 159, 160, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 265, 277, 287, 288, 294, 302, 304, 325, 326, 327, 328, 330, 331, 332, 337, 338, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 559, 562, 592, 600, 601, 610, 616, 620, 622, 624, 626, 628, 629, 638, 639, 641, 643, 644], "e": [0, 2, 6, 7, 17, 19, 20, 21, 22, 26, 27, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 89, 90, 95, 97, 101, 102, 114, 116, 120, 123, 126, 127, 130, 131, 138, 150, 151, 154, 158, 159, 160, 163, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 220, 222, 225, 226, 227, 228, 236, 239, 242, 244, 246, 250, 258, 265, 267, 270, 271, 272, 275, 277, 282, 298, 302, 303, 304, 307, 314, 320, 321, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 341, 342, 344, 345, 349, 351, 352, 353, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 403, 406, 416, 420, 475, 555, 565, 568, 569, 570, 571, 573, 574, 575, 576, 578, 581, 582, 583, 586, 589, 594, 615, 623, 624, 626, 628, 629, 631, 635, 637, 638, 640, 641, 643, 644], "g": [0, 2, 6, 7, 17, 19, 20, 21, 22, 26, 27, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 89, 114, 120, 123, 126, 127, 130, 131, 138, 150, 151, 154, 158, 159, 160, 163, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 220, 222, 225, 226, 236, 239, 242, 246, 250, 258, 265, 267, 270, 271, 272, 275, 277, 282, 302, 303, 304, 320, 321, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 342, 344, 345, 352, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 403, 416, 420, 475, 565, 568, 569, 570, 571, 573, 574, 576, 578, 581, 582, 583, 586, 589, 594, 615, 623, 624, 626, 628, 631, 637, 638, 639, 640, 641, 643, 644], "collector": [0, 7, 17, 18, 22, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 255, 263, 271, 302, 304, 312, 326, 329, 332, 337, 339, 343, 351, 365, 368, 380, 383, 412, 416, 419, 420, 421, 475, 557, 558, 562, 564, 565, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 581, 583, 589, 592, 594, 608, 615, 616, 626, 641, 644], "contain": [0, 11, 17, 21, 22, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 94, 102, 104, 106, 108, 109, 110, 115, 118, 119, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 221, 225, 229, 232, 239, 250, 262, 265, 270, 271, 272, 275, 277, 278, 279, 280, 288, 297, 298, 305, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 342, 344, 345, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 397, 406, 555, 562, 563, 564, 565, 566, 577, 584, 585, 594, 608, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 637, 638, 639, 640, 641, 643, 644], "etc": [0, 6, 7, 12, 17, 21, 22, 26, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 262, 272, 282, 305, 320, 326, 332, 337, 376, 378, 380, 383, 384, 402, 568, 569, 570, 571, 573, 574, 576, 578, 581, 583, 589, 601, 623, 624, 630, 641, 643, 644], "have": [0, 2, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 32, 35, 36, 38, 42, 46, 47, 50, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 107, 110, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 209, 213, 214, 217, 221, 226, 229, 232, 233, 241, 245, 246, 262, 263, 265, 269, 270, 271, 272, 279, 280, 286, 288, 305, 306, 312, 317, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 346, 347, 349, 351, 365, 368, 370, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 393, 402, 406, 416, 418, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589, 594, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 636, 637, 638, 639, 640, 641, 643, 644], "few": [0, 12, 27, 86, 87, 109, 130, 176, 180, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 393, 406, 594, 615, 624, 625, 628, 637, 638, 641, 643, 644], "depend": [0, 2, 3, 5, 6, 18, 21, 22, 23, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 58, 75, 120, 123, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 175, 177, 178, 179, 180, 190, 229, 232, 286, 322, 332, 337, 339, 345, 368, 395, 615, 622, 624, 625, 634, 637, 638, 639, 643, 644], "possibl": [0, 19, 20, 22, 23, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 80, 83, 85, 86, 87, 88, 96, 102, 108, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 225, 250, 265, 270, 271, 272, 275, 277, 288, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 410, 416, 594, 622, 624, 625, 626, 628, 630, 631, 637, 638, 639, 641, 643, 644], "standard": [0, 11, 19, 21, 63, 123, 246, 257, 279, 280, 286, 299, 311, 315, 316, 324, 326, 332, 337, 351, 365, 368, 372, 373, 386, 387, 388, 389, 409, 622, 623, 627, 628, 638, 641, 643], "numpi": [0, 20, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 239, 268, 273, 282, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 416, 626, 639, 641, 643, 644], "common": [0, 22, 23, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 74, 88, 120, 130, 136, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 233, 271, 283, 284, 285, 326, 349, 350, 351, 352, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 380, 383, 402, 403, 420, 422, 424, 425, 562, 592, 593, 594, 608, 615, 622, 624, 628, 631, 636, 637, 638, 639, 640, 643, 644], "openai": [0, 26, 129, 131, 138, 155, 179, 624, 639, 643, 644], "gym": [0, 3, 7, 16, 17, 18, 22, 23, 27, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 88, 120, 123, 126, 127, 129, 130, 131, 132, 134, 135, 138, 142, 143, 145, 146, 150, 151, 154, 155, 158, 159, 160, 163, 164, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 209, 211, 217, 221, 224, 233, 240, 241, 246, 248, 253, 255, 258, 265, 271, 278, 279, 282, 383, 452, 562, 593, 622, 623, 624, 625, 627, 631, 632, 639, 640, 641], "onli": [0, 2, 6, 7, 17, 19, 20, 22, 23, 26, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 95, 97, 101, 102, 108, 109, 116, 120, 123, 124, 125, 126, 129, 130, 131, 132, 134, 137, 138, 145, 146, 150, 151, 152, 153, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 217, 221, 222, 224, 225, 226, 227, 229, 231, 232, 236, 239, 244, 246, 250, 251, 255, 262, 263, 264, 265, 266, 270, 271, 272, 275, 277, 279, 280, 282, 297, 304, 306, 313, 317, 326, 329, 332, 337, 340, 342, 344, 345, 346, 347, 349, 351, 352, 353, 357, 358, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 393, 401, 402, 404, 416, 418, 556, 569, 578, 582, 589, 615, 622, 623, 624, 625, 626, 628, 629, 630, 631, 632, 634, 636, 637, 638, 639, 641, 643, 644], "option": [0, 3, 6, 10, 18, 22, 23, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 101, 102, 103, 104, 106, 107, 108, 109, 112, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 205, 206, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 228, 229, 231, 232, 233, 234, 236, 237, 239, 240, 241, 242, 243, 244, 245, 246, 250, 251, 253, 254, 257, 258, 259, 262, 263, 264, 265, 266, 268, 269, 270, 272, 273, 274, 275, 277, 278, 279, 280, 282, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 340, 341, 342, 344, 345, 346, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 395, 398, 400, 401, 402, 403, 404, 406, 408, 409, 410, 411, 412, 413, 416, 419, 420, 421, 475, 556, 562, 564, 565, 566, 568, 570, 571, 573, 574, 575, 576, 578, 581, 582, 583, 586, 588, 589, 592, 594, 625, 627, 630, 637, 638, 641, 643], "On": [0, 5, 19, 21, 26, 42, 44, 47, 50, 60, 80, 570, 578, 583, 594, 623, 637, 638], "end": [0, 6, 17, 32, 35, 36, 38, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 93, 102, 107, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 233, 239, 248, 263, 264, 270, 272, 288, 326, 332, 337, 341, 352, 371, 376, 378, 380, 383, 384, 436, 437, 495, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "come": [0, 1, 2, 4, 5, 6, 18, 20, 21, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 114, 120, 123, 126, 130, 137, 138, 141, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 229, 232, 283, 284, 285, 322, 340, 342, 349, 351, 365, 368, 370, 393, 569, 577, 622, 623, 624, 625, 629, 630, 631, 632, 637, 638, 641, 643, 644], "set": [0, 2, 3, 6, 7, 15, 17, 18, 21, 22, 26, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 98, 107, 110, 116, 120, 123, 126, 128, 130, 131, 137, 138, 142, 143, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 211, 213, 215, 217, 218, 221, 222, 225, 229, 232, 239, 240, 241, 242, 250, 255, 263, 264, 265, 266, 270, 271, 272, 275, 277, 279, 280, 282, 286, 302, 304, 306, 312, 317, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 339, 344, 345, 351, 352, 358, 363, 365, 366, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 390, 393, 405, 406, 410, 412, 421, 558, 566, 568, 570, 571, 573, 574, 575, 576, 578, 581, 583, 589, 593, 594, 620, 622, 623, 624, 625, 626, 628, 629, 630, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "re": [0, 21, 27, 33, 42, 43, 44, 45, 47, 48, 50, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 107, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 236, 304, 306, 326, 332, 337, 342, 345, 376, 378, 380, 383, 384, 401, 616, 622, 624, 625, 627, 629, 634, 636, 637, 639, 643, 644], "usabl": [0, 95, 616, 625, 643], "function": [0, 1, 7, 12, 17, 18, 19, 20, 21, 22, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 126, 127, 130, 131, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 211, 212, 213, 217, 218, 229, 232, 239, 241, 243, 269, 270, 272, 273, 279, 280, 282, 283, 284, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 304, 306, 307, 308, 309, 310, 311, 312, 314, 317, 321, 322, 325, 326, 327, 328, 330, 331, 332, 337, 338, 339, 341, 342, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 402, 404, 416, 420, 421, 474, 475, 562, 570, 581, 590, 596, 599, 607, 622, 625, 626, 627, 628, 631, 634, 636, 639, 641, 644], "cost": [0, 15, 59, 83, 96, 98, 349, 351, 365, 368, 370, 622, 623, 626, 637, 638, 639, 641], "return": [0, 1, 5, 6, 10, 16, 17, 18, 19, 20, 21, 22, 26, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 94, 95, 96, 102, 104, 106, 108, 109, 112, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 204, 205, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 288, 289, 290, 291, 292, 293, 295, 302, 303, 304, 305, 306, 307, 310, 311, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 335, 336, 337, 340, 341, 342, 344, 345, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 397, 402, 403, 404, 405, 416, 418, 419, 555, 557, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 587, 589, 590, 594, 608, 615, 622, 623, 624, 626, 628, 629, 631, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "process": [0, 1, 2, 3, 5, 6, 7, 12, 18, 21, 22, 23, 24, 27, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 65, 68, 72, 73, 78, 80, 84, 85, 86, 87, 88, 90, 95, 97, 101, 102, 104, 108, 116, 120, 123, 126, 127, 130, 134, 138, 141, 145, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 220, 221, 229, 232, 239, 265, 268, 270, 271, 279, 280, 298, 302, 304, 312, 314, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 351, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 568, 569, 570, 571, 573, 574, 575, 576, 578, 581, 582, 583, 589, 594, 615, 622, 623, 625, 626, 627, 634, 635, 637, 638, 639, 640, 641, 643, 644], "good": [0, 2, 23, 28, 101, 102, 150, 191, 594, 615, 622, 624, 625, 626, 628, 638, 643, 644], "runtim": [0, 22, 56, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 615, 626, 639], "perform": [0, 5, 6, 7, 10, 18, 20, 22, 23, 27, 32, 33, 35, 36, 38, 42, 43, 44, 45, 47, 48, 54, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 95, 120, 123, 124, 125, 126, 129, 130, 131, 132, 137, 138, 150, 151, 154, 155, 158, 159, 160, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 239, 245, 267, 270, 272, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 317, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 338, 341, 348, 351, 352, 361, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 410, 416, 418, 567, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589, 592, 594, 622, 623, 624, 625, 626, 627, 630, 632, 635, 636, 637, 638, 639, 644], "To": [0, 7, 18, 19, 20, 21, 23, 25, 26, 27, 28, 41, 42, 44, 47, 65, 66, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 93, 102, 108, 109, 112, 119, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 141, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 227, 263, 265, 279, 283, 284, 285, 287, 302, 304, 312, 326, 332, 337, 345, 352, 358, 363, 366, 372, 376, 378, 380, 383, 384, 393, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 587, 588, 594, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 637, 638, 639, 640, 641, 643, 644], "read": [0, 6, 17, 26, 56, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 110, 112, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 233, 234, 235, 236, 237, 240, 241, 243, 248, 249, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 269, 270, 271, 274, 275, 276, 278, 279, 283, 284, 285, 287, 297, 310, 322, 323, 325, 327, 328, 330, 331, 340, 341, 342, 344, 345, 347, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 393, 410, 416, 570, 577, 583, 584, 585, 622, 623, 624, 626, 627, 628, 636, 637, 638, 639, 640, 643, 644], "philosophi": [0, 28], "capabl": [0, 3, 18, 20, 26, 28, 30, 39, 50, 56, 170, 184, 420, 584, 594, 622, 627, 630, 634, 636, 640, 644], "beyond": [0, 6, 7, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 615, 626], "api": [0, 6, 16, 18, 22, 24, 46, 56, 60, 71, 74, 86, 87, 123, 126, 152, 153, 155, 176, 180, 182, 190, 250, 277, 279, 280, 324, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 384, 385, 420, 421, 583, 585, 587, 589, 594, 596, 598, 626, 627, 628, 629, 630, 631, 635, 637, 638, 639, 641, 643, 644], "check": [0, 17, 22, 23, 24, 25, 26, 28, 32, 34, 35, 36, 38, 42, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 86, 87, 88, 92, 93, 100, 108, 120, 123, 126, 127, 129, 130, 131, 138, 144, 150, 151, 154, 158, 159, 160, 165, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 221, 222, 227, 235, 241, 251, 265, 268, 272, 282, 295, 297, 298, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 344, 345, 352, 363, 368, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 402, 404, 567, 568, 570, 573, 574, 576, 578, 581, 582, 583, 584, 589, 591, 615, 623, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 636, 637, 638, 639, 640, 641, 643, 644], "paper": [0, 80, 83, 121, 122, 124, 125, 132, 136, 137, 142, 143, 145, 146, 155, 163, 164, 250, 275, 277, 288, 356, 372, 376, 378, 380, 622, 624, 637, 638], "releas": [0, 6, 23, 26, 29, 54, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384, 571, 573, 574, 576, 581, 583, 589, 594, 615], "sync": [0, 1, 2, 5, 7, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 120, 191, 324, 419, 562, 567, 568, 570, 578, 622], "so": [0, 5, 21, 22, 23, 25, 26, 29, 30, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 265, 270, 279, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 346, 347, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 393, 570, 578, 594, 622, 624, 625, 629, 632, 637, 638, 639, 644], "make": [0, 1, 5, 6, 7, 11, 16, 17, 18, 19, 21, 23, 26, 30, 60, 65, 66, 68, 69, 74, 78, 79, 82, 84, 85, 86, 87, 88, 106, 110, 112, 119, 120, 123, 126, 130, 131, 134, 135, 137, 138, 140, 146, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 227, 234, 242, 246, 250, 251, 255, 259, 263, 267, 271, 275, 287, 297, 302, 304, 324, 325, 326, 327, 328, 330, 331, 332, 337, 345, 349, 351, 365, 368, 370, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 402, 412, 558, 566, 601, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "sure": [0, 5, 19, 23, 26, 50, 82, 88, 110, 123, 130, 134, 173, 174, 175, 177, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 255, 271, 297, 383, 566, 622, 624, 625, 626, 629, 637, 638, 639, 641, 643, 644], "alwai": [0, 19, 21, 22, 35, 36, 38, 47, 52, 58, 74, 75, 78, 88, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 241, 245, 267, 279, 280, 326, 332, 337, 359, 366, 376, 378, 380, 383, 384, 468, 568, 570, 571, 573, 574, 576, 578, 581, 583, 584, 589, 615, 623, 624, 625, 626, 637, 638, 639, 641], "enjoi": [0, 22, 83, 630], "latest": [0, 21, 29, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 145, 148, 149, 152, 153, 190, 412, 624, 637, 638, 639, 643], "featur": [0, 5, 6, 18, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 54, 56, 63, 64, 74, 81, 86, 87, 102, 108, 109, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 197, 218, 221, 236, 239, 241, 248, 265, 266, 274, 279, 288, 299, 300, 302, 304, 305, 325, 326, 327, 328, 330, 331, 332, 337, 345, 349, 351, 365, 368, 370, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 402, 420, 421, 566, 592, 596, 622, 623, 624, 625, 626, 628, 629, 630, 632, 635, 639, 641, 643, 644], "recent": [0, 26, 189, 278, 280, 282], "version": [0, 2, 5, 6, 7, 18, 25, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 48, 49, 52, 53, 54, 55, 76, 77, 80, 85, 86, 87, 88, 108, 120, 123, 126, 129, 130, 131, 132, 138, 145, 146, 150, 151, 152, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 221, 269, 278, 279, 280, 282, 285, 302, 304, 325, 326, 327, 328, 329, 330, 331, 332, 336, 337, 349, 351, 365, 366, 368, 370, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 389, 420, 421, 592, 593, 596, 622, 624, 625, 626, 627, 629, 632, 637, 638, 639, 640, 644], "although": [0, 2, 5, 21, 27, 50, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 338, 341, 348, 622, 623, 630, 641], "core": [0, 7, 10, 19, 27, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 170, 615, 616, 617, 625, 628, 643], "guarante": [0, 12, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 345, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 630], "backward": [0, 1, 3, 5, 7, 8, 9, 27, 35, 36, 38, 54, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 279, 280, 308, 309, 316, 325, 326, 327, 328, 330, 331, 332, 337, 345, 349, 350, 352, 353, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 419, 622, 624, 625, 626, 629, 630, 632, 637, 638, 639], "compat": [0, 1, 3, 5, 6, 7, 17, 18, 26, 34, 35, 36, 38, 50, 54, 56, 60, 69, 71, 79, 86, 87, 88, 96, 98, 106, 108, 109, 110, 114, 120, 123, 126, 130, 132, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 263, 272, 275, 279, 280, 282, 302, 304, 308, 309, 313, 316, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 352, 353, 354, 356, 357, 358, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 419, 575, 583, 585, 589, 594, 622, 625, 634, 641], "2": [0, 2, 4, 7, 8, 10, 18, 19, 21, 22, 27, 28, 29, 33, 34, 35, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 95, 97, 101, 102, 108, 109, 114, 116, 120, 121, 122, 123, 126, 127, 130, 136, 137, 138, 141, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 206, 213, 217, 218, 220, 222, 225, 226, 227, 229, 230, 231, 232, 241, 242, 246, 248, 250, 252, 255, 258, 262, 263, 264, 265, 270, 271, 272, 275, 277, 279, 280, 282, 287, 288, 289, 290, 291, 292, 293, 294, 297, 298, 300, 301, 302, 304, 305, 306, 307, 311, 312, 320, 322, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 337, 338, 341, 344, 348, 349, 350, 351, 352, 353, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 393, 402, 406, 466, 467, 470, 471, 472, 552, 568, 569, 570, 572, 573, 574, 575, 576, 578, 581, 583, 589, 594, 601, 615, 621, 622, 623, 624, 625, 626, 628, 629, 630, 631, 636, 637, 638, 639, 641, 642, 643, 644], "0": [0, 2, 6, 7, 9, 10, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 101, 102, 108, 109, 116, 120, 121, 122, 123, 126, 129, 130, 132, 133, 136, 137, 138, 144, 145, 146, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 203, 205, 214, 215, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 230, 231, 233, 234, 235, 237, 240, 241, 242, 243, 244, 245, 246, 249, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 275, 276, 277, 278, 279, 280, 282, 286, 287, 288, 290, 291, 292, 293, 294, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 310, 312, 314, 315, 316, 319, 320, 321, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 340, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 402, 406, 413, 419, 420, 422, 423, 424, 425, 428, 448, 452, 466, 470, 474, 475, 490, 506, 508, 516, 518, 522, 523, 525, 534, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 562, 566, 568, 569, 574, 575, 576, 577, 582, 585, 587, 588, 589, 594, 608, 615, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644], "nightli": [0, 25], "via": [0, 3, 6, 17, 18, 22, 23, 26, 27, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 79, 81, 82, 83, 84, 85, 87, 89, 95, 96, 130, 150, 158, 178, 180, 186, 190, 242, 250, 253, 277, 286, 326, 332, 337, 352, 355, 366, 376, 378, 380, 384, 420, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 581, 582, 583, 587, 589, 608, 622, 623, 624, 625, 628, 630, 641, 643, 644], "tensordict": [0, 1, 2, 6, 10, 16, 17, 18, 19, 20, 21, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 96, 97, 98, 100, 101, 102, 106, 108, 109, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 206, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 283, 284, 285, 286, 287, 296, 297, 298, 301, 302, 304, 307, 312, 313, 314, 317, 322, 325, 326, 327, 328, 329, 330, 331, 332, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 406, 410, 411, 412, 414, 416, 419, 440, 471, 567, 568, 570, 571, 573, 574, 575, 576, 577, 578, 580, 581, 582, 583, 584, 585, 586, 589, 594, 601, 608, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 639, 640, 644], "git": [0, 25, 26, 29], "clone": [0, 23, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 95, 172, 184, 193, 194, 241, 252, 270, 271, 280, 283, 284, 285, 326, 332, 337, 344, 357, 364, 372, 622, 637, 639, 643], "willing": 0, "contribut": [0, 306, 420], "cd": [0, 26], "path": [0, 18, 25, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 93, 95, 111, 117, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 250, 277, 325, 326, 327, 328, 329, 330, 331, 332, 337, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 395, 401, 402, 416, 419, 420, 421, 475, 583, 584, 623, 626, 632, 637], "root": [0, 19, 21, 22, 60, 65, 66, 68, 69, 71, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 221, 244, 266, 267, 302, 303, 304, 320, 321, 386, 625, 627, 637, 638, 639, 641, 644], "http": [0, 24, 25, 26, 29, 35, 38, 42, 44, 47, 65, 78, 80, 81, 82, 83, 84, 85, 101, 102, 121, 122, 124, 125, 132, 134, 136, 137, 142, 143, 145, 146, 147, 148, 149, 152, 153, 155, 161, 162, 163, 164, 177, 186, 190, 221, 250, 275, 289, 290, 291, 292, 293, 294, 298, 299, 300, 306, 308, 309, 312, 315, 316, 317, 349, 350, 352, 354, 355, 356, 357, 359, 360, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 386, 591, 633, 634, 640, 643], "github": [0, 24, 25, 26, 29, 42, 44, 47, 78, 80, 81, 83, 121, 122, 124, 125, 129, 132, 136, 137, 142, 143, 145, 146, 148, 149, 152, 153, 155, 161, 162, 163, 164, 218, 221, 275, 628, 632, 634, 637, 638, 643], "com": [0, 24, 25, 26, 29, 42, 44, 47, 80, 83, 84, 121, 122, 124, 125, 132, 134, 136, 137, 142, 143, 145, 146, 148, 149, 152, 153, 155, 161, 162, 163, 164, 221, 634, 643], "setup": [0, 1, 6, 26, 42, 47, 50, 121, 122, 134, 136, 137, 161, 195, 196, 384, 420, 583, 588, 589], "py": [0, 6, 7, 18, 22, 129, 131, 211, 221, 295, 615, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644], "develop": [0, 6, 22, 23, 26, 134, 332, 337, 594, 622, 635, 643], "If": [0, 2, 3, 4, 5, 6, 9, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 102, 104, 106, 107, 108, 109, 114, 116, 120, 123, 124, 125, 126, 127, 129, 130, 131, 132, 134, 137, 138, 142, 143, 144, 145, 146, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 209, 212, 213, 214, 217, 218, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 236, 239, 241, 242, 243, 244, 245, 246, 250, 251, 254, 255, 258, 259, 264, 265, 266, 267, 268, 269, 270, 272, 273, 275, 277, 279, 280, 282, 287, 288, 297, 298, 301, 302, 304, 305, 306, 308, 309, 312, 313, 314, 315, 316, 317, 322, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 340, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 358, 359, 360, 361, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 397, 401, 402, 403, 404, 405, 409, 411, 412, 416, 419, 420, 421, 475, 556, 562, 566, 567, 568, 570, 572, 573, 574, 575, 576, 577, 578, 581, 583, 584, 586, 588, 589, 593, 622, 623, 624, 625, 626, 627, 629, 631, 632, 634, 636, 637, 638, 639, 641, 643, 644], "us": [0, 1, 2, 3, 4, 7, 8, 9, 12, 15, 16, 17, 18, 19, 20, 22, 24, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 98, 100, 101, 102, 103, 108, 109, 114, 116, 120, 121, 122, 123, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 208, 210, 211, 212, 213, 214, 215, 217, 218, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 244, 246, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 282, 286, 287, 288, 289, 290, 291, 294, 296, 297, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 342, 344, 345, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 396, 397, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 463, 473, 475, 556, 557, 558, 560, 562, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 581, 582, 583, 584, 585, 586, 587, 588, 589, 593, 594, 595, 608, 615, 616, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 642, 644], "uv": [0, 626], "specif": [0, 1, 2, 7, 16, 18, 22, 24, 27, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 72, 73, 74, 75, 76, 77, 120, 123, 126, 130, 138, 148, 149, 150, 151, 154, 158, 159, 160, 163, 170, 171, 172, 175, 178, 179, 180, 185, 190, 209, 244, 265, 280, 294, 302, 304, 324, 326, 332, 333, 334, 337, 349, 351, 366, 368, 370, 376, 378, 380, 384, 393, 402, 403, 404, 416, 420, 567, 568, 570, 571, 572, 573, 574, 575, 576, 581, 583, 589, 592, 601, 615, 616, 621, 624, 625, 627, 628, 629, 630, 631, 632, 633, 634, 637, 638, 641, 642, 643], "build": [0, 3, 7, 21, 26, 56, 60, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 121, 122, 123, 126, 130, 131, 132, 136, 137, 138, 142, 143, 145, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 255, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 416, 559, 560, 561, 596, 601, 607, 624, 625, 626, 628, 629, 630, 631, 637, 638, 639, 640, 643, 644], "beforehand": 0, "wheel": [0, 624], "dep": 0, "edit": [0, 21, 183, 271, 630], "prevent": [0, 23, 57, 59, 60, 61, 62, 64, 66, 71, 93, 101, 102, 121, 122, 279, 280, 303, 320, 321, 324, 332, 337, 349, 351, 365, 368, 370, 380, 413, 594, 631, 641], "resolut": [0, 326, 332, 337, 348, 568, 571, 573, 574, 576, 581, 583, 589], "potenti": [0, 2, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 639, 641], "downgrad": 0, "A": [0, 2, 6, 21, 22, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 107, 108, 110, 114, 115, 116, 117, 118, 120, 123, 126, 128, 130, 132, 133, 135, 138, 150, 151, 154, 155, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 203, 204, 205, 207, 212, 214, 216, 217, 218, 220, 221, 224, 225, 226, 227, 231, 237, 241, 243, 244, 250, 251, 253, 260, 265, 267, 270, 271, 272, 275, 276, 278, 279, 280, 281, 282, 286, 287, 288, 297, 298, 301, 302, 304, 305, 306, 307, 313, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 338, 341, 342, 343, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 394, 395, 398, 401, 403, 404, 405, 408, 415, 416, 419, 421, 423, 462, 463, 464, 465, 466, 467, 468, 470, 471, 472, 473, 474, 562, 570, 578, 581, 583, 589, 590, 615, 621, 622, 624, 626, 628, 629, 630, 633, 634, 639, 642, 644], "seri": [0, 12, 17, 26, 27, 64, 94, 104, 114, 115, 118, 119, 158, 245, 271, 393, 622, 623, 624, 631, 632, 637, 638, 641, 644], "quick": [0, 78, 592, 626], "ramp": 0, "up": [0, 1, 2, 5, 6, 7, 8, 21, 22, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 85, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 201, 217, 220, 239, 242, 266, 271, 324, 329, 368, 383, 403, 421, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589, 593, 615, 622, 623, 624, 625, 628, 632, 634, 635, 637, 638, 639, 641, 643, 644], "hurri": [0, 627], "last": [0, 2, 17, 18, 23, 32, 34, 35, 36, 38, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 107, 108, 109, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 183, 195, 206, 214, 217, 220, 225, 226, 236, 244, 246, 251, 264, 266, 268, 278, 282, 286, 288, 301, 302, 304, 305, 306, 308, 320, 326, 332, 337, 338, 341, 345, 352, 386, 388, 389, 594, 623, 624, 625, 626, 627, 628, 634, 637, 638, 639, 640, 641, 643, 644], "item": [0, 21, 27, 34, 38, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 96, 102, 107, 114, 214, 235, 271, 280, 306, 326, 332, 337, 353, 354, 356, 384, 406, 608, 622, 624, 625, 629, 630, 634, 637, 638, 639, 641], "navig": [0, 184, 634, 638], "previou": [0, 22, 23, 29, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 236, 265, 316, 317, 326, 332, 337, 624, 625, 626, 627, 628, 632, 639, 644], "whenev": [0, 2, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 83, 88, 101, 102, 108, 109, 124, 125, 129, 131, 132, 142, 143, 155, 163, 164, 171, 172, 173, 174, 175, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 236, 240, 271, 272, 278, 326, 332, 337, 366, 376, 378, 380, 383, 384, 386, 387, 388, 389, 391, 419, 631, 634, 641], "want": [0, 5, 6, 21, 22, 25, 26, 27, 34, 50, 52, 109, 171, 172, 175, 185, 221, 246, 326, 332, 337, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 615, 622, 623, 624, 625, 626, 627, 629, 630, 631, 637, 638, 639, 640, 641, 643, 644], "ted": [0, 10, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 100, 621, 633, 642], "s": [0, 1, 2, 3, 5, 6, 7, 11, 17, 18, 19, 21, 22, 25, 26, 27, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 60, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 108, 109, 114, 120, 121, 122, 123, 126, 130, 134, 136, 137, 138, 142, 143, 145, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 225, 226, 239, 244, 250, 263, 265, 268, 269, 270, 271, 272, 275, 277, 279, 280, 283, 285, 286, 288, 295, 298, 301, 302, 304, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 342, 344, 345, 348, 350, 351, 352, 357, 363, 364, 365, 366, 368, 371, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 402, 418, 419, 420, 567, 568, 569, 570, 571, 573, 574, 575, 576, 578, 581, 582, 583, 584, 585, 589, 594, 615, 621, 622, 623, 624, 625, 626, 627, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644], "modul": [0, 6, 7, 17, 18, 21, 22, 23, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 65, 68, 69, 72, 73, 86, 87, 88, 114, 120, 121, 122, 123, 126, 130, 138, 144, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 214, 220, 221, 225, 231, 233, 239, 241, 243, 250, 251, 255, 264, 265, 270, 271, 272, 275, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 415, 416, 418, 420, 421, 475, 559, 562, 568, 570, 571, 573, 574, 575, 576, 580, 581, 583, 589, 592, 594, 605, 606, 607, 608, 609, 610, 611, 613, 614, 621, 623, 624, 627, 629, 630, 631, 633, 635, 636, 637, 638, 639, 640, 641, 642], "optim": [0, 1, 2, 15, 27, 55, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 350, 352, 366, 367, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 410, 411, 416, 418, 420, 421, 475, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 562, 592, 615, 616, 621, 624, 625, 626, 627, 628, 630, 633, 635, 637, 638, 639, 642], "collect": [0, 1, 2, 3, 4, 5, 6, 12, 20, 22, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 60, 61, 65, 66, 67, 68, 69, 71, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 107, 120, 123, 126, 130, 138, 150, 151, 154, 155, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 218, 219, 220, 221, 222, 223, 225, 228, 229, 232, 236, 238, 242, 246, 247, 250, 252, 254, 255, 256, 257, 258, 262, 264, 265, 266, 268, 271, 272, 273, 277, 279, 280, 282, 288, 295, 303, 305, 306, 310, 312, 320, 325, 326, 327, 328, 330, 331, 332, 337, 341, 350, 353, 356, 358, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 406, 409, 411, 412, 416, 418, 419, 420, 421, 475, 555, 556, 562, 564, 565, 567, 570, 575, 579, 582, 587, 588, 589, 592, 594, 601, 608, 616, 621, 622, 625, 626, 627, 628, 629, 632, 633, 637, 638, 639, 640, 641, 642, 643, 644], "storag": [0, 2, 4, 10, 13, 27, 32, 34, 35, 36, 38, 50, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 107, 108, 109, 111, 112, 113, 114, 116, 117, 120, 123, 126, 128, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 220, 221, 229, 232, 255, 325, 326, 327, 328, 330, 331, 332, 337, 351, 365, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 403, 421, 427, 428, 429, 430, 433, 434, 438, 439, 440, 441, 583, 584, 585, 586, 592, 621, 623, 624, 625, 626, 627, 629, 632, 633, 637, 638, 640, 642], "log": [0, 20, 23, 27, 30, 188, 189, 195, 196, 295, 296, 297, 298, 306, 310, 320, 321, 324, 326, 329, 332, 333, 337, 342, 345, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 401, 408, 409, 410, 416, 418, 420, 421, 475, 562, 569, 582, 584, 592, 621, 622, 623, 624, 627, 628, 632, 633, 637, 638, 639, 642, 643], "your": [0, 1, 5, 7, 16, 22, 26, 27, 29, 30, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 52, 88, 120, 123, 126, 130, 134, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 345, 351, 368, 376, 378, 380, 383, 384, 405, 566, 593, 594, 615, 621, 623, 624, 625, 627, 628, 629, 630, 631, 633, 635, 637, 638, 641, 642, 643], "own": [0, 2, 5, 7, 16, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 55, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 393, 568, 573, 576, 577, 615, 621, 623, 624, 627, 633, 637, 638, 639, 642], "train": [0, 1, 2, 5, 6, 9, 11, 18, 20, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 59, 78, 80, 86, 87, 88, 101, 102, 120, 123, 126, 130, 135, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 229, 237, 250, 264, 269, 272, 275, 277, 286, 290, 292, 301, 312, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 403, 409, 416, 418, 419, 420, 421, 475, 562, 574, 586, 592, 594, 598, 599, 605, 615, 616, 621, 623, 627, 630, 631, 633, 640, 641, 642, 643, 644], "loop": [0, 1, 5, 6, 7, 27, 34, 42, 47, 50, 52, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 286, 301, 312, 317, 325, 327, 328, 330, 331, 350, 352, 358, 364, 368, 369, 371, 372, 373, 377, 379, 381, 382, 385, 386, 387, 388, 389, 412, 416, 567, 568, 569, 570, 573, 574, 576, 578, 581, 583, 586, 589, 616, 618, 621, 622, 623, 627, 629, 630, 631, 633, 636, 641, 642, 643], "ppo": [0, 1, 5, 7, 23, 27, 35, 36, 38, 342, 345, 351, 365, 368, 376, 420, 474, 475, 616, 621, 622, 623, 626, 628, 629, 633, 637, 642], "pendulum": [0, 1, 7, 16, 18, 21, 22, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 88, 114, 120, 123, 124, 125, 126, 127, 129, 130, 131, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 221, 224, 225, 227, 234, 240, 241, 246, 253, 255, 259, 260, 263, 265, 266, 267, 270, 271, 272, 273, 279, 280, 287, 302, 304, 339, 383, 562, 601, 621, 623, 624, 627, 628, 629, 633, 642, 643, 644], "introduct": [0, 627, 637, 638, 644], "multi": [0, 1, 4, 5, 16, 17, 26, 28, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 68, 70, 71, 72, 73, 88, 92, 93, 100, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 242, 272, 302, 304, 305, 324, 326, 332, 337, 341, 345, 376, 378, 380, 383, 384, 386, 387, 388, 389, 424, 425, 467, 592, 594, 596, 615, 621, 622, 623, 624, 625, 627, 628, 633, 639, 642, 643], "agent": [0, 16, 21, 22, 28, 67, 70, 71, 135, 141, 142, 143, 148, 149, 152, 153, 156, 157, 161, 162, 163, 164, 166, 184, 242, 262, 263, 264, 306, 351, 365, 368, 420, 592, 621, 627, 633, 639, 642], "env": [0, 1, 2, 4, 5, 6, 7, 18, 19, 20, 21, 22, 24, 25, 26, 27, 30, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 53, 60, 65, 66, 69, 72, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 114, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 287, 302, 304, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 344, 366, 376, 378, 380, 383, 384, 391, 392, 393, 405, 421, 445, 446, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 533, 534, 535, 536, 537, 538, 539, 540, 556, 557, 558, 562, 564, 565, 566, 574, 592, 594, 601, 615, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 636, 637, 638, 640, 641, 642], "pretrain": [0, 324, 621, 633, 642], "recurr": [0, 220, 302, 304, 316, 386, 621, 623, 628, 633, 641, 642], "dqn": [0, 1, 5, 7, 78, 214, 233, 288, 297, 298, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 559, 621, 626, 628, 629, 632, 633, 642], "polici": [0, 1, 3, 4, 5, 6, 7, 10, 12, 17, 21, 22, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 66, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 226, 231, 241, 244, 264, 267, 271, 283, 284, 285, 286, 287, 297, 298, 301, 302, 304, 312, 313, 314, 326, 329, 332, 337, 339, 340, 341, 342, 343, 344, 345, 348, 349, 350, 351, 352, 353, 357, 358, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 410, 418, 419, 420, 421, 422, 423, 424, 425, 475, 488, 557, 558, 562, 564, 565, 568, 569, 570, 571, 573, 574, 576, 581, 583, 589, 592, 601, 602, 608, 621, 623, 627, 629, 630, 633, 635, 640, 641, 642, 643, 644], "replai": [0, 1, 5, 10, 13, 15, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 101, 102, 103, 104, 105, 107, 109, 110, 112, 114, 115, 119, 220, 221, 231, 251, 255, 265, 271, 352, 353, 354, 356, 357, 358, 364, 369, 371, 372, 373, 383, 403, 412, 416, 418, 420, 421, 430, 431, 432, 433, 436, 440, 441, 475, 560, 562, 592, 594, 615, 616, 621, 626, 633, 639, 640, 642], "buffer": [0, 1, 3, 5, 6, 10, 13, 15, 18, 22, 23, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 114, 115, 116, 119, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 220, 221, 225, 230, 231, 239, 250, 251, 255, 265, 270, 271, 272, 275, 277, 286, 312, 325, 326, 327, 328, 330, 331, 332, 337, 344, 347, 351, 352, 353, 354, 356, 357, 358, 364, 365, 368, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 402, 403, 412, 416, 418, 420, 421, 430, 431, 432, 433, 436, 440, 441, 475, 560, 562, 567, 569, 570, 572, 575, 577, 578, 579, 583, 584, 585, 586, 592, 594, 615, 616, 621, 626, 631, 633, 639, 640, 642, 644], "export": [0, 25, 26, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 621, 633, 642], "llm": [0, 6, 52, 53, 54, 55, 86, 87, 88, 89, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 503, 582, 583, 584, 585, 586, 587, 588, 589, 590, 592, 596, 615, 621, 633, 642], "tool": [0, 3, 18, 20, 24, 87, 170, 184, 186, 187, 190, 193, 197, 200, 201, 202, 203, 594, 596, 597, 600, 625, 627, 637, 639, 641, 644], "enabl": [0, 7, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 79, 89, 95, 97, 107, 116, 150, 158, 170, 184, 218, 302, 304, 312, 324, 326, 329, 332, 333, 334, 337, 339, 341, 380, 391, 393, 410, 418, 420, 421, 574, 594, 605, 615, 624, 627, 637, 638, 639, 641], "competit": [0, 22, 142, 143, 621, 633, 638, 642], "ddpg": [0, 290, 291, 292, 293, 353, 421, 621, 623, 629, 633, 638, 642], "task": [0, 7, 19, 22, 28, 70, 71, 80, 83, 120, 123, 124, 125, 126, 130, 133, 138, 142, 143, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 175, 177, 178, 179, 180, 182, 250, 263, 272, 275, 277, 357, 364, 421, 592, 621, 622, 623, 624, 625, 627, 628, 633, 634, 637, 638, 639, 642, 644], "object": [0, 6, 17, 21, 23, 25, 26, 32, 34, 35, 36, 38, 39, 42, 44, 47, 50, 52, 53, 60, 63, 69, 74, 86, 87, 88, 89, 90, 95, 96, 97, 98, 106, 110, 112, 116, 119, 120, 123, 126, 130, 136, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 229, 232, 233, 239, 242, 246, 250, 270, 271, 272, 275, 279, 280, 283, 302, 304, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 343, 344, 345, 346, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 393, 421, 556, 557, 558, 559, 561, 562, 566, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589, 592, 621, 623, 624, 625, 626, 630, 632, 633, 635, 637, 638, 639, 641, 642, 644], "loss": [0, 6, 7, 19, 21, 27, 233, 306, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 376, 378, 380, 384, 386, 411, 415, 416, 420, 421, 473, 474, 475, 559, 562, 592, 594, 599, 608, 609, 610, 611, 613, 614, 616, 621, 626, 627, 629, 630, 631, 633, 639, 641, 642], "trainer": [0, 6, 7, 324, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 417, 418, 419, 420, 421, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 574, 582, 583, 587, 588, 589, 592, 621, 622, 633, 642], "exampl": [0, 2, 3, 5, 18, 19, 21, 23, 28, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 101, 102, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 203, 206, 207, 211, 212, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 246, 248, 249, 250, 251, 252, 253, 254, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 320, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 393, 402, 404, 405, 406, 407, 408, 409, 411, 412, 413, 414, 415, 419, 420, 421, 466, 467, 470, 471, 472, 475, 562, 570, 574, 578, 583, 585, 586, 589, 592, 621, 622, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 636, 637, 638, 639, 640, 642, 643, 644], "packag": [0, 18, 25, 26, 29, 190, 211, 592, 593, 626, 634, 644], "multicollector": [0, 2, 6, 35, 38, 592], "kei": [0, 2, 6, 7, 17, 18, 19, 22, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 86, 87, 88, 92, 101, 102, 106, 108, 109, 114, 120, 123, 126, 130, 136, 137, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 243, 246, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 286, 287, 296, 297, 298, 301, 302, 304, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 340, 341, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 409, 410, 411, 413, 414, 416, 419, 420, 556, 584, 585, 590, 592, 622, 624, 625, 626, 627, 629, 634, 635, 636, 637, 638, 639, 641, 643, 644], "legaci": [0, 5, 26, 35, 36, 38, 56, 86, 87, 176, 188, 189, 195, 196, 325, 326, 327, 328, 330, 331, 332, 337, 377, 379, 381, 382, 385, 419, 574, 576, 592], "name": [0, 5, 6, 7, 17, 18, 21, 25, 26, 32, 34, 35, 36, 38, 54, 55, 60, 71, 78, 80, 82, 85, 86, 87, 88, 89, 120, 121, 123, 124, 126, 130, 136, 138, 142, 143, 145, 148, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 209, 213, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 231, 233, 234, 235, 237, 239, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 282, 297, 302, 304, 313, 318, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 389, 390, 391, 395, 397, 398, 399, 400, 401, 402, 403, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 417, 418, 419, 574, 575, 576, 582, 587, 588, 590, 592, 608, 615, 622, 623, 624, 625, 626, 629, 630, 631, 634, 635, 637, 638, 639, 640, 644], "interfac": [0, 1, 16, 22, 55, 120, 133, 147, 305, 324, 326, 329, 332, 337, 403, 426, 575, 579, 585, 589, 592, 598, 622, 624, 626, 631, 634, 635, 639, 641], "servic": [0, 50, 186, 189, 192, 193, 195, 201, 202, 243, 324, 333, 402, 403, 404, 592, 594], "registri": [0, 129, 161, 186, 193, 201, 402, 403, 404, 592, 594], "overview": [0, 592, 624, 626, 629, 637, 638, 643], "usag": [0, 1, 12, 18, 24, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 79, 85, 91, 93, 114, 171, 189, 191, 192, 218, 221, 233, 302, 304, 324, 326, 332, 337, 351, 352, 357, 364, 365, 368, 371, 374, 376, 378, 380, 384, 402, 404, 419, 420, 570, 578, 592, 594, 622, 624, 625, 628, 629, 631, 637, 638, 641], "executor": [0, 22, 42, 44, 47, 159, 193, 592], "best": [0, 5, 24, 28, 134, 302, 304, 324, 368, 592, 637, 638, 641, 643], "practic": [0, 3, 4, 18, 21, 22, 23, 24, 27, 52, 63, 78, 271, 303, 320, 321, 592, 593, 622, 623, 624, 625, 626, 629, 634, 637, 638, 640, 644], "also": [0, 2, 5, 6, 7, 12, 17, 18, 19, 21, 22, 27, 28, 30, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 57, 59, 61, 62, 64, 68, 69, 72, 73, 74, 78, 80, 81, 83, 84, 85, 86, 87, 88, 95, 96, 97, 102, 108, 109, 114, 116, 120, 123, 126, 130, 137, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 211, 212, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 231, 233, 234, 235, 237, 239, 240, 241, 243, 246, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 282, 288, 305, 316, 325, 326, 327, 328, 330, 331, 332, 337, 341, 342, 346, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 363, 364, 368, 371, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 391, 393, 409, 592, 594, 622, 623, 624, 625, 626, 627, 628, 629, 630, 634, 636, 637, 638, 639, 641, 643, 644], "_util": [0, 18, 150, 592, 626, 632], "implement_for": [0, 18, 592], "set_auto_unwrap_transformed_env": [0, 31, 272, 592], "auto_unwrap_transformed_env": [0, 405, 592], "configur": [0, 2, 4, 27, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 55, 123, 171, 190, 241, 289, 294, 311, 324, 326, 333, 351, 366, 368, 376, 378, 380, 384, 402, 403, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 570, 573, 574, 576, 581, 592, 601, 616, 622, 623, 624, 629, 635, 637, 638, 639], "system": [0, 10, 16, 23, 24, 87, 93, 170, 171, 172, 175, 177, 191, 193, 195, 196, 339, 380, 384, 426, 592, 594, 615, 616, 624, 635, 637, 638, 639], "simpl": [0, 19, 21, 28, 40, 41, 64, 74, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 290, 324, 326, 332, 337, 341, 345, 354, 356, 366, 368, 370, 376, 378, 380, 383, 384, 386, 409, 592, 594, 615, 622, 623, 624, 627, 628, 629, 635, 637, 638, 641, 644], "categori": [0, 60, 80, 592], "group": [0, 6, 18, 19, 22, 54, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 86, 87, 88, 120, 123, 126, 130, 138, 141, 142, 143, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 166, 170, 171, 172, 175, 176, 178, 179, 180, 185, 242, 262, 324, 325, 327, 328, 330, 331, 332, 333, 335, 336, 377, 379, 381, 382, 385, 575, 576, 582, 583, 587, 588, 592, 594, 623, 628, 630, 638, 641], "complex": [0, 6, 12, 22, 37, 39, 40, 41, 46, 49, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384, 402, 589, 592, 594, 615, 622, 623, 627, 628], "parallel": [0, 1, 2, 3, 4, 5, 16, 18, 19, 21, 27, 35, 36, 38, 54, 55, 120, 123, 126, 129, 130, 131, 138, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 272, 278, 302, 304, 324, 333, 334, 349, 442, 563, 564, 565, 566, 589, 592, 615, 623, 624, 637, 638, 643], "avail": [0, 2, 3, 5, 16, 20, 23, 25, 32, 35, 36, 38, 50, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 102, 107, 108, 109, 121, 122, 124, 125, 134, 136, 137, 142, 143, 148, 149, 150, 152, 153, 155, 161, 162, 163, 164, 182, 186, 192, 194, 195, 201, 214, 217, 220, 239, 241, 333, 342, 345, 366, 376, 378, 380, 384, 393, 564, 565, 568, 569, 570, 571, 573, 574, 576, 577, 578, 579, 581, 583, 589, 592, 594, 615, 622, 623, 624, 625, 626, 627, 628, 635, 637, 638, 639, 641, 644], "complet": [0, 1, 5, 6, 26, 28, 35, 36, 38, 46, 52, 53, 102, 107, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 184, 221, 263, 324, 326, 332, 337, 383, 420, 572, 575, 582, 589, 592, 593, 594, 615, 622, 624, 627, 634, 635, 636], "run": [0, 1, 2, 6, 16, 18, 19, 22, 23, 24, 25, 26, 27, 29, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 66, 78, 80, 88, 102, 108, 109, 120, 121, 122, 123, 124, 125, 126, 129, 130, 136, 137, 138, 144, 145, 146, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 225, 239, 245, 246, 262, 270, 271, 272, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 317, 324, 326, 332, 337, 338, 341, 345, 346, 347, 348, 352, 358, 371, 376, 378, 380, 383, 384, 393, 401, 410, 421, 564, 565, 566, 574, 592, 593, 615, 616, 622, 623, 624, 625, 626, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 639, 640, 641, 643], "experi": [0, 1, 16, 17, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 395, 396, 397, 398, 399, 400, 401, 402, 421, 592, 593, 619, 623, 624, 626, 630, 631, 637, 638, 641], "store": [0, 2, 6, 12, 17, 27, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 60, 63, 65, 66, 68, 69, 72, 73, 80, 81, 83, 84, 86, 87, 88, 90, 93, 95, 96, 97, 98, 101, 102, 108, 114, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 267, 278, 279, 280, 286, 312, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 401, 420, 421, 475, 567, 568, 570, 574, 575, 576, 578, 592, 622, 624, 625, 628, 630, 632, 637, 638, 640, 644], "implement": [0, 1, 6, 9, 10, 12, 17, 21, 22, 28, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 70, 71, 74, 75, 76, 77, 88, 99, 101, 110, 111, 120, 123, 126, 130, 138, 144, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 237, 241, 244, 252, 253, 259, 263, 269, 271, 272, 273, 279, 280, 282, 302, 303, 304, 319, 320, 321, 324, 326, 332, 334, 337, 349, 350, 352, 355, 356, 357, 363, 364, 366, 367, 368, 370, 371, 372, 376, 378, 380, 383, 384, 391, 406, 420, 421, 557, 587, 588, 589, 592, 594, 615, 616, 622, 623, 624, 625, 626, 637, 638, 639, 643], "detail": [0, 6, 21, 24, 25, 26, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 268, 272, 298, 307, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 351, 359, 365, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 568, 592, 593, 594, 623, 626, 630, 636, 641], "class": [0, 1, 2, 4, 5, 6, 10, 14, 16, 18, 19, 20, 21, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 126, 127, 128, 129, 130, 131, 132, 137, 138, 141, 144, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 211, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 393, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 592, 594, 595, 601, 610, 615, 617, 619, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 634, 637, 638, 641, 644], "creat": [0, 1, 4, 6, 10, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 29, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 98, 114, 120, 123, 126, 127, 130, 134, 138, 150, 151, 152, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 218, 221, 226, 239, 243, 250, 270, 271, 272, 275, 278, 279, 280, 288, 290, 291, 292, 293, 294, 295, 299, 300, 302, 303, 304, 305, 308, 309, 315, 316, 317, 320, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 344, 345, 352, 354, 359, 368, 369, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 402, 403, 404, 412, 420, 421, 475, 556, 557, 558, 562, 564, 565, 567, 568, 570, 571, 572, 573, 574, 575, 576, 577, 578, 581, 583, 589, 592, 594, 601, 608, 615, 616, 622, 623, 624, 625, 626, 628, 631, 634, 635, 637, 638, 639, 640, 641, 643, 644], "custom": [0, 6, 10, 16, 21, 22, 24, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 81, 86, 87, 88, 89, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 275, 303, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 359, 368, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 404, 420, 475, 566, 571, 573, 574, 576, 581, 583, 587, 588, 589, 592, 604, 616, 618, 622, 623, 624, 625, 628, 629, 631, 634, 637, 638], "futur": [0, 23, 34, 41, 54, 56, 86, 87, 88, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 250, 270, 272, 277, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 420, 421, 575, 592, 593, 594, 615], "extens": [0, 65, 68, 72, 73, 109, 592, 641], "thing": [0, 5, 19, 21, 22, 26, 27, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 271, 325, 327, 328, 330, 331, 358, 371, 377, 379, 381, 382, 385, 593, 624, 625, 626, 627, 628, 629, 630, 631, 637, 638, 641, 644], "consid": [0, 2, 18, 21, 27, 34, 35, 36, 37, 38, 39, 42, 46, 47, 49, 50, 52, 54, 60, 65, 68, 71, 72, 73, 88, 95, 97, 108, 109, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 231, 279, 295, 306, 319, 326, 332, 337, 350, 352, 364, 369, 371, 372, 373, 376, 378, 380, 383, 384, 386, 388, 389, 593, 594, 615, 622, 627, 628, 629, 639, 641], "when": [0, 1, 2, 3, 6, 7, 8, 17, 18, 20, 21, 22, 24, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 96, 97, 98, 100, 101, 102, 103, 107, 108, 109, 110, 112, 116, 120, 121, 122, 123, 126, 127, 129, 130, 131, 137, 138, 141, 142, 143, 145, 147, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 212, 215, 217, 220, 221, 225, 226, 229, 231, 232, 241, 242, 245, 246, 250, 251, 258, 265, 267, 270, 271, 272, 275, 277, 278, 279, 280, 282, 295, 302, 304, 305, 306, 317, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 342, 344, 345, 347, 350, 351, 352, 354, 358, 359, 364, 365, 366, 368, 369, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 393, 395, 398, 400, 401, 402, 412, 418, 419, 566, 567, 568, 570, 573, 574, 576, 577, 578, 581, 582, 583, 589, 593, 594, 615, 622, 623, 624, 625, 626, 628, 630, 631, 637, 638, 639, 640, 641, 643, 644], "debug": [0, 6, 25, 27, 78, 79, 80, 81, 82, 83, 84, 85, 191, 267, 326, 332, 337, 569, 593, 644], "work": [0, 4, 6, 18, 20, 21, 22, 23, 27, 46, 49, 54, 55, 60, 68, 71, 78, 79, 80, 81, 82, 83, 84, 85, 88, 95, 101, 102, 106, 108, 109, 112, 119, 120, 123, 126, 129, 130, 131, 134, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 212, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 280, 282, 288, 298, 305, 314, 324, 326, 332, 337, 348, 351, 365, 368, 376, 378, 380, 383, 384, 402, 403, 416, 575, 589, 592, 593, 594, 601, 622, 623, 624, 625, 627, 630, 635, 636, 637, 638, 639, 640, 641, 643, 644], "habitat": [0, 18, 132, 449, 593, 640], "lab": [0, 17, 124, 125, 132, 135, 593], "mujoco": [0, 25, 27, 155, 593, 622, 624, 625], "error": [0, 2, 22, 26, 29, 32, 34, 35, 36, 38, 52, 57, 59, 61, 62, 64, 70, 86, 87, 88, 95, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 165, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 251, 270, 282, 324, 325, 326, 327, 328, 330, 331, 332, 337, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 593, 594, 615, 622, 624, 637, 638, 644], "solut": [0, 12, 18, 25, 26, 28, 50, 108, 593, 626, 643], "resourc": [0, 3, 33, 42, 43, 44, 45, 47, 48, 50, 132, 171, 172, 175, 184, 185, 192, 194, 195, 324, 329, 337, 402, 403, 571, 573, 574, 576, 581, 583, 589, 593, 594, 615, 622, 624, 626, 637, 638], "issu": [0, 6, 20, 22, 23, 24, 27, 66, 78, 81, 93, 95, 97, 101, 102, 108, 116, 120, 123, 126, 129, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 194, 195, 212, 221, 251, 266, 297, 298, 313, 314, 324, 340, 342, 344, 345, 351, 368, 420, 593, 594, 635, 643], "customis": [0, 593, 623, 631], "video": [0, 16, 23, 28, 86, 393, 395, 398, 400, 401, 410, 566, 593, 632, 637, 638], "render": [0, 20, 27, 137, 163, 391, 393, 410, 593, 622, 623, 624, 626, 627, 631], "index": [0, 21, 26, 27, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 94, 95, 96, 97, 101, 102, 104, 106, 108, 112, 114, 115, 116, 118, 119, 120, 123, 126, 130, 138, 142, 143, 148, 149, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 195, 212, 216, 221, 225, 231, 272, 306, 324, 325, 327, 328, 330, 331, 341, 377, 379, 381, 382, 385, 568, 569, 570, 571, 573, 574, 575, 576, 577, 578, 579, 581, 583, 589, 627, 634, 636, 637, 638, 641, 643], "search": [0, 60, 71, 147, 186, 187, 203, 213, 326, 332, 337, 623], "page": [0, 26, 184, 401, 629, 634], "bridg": [1, 421], "between": [1, 2, 6, 19, 21, 23, 24, 32, 34, 35, 36, 38, 39, 46, 50, 52, 53, 54, 65, 66, 68, 69, 72, 73, 83, 86, 87, 88, 90, 97, 101, 102, 104, 107, 108, 109, 116, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 231, 245, 256, 267, 270, 272, 279, 280, 288, 296, 298, 302, 304, 305, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 342, 345, 349, 351, 352, 353, 356, 357, 358, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 410, 416, 421, 570, 574, 590, 596, 615, 622, 623, 625, 626, 630, 634, 635, 637, 638, 639, 641, 644], "manag": [1, 2, 6, 10, 11, 22, 27, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 190, 192, 201, 302, 304, 324, 337, 368, 386, 387, 388, 389, 403, 404, 405, 410, 421, 581, 594, 596, 615, 625, 626, 629, 634, 643], "gather": [1, 2, 17, 18, 42, 47, 50, 95, 97, 102, 108, 116, 195, 244, 251, 310, 326, 332, 337, 366, 376, 378, 380, 384, 420, 421, 475, 556, 593, 623, 624, 625, 626, 630, 637, 638, 639, 641, 643, 644], "thei": [1, 2, 3, 6, 7, 17, 20, 21, 22, 23, 27, 28, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 120, 123, 126, 129, 130, 131, 138, 141, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 220, 235, 241, 250, 259, 267, 271, 272, 277, 304, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 412, 416, 568, 570, 573, 574, 576, 578, 581, 583, 589, 602, 615, 622, 623, 624, 625, 626, 629, 636, 637, 638, 639, 640, 641, 643, 644], "handl": [1, 5, 6, 7, 16, 17, 18, 20, 22, 35, 36, 37, 38, 39, 40, 41, 42, 46, 47, 49, 50, 54, 55, 63, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 278, 279, 280, 304, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 403, 409, 416, 421, 564, 565, 567, 568, 569, 571, 572, 573, 574, 575, 576, 580, 581, 582, 583, 589, 594, 596, 615, 622, 623, 624, 625, 627, 629, 634, 638, 641], "reset": [1, 2, 7, 16, 17, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 109, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 216, 217, 218, 221, 233, 236, 240, 245, 250, 258, 263, 264, 265, 266, 267, 270, 271, 272, 275, 278, 279, 282, 287, 302, 304, 312, 326, 332, 337, 341, 366, 376, 378, 380, 383, 384, 392, 402, 403, 594, 615, 622, 623, 624, 625, 626, 627, 630, 634, 636, 637, 638, 643], "execut": [1, 2, 3, 5, 17, 18, 20, 21, 22, 25, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 95, 96, 98, 108, 109, 120, 121, 122, 123, 126, 127, 130, 131, 132, 134, 136, 137, 138, 144, 145, 150, 151, 154, 155, 158, 159, 160, 161, 170, 171, 172, 175, 176, 178, 179, 180, 186, 190, 192, 193, 197, 201, 215, 226, 227, 244, 267, 272, 301, 302, 304, 324, 325, 327, 328, 329, 330, 331, 334, 341, 346, 347, 366, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 556, 566, 594, 597, 615, 621, 623, 624, 625, 626, 627, 628, 629, 630, 631, 637, 638, 641, 642, 643, 644], "aggreg": [1, 2, 22, 78, 102, 114, 152, 153, 177, 213, 242, 280, 288, 290, 291, 347, 380, 403, 594, 638], "easi": [1, 7, 16, 17, 18, 21, 24, 30, 78, 82, 120, 123, 124, 125, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 301, 312, 601, 622, 623, 624, 635, 638, 640, 641, 643, 644], "qualiti": [1, 30, 177, 285, 368], "sever": [1, 2, 5, 6, 7, 12, 20, 27, 55, 61, 80, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 222, 224, 225, 242, 272, 325, 326, 327, 328, 330, 331, 332, 337, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 468, 594, 622, 624, 626, 631, 632, 641, 644], "differ": [1, 2, 5, 6, 7, 15, 16, 17, 19, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 83, 86, 87, 88, 101, 106, 120, 121, 122, 123, 126, 127, 130, 136, 137, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 221, 226, 230, 231, 242, 246, 253, 262, 270, 272, 274, 282, 305, 317, 324, 325, 326, 327, 328, 330, 331, 332, 337, 345, 364, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 402, 410, 416, 419, 564, 565, 570, 574, 576, 579, 583, 587, 588, 594, 598, 615, 616, 622, 623, 624, 626, 627, 629, 631, 635, 636, 637, 638, 639, 640, 641, 643, 644], "scenario": [1, 4, 6, 40, 46, 49, 142, 143, 150, 163, 164, 226, 270, 380, 391, 615, 622, 628, 637, 638, 639], "singl": [1, 2, 3, 4, 7, 16, 17, 18, 19, 20, 21, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 96, 109, 114, 120, 123, 126, 129, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 214, 221, 222, 242, 250, 255, 265, 270, 272, 277, 288, 302, 304, 305, 314, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 347, 350, 351, 352, 354, 356, 358, 359, 364, 365, 368, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 566, 567, 568, 570, 572, 573, 574, 575, 576, 581, 583, 589, 592, 594, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 634, 636, 637, 638, 639, 640, 641, 643], "worker": [1, 2, 4, 5, 6, 7, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 65, 68, 69, 72, 73, 74, 80, 85, 86, 87, 88, 127, 145, 150, 158, 173, 174, 176, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 271, 279, 280, 324, 325, 327, 328, 330, 331, 334, 335, 336, 377, 379, 381, 382, 383, 385, 402, 403, 404, 416, 564, 565, 566, 567, 568, 569, 570, 571, 573, 574, 575, 576, 577, 578, 579, 581, 582, 583, 585, 586, 587, 588, 589, 592, 622, 623, 624, 643, 644], "across": [1, 2, 3, 16, 19, 27, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 87, 102, 108, 109, 121, 122, 124, 125, 129, 131, 132, 134, 136, 137, 145, 146, 150, 155, 160, 171, 172, 175, 185, 194, 195, 270, 279, 280, 302, 304, 312, 324, 326, 366, 368, 376, 378, 380, 383, 384, 403, 404, 419, 434, 568, 573, 576, 581, 594, 598, 615, 622, 627, 631, 637, 638, 639], "multipl": [1, 2, 3, 6, 7, 17, 18, 21, 22, 24, 27, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 62, 68, 69, 72, 73, 87, 90, 97, 104, 116, 120, 121, 122, 136, 137, 150, 158, 160, 171, 172, 175, 177, 178, 185, 192, 194, 195, 222, 224, 231, 240, 244, 245, 255, 258, 262, 263, 270, 279, 297, 304, 313, 324, 326, 332, 337, 340, 342, 344, 345, 348, 351, 358, 365, 368, 403, 420, 434, 566, 567, 570, 571, 572, 573, 574, 575, 576, 581, 583, 589, 592, 594, 596, 622, 623, 624, 627, 629, 630, 635, 637, 638, 639, 641, 643], "distribut": [1, 6, 10, 15, 21, 22, 23, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 123, 152, 153, 191, 241, 246, 280, 286, 295, 296, 297, 298, 299, 303, 306, 307, 310, 311, 315, 316, 317, 319, 320, 321, 324, 326, 329, 332, 335, 336, 337, 342, 345, 346, 349, 350, 351, 352, 357, 358, 359, 364, 365, 368, 369, 370, 371, 372, 373, 380, 402, 403, 404, 434, 567, 568, 569, 572, 573, 574, 575, 576, 577, 582, 583, 587, 588, 592, 601, 615, 623, 624, 626, 628, 630, 637, 638, 639, 643, 644], "For": [1, 2, 5, 6, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69, 72, 73, 74, 75, 76, 77, 79, 83, 85, 86, 87, 88, 89, 95, 97, 102, 108, 116, 120, 123, 126, 129, 130, 131, 135, 137, 138, 150, 151, 152, 153, 154, 158, 159, 160, 161, 163, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 229, 232, 236, 246, 264, 271, 272, 278, 283, 285, 298, 302, 303, 304, 306, 313, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 357, 359, 364, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 404, 410, 568, 570, 573, 574, 576, 577, 578, 581, 582, 583, 584, 587, 589, 594, 615, 622, 623, 624, 625, 627, 628, 630, 631, 634, 637, 638, 639, 640, 641, 644], "node": [1, 3, 7, 15, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 60, 71, 85, 86, 87, 138, 176, 179, 270, 324, 325, 327, 328, 330, 331, 335, 336, 377, 379, 381, 382, 385, 582, 583, 589, 592, 615, 630, 643], "rai": [1, 3, 6, 10, 32, 34, 35, 36, 38, 39, 50, 52, 53, 54, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 171, 172, 175, 185, 189, 192, 193, 194, 195, 243, 324, 329, 334, 337, 402, 403, 404, 574, 575, 576, 582, 587, 588, 589, 615], "rpc": [1, 3, 6, 32, 34, 35, 36, 38, 47, 49, 51, 52, 53, 67, 324, 572, 573, 582, 585, 587, 588], "backend": [1, 3, 6, 7, 8, 10, 16, 17, 18, 20, 22, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 175, 178, 179, 180, 192, 193, 211, 282, 317, 326, 332, 333, 334, 337, 403, 404, 448, 452, 568, 574, 575, 576, 581, 587, 588, 592, 598, 615, 622, 624, 625, 626, 627, 630, 631, 635, 639], "distributedcollector": [1, 3, 43], "rpccollector": [1, 3, 48], "unifi": [1, 16, 324, 337, 580, 594, 598, 635, 644], "paramet": [1, 2, 5, 6, 7, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 96, 97, 98, 101, 102, 103, 104, 106, 107, 110, 112, 114, 116, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 204, 205, 206, 210, 211, 212, 213, 214, 215, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 395, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 463, 473, 475, 555, 556, 557, 558, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 608, 615, 622, 625, 626, 628, 632, 637, 638, 639, 640, 643], "choos": [1, 2, 3, 6, 22, 30, 63, 120, 123, 141, 302, 304, 368, 622, 623, 624, 626, 637, 638, 641, 643], "synchron": [1, 3, 5, 22, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 86, 87, 145, 176, 190, 208, 324, 325, 327, 328, 330, 331, 337, 377, 379, 381, 382, 385, 402, 423, 425, 564, 565, 568, 569, 570, 571, 573, 574, 575, 576, 578, 579, 581, 582, 583, 589, 592, 594, 623, 624, 637], "asynchron": [1, 2, 3, 22, 28, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 349, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 416, 418, 422, 424, 564, 572, 622, 623, 624], "import": [1, 5, 6, 7, 10, 16, 18, 19, 20, 21, 22, 23, 25, 29, 30, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 101, 102, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 140, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 206, 211, 212, 213, 214, 215, 217, 218, 220, 221, 224, 226, 227, 233, 234, 239, 240, 241, 242, 246, 248, 250, 252, 253, 254, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 270, 271, 273, 277, 279, 280, 282, 283, 284, 285, 287, 290, 291, 292, 293, 296, 297, 298, 300, 301, 302, 303, 304, 305, 307, 312, 313, 314, 320, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 393, 408, 410, 420, 421, 562, 589, 594, 601, 608, 615, 616, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 636, 637, 638, 639, 640, 641, 643, 644], "all": [1, 2, 3, 5, 6, 7, 17, 18, 19, 21, 22, 23, 27, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 120, 123, 124, 125, 126, 127, 129, 130, 131, 132, 137, 138, 142, 143, 144, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 166, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 206, 210, 212, 214, 220, 221, 224, 225, 229, 230, 232, 235, 241, 245, 246, 250, 258, 260, 262, 265, 266, 271, 272, 275, 277, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 341, 344, 345, 347, 348, 349, 350, 351, 352, 361, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 402, 403, 404, 411, 416, 420, 426, 475, 555, 564, 565, 566, 567, 568, 569, 570, 573, 574, 575, 576, 578, 581, 582, 583, 585, 587, 589, 593, 610, 615, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 636, 637, 638, 639, 641, 643, 644], "befor": [1, 2, 4, 5, 6, 17, 21, 22, 23, 25, 26, 29, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 59, 61, 82, 88, 107, 109, 114, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 278, 279, 280, 286, 302, 304, 305, 324, 326, 332, 337, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 387, 388, 389, 412, 568, 570, 573, 574, 575, 576, 579, 581, 582, 583, 587, 589, 594, 615, 622, 624, 625, 626, 630, 631, 637, 638, 639, 641, 644], "deliv": [1, 2, 5, 18, 34, 35, 36, 38, 83, 185, 622, 623, 627, 630, 643], "batch": [1, 4, 5, 6, 7, 9, 16, 18, 19, 20, 32, 34, 35, 36, 38, 39, 42, 44, 47, 50, 52, 53, 55, 56, 60, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 98, 102, 103, 107, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 144, 145, 147, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 218, 221, 225, 227, 236, 244, 246, 248, 251, 255, 262, 265, 267, 271, 272, 274, 278, 279, 280, 295, 302, 304, 306, 310, 312, 319, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 341, 344, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 406, 409, 412, 413, 414, 416, 418, 419, 420, 421, 442, 475, 564, 565, 566, 594, 596, 608, 623, 624, 625, 626, 627, 630, 632, 634, 636, 637, 638, 640, 643, 644], "create_env_fn": [1, 5, 6, 7, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 127, 150, 158, 422, 423, 424, 425, 442, 475, 570, 622, 643], "make_env": [1, 4, 5, 16, 20, 22, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 150, 158, 164, 270, 279, 280, 391, 557, 558, 594, 622, 623, 643, 644], "4": [1, 4, 5, 6, 7, 10, 16, 17, 22, 26, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 60, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 101, 102, 108, 109, 116, 120, 121, 122, 123, 124, 125, 126, 130, 136, 137, 138, 139, 140, 141, 144, 146, 150, 151, 154, 156, 157, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 194, 214, 215, 217, 218, 221, 226, 227, 233, 255, 262, 263, 264, 270, 279, 280, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 297, 298, 299, 300, 301, 303, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 320, 322, 325, 327, 328, 330, 331, 338, 340, 341, 342, 344, 347, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 391, 392, 402, 420, 421, 475, 483, 493, 499, 568, 570, 573, 574, 576, 581, 583, 589, 594, 615, 621, 622, 623, 624, 625, 626, 628, 630, 631, 637, 638, 639, 640, 641, 642, 643, 644], "my_polici": [1, 5, 35, 36, 38], "frames_per_batch": [1, 2, 4, 5, 6, 7, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 66, 218, 221, 255, 302, 304, 421, 422, 423, 424, 425, 555, 570, 622, 623, 624, 625, 626, 630, 632, 637, 638, 641, 643], "200": [1, 7, 16, 34, 35, 38, 50, 66, 78, 88, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 255, 290, 291, 299, 315, 316, 326, 332, 337, 376, 378, 380, 383, 384, 391, 393, 622, 625, 626, 630, 632, 641], "total_fram": [1, 4, 5, 6, 7, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 66, 218, 221, 255, 416, 420, 421, 422, 423, 424, 425, 475, 555, 562, 570, 616, 622, 623, 624, 625, 626, 630, 632, 637, 638, 641, 643], "10000": [1, 6, 32, 35, 36, 38, 50, 150, 416, 420, 421, 475, 622, 624, 625], "true": [1, 2, 5, 6, 7, 9, 18, 21, 22, 23, 27, 30, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 95, 96, 97, 98, 101, 102, 104, 106, 107, 108, 109, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 213, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 231, 234, 236, 239, 240, 241, 242, 244, 245, 246, 250, 251, 253, 254, 257, 258, 259, 262, 263, 265, 268, 269, 270, 271, 272, 273, 274, 275, 277, 279, 280, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 297, 298, 300, 302, 304, 305, 306, 312, 313, 314, 317, 319, 320, 321, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 340, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 393, 401, 402, 405, 408, 409, 410, 412, 416, 418, 420, 421, 422, 423, 424, 425, 435, 436, 437, 444, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 466, 467, 470, 474, 475, 477, 505, 507, 524, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 566, 567, 568, 570, 571, 573, 574, 576, 578, 580, 581, 583, 584, 585, 587, 589, 594, 615, 622, 623, 624, 625, 626, 627, 628, 631, 632, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "deliveri": [1, 5, 17, 35, 36, 38], "serv": [1, 2, 5, 16, 22, 35, 36, 38, 42, 47, 50, 86, 87, 132, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 426, 594, 641, 643, 644], "fals": [1, 2, 3, 5, 18, 22, 30, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 106, 107, 108, 109, 110, 115, 116, 118, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 208, 212, 213, 214, 215, 217, 218, 221, 222, 225, 227, 229, 232, 233, 234, 236, 239, 240, 241, 243, 244, 245, 246, 248, 250, 251, 252, 253, 255, 257, 258, 259, 262, 263, 265, 268, 269, 270, 271, 272, 273, 274, 275, 277, 279, 280, 282, 283, 284, 285, 286, 287, 288, 290, 296, 297, 298, 301, 302, 303, 304, 305, 306, 312, 313, 314, 317, 320, 321, 322, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 337, 340, 341, 342, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 393, 401, 405, 408, 409, 410, 412, 413, 416, 420, 421, 422, 423, 424, 425, 427, 428, 429, 430, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 479, 480, 505, 508, 518, 529, 541, 542, 543, 544, 545, 551, 552, 553, 566, 568, 570, 578, 585, 587, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "async": [1, 7, 16, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 66, 120, 154, 159, 190, 278, 324, 333, 336, 337, 418, 420, 475], "faster": [1, 3, 23, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 84, 85, 101, 145, 306, 386, 387, 388, 389, 625, 626, 637, 638], "mai": [1, 2, 3, 5, 6, 17, 18, 19, 21, 22, 23, 24, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 54, 56, 60, 70, 71, 74, 79, 85, 86, 87, 88, 93, 96, 101, 102, 108, 120, 123, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 246, 259, 270, 272, 274, 279, 280, 302, 304, 305, 317, 325, 326, 327, 328, 330, 331, 332, 337, 339, 345, 351, 358, 365, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 420, 421, 568, 570, 573, 574, 576, 578, 579, 581, 583, 589, 594, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 637, 638, 639, 640, 641, 644], "lag": [1, 2, 622, 623, 624], "vs": [1, 6, 280, 282, 326, 332, 337, 402], "algorithm": [1, 5, 7, 10, 12, 18, 20, 27, 28, 33, 35, 36, 38, 42, 43, 44, 45, 47, 48, 144, 214, 262, 349, 368, 369, 371, 418, 420, 421, 608, 609, 612, 613, 614, 616, 622, 623, 624, 625, 626, 628, 629, 630, 631, 637, 638, 640, 641, 643], "a2c": [1, 5, 349], "where": [1, 2, 4, 6, 7, 11, 17, 18, 19, 20, 21, 22, 23, 26, 27, 32, 34, 35, 36, 37, 38, 39, 40, 42, 44, 46, 47, 49, 50, 52, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 95, 97, 102, 108, 109, 114, 116, 117, 120, 123, 126, 130, 138, 141, 144, 147, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 212, 213, 214, 215, 218, 221, 226, 233, 241, 250, 255, 258, 263, 264, 265, 266, 267, 271, 272, 274, 277, 278, 286, 301, 302, 304, 306, 312, 317, 325, 326, 327, 328, 330, 331, 332, 337, 339, 342, 344, 345, 349, 350, 351, 352, 357, 358, 359, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 395, 401, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 421, 583, 584, 616, 622, 623, 624, 626, 627, 634, 636, 637, 638, 639, 641, 644], "must": [1, 4, 6, 18, 21, 22, 26, 30, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 95, 96, 97, 98, 102, 108, 109, 110, 111, 112, 114, 116, 120, 121, 123, 126, 127, 130, 136, 138, 148, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 163, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 214, 217, 218, 221, 224, 226, 227, 233, 237, 239, 241, 243, 244, 246, 248, 259, 262, 264, 265, 266, 269, 270, 272, 273, 274, 279, 286, 288, 297, 298, 302, 304, 305, 306, 313, 314, 322, 324, 326, 329, 332, 337, 340, 341, 342, 344, 345, 348, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 395, 401, 402, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 421, 582, 583, 589, 590, 594, 622, 623, 624, 625, 628, 634, 636, 639, 641], "match": [1, 10, 19, 21, 22, 25, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 112, 120, 123, 124, 125, 126, 127, 129, 130, 131, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 238, 240, 241, 242, 243, 244, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 288, 295, 297, 302, 304, 305, 313, 319, 322, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 344, 345, 348, 350, 351, 352, 358, 365, 367, 368, 369, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 412, 419, 577, 622, 624, 626, 636, 638, 639, 641, 644], "current": [1, 4, 18, 22, 31, 32, 34, 35, 36, 37, 38, 39, 46, 49, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 99, 102, 109, 120, 123, 126, 130, 132, 138, 145, 148, 149, 150, 151, 154, 158, 159, 160, 167, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 217, 218, 221, 239, 251, 264, 265, 266, 270, 271, 272, 280, 299, 312, 316, 317, 320, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 341, 349, 351, 352, 359, 365, 368, 370, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 396, 402, 403, 404, 568, 570, 571, 573, 574, 576, 577, 578, 581, 583, 586, 587, 588, 589, 615, 622, 623, 624, 625, 629, 637, 638, 639, 641, 644], "off": [1, 2, 5, 10, 12, 23, 35, 36, 38, 297, 303, 321, 371, 391, 410, 418, 421, 557, 622, 623, 624, 628, 629, 637, 638, 640, 643, 644], "sac": [1, 5, 7, 35, 36, 38, 358, 369, 371, 421, 616], "slight": [1, 150, 158, 623], "accept": [1, 2, 6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 68, 75, 80, 81, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 216, 221, 225, 236, 239, 250, 258, 262, 265, 270, 271, 272, 273, 274, 275, 277, 305, 325, 326, 327, 328, 330, 331, 332, 337, 344, 345, 346, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 615, 624, 627, 631, 641, 643, 644], "flexibl": [1, 6, 10, 16, 22, 28, 145, 170, 374, 594, 615, 622, 626, 635, 641, 644], "devic": [1, 2, 3, 6, 12, 17, 18, 19, 21, 22, 26, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 108, 109, 116, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 209, 212, 214, 218, 225, 229, 230, 232, 233, 234, 239, 241, 242, 243, 248, 249, 250, 252, 253, 255, 259, 262, 263, 265, 268, 271, 272, 273, 275, 277, 279, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 308, 309, 311, 312, 313, 314, 315, 316, 320, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 340, 341, 342, 344, 345, 347, 349, 350, 351, 352, 353, 354, 356, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 412, 419, 422, 423, 424, 425, 427, 429, 441, 442, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 466, 467, 474, 492, 511, 535, 536, 537, 560, 570, 581, 582, 589, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 636, 637, 638, 639, 640, 641, 643], "control": [1, 2, 7, 13, 17, 18, 22, 24, 27, 34, 56, 60, 68, 69, 71, 72, 73, 101, 102, 108, 120, 123, 124, 125, 126, 130, 137, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 194, 195, 196, 208, 212, 231, 290, 291, 292, 293, 302, 304, 312, 316, 324, 326, 332, 337, 344, 345, 346, 349, 351, 352, 365, 366, 368, 376, 378, 380, 384, 386, 391, 405, 421, 594, 615, 622, 623, 624, 625, 626, 627, 628, 629, 637, 638, 639, 641, 643], "weight": [1, 2, 23, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 65, 69, 86, 87, 88, 101, 102, 106, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 239, 242, 250, 265, 270, 271, 272, 275, 277, 302, 304, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 349, 350, 351, 352, 358, 361, 368, 371, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 419, 421, 504, 561, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 592, 622, 623, 624, 626, 636, 639, 641, 643], "keep": [1, 2, 7, 20, 21, 22, 23, 26, 27, 35, 65, 68, 69, 72, 73, 86, 87, 88, 107, 114, 123, 150, 158, 176, 189, 191, 195, 212, 246, 250, 277, 279, 280, 312, 325, 327, 328, 330, 331, 341, 351, 368, 377, 379, 380, 381, 382, 383, 385, 393, 408, 416, 622, 623, 624, 625, 630, 631, 632, 638, 639, 641, 644], "infer": [1, 2, 6, 21, 34, 35, 36, 37, 38, 39, 41, 42, 46, 47, 49, 50, 52, 53, 54, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 194, 195, 196, 221, 279, 306, 324, 334, 337, 342, 345, 356, 380, 384, 391, 403, 583, 589, 594, 598, 622, 624, 626, 630, 632, 635, 641, 643], "date": [1, 37, 39, 123, 220, 396], "integr": [1, 6, 7, 16, 54, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 293, 302, 304, 324, 326, 332, 337, 344, 376, 378, 380, 383, 384, 627, 628, 630, 634, 637, 638, 639, 640], "seamless": [1, 305, 324, 594, 635], "strategi": [1, 2, 5, 6, 7, 10, 12, 22, 34, 83, 86, 87, 106, 141, 176, 188, 214, 301, 310, 324, 325, 327, 328, 330, 331, 337, 377, 379, 380, 381, 382, 385, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 589, 592, 594, 601, 615, 622, 623, 626, 628, 637, 638, 641, 643], "organ": [1, 2, 7, 16, 634, 639, 641], "gymenv": [1, 5, 6, 16, 18, 20, 21, 22, 24, 30, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 88, 114, 120, 123, 126, 127, 130, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 217, 218, 221, 224, 225, 226, 227, 233, 239, 240, 241, 246, 248, 253, 254, 255, 258, 260, 264, 265, 266, 267, 270, 271, 272, 273, 279, 280, 287, 302, 304, 339, 341, 383, 391, 393, 448, 562, 570, 601, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 640, 641, 643, 644], "parallelenv": [1, 3, 4, 16, 18, 20, 22, 32, 34, 35, 36, 38, 47, 52, 53, 88, 114, 120, 123, 126, 130, 138, 145, 151, 152, 153, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 271, 280, 302, 304, 383, 391, 563, 622, 623, 624, 627, 636, 643, 644], "def": [1, 5, 6, 7, 16, 18, 20, 21, 22, 35, 36, 38, 51, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 120, 123, 126, 127, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 209, 211, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 280, 282, 322, 325, 326, 327, 328, 330, 331, 332, 337, 341, 342, 350, 352, 353, 358, 364, 366, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 405, 587, 588, 594, 615, 622, 623, 626, 634, 636, 637, 638, 639, 641, 643, 644], "v1": [1, 5, 6, 7, 16, 18, 20, 21, 22, 30, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 79, 81, 86, 87, 88, 114, 120, 123, 126, 127, 129, 130, 131, 136, 137, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 217, 218, 221, 224, 226, 227, 234, 240, 241, 246, 253, 255, 258, 259, 260, 263, 264, 265, 266, 267, 270, 271, 273, 279, 280, 287, 302, 304, 325, 327, 328, 330, 331, 339, 341, 377, 379, 381, 382, 383, 385, 391, 570, 601, 623, 625, 627, 628, 629, 630, 631, 632, 639, 641, 643, 644], "shape": [1, 4, 6, 14, 17, 18, 19, 22, 33, 34, 35, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 95, 96, 97, 101, 108, 114, 116, 120, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 175, 176, 177, 178, 179, 180, 183, 185, 188, 195, 196, 206, 212, 214, 218, 220, 222, 229, 232, 233, 234, 239, 241, 242, 246, 248, 252, 253, 255, 259, 262, 263, 265, 268, 273, 279, 281, 283, 284, 285, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 319, 320, 322, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 341, 342, 344, 345, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 391, 393, 406, 412, 416, 466, 467, 470, 471, 472, 562, 582, 587, 588, 590, 594, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 640, 641, 643, 644], "50": [1, 34, 35, 38, 50, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 85, 88, 108, 109, 142, 143, 183, 324, 329, 332, 337, 552, 615, 622, 623, 624, 625, 635, 637, 641], "step": [1, 2, 3, 4, 6, 7, 16, 17, 18, 19, 21, 23, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 78, 86, 87, 88, 92, 93, 100, 102, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 212, 213, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 236, 237, 240, 241, 243, 244, 246, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 286, 299, 301, 302, 304, 312, 317, 325, 327, 328, 330, 331, 341, 342, 345, 349, 360, 368, 377, 379, 381, 382, 383, 385, 386, 387, 388, 389, 392, 395, 406, 410, 416, 418, 420, 421, 475, 594, 616, 623, 625, 626, 628, 629, 631, 632, 635, 636, 639, 640, 643], "each": [1, 2, 3, 5, 6, 7, 11, 12, 15, 17, 19, 20, 21, 22, 23, 26, 27, 32, 34, 35, 36, 37, 38, 39, 42, 44, 46, 47, 49, 50, 52, 53, 55, 56, 60, 61, 62, 68, 69, 71, 72, 78, 79, 80, 83, 86, 87, 88, 101, 102, 106, 108, 109, 111, 114, 120, 123, 126, 127, 130, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 240, 242, 244, 250, 255, 258, 263, 264, 265, 266, 270, 271, 277, 279, 280, 282, 286, 297, 298, 301, 302, 304, 308, 314, 317, 324, 325, 326, 327, 328, 330, 331, 332, 337, 345, 347, 351, 365, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 393, 402, 410, 412, 564, 565, 568, 570, 571, 573, 574, 576, 577, 578, 579, 581, 582, 583, 589, 594, 615, 622, 623, 624, 625, 628, 629, 630, 632, 637, 638, 639, 640, 641, 643, 644], "updat": [1, 17, 18, 21, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 144, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 215, 217, 218, 229, 231, 232, 239, 252, 263, 264, 270, 272, 276, 279, 280, 286, 301, 312, 313, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 344, 345, 349, 350, 351, 352, 353, 354, 356, 358, 359, 360, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 410, 415, 416, 418, 419, 421, 557, 558, 561, 562, 567, 568, 569, 570, 572, 573, 574, 575, 576, 577, 578, 581, 583, 585, 587, 589, 592, 623, 624, 625, 626, 629, 632, 637, 638, 639, 641, 644], "period": [1, 191, 582], "should_upd": 1, "update_policy_weights_": [1, 2, 6, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 191, 568, 570, 573, 574, 576, 578, 581, 583, 589, 622, 638, 643], "shutdown": [1, 5, 6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 154, 159, 190, 218, 324, 402, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589, 615, 622, 623, 641, 643], "follow": [1, 2, 3, 4, 5, 6, 9, 17, 18, 19, 21, 22, 25, 26, 27, 30, 41, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 109, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 144, 147, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 217, 221, 241, 250, 275, 279, 280, 288, 298, 302, 304, 305, 313, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 349, 350, 351, 352, 353, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 416, 567, 568, 569, 570, 572, 573, 575, 576, 582, 594, 608, 622, 623, 624, 625, 626, 629, 630, 636, 637, 638, 639, 641, 643, 644], "kept": [1, 3, 19, 22, 46, 49, 56, 107, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 212, 231, 259, 303, 320, 321, 583, 585, 587, 589, 629, 637], "syncdatacollector": [1, 4, 5, 18, 622, 623, 624, 625, 626, 630, 632, 637, 638, 641], "multisyncdatacollector": [1, 2, 4, 5, 624, 630, 643], "multiasyncdatacollector": [1, 2, 5, 53, 622, 623, 624, 630, 643], "datacollectorbas": [1, 5], "basecollector": [1, 5, 32, 35, 36, 37, 38, 39, 40, 41, 44, 46, 49, 54, 55, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 271, 342, 345, 383, 419, 420, 421, 557, 558, 562], "basic": [1, 6, 21, 40, 89, 144, 170, 402, 404, 420, 570, 578, 592, 594, 616, 624, 629, 630, 632, 637, 643, 644], "size": [1, 16, 18, 19, 22, 34, 35, 38, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 103, 107, 108, 109, 110, 116, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 214, 218, 220, 221, 222, 225, 228, 229, 232, 233, 234, 236, 239, 242, 244, 248, 250, 252, 253, 255, 259, 261, 262, 263, 265, 267, 268, 271, 272, 273, 274, 277, 279, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 315, 316, 319, 320, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 341, 342, 344, 347, 349, 350, 351, 352, 353, 354, 356, 357, 358, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 393, 402, 406, 412, 418, 420, 421, 582, 587, 588, 594, 623, 624, 625, 626, 627, 628, 629, 630, 631, 634, 635, 636, 637, 638, 639, 640, 644], "copi": [1, 6, 18, 35, 36, 37, 38, 39, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 74, 75, 76, 77, 83, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 217, 221, 239, 253, 264, 270, 271, 272, 279, 280, 282, 302, 304, 325, 326, 327, 328, 330, 331, 332, 337, 352, 366, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 391, 568, 570, 573, 574, 576, 577, 578, 581, 583, 589, 594, 622, 623, 625, 627, 637, 641, 643], "distributedsynccollector": [1, 3, 45], "distributeddatacollector": [1, 3, 42, 46, 51, 572], "rpcdatacollector": [1, 3, 34, 35, 36, 38, 47, 49, 51], "distributedsyncdatacollector": [1, 3], "submitit_delayed_launch": 1, "raycollector": [1, 39, 66], "lifecycl": [1, 22, 324], "scheme": [1, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 567, 568, 569, 570, 571, 573, 574, 575, 576, 578, 581, 583, 585, 586, 587, 588, 589, 594, 644], "behavior": [1, 2, 18, 21, 22, 23, 35, 36, 38, 50, 74, 83, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 222, 229, 232, 246, 251, 264, 272, 280, 302, 303, 304, 321, 324, 325, 326, 327, 328, 330, 331, 332, 337, 351, 357, 364, 368, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 405, 410, 581, 615, 623, 625, 637, 638, 639, 641], "transport": [1, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 581, 582, 583, 584, 585, 589], "interoper": [1, 35, 36, 38], "helper": [1, 16, 339, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 592, 601, 616, 622, 623, 625, 637, 639], "somewhat": [2, 185, 628, 644], "equival": [2, 7, 17, 50, 53, 54, 57, 59, 60, 61, 62, 64, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 230, 233, 265, 267, 272, 297, 298, 305, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 412, 630, 643, 644], "dataload": [2, 6, 52, 107, 109, 170, 171, 172, 175, 178, 185, 194, 623, 630, 641], "except": [2, 17, 21, 32, 34, 35, 36, 38, 42, 44, 47, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 235, 255, 264, 265, 266, 270, 272, 286, 301, 302, 304, 310, 312, 325, 326, 327, 328, 330, 331, 332, 337, 349, 352, 366, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 594, 622, 623, 627, 635, 637, 641, 643, 644], "1": [2, 4, 7, 8, 10, 18, 19, 21, 22, 23, 27, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 95, 96, 97, 101, 102, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 206, 212, 214, 215, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 237, 239, 241, 242, 244, 246, 248, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 270, 271, 272, 273, 275, 277, 279, 280, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 298, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 361, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 393, 402, 404, 406, 410, 412, 413, 421, 422, 423, 424, 425, 427, 429, 442, 448, 466, 467, 470, 472, 474, 475, 479, 484, 505, 508, 518, 527, 542, 547, 552, 562, 566, 568, 569, 570, 572, 573, 574, 575, 576, 578, 581, 582, 583, 584, 587, 588, 589, 593, 594, 615, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 636, 637, 638, 639, 640, 641, 642, 643, 644], "over": [2, 5, 7, 18, 20, 21, 22, 23, 27, 35, 36, 38, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 101, 102, 107, 108, 109, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 231, 246, 258, 266, 280, 306, 310, 317, 320, 326, 332, 337, 347, 359, 361, 366, 376, 378, 380, 383, 384, 386, 391, 412, 555, 622, 623, 624, 626, 627, 628, 629, 630, 637, 638, 639, 644], "non": [2, 6, 12, 17, 22, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 53, 55, 57, 58, 60, 63, 65, 70, 71, 74, 75, 76, 77, 83, 86, 87, 88, 96, 98, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 218, 219, 221, 225, 236, 250, 262, 265, 271, 272, 273, 274, 275, 277, 280, 287, 302, 304, 307, 325, 326, 327, 328, 330, 331, 332, 337, 344, 345, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 568, 570, 572, 573, 574, 576, 578, 581, 583, 589, 622, 625, 626, 637, 638, 639, 641, 644], "static": [2, 60, 71, 102, 108, 109, 132, 151, 174, 180, 279, 282, 326, 332, 337, 364, 376, 378, 380, 384, 627, 639, 641], "like": [2, 4, 6, 7, 17, 19, 21, 22, 23, 26, 30, 34, 35, 36, 38, 46, 50, 60, 63, 65, 68, 69, 71, 72, 73, 86, 87, 88, 90, 98, 109, 120, 123, 126, 127, 130, 132, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 233, 265, 268, 303, 320, 325, 326, 327, 328, 329, 330, 331, 332, 337, 339, 345, 349, 351, 365, 368, 369, 370, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 403, 569, 615, 622, 624, 625, 626, 627, 628, 629, 630, 631, 632, 637, 638, 639, 640, 641, 643, 644], "being": [2, 3, 17, 18, 21, 22, 26, 27, 32, 34, 35, 36, 38, 41, 42, 44, 47, 49, 50, 70, 86, 87, 88, 96, 98, 101, 102, 114, 117, 120, 123, 126, 129, 130, 131, 132, 137, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 220, 229, 231, 232, 239, 245, 253, 265, 270, 271, 272, 301, 302, 304, 312, 325, 326, 327, 328, 330, 331, 332, 337, 351, 352, 365, 366, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 412, 419, 564, 565, 566, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589, 615, 622, 623, 624, 625, 630, 637, 638, 639, 641], "torchrl": [2, 3, 5, 6, 12, 14, 15, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 594, 615, 621, 625, 627, 629, 630, 631, 632, 633, 636, 640, 641, 642], "two": [2, 6, 7, 18, 22, 23, 27, 29, 61, 62, 65, 68, 69, 72, 73, 83, 86, 87, 88, 107, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 226, 246, 250, 270, 277, 293, 302, 304, 317, 320, 325, 326, 327, 328, 330, 331, 332, 337, 345, 365, 368, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 410, 416, 570, 594, 622, 623, 624, 625, 626, 627, 628, 630, 631, 635, 636, 637, 638, 639, 641, 643, 644], "main": [2, 6, 7, 19, 24, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 56, 66, 85, 127, 150, 158, 170, 193, 221, 226, 324, 345, 416, 567, 568, 569, 570, 571, 573, 574, 576, 578, 581, 583, 589, 594, 622, 623, 634, 635, 636, 643, 644], "argument": [2, 3, 6, 18, 19, 20, 21, 22, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 95, 96, 97, 98, 101, 102, 106, 107, 108, 109, 112, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 152, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 206, 212, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 244, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 286, 287, 288, 297, 298, 301, 302, 304, 305, 306, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 340, 341, 342, 344, 345, 346, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 398, 400, 401, 402, 403, 404, 408, 416, 420, 421, 555, 562, 563, 566, 580, 615, 622, 623, 624, 625, 626, 627, 628, 630, 637, 638, 639, 641, 643, 644], "list": [2, 21, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 96, 98, 106, 107, 108, 109, 110, 112, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 212, 219, 220, 224, 225, 229, 230, 232, 241, 242, 246, 248, 250, 258, 260, 268, 269, 270, 271, 272, 274, 275, 277, 279, 287, 288, 290, 296, 298, 300, 302, 304, 305, 306, 308, 313, 314, 322, 324, 325, 326, 327, 328, 330, 331, 332, 334, 337, 341, 345, 347, 348, 350, 352, 364, 366, 369, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 389, 391, 392, 402, 403, 404, 410, 412, 430, 438, 439, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 478, 480, 481, 482, 483, 484, 485, 486, 487, 490, 491, 492, 493, 494, 496, 497, 498, 499, 500, 501, 503, 504, 506, 508, 509, 510, 511, 512, 515, 516, 517, 518, 519, 520, 521, 522, 523, 525, 526, 527, 528, 529, 530, 533, 534, 535, 536, 537, 538, 539, 540, 564, 565, 568, 570, 571, 573, 574, 576, 577, 578, 581, 583, 589, 615, 622, 624, 627, 628, 629, 630, 634, 635, 636, 637, 639, 640, 641, 643, 644], "constructor": [2, 17, 21, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 66, 68, 72, 73, 83, 86, 87, 101, 114, 120, 123, 126, 130, 138, 145, 150, 151, 154, 158, 159, 160, 163, 170, 171, 172, 175, 176, 177, 178, 179, 180, 195, 196, 217, 221, 270, 288, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 402, 403, 420, 563, 566, 580, 594, 615, 622, 623, 624, 627, 630, 637, 638, 641, 643], "iter": [2, 5, 18, 20, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 98, 107, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 234, 246, 259, 282, 287, 288, 297, 305, 313, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 344, 346, 347, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 410, 412, 414, 416, 622, 624, 625, 630, 632, 637, 638, 639], "queri": [2, 18, 38, 86, 87, 88, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 203, 250, 275, 279, 325, 326, 327, 328, 330, 331, 332, 337, 347, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 622, 629, 634, 639, 643], "defin": [2, 7, 14, 21, 32, 34, 35, 36, 38, 41, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 251, 264, 282, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 348, 354, 356, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 415, 475, 563, 615, 622, 623, 625, 629, 632, 635, 639, 641, 644], "number": [2, 16, 17, 18, 19, 27, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 106, 108, 109, 116, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 144, 145, 146, 147, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 231, 233, 234, 235, 237, 240, 241, 243, 245, 246, 249, 251, 252, 253, 255, 257, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 286, 288, 295, 299, 300, 301, 302, 303, 304, 305, 307, 308, 309, 312, 315, 316, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341, 342, 344, 345, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 398, 400, 401, 402, 406, 408, 410, 416, 418, 419, 420, 421, 475, 555, 556, 564, 565, 566, 582, 583, 584, 589, 594, 622, 623, 624, 625, 627, 628, 630, 632, 637, 638, 639, 640, 641, 644], "stack": [2, 4, 10, 17, 18, 19, 22, 26, 27, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 74, 75, 76, 77, 86, 87, 96, 101, 120, 123, 126, 129, 130, 131, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 186, 195, 196, 204, 205, 221, 226, 244, 279, 302, 304, 317, 325, 327, 328, 330, 331, 341, 346, 347, 350, 352, 364, 369, 371, 372, 373, 377, 379, 381, 382, 385, 386, 392, 406, 428, 523, 594, 623, 626, 627, 634, 635, 636, 637, 639, 643], "user": [2, 6, 12, 18, 20, 21, 22, 24, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 56, 78, 79, 83, 85, 87, 88, 89, 95, 102, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 222, 239, 264, 270, 272, 294, 326, 332, 337, 352, 368, 371, 372, 376, 378, 380, 383, 384, 393, 563, 594, 622, 623, 626, 627, 629, 630, 635, 639, 643, 644], "reach": [2, 18, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 107, 120, 123, 126, 130, 137, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 244, 263, 286, 301, 312, 622, 624, 632, 634, 637, 638, 643, 644], "done": [2, 17, 18, 19, 21, 22, 23, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 92, 93, 95, 100, 102, 108, 109, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 212, 213, 214, 215, 217, 218, 221, 229, 230, 232, 233, 234, 239, 243, 244, 245, 246, 248, 252, 253, 255, 257, 259, 262, 263, 265, 266, 269, 270, 271, 272, 273, 279, 302, 304, 320, 329, 341, 349, 350, 351, 352, 353, 354, 356, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 380, 383, 384, 386, 387, 388, 389, 390, 409, 495, 594, 615, 622, 624, 625, 626, 627, 628, 629, 630, 631, 632, 635, 636, 637, 638, 639, 640, 641, 643, 644], "state": [2, 6, 17, 18, 21, 22, 23, 32, 34, 35, 36, 38, 40, 41, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 100, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 144, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 217, 220, 221, 222, 224, 225, 227, 230, 233, 236, 239, 243, 244, 246, 253, 263, 264, 269, 270, 271, 272, 273, 274, 279, 280, 283, 289, 294, 299, 302, 304, 305, 308, 311, 315, 316, 317, 323, 325, 326, 327, 328, 329, 330, 331, 332, 337, 341, 344, 349, 351, 352, 356, 358, 365, 366, 368, 369, 370, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 402, 409, 416, 418, 420, 421, 475, 566, 575, 580, 594, 603, 608, 616, 622, 623, 624, 625, 626, 627, 628, 629, 630, 634, 635, 637, 638, 639, 644], "after": [2, 4, 6, 19, 20, 22, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 66, 69, 78, 86, 87, 88, 95, 97, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 135, 136, 137, 138, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 286, 297, 301, 302, 304, 313, 325, 326, 327, 328, 330, 331, 332, 337, 352, 361, 371, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 402, 403, 567, 568, 569, 570, 571, 573, 574, 575, 576, 578, 579, 581, 583, 589, 594, 615, 623, 624, 625, 626, 627, 628, 630, 632, 634, 637, 638, 639, 640, 641, 644], "predefin": [2, 7, 183, 393, 623, 625, 630, 641, 643], "becaus": [2, 18, 21, 22, 23, 26, 53, 60, 71, 78, 86, 87, 88, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 233, 241, 263, 278, 293, 297, 298, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 342, 344, 345, 349, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 622, 623, 625, 626, 628, 629, 630, 634, 636, 637, 638, 639, 641, 644], "comput": [2, 6, 17, 18, 21, 22, 23, 27, 33, 34, 38, 39, 42, 43, 44, 45, 47, 48, 50, 52, 53, 59, 86, 87, 88, 101, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 243, 246, 260, 272, 276, 280, 283, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 317, 320, 321, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 341, 342, 345, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 409, 420, 421, 475, 556, 570, 576, 594, 597, 608, 615, 622, 624, 625, 626, 627, 628, 634, 635, 636, 637, 638, 640, 641], "heavi": [2, 6, 27, 78, 615, 641], "crucial": [2, 20, 86, 87, 176, 286, 301, 312, 325, 327, 328, 330, 331, 357, 364, 366, 377, 379, 380, 381, 382, 385, 421, 594, 622, 623, 624, 625, 627, 629, 631, 637, 638, 639, 643, 644], "hyperparamet": [2, 106, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 592, 622, 631, 639, 641], "appropri": [2, 6, 7, 17, 23, 26, 87, 94, 104, 114, 115, 118, 119, 138, 150, 158, 179, 180, 233, 563, 566, 594, 615, 622, 631, 641], "take": [2, 17, 20, 21, 22, 27, 41, 56, 80, 86, 87, 90, 111, 117, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 183, 224, 226, 263, 266, 267, 271, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 303, 304, 307, 308, 309, 311, 312, 314, 315, 316, 320, 325, 327, 328, 330, 331, 338, 341, 342, 345, 348, 368, 377, 379, 381, 382, 385, 393, 406, 419, 594, 622, 623, 624, 626, 627, 628, 629, 637, 638, 639, 641, 644], "consider": [2, 21, 22, 27, 129, 131, 271, 324, 592, 594, 623, 637, 638, 641], "whether": [2, 18, 22, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 97, 104, 116, 120, 123, 126, 130, 137, 138, 142, 143, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 217, 226, 227, 229, 232, 243, 264, 270, 272, 279, 280, 288, 302, 304, 305, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 341, 345, 349, 350, 351, 352, 353, 354, 356, 358, 359, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 405, 416, 420, 421, 475, 566, 568, 570, 571, 573, 574, 576, 578, 580, 581, 583, 585, 587, 589, 615, 622, 623, 624, 626, 627, 637, 638, 639, 643, 644], "should": [2, 5, 6, 7, 17, 18, 20, 21, 22, 23, 24, 26, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 95, 98, 102, 108, 109, 110, 114, 117, 120, 123, 124, 125, 126, 129, 130, 131, 132, 137, 138, 141, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 217, 218, 221, 224, 225, 226, 229, 230, 233, 234, 236, 241, 242, 244, 246, 251, 252, 253, 255, 258, 259, 263, 264, 266, 269, 271, 272, 273, 278, 279, 280, 282, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 339, 341, 342, 344, 345, 348, 349, 351, 352, 358, 365, 366, 368, 369, 370, 371, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 393, 395, 405, 410, 411, 412, 416, 562, 564, 565, 566, 569, 571, 573, 574, 576, 581, 582, 583, 589, 615, 622, 623, 624, 625, 626, 628, 630, 631, 634, 636, 637, 638, 639, 640, 641, 643, 644], "occur": [2, 6, 27, 35, 70, 71, 78, 120, 123, 126, 130, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 222, 234, 246, 251, 278, 297, 298, 313, 314, 326, 332, 337, 340, 342, 344, 345, 361, 376, 378, 380, 384, 594, 626, 641, 644], "serial": [2, 6, 15, 18, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 279, 280, 326, 332, 337, 376, 378, 380, 383, 384], "multisynccollector": [2, 3, 5, 33, 34, 35, 36, 42, 43, 44, 45, 47, 48, 50, 52, 53, 425, 565, 570], "split": [2, 6, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 71, 78, 79, 80, 81, 82, 83, 84, 85, 102, 108, 109, 141, 152, 153, 171, 307, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 624, 628, 641, 643], "workload": [2, 324], "result": [2, 3, 7, 17, 18, 20, 21, 22, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 56, 58, 65, 66, 67, 68, 69, 72, 73, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 95, 102, 107, 108, 109, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 212, 213, 214, 217, 218, 219, 221, 222, 223, 224, 225, 227, 228, 229, 230, 231, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 286, 298, 301, 302, 304, 305, 314, 320, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 337, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 392, 402, 418, 419, 594, 615, 623, 625, 627, 628, 631, 632, 635, 639, 640, 643, 644], "final": [2, 7, 21, 22, 23, 50, 86, 87, 172, 175, 176, 177, 183, 265, 278, 286, 301, 302, 304, 312, 324, 325, 327, 328, 330, 331, 333, 334, 346, 377, 379, 381, 382, 385, 386, 410, 622, 623, 624, 626, 631, 632, 634, 637, 638, 639, 644], "multiasynccollector": [2, 5, 32, 36, 38, 42, 44, 47, 50, 424, 564], "continu": [2, 21, 28, 58, 60, 75, 76, 87, 109, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 206, 214, 239, 265, 273, 290, 291, 292, 293, 312, 326, 347, 350, 386, 421, 569, 622, 624, 625, 628, 637, 638, 639, 641, 644], "concomitantli": [2, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180], "network": [2, 6, 23, 27, 81, 88, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 283, 284, 285, 288, 290, 291, 292, 293, 296, 299, 300, 305, 308, 309, 315, 316, 317, 326, 332, 337, 344, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 415, 421, 466, 468, 469, 470, 472, 475, 561, 562, 592, 601, 607, 626, 629, 632, 636, 639, 644], "impli": [2, 644], "slightli": [2, 56, 78, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 625, 626, 637, 639, 640, 641, 644], "therefor": [2, 19, 21, 22, 26, 65, 68, 72, 73, 84, 85, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 183, 255, 325, 327, 328, 330, 331, 368, 377, 379, 381, 382, 383, 385, 626, 629, 637, 644], "fastest": 2, "price": 2, "suitabl": [2, 6, 221, 380], "curriculum": [2, 23], "remot": [2, 6, 10, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 150, 158, 176, 189, 194, 195, 280, 325, 327, 328, 329, 330, 331, 337, 377, 379, 381, 382, 385, 402, 403, 572, 573, 574, 575, 576, 582, 587, 588, 589, 615, 644], "rollout": [2, 16, 17, 18, 20, 22, 30, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 114, 120, 121, 122, 123, 126, 130, 132, 133, 136, 137, 138, 142, 143, 144, 145, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 165, 170, 171, 172, 175, 178, 179, 180, 185, 208, 214, 215, 217, 218, 221, 224, 226, 227, 229, 232, 233, 234, 239, 241, 242, 248, 252, 253, 258, 259, 260, 263, 264, 266, 267, 270, 273, 279, 280, 287, 302, 304, 312, 317, 341, 349, 391, 393, 556, 608, 622, 624, 625, 626, 628, 629, 630, 631, 632, 640, 641, 643], "necessari": [2, 6, 23, 25, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 78, 80, 81, 83, 84, 85, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 259, 369, 386, 387, 388, 389, 390, 622, 624, 628, 629, 630, 634, 635], "synchronis": [2, 127, 637, 638], "either": [2, 5, 24, 51, 55, 57, 65, 66, 68, 69, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 243, 244, 263, 264, 280, 323, 326, 332, 334, 337, 366, 372, 373, 376, 378, 380, 383, 384, 397, 594, 602, 622, 623, 625, 637, 640, 641, 643, 644], "update_at_each_batch": [2, 32, 35, 36, 38], "second": [2, 6, 22, 27, 32, 34, 35, 36, 38, 52, 56, 61, 62, 78, 80, 114, 150, 184, 190, 192, 197, 218, 267, 298, 302, 304, 324, 326, 332, 337, 351, 365, 368, 371, 393, 395, 398, 400, 401, 414, 567, 568, 569, 570, 572, 573, 574, 575, 576, 578, 579, 581, 583, 589, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 635, 636, 637, 638, 639, 640, 641, 643, 644], "oper": [2, 3, 6, 17, 21, 22, 23, 26, 27, 32, 34, 35, 36, 38, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 96, 97, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 236, 241, 267, 269, 273, 280, 283, 284, 285, 296, 297, 298, 323, 325, 326, 327, 328, 329, 330, 331, 332, 337, 344, 349, 351, 353, 354, 359, 365, 368, 370, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 402, 403, 416, 568, 570, 575, 582, 583, 584, 587, 594, 596, 608, 622, 623, 624, 625, 626, 627, 628, 636, 637, 638, 639, 644], "instanc": [2, 6, 7, 17, 20, 21, 22, 23, 26, 27, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 58, 60, 65, 66, 67, 68, 69, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 95, 96, 97, 100, 102, 108, 109, 116, 120, 123, 125, 126, 127, 129, 130, 131, 135, 138, 144, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 213, 246, 265, 272, 279, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 313, 314, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 341, 342, 344, 345, 346, 347, 348, 350, 352, 354, 357, 358, 364, 366, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 393, 397, 404, 405, 410, 418, 419, 468, 556, 557, 558, 562, 564, 565, 578, 581, 583, 589, 594, 615, 622, 624, 625, 626, 627, 628, 634, 639, 641, 644], "cpu": [2, 3, 6, 18, 22, 27, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 101, 108, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 214, 218, 225, 229, 230, 232, 233, 234, 239, 242, 243, 248, 250, 252, 253, 255, 259, 262, 263, 265, 271, 272, 273, 275, 277, 283, 284, 285, 287, 296, 297, 298, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 329, 330, 331, 332, 337, 340, 341, 342, 344, 347, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 402, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 492, 511, 535, 536, 537, 577, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 636, 637, 638, 639, 640, 641, 643, 644], "slower": [2, 3, 8, 9, 570, 637], "than": [2, 3, 6, 22, 23, 27, 32, 34, 35, 36, 38, 42, 44, 46, 47, 50, 52, 53, 57, 65, 68, 69, 72, 73, 78, 79, 83, 86, 87, 88, 102, 108, 109, 112, 114, 120, 123, 126, 130, 134, 138, 148, 149, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 189, 195, 226, 242, 244, 253, 280, 286, 293, 297, 302, 304, 305, 307, 322, 325, 327, 328, 330, 331, 332, 340, 344, 345, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 417, 419, 570, 583, 593, 594, 615, 622, 623, 624, 625, 626, 627, 629, 637, 638, 639, 641, 643, 644], "one": [2, 3, 6, 7, 17, 18, 20, 21, 22, 23, 24, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 83, 86, 87, 88, 92, 93, 94, 95, 100, 101, 102, 104, 108, 109, 110, 112, 114, 115, 118, 119, 120, 121, 122, 123, 126, 127, 129, 130, 131, 132, 134, 135, 136, 137, 138, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 221, 224, 226, 227, 229, 230, 231, 232, 239, 242, 243, 245, 246, 250, 255, 258, 261, 262, 264, 265, 266, 271, 272, 274, 277, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 310, 311, 312, 313, 314, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 341, 342, 344, 345, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 393, 395, 404, 408, 410, 411, 416, 556, 566, 568, 578, 589, 593, 594, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 636, 637, 638, 639, 640, 641, 644], "cuda": [2, 3, 21, 22, 26, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 121, 122, 123, 126, 130, 132, 133, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 225, 241, 249, 250, 265, 271, 272, 275, 277, 326, 332, 333, 337, 344, 376, 378, 380, 383, 384, 407, 577, 582, 622, 623, 624, 625, 637, 638, 640, 644], "dispatch": [2, 5, 22, 42, 44, 47, 50, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 326, 332, 337, 341, 376, 378, 380, 383, 384, 393, 568, 570, 573, 574, 576, 578, 581, 583, 589, 622, 644], "speed": [2, 5, 22, 23, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 615, 622, 623, 624, 625, 637, 638, 639, 641, 643], "avoid": [2, 7, 17, 20, 81, 88, 95, 97, 108, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 211, 221, 239, 270, 272, 279, 280, 303, 320, 322, 326, 332, 337, 340, 344, 351, 352, 365, 368, 371, 376, 378, 380, 383, 384, 555, 567, 570, 572, 574, 576, 577, 594, 615, 624, 626, 635, 638], "oom": [2, 20, 86, 87, 95, 97, 116, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "choic": [2, 15, 63, 79, 85, 86, 87, 150, 176, 185, 307, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 420, 622, 623, 629, 637, 638], "pass": [2, 4, 5, 6, 9, 12, 17, 18, 19, 20, 21, 22, 23, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 57, 60, 63, 65, 66, 68, 69, 71, 72, 73, 74, 78, 80, 81, 83, 84, 85, 86, 87, 88, 93, 95, 97, 102, 108, 109, 114, 116, 120, 123, 126, 127, 128, 130, 131, 138, 141, 145, 150, 151, 152, 153, 154, 158, 159, 160, 163, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 215, 217, 218, 221, 225, 227, 229, 232, 242, 244, 252, 253, 270, 271, 274, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 313, 314, 315, 316, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 340, 341, 342, 344, 345, 347, 348, 350, 351, 352, 364, 365, 366, 368, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 402, 403, 404, 412, 416, 420, 421, 564, 565, 566, 574, 577, 578, 594, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 636, 637, 638, 639, 641, 643, 644], "ie": [2, 17, 42, 47, 51, 57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 72, 74, 75, 76, 77, 83, 101, 109, 120, 123, 126, 130, 134, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 214, 221, 236, 262, 265, 274, 279, 302, 304, 326, 332, 337, 344, 376, 378, 380, 384, 623, 638], "while": [2, 6, 7, 17, 21, 22, 26, 27, 32, 34, 35, 36, 38, 52, 56, 66, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 255, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 341, 348, 351, 357, 364, 365, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 575, 594, 615, 622, 624, 625, 628, 630, 631, 637, 638, 639, 640, 641, 643], "wait": [2, 6, 32, 33, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 66, 95, 97, 161, 183, 324, 326, 332, 337, 567, 568, 569, 570, 572, 573, 574, 575, 576, 578, 579, 581, 582, 583, 589, 625, 639], "impact": [2, 18, 33, 42, 43, 44, 45, 47, 48, 83, 137, 229, 232, 332, 349, 351, 365, 368, 370, 380, 623, 625, 637, 638], "memori": [2, 3, 4, 6, 9, 10, 12, 18, 21, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 59, 66, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 90, 91, 93, 95, 96, 100, 120, 121, 122, 123, 126, 127, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 221, 225, 250, 265, 271, 272, 275, 277, 279, 280, 295, 325, 326, 327, 328, 330, 331, 332, 337, 344, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 427, 566, 568, 569, 570, 573, 574, 576, 577, 578, 581, 583, 584, 589, 594, 615, 622, 623, 625, 637, 641, 643], "which": [2, 3, 5, 6, 7, 10, 17, 18, 19, 21, 22, 23, 26, 27, 32, 34, 35, 36, 37, 38, 41, 42, 44, 47, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 92, 96, 106, 107, 114, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 205, 221, 222, 226, 229, 232, 237, 239, 241, 242, 245, 246, 250, 251, 253, 263, 265, 266, 269, 270, 271, 272, 273, 275, 279, 282, 283, 284, 285, 286, 296, 302, 303, 304, 306, 317, 321, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 342, 344, 345, 346, 347, 349, 350, 351, 352, 354, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 393, 402, 406, 411, 420, 568, 569, 570, 573, 574, 576, 578, 581, 583, 589, 594, 596, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 634, 636, 637, 638, 639, 640, 641, 644], "storing_devic": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 422, 423, 424, 425, 623, 625, 638], "dure": [2, 6, 10, 18, 20, 21, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 93, 95, 97, 98, 101, 102, 106, 108, 120, 123, 126, 127, 130, 137, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 182, 185, 191, 198, 199, 217, 218, 221, 224, 229, 232, 234, 236, 237, 239, 244, 248, 260, 262, 265, 267, 269, 270, 272, 273, 274, 279, 280, 287, 302, 304, 324, 332, 341, 351, 368, 380, 384, 386, 388, 389, 410, 416, 418, 421, 567, 569, 570, 576, 578, 586, 587, 590, 594, 605, 622, 623, 624, 625, 628, 629, 630, 632, 637, 638, 639, 641, 644], "heurist": [2, 23, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 176, 286, 325, 327, 328, 330, 331, 341, 345, 377, 379, 381, 382, 385, 622, 626, 630, 644], "usual": [2, 17, 18, 21, 23, 25, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 79, 106, 114, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 270, 368, 372, 380, 384, 386, 387, 388, 389, 390, 392, 593, 594, 596, 622, 623, 624, 625, 628, 630, 631, 638, 641, 644], "same": [2, 4, 5, 6, 7, 18, 19, 21, 22, 23, 34, 41, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 83, 86, 87, 88, 107, 108, 109, 112, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 141, 145, 146, 150, 151, 152, 153, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 221, 229, 231, 232, 237, 239, 242, 244, 245, 246, 262, 270, 271, 272, 279, 282, 288, 305, 306, 312, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 350, 352, 364, 366, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 420, 567, 568, 570, 572, 573, 575, 576, 583, 584, 589, 590, 594, 615, 622, 623, 624, 627, 628, 630, 634, 635, 636, 637, 638, 640, 641, 644], "default": [2, 3, 6, 7, 17, 19, 21, 22, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 95, 96, 97, 98, 101, 102, 104, 106, 107, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 205, 206, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 245, 246, 248, 249, 250, 251, 252, 253, 255, 257, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341, 342, 344, 345, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 395, 398, 399, 400, 401, 402, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 466, 475, 562, 566, 568, 569, 570, 571, 573, 574, 575, 576, 578, 580, 581, 583, 585, 587, 589, 622, 623, 624, 625, 626, 628, 637, 640, 641, 643, 644], "besid": 2, "those": [2, 22, 24, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 199, 221, 226, 229, 232, 239, 246, 265, 266, 269, 273, 304, 342, 345, 346, 347, 419, 564, 565, 568, 570, 573, 574, 576, 581, 583, 589, 622, 623, 627, 628, 638, 639, 644], "max_frames_per_traj": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 422, 423, 424, 425, 555, 622, 624, 643], "frame": [2, 30, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 78, 90, 221, 237, 286, 301, 312, 341, 392, 393, 395, 398, 400, 401, 408, 410, 416, 420, 421, 475, 555, 556, 622, 623, 624, 625, 628, 637, 638, 641, 643, 644], "call": [2, 6, 7, 8, 17, 18, 20, 21, 22, 26, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 102, 103, 107, 108, 110, 112, 116, 117, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 135, 136, 137, 138, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 203, 210, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 230, 231, 233, 234, 235, 236, 237, 239, 240, 241, 243, 244, 246, 248, 249, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 316, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 341, 344, 345, 347, 348, 350, 351, 352, 358, 364, 365, 366, 368, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 395, 402, 403, 410, 412, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 579, 581, 582, 583, 587, 588, 589, 594, 596, 615, 623, 624, 625, 626, 627, 628, 630, 631, 637, 638, 639, 641, 643, 644], "init_random_fram": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 422, 423, 424, 425, 555, 622, 623, 626, 632], "random": [2, 7, 19, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 85, 103, 114, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 185, 214, 231, 245, 246, 265, 272, 287, 301, 302, 324, 326, 332, 337, 342, 343, 344, 345, 350, 366, 369, 375, 376, 378, 380, 384, 410, 420, 421, 422, 423, 424, 425, 432, 470, 475, 507, 556, 608, 622, 623, 624, 625, 626, 627, 628, 630, 639, 640, 641, 643, 644], "rand_step": [2, 19, 22, 120, 123, 124, 125, 126, 127, 129, 130, 131, 138, 139, 140, 144, 145, 146, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 240, 265, 279, 639, 643, 644], "reset_at_each_it": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 422, 423, 424, 425, 622], "split_traj": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 79, 81, 83, 84, 85, 422, 423, 424, 425, 622, 623, 624], "trajectori": [2, 4, 11, 17, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 56, 72, 78, 79, 80, 81, 83, 84, 85, 101, 102, 108, 109, 114, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 251, 263, 270, 304, 312, 368, 383, 386, 389, 406, 436, 437, 622, 623, 624, 625, 627, 630, 632, 639, 643, 644], "pad": [2, 22, 56, 79, 81, 83, 84, 85, 87, 185, 188, 189, 195, 196, 199, 205, 221, 269, 288, 290, 291, 304, 306, 326, 327, 328, 329, 330, 331, 332, 337, 380, 412, 466, 594, 635], "along": [2, 18, 22, 35, 36, 38, 56, 57, 58, 59, 60, 61, 62, 63, 64, 69, 70, 71, 74, 75, 76, 77, 79, 81, 83, 84, 85, 86, 87, 88, 97, 102, 108, 109, 114, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 205, 206, 220, 221, 222, 244, 246, 248, 251, 258, 262, 268, 297, 304, 305, 306, 315, 316, 325, 326, 327, 328, 330, 331, 332, 337, 342, 344, 345, 352, 366, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 622, 623, 625, 627, 629, 637, 638, 639, 641, 643], "mask": [2, 16, 18, 22, 23, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 87, 89, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 195, 196, 215, 251, 287, 297, 298, 301, 306, 313, 314, 326, 329, 332, 337, 358, 371, 376, 380, 384, 409, 412, 594, 596, 623, 625, 626, 635, 644], "point": [2, 19, 22, 51, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 70, 71, 74, 75, 76, 77, 82, 88, 94, 101, 102, 104, 114, 115, 118, 119, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 275, 276, 277, 278, 279, 324, 326, 332, 337, 344, 359, 376, 378, 380, 383, 384, 416, 593, 616, 618, 623, 624, 636, 637, 638, 639, 641, 643, 644], "boolean": [2, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 108, 109, 130, 180, 213, 217, 226, 251, 263, 306, 312, 594, 625], "repres": [2, 17, 19, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 60, 63, 71, 72, 81, 86, 87, 96, 120, 123, 124, 125, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 237, 251, 267, 279, 297, 298, 306, 313, 314, 320, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 386, 412, 602, 622, 624, 625, 626, 627, 628, 629, 637, 638], "valid": [2, 7, 19, 56, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 166, 170, 171, 172, 175, 178, 179, 180, 217, 251, 270, 272, 286, 288, 305, 306, 312, 326, 329, 351, 358, 365, 368, 371, 378, 380, 386, 387, 388, 389, 412, 626, 644], "valu": [2, 7, 17, 18, 19, 21, 22, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 101, 102, 108, 109, 114, 120, 123, 126, 130, 131, 138, 141, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 203, 206, 211, 212, 213, 214, 217, 219, 221, 222, 224, 227, 229, 230, 231, 232, 233, 239, 245, 246, 250, 251, 254, 255, 256, 258, 260, 262, 265, 266, 270, 271, 272, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 290, 291, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 310, 312, 313, 314, 318, 319, 320, 321, 322, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 342, 344, 345, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 393, 405, 406, 408, 409, 410, 411, 412, 416, 420, 472, 475, 562, 592, 601, 608, 623, 626, 629, 630, 631, 636, 637, 638, 639, 641, 643, 644], "exploration_typ": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 410, 422, 423, 424, 425, 470, 622, 623], "explor": [2, 7, 281, 286, 297, 298, 301, 312, 313, 314, 339, 340, 342, 344, 345, 349, 366, 368, 410, 421, 557, 558, 562, 592, 601, 624, 625, 626, 627, 629, 630, 632, 637, 638, 639], "reset_when_don": [2, 32, 34, 35, 36, 38], "its": [2, 6, 17, 18, 19, 21, 22, 23, 24, 26, 28, 30, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 72, 74, 75, 76, 77, 86, 87, 88, 95, 97, 101, 102, 108, 109, 120, 123, 126, 130, 137, 138, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 220, 221, 227, 233, 241, 263, 264, 265, 270, 272, 278, 279, 280, 282, 286, 288, 297, 302, 304, 306, 307, 313, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 348, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 416, 420, 421, 562, 568, 573, 576, 577, 589, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 637, 638, 639, 640, 641, 643, 644], "within": [2, 20, 21, 22, 32, 35, 36, 38, 41, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 96, 101, 102, 109, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 280, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 345, 348, 354, 359, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 391, 393, 402, 416, 615, 623, 626, 627, 628, 629, 630, 631, 632, 637, 639, 643], "how": [2, 5, 6, 13, 17, 19, 21, 30, 41, 42, 44, 47, 65, 72, 83, 86, 87, 88, 101, 102, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 242, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 349, 351, 365, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 395, 416, 418, 581, 585, 592, 593, 622, 623, 624, 625, 626, 627, 628, 630, 631, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "tabl": [2, 380, 623, 628], "summar": [2, 17, 187, 639], "what": [2, 7, 18, 19, 21, 22, 27, 30, 35, 36, 38, 65, 74, 78, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 195, 196, 212, 233, 265, 270, 313, 352, 363, 366, 372, 376, 378, 380, 384, 593, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 634, 635, 637, 638, 639, 640, 641, 643, 644], "expect": [2, 5, 6, 8, 17, 18, 21, 22, 23, 26, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 81, 86, 87, 88, 102, 107, 108, 120, 123, 126, 130, 138, 144, 147, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 214, 218, 219, 220, 221, 222, 223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 238, 240, 241, 242, 243, 244, 246, 248, 250, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 298, 302, 304, 312, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 347, 349, 350, 351, 352, 353, 354, 356, 357, 358, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 556, 593, 615, 622, 624, 625, 627, 628, 629, 630, 634, 635, 637, 638, 639, 641, 644], "n": [2, 4, 6, 17, 19, 25, 26, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 101, 102, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 231, 236, 274, 312, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 345, 349, 350, 358, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 412, 483, 594, 623, 625, 626, 628, 635, 637, 638, 641, 643, 644], "b": [2, 22, 26, 27, 52, 56, 60, 68, 71, 72, 73, 86, 87, 95, 96, 114, 123, 176, 197, 201, 239, 273, 325, 326, 327, 328, 330, 331, 332, 337, 348, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 393, 623, 634, 641], "cat_result": [2, 4, 35, 36, 38], "na": [2, 172, 175, 193], "t": [2, 4, 12, 21, 22, 23, 25, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 92, 101, 102, 107, 108, 109, 114, 120, 123, 126, 127, 129, 130, 138, 145, 146, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 239, 240, 241, 243, 249, 250, 251, 252, 253, 254, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 277, 278, 279, 282, 297, 302, 304, 306, 312, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 344, 349, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 393, 401, 416, 419, 566, 583, 593, 594, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 636, 637, 638, 639, 640, 641, 643, 644], "p": [2, 23, 69, 101, 102, 106, 127, 156, 157, 287, 317], "In": [2, 3, 4, 6, 7, 8, 12, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 51, 52, 78, 79, 81, 83, 84, 85, 86, 87, 88, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 229, 230, 232, 240, 250, 255, 259, 264, 265, 268, 270, 271, 272, 275, 277, 278, 280, 282, 303, 305, 316, 320, 321, 325, 326, 327, 328, 330, 331, 332, 337, 344, 345, 347, 349, 350, 352, 353, 354, 356, 357, 358, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 419, 564, 565, 566, 588, 589, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 637, 638, 639, 640, 641, 644], "case": [2, 4, 6, 7, 15, 18, 19, 20, 21, 22, 23, 24, 26, 27, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 92, 93, 100, 114, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 195, 197, 229, 230, 232, 240, 246, 265, 268, 272, 273, 282, 286, 304, 305, 325, 327, 328, 330, 331, 342, 344, 345, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 393, 403, 406, 419, 564, 565, 566, 594, 595, 622, 623, 624, 625, 626, 627, 628, 630, 631, 635, 637, 638, 639, 641, 643, 644], "dimens": [2, 4, 17, 18, 19, 22, 34, 35, 36, 38, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 79, 81, 83, 84, 85, 86, 87, 95, 96, 97, 102, 108, 109, 114, 116, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 177, 178, 179, 180, 185, 205, 206, 214, 220, 221, 222, 236, 244, 246, 248, 251, 258, 261, 262, 265, 268, 274, 279, 280, 288, 289, 294, 295, 297, 302, 304, 305, 306, 308, 311, 315, 316, 319, 320, 325, 327, 328, 330, 331, 332, 337, 338, 341, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 566, 594, 622, 623, 624, 625, 627, 634, 637, 638, 639, 641], "time": [2, 4, 5, 7, 17, 22, 23, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 56, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 92, 95, 114, 120, 121, 122, 123, 126, 127, 130, 136, 137, 138, 141, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 212, 220, 221, 222, 244, 251, 258, 265, 266, 267, 270, 272, 279, 287, 299, 304, 312, 317, 325, 326, 327, 328, 330, 331, 332, 337, 341, 345, 350, 351, 352, 358, 361, 364, 365, 366, 368, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 416, 420, 475, 528, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 579, 581, 583, 589, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 635, 636, 637, 638, 639, 640, 641, 643, 644], "adapt": [2, 4, 215, 244, 263, 279, 324, 358, 365, 371, 594, 622, 626, 639], "equal": [2, 32, 35, 36, 38, 78, 88, 102, 108, 109, 123, 145, 148, 149, 150, 158, 178, 245, 246, 288, 302, 304, 305, 306, 326, 332, 337, 351, 368, 380, 406, 564, 565, 622, 624, 640], "i": [2, 5, 6, 17, 19, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 60, 65, 68, 71, 73, 86, 87, 88, 90, 91, 95, 97, 101, 102, 108, 109, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 228, 244, 250, 255, 258, 270, 272, 277, 298, 302, 304, 307, 314, 325, 326, 327, 328, 330, 331, 332, 337, 341, 342, 344, 345, 349, 351, 352, 353, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 406, 555, 575, 594, 622, 623, 624, 625, 626, 628, 629, 630, 631, 632, 637, 638, 639, 641, 643, 644], "introduc": [2, 101, 102, 150, 158, 302, 304, 312, 622, 637], "some": [2, 6, 8, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 51, 57, 58, 59, 60, 61, 62, 63, 64, 66, 68, 69, 70, 71, 74, 75, 76, 77, 79, 85, 86, 87, 88, 90, 95, 97, 114, 116, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 203, 217, 250, 265, 272, 275, 290, 302, 325, 326, 327, 328, 330, 331, 332, 337, 345, 346, 347, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 406, 555, 568, 570, 573, 574, 576, 578, 579, 581, 583, 589, 594, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 637, 638, 639, 641, 643, 644], "confus": [2, 57, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 326, 332, 337, 376, 378, 380, 383, 384], "other": [2, 3, 5, 6, 7, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 30, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 74, 75, 76, 77, 78, 79, 81, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 106, 107, 108, 109, 110, 112, 116, 120, 123, 126, 129, 130, 131, 135, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 224, 226, 230, 231, 252, 259, 265, 268, 275, 279, 280, 298, 301, 302, 304, 307, 314, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 345, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 391, 402, 404, 409, 412, 564, 565, 569, 577, 588, 589, 592, 594, 608, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 637, 638, 639, 640, 643, 644], "better": [2, 6, 19, 22, 27, 28, 34, 35, 36, 38, 54, 55, 56, 137, 170, 171, 172, 175, 177, 189, 302, 304, 324, 333, 337, 594, 624, 627, 639, 643], "consist": [2, 5, 16, 17, 18, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 80, 83, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 278, 288, 305, 326, 332, 337, 376, 378, 380, 383, 384, 587, 590, 598, 615, 622, 623, 624, 635, 639, 640, 644], "interact": [2, 20, 21, 23, 24, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 83, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 181, 184, 272, 342, 345, 421, 594, 622, 624, 626, 627, 628, 630, 637, 638, 639, 644], "separ": [2, 4, 6, 7, 23, 27, 32, 34, 35, 36, 38, 42, 47, 50, 52, 56, 60, 68, 71, 72, 73, 78, 80, 86, 87, 176, 183, 221, 250, 277, 324, 325, 327, 328, 330, 331, 350, 353, 356, 358, 369, 371, 372, 373, 377, 379, 381, 382, 385, 386, 402, 582, 594, 615, 622, 623, 628, 629, 637, 638, 641, 644], "interchang": [2, 624, 627, 631, 635, 640, 641], "wherea": [2, 51, 52, 63, 83, 88, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 231, 270, 272, 326, 332, 337, 352, 366, 371, 376, 378, 380, 383, 384, 631], "correspond": [2, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 72, 74, 75, 76, 77, 80, 83, 85, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 250, 265, 270, 272, 277, 279, 280, 301, 302, 304, 306, 312, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 352, 354, 357, 358, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 403, 567, 622, 623, 624, 626, 627, 629, 630, 631, 637, 638, 639, 640], "sub": [2, 3, 6, 21, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 71, 78, 83, 88, 108, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 251, 270, 271, 280, 326, 332, 337, 346, 347, 376, 378, 380, 383, 384, 406, 416, 568, 570, 573, 574, 576, 578, 581, 583, 589, 622, 623, 624, 630, 636, 643, 644], "doesn": [2, 23, 32, 35, 36, 38, 88, 114, 120, 123, 126, 130, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 282, 326, 329, 332, 337, 376, 378, 380, 383, 384, 583, 626, 627], "understood": [2, 622], "basi": [2, 114, 641, 643], "we": [2, 6, 12, 17, 18, 19, 21, 22, 24, 26, 28, 30, 53, 54, 56, 60, 65, 68, 72, 73, 78, 79, 83, 85, 88, 95, 107, 109, 114, 120, 121, 122, 123, 126, 127, 130, 134, 136, 137, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 226, 241, 250, 253, 259, 270, 275, 278, 279, 280, 282, 304, 306, 324, 326, 332, 337, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 393, 420, 567, 570, 578, 593, 594, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 636, 637, 638, 639, 640, 641, 643, 644], "anoth": [2, 18, 21, 22, 27, 37, 39, 40, 41, 46, 49, 54, 74, 83, 87, 96, 102, 108, 120, 123, 126, 129, 130, 131, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 196, 218, 227, 229, 230, 232, 265, 271, 305, 342, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 403, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 417, 419, 622, 624, 625, 626, 628, 629, 636, 637, 638, 639, 644], "wise": [2, 244, 380], "requir": [2, 4, 6, 17, 18, 22, 23, 26, 27, 32, 34, 35, 36, 37, 38, 39, 40, 42, 44, 46, 47, 49, 50, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 81, 83, 86, 87, 88, 96, 101, 102, 108, 109, 120, 123, 126, 130, 134, 138, 145, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 225, 226, 239, 250, 262, 265, 270, 271, 272, 275, 277, 280, 302, 304, 305, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 344, 345, 346, 347, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 391, 393, 395, 404, 419, 420, 475, 583, 588, 589, 594, 622, 623, 624, 625, 627, 628, 629, 631, 634, 635, 637, 638, 639, 641, 643, 644], "method": [2, 6, 16, 20, 21, 22, 23, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 108, 109, 110, 111, 112, 114, 116, 120, 123, 126, 129, 130, 131, 132, 137, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 209, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 233, 234, 235, 236, 237, 240, 241, 243, 244, 246, 249, 250, 251, 252, 253, 254, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 295, 297, 298, 301, 302, 304, 313, 314, 317, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 343, 344, 345, 346, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 363, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 391, 392, 402, 403, 409, 421, 563, 567, 568, 569, 570, 571, 573, 574, 575, 576, 577, 578, 581, 582, 583, 585, 587, 589, 592, 608, 615, 620, 623, 624, 625, 626, 627, 628, 629, 630, 631, 634, 637, 639, 641, 644], "op": [2, 6, 7, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 57, 58, 59, 61, 62, 63, 64, 74, 75, 76, 77, 186, 245, 278, 286, 301, 393, 419, 567, 569, 571, 572, 577, 579, 587, 626], "sinc": [2, 3, 6, 19, 21, 23, 24, 26, 30, 32, 34, 35, 36, 38, 41, 52, 53, 54, 56, 65, 68, 72, 73, 78, 85, 86, 87, 88, 101, 102, 109, 114, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 155, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 212, 227, 286, 287, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 348, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 393, 568, 570, 573, 574, 575, 576, 578, 581, 583, 589, 594, 622, 623, 624, 625, 626, 627, 628, 629, 634, 637, 639, 640, 641, 643, 644], "goal": [2, 17, 23, 78, 79, 80, 81, 82, 83, 84, 85, 138, 179, 264, 622, 623, 624, 625, 634, 638, 639], "policy_devic": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 422, 423, 424, 425, 623], "explicitli": [2, 22, 23, 59, 69, 89, 92, 93, 100, 217, 342, 405, 615, 623, 625, 630, 637, 638, 641], "do": [2, 5, 6, 17, 21, 22, 23, 26, 63, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 177, 178, 179, 180, 193, 195, 196, 212, 214, 226, 251, 265, 270, 278, 279, 284, 302, 304, 345, 366, 376, 378, 380, 384, 386, 393, 588, 589, 594, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 636, 637, 638, 639, 641, 643, 644], "deepcopi": [2, 366, 376, 378, 380, 384, 637], "structur": [2, 6, 7, 11, 12, 16, 17, 22, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 63, 65, 68, 72, 73, 74, 86, 87, 96, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 185, 195, 196, 202, 213, 229, 232, 265, 312, 325, 326, 327, 328, 330, 331, 332, 337, 349, 358, 368, 371, 377, 379, 381, 382, 385, 386, 387, 388, 389, 390, 426, 594, 601, 608, 615, 622, 624, 625, 627, 630, 637, 638, 639, 640], "place": [2, 7, 21, 22, 40, 60, 69, 71, 86, 87, 88, 95, 97, 106, 108, 116, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 217, 225, 233, 250, 265, 271, 272, 275, 277, 278, 279, 325, 326, 327, 328, 329, 330, 331, 332, 337, 341, 344, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 412, 419, 555, 568, 570, 571, 573, 574, 576, 577, 578, 580, 581, 583, 585, 587, 589, 594, 623, 624, 628, 631, 637, 638, 639, 641], "instanti": [2, 6, 7, 17, 22, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 101, 102, 134, 137, 150, 158, 176, 180, 217, 225, 239, 265, 325, 327, 328, 330, 331, 339, 377, 379, 381, 382, 385, 386, 387, 388, 389, 390, 391, 402, 403, 420, 466, 467, 470, 471, 472, 615, 622, 623, 628, 629, 631, 637, 638, 639, 641, 644], "graph": [2, 21, 23, 27, 86, 87, 121, 122, 136, 137, 176, 189, 303, 320, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 384, 385, 622, 626, 639], "reli": [2, 6, 17, 30, 56, 265, 302, 304, 335, 336, 349, 368, 386, 418, 622, 624, 626, 628, 630, 639, 644], "third": [2, 246, 267, 298, 637, 638], "parti": 2, "try": [2, 23, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 60, 71, 86, 87, 176, 325, 326, 327, 328, 330, 331, 332, 337, 377, 379, 381, 382, 385, 594, 622, 623, 624, 626, 629, 630, 635, 637, 638, 639, 643, 644], "limit": [2, 5, 7, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 189, 195, 196, 221, 241, 349, 351, 365, 366, 368, 370, 376, 378, 380, 384, 594, 615, 622, 623, 625, 637, 638, 639], "chart": 2, "show": [2, 7, 30, 35, 36, 38, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 324, 326, 332, 337, 376, 378, 380, 383, 384, 393, 420, 421, 475, 622, 624, 625, 626, 634, 637, 638, 639, 641, 643], "decis": [2, 18, 19, 289, 294, 311, 355, 367, 625, 627, 628, 637, 638, 641, 644], "tree": [2, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 221, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 637, 641], "These": [3, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 80, 85, 117, 163, 250, 277, 280, 376, 378, 380, 384, 594, 601, 608, 615, 622, 624, 637, 638, 639, 641, 644], "gloo": [3, 42, 44, 47, 51, 568, 574, 575, 576], "nccl": [3, 42, 44, 47, 324, 335, 336, 568, 574, 575, 576, 582, 583, 587, 588, 589], "mpi": [3, 42, 44, 47], "launcher": [3, 42, 44, 47, 51], "submitit": [3, 42, 44, 47, 51], "torch": [3, 6, 10, 17, 18, 19, 21, 22, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 104, 107, 108, 109, 114, 115, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 213, 214, 215, 217, 218, 219, 220, 222, 225, 226, 227, 229, 230, 231, 232, 233, 234, 239, 241, 242, 243, 246, 248, 250, 252, 253, 255, 257, 258, 259, 260, 262, 263, 264, 265, 266, 268, 271, 272, 273, 275, 277, 279, 280, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 324, 325, 326, 327, 328, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 395, 406, 413, 414, 421, 466, 467, 470, 471, 472, 491, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 562, 567, 568, 572, 573, 574, 575, 576, 581, 582, 587, 588, 589, 594, 601, 616, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "multiprocess": [3, 5, 6, 22, 35, 36, 37, 38, 42, 44, 47, 50, 68, 69, 72, 73, 78, 85, 95, 96, 97, 98, 120, 127, 128, 150, 154, 158, 279, 280, 567, 568, 569, 570, 573, 575, 576, 577, 615, 622, 623, 624, 625, 630, 637, 638, 639, 640, 644], "mode": [3, 21, 25, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 123, 126, 130, 135, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 264, 272, 279, 280, 295, 302, 303, 304, 310, 317, 319, 320, 321, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 351, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 405, 410, 525, 594, 608, 615, 622, 623, 637, 638, 643, 644], "find": [3, 23, 25, 26, 42, 44, 47, 65, 108, 109, 183, 286, 312, 403, 409, 413, 587, 622, 623, 626, 628, 629, 634, 637, 638], "folder": [3, 86, 87, 163, 176, 221, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 623, 626, 640, 641], "variou": [3, 10, 15, 19, 21, 22, 37, 123, 271, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 374, 376, 378, 380, 384, 393, 564, 565, 596, 618, 622, 623, 624, 626, 627, 628, 629, 631, 637, 638, 641, 644], "machin": [3, 26, 42, 44, 47, 82, 134, 583, 637, 638, 643], "One": [3, 4, 6, 22, 23, 27, 57, 59, 60, 62, 64, 71, 114, 120, 121, 122, 150, 154, 158, 159, 221, 255, 275, 286, 310, 344, 348, 397, 615, 622, 623, 641, 644], "wonder": 3, "why": [3, 22, 212, 637, 639, 644], "instead": [3, 21, 22, 23, 26, 27, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 52, 53, 54, 57, 59, 66, 83, 86, 87, 88, 101, 102, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 236, 282, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 316, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 344, 348, 349, 351, 352, 354, 357, 358, 359, 364, 365, 368, 369, 370, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 390, 566, 625, 626, 627, 628, 632, 639, 641, 644], "gener": [3, 5, 6, 16, 17, 21, 22, 26, 27, 28, 32, 34, 35, 36, 38, 42, 44, 47, 50, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 105, 107, 120, 123, 126, 127, 130, 138, 142, 143, 144, 147, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 213, 215, 218, 225, 227, 229, 230, 234, 239, 241, 244, 246, 252, 253, 258, 259, 263, 265, 269, 271, 273, 278, 280, 287, 295, 302, 304, 306, 310, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 337, 340, 342, 345, 363, 369, 377, 379, 380, 381, 382, 383, 384, 385, 386, 396, 409, 416, 433, 594, 596, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "lower": [3, 15, 22, 50, 58, 101, 102, 224, 279, 280, 315, 316, 348, 368, 624, 637, 639], "io": [3, 30, 78, 83, 136, 137, 145, 148, 149, 161, 162, 202, 626], "footprint": [3, 641], "need": [3, 4, 6, 7, 17, 18, 19, 20, 21, 22, 23, 26, 27, 29, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 65, 68, 69, 72, 73, 74, 86, 87, 88, 95, 110, 114, 120, 123, 126, 130, 134, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 224, 226, 227, 236, 242, 250, 253, 266, 270, 271, 272, 277, 279, 280, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 313, 314, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 341, 342, 344, 348, 358, 370, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 393, 402, 416, 566, 575, 577, 589, 594, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 637, 638, 639, 641, 643, 644], "commun": [3, 18, 22, 46, 49, 86, 87, 138, 150, 154, 158, 176, 179, 324, 325, 327, 328, 330, 331, 335, 336, 377, 379, 381, 382, 385, 567, 570, 572, 575, 577, 579, 581, 582, 587, 588, 589, 593, 615, 624, 644], "yet": [3, 6, 121, 122, 136, 330, 331, 383, 640], "spec": [3, 16, 19, 22, 34, 35, 36, 38, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 87, 88, 120, 121, 122, 123, 126, 128, 129, 130, 131, 132, 135, 136, 137, 138, 144, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 209, 212, 213, 214, 215, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 232, 233, 234, 236, 238, 240, 241, 242, 243, 244, 246, 248, 250, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 286, 297, 298, 301, 302, 304, 312, 313, 314, 316, 325, 327, 328, 330, 331, 339, 340, 342, 343, 344, 345, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 383, 594, 601, 622, 623, 624, 625, 626, 627, 628, 632, 634, 636, 637, 638, 643], "plai": [3, 19, 152, 153, 160, 170, 221, 623, 624, 629, 641, 644], "role": [3, 19, 87, 89, 143, 170, 172, 175, 183, 190, 195, 196, 197, 332, 337, 384, 623, 629, 635, 644], "opposit": [3, 637], "direct": [3, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 366, 376, 378, 380, 383, 384, 623, 629, 635], "vector": [3, 16, 21, 27, 57, 64, 121, 122, 131, 136, 137, 141, 152, 153, 155, 163, 164, 231, 278, 280, 290, 292, 305, 386, 389, 592, 622, 623, 625, 636, 637, 638, 639, 640, 644], "share": [3, 6, 7, 15, 19, 21, 25, 27, 32, 34, 35, 36, 38, 50, 52, 56, 68, 69, 72, 73, 74, 86, 87, 90, 93, 95, 96, 97, 98, 102, 104, 108, 110, 112, 116, 127, 150, 158, 171, 172, 175, 176, 185, 192, 193, 194, 195, 262, 270, 279, 280, 283, 284, 285, 302, 304, 325, 327, 328, 330, 331, 349, 350, 351, 352, 353, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 377, 379, 381, 382, 385, 403, 433, 468, 470, 471, 472, 566, 568, 569, 570, 571, 573, 574, 575, 576, 577, 578, 581, 583, 584, 585, 586, 589, 594, 615, 624, 626, 632, 634, 635, 636, 637, 638, 643, 644], "among": [3, 18, 63, 152, 153, 270, 358, 371, 637, 638], "achiev": [3, 4, 21, 23, 88, 120, 123, 126, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 264, 287, 326, 332, 337, 342, 376, 378, 380, 383, 384, 412, 622, 623, 624, 625, 626, 634, 637, 638, 639, 641, 643, 644], "prohibit": [3, 21, 114], "slow": [3, 22, 23, 30, 86, 87, 96, 108, 109, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "compar": [3, 21, 22, 83, 114, 350, 352, 364, 369, 371, 372, 373, 410, 615, 622, 624, 626, 628, 629, 637, 638, 641, 644], "gpu": [3, 26, 27, 53, 55, 88, 95, 97, 116, 120, 123, 126, 130, 131, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 243, 324, 326, 329, 332, 333, 334, 337, 376, 378, 380, 383, 384, 402, 582, 588, 589, 622, 624, 625, 637, 638, 644], "nativ": [3, 6, 16, 26, 28, 81, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 324, 337, 393, 625, 641], "driver": [3, 26], "mean": [3, 5, 6, 7, 17, 19, 21, 22, 23, 26, 32, 34, 35, 36, 38, 39, 42, 44, 47, 50, 52, 72, 74, 78, 86, 87, 96, 101, 102, 108, 109, 114, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 183, 217, 246, 270, 279, 280, 286, 295, 299, 302, 304, 311, 319, 320, 325, 327, 328, 330, 331, 342, 345, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 377, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 409, 420, 568, 569, 570, 573, 574, 576, 578, 579, 581, 583, 589, 622, 623, 624, 626, 628, 637, 638, 639, 641, 644], "keyword": [3, 6, 21, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 93, 95, 96, 97, 98, 101, 102, 106, 108, 109, 112, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 206, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 244, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 286, 287, 297, 301, 302, 304, 306, 312, 313, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 340, 341, 342, 344, 345, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 398, 400, 401, 403, 416, 420, 421, 563, 622, 623, 624, 626, 628, 631, 637, 638, 641, 643, 644], "given": [3, 4, 12, 22, 35, 36, 38, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 109, 120, 123, 126, 130, 138, 144, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 225, 231, 239, 246, 250, 265, 269, 271, 272, 273, 275, 277, 279, 280, 286, 287, 297, 298, 299, 301, 302, 304, 314, 317, 318, 322, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 344, 345, 346, 347, 353, 354, 356, 366, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 403, 407, 410, 562, 622, 623, 624, 627, 628, 629, 630, 631, 638, 639, 644], "mani": [3, 7, 16, 18, 19, 22, 23, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 68, 86, 87, 121, 122, 124, 125, 126, 129, 131, 132, 136, 137, 145, 146, 155, 176, 178, 183, 185, 265, 325, 327, 328, 330, 331, 349, 351, 358, 365, 368, 377, 379, 380, 381, 382, 385, 418, 570, 615, 622, 623, 624, 626, 627, 628, 630, 632, 637, 638, 639, 641, 643, 644], "eg": [3, 17, 22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 124, 125, 126, 129, 130, 131, 132, 134, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 231, 263, 272, 282, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 393], "gymnasium": [3, 17, 18, 22, 24, 32, 34, 35, 36, 38, 52, 120, 123, 126, 129, 130, 131, 135, 138, 139, 140, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 175, 178, 179, 180, 211, 234, 259, 263, 278, 282, 448, 623, 624, 626, 639, 643, 644], "warn": [3, 22, 35, 36, 38, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 272, 279, 286, 301, 312, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 405, 623, 634, 635], "quickli": [3, 22, 623, 637, 638, 644], "becom": [3, 22, 23, 50, 402, 403, 615, 637, 638, 644], "quit": [3, 22, 30, 78, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 622, 623, 624, 626, 628, 637, 638, 644], "annoi": [3, 22], "By": [3, 17, 21, 22, 34, 37, 39, 40, 41, 46, 49, 60, 64, 71, 88, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 142, 143, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 244, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 345, 366, 376, 378, 380, 383, 384, 405, 410, 566, 594, 622, 625, 637, 640, 641, 644], "filter": [3, 21, 22, 23, 102, 108, 109, 349, 350, 352, 353, 357, 358, 364, 368, 369, 371, 380, 402, 627], "out": [3, 17, 19, 21, 22, 23, 24, 28, 37, 39, 40, 41, 46, 49, 50, 54, 55, 79, 83, 86, 87, 88, 93, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 262, 265, 286, 297, 298, 306, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 344, 345, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 622, 623, 624, 625, 626, 627, 628, 630, 637, 638, 639, 641, 643, 644], "still": [3, 17, 22, 28, 75, 83, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 270, 272, 312, 326, 332, 337, 365, 366, 376, 378, 380, 384, 594, 622, 623, 625, 636, 639, 641, 644], "wish": [3, 22, 30, 32, 35, 36, 38, 83, 211, 629, 641], "displai": [3, 22, 26, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 416, 622, 623, 634, 638, 639], "filter_warnings_subprocess": [3, 22], "simplest": [4, 114, 326, 332, 337, 348, 376, 378, 380, 384, 622, 624, 628, 637, 638, 641, 644], "transit": [4, 35, 36, 38, 79, 83, 88, 102, 109, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 317, 323, 326, 332, 337, 376, 378, 380, 383, 384, 622, 625, 627, 628, 630, 637, 639, 641], "sampl": [4, 5, 7, 10, 11, 15, 23, 27, 28, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 95, 96, 97, 101, 102, 103, 106, 107, 108, 109, 112, 114, 116, 120, 123, 126, 130, 138, 144, 147, 150, 151, 154, 158, 159, 160, 167, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 210, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 280, 286, 295, 297, 298, 301, 303, 306, 310, 311, 312, 313, 314, 315, 316, 317, 320, 321, 326, 329, 332, 337, 340, 342, 344, 345, 349, 350, 351, 352, 353, 354, 356, 365, 367, 368, 372, 373, 376, 380, 383, 406, 412, 416, 418, 421, 431, 432, 435, 436, 437, 477, 555, 592, 622, 623, 624, 625, 626, 627, 628, 630, 632, 637, 638, 640, 643, 644], "attent": [4, 27, 178, 221, 326, 332, 337, 380, 622, 625, 635, 644], "built": [4, 7, 10, 16, 17, 21, 24, 26, 69, 86, 87, 121, 122, 129, 136, 137, 147, 148, 176, 317, 325, 327, 328, 330, 331, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 384, 385, 560, 562, 563, 566, 594, 601, 615, 622, 623, 624, 625, 626, 629, 631, 634, 639, 641, 644], "flatten": [4, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 114, 176, 218, 236, 325, 327, 328, 330, 331, 338, 377, 379, 381, 382, 383, 385, 386, 412, 584, 585, 594, 626, 638], "suffici": [4, 18, 23, 622], "preprocess": [4, 10, 16, 78, 79, 80, 81, 82, 83, 84, 85, 271, 623, 626], "popul": [4, 17, 34, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 178, 240, 265, 295, 366, 376, 378, 380, 384, 622, 624, 625, 628, 630, 639, 641], "replaybuff": [4, 10, 12, 21, 32, 34, 35, 36, 38, 50, 52, 53, 65, 66, 67, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 95, 96, 101, 102, 103, 108, 109, 118, 221, 251, 255, 354, 359, 402, 420, 421, 433, 560, 562, 624, 626, 630, 632, 637, 638, 640, 641, 643], "lazytensorstorag": [4, 10, 12, 32, 34, 35, 36, 38, 52, 65, 68, 72, 73, 101, 108, 109, 114, 255, 421, 429, 624, 626, 632, 637, 638, 641], "lambda": [4, 6, 32, 34, 35, 36, 38, 50, 51, 52, 53, 68, 114, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 183, 211, 218, 226, 227, 239, 241, 265, 273, 280, 282, 287, 297, 313, 326, 332, 337, 341, 342, 360, 362, 363, 372, 376, 378, 380, 384, 386, 389, 391, 419, 420, 562, 570, 587, 594, 622, 623, 625, 626, 637, 638, 640, 641, 643, 644], "reshap": [4, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 108, 114, 218, 302, 304, 305, 391, 594, 624, 626, 637, 638], "extend": [4, 7, 10, 27, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 94, 95, 98, 101, 102, 104, 108, 109, 112, 114, 115, 118, 119, 170, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 220, 255, 271, 366, 376, 378, 380, 383, 384, 412, 420, 587, 588, 594, 596, 604, 622, 623, 624, 626, 630, 632, 637, 638, 640, 641, 643], "slice": [4, 10, 17, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 83, 102, 108, 109, 214, 220, 221, 325, 436, 437, 625, 641], "recommend": [4, 5, 23, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 68, 72, 73, 86, 87, 108, 114, 134, 150, 158, 170, 171, 172, 175, 176, 189, 221, 324, 325, 327, 328, 330, 331, 332, 335, 336, 337, 351, 368, 377, 378, 379, 380, 381, 382, 385, 594, 615, 630, 635, 637, 638], "multidimension": [4, 72, 101, 102, 641], "slicesampl": [4, 10, 78, 102, 109, 221, 436, 625, 641], "sampler": [4, 7, 10, 13, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 95, 96, 97, 98, 101, 102, 103, 106, 107, 108, 109, 110, 112, 114, 116, 221, 251, 354, 359, 433, 440, 622, 624, 625, 637, 638, 641], "ensur": [4, 7, 17, 21, 33, 42, 43, 44, 45, 46, 47, 48, 49, 65, 72, 88, 101, 102, 107, 120, 123, 126, 130, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 221, 250, 263, 272, 275, 279, 280, 297, 302, 304, 324, 326, 332, 337, 351, 365, 368, 376, 378, 380, 383, 384, 402, 568, 570, 571, 573, 574, 576, 581, 582, 583, 587, 589, 590, 594, 598, 615, 623, 624, 625, 639, 641], "clearli": 4, "dimension": [4, 65, 68, 72, 73, 178, 231, 302, 304, 386, 638], "num_slic": [4, 78, 83, 102, 108, 109, 436, 437, 641], "trajectory_kei": [4, 56, 108, 109], "traj_id": [4, 17, 34, 35, 38, 52, 56, 218, 255, 630, 641], "dim": [4, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 108, 176, 190, 205, 221, 222, 244, 248, 261, 262, 265, 274, 279, 325, 327, 328, 330, 331, 341, 377, 379, 381, 382, 385, 483, 484, 505, 509, 522, 523, 527, 534, 566, 594, 623, 624, 626, 637, 639, 641], "ndim": [4, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 95, 97, 101, 102, 114, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 244, 341, 427, 429, 441], "regular": [4, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 86, 87, 88, 101, 106, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 296, 298, 302, 304, 313, 314, 325, 327, 328, 329, 330, 331, 344, 345, 359, 368, 377, 379, 381, 382, 383, 384, 385, 419, 420, 421, 622, 623, 626, 627, 628, 632, 634, 641, 644], "behav": [4, 22, 132, 144, 310, 357, 364, 366, 376, 378, 380, 384, 626, 640], "accordingli": [4, 22, 86, 87, 102, 174, 176, 227, 244, 263, 264, 313, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 625], "3": [4, 18, 19, 20, 22, 25, 26, 29, 30, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 97, 101, 102, 108, 109, 114, 116, 120, 123, 124, 125, 126, 129, 130, 131, 132, 133, 138, 141, 142, 143, 145, 147, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 206, 215, 217, 218, 221, 225, 226, 227, 231, 233, 234, 239, 241, 246, 248, 250, 252, 253, 255, 258, 259, 262, 263, 264, 265, 268, 270, 271, 272, 273, 275, 277, 280, 282, 283, 284, 285, 287, 288, 290, 291, 292, 294, 297, 298, 300, 302, 303, 304, 305, 306, 307, 310, 314, 320, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 339, 340, 342, 343, 344, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 393, 402, 414, 466, 483, 506, 568, 569, 570, 572, 573, 574, 575, 576, 578, 581, 583, 589, 601, 615, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 637, 638, 639, 640, 641, 642, 643, 644], "isn": [4, 22, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 83, 86, 87, 101, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 217, 233, 239, 297, 325, 327, 328, 330, 331, 344, 377, 379, 381, 382, 385, 386, 628, 629, 631, 637, 638], "fulli": [4, 6, 27, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 623, 626, 629, 639, 641], "ani": [4, 6, 7, 12, 17, 18, 19, 21, 22, 24, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 94, 95, 96, 97, 98, 104, 107, 109, 110, 112, 114, 115, 116, 118, 119, 120, 123, 126, 127, 130, 131, 138, 145, 150, 151, 152, 153, 154, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 213, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 236, 237, 239, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 280, 282, 287, 288, 294, 295, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 345, 346, 347, 349, 350, 351, 352, 353, 354, 356, 357, 358, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 389, 391, 393, 398, 402, 403, 409, 416, 418, 419, 420, 422, 423, 424, 425, 427, 429, 433, 436, 437, 438, 439, 440, 441, 442, 444, 448, 452, 466, 467, 468, 470, 471, 472, 474, 475, 480, 487, 488, 489, 526, 533, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 586, 587, 588, 589, 593, 615, 622, 623, 624, 625, 626, 628, 629, 634, 637, 638, 639, 641, 643, 644], "consecut": [4, 17, 78, 107, 134, 304, 312, 393, 625, 627, 630, 638, 641, 644], "won": [4, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 83, 86, 87, 88, 120, 123, 126, 127, 129, 130, 138, 145, 146, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 277, 325, 326, 327, 328, 330, 331, 332, 337, 349, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 416, 566, 623, 624, 627, 628], "therebi": [4, 391, 622, 623], "interrupt": [4, 130, 180, 341, 402, 403], "asyncdatacollector": 5, "asynccollector": [5, 422], "_multidatacollector": 5, "It": [5, 7, 11, 17, 20, 21, 22, 23, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 106, 114, 119, 120, 123, 126, 130, 132, 138, 144, 145, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 208, 212, 215, 218, 220, 221, 233, 239, 241, 246, 251, 264, 270, 272, 278, 280, 286, 290, 292, 298, 299, 301, 312, 314, 315, 316, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 345, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 391, 401, 402, 409, 410, 420, 468, 570, 571, 573, 574, 576, 581, 583, 589, 592, 593, 594, 596, 622, 623, 625, 626, 627, 637, 638, 639, 640, 641, 643, 644], "cartpol": [5, 6, 7, 18, 20, 22, 30, 35, 36, 38, 120, 123, 124, 125, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 218, 221, 226, 258, 264, 279, 341, 391, 570, 623, 625, 628, 630, 631, 632, 641, 644], "sync_collector": [5, 35, 36, 38], "1000": [5, 23, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 68, 90, 95, 96, 101, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 279, 286, 301, 312, 342, 345, 421, 530, 570, 622, 623, 624, 625, 626, 628, 630, 632, 635, 639, 640, 641], "100000": [5, 7, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 421, 623], "async_collector": [5, 35, 36, 38], "comparison": [5, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 326, 332, 337, 366, 376, 378, 380, 383, 384, 622, 623], "older": [5, 26, 282], "throughput": [5, 28, 137, 324, 333, 337, 622], "slowest": 5, "higher": [5, 22, 23, 101, 102, 177, 188, 196, 224, 324, 326, 332, 337, 348, 378, 380, 384, 622, 623, 624, 637, 641, 644], "allow": [5, 6, 7, 12, 16, 17, 18, 20, 21, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 63, 64, 68, 69, 70, 71, 72, 73, 78, 83, 86, 87, 88, 89, 96, 102, 106, 108, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 212, 217, 218, 253, 280, 305, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 570, 594, 615, 622, 624, 625, 626, 627, 628, 629, 635, 637, 638, 639, 641, 643, 644], "start": [5, 6, 20, 21, 22, 23, 24, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 66, 74, 78, 85, 101, 102, 108, 109, 120, 123, 126, 127, 130, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 214, 228, 318, 374, 411, 568, 570, 571, 572, 573, 574, 575, 576, 578, 579, 581, 582, 583, 587, 589, 592, 621, 622, 623, 625, 626, 633, 638, 639, 641, 642, 644], "get": [5, 6, 18, 19, 21, 22, 23, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 60, 65, 68, 71, 78, 79, 83, 86, 87, 88, 95, 97, 102, 108, 109, 110, 112, 114, 116, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 188, 190, 194, 195, 196, 201, 215, 220, 222, 226, 229, 231, 232, 241, 246, 251, 264, 265, 268, 272, 279, 280, 301, 313, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 340, 342, 345, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 393, 397, 402, 403, 404, 568, 570, 571, 573, 574, 576, 577, 578, 581, 583, 587, 589, 592, 594, 608, 621, 622, 623, 624, 625, 626, 633, 635, 637, 638, 639, 641, 642, 643, 644], "rid": [5, 326, 332, 337, 376, 378, 380, 384], "natur": [5, 18, 33, 42, 43, 44, 45, 47, 48, 170, 186, 622, 628, 629, 630, 641], "background": [5, 32, 33, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 53, 190, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589, 641], "simpli": [5, 6, 7, 20, 22, 25, 86, 87, 112, 114, 119, 176, 182, 234, 259, 278, 325, 327, 328, 330, 331, 366, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 622, 624, 629, 634, 637, 638, 644], "replay_buff": [5, 7, 27, 32, 34, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 221, 412, 419, 420, 421, 422, 423, 424, 425, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 475, 562, 622, 623, 624, 625, 630, 637, 638, 641], "rb": [5, 32, 34, 35, 36, 38, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 96, 101, 102, 108, 109, 114, 221, 255, 623, 625, 626, 630, 632, 638, 640, 641, 643], "paus": [5, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "sleep": [5, 32, 34, 35, 36, 38, 52, 66, 127, 644], "10": [5, 6, 18, 20, 26, 51, 56, 57, 59, 61, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 101, 108, 109, 114, 116, 120, 121, 122, 123, 126, 127, 130, 136, 137, 138, 144, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 183, 185, 188, 190, 192, 193, 197, 214, 215, 218, 220, 221, 226, 227, 264, 266, 267, 268, 279, 280, 287, 289, 290, 292, 294, 296, 301, 302, 304, 306, 311, 312, 325, 327, 328, 330, 331, 342, 345, 348, 350, 354, 356, 363, 368, 369, 370, 373, 377, 378, 379, 380, 381, 382, 385, 386, 387, 388, 389, 393, 402, 406, 467, 470, 471, 472, 477, 482, 525, 543, 569, 615, 616, 622, 623, 624, 625, 626, 627, 628, 632, 637, 639, 641, 643, 644], "rang": [5, 6, 17, 19, 23, 27, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 97, 114, 120, 123, 126, 127, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 185, 255, 268, 279, 282, 325, 327, 328, 330, 331, 365, 372, 373, 377, 379, 381, 382, 385, 622, 624, 625, 626, 629, 630, 632, 637, 638, 639, 641, 643], "optim_step": [5, 623, 626, 632], "rest": [5, 7, 32, 35, 36, 38, 624, 625, 637, 639, 643], "multithread": [5, 22, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 145, 146, 630, 641], "mind": [5, 21, 22, 78, 83, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 637, 638], "gil": 5, "relat": [5, 19, 22, 23, 29, 60, 65, 150, 175, 236, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 623, 632, 639], "restrict": [5, 22, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 623, 634, 640, 641, 644], "hand": [5, 19, 26, 50, 60, 637, 638, 639], "let": [5, 6, 7, 19, 25, 26, 30, 56, 65, 68, 72, 73, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 297, 326, 332, 337, 376, 378, 380, 383, 384, 410, 594, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "child": [5, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 623], "fill": [5, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 130, 180, 217, 265, 278, 304, 386, 625, 639, 640], "truli": [5, 278, 402, 643], "decoupl": [5, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 52, 622, 629, 643], "been": [5, 18, 24, 26, 27, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 107, 120, 123, 126, 130, 134, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 241, 243, 263, 264, 271, 272, 302, 304, 341, 349, 366, 368, 370, 376, 378, 380, 384, 402, 567, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589, 622, 623, 624, 625, 636, 637, 638, 639, 641, 643, 644], "shut": [5, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 154, 159, 402], "down": [5, 23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 154, 159, 402, 625, 627], "async_shutdown": [5, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 66], "drastic": [5, 6, 137, 150, 641], "hardwar": [5, 17, 626], "load": [5, 6, 25, 26, 32, 34, 35, 36, 38, 52, 53, 54, 55, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 95, 96, 97, 98, 110, 111, 112, 116, 117, 120, 123, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 279, 280, 324, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 416, 418, 420, 421, 566, 585, 594, 597, 622, 624, 626, 634, 635, 641], "factor": [5, 27, 30, 255, 286, 301, 303, 312, 320, 321, 350, 356, 359, 360, 362, 420, 622, 623, 626, 628, 632, 637, 638, 641, 644], "signific": [5, 21, 24, 27, 615, 624, 643, 644], "understand": [5, 6, 19, 27, 33, 42, 43, 44, 45, 47, 48, 615, 622, 623, 626, 627, 628, 634, 637, 638], "affect": [5, 22, 27, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 272, 280, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 402, 637], "legitim": [5, 644], "unless": [5, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 86, 87, 88, 92, 107, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 280, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 352, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 624], "benchmark": [5, 18, 22, 28, 121, 122, 130, 136, 137, 180], "pipelin": [6, 19, 26, 130, 180, 333, 376, 594, 598, 624], "typic": [6, 17, 22, 23, 27, 33, 34, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 81, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 233, 264, 326, 332, 337, 342, 350, 352, 366, 368, 371, 376, 378, 380, 383, 384, 420, 575, 582, 589, 594, 624, 626, 627, 629, 630, 635, 637, 638, 639], "big": [6, 624, 630, 641, 644], "bucket": [6, 171], "send": [6, 22, 27, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 86, 87, 154, 159, 176, 324, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 401, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 581, 583, 586, 588, 589, 643], "occasion": 6, "tradit": [6, 629, 637], "neural": [6, 7, 141, 152, 153, 288, 344, 386, 601, 623, 624, 625, 628, 637, 638, 639, 644], "both": [6, 7, 18, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 54, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 127, 129, 130, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 161, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 214, 221, 239, 253, 269, 270, 272, 283, 284, 285, 288, 298, 302, 304, 305, 314, 324, 326, 332, 334, 337, 349, 351, 352, 353, 357, 358, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 402, 403, 409, 410, 419, 475, 572, 575, 577, 580, 581, 587, 588, 589, 594, 615, 622, 624, 626, 627, 629, 634, 635, 637, 638, 639, 640, 641, 644], "anyth": [6, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50], "happen": [6, 7, 18, 21, 22, 33, 34, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 282, 312, 418, 569, 575, 623, 626, 629, 630, 631, 640, 644], "held": 6, "datacollector": [6, 32, 34, 35, 36, 38, 50, 52, 53, 368, 624, 630, 641], "receiv": [6, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 271, 272, 280, 305, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 587, 589, 622, 624, 629, 636, 639], "postprocess": [6, 34], "hook": [6, 37, 39, 40, 41, 46, 49, 54, 55, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 117, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 348, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 475, 592, 616], "itself": [6, 21, 34, 42, 47, 50, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 325, 326, 327, 328, 330, 331, 332, 337, 366, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 624, 627], "transfer": [6, 55, 86, 87, 176, 303, 320, 325, 327, 328, 330, 331, 345, 377, 379, 381, 382, 385, 572, 575, 582, 583, 587, 588], "think": [6, 21, 87, 170, 172, 174, 175, 177, 183, 593, 594, 624, 637, 638, 644], "world": [6, 19, 24, 144, 323, 324, 333, 361, 402, 592, 601, 615, 626, 631, 637, 638, 639, 644], "engin": [6, 26, 54, 55, 155, 324, 333, 334, 337, 383, 582, 583, 585, 587, 588, 589, 594, 634, 639], "veri": [6, 12, 15, 18, 19, 22, 86, 87, 136, 137, 175, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 623, 627, 630, 634, 637, 639, 641, 643, 644], "kernel": [6, 288], "forward": [6, 16, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 240, 241, 243, 246, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 317, 322, 324, 326, 332, 337, 338, 341, 342, 344, 345, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 625, 626, 639, 643], "format": [6, 10, 20, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 62, 64, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 92, 93, 100, 106, 114, 120, 123, 126, 130, 138, 150, 151, 152, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 203, 221, 225, 250, 265, 271, 272, 275, 277, 326, 330, 332, 337, 344, 376, 378, 380, 383, 384, 393, 580, 590, 594, 596, 597, 598, 608, 622, 623, 626, 627, 629, 631, 634, 643, 644], "quantiz": 6, "much": [6, 22, 27, 32, 35, 36, 38, 65, 72, 83, 86, 87, 101, 102, 150, 158, 176, 325, 327, 328, 330, 331, 365, 368, 377, 379, 381, 382, 385, 624, 626, 627, 631, 637, 638, 639, 641, 644], "cannot": [6, 18, 22, 23, 26, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 60, 62, 64, 68, 72, 73, 90, 97, 98, 102, 104, 108, 109, 116, 120, 123, 126, 129, 130, 131, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 229, 232, 251, 258, 270, 313, 349, 352, 368, 623, 624, 625, 626, 637, 638, 639], "dump": [6, 20, 30, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 93, 95, 96, 97, 98, 110, 112, 116, 176, 190, 194, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 391, 392, 393, 631, 632, 637], "dict": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 102, 108, 109, 120, 123, 126, 127, 128, 129, 130, 131, 138, 142, 143, 145, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 239, 241, 265, 270, 272, 278, 279, 280, 282, 288, 289, 290, 291, 292, 293, 294, 300, 305, 311, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 352, 371, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 397, 398, 402, 403, 404, 410, 416, 418, 419, 420, 421, 422, 423, 424, 425, 442, 466, 467, 475, 514, 557, 558, 564, 565, 566, 568, 570, 571, 573, 574, 576, 577, 578, 580, 581, 582, 583, 584, 587, 588, 589, 590, 615, 622, 623, 624, 641, 643, 644], "who": 6, "activ": [6, 25, 26, 28, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 288, 294, 299, 305, 351, 365, 368, 626, 639, 643], "ask": [6, 22, 27, 78, 83, 102, 108, 109, 332, 393, 624, 625, 627, 628, 637, 638, 640, 644], "push": [6, 55, 384, 587], "intermedi": [6, 23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 220, 287, 298, 302, 304, 317, 326, 332, 337, 376, 378, 380, 384, 622, 626, 640], "approach": [6, 21, 34, 65, 68, 72, 73, 86, 87, 176, 189, 221, 246, 325, 327, 328, 330, 331, 335, 336, 337, 372, 377, 379, 381, 382, 385, 421, 569, 570, 583, 594, 622, 624, 629, 630, 637, 644], "intermediari": 6, "server": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 190], "fetch": [6, 40, 86, 87, 121, 122, 124, 125, 176, 241, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 587, 628, 640, 641, 644], "tri": [6, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 324, 326, 332, 337, 344, 376, 378, 380, 383, 384, 631], "account": [6, 95, 97, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 227, 306, 623, 625, 641, 644], "problem": [6, 18, 26, 27, 28, 34, 175, 380, 623, 624, 625, 630, 637, 638, 639, 641, 644], "manner": [6, 130, 180, 250, 275, 622, 623, 624, 630, 636, 639, 641], "identifi": [6, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 195, 196, 402, 403, 568, 570, 571, 573, 574, 575, 576, 578, 581, 583, 584, 589, 596, 615, 634], "three": [6, 57, 59, 61, 62, 64, 170, 352, 594, 624, 626, 627, 628, 637, 638, 639, 641, 644], "orchestr": [6, 594, 597, 623, 629, 631], "entir": [6, 23, 34, 35, 36, 38, 50, 60, 83, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 280, 571, 594, 624, 627, 639, 641], "includ": [6, 7, 12, 16, 19, 21, 23, 26, 28, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 63, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 95, 96, 97, 98, 100, 110, 112, 116, 120, 123, 126, 130, 138, 144, 148, 149, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 236, 239, 264, 270, 272, 279, 280, 302, 304, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 349, 352, 366, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 403, 409, 420, 475, 555, 594, 596, 600, 606, 622, 623, 624, 625, 626, 634, 635, 637, 638, 639, 641, 644], "coordin": [6, 35, 36, 38, 50, 95, 97, 228, 567, 568, 575, 582, 583, 585, 587, 588, 615], "actual": [6, 17, 18, 21, 23, 26, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 278, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 555, 569, 570, 572, 575, 587, 590, 594, 622, 624, 626, 637, 638, 639], "through": [6, 12, 17, 18, 21, 22, 23, 24, 27, 32, 34, 35, 36, 38, 41, 42, 47, 50, 52, 53, 55, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 120, 121, 122, 123, 126, 129, 130, 131, 134, 136, 137, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 184, 185, 190, 217, 227, 229, 232, 251, 282, 287, 305, 315, 316, 324, 325, 327, 328, 330, 331, 337, 341, 342, 345, 346, 347, 366, 377, 379, 381, 382, 385, 386, 387, 388, 389, 405, 569, 570, 577, 582, 615, 622, 623, 624, 625, 627, 629, 636, 637, 638, 639, 640, 641, 644], "queue": [6, 52, 154, 279, 326, 332, 337, 383, 569, 570, 577, 615, 641, 643], "determin": [6, 22, 35, 36, 38, 39, 65, 72, 79, 86, 87, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 174, 175, 176, 178, 179, 180, 183, 186, 250, 277, 312, 325, 326, 327, 328, 330, 331, 332, 337, 352, 377, 379, 380, 381, 382, 385, 581, 623, 628, 637, 638], "state_dict": [6, 32, 34, 35, 36, 38, 50, 52, 53, 54, 55, 86, 87, 88, 90, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 418, 566, 570, 571, 573, 574, 576, 580, 581, 583, 589, 590, 622, 623, 644], "extract": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 60, 71, 80, 102, 150, 158, 170, 184, 186, 190, 193, 197, 199, 217, 239, 269, 273, 339, 568, 569, 570, 571, 573, 574, 576, 578, 580, 581, 583, 586, 588, 589, 590, 594, 622, 624, 643], "appli": [6, 7, 10, 21, 22, 23, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 231, 233, 234, 235, 236, 237, 240, 241, 242, 243, 245, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 297, 320, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 391, 409, 411, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 583, 585, 587, 589, 594, 622, 623, 624, 630, 634, 637, 639, 643, 644], "automat": [6, 7, 18, 19, 20, 22, 24, 31, 35, 36, 38, 41, 55, 58, 69, 74, 75, 85, 86, 87, 89, 95, 97, 109, 116, 120, 121, 122, 123, 126, 129, 130, 131, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 174, 175, 176, 178, 179, 180, 191, 217, 229, 232, 246, 265, 278, 280, 302, 304, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 339, 340, 341, 342, 345, 377, 379, 381, 382, 385, 391, 405, 409, 416, 420, 475, 568, 570, 573, 574, 576, 577, 578, 580, 581, 583, 587, 589, 596, 601, 615, 622, 624, 625, 627, 628, 637, 638, 639, 641, 643], "weight_sync_schem": [6, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 419, 420, 422, 423, 424, 425, 475, 567, 568, 570, 571, 572, 573, 574, 575, 576, 578, 579, 581, 583, 589, 594], "intern": [6, 20, 22, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 280, 324, 326, 332, 337, 402, 570, 571, 578, 581, 582, 587, 620], "propag": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 71, 349, 351, 352, 353, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 386, 387, 388, 389, 624, 625, 637, 638], "convent": [6, 22, 78, 79, 80, 81, 82, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 326, 608, 622, 625, 637, 638, 639], "regist": [6, 7, 20, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 209, 212, 229, 232, 233, 258, 270, 272, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 348, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 393, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 568, 570, 573, 574, 576, 578, 581, 583, 586, 588, 589, 594, 615, 616, 622, 624, 627, 641, 644], "posit": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 102, 120, 123, 124, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 226, 236, 237, 239, 261, 262, 263, 266, 270, 272, 274, 307, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384, 402, 403, 624, 637, 638, 639, 641], "policy_modul": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 624, 637, 638], "weights_tensordict": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "clariti": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 272], "actor_modul": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 643], "weights_td": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "model_id": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 568, 569, 570, 571, 573, 574, 575, 576, 578, 581, 582, 583, 584, 589], "actor": [6, 21, 23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 66, 171, 172, 175, 185, 189, 192, 193, 194, 195, 241, 243, 283, 284, 285, 289, 290, 292, 297, 298, 299, 301, 311, 312, 313, 314, 324, 329, 334, 337, 339, 341, 342, 343, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 376, 378, 380, 384, 402, 403, 404, 421, 474, 475, 574, 575, 576, 588, 589, 592, 601, 608, 615, 623, 625, 626, 627, 629, 632, 637, 640, 643], "atom": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "weights_dict": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "actor_td": 6, "critic": [6, 23, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 177, 283, 349, 351, 352, 353, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 380, 421, 474, 475, 572, 592, 601, 608, 615, 622, 629], "critic_td": 6, "primarili": [6, 74, 251, 628], "special": [6, 7, 18, 60, 71, 76, 77, 86, 87, 176, 180, 325, 326, 327, 328, 330, 331, 332, 337, 377, 379, 381, 382, 385, 594, 595, 599, 612, 615, 622, 625, 626, 644], "outsid": [6, 22, 34, 230, 270, 631, 637, 638, 639], "pattern": [6, 89, 190, 197, 567, 568, 570, 572, 573, 575, 576, 577, 582, 592, 594], "clear": [6, 20, 30, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 80, 88, 120, 121, 122, 123, 126, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 402, 407, 615, 627, 630, 635], "local": [6, 23, 26, 29, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 67, 81, 86, 88, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 280, 326, 332, 334, 337, 376, 378, 380, 383, 384, 398, 401, 583, 584, 615, 626, 631, 632, 637, 638], "inter": [6, 22, 150, 154], "base": [6, 10, 11, 12, 16, 19, 21, 22, 23, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 83, 86, 87, 101, 102, 105, 111, 114, 115, 117, 118, 120, 121, 122, 123, 126, 130, 134, 136, 137, 138, 144, 145, 146, 150, 151, 154, 158, 159, 160, 163, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 185, 188, 189, 191, 194, 195, 199, 204, 205, 212, 218, 225, 226, 230, 255, 269, 271, 272, 273, 275, 276, 280, 283, 286, 302, 304, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 352, 353, 354, 356, 357, 358, 360, 364, 368, 369, 370, 371, 372, 373, 377, 379, 381, 382, 385, 386, 387, 388, 389, 390, 401, 402, 403, 416, 420, 426, 430, 440, 441, 443, 447, 476, 532, 567, 568, 569, 570, 571, 573, 574, 576, 577, 578, 580, 581, 583, 584, 585, 587, 589, 592, 601, 608, 610, 615, 622, 623, 625, 627, 628, 629, 631, 634, 635, 637, 638, 639, 641, 644], "tcpstore": [6, 567, 568], "small": [6, 101, 102, 109, 275, 280, 622, 624, 626, 637, 638, 644], "logic": [6, 21, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 89, 571, 573, 574, 576, 581, 583, 589, 637], "sender": [6, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 581, 582, 583, 584, 586, 589, 594], "trigger": [6, 26, 178, 280, 326, 332, 337, 376, 378, 380, 384, 568, 570, 573, 574, 576, 578, 581, 583, 589, 625], "_receive_weights_schem": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "side": [6, 18, 23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 188, 189, 195, 196, 202, 306, 326, 568, 570, 571, 573, 574, 575, 576, 578, 579, 581, 582, 583, 589, 644], "init_on_send": [6, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589], "context": [6, 17, 19, 21, 24, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 109, 120, 123, 126, 127, 130, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 265, 274, 302, 304, 326, 332, 337, 376, 378, 380, 383, 384, 386, 387, 388, 389, 393, 405, 410, 568, 569, 570, 571, 573, 574, 576, 577, 578, 581, 583, 589, 594, 615, 622, 623, 624, 625, 626, 637, 638, 639, 640, 641, 643], "NO": 6, "pickl": [6, 32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 68, 69, 72, 73, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 376, 378, 380, 383, 384], "init": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 66, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 271, 279, 324, 326, 329, 332, 337, 376, 378, 380, 383, 384, 386, 400, 401, 402, 404, 582, 587, 589, 615, 623, 624], "block": [6, 53, 55, 89, 94, 119, 135, 175, 177, 186, 193, 203, 324, 567, 568, 569, 570, 572, 573, 574, 575, 576, 578, 579, 581, 583, 589, 594, 622, 625, 626, 629, 630, 637, 641], "readi": [6, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 170, 324, 568, 570, 571, 573, 574, 576, 578, 581, 583, 584, 587, 589, 593, 623, 624, 626, 628, 631, 641, 643], "init_on_receiv": [6, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589], "resolv": [6, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 419], "handler": 6, "prepar": [6, 25, 80, 170, 173, 195, 196, 384, 568, 570, 571, 573, 574, 576, 578, 581, 583, 588, 589, 594, 624], "without": [6, 17, 18, 19, 22, 26, 28, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 83, 86, 87, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 217, 229, 232, 268, 271, 284, 285, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 339, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 402, 435, 437, 562, 567, 569, 570, 575, 577, 578, 593, 615, 622, 623, 624, 626, 627, 628, 629, 630, 634, 635, 637, 638, 639, 641, 644], "attribut": [6, 17, 19, 21, 22, 23, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 129, 130, 131, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 233, 244, 250, 272, 275, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 345, 349, 350, 352, 353, 354, 356, 358, 359, 360, 363, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 583, 622, 625, 639], "refer": [6, 7, 17, 18, 21, 26, 27, 28, 30, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 123, 126, 129, 130, 131, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 270, 271, 272, 279, 285, 298, 299, 306, 308, 309, 315, 316, 317, 325, 326, 327, 328, 330, 331, 332, 337, 349, 352, 359, 360, 361, 362, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 568, 569, 570, 571, 573, 574, 576, 577, 581, 582, 583, 589, 621, 622, 624, 626, 628, 629, 630, 631, 637, 638, 641], "indic": [6, 12, 17, 18, 20, 22, 27, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 94, 101, 102, 104, 106, 107, 108, 109, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 213, 214, 221, 222, 226, 263, 264, 265, 266, 272, 280, 282, 288, 305, 306, 312, 313, 314, 325, 327, 328, 330, 331, 341, 349, 350, 351, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 556, 566, 593, 615, 624, 625, 626, 630, 631, 632, 639, 641, 644], "primit": [6, 21, 23, 83, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 568, 572], "NOT": [6, 22, 35, 36, 38, 92, 93, 100, 109, 251, 589], "sent": [6, 35, 36, 38, 65, 68, 69, 72, 73, 86, 87, 90, 95, 97, 116, 176, 279, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 568, 569, 570, 572, 573, 574, 576, 577, 578, 579, 581, 583, 589], "explicit": [6, 23, 34, 35, 36, 38, 171, 172, 175, 185, 194, 195, 282, 303, 315, 316, 320, 329, 402, 577, 578, 615, 641], "param": [6, 27, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 273, 280, 295, 319, 325, 326, 327, 328, 330, 331, 332, 337, 342, 344, 347, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 582, 587, 588, 622, 626, 632, 637, 638, 639, 640, 643], "num_work": [6, 7, 35, 36, 38, 46, 49, 78, 79, 80, 81, 82, 83, 84, 85, 145, 150, 158, 194, 424, 425, 442, 581, 622, 623], "inner_collector": 6, "worker_idx": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 581, 583, 589], "simultan": [6, 22, 47, 137, 145, 146, 150, 158, 570, 582, 589, 615, 639], "order": [6, 21, 30, 34, 41, 52, 53, 64, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 107, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 222, 229, 232, 239, 248, 262, 270, 272, 297, 322, 324, 326, 332, 337, 340, 344, 346, 347, 349, 350, 352, 353, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 572, 623, 637, 638], "driven": 6, "exchang": 6, "notabl": [6, 22], "until": [6, 20, 26, 50, 52, 88, 137, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 266, 271, 383, 405, 567, 570, 572, 575, 578, 624, 625, 632, 637, 638], "exact": [6, 22, 56, 150, 615], "sharedmem": 6, "put": [6, 65, 66, 68, 69, 130, 142, 143, 160, 163, 164, 279, 401, 566, 623, 624, 625, 627, 634, 637, 639], "recv": [6, 567, 568, 572, 575], "send_async": [6, 570, 578], "train_step": 6, "new_weight": [6, 191], "zero": [6, 18, 22, 23, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 97, 101, 102, 108, 109, 114, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 218, 220, 222, 226, 229, 231, 232, 246, 252, 255, 262, 280, 291, 292, 293, 300, 301, 302, 303, 304, 306, 312, 314, 320, 325, 326, 327, 328, 330, 331, 332, 337, 345, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 577, 625, 626, 635, 641, 643, 644], "instantan": 6, "none": [6, 18, 21, 22, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 95, 96, 97, 98, 100, 101, 102, 106, 108, 109, 110, 112, 114, 116, 120, 123, 126, 127, 129, 130, 138, 142, 143, 144, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 206, 207, 209, 210, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 228, 229, 230, 232, 236, 238, 239, 241, 242, 243, 246, 247, 248, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 320, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 342, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 397, 398, 399, 402, 403, 409, 410, 411, 412, 413, 414, 416, 418, 419, 420, 421, 422, 423, 424, 425, 427, 428, 429, 430, 431, 433, 436, 437, 440, 441, 442, 444, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 466, 467, 468, 470, 471, 472, 474, 475, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 499, 500, 501, 502, 503, 504, 506, 508, 509, 510, 511, 512, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 545, 547, 549, 551, 552, 553, 556, 557, 558, 559, 561, 562, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 635, 636, 637, 638, 639, 641, 643, 644], "mp": [6, 42, 44, 47, 78, 79, 80, 81, 82, 83, 84, 85, 127, 279, 280, 569, 577], "signal": [6, 17, 32, 34, 35, 36, 38, 56, 78, 79, 81, 83, 84, 85, 102, 108, 109, 114, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 177, 178, 179, 180, 213, 221, 227, 233, 242, 263, 266, 567, 572, 575, 587, 588, 622, 624, 637, 638, 641, 644], "alreadi": [6, 20, 21, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 243, 265, 282, 325, 326, 327, 328, 329, 330, 331, 332, 337, 345, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 402, 403, 567, 577, 615, 622, 624, 631, 637, 638], "part": [6, 7, 12, 20, 21, 22, 23, 27, 78, 80, 81, 83, 84, 85, 88, 102, 120, 121, 123, 126, 130, 136, 138, 148, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 220, 246, 255, 258, 322, 326, 332, 337, 376, 378, 380, 383, 384, 406, 566, 615, 622, 624, 625, 626, 632, 637, 639, 644], "irecv": 6, "return_prematur": 6, "rank": [6, 46, 86, 87, 114, 176, 324, 325, 327, 328, 330, 331, 335, 336, 377, 379, 381, 382, 385, 567, 573, 574, 575, 576, 582, 587, 588, 589], "flag": [6, 7, 17, 19, 27, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 174, 175, 177, 178, 179, 180, 183, 240, 312, 637, 638, 639, 640], "poll": [6, 585, 587], "ref": [6, 324], "connectioninfo": 6, "init_process_group": [6, 575], "isend": [6, 572, 575], "insid": [6, 7, 21, 86, 87, 150, 176, 230, 325, 327, 328, 330, 331, 339, 377, 379, 381, 382, 385, 574, 615, 644], "raymoduletransform": [6, 574], "join": [6, 127, 185, 575, 623, 624, 626, 637], "uniqu": [6, 64, 108, 109, 138, 142, 143, 177, 179, 221, 233, 264, 265, 266, 270, 341, 401, 402, 403, 574, 576, 577, 594, 615, 630, 641], "even": [6, 17, 21, 23, 27, 30, 35, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 90, 95, 96, 97, 98, 102, 108, 110, 112, 116, 120, 123, 126, 127, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 217, 622, 624, 627, 634, 637, 638, 639, 644], "invok": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 67, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 326, 332, 337, 376, 378, 380, 383, 384], "mechan": [6, 23, 32, 34, 35, 36, 37, 38, 39, 40, 46, 49, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 324, 326, 332, 337, 376, 378, 380, 383, 384, 579, 587, 588, 594, 615, 623, 629, 639], "benefit": [6, 101, 102, 593, 627, 635, 637, 638, 641], "cascad": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 568, 570, 573, 574, 576, 578, 581, 583, 589], "grace": [6, 324], "runnabl": 6, "repositori": [6, 26, 80, 81, 82, 85, 163, 164, 637, 638], "weight_sync_standalon": 6, "weight_sync_collector": 6, "seamlessli": [6, 19, 170, 191, 594, 601, 635, 639], "nn": [6, 17, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 66, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 167, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 226, 231, 233, 241, 250, 265, 271, 272, 275, 277, 283, 284, 285, 287, 288, 290, 291, 292, 293, 297, 299, 300, 301, 302, 304, 305, 307, 312, 313, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 342, 344, 345, 346, 347, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 471, 562, 568, 570, 571, 573, 574, 575, 576, 580, 581, 583, 589, 601, 622, 623, 624, 625, 626, 628, 629, 632, 636, 637, 638, 639, 640, 643], "tensordictmodul": [6, 17, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 66, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 220, 226, 241, 283, 284, 285, 287, 297, 302, 304, 313, 314, 317, 323, 326, 332, 337, 341, 342, 344, 346, 347, 348, 350, 352, 353, 357, 358, 360, 361, 362, 363, 364, 366, 369, 371, 372, 373, 376, 378, 380, 384, 386, 387, 388, 389, 410, 471, 562, 601, 622, 624, 625, 629, 632, 636, 637, 638, 639, 640, 644], "weight_upd": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 594], "linear": [6, 21, 32, 34, 35, 36, 38, 50, 52, 53, 66, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 241, 250, 265, 271, 272, 275, 277, 283, 284, 285, 287, 288, 290, 291, 292, 293, 300, 301, 305, 307, 312, 313, 315, 316, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 342, 344, 347, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 562, 601, 623, 626, 636, 640, 643], "observation_spec": [6, 17, 18, 19, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 193, 194, 195, 196, 197, 198, 199, 215, 218, 221, 222, 223, 224, 225, 228, 229, 230, 232, 233, 236, 238, 239, 240, 241, 243, 246, 248, 250, 252, 254, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 278, 279, 280, 302, 304, 383, 556, 562, 622, 624, 629, 636, 637, 638, 639, 644], "observ": [6, 7, 10, 16, 17, 18, 19, 21, 22, 27, 32, 34, 35, 36, 38, 50, 52, 53, 66, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 92, 93, 100, 102, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 193, 194, 195, 196, 197, 198, 199, 207, 212, 214, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 233, 234, 236, 238, 239, 240, 241, 243, 244, 246, 247, 248, 252, 253, 254, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 278, 279, 280, 283, 284, 285, 287, 289, 290, 291, 292, 293, 294, 297, 301, 302, 304, 308, 309, 311, 312, 313, 315, 317, 322, 323, 339, 340, 341, 342, 349, 350, 351, 352, 353, 354, 356, 357, 358, 361, 364, 365, 368, 369, 370, 371, 372, 373, 383, 386, 387, 388, 389, 390, 391, 393, 420, 421, 471, 562, 594, 601, 602, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 636, 637, 638, 639, 641, 643, 644], "action_spec": [6, 17, 18, 19, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 88, 120, 121, 122, 123, 126, 130, 136, 137, 138, 144, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 218, 221, 225, 229, 230, 232, 241, 243, 246, 252, 255, 271, 272, 273, 274, 297, 313, 316, 339, 340, 342, 343, 350, 352, 354, 356, 369, 371, 372, 373, 383, 562, 601, 622, 623, 624, 625, 626, 628, 629, 630, 632, 636, 637, 638, 639, 640, 641, 643, 644], "in_kei": [6, 7, 20, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 66, 69, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 207, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 283, 284, 285, 287, 296, 297, 302, 304, 313, 322, 326, 329, 332, 337, 339, 340, 341, 342, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 363, 364, 365, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 392, 393, 468, 470, 471, 472, 478, 481, 482, 483, 484, 485, 486, 490, 491, 492, 493, 494, 497, 498, 499, 500, 501, 503, 504, 506, 508, 509, 510, 511, 512, 515, 516, 517, 518, 519, 521, 522, 523, 525, 526, 527, 529, 530, 533, 534, 535, 536, 537, 538, 539, 540, 562, 601, 622, 623, 624, 625, 626, 628, 629, 632, 635, 636, 637, 638, 639, 640, 641, 643, 644], "out_kei": [6, 7, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 66, 69, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 207, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 277, 278, 279, 280, 283, 284, 285, 287, 296, 298, 302, 304, 313, 314, 322, 326, 329, 332, 337, 339, 340, 341, 342, 344, 345, 347, 348, 349, 350, 351, 352, 357, 358, 363, 364, 365, 368, 369, 370, 371, 372, 376, 378, 380, 383, 384, 386, 387, 388, 389, 391, 393, 410, 468, 470, 471, 472, 478, 481, 482, 483, 484, 485, 486, 490, 491, 492, 493, 494, 497, 498, 499, 500, 501, 503, 504, 506, 508, 509, 510, 511, 512, 515, 516, 517, 518, 519, 521, 522, 523, 525, 526, 527, 528, 529, 530, 531, 533, 534, 535, 536, 537, 538, 539, 540, 562, 601, 622, 623, 624, 625, 626, 628, 632, 635, 636, 637, 638, 639, 640, 641, 643, 644], "action": [6, 7, 10, 16, 17, 18, 19, 22, 27, 28, 32, 34, 35, 36, 38, 50, 52, 53, 64, 66, 78, 79, 80, 81, 82, 83, 84, 85, 88, 101, 102, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 214, 215, 218, 224, 225, 226, 229, 230, 231, 232, 233, 234, 236, 237, 239, 241, 243, 244, 245, 246, 248, 252, 253, 255, 259, 263, 265, 269, 271, 272, 273, 274, 278, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 301, 302, 304, 305, 306, 311, 312, 313, 314, 316, 317, 319, 320, 322, 326, 332, 337, 339, 340, 341, 342, 343, 345, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 409, 420, 421, 471, 477, 562, 566, 594, 601, 602, 603, 605, 622, 623, 624, 626, 627, 628, 629, 630, 631, 634, 635, 636, 637, 638, 640, 641, 643, 644], "192": [6, 142, 143, 623], "enumer": [6, 34, 35, 38, 50, 52, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 73, 74, 75, 76, 77, 88, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 374, 376, 378, 380, 383, 384, 622, 623, 624, 625, 632, 637, 641, 643], "worker_fn": 6, "overwritten": [6, 42, 44, 47, 50, 78, 80, 81, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 236], "now": [6, 18, 21, 26, 65, 68, 69, 72, 73, 89, 148, 149, 150, 185, 189, 221, 259, 324, 339, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 634, 636, 637, 638, 640, 641, 644], "from_modul": [6, 35, 36, 38, 86, 87, 176, 325, 326, 327, 328, 330, 331, 332, 337, 344, 347, 377, 379, 381, 382, 385, 419, 643], "spawn": [6, 22, 23, 42, 51, 134, 145, 150, 158, 270, 622, 623, 637, 638], "target": [6, 7, 23, 27, 50, 88, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 264, 324, 326, 332, 337, 344, 345, 349, 350, 351, 352, 353, 354, 356, 358, 359, 362, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 415, 421, 555, 561, 562, 625, 626, 632, 637, 639], "arg": [6, 17, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 58, 60, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 102, 108, 109, 110, 112, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 208, 214, 215, 216, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 244, 249, 250, 251, 252, 253, 255, 258, 259, 261, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 274, 275, 276, 277, 278, 279, 283, 284, 285, 286, 287, 288, 295, 296, 297, 298, 301, 302, 304, 305, 312, 313, 314, 317, 322, 323, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 400, 401, 402, 403, 408, 412, 416, 420, 421, 566, 568, 570, 571, 573, 574, 576, 577, 578, 579, 583, 589, 615, 623, 626, 634], "w": [6, 23, 69, 123, 148, 149, 190, 221, 223, 228, 254, 268, 312, 368, 393, 515, 623, 625, 641], "epoch": [6, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 416, 420, 475, 624, 637, 638], "stop": [6, 17, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 85, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 186, 326, 332, 337, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589, 624, 630, 637, 638, 643, 644], "With": [6, 17, 86, 87, 136, 137, 141, 176, 264, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 402, 404, 589, 623, 634, 636, 637, 638, 641, 644], "dictionari": [6, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 60, 86, 87, 88, 89, 102, 106, 108, 109, 120, 123, 126, 129, 130, 131, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 239, 265, 270, 272, 280, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 352, 371, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 410, 418, 564, 565, 566, 580, 623, 624, 627, 629, 637, 639, 644], "map": [6, 17, 21, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 93, 95, 100, 101, 102, 120, 123, 126, 130, 138, 141, 142, 143, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 214, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 232, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 278, 279, 280, 283, 284, 285, 297, 307, 313, 322, 323, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 344, 345, 347, 348, 351, 352, 365, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 410, 419, 420, 427, 475, 570, 582, 583, 584, 587, 588, 590, 602, 622, 623, 624, 625, 628, 629, 640], "transportbackend": [6, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589], "protocol": [6, 190, 197, 202], "stateless": [6, 17, 22, 53, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 218, 227, 280, 335, 336, 366, 376, 378, 380, 384, 391, 622, 627, 639, 644], "design": [6, 7, 10, 16, 17, 18, 22, 37, 46, 49, 63, 64, 86, 87, 88, 106, 112, 119, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 221, 239, 251, 270, 272, 280, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 601, 608, 615, 622, 623, 624, 627, 628, 629, 634, 635, 636, 637, 638, 639, 641, 643, 644], "rather": [6, 23, 65, 68, 69, 72, 73, 112, 148, 149, 178, 185, 253, 280, 622, 623, 624, 625, 627, 629, 637, 638, 641], "kwarg": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 58, 60, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 95, 96, 97, 98, 100, 101, 102, 108, 109, 110, 112, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 202, 208, 209, 215, 216, 218, 225, 243, 250, 252, 261, 265, 270, 271, 272, 274, 276, 277, 279, 281, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 296, 297, 298, 300, 301, 302, 303, 304, 305, 310, 312, 313, 314, 317, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 340, 341, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 397, 398, 400, 401, 402, 403, 408, 416, 420, 421, 557, 558, 563, 564, 565, 568, 570, 571, 573, 574, 576, 578, 579, 581, 583, 589, 615, 624, 626, 638], "receive_weight": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 567, 569, 572, 575, 577, 579, 582, 584], "pre": [6, 26, 51, 55, 83, 88, 97, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 269, 275, 277, 315, 316, 326, 332, 337, 376, 378, 380, 383, 384, 567, 570, 572, 575, 579, 644], "alloc": [6, 86, 87, 97, 176, 194, 295, 306, 324, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 567, 572, 575, 579, 594, 615, 622], "weightstrategi": [6, 567, 568, 570, 571, 572, 573, 574, 575, 576, 578, 579, 581, 583, 589, 590], "applic": [6, 86, 87, 150, 158, 170, 176, 325, 327, 328, 330, 331, 371, 377, 379, 381, 382, 385, 580, 582, 615, 627, 628, 639], "setup_connection_and_weights_on_receiv": [6, 567, 569, 572, 575, 577, 579], "recept": [6, 38], "note": [6, 18, 19, 20, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 213, 229, 232, 270, 279, 280, 302, 304, 312, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 351, 359, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 568, 570, 573, 574, 576, 578, 581, 583, 587, 589, 615, 623, 626, 628, 634, 636, 637, 638, 644], "mptransport": [6, 570], "ye": 6, "rpctransport": [6, 573], "raytransport": [6, 574, 576], "distributedtransport": 6, "sharedmemtransport": [6, 569, 579], "instant": [6, 577, 584], "arriv": [6, 570, 578], "specifi": [6, 7, 15, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 228, 229, 230, 232, 258, 261, 264, 269, 273, 274, 282, 307, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 344, 345, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 401, 404, 568, 570, 573, 574, 576, 578, 579, 580, 581, 583, 589, 615, 622, 624, 625, 626, 630, 634, 637], "expir": [6, 567, 572, 575], "weightupdat": 6, "deprec": [6, 34, 35, 36, 38, 41, 43, 45, 46, 48, 50, 56, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 279, 325, 326, 327, 328, 330, 331, 332, 337, 349, 351, 352, 354, 357, 358, 359, 364, 365, 368, 369, 370, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 592, 626, 644], "11": [6, 29, 56, 64, 95, 96, 97, 101, 109, 116, 127, 214, 226, 268, 594, 621, 622, 623, 624, 625, 637, 639, 641, 642], "prefer": [6, 18, 22, 32, 35, 36, 38, 47, 56, 65, 68, 72, 73, 108, 109, 120, 154, 159, 181, 251, 259, 368, 372, 412, 624, 637, 638, 641, 643], "power": [7, 16, 30, 623], "top": [7, 21, 23, 88, 114, 121, 122, 136, 137, 228, 271, 326, 332, 337, 490, 601, 628], "hydra": [7, 420, 616], "dataclass": [7, 74, 86, 87, 176, 325, 327, 328, 330, 331, 366, 377, 379, 381, 382, 385], "compos": [7, 10, 21, 65, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 103, 104, 105, 114, 115, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 226, 227, 239, 254, 270, 271, 272, 279, 326, 332, 337, 341, 352, 361, 371, 376, 378, 380, 383, 384, 393, 487, 601, 622, 623, 624, 625, 626, 630, 634, 636, 638, 639, 640, 641, 643, 644], "overridden": [7, 22, 37, 39, 40, 41, 46, 49, 78, 80, 81, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 208, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 338, 341, 348, 386, 388, 389, 625, 637], "advantag": [7, 21, 22, 27, 178, 185, 300, 349, 351, 365, 368, 370, 376, 378, 380, 383, 386, 387, 388, 389, 390, 622, 623, 624, 625, 638, 639, 644], "glimps": 7, "go": [7, 19, 21, 26, 96, 141, 150, 227, 251, 255, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "sota": [7, 35, 38, 144, 237, 370, 406, 557, 622, 623, 643], "ppo_train": 7, "help": [7, 17, 23, 74, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 233, 326, 332, 333, 334, 337, 349, 351, 365, 368, 370, 376, 378, 380, 383, 384, 420, 593, 622, 623, 624, 625, 634, 635, 637, 638], "overrid": [7, 22, 37, 39, 40, 41, 46, 49, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 78, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 295, 326, 332, 337, 376, 378, 380, 383, 384, 393, 566, 571, 573, 574, 576, 581, 583, 588, 589, 634], "reproduc": [7, 17, 21, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 221, 239, 420, 421, 475, 622, 624, 626, 638], "command": [7, 25, 26, 29, 154, 159, 160, 190, 624, 634, 637, 638, 639, 644], "here": [7, 18, 19, 21, 23, 26, 27, 28, 29, 35, 38, 50, 84, 85, 114, 120, 123, 124, 125, 126, 130, 134, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 193, 221, 270, 401, 594, 622, 623, 624, 625, 626, 627, 628, 630, 632, 637, 638, 639, 641, 643, 644], "minim": [7, 16, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 395, 570, 594, 641], "config": [7, 25, 26, 190, 250, 277, 286, 289, 294, 311, 339, 420, 556, 557, 558, 560, 563, 615], "yaml": 7, "training_env": 7, "env_nam": [7, 25, 120, 121, 123, 124, 126, 127, 129, 130, 132, 136, 138, 139, 145, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 622, 624, 644], "tell": [7, 18, 23, 26, 120, 152, 153, 270, 578, 585, 622, 625, 630, 637, 638], "proper": [7, 22, 23, 25, 26, 189, 324, 386, 387, 388, 389, 594, 623, 624, 634, 637, 638, 639, 641], "select": [7, 23, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 123, 142, 143, 152, 153, 163, 164, 170, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 236, 237, 240, 241, 243, 244, 245, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 297, 313, 324, 326, 332, 337, 343, 376, 378, 380, 383, 384, 414, 622, 626, 627, 635, 637, 641], "syntax": [7, 615, 622], "dmcontrol": [7, 16, 18, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "brax": [7, 16, 27, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 253, 445, 627, 644], "well": [7, 15, 16, 17, 20, 21, 22, 27, 50, 56, 65, 68, 72, 73, 74, 88, 102, 106, 110, 117, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 271, 272, 290, 315, 316, 326, 332, 337, 345, 366, 368, 372, 376, 378, 380, 383, 384, 386, 390, 622, 623, 625, 626, 627, 628, 629, 631, 640, 641, 643], "reward": [7, 10, 17, 18, 19, 22, 34, 35, 38, 78, 79, 80, 81, 82, 83, 84, 85, 88, 101, 102, 114, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 214, 215, 218, 219, 224, 225, 229, 230, 232, 233, 234, 239, 241, 242, 243, 244, 248, 252, 253, 255, 256, 257, 258, 259, 260, 262, 263, 264, 269, 271, 272, 273, 274, 276, 277, 279, 280, 302, 323, 341, 349, 350, 352, 353, 354, 356, 357, 358, 361, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 408, 409, 410, 413, 420, 421, 566, 597, 616, 622, 623, 624, 625, 626, 627, 628, 630, 631, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "mlp": [7, 144, 283, 288, 290, 291, 292, 293, 297, 300, 302, 304, 354, 356, 467, 601, 623, 626, 628, 629, 632, 636, 640, 643], "convnet": [7, 290, 291, 300, 466, 601, 625, 626, 628, 643], "writer": [7, 10, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 94, 97, 102, 104, 108, 114, 115, 116, 119, 433, 434, 439, 440, 624, 641], "logger": [7, 20, 30, 391, 393, 395, 396, 397, 398, 399, 400, 401, 409, 416, 420, 421, 462, 463, 464, 465, 475, 562, 566, 592, 616, 623, 634, 637], "assign": [7, 17, 23, 32, 35, 36, 38, 54, 58, 75, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 352, 353, 354, 356, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 589, 615, 624, 628, 634, 637, 638, 641], "locat": [7, 15, 26, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 209, 228, 233, 246, 257, 280, 303, 320, 321, 324, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 417, 419, 615, 622, 623, 624, 631, 637, 638, 641], "batched_env": [7, 644], "transformed_env": [7, 225, 272, 627], "base_env": [7, 21, 22, 120, 122, 123, 126, 130, 131, 137, 138, 149, 150, 151, 154, 158, 159, 160, 162, 170, 171, 172, 175, 178, 179, 180, 194, 214, 215, 218, 224, 226, 227, 229, 231, 232, 241, 248, 252, 254, 260, 263, 265, 266, 270, 272, 393, 405, 444, 574, 594, 622, 623, 624, 626, 637, 640, 643, 644], "transform0": 7, "noop_reset": 7, "transform1": [7, 21], "step_count": [7, 34, 35, 38, 120, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 227, 263, 524, 624, 625, 626, 627, 632], "noop": [7, 245, 507], "30": [7, 18, 20, 68, 81, 88, 108, 109, 184, 217, 245, 315, 316, 391, 395, 398, 400, 401, 462, 507, 615, 622, 623, 624, 630, 635, 637, 638, 639, 641], "max_step": [7, 16, 17, 30, 114, 120, 123, 126, 130, 138, 142, 143, 144, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 183, 263, 270, 391, 524, 627, 628, 629, 631, 632, 637, 638, 643, 644], "step_count_kei": [7, 226, 227, 263, 524], "_partial_": [7, 422, 423, 424, 425, 427, 428, 429, 430, 433, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 466, 467, 468, 469, 470, 471, 472, 473, 474, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554], "individu": [7, 23, 34, 42, 44, 47, 50, 69, 88, 102, 114, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 280, 317, 326, 332, 337, 351, 365, 368, 376, 378, 380, 383, 384, 622, 625, 638], "construct": [7, 18, 24, 56, 65, 68, 69, 72, 73, 74, 78, 88, 120, 123, 126, 127, 129, 130, 138, 150, 151, 152, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 280, 302, 304, 316, 326, 332, 337, 345, 376, 378, 380, 383, 384, 416, 601, 616, 623, 624, 625, 628, 637, 639, 641, 644], "repeat": [7, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 181, 185, 194, 270, 295, 324, 326, 332, 337, 531, 624, 637, 638, 639], "layer": [7, 246, 279, 288, 290, 291, 296, 299, 302, 304, 305, 308, 309, 324, 333, 334, 338, 348, 467, 582, 587, 588, 594, 596, 597, 601, 623, 624, 625, 626, 628, 637, 640], "episod": [7, 10, 18, 78, 79, 80, 81, 82, 83, 84, 85, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 217, 255, 258, 264, 386, 420, 623, 627, 632, 637, 638, 641], "track": [7, 20, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 73, 86, 87, 101, 102, 107, 123, 176, 178, 191, 258, 267, 279, 280, 312, 325, 327, 328, 330, 331, 341, 377, 379, 381, 382, 383, 385, 398, 408, 418, 420, 475, 592, 619, 623, 625, 627, 630, 638, 639, 641], "count": [7, 18, 20, 22, 32, 34, 35, 36, 38, 52, 126, 127, 226, 263, 270, 280, 312, 324, 410, 416, 555, 594, 622, 623, 624, 625, 641, 644], "composit": [7, 10, 17, 18, 19, 21, 57, 58, 59, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 87, 88, 106, 112, 119, 120, 123, 126, 128, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 206, 213, 215, 218, 229, 230, 231, 232, 234, 239, 241, 244, 252, 253, 259, 263, 265, 269, 270, 271, 273, 280, 286, 340, 342, 345, 347, 348, 349, 368, 383, 594, 622, 624, 625, 628, 634, 637, 638, 639, 644], "combin": [7, 23, 102, 188, 195, 196, 324, 372, 623, 626, 631, 641, 643], "maximum": [7, 17, 23, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 47, 48, 50, 57, 75, 90, 95, 96, 97, 98, 101, 102, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 231, 256, 263, 264, 266, 319, 320, 321, 326, 329, 332, 337, 348, 350, 352, 357, 358, 364, 366, 367, 371, 376, 378, 380, 384, 393, 412, 420, 421, 475, 567, 568, 569, 570, 572, 573, 574, 575, 576, 578, 579, 581, 583, 589, 594, 615, 622, 623, 624, 625, 628, 637, 638, 641], "length": [7, 35, 36, 38, 47, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 83, 87, 102, 108, 109, 112, 120, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 196, 214, 221, 242, 251, 279, 288, 290, 292, 294, 305, 322, 325, 326, 332, 337, 340, 344, 383, 384, 406, 412, 594, 622, 624, 625, 630, 632, 634, 639, 641, 644], "concept": [7, 21, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 594, 623, 634, 641], "nest": [7, 11, 16, 17, 19, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 60, 68, 69, 71, 86, 87, 88, 95, 96, 97, 100, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 213, 221, 263, 266, 270, 271, 325, 326, 327, 328, 330, 331, 332, 337, 341, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 405, 409, 616, 623, 624, 626, 638, 639, 641, 643], "deep": [7, 22, 28, 221, 242, 290, 291, 292, 293, 296, 312, 349, 352, 371, 622, 637], "factori": [7, 28, 32, 34, 35, 36, 38, 42, 44, 47, 50, 66, 68, 72, 73, 74, 194, 243, 403, 422, 442, 466, 467, 622], "onc": [7, 22, 26, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 54, 69, 83, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 244, 255, 265, 272, 286, 312, 325, 326, 327, 328, 330, 331, 332, 337, 341, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 413, 568, 570, 571, 573, 574, 576, 578, 579, 581, 583, 589, 615, 623, 624, 625, 628, 631, 639, 641, 644], "per": [7, 19, 20, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 53, 80, 88, 101, 102, 108, 114, 134, 136, 137, 150, 152, 153, 196, 224, 244, 258, 288, 299, 301, 324, 333, 341, 368, 380, 393, 395, 398, 400, 401, 416, 418, 420, 421, 475, 564, 565, 577, 589, 594, 622, 623, 624, 625, 626, 628, 629, 632, 637, 638, 641, 643], "variabl": [7, 18, 20, 22, 23, 26, 27, 41, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 80, 81, 84, 85, 87, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 142, 143, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 175, 178, 179, 180, 185, 196, 200, 202, 225, 267, 271, 280, 283, 284, 285, 302, 304, 326, 332, 337, 366, 369, 405, 594, 623, 635], "interpol": [7, 69, 254, 515, 623, 625, 626], "script": [7, 26, 80, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 405, 562, 566, 616, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 635, 636, 637, 638, 639, 640, 641, 644], "discov": [7, 23], "print": [7, 18, 22, 25, 26, 34, 35, 38, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 101, 102, 108, 109, 114, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 136, 137, 138, 139, 140, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 203, 206, 211, 212, 213, 214, 217, 218, 221, 222, 226, 227, 229, 230, 231, 232, 240, 246, 252, 253, 255, 258, 263, 265, 266, 267, 268, 279, 280, 283, 284, 285, 288, 290, 291, 292, 293, 294, 297, 300, 301, 302, 304, 305, 306, 307, 310, 312, 313, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 340, 341, 342, 344, 345, 347, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 402, 562, 585, 594, 615, 623, 624, 625, 626, 627, 628, 629, 630, 631, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "someth": [7, 88, 120, 123, 126, 130, 138, 141, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 593, 623, 624, 639, 644], "policy_model": [7, 586], "tanh_norm": 7, "value_model": [7, 360, 362], "policy_network": 7, "value_network": [7, 353, 354, 356, 357, 359, 364, 371, 386, 387, 388, 389, 608, 622, 624, 626, 629, 632, 637], "tensor": [7, 10, 11, 12, 14, 17, 18, 19, 22, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 106, 108, 109, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 206, 208, 212, 213, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 231, 232, 233, 234, 236, 239, 240, 242, 246, 248, 250, 251, 252, 253, 255, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 270, 271, 272, 273, 274, 275, 277, 279, 280, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 340, 341, 342, 344, 345, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 361, 362, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 409, 429, 441, 577, 594, 596, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 636, 637, 638, 639, 640, 643, 644], "without_replac": 7, "round_robin": 7, "adam": [7, 172, 320, 421, 544, 622, 623, 624, 625, 626, 629, 632, 637, 638, 639], "wandb": [7, 393, 397, 401, 416, 420, 465, 475, 631, 643], "out_featur": [7, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 283, 288, 290, 291, 292, 293, 297, 299, 300, 302, 304, 305, 326, 332, 337, 344, 354, 356, 376, 378, 380, 383, 384, 467, 470, 471, 472, 622, 625, 626, 628, 629, 632, 643], "in_featur": [7, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 283, 288, 290, 291, 292, 293, 300, 305, 326, 332, 337, 344, 354, 356, 376, 378, 380, 383, 384, 466, 467, 470, 471, 472, 626, 628, 629], "num_cel": [7, 283, 288, 290, 291, 292, 293, 299, 300, 302, 304, 305, 466, 467, 470, 471, 472, 623, 624, 625, 626, 628, 629, 632, 637, 638, 643], "128": [7, 78, 79, 83, 109, 121, 122, 136, 137, 193, 291, 294, 615, 623, 625, 626, 632, 637, 640, 641], "num_cal": 7, "state_valu": [7, 284, 285, 322, 351, 357, 364, 365, 368, 369, 371, 386, 387, 388, 389, 622, 624, 638], "loss_modul": [7, 351, 365, 366, 368, 376, 378, 380, 384, 415, 416, 419, 420, 421, 475, 561, 562, 608, 616, 622, 623, 624, 637, 638, 641], "1024": [7, 50, 66, 294, 402, 623, 626, 641], "lr": [7, 421, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 622, 623, 624, 625, 632, 637, 638, 639], "001": [7, 544, 545, 550, 553, 554, 622, 639], "actor_network": [7, 349, 350, 351, 352, 353, 355, 357, 358, 364, 365, 367, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 415, 419, 420, 421, 474, 475, 608, 622, 624, 629, 637, 638], "critic_network": [7, 349, 351, 365, 368, 370, 419, 420, 474, 475, 624, 638], "exp_nam": [7, 30, 393, 394, 395, 398, 399, 400, 401, 462, 464, 465, 562, 623, 631, 632], "my_experi": [7, 404], "0001": [7, 280, 299, 307, 470, 541, 544, 548, 624], "chang": [7, 18, 21, 24, 26, 30, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 86, 87, 88, 90, 95, 96, 97, 98, 102, 107, 108, 110, 112, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 232, 234, 241, 244, 252, 253, 259, 263, 269, 271, 272, 273, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 420, 421, 570, 578, 594, 615, 622, 625, 635, 637, 638, 639, 640, 641, 644], "rate": [7, 23, 30, 78, 279, 280, 420, 623, 624, 637, 638], "multirun": 7, "01": [7, 217, 246, 280, 312, 349, 351, 365, 368, 380, 541, 543, 545, 551, 552, 622, 623, 624, 637, 639], "8": [7, 25, 26, 60, 68, 71, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 108, 109, 120, 121, 122, 123, 124, 125, 126, 130, 138, 148, 149, 150, 151, 154, 158, 159, 160, 161, 170, 171, 172, 175, 178, 179, 180, 214, 217, 226, 227, 264, 267, 273, 280, 283, 284, 285, 288, 290, 291, 300, 305, 342, 344, 347, 364, 622, 623, 626, 630, 632, 637, 639, 640, 641, 643], "my_custom_config": 7, "under": [7, 17, 18, 21, 23, 50, 60, 71, 78, 79, 80, 81, 83, 84, 85, 88, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 242, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 297, 298, 313, 314, 326, 332, 337, 340, 342, 344, 345, 366, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 393, 416, 594, 622, 623, 628, 637, 639, 644], "hood": [7, 17, 50, 78, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 639], "configstor": 7, "type": [7, 10, 21, 22, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 85, 86, 87, 88, 95, 120, 123, 126, 130, 138, 141, 144, 147, 150, 151, 152, 153, 154, 158, 159, 160, 167, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 204, 205, 209, 210, 212, 214, 218, 221, 225, 229, 230, 233, 234, 239, 241, 244, 250, 252, 253, 259, 263, 265, 269, 270, 271, 272, 273, 275, 277, 279, 280, 286, 288, 297, 305, 318, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 335, 336, 337, 342, 344, 345, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 402, 403, 404, 422, 442, 466, 467, 473, 564, 577, 580, 615, 622, 623, 624, 626, 630, 634, 637, 638, 639, 641, 644], "safeti": [7, 32, 35, 36, 38, 144, 150, 158, 280, 615, 634], "id": [7, 26, 32, 34, 35, 36, 37, 38, 39, 40, 41, 46, 49, 52, 53, 55, 56, 69, 102, 108, 109, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 175, 177, 178, 179, 180, 200, 312, 324, 332, 352, 369, 396, 401, 465, 568, 570, 571, 573, 574, 576, 578, 581, 582, 583, 589, 630, 641], "registr": [7, 41, 402, 592, 623], "config_stor": 7, "cs": 7, "gymenvconfig": 7, "batchedenvconfig": 7, "tanhnormalmodelconfig": [7, 468], "inherit": [7, 21, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 193, 366, 376, 624, 637, 638], "envs_lib": 7, "envlibsconfig": 7, "mycustomenvconfig": 7, "_target_": [7, 422, 423, 424, 425, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 444, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 465, 466, 467, 470, 471, 472, 474, 475, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554], "str": [7, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 95, 96, 97, 98, 101, 102, 114, 116, 120, 121, 123, 124, 125, 126, 128, 129, 130, 131, 132, 136, 138, 142, 143, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 210, 213, 217, 221, 233, 239, 240, 241, 243, 250, 254, 263, 264, 267, 269, 270, 272, 273, 275, 277, 278, 279, 282, 288, 289, 290, 291, 292, 293, 296, 297, 298, 300, 302, 304, 305, 306, 307, 311, 313, 314, 317, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 340, 342, 344, 345, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 444, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 465, 466, 467, 470, 471, 472, 474, 475, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 556, 566, 568, 569, 570, 571, 573, 574, 575, 576, 577, 578, 580, 581, 582, 583, 584, 587, 588, 589, 615, 623, 624, 626, 634], "my_modul": [7, 574], "mycustomenv": 7, "myenv": [7, 150, 218, 229, 232], "custom_param": 7, "float": [7, 18, 21, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 58, 60, 64, 65, 69, 72, 75, 83, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 214, 217, 221, 225, 229, 232, 241, 242, 246, 250, 255, 256, 257, 264, 265, 268, 271, 272, 275, 277, 280, 286, 287, 295, 299, 303, 305, 306, 315, 316, 319, 320, 321, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 348, 349, 350, 351, 352, 356, 357, 358, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 413, 420, 421, 431, 467, 470, 474, 475, 486, 504, 506, 508, 516, 517, 518, 525, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 581, 582, 583, 584, 585, 587, 589, 594, 622, 623, 641, 644], "__post_init__": 7, "self": [7, 18, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 71, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 277, 278, 279, 282, 286, 301, 302, 304, 322, 325, 326, 327, 328, 330, 331, 332, 337, 342, 344, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 587, 588, 594, 615, 622, 626, 634, 639, 643], "super": [7, 18, 21, 88, 144, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 322, 350, 352, 353, 358, 364, 369, 371, 372, 373, 383, 571, 573, 574, 576, 581, 583, 588, 589, 622, 639, 643], "my_custom": 7, "begin": [7, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 102, 108, 217, 405, 626, 627, 628, 629, 630, 631, 632, 634], "gradual": 7, "add": [7, 10, 16, 21, 23, 25, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 94, 96, 101, 104, 114, 115, 118, 119, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 221, 239, 241, 269, 272, 302, 304, 326, 332, 337, 349, 375, 376, 378, 380, 383, 384, 411, 420, 475, 571, 573, 574, 576, 581, 583, 589, 594, 605, 615, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 637, 638, 639, 641, 643], "leverag": [7, 39, 50, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 324, 594, 622, 638, 644], "sparingli": 7, "correctli": [7, 22, 26, 88, 90, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 594], "duplic": [7, 88, 107, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 350, 352, 354, 359, 364, 366, 369, 371, 372, 373, 376, 378, 380, 383, 384], "As": [7, 19, 22, 23, 68, 69, 72, 73, 74, 78, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 255, 295, 345, 386, 622, 623, 624, 625, 626, 627, 629, 630, 637, 638, 639, 640, 641, 643, 644], "td3": [7, 372, 373], "expand": [7, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 95, 108, 109, 176, 218, 265, 295, 325, 327, 328, 330, 331, 344, 347, 350, 352, 364, 366, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 626, 637, 638, 639, 641, 643], "sactrainerconfig": 7, "td3trainerconfig": 7, "addit": [7, 16, 19, 22, 23, 37, 39, 46, 49, 63, 79, 86, 87, 88, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 163, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 225, 250, 265, 269, 271, 272, 275, 277, 286, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 337, 341, 344, 351, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 391, 393, 573, 574, 576, 589, 612, 615, 622, 623, 626, 627, 637, 638, 641], "maintain": [7, 18, 24, 28, 35, 36, 38, 63, 189, 192, 201, 221, 280, 358, 371, 577, 581, 594, 615, 639], "circumst": 8, "cudnn": [8, 302, 304, 625, 626], "7": [8, 10, 25, 29, 64, 65, 68, 72, 101, 102, 109, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 214, 217, 226, 227, 264, 267, 280, 287, 288, 291, 305, 324, 332, 337, 589, 622, 623, 626, 630, 631, 637, 639, 641, 643], "5x": 8, "batch_first": [8, 625], "input": [8, 9, 16, 17, 18, 20, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 96, 98, 111, 117, 120, 123, 126, 130, 138, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 243, 244, 248, 249, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 287, 288, 290, 291, 292, 293, 296, 297, 298, 301, 302, 303, 304, 305, 307, 308, 309, 312, 313, 314, 315, 316, 320, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 340, 341, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 409, 413, 555, 562, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589, 594, 598, 608, 622, 623, 624, 625, 626, 627, 634, 637, 638, 639, 643, 644], "fix": [8, 27, 150, 208, 265, 350, 352, 367, 371, 615, 623, 632, 639, 644], "5": [8, 10, 18, 19, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 72, 73, 78, 87, 88, 90, 108, 109, 114, 120, 123, 126, 127, 130, 136, 137, 138, 142, 143, 145, 150, 151, 154, 156, 157, 158, 159, 160, 163, 164, 170, 172, 175, 177, 178, 179, 180, 183, 193, 214, 217, 218, 220, 226, 227, 242, 255, 262, 263, 264, 270, 280, 287, 288, 290, 291, 296, 297, 299, 300, 303, 305, 308, 313, 320, 321, 324, 333, 334, 337, 341, 348, 365, 368, 370, 372, 373, 380, 391, 466, 467, 470, 472, 552, 594, 615, 621, 622, 623, 626, 628, 630, 632, 637, 638, 639, 641, 642, 643, 644], "condit": [9, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 178, 183, 226, 227, 264, 279, 297, 298, 313, 314, 316, 341, 488, 577, 592, 594, 622, 637, 639, 641], "met": [9, 226, 227, 637, 639], "packedsequ": 9, "dropout": [9, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 287, 302, 304, 305, 326, 332, 337, 376, 378, 380, 383, 384, 467, 625], "comprehens": [10, 16, 420, 421, 594, 596, 601, 608, 615], "around": [10, 24, 26, 32, 72, 73, 89, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 341, 343, 345, 386, 594, 622, 623, 634, 638, 644], "central": [10, 12, 37, 41, 46, 49, 50, 324, 403, 615, 622, 623, 627, 637, 638, 641], "offer": [10, 16, 17, 20, 22, 26, 120, 121, 122, 123, 126, 130, 136, 137, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 270, 391, 601, 622, 623, 626, 627, 629, 630, 637, 639, 641, 644], "memmap": [10, 86, 87, 95, 97, 150, 158, 176, 279, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 393, 395, 412, 583, 584, 586, 641], "compress": [10, 90, 91], "advanc": [10, 22, 50, 65, 68, 72, 73, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 324, 402, 592, 627, 630, 641], "priorit": [10, 27, 65, 72, 101, 102, 352, 353, 354, 356, 357, 358, 364, 369, 371, 372, 373, 431, 622, 623, 630, 643], "mix": [10, 251, 615, 622, 637, 638], "arbitrari": [10, 16, 17, 22, 57, 64, 68, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 622, 623, 639, 641], "lazymemmapstorag": [10, 12, 15, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 102, 108, 109, 220, 221, 427, 622, 623, 625, 630, 637, 640, 641], "prioritizedsampl": [10, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 102, 354, 359, 431, 622, 641], "max_siz": [10, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 95, 96, 97, 98, 108, 109, 110, 114, 116, 427, 428, 429, 430, 441, 624, 630], "1000000": [10, 78, 79, 80, 81, 82, 83, 84, 85, 402, 421, 541, 616], "max_capac": [10, 101, 102, 431, 622, 641], "alpha": [10, 65, 72, 101, 102, 288, 290, 291, 292, 293, 300, 350, 352, 358, 367, 369, 371, 372, 431, 541, 551, 622, 641, 643], "beta": [10, 23, 65, 72, 101, 102, 357, 364, 365, 384, 431, 544, 545, 546, 548, 549, 550, 554, 622, 623, 641, 643], "batch_siz": [10, 17, 18, 19, 22, 27, 34, 35, 38, 52, 55, 56, 60, 63, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 101, 102, 103, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 133, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 212, 213, 214, 218, 220, 221, 225, 229, 232, 233, 234, 239, 248, 252, 253, 255, 259, 262, 263, 265, 271, 272, 273, 283, 284, 285, 287, 294, 295, 296, 297, 298, 301, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 342, 344, 345, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 402, 406, 412, 418, 420, 421, 433, 440, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 480, 594, 615, 622, 623, 624, 625, 627, 628, 629, 630, 631, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "256": [10, 34, 52, 142, 143, 239, 294, 594, 623, 624, 626, 637, 638], "randn": [10, 22, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 95, 96, 97, 102, 108, 109, 116, 120, 176, 188, 206, 220, 246, 283, 284, 285, 287, 289, 290, 294, 296, 297, 306, 307, 310, 311, 313, 322, 325, 327, 328, 330, 331, 338, 340, 342, 344, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 414, 466, 467, 470, 471, 472, 626, 641, 643, 644], "32": [10, 51, 60, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 109, 130, 137, 156, 157, 163, 164, 180, 185, 192, 193, 194, 221, 239, 288, 289, 290, 291, 293, 294, 300, 305, 308, 309, 311, 391, 402, 465, 466, 467, 470, 471, 472, 615, 622, 623, 624, 625, 626, 628, 629, 637, 639, 640, 641, 643, 644], "compressedliststorag": [10, 91], "compressedliststoragecheckpoint": 10, "flatstoragecheckpoint": 10, "h5storagecheckpoint": 10, "immutabledatasetwrit": [10, 78, 79, 80, 81, 82, 83, 84, 85], "liststorag": [10, 12, 65, 66, 68, 69, 72, 73, 96, 430, 641], "lazystackstorag": [10, 88, 428], "liststoragecheckpoint": 10, "nestedstoragecheckpoint": 10, "storagecheckpointerbas": [10, 68, 110], "storageensembl": [10, 69, 106, 438], "storageensemblecheckpoint": 10, "tensorstorag": [10, 12, 68, 78, 79, 80, 81, 82, 83, 84, 85, 95, 101, 102, 114, 117, 441, 630, 641], "tensorstoragecheckpoint": [10, 95], "prioritizedslicesampl": [10, 641], "randomsampl": [10, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 432, 622, 637], "samplerensembl": [10, 69], "samplerwithoutreplac": [10, 88, 114, 435, 624, 638, 641], "slicesamplerwithoutreplac": [10, 108, 437, 641], "tensorspec": [10, 17, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 75, 76, 77, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 213, 214, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 238, 240, 241, 242, 243, 244, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 286, 297, 298, 301, 312, 313, 314, 316, 340, 342, 343, 344, 345, 346, 348, 350, 352, 354, 357, 358, 369, 371, 372, 373, 383, 592, 639], "binari": [10, 18, 26, 64, 161, 215, 219, 297, 298, 313, 314, 354, 357, 358, 634], "bound": [10, 18, 23, 50, 60, 75, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 224, 245, 279, 286, 297, 298, 301, 312, 313, 314, 315, 316, 326, 332, 337, 340, 342, 343, 344, 345, 348, 349, 350, 352, 353, 364, 368, 369, 371, 372, 373, 376, 378, 380, 383, 384, 622, 623, 624, 626, 637, 639, 643, 644], "categor": [10, 19, 21, 57, 58, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 175, 178, 179, 180, 213, 214, 215, 233, 252, 297, 298, 310, 313, 314, 326, 342, 354, 357, 358, 477, 625, 637, 638, 644], "multicategor": [10, 62], "multionehot": [10, 61, 354, 357, 358], "nontensor": [10, 17, 87, 175, 180, 239, 273], "onehot": [10, 57, 58, 59, 60, 61, 62, 63, 70, 71, 74, 75, 76, 77, 121, 122, 129, 131, 132, 135, 136, 137, 145, 146, 148, 149, 155, 161, 162, 297, 313, 354, 356, 357, 358, 628], "stackedcomposit": 10, "unbound": [10, 18, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 76, 77, 86, 87, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 206, 215, 218, 229, 232, 252, 265, 322, 325, 327, 328, 330, 331, 340, 344, 347, 370, 377, 379, 381, 382, 385, 594, 634, 639, 641], "unboundedcontinu": [10, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 252, 265, 347, 624, 625, 637, 638, 639, 644], "unboundeddiscret": [10, 75, 151, 239, 639, 644], "offlin": [11, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 78, 80, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 350, 356, 357, 364, 372, 383, 401, 465, 592, 608, 627, 640, 641], "layout": [11, 56, 326, 329, 332, 337, 626], "element": [11, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 56, 57, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 95, 96, 97, 98, 101, 102, 108, 109, 114, 116, 120, 123, 126, 130, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 185, 214, 221, 226, 227, 251, 260, 264, 265, 280, 286, 288, 297, 322, 325, 327, 328, 330, 331, 340, 341, 344, 345, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 406, 622, 624, 628, 630, 634, 641, 644], "full": [11, 18, 19, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 188, 190, 195, 196, 197, 298, 302, 304, 325, 327, 328, 330, 331, 332, 337, 345, 368, 376, 377, 378, 379, 380, 381, 382, 385, 406, 594, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "sequenc": [11, 23, 32, 34, 35, 36, 38, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 74, 75, 76, 77, 83, 86, 87, 94, 104, 106, 112, 115, 118, 119, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 199, 201, 207, 219, 220, 221, 222, 223, 228, 229, 231, 232, 236, 238, 239, 242, 246, 247, 251, 252, 253, 254, 255, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 273, 279, 280, 288, 295, 305, 306, 310, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 346, 347, 355, 376, 377, 378, 379, 380, 381, 382, 384, 385, 392, 393, 410, 411, 412, 414, 416, 594, 622, 624, 625, 626, 636, 637, 638, 644], "wide": [12, 22, 24, 643], "give": [12, 22, 26, 60, 71, 72, 80, 87, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 351, 365, 368, 593, 615, 622, 623, 626, 637, 638, 639, 640, 643], "abil": [12, 15, 366, 639, 641], "panel": [12, 624], "almost": [12, 280, 306, 625], "physic": [12, 25, 26, 93, 150, 151, 155, 622, 637, 638, 639], "theori": 12, "crude": 12, "made": [12, 18, 22, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 78, 88, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 265, 271, 312, 326, 332, 337, 354, 366, 376, 378, 380, 383, 384, 468, 622, 623, 625, 637, 638, 640, 641, 643], "ineffici": [12, 23], "contigu": [12, 18, 27, 58, 60, 75, 80, 83, 84, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 239, 242, 265, 273, 624, 625, 637, 638, 639, 641, 643, 644], "collate_fn": [12, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 170, 171, 172, 175, 641, 643], "__init__": [12, 18, 21, 26, 88, 126, 144, 161, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 211, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 295, 322, 334, 350, 352, 353, 358, 364, 369, 371, 372, 373, 383, 615, 639, 644], "retriev": [13, 17, 22, 32, 35, 36, 37, 38, 39, 41, 46, 49, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 106, 108, 109, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 188, 189, 195, 196, 201, 212, 222, 230, 233, 246, 325, 327, 328, 330, 331, 337, 341, 342, 345, 348, 349, 350, 351, 352, 354, 365, 368, 369, 371, 372, 373, 377, 379, 380, 381, 382, 385, 386, 387, 388, 389, 402, 403, 404, 566, 575, 623, 624, 628, 639, 644], "dtype": [14, 18, 19, 22, 34, 35, 38, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 101, 102, 108, 109, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 209, 212, 213, 214, 215, 218, 219, 225, 226, 229, 230, 231, 232, 233, 234, 239, 241, 242, 246, 248, 250, 252, 253, 255, 259, 262, 263, 265, 267, 268, 271, 272, 273, 275, 277, 283, 284, 285, 287, 296, 297, 298, 302, 304, 312, 313, 314, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 342, 344, 345, 347, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 491, 529, 582, 587, 588, 590, 594, 624, 625, 626, 627, 628, 629, 630, 631, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "domain": [14, 16, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 184, 206, 231, 239, 265, 273, 297, 298, 313, 314, 340, 342, 344, 345, 346, 347, 624, 625, 628, 629, 634, 637, 638, 639, 643, 644], "influenti": 15, "latenc": [15, 22, 615], "especi": [15, 17, 26, 27, 222, 326, 332, 337, 570], "larger": [15, 23, 42, 47, 50, 302, 304, 357, 364, 643], "volum": 15, "advis": [15, 30, 80, 631, 644], "due": [15, 22, 24, 33, 42, 43, 44, 45, 47, 48, 56, 351, 368, 421, 589, 629, 640, 641, 644], "memorymappedtensor": [15, 78, 79, 80, 81, 82, 83, 84, 85, 95, 395, 630, 640], "file": [15, 25, 26, 27, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 78, 79, 80, 81, 83, 84, 85, 86, 87, 93, 95, 163, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 392, 393, 395, 416, 420, 421, 475, 583, 584, 585, 592, 615, 621, 623, 626, 637, 641, 642], "improv": [15, 23, 30, 54, 177, 192, 237, 349, 420, 626, 637, 638, 641], "failur": [15, 23, 177, 324, 351, 368, 380, 594], "recoveri": 15, "wrapper": [16, 17, 21, 32, 55, 72, 73, 86, 87, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 169, 170, 171, 172, 175, 176, 178, 179, 180, 185, 189, 278, 282, 287, 323, 325, 326, 327, 328, 329, 330, 331, 332, 334, 337, 341, 343, 345, 377, 379, 381, 382, 385, 386, 398, 399, 400, 401, 566, 590, 592, 601, 621, 624, 625, 627, 633, 634, 637, 638, 640, 642, 643, 644], "popular": [16, 22, 625, 629, 638], "framework": [16, 18, 23, 28, 51, 120, 121, 122, 123, 126, 130, 136, 137, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 594, 615, 634, 635, 643, 644], "jumanji": [16, 18, 120, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 451], "envbas": [16, 17, 18, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 88, 120, 123, 127, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 215, 218, 229, 232, 245, 252, 253, 271, 272, 279, 302, 304, 339, 341, 383, 410, 556, 557, 558, 562, 564, 565, 566, 627], "foundat": [16, 18, 24, 152, 153, 426, 596, 624, 638], "output": [16, 17, 18, 19, 20, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 65, 68, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 137, 138, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 213, 218, 219, 221, 224, 225, 227, 228, 229, 230, 232, 234, 236, 239, 241, 244, 246, 250, 252, 253, 258, 259, 262, 263, 266, 267, 269, 271, 272, 273, 275, 277, 278, 280, 283, 286, 288, 289, 290, 291, 294, 296, 297, 298, 299, 302, 304, 305, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 340, 341, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 406, 594, 596, 598, 601, 608, 622, 623, 624, 625, 626, 627, 628, 631, 634, 635, 636, 637, 638, 639, 640, 643, 644], "infrastructur": [16, 19, 197, 637, 638], "transformedenv": [16, 21, 22, 30, 31, 88, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 218, 221, 224, 225, 227, 229, 232, 233, 234, 240, 241, 242, 245, 246, 248, 252, 253, 254, 255, 258, 259, 260, 263, 264, 265, 266, 270, 271, 279, 302, 304, 341, 383, 393, 405, 444, 574, 594, 622, 623, 624, 625, 626, 627, 631, 632, 636, 637, 638, 639, 640, 641, 643, 644], "rewardsum": [16, 21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 212, 271, 383, 519, 637, 638], "stepcount": [16, 88, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 226, 227, 270, 271, 272, 287, 383, 524, 594, 622, 623, 624, 625, 626, 627, 632, 637, 638, 643], "parallel_env": [16, 153, 622, 643, 644], "100": [16, 32, 34, 35, 36, 38, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 95, 97, 108, 109, 114, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 224, 226, 233, 246, 255, 260, 263, 298, 306, 324, 326, 332, 337, 341, 376, 378, 380, 383, 384, 393, 407, 421, 547, 562, 570, 615, 623, 624, 625, 626, 627, 629, 632, 636, 637, 638, 639, 641, 643, 644], "lock": [16, 60, 71, 86, 87, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 218, 227, 265, 279, 280, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 639], "partial": [16, 17, 32, 34, 35, 36, 38, 52, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 220, 221, 264, 265, 266, 303, 320, 342, 416, 625], "invers": [16, 23, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 221, 229, 232, 234, 239, 243, 246, 253, 255, 267, 269, 271, 273, 351, 357, 364, 368, 380, 383, 639], "marlgroupmaptyp": [16, 142, 143, 148, 149, 152, 153, 161, 162, 163, 164, 166, 637], "check_marl_group": 16, "auto": [16, 54, 89, 97, 116, 126, 131, 216, 217, 272, 278, 312, 350, 352, 358, 367, 369, 371, 372, 373, 402, 404, 589, 637, 638], "dynam": [16, 26, 34, 35, 36, 38, 80, 83, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 206, 357, 364, 402, 596, 601, 606, 624, 627, 639], "record": [16, 30, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 207, 214, 241, 326, 332, 337, 368, 376, 378, 380, 383, 384, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 410, 421, 462, 464, 465, 562, 592, 616, 623, 624, 628, 632, 637], "dm": [17, 622, 644], "abl": [17, 21, 22, 120, 141, 152, 153, 154, 159, 302, 304, 622, 624, 625, 628, 636, 637, 638, 639, 641], "simul": [17, 18, 19, 20, 24, 26, 27, 74, 121, 122, 123, 132, 136, 137, 155, 163, 164, 170, 208, 317, 594, 622, 624, 626, 627, 631, 635, 637, 638], "box": [17, 19, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 129, 131, 366, 376, 378, 380, 384, 634], "lib": [17, 18, 19, 24, 25, 26, 28, 29, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 88, 120, 123, 126, 127, 130, 135, 138, 142, 143, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 221, 224, 233, 240, 241, 246, 248, 253, 255, 258, 265, 271, 278, 279, 383, 391, 445, 446, 447, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 562, 622, 623, 624, 625, 626, 636, 638, 640, 641, 643, 644], "hope": [17, 30], "imit": [17, 363], "parent": [17, 20, 21, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 63, 69, 74, 88, 112, 119, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 221, 222, 225, 226, 227, 230, 233, 236, 237, 244, 246, 250, 258, 263, 264, 265, 266, 270, 271, 274, 275, 283, 302, 304, 326, 332, 337, 366, 368, 376, 378, 380, 383, 384, 390, 391, 393, 468, 469, 570, 574, 622, 630, 639, 643, 644], "subclass": [17, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 58, 60, 69, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 216, 217, 271, 278, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 337, 338, 341, 344, 345, 346, 348, 366, 368, 571, 573, 574, 576, 581, 583, 588, 589, 615, 623, 625, 630, 639, 641], "organis": [17, 84, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272, 623], "togeth": [17, 21, 30, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 70, 71, 96, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 251, 262, 271, 283, 284, 285, 302, 304, 323, 589, 594, 623, 625, 627, 637], "live": [17, 22, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 233, 326, 332, 337, 376, 378, 380, 383, 384, 495], "doe": [17, 18, 21, 22, 40, 42, 65, 72, 78, 79, 83, 86, 87, 88, 92, 93, 100, 102, 108, 110, 112, 119, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 280, 294, 295, 302, 304, 325, 326, 327, 328, 330, 331, 332, 337, 346, 347, 349, 351, 359, 365, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 416, 571, 622, 623, 624, 625, 627, 630, 637, 639, 641, 644], "respons": [17, 20, 22, 27, 34, 35, 36, 38, 41, 42, 47, 50, 52, 53, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 174, 175, 177, 178, 179, 180, 183, 186, 187, 190, 193, 203, 325, 327, 329, 330, 331, 332, 337, 380, 384, 416, 567, 594, 596, 629, 630, 634, 635, 644], "just": [17, 22, 23, 86, 87, 112, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 135, 136, 137, 138, 141, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 175, 176, 178, 179, 180, 213, 217, 224, 265, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 406, 594, 615, 622, 623, 624, 625, 626, 627, 628, 630, 634, 637, 638, 639, 641, 643, 644], "care": [17, 20, 21, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 338, 341, 348, 393, 622, 624, 626, 637, 638, 639, 641], "desir": [17, 18, 30, 32, 34, 35, 36, 38, 52, 59, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 216, 218, 225, 227, 246, 248, 250, 251, 265, 271, 272, 275, 277, 288, 295, 297, 298, 305, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 344, 345, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 622, 626, 634, 637, 638, 639, 641], "parametr": [17, 307, 345, 350, 352, 357, 364, 371, 622, 624], "pair": [17, 22, 55, 79, 86, 87, 120, 123, 124, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 255, 265, 270, 283, 302, 325, 327, 328, 330, 331, 342, 345, 366, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 581, 603, 622, 623, 624, 628, 629, 636, 639, 644], "state_spec": [17, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 225, 230, 243, 246, 271, 273, 274, 383, 639, 644], "empti": [17, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 98, 120, 123, 126, 130, 137, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 206, 229, 232, 250, 252, 266, 272, 275, 277, 280, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 397, 403, 615, 622, 639], "reward_spec": [17, 18, 19, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 218, 219, 224, 225, 229, 230, 232, 242, 243, 252, 256, 257, 258, 260, 262, 269, 271, 273, 274, 280, 383, 594, 624, 634, 637, 638, 639, 644], "done_spec": [17, 18, 19, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 229, 230, 232, 233, 243, 252, 262, 269, 271, 273, 383, 637, 638, 639, 644], "termin": [17, 18, 19, 22, 26, 32, 34, 35, 36, 38, 52, 66, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 100, 108, 120, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 142, 143, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 178, 179, 180, 185, 208, 213, 214, 217, 218, 233, 239, 252, 265, 273, 302, 304, 341, 346, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 386, 387, 388, 389, 390, 402, 403, 594, 615, 622, 623, 624, 625, 627, 628, 630, 631, 634, 636, 637, 638, 639, 640, 641, 643, 644], "input_spec": [17, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 225, 229, 230, 231, 244, 248, 252, 253, 258, 259, 262, 263, 264, 265, 269, 271, 272, 273, 276, 383, 624, 639], "full_action_spec": [17, 120, 123, 126, 130, 138, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 175, 178, 179, 180, 214, 230, 624, 637, 638], "full_state_spec": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 214, 230, 624], "output_spec": [17, 19, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 272, 273, 280, 383, 639], "full_observation_spec": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180], "full_reward_spec": [17, 18, 19, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 218, 230, 252, 637, 638], "full_done_spec": [17, 18, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 218, 230, 252, 637, 638], "carri": [17, 19, 50, 62, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 265, 280, 366, 376, 378, 380, 384, 623, 625, 637, 638, 639, 641], "spec_lock": [17, 126], "modif": [17, 19, 22, 24, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 236, 239, 326, 332, 337, 366, 376, 378, 380, 383, 384, 594, 624, 639], "children": [17, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "unlock": [17, 22, 60, 71, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "set_spec_lock_": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "reason": [17, 21, 22, 23, 27, 83, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 275, 304, 326, 332, 337, 376, 378, 380, 383, 384, 594, 622, 623, 624, 629, 630, 637, 639, 641], "cach": [17, 20, 32, 35, 36, 38, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 102, 108, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 194, 212, 217, 229, 232, 250, 271, 272, 277, 324, 407, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589, 594], "modifi": [17, 18, 22, 26, 27, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 225, 227, 236, 239, 241, 243, 250, 265, 271, 272, 275, 277, 280, 312, 325, 326, 327, 328, 330, 331, 332, 337, 344, 345, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 555, 594, 622, 623, 624, 626, 627, 637, 638, 639], "often": [17, 22, 27, 351, 366, 368, 376, 378, 380, 384, 416, 622, 623, 627, 629, 639, 641, 644], "principl": [17, 594], "new_spec": 17, "eras": [17, 21, 22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272], "relock": 17, "wa": [17, 22, 24, 26, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 91, 95, 102, 107, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 185, 213, 221, 239, 272, 325, 326, 327, 328, 330, 331, 332, 337, 349, 351, 365, 368, 370, 377, 379, 380, 381, 382, 385, 403, 568, 570, 573, 574, 575, 576, 578, 581, 583, 589, 623, 624, 627, 628, 636, 637, 641, 643], "previous": [17, 23, 81, 403, 624, 644], "importantli": [17, 342, 345], "action_s": 17, "prealloc": [17, 22, 150, 158, 639], "necessarili": [17, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 644], "present": [17, 18, 19, 22, 52, 65, 66, 68, 69, 74, 78, 79, 83, 86, 87, 88, 101, 102, 107, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 234, 255, 259, 265, 270, 272, 288, 289, 290, 291, 292, 293, 300, 302, 304, 311, 312, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 345, 346, 347, 349, 350, 351, 352, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 566, 622, 632, 636, 637, 638, 641, 643], "0s": [17, 78, 83, 265, 625], "step_and_maybe_reset": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 594, 627, 634], "next": [17, 18, 19, 23, 27, 34, 35, 38, 53, 56, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 92, 93, 100, 102, 108, 109, 114, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 136, 137, 138, 142, 143, 144, 148, 149, 150, 151, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 178, 179, 180, 183, 185, 188, 190, 192, 193, 195, 206, 212, 214, 217, 218, 220, 221, 226, 227, 229, 232, 233, 234, 239, 240, 241, 242, 244, 248, 252, 253, 255, 258, 259, 263, 265, 267, 270, 273, 278, 279, 280, 302, 304, 316, 317, 323, 341, 349, 350, 352, 353, 354, 356, 357, 358, 359, 364, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 393, 409, 410, 413, 436, 437, 594, 615, 623, 625, 626, 628, 631, 632, 634, 636, 639, 640, 643, 644], "step_mdp": [17, 60, 71, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 302, 304, 625, 627, 639, 643, 644], "done_kei": [17, 18, 19, 56, 88, 92, 93, 100, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 217, 221, 233, 255, 263, 383, 495, 637, 638], "_reset": [17, 18, 22, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 215, 217, 218, 221, 229, 232, 240, 252, 267, 637], "data_": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "append": [17, 19, 20, 21, 27, 30, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 182, 185, 195, 217, 224, 225, 244, 255, 265, 272, 278, 297, 302, 304, 313, 594, 596, 622, 623, 624, 625, 626, 634, 637, 638, 639, 640, 641, 643], "set_se": [17, 18, 32, 34, 35, 36, 38, 50, 52, 53, 120, 121, 122, 123, 126, 130, 136, 137, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 226, 227, 246, 253, 258, 264, 266, 272, 594, 626, 630, 632, 639, 643, 644], "seed": [17, 18, 32, 34, 35, 36, 38, 50, 52, 53, 68, 69, 72, 73, 84, 120, 123, 126, 130, 138, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 175, 178, 179, 180, 181, 215, 218, 229, 232, 239, 252, 272, 391, 416, 420, 421, 475, 637], "determinist": [17, 32, 34, 35, 36, 38, 42, 44, 47, 50, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 210, 225, 250, 265, 271, 272, 275, 277, 289, 299, 308, 315, 316, 317, 326, 332, 337, 340, 342, 344, 345, 348, 350, 351, 366, 368, 376, 378, 380, 383, 384, 410, 602, 622, 623, 624, 625, 626, 628, 629, 632, 637, 639, 643, 644], "preced": [17, 123, 221, 419, 625], "risk": [17, 251], "overlap": [17, 72, 114], "mark": [17, 34, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 267, 302, 304, 386, 388, 389, 630, 641], "trail": [17, 63, 177, 279, 634], "treat": [17, 21, 628, 629], "figur": [17, 21, 622, 624, 625, 638, 639, 644], "brief": [17, 624, 627, 629, 641], "entri": [17, 19, 21, 22, 32, 35, 36, 38, 56, 60, 71, 79, 80, 81, 82, 84, 85, 86, 87, 88, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 142, 143, 150, 151, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 217, 221, 223, 224, 227, 228, 229, 230, 232, 233, 236, 240, 242, 244, 246, 248, 250, 253, 255, 258, 260, 262, 263, 264, 265, 267, 270, 272, 274, 277, 279, 297, 302, 306, 313, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 350, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 622, 624, 625, 627, 628, 629, 631, 637, 638, 639, 640, 641, 643, 644], "metaclass": [17, 126, 131], "everi": [17, 27, 32, 34, 35, 36, 38, 39, 52, 53, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 110, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 263, 264, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 326, 332, 337, 338, 341, 348, 351, 365, 366, 368, 376, 378, 380, 383, 384, 416, 622, 623, 624, 625, 627, 628, 637, 638, 639], "flank": [17, 625], "dual": 17, "strictli": [17, 27, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 242, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384, 622, 624], "union": [17, 34, 47, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 275, 277, 288, 289, 290, 291, 292, 293, 300, 305, 311, 324, 326, 332, 337, 344, 356, 358, 369, 376, 378, 380, 383, 384, 412, 563, 566], "interpret": [17, 65, 66, 68, 69, 192, 193, 594, 615, 623], "truncat": [17, 18, 19, 22, 32, 34, 35, 36, 38, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 93, 100, 102, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 178, 179, 180, 185, 213, 214, 233, 234, 239, 245, 252, 255, 259, 263, 265, 272, 273, 302, 304, 321, 330, 341, 386, 436, 437, 524, 622, 624, 625, 627, 628, 630, 631, 636, 637, 640, 641, 644], "look": [17, 19, 22, 24, 26, 27, 86, 87, 88, 102, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 226, 239, 250, 251, 275, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 346, 347, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 624, 625, 626, 627, 628, 629, 630, 631, 632, 637, 638, 639, 640, 641, 643, 644], "assess": [17, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 71, 142, 143, 166, 175, 622], "split_trajectori": [17, 32, 34, 35, 36, 38, 42, 44, 47, 50, 78, 83, 102, 108, 109], "adjac": [17, 56, 236, 341], "junction": 17, "miss": [17, 22, 23, 25, 26, 60, 88, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 239, 270, 272, 278, 282, 326, 332, 337, 346, 347, 349, 352, 368, 371, 376, 378, 380, 383, 384, 593, 615, 622, 625, 635], "inittrack": [17, 302, 304, 341, 502, 622, 625], "our": [17, 18, 21, 26, 27, 30, 42, 68, 221, 226, 393, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 636, 637, 638, 640, 641, 643], "tutori": [17, 21, 151, 184, 591, 621, 622, 623, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 639, 640, 641, 642, 644], "inform": [17, 18, 19, 21, 23, 32, 34, 35, 36, 38, 42, 44, 47, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 86, 87, 88, 101, 102, 120, 123, 126, 127, 130, 133, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 287, 288, 305, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 416, 420, 475, 622, 623, 624, 625, 626, 627, 634, 637, 638, 639, 641, 643], "scratch": [17, 27, 623, 639], "mission": 18, "irrespect": [18, 344, 345], "statu": [18, 46, 126, 189, 190], "mostli": [18, 22, 32, 393, 631, 641, 644], "Its": [18, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 279, 326, 332, 337, 344, 376, 378, 380, 383, 384, 390], "success": [18, 78, 79, 80, 81, 82, 83, 84, 85, 172, 174, 177, 178, 185, 190, 192, 221, 267, 301, 352, 372, 594, 623, 630, 632, 635, 639, 641, 643], "inspir": [18, 626, 639], "howev": [18, 24, 26, 54, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 326, 332, 337, 349, 351, 352, 365, 368, 370, 371, 376, 378, 380, 383, 384, 594, 622, 623, 625, 626, 629, 639, 641, 644], "gone": [18, 23, 24, 341], "sometim": [18, 74, 625, 644], "hard": [18, 26, 35, 36, 38, 114, 124, 125, 150, 623, 644], "accommod": [18, 19, 615, 627, 628], "extern": [18, 229, 232, 280, 324, 335, 336, 615, 634, 637, 644], "adopt": [18, 24, 622, 644], "moreov": 18, "facilit": [18, 26, 249, 250, 265, 275, 277, 283, 284, 285, 622, 625, 628, 639], "instal": [18, 24, 29, 42, 44, 47, 79, 82, 120, 123, 126, 130, 135, 138, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 190, 395, 404, 416, 593, 622, 624, 625, 626, 627, 628, 629, 630, 631, 632, 637, 638, 644], "virtual": [18, 129], "concomittantli": 18, "fortun": [18, 21, 625, 626, 627, 628, 631], "decor": [18, 27, 209, 211, 282, 302, 304, 366, 386, 387, 388, 389, 405, 594, 625, 643], "set_gym_backend": [18, 32, 34, 35, 36, 38, 52, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 175, 178, 179, 180, 217, 627, 643], "relev": [18, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 386, 387, 388, 389, 390, 401, 626, 639], "gym_backend": [18, 211], "env1": [18, 287, 636], "venv": [18, 626], "python3": [18, 25, 26, 29, 626], "site": [18, 25, 26, 84, 123, 211, 626], "env2": [18, 636], "_env": [18, 25, 129, 644], "classic_control": 18, "pendulumenv": [18, 639], "0x15147e190": 18, "0x1629916a0": 18, "further": [18, 22, 24, 384, 622, 624, 626, 627], "mo_gymnasium": [18, 140, 169, 242], "handi": [18, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 631], "v0": [18, 35, 36, 38, 60, 71, 86, 87, 120, 123, 126, 130, 132, 135, 136, 137, 138, 139, 140, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 225, 242, 272, 279, 280, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 405, 562], "26": [18, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 195, 196, 226, 623, 637], "fun": [18, 211, 282, 624, 637, 638], "effect": [18, 22, 34, 52, 53, 60, 65, 66, 68, 69, 72, 73, 78, 83, 86, 87, 88, 101, 102, 106, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 217, 221, 227, 272, 325, 326, 327, 328, 330, 331, 332, 337, 351, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 416, 421, 594, 622, 628, 637, 641, 644], "autoresettransform": [18, 479], "skip": [18, 20, 22, 33, 34, 39, 42, 43, 44, 45, 47, 48, 50, 52, 53, 78, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 237, 239, 244, 270, 272, 326, 331, 332, 337, 342, 345, 352, 366, 371, 376, 378, 380, 383, 384, 386, 387, 388, 389, 392, 393, 408, 410, 420, 421, 475, 622, 623, 635, 639], "fine": [18, 68, 69, 72, 73, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 218, 241, 326, 332, 337, 384, 594, 626, 630, 640], "grain": [18, 68, 69, 72, 73, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 218, 326, 332, 337], "invalid": [18, 88, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 166, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 306, 326, 332, 333, 337, 376, 378, 380, 383, 384, 635], "nan": [18, 217, 278, 479], "auto_reset": [18, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 217, 639], "auto_reset_replac": [18, 217], "replac": [18, 21, 25, 26, 78, 83, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 217, 231, 233, 240, 279, 280, 301, 324, 326, 332, 337, 350, 352, 358, 364, 369, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 435, 437, 479, 637, 641, 643], "placehold": [18, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 131, 132, 175, 233, 272, 278], "manual_se": [18, 57, 61, 65, 68, 72, 73, 80, 84, 85, 86, 87, 96, 108, 109, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 215, 217, 226, 227, 231, 246, 255, 258, 264, 266, 280, 298, 301, 306, 310, 312, 325, 327, 328, 330, 331, 340, 345, 348, 349, 350, 352, 353, 357, 364, 371, 377, 379, 381, 382, 385, 626, 630, 632, 637, 638, 639, 643, 644], "autoresettinggymenv": [18, 217], "_step": [18, 21, 22, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 236, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 383], "td_reset": [18, 217], "exclud": [18, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 84, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 195, 196, 212, 217, 221, 234, 329, 337, 351, 365, 368, 380, 637, 638, 641], "r": [18, 20, 23, 86, 87, 89, 123, 172, 175, 176, 190, 193, 197, 214, 215, 217, 224, 226, 227, 246, 260, 267, 270, 279, 280, 287, 325, 327, 328, 330, 331, 345, 368, 377, 379, 381, 382, 385, 391, 594, 623, 626, 639, 644], "break_when_any_don": [18, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 217, 270, 287, 341, 638], "squeez": [18, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 217, 218, 221, 226, 261, 264, 288, 622, 626, 639, 641], "creation": [18, 19, 150, 158, 196, 332, 380, 475, 570, 589, 644], "imposs": [18, 20, 68, 72, 73, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 349, 351, 365, 368, 370], "forecast": 18, "awar": [18, 26, 60, 71, 88, 90, 95, 96, 97, 98, 110, 112, 116, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 271, 302, 304, 324, 383, 623, 625], "detect": [18, 20, 85, 87, 89, 174, 178, 366, 375, 376, 378, 380, 384, 402, 580, 594, 596], "return_contigu": [18, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 636], "tensordictbas": [18, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 114, 120, 123, 126, 128, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 212, 213, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 233, 234, 235, 236, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 280, 286, 298, 301, 302, 304, 312, 314, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 345, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 416, 567, 568, 570, 571, 573, 574, 576, 577, 578, 580, 581, 583, 589, 622, 637, 639], "envwithdynamicspec": 18, "max_count": 18, "bool": [18, 19, 22, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 94, 95, 96, 97, 98, 101, 102, 104, 106, 107, 108, 109, 110, 115, 116, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 213, 214, 215, 217, 218, 221, 222, 226, 227, 229, 231, 232, 233, 234, 236, 239, 241, 243, 244, 245, 246, 248, 250, 252, 253, 255, 257, 258, 259, 262, 263, 265, 268, 269, 270, 272, 273, 274, 275, 277, 279, 280, 282, 286, 287, 288, 290, 291, 297, 298, 302, 303, 304, 305, 306, 313, 314, 317, 319, 320, 321, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 340, 341, 342, 344, 345, 346, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 393, 401, 402, 405, 408, 409, 410, 412, 413, 416, 420, 421, 422, 423, 424, 425, 427, 428, 429, 430, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 477, 479, 480, 505, 507, 508, 518, 524, 529, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 566, 567, 568, 570, 571, 573, 574, 576, 578, 580, 581, 582, 583, 584, 585, 587, 589, 594, 623, 624, 625, 626, 627, 628, 630, 631, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "_set_se": [18, 215, 218, 229, 232, 252, 639], "int": [18, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 94, 95, 96, 97, 98, 101, 102, 103, 104, 106, 108, 109, 110, 114, 115, 116, 118, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 142, 143, 144, 145, 146, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 205, 206, 214, 216, 217, 218, 220, 221, 222, 223, 225, 228, 231, 236, 237, 239, 243, 244, 245, 246, 248, 250, 251, 254, 261, 262, 263, 266, 269, 270, 272, 274, 275, 277, 286, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 301, 303, 305, 306, 308, 309, 311, 312, 314, 315, 316, 319, 320, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 341, 342, 344, 345, 349, 350, 351, 358, 360, 361, 365, 366, 367, 368, 369, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 389, 392, 393, 395, 398, 400, 401, 402, 406, 407, 408, 410, 412, 416, 419, 420, 421, 422, 423, 424, 425, 427, 428, 429, 430, 431, 433, 436, 437, 440, 441, 442, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 466, 467, 474, 475, 477, 479, 480, 482, 483, 484, 485, 490, 493, 499, 505, 506, 507, 509, 512, 515, 522, 523, 524, 527, 530, 531, 534, 547, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 581, 582, 583, 584, 589, 626, 639, 641], "lazystackedtensordict": [18, 52, 71, 78, 86, 87, 96, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 636], "field": [18, 19, 22, 32, 34, 35, 36, 38, 52, 53, 56, 60, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 101, 108, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 218, 229, 232, 233, 234, 239, 248, 252, 253, 255, 259, 262, 263, 265, 270, 272, 273, 283, 284, 285, 287, 296, 297, 298, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 342, 344, 347, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 475, 556, 593, 594, 623, 624, 625, 627, 628, 629, 630, 631, 635, 636, 637, 638, 639, 640, 641, 644], "float32": [18, 21, 34, 35, 38, 58, 60, 65, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 95, 96, 97, 101, 102, 108, 116, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 144, 147, 148, 149, 150, 151, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 206, 212, 214, 218, 229, 232, 233, 234, 239, 242, 246, 248, 252, 253, 255, 259, 262, 263, 265, 268, 273, 283, 284, 285, 287, 296, 297, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 342, 344, 347, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 491, 624, 625, 626, 627, 628, 629, 630, 631, 634, 636, 637, 638, 639, 640, 641, 644], "is_shar": [18, 22, 34, 35, 38, 52, 56, 60, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 95, 96, 97, 101, 108, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 185, 212, 214, 218, 229, 232, 233, 234, 239, 248, 252, 253, 255, 259, 262, 263, 265, 273, 279, 283, 284, 285, 287, 296, 297, 298, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 342, 344, 347, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 624, 625, 627, 628, 629, 630, 631, 636, 637, 638, 639, 640, 641, 644], "exclusive_field": [18, 52, 78, 86, 87, 96, 120, 172, 175, 176, 185, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 636], "stack_dim": [18, 52, 78, 86, 87, 96, 120, 172, 175, 176, 185, 205, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 428, 636], "absenc": [18, 22], "dramat": 18, "carefulli": [18, 183, 637, 638, 644], "against": [18, 24, 26, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 297, 298, 313, 314, 326, 332, 337, 340, 342, 344, 345, 350, 352, 364, 369, 371, 372, 373, 376, 378, 380, 383, 384, 624, 637, 638], "plain": [18, 27, 350, 352, 358, 364, 369, 371, 372, 373, 387, 388, 389, 627], "deseri": 18, "larg": [18, 23, 59, 86, 87, 101, 102, 108, 109, 176, 229, 232, 275, 324, 325, 327, 328, 330, 331, 332, 349, 351, 365, 368, 370, 377, 379, 380, 381, 382, 385, 570, 623, 624, 635, 637, 638, 641], "expens": [18, 20, 53, 102, 108, 109, 391, 641], "check_env_spec": [18, 20, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 214, 239, 252, 273, 391, 624, 637, 638, 639], "vari": [18, 19, 129, 131, 132, 152, 153, 155, 163, 251, 626, 638], "absent": [18, 60, 71, 79, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 259, 272], "view": [19, 27, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 83, 84, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 305, 326, 332, 337, 376, 378, 380, 383, 384, 594, 627, 639, 641, 643, 644], "act": [19, 22, 23, 108, 109, 152, 153, 272, 296, 350, 352, 353, 364, 369, 371, 372, 373, 625, 626, 637, 638, 641, 643], "paradigm": [19, 32, 638], "decpodp": 19, "markov": [19, 627, 644], "game": [19, 20, 23, 24, 78, 123, 142, 143, 148, 149, 226, 288, 393, 626, 631], "thank": [19, 170, 195, 196, 384, 622, 626, 627, 643], "carrier": [19, 624, 625, 627, 641], "particular": [19, 79, 80, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 272, 326, 332, 337, 376, 378, 380, 383, 384, 623, 625, 627, 636, 638, 641], "thu": [19, 365, 638], "vma": [19, 163, 164, 391, 461, 637, 638], "robot": [19, 24, 26, 83, 250, 275, 277, 368, 626, 638], "vmasenv": [19, 391, 461, 637, 638], "balanc": [19, 101, 102, 124, 125, 324, 622, 623, 644], "num_env": [19, 32, 35, 36, 38, 50, 120, 129, 133, 146, 163, 164, 171, 172, 175, 181, 391, 448, 452, 615, 637, 638], "n_agent": [19, 163, 164, 391, 637, 638], "td": [19, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 101, 102, 114, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 139, 140, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 175, 176, 178, 179, 180, 183, 185, 186, 190, 212, 215, 218, 220, 222, 226, 227, 229, 230, 231, 232, 240, 241, 242, 244, 246, 255, 258, 262, 265, 268, 272, 279, 283, 284, 285, 287, 296, 297, 301, 312, 313, 322, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 343, 344, 347, 376, 377, 378, 379, 380, 381, 382, 384, 385, 387, 388, 389, 392, 406, 414, 594, 608, 622, 623, 625, 638, 639, 640, 643], "info": [19, 35, 38, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 106, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 142, 143, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 175, 178, 179, 180, 190, 239, 273, 275, 278, 281, 401, 573, 574, 575, 576, 627, 632, 634, 637, 638, 641, 643], "ground_rew": 19, "pos_rew": [19, 638], "16": [19, 20, 32, 35, 36, 38, 52, 84, 88, 102, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 324, 326, 329, 332, 337, 376, 378, 380, 383, 384, 615, 622, 623, 625, 637, 638, 641], "style": [19, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 187, 197, 203, 376, 421], "info_spec": [19, 150], "agent_i_action_spec": 19, "agent_i_reward_spec": 19, "agent_i_observation_spec": 19, "prefix": [19, 56, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 267, 270, 272, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 352, 366, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 392, 402, 416, 420, 475, 625, 629, 634, 644], "exactli": [19, 88, 120, 123, 126, 130, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 310, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384, 622, 625, 630, 637, 638], "action_kei": [19, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 214, 215, 231, 241, 244, 286, 301, 312, 341, 343, 477, 637, 638], "reward_kei": [19, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 409, 413, 637, 638], "right": [19, 22, 25, 26, 56, 102, 108, 180, 226, 332, 337, 623, 624, 626, 638, 639, 644], "set_kei": [19, 233, 349, 351, 352, 354, 357, 358, 359, 364, 365, 366, 368, 369, 370, 371, 376, 378, 380, 384, 390, 622, 637, 638], "awai": [19, 624, 627, 637, 638, 643], "eas": [19, 637, 638], "access": [19, 21, 26, 27, 30, 32, 34, 35, 36, 38, 52, 53, 65, 80, 81, 82, 88, 95, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 221, 250, 271, 275, 324, 326, 332, 337, 376, 378, 380, 383, 384, 402, 403, 404, 566, 577, 592, 593, 608, 622, 627, 637, 638, 639, 641, 643], "leaf": [19, 21, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 240, 263, 265, 271, 345], "abov": [19, 21, 22, 26, 54, 75, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 271, 303, 320, 321, 326, 332, 337, 376, 378, 380, 383, 384, 594, 622, 624, 626, 627, 628, 637, 638, 639, 644], "would": [19, 21, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 302, 304, 305, 326, 332, 337, 345, 376, 378, 380, 383, 384, 623, 624, 625, 627, 629, 630, 639, 641, 643, 644], "ey": 20, "report": [20, 121, 122, 136, 137, 420, 631], "foremost": 20, "callback": [20, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 638], "callabl": [20, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 120, 123, 126, 127, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 211, 216, 218, 225, 226, 227, 233, 239, 243, 265, 272, 273, 282, 288, 303, 305, 320, 326, 332, 337, 345, 366, 376, 378, 380, 383, 384, 391, 419, 420, 421, 557, 558, 564, 565, 566, 581, 623, 641], "upon": [20, 27, 41, 637, 639], "ad": [20, 23, 32, 34, 35, 36, 38, 52, 56, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 258, 270, 272, 312, 325, 326, 327, 328, 330, 331, 332, 337, 349, 351, 352, 354, 359, 365, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 594, 623, 625, 626, 628, 634, 637, 641, 643, 644], "save": [20, 27, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 98, 100, 110, 111, 112, 116, 117, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 278, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 392, 393, 395, 401, 416, 420, 421, 475, 615, 616, 630, 631, 632, 637, 638], "disk": [20, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 91, 95, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 416, 622, 623, 625, 630, 631, 637, 641], "tensordictrecord": 20, "imag": [20, 23, 26, 30, 83, 86, 90, 221, 223, 226, 228, 250, 268, 277, 305, 391, 393, 622, 623, 626, 627, 631, 638, 640, 644], "pixel": [20, 21, 22, 26, 60, 69, 85, 123, 124, 125, 129, 131, 132, 155, 221, 223, 228, 233, 236, 238, 246, 248, 250, 254, 268, 275, 277, 290, 308, 309, 391, 393, 622, 623, 625, 626, 631, 637, 640, 641, 643, 644], "atari": [20, 22, 23, 78, 79, 80, 81, 83, 84, 85, 90, 221, 288, 393, 626, 631, 644], "videorecord": [20, 30, 391, 624, 631, 632, 637], "csvlogger": [20, 30, 391, 393, 462, 616, 623, 631, 632, 637], "wandblogg": [20, 465, 616, 631], "tensorboardlogg": [20, 464, 562, 616, 631], "tag": [20, 26, 30, 174, 175, 177, 187, 200, 203, 391, 393, 395, 398, 566, 594, 631, 632, 634, 637], "mp4": [20, 391, 393, 395, 632, 637], "video_format": [20, 391, 393, 395, 462, 632, 637], "whc": 20, "cwh": 20, "dummi": [20, 160, 185, 391, 622, 626, 630, 644], "exp": [20, 307], "al": [20, 32, 34, 35, 36, 38, 52, 129, 131, 233, 248, 495, 626, 644], "pong": [20, 32, 34, 35, 36, 38, 52, 78, 146, 248, 626, 644], "v5": [20, 32, 34, 35, 36, 38, 52, 129, 131, 146, 233, 248, 626, 644], "append_transform": [20, 21, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 207, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 280, 287, 302, 304, 383, 391, 594, 615, 622, 625, 634, 637, 639, 641, 643, 644], "grow": [20, 96], "tediou": [20, 627], "workspac": [20, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 239], "assum": [20, 22, 25, 34, 35, 36, 37, 38, 39, 46, 49, 50, 54, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 72, 73, 74, 75, 76, 77, 79, 81, 83, 84, 85, 92, 93, 100, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 206, 220, 223, 228, 236, 250, 251, 258, 265, 272, 275, 277, 287, 302, 304, 348, 354, 358, 359, 371, 383, 393, 567, 622, 624, 636, 639], "pixelrendertransform": [20, 637], "stream": [20, 83, 90], "alik": [20, 391], "envcreat": [20, 34, 50, 51, 150, 158, 270, 280, 391, 562, 563, 566, 622, 623, 643, 644], "render_mod": [20, 391, 448, 452, 639], "rgb_arrai": [20, 391, 637, 638, 639], "uncom": [20, 631], "line": [20, 26, 78, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 623, 631, 637, 638], "__name__": [20, 32, 34, 35, 36, 38, 51, 52, 66, 127, 280, 391, 623, 643], "__main__": [20, 32, 34, 35, 36, 38, 51, 52, 66, 127, 280, 391, 643], "comment": [20, 623, 643], "pixels_record": [20, 391], "close": [20, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 52, 66, 88, 120, 130, 145, 173, 174, 177, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 241, 271, 280, 339, 349, 351, 365, 368, 380, 383, 391, 569, 622, 623, 627, 634, 636, 637, 639, 643], "purpos": [20, 21, 22, 26, 30, 35, 36, 38, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 197, 221, 325, 327, 328, 330, 331, 349, 351, 363, 365, 368, 370, 377, 379, 380, 381, 382, 385, 562, 615, 622, 624, 625, 626, 629, 631, 637, 638, 640, 644], "raw": [21, 23, 90, 199, 239, 269, 273, 303, 320, 321, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589, 623, 626, 630, 639], "torchvis": [21, 30, 250, 277, 395, 637, 643, 644], "from_pixel": [21, 22, 30, 121, 122, 124, 125, 129, 131, 132, 136, 137, 155, 221, 254, 391, 393, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 622, 623, 625, 627, 631, 632, 640, 641, 643, 644], "totensorimag": [21, 69, 85, 221, 254, 529, 623, 625, 626, 641, 643, 644], "resiz": [21, 69, 85, 221, 515, 623, 625, 626, 627, 641, 644], "64": [21, 69, 78, 83, 86, 87, 176, 221, 254, 290, 291, 300, 302, 304, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 466, 601, 615, 622, 623, 624, 625, 626, 628, 632, 636, 639, 641, 643, 644], "appar": [21, 408], "bring": [21, 624, 627, 644], "speedup": [21, 22, 27, 637, 644], "kind": [21, 68, 74, 629, 637, 641], "great": [21, 22, 26, 27, 626, 635, 637, 643], "consult": 21, "interest": [21, 22, 342, 345, 623, 624, 627, 638, 639, 644], "resize_par": 21, "inv": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 224, 231, 234, 239, 248, 255, 260, 262, 267, 271, 274, 383, 639], "revers": 21, "chain": [21, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 138, 170, 176, 178, 179, 194, 195, 225, 231, 288, 317, 325, 327, 328, 330, 331, 347, 377, 379, 381, 382, 385, 594, 644], "taken": [21, 53, 57, 59, 61, 62, 64, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 214, 254, 306, 622, 624, 625, 628, 637, 638, 639], "in_keys_inv": [21, 194, 199, 207, 224, 229, 230, 232, 239, 246, 247, 248, 252, 253, 255, 260, 269, 271, 273, 274, 486, 491, 492, 494, 622, 636, 639, 644], "doubletofloat": [21, 494, 622, 624, 636], "float64": [21, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 124, 125, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 225, 229, 232, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384, 636, 644], "paragraph": [21, 22], "in_": 21, "out_": 21, "perspect": [21, 183, 298, 359, 624, 626], "inner": [21, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 231, 272, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589, 616, 623, 624, 638, 644], "outer": [21, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272, 616, 622, 623, 644], "ob": [21, 23, 27, 56, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 101, 108, 109, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 212, 215, 217, 226, 229, 230, 232, 246, 260, 262, 268, 290, 291, 292, 293, 313, 322, 350, 352, 353, 358, 364, 369, 371, 372, 373, 386, 387, 388, 389, 623, 626, 636, 637, 639, 641, 643, 644], "obs_standard": 21, "similarli": [21, 50, 88, 107, 112, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 244, 326, 332, 337, 346, 347, 357, 364, 376, 378, 380, 383, 384, 386, 594, 644], "seen": [21, 42, 44, 47, 50, 60, 71, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 230, 622, 623, 625, 629, 637, 638, 641], "out_keys_inv": [21, 194, 199, 207, 224, 229, 230, 232, 239, 246, 247, 248, 252, 253, 260, 262, 269, 271, 273, 274, 486, 491, 492, 494, 639], "produc": [21, 34, 60, 71, 108, 214, 217, 218, 283, 285, 288, 305, 310, 345, 386, 393, 624, 625, 626, 627, 628, 630, 641, 644], "illustr": [21, 622, 623, 628, 641], "renametransform": [21, 69, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 514], "renam": [21, 60, 69, 71, 86, 87, 171, 176, 212, 253, 255, 272, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 622], "schemat": 21, "outermost": 21, "innermost": 21, "similar": [21, 63, 68, 83, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 276, 277, 279, 280, 283, 285, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 344, 345, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 569, 585, 622, 623, 624, 625, 626, 628, 629, 630, 631, 639, 641, 643, 644], "transform_action_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 230, 243, 246, 271, 273, 274, 383], "pseudocod": 21, "could": [21, 22, 23, 25, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 345, 376, 378, 380, 383, 384, 615, 623, 624, 631, 637, 638, 640, 644], "spec_from_random_valu": 21, "_apply_transform": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 383, 626, 639, 644], "rand": [21, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 96, 121, 122, 136, 137, 144, 148, 149, 161, 162, 215, 218, 229, 232, 252, 262, 342, 343, 349, 350, 352, 353, 354, 356, 357, 358, 364, 366, 368, 369, 371, 372, 373, 376, 378, 380, 384, 626, 639, 643, 644], "did": [21, 68, 278, 623, 624, 630, 641, 644], "_inv_apply_transform": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 271, 383, 639, 644], "actiondiscret": [21, 477], "rand_act": [21, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 218, 272, 627], "action_discret": 21, "counterpart": [21, 221], "obtain": [21, 26, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 196, 220, 250, 264, 277, 287, 412, 622, 624, 626, 627, 628, 629, 637, 638], "addonetoob": 21, "There": [21, 29, 69, 86, 87, 172, 176, 271, 302, 304, 325, 327, 328, 330, 331, 349, 368, 377, 379, 381, 382, 385, 624, 625, 626, 628, 630, 637, 638, 639, 641, 643, 644], "Is": [21, 271], "ident": [21, 34, 35, 38, 68, 69, 72, 73, 86, 87, 95, 108, 120, 123, 126, 129, 130, 131, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 233, 262, 271, 280, 325, 327, 328, 330, 331, 350, 352, 364, 369, 371, 372, 373, 377, 379, 381, 382, 385, 386, 387, 388, 389, 564, 565, 623, 627, 637, 638], "rewrit": [21, 271], "otherwis": [21, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 109, 120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 222, 226, 227, 231, 239, 246, 264, 265, 266, 270, 271, 272, 279, 282, 297, 303, 313, 320, 321, 325, 326, 327, 328, 330, 331, 332, 337, 345, 348, 350, 352, 361, 366, 367, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 389, 410, 412, 568, 569, 570, 571, 573, 574, 575, 576, 578, 581, 583, 585, 589, 622, 623, 624, 625, 634, 639, 644], "_call": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 231, 233, 234, 235, 236, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 383, 634, 639], "_inv_cal": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 271, 383], "overwrit": [21, 271], "till": [21, 271, 278], "encapsul": [21, 271, 627, 628, 629], "don": [21, 22, 23, 25, 26, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 170, 197, 221, 271, 306, 324, 615, 623, 624, 626, 630, 641, 643, 644], "forget": [21, 271], "transform_output_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 273, 280, 383], "transform_input_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 225, 229, 230, 231, 244, 248, 252, 253, 258, 262, 263, 264, 265, 269, 271, 273, 276, 383], "transform_observation_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 222, 223, 224, 225, 228, 229, 230, 233, 234, 236, 238, 240, 241, 243, 244, 246, 248, 252, 253, 254, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 278, 279, 280, 383, 639], "transform_state_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 230, 243, 246, 271, 273, 274, 383], "transform_reward_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 219, 224, 225, 229, 230, 234, 241, 242, 243, 244, 252, 253, 256, 257, 258, 259, 260, 262, 263, 269, 271, 273, 274, 280, 383, 594, 634], "undo": [21, 183], "addonetoact": 21, "subtract": [21, 188, 264], "properti": [21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 270, 271, 272, 279, 280, 286, 295, 303, 306, 310, 319, 320, 321, 325, 326, 327, 328, 329, 330, 331, 332, 337, 341, 349, 352, 366, 368, 370, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 568, 570, 571, 573, 574, 576, 577, 578, 581, 583, 589, 628, 630, 639, 641], "manipul": [21, 23, 27, 124, 125, 250, 271, 275, 644], "third_transform": 21, "assert": [21, 22, 25, 34, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 114, 120, 123, 126, 130, 133, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 183, 206, 211, 214, 218, 221, 224, 229, 232, 241, 253, 260, 272, 279, 287, 307, 325, 327, 328, 330, 331, 339, 377, 379, 381, 382, 384, 385, 386, 387, 388, 389, 405, 406, 414, 466, 467, 470, 471, 472, 615, 630, 636, 641, 644], "lead": [21, 23, 27, 29, 52, 56, 60, 65, 68, 71, 79, 101, 107, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 265, 282, 303, 320, 321, 622, 625, 626, 637, 638, 639, 641, 643], "unexpect": [21, 34, 35, 36, 38, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 644], "behviour": 21, "rais": [21, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 81, 83, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 165, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 221, 235, 245, 255, 264, 265, 266, 270, 272, 279, 286, 301, 312, 325, 326, 327, 328, 330, 331, 332, 333, 337, 352, 366, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 403, 404, 405, 568, 570, 573, 574, 575, 576, 577, 578, 579, 581, 583, 589, 615, 622, 624, 637, 638, 641], "catfram": [21, 341, 483, 623], "hold": [21, 22, 271, 383, 570, 639, 641], "notic": [21, 114, 221, 624, 632, 639], "parenthood": 21, "henc": [21, 53, 65, 213, 251, 622, 624, 637, 638, 639], "transform2": 21, "transform3": 21, "last_two": 21, "isinst": [21, 150, 158, 272, 391, 405, 471, 626, 639], "discret": [21, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 129, 130, 131, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 214, 231, 239, 310, 356, 357, 358, 359, 623, 624, 628, 637, 638, 639, 644], "might": [21, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 397, 593, 622, 627, 644], "throughout": [21, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 624, 637, 644], "action_mask": [21, 123, 136, 137, 152, 153, 156, 157, 215, 478, 635], "unavail": [21, 152, 153], "probabl": [21, 23, 27, 69, 101, 102, 106, 188, 189, 195, 196, 287, 295, 301, 302, 304, 305, 306, 310, 317, 320, 321, 326, 329, 332, 337, 342, 345, 352, 358, 368, 371, 376, 378, 380, 384, 623, 626, 628, 643], "probabilistictensordictmodul": [21, 241, 345, 346, 643], "tensordictsequenti": [21, 287, 297, 301, 302, 304, 312, 326, 332, 337, 339, 341, 346, 347, 376, 378, 380, 384, 622, 623, 625, 626, 628, 632, 636, 637, 640, 643], "maskedcategor": [21, 601], "in_feat": 21, "out_feat": 21, "logit": [21, 296, 298, 306, 310, 326, 329, 332, 337, 342, 357, 358, 594], "dist": [21, 29, 303, 306, 310, 320, 345, 628], "distribution_class": [21, 241, 283, 284, 285, 342, 345, 347, 349, 350, 352, 357, 358, 364, 368, 369, 370, 371, 601, 622, 624, 628, 637, 638, 643], "wrap": [21, 24, 32, 34, 35, 36, 38, 42, 44, 47, 50, 81, 88, 120, 121, 122, 123, 126, 130, 131, 135, 136, 137, 138, 143, 146, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 162, 164, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 227, 243, 270, 272, 282, 283, 284, 285, 302, 304, 313, 323, 326, 329, 332, 337, 341, 345, 366, 376, 378, 380, 383, 384, 594, 622, 623, 624, 625, 629, 632, 634, 637, 638, 644], "actionmask": [21, 123, 478], "know": [21, 22, 23, 28, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 68, 72, 73, 129, 131, 286, 366, 369, 376, 378, 380, 384, 410, 622, 623, 624, 625, 626, 627, 628, 629, 630, 637, 638, 641], "your_base_env": 21, "mask_kei": [21, 56, 215, 251, 326, 332, 337, 478], "intens": [22, 27], "gym3": 22, "envpool": [22, 145, 146, 454], "scale": [22, 23, 79, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 177, 178, 179, 180, 221, 241, 246, 257, 264, 268, 279, 280, 283, 284, 285, 299, 303, 307, 315, 316, 320, 321, 342, 345, 347, 349, 350, 352, 364, 368, 369, 370, 371, 413, 508, 518, 556, 566, 601, 622, 623, 624, 625, 628, 638, 643], "varieti": [22, 30], "serialenv": [22, 120, 123, 126, 130, 138, 150, 151, 154, 159, 160, 170, 171, 172, 175, 178, 179, 180, 265, 280, 287, 341, 643, 644], "Of": [22, 26, 593, 639, 644], "cours": [22, 23, 593, 639, 644], "saniti": [22, 26, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 624], "9": [22, 26, 56, 65, 68, 72, 84, 85, 86, 87, 102, 109, 114, 124, 125, 141, 152, 153, 160, 176, 214, 217, 226, 227, 264, 267, 272, 279, 280, 306, 325, 327, 328, 330, 331, 332, 337, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 384, 385, 405, 420, 542, 544, 545, 546, 548, 549, 550, 554, 622, 623, 624, 626, 630, 637, 638, 639, 641], "81": [22, 86, 87, 108, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 623], "c": [22, 25, 26, 32, 34, 35, 36, 38, 52, 60, 68, 72, 73, 82, 86, 87, 95, 96, 176, 246, 268, 273, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 384, 385, 623, 641], "d": [22, 60, 65, 68, 71, 72, 73, 80, 82, 84, 85, 101, 102, 326, 332, 337, 342, 345, 376, 378, 380, 384, 643], "forc": [22, 25, 26, 32, 35, 36, 38, 42, 44, 47, 50, 78, 80, 81, 83, 84, 85, 151, 332, 623, 637, 638, 639], "launch": [22, 32, 35, 36, 38, 42, 44, 47, 51, 78, 80, 150, 158, 190, 324, 333], "bottleneck": [22, 27, 102, 108, 109], "precis": [22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 212, 229, 232, 622, 624], "misspecifi": 22, "caus": [22, 26, 27, 34, 35, 36, 38, 95, 97, 101, 102, 116, 120, 123, 126, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 251, 380, 644], "breakag": 22, "mismatch": [22, 351, 368, 380, 623], "subprocess": [22, 32, 35, 36, 38, 127, 150, 158], "multithreadedenv": [22, 454], "underneath": 22, "cover": [22, 129, 131, 593, 624, 627, 630, 631, 639, 643], "classic": [22, 135, 144, 153, 623], "benchmark_batched_env": 22, "distinguish": [22, 68, 72, 73, 142, 143, 163, 164], "mere": [22, 32, 626], "batch_lock": [22, 120, 123, 126, 128, 130, 138, 150, 154, 158, 159, 170, 171, 172, 175, 178, 179, 180, 218, 265, 272, 639], "contrast": [22, 641], "braxenv": [22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 253, 445, 627], "jumanjienv": [22, 451], "straightforward": [22, 40, 622, 623, 627, 628, 629, 630, 641], "merg": [22, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 639], "deal": [22, 65, 66, 68, 69, 366, 376, 378, 380, 384, 622, 624, 638, 641], "silent": [22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 326, 338, 341, 348], "temporari": [22, 95, 97, 615, 622], "arm": 22, "unbatch": 22, "captur": [22, 190, 197, 286, 301, 312, 545, 594, 626], "content": [22, 27, 34, 60, 65, 68, 71, 72, 73, 86, 87, 89, 95, 107, 108, 109, 120, 123, 126, 129, 130, 131, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 174, 175, 176, 178, 179, 180, 184, 190, 195, 196, 252, 288, 305, 325, 327, 328, 330, 331, 332, 337, 342, 366, 376, 377, 378, 379, 380, 381, 382, 384, 385, 594, 624, 634, 635, 639, 643], "found": [22, 25, 26, 29, 32, 34, 35, 36, 38, 50, 56, 60, 71, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 213, 215, 221, 242, 255, 258, 266, 279, 280, 301, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 365, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 403, 596, 615, 622, 623, 625, 626, 627, 629, 631, 634, 639, 641, 643], "essenti": [22, 33, 42, 43, 44, 45, 47, 48, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 594, 623, 627, 637, 639, 641], "break_when_all_don": [22, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "conditionalskip": [22, 489], "programmat": 22, "pretti": [22, 622, 627, 631, 641], "likewis": 22, "te": 22, "dive": 22, "privat": [22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 278, 639, 644], "distinct": [22, 65, 66, 68, 69, 86, 87, 176, 218, 221, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 629, 636], "total": [22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 109, 114, 172, 176, 183, 226, 325, 327, 328, 330, 331, 335, 336, 351, 365, 368, 377, 379, 380, 381, 382, 385, 406, 408, 410, 416, 418, 420, 421, 475, 555, 556, 582, 608, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644], "accord": [22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 69, 71, 86, 87, 106, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 175, 176, 178, 179, 180, 246, 257, 303, 315, 317, 320, 321, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 628, 629, 637, 639, 641], "nevertheless": [22, 624, 627, 641], "wherev": 22, "expos": [22, 155, 229, 232, 346, 351, 368, 623], "lost": [22, 27, 278], "face": [22, 24, 27, 28, 329, 332, 627, 635, 644], "word": [22, 30, 78, 79, 81, 83, 84, 85, 366, 376, 378, 380, 384, 622, 630, 639, 644], "preliminari": 22, "warranti": 22, "long": [22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 95, 102, 148, 149, 231, 270, 324, 357, 380, 625, 626, 630, 641], "assumpt": [22, 74, 639, 641], "preclud": 22, "presenc": [22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 326, 332, 337, 376, 378, 380, 384, 629], "annihil": 22, "known": [22, 24, 26, 27, 130, 180, 265, 622, 623, 627], "supersed": [22, 56], "pettingzoowrapp": 22, "associ": [22, 60, 66, 71, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 271, 315, 325, 326, 327, 328, 329, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 403, 566, 568, 574, 576, 622, 641], "__not__": [22, 342, 350, 352, 364, 369, 371, 372, 373], "constrain": [22, 241, 302, 304, 368, 644], "li": 22, "fact": [22, 26, 27, 594, 622, 624, 627, 637, 638, 639, 640, 641, 644], "predict": [22, 296, 299, 323, 349, 351, 356, 359, 361, 362, 365, 368, 370, 380, 622, 623, 629], "meaning": [22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 177, 418], "perfectli": [22, 622, 626, 639], "meaningless": 22, "discard": [22, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 79, 81, 130, 212, 275, 392, 641, 644], "val": [22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 171, 280, 303, 320, 405, 626, 629, 643], "agent0": [22, 368, 626], "agent1": [22, 368], "elimin": [22, 627], "500": [22, 622, 623, 626, 644], "uint8": [22, 60, 78, 83, 86, 87, 124, 125, 142, 143, 176, 233, 239, 248, 268, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 623, 631, 640, 641, 644], "significantli": [22, 33, 42, 43, 44, 45, 47, 48, 90, 108, 109, 221, 351, 368, 380, 570, 622, 623, 629, 638], "asyncenvpool": [22, 52, 154, 159], "thread": [22, 32, 34, 35, 36, 38, 50, 52, 53, 86, 87, 120, 121, 122, 136, 137, 150, 158, 159, 176, 190, 280, 324, 325, 326, 327, 328, 330, 331, 332, 337, 377, 379, 381, 382, 385, 568, 570, 571, 573, 574, 576, 578, 581, 583, 584, 589], "pool": [22, 78, 79, 80, 81, 82, 83, 84, 85, 120, 154, 159, 192, 266, 615], "concurr": [22, 120, 324, 329, 418, 615, 637, 638], "contrari": 22, "permit": [22, 224, 236, 262, 274, 349, 351, 365, 368, 370], "job": [22, 26, 42, 44, 47, 51, 68, 69, 72, 73, 641, 643], "famili": [22, 87, 89, 596], "particularli": [22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 68, 69, 72, 73, 86, 87, 90, 176, 191, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 418, 421, 615, 626, 643, 644], "pleas": [22, 41, 81, 88, 120, 123, 126, 129, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 239, 266, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384, 420, 593, 594], "processorasyncenvpool": 22, "threadingasyncenvpool": 22, "functool": [22, 32, 34, 35, 36, 38, 52, 120, 150, 158, 303, 320], "lazi": [22, 70, 71, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 250, 275, 325, 327, 328, 330, 331, 346, 347, 377, 379, 381, 382, 385, 427, 428, 429, 622, 623, 628, 630, 636, 641, 644], "s0": [22, 120], "clamp": [22, 120, 345, 348, 361, 416, 637, 639], "env_index": [22, 120], "async_step_send": [22, 120, 154, 159], "s0_result": [22, 120], "async_step_recv": [22, 120, 154, 159], "reveal": 23, "bug": 23, "curv": 23, "exploit": [23, 628], "cv": 23, "flip": [23, 137], "correspondingli": 23, "prescript": 23, "tune": [23, 241, 384, 594, 637, 638, 640], "coeffici": [23, 188, 195, 241, 351, 358, 365, 368, 371, 380, 384, 638], "bonu": [23, 177, 349, 351, 365, 368, 380, 594], "altern": [23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 59, 86, 87, 145, 170, 176, 197, 226, 270, 294, 306, 324, 325, 327, 328, 330, 331, 352, 377, 379, 381, 382, 385, 391, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589, 615, 622, 624, 626, 637, 638], "reduc": [23, 25, 59, 101, 102, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 192, 212, 221, 227, 264, 280, 320, 384, 525, 570, 623, 637], "downstream": [23, 380, 622], "formul": [23, 637, 638], "gradient": [23, 65, 68, 69, 72, 73, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 243, 272, 303, 310, 320, 321, 326, 332, 337, 345, 349, 351, 352, 353, 357, 358, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 416, 420, 421, 475, 592, 608, 622, 624, 637, 638, 639], "norm": [23, 27, 86, 87, 121, 122, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 409, 416, 420, 421, 475, 622, 623, 624, 637, 638, 639], "easier": [23, 622, 643], "optima": 23, "sens": [23, 86, 87, 176, 185, 221, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 630, 639], "product": [23, 28, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 564, 565, 615, 635], "sum": [23, 35, 36, 38, 50, 62, 64, 86, 87, 114, 121, 122, 124, 125, 129, 131, 132, 136, 137, 145, 146, 155, 176, 177, 220, 242, 258, 306, 320, 325, 327, 328, 330, 331, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 377, 379, 380, 381, 382, 384, 385, 409, 594, 608, 622, 623, 624, 626, 629, 632, 637, 638, 639, 644], "stat": [23, 246, 279, 280, 556, 566, 623, 624], "yield": [23, 34, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 324, 326, 332, 337, 366, 376, 378, 380, 383, 384, 622, 625, 629], "insight": [23, 171, 418, 615, 626], "auxiliari": [23, 629], "credit": 23, "past": [23, 221, 341, 623, 641], "difficult": [23, 150, 631], "spars": [23, 594, 625], "instrument": 23, "greatli": 23, "soccer": 23, "kick": 23, "ball": [23, 172], "likelihood": [23, 622], "score": [23, 177, 332, 368, 594], "undesir": [23, 150, 158], "though": [23, 30, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 305, 332, 615, 624, 637, 638], "unintention": 23, "valuabl": 23, "idiosyncrat": 23, "subtask": 23, "hierarch": 23, "fall": [23, 37, 39, 41, 46, 49, 54, 55, 79, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "curios": 23, "magnitudin": 23, "domin": 23, "smaller": [23, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 357, 364, 624, 638], "addition": [23, 295], "timestep": [23, 79, 255, 637, 638], "realli": 23, "huge": [23, 625], "std": [23, 246, 279, 286, 307, 311, 420, 622, 644], "initi": [23, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 59, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 97, 114, 120, 123, 126, 130, 138, 148, 149, 150, 151, 154, 158, 159, 160, 161, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 220, 239, 246, 250, 265, 272, 275, 280, 281, 282, 286, 301, 312, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 339, 341, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 404, 566, 567, 568, 569, 570, 571, 573, 574, 575, 576, 577, 578, 579, 581, 582, 583, 587, 588, 589, 594, 615, 622, 623, 625, 627, 628, 630, 634, 637, 639, 644], "estim": [23, 78, 102, 108, 109, 170, 171, 172, 175, 178, 185, 233, 241, 283, 284, 285, 290, 320, 349, 350, 351, 352, 353, 354, 356, 358, 359, 360, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 376, 378, 380, 384, 386, 387, 388, 389, 390, 603, 608, 623, 624, 628, 629, 637, 638], "encount": [23, 83, 244, 341, 593, 623, 628, 639], "unseen": 23, "extrins": 23, "wrong": [23, 102, 108, 183], "goe": [23, 152, 153, 622, 624, 637, 638, 644], "bonus": 23, "denser": 23, "prior": [23, 315, 316, 317, 361, 638], "freshli": 23, "drop": [23, 107, 109, 212, 280, 324, 351, 368, 380], "meant": [23, 144, 178], "encourag": [23, 150, 183, 368, 421, 622, 623, 641], "measur": [23, 88, 95, 97, 101, 116, 121, 122, 136, 137, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 351, 368, 380, 383, 418, 421, 624, 630], "novelti": 23, "revisit": 23, "diminish": 23, "decreas": [23, 628], "ideal": [23, 170, 226, 246, 380, 635, 639], "distil": 23, "nois": [23, 281, 312, 315, 316, 369, 372, 373, 410, 566, 605, 622, 637], "exploratori": [23, 349, 351, 365, 368, 380], "misalign": 23, "trade": [23, 628], "unavoid": 23, "prioriti": [23, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 95, 96, 97, 98, 101, 102, 110, 112, 116, 352, 353, 354, 356, 357, 358, 359, 364, 369, 371, 372, 373, 622, 623, 641], "schedul": [23, 26, 324, 410, 624, 639], "divers": [23, 150, 158, 332], "bootstrap": [23, 359, 386, 387, 622, 625], "noisi": 23, "unstabl": [23, 101, 102, 303, 320, 321], "inher": [23, 349, 368], "stochast": [23, 241, 299, 308, 316, 350, 352, 355, 357, 358, 363, 364, 367, 369, 371, 421, 601, 602, 624, 628, 638], "enemi": 23, "pomdp": [23, 641], "loos": [23, 345, 587, 623, 624], "nonexist": 23, "architectur": [23, 189, 294, 324, 332, 601, 615, 629, 637, 638, 643], "lstm": [23, 265, 304, 307, 626], "rel": [23, 69, 265, 295, 319, 622, 623, 637, 638, 641], "tend": 23, "stabl": [23, 28, 29, 101, 102, 147], "compens": 23, "descent": 23, "minimum": [23, 75, 120, 150, 158, 256, 299, 307, 319, 320, 321, 326, 332, 337, 348, 350, 352, 358, 366, 367, 371, 376, 378, 380, 384, 406, 622, 624, 632, 637, 638], "manual": [23, 30, 42, 47, 50, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 95, 130, 131, 180, 191, 420, 622, 625, 641], "deviat": [23, 246, 279, 280, 286, 299, 311, 368, 372, 373, 384, 409, 622, 628, 638], "radic": 23, "stabil": [23, 101, 102, 237, 324, 333, 334, 349, 351, 365, 368, 370, 380], "stage": [23, 622, 639], "never": [23, 32, 35, 36, 38, 52, 58, 75, 101, 102, 208, 267, 630, 643], "solv": [23, 26, 28, 29, 65, 66, 68, 69, 183, 593, 622, 623, 624, 630, 632, 637, 638, 639, 641], "submit": [23, 129, 218, 593, 643], "adequ": [23, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 624, 637, 638], "infeas": 23, "allevi": 23, "prune": [23, 138, 179], "fire": [23, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "certain": [23, 42, 44, 47, 50, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 226, 227, 237, 263, 272, 301, 326, 332, 333, 334, 337, 365, 376, 378, 380, 383, 384, 622, 623, 624, 626, 632, 637, 638, 644], "illeg": 23, "move": [23, 74, 85, 88, 96, 98, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 225, 230, 250, 265, 271, 272, 275, 277, 279, 280, 305, 326, 332, 337, 344, 376, 378, 380, 383, 384, 413, 622, 623, 625, 627, 644], "chess": [23, 123, 148, 149], "grasp": 23, "wherein": 23, "cumul": [23, 258, 264, 624], "q": [23, 28, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 285, 290, 291, 292, 293, 296, 298, 300, 313, 314, 317, 350, 352, 353, 354, 356, 357, 358, 359, 364, 369, 371, 372, 373, 601, 622, 629, 634], "flow": [23, 208, 386, 569, 570, 577, 622, 624, 637, 638, 639, 641], "reparameter": [23, 295, 310], "soft": [23, 371, 421, 637], "clip": [23, 183, 224, 256, 349, 351, 365, 368, 370, 372, 373, 376, 378, 380, 416, 420, 421, 474, 475, 624, 638, 639], "oppos": 23, "incorrect": [23, 108, 183, 368], "thought": [23, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 594], "region": [23, 102, 380], "squash": [23, 338, 625, 643], "tanh": [23, 288, 303, 305, 319, 320, 321, 348, 624, 626, 628, 637, 638, 639, 640], "correct": [23, 86, 87, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 182, 183, 188, 221, 241, 325, 327, 328, 330, 331, 377, 379, 380, 381, 382, 385, 555, 615, 624, 625, 634], "prob": [23, 188, 189, 195, 196, 306, 310, 324, 326, 329, 332, 337, 624, 635, 638], "rememb": [23, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 637], "remap": 23, "origin": [23, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 90, 134, 170, 176, 230, 231, 241, 250, 272, 277, 325, 326, 327, 328, 330, 331, 332, 337, 342, 344, 345, 350, 352, 364, 366, 368, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 594, 622, 626, 634, 636, 639, 644], "real": [24, 35, 36, 38, 83, 326, 332, 337, 345, 575, 625, 626, 639, 640], "histor": 24, "ceas": 24, "fork": [24, 78, 79, 80, 81, 82, 83, 84, 85, 622, 623, 624, 625, 637, 638, 640, 643], "farama": [24, 81, 139, 140, 152, 153, 624, 639], "bc": [24, 372], "break": [24, 32, 34, 35, 36, 38, 50, 52, 54, 66, 68, 73, 78, 80, 81, 83, 84, 85, 88, 102, 108, 109, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 255, 279, 280, 302, 303, 304, 320, 326, 332, 337, 376, 378, 380, 383, 384, 393, 623, 626, 630, 632, 641, 643], "13": [24, 108, 109, 155, 226, 278, 280, 282, 622, 623, 624, 635, 637, 641], "gymwrapp": [24, 120, 123, 126, 130, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 234, 259, 263, 278, 624, 643], "feel": [24, 593, 632, 643], "free": [24, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 176, 212, 229, 232, 325, 327, 328, 330, 331, 349, 361, 368, 377, 379, 381, 382, 385, 615, 624, 632, 638, 643], "gladli": 24, "conda": [25, 26, 593], "cmake": 25, "14": [25, 78, 79, 80, 81, 82, 83, 84, 85, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 226, 246, 282, 368, 622, 623, 637, 641], "sim": 25, "bullet": 25, "headless": [25, 26, 135, 184, 634], "cluster": [25, 26, 27, 42, 50, 80, 402, 403, 404, 593], "withbullet": 25, "forg": [25, 26], "aihabitat": [25, 132], "y": [25, 26, 68, 86, 87, 147, 176, 300, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 384, 385, 466, 467, 470, 472, 622, 638, 641], "facebookresearch": [25, 80, 132], "subdirectori": 25, "verbos": [25, 52, 53, 88, 177, 324, 333, 383, 632, 634], "magnum_log": 25, "quiet": 25, "habitat_sim_log": 25, "remov": [25, 34, 35, 36, 38, 41, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 252, 261, 272, 325, 326, 327, 328, 330, 331, 332, 337, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 403, 594, 637, 638, 643, 644], "readm": [25, 26, 163, 643], "md": [25, 26], "habitatenv": [25, 449], "_has_habitat": 25, "available_env": [25, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 139, 142, 143, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 175, 178, 179, 180, 644], "startswith": [25, 287, 608, 622, 629], "oserror": 25, "libllvmlit": 25, "ionstal": 25, "pointer": [25, 127, 366, 622], "llvmlite": 25, "var": [25, 26, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 280, 326, 332, 337, 352, 366, 371, 376, 378, 380, 383, 384, 623, 626, 640, 641], "ld_preload": [25, 26], "bind": 25, "deactiv": [25, 26, 121, 122, 297, 350, 352, 358, 364, 366, 369, 371, 372, 373, 387, 388, 389], "importerror": [25, 26, 29, 404, 635], "usr": [25, 26, 29], "x86_64": [25, 26], "linux": [25, 26], "gnu": [25, 26], "libopengl": [25, 26], "undefin": [25, 26, 29, 59, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 352, 366, 371, 376, 378, 380, 383, 384, 626, 641], "symbol": [25, 26, 29], "_glapi_tls_curr": [25, 26], "link": [25, 26, 126, 623, 632], "mujoco_env": [25, 26], "libglvnd": [25, 26], "glx": [25, 26], "cos7": [25, 26], "reinstal": [25, 26], "xvfbwrapper": [25, 26], "sysroot": [25, 26], "lib64": [25, 26], "libgldispatch": [25, 26], "offici": [26, 79, 190, 626], "stand": [26, 124, 125, 150, 158, 636, 639, 644], "joint": [26, 623], "contact": [26, 637], "biomechan": 26, "graphic": 26, "anim": [26, 638], "area": 26, "demand": [26, 570, 631, 644], "fast": [26, 28, 96, 121, 122, 212, 253, 369, 615, 622, 623, 624, 643], "accur": [26, 79, 85, 594, 623, 639, 641], "articul": 26, "acquir": [26, 624], "deepmind": [26, 27, 28, 83, 120, 123, 124, 125, 126, 130, 138, 142, 143, 148, 149, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 233, 624, 627], "whomev": 26, "licenc": 26, "were": [26, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 67, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 150, 158, 239, 339, 351, 368, 570, 585, 594, 596, 624, 637, 641], "incorpor": [26, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 301, 312, 372, 421, 625, 628, 639], "relianc": 26, "obsolet": 26, "pro": [26, 593], "tip": [26, 593], "glfw": [26, 622], "osmesa": 26, "egl": 26, "advic": [26, 83, 644], "sudo": [26, 593], "apt": [26, 638], "libglfw3": 26, "libglew2": 26, "libgl1": 26, "mesa": 26, "libosmesa6": 26, "workflow": [26, 283, 284, 285, 286, 324, 594, 635], "glew": 26, "mesalib": 26, "anaconda": 26, "libgl": 26, "cos6": 26, "menpo": 26, "glfw3": 26, "mujoco_gl": 26, "pyopengl_platform": 26, "mkdir": 26, "earlier": [26, 622, 624, 625, 637, 638, 641], "roboti": 26, "download": [26, 29, 78, 79, 80, 81, 83, 84, 85, 134, 250, 277, 393, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "html": [26, 35, 38, 145, 147, 148, 149, 634], "wget": 26, "mujoco210": 26, "tar": [26, 80], "gz": 26, "xf": 26, "charg": [26, 32, 35, 36, 38, 150, 158], "mjkei": 26, "txt": [26, 384], "mjlib_path": 26, "home": 26, "bin": [26, 190, 298], "libmujoco210": 26, "ld_library_path": 26, "mujoco_py_mujoco_path": 26, "too": [26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 245, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 303, 320, 321, 326, 332, 337, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 623, 628, 631, 639, 641, 644], "mujoco_py_mjkey_path": 26, "reload": 26, "later": [26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 101, 102, 293, 339, 342, 345, 403, 569, 622, 624, 626, 641], "nvidia": [26, 134, 626], "hack": [26, 622], "adatp": 26, "unnot": [26, 251], "mujoco_pi": 26, "cymj": 26, "linuxgpuextensionbuild": 26, "filenam": [26, 86, 87, 93, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 623, 641], "troubleshoot": [26, 351, 365, 368], "gl": 26, "h": [26, 69, 221, 223, 228, 254, 268, 302, 304, 393, 515, 623, 625, 641], "eglshim": 26, "fatal": 26, "No": [26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 54, 57, 59, 62, 64, 177, 402, 567, 569, 571, 572, 577], "directori": [26, 78, 79, 80, 81, 83, 84, 85, 86, 87, 91, 95, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 398, 401, 583, 584, 585, 586, 622, 628, 631, 637, 640], "devel": 26, "ubuntu": [26, 134], "libglew": 26, "dev": 26, "cento": 26, "yum": 26, "glu": 26, "38": [26, 623], "disappear": [26, 623, 625, 636], "libstdc": 26, "6": [26, 32, 34, 35, 36, 38, 52, 53, 56, 60, 68, 71, 78, 84, 85, 101, 102, 109, 124, 125, 130, 150, 156, 157, 172, 180, 214, 217, 226, 227, 246, 248, 264, 270, 280, 287, 288, 290, 291, 292, 295, 300, 305, 308, 319, 322, 341, 342, 622, 623, 626, 630, 637, 639, 641, 643, 644], "glibcxx_3": 26, "29": [26, 108, 109, 623, 638, 639], "compil": [26, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 68, 72, 73, 86, 87, 88, 90, 94, 95, 96, 97, 98, 102, 104, 108, 109, 110, 115, 116, 118, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 282, 303, 317, 320, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 427, 428, 429, 430, 434, 436, 437, 441], "libosmesa": 26, "libgcc": 26, "Then": [26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 175, 183, 278, 587, 588, 624, 636], "filenotfounderror": [26, 81], "errno": 26, "patchelf": 26, "fatalerror": 26, "gladloadgl": 26, "mj_env": 26, "912": 26, "glfwerror": 26, "65537": 26, "myscript": 26, "runtimeerror": [26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 59, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 245, 270, 272, 326, 332, 333, 337, 352, 371, 376, 378, 380, 383, 384, 575, 644], "slurm": 26, "mjrendercontext": 26, "pyx": 26, "46": [26, 108, 121, 122, 623], "114": [26, 626], "_setup_opengl_context": 26, "opengl_context": 26, "130": [26, 621, 642], "offscreenopenglcontext": 26, "fail": [26, 32, 34, 35, 36, 38, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 195, 215, 326, 332, 337], "opengl": [26, 637, 638], "global": [26, 68, 69, 72, 73, 88, 89, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 270, 326, 332, 335, 336, 337, 342, 345, 376, 378, 380, 383, 384, 402, 403, 622, 637, 638], "cuda_visible_devic": [26, 589], "slurm_step_gpu": 26, "black": [26, 123, 637], "onscreen": 26, "101": 26, "lgl": 26, "libegl": 26, "x11": [26, 638], "xlib": 26, "libx11": 26, "xorg": 26, "attributeerror": [26, 32, 35, 36, 38, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "nonetyp": 26, "glgeterror": 26, "this_dir": 26, "pwd": 26, "ln": 26, "libglut": 26, "12": [26, 29, 35, 36, 38, 84, 86, 87, 95, 97, 109, 116, 136, 137, 150, 156, 157, 158, 172, 176, 190, 226, 272, 280, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 393, 621, 622, 623, 626, 637, 638, 639, 641, 642], "sketch": 27, "_": [27, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 96, 123, 127, 134, 163, 164, 176, 185, 222, 229, 231, 232, 241, 246, 253, 268, 279, 322, 325, 327, 328, 330, 331, 340, 344, 345, 349, 350, 352, 353, 357, 358, 364, 368, 369, 371, 372, 373, 377, 379, 381, 382, 385, 386, 387, 388, 389, 395, 622, 623, 624, 625, 626, 632, 637, 638, 639, 641, 643], "n_training_step": 27, "datapoint": [27, 641], "onlin": [27, 32, 38, 221, 294, 311, 349, 355, 367, 368, 406, 566, 624, 625, 638, 641], "n_data_per_train": 27, "no_grad": [27, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 243, 326, 332, 337, 376, 378, 380, 383, 384, 386, 387, 388, 389, 624, 625, 626, 638], "loss_fn": [27, 625, 629, 630, 643], "zero_grad": [27, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 622, 624, 625, 626, 629, 632, 637, 638, 639], "backpropag": [27, 121, 122, 136, 137, 150, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 629, 638, 639], "differenti": [27, 121, 122, 241, 352, 372, 386, 387, 388, 389, 541, 542, 543, 545, 551, 552, 553, 625, 628, 629, 637, 638, 639], "pai": [27, 221, 622, 625], "denomin": 27, "artifact": 27, "numer": [27, 68, 101, 102, 130, 180, 279, 297, 298, 303, 313, 314, 320, 321, 324, 333, 334, 340, 342, 344, 345, 413, 624, 641, 644], "misconcept": 27, "freed": 27, "appear": [27, 30, 58, 64, 75, 78, 83, 102, 108, 109, 126, 178, 185, 186, 639, 641], "compuat": 27, "twice": [27, 109], "retain_graph": [27, 121, 122], "discuss": [27, 28, 630, 637, 638], "inplac": [27, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 329, 330, 331, 332, 337, 344, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 568, 570, 571, 573, 574, 576, 578, 580, 581, 583, 585, 587, 589, 622, 626], "accumul": [27, 317], "onto": [27, 64, 86, 87, 176, 189, 195, 206, 230, 286, 297, 298, 307, 312, 313, 314, 325, 327, 328, 330, 331, 340, 342, 344, 345, 377, 379, 381, 382, 385, 386, 625, 639], "submodul": [27, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 265, 302, 304, 326, 332, 337, 366, 376, 378, 380, 383, 384], "grad": [27, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 330, 331, 332, 337, 345, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 622, 624], "whose": [27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "neg": [27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 72, 74, 101, 102, 182, 221, 236, 251, 262, 274, 326, 351, 360, 365, 368, 386, 388, 389, 624, 637, 638, 639], "fit": [27, 246, 265, 282, 324, 622], "jax": [27, 121, 122, 136, 137, 282], "improperli": 27, "underli": [27, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 326, 332, 366, 615, 625, 627, 629, 631, 639], "tedeiou": 27, "amount": [27, 150, 312, 386, 623, 641], "costli": [27, 639], "concaten": [27, 35, 36, 38, 50, 61, 62, 83, 86, 87, 176, 178, 221, 222, 246, 262, 305, 325, 327, 328, 330, 331, 347, 377, 379, 381, 382, 385, 622, 623, 628, 637, 638, 639, 641, 644], "constitut": [27, 623, 638, 639], "profil": [27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "frequent": [27, 615, 641], "techniqu": [27, 150, 158, 623, 626, 630, 641], "program": [27, 357, 364, 644], "functorch": [27, 29], "incl": 27, "suit": [27, 125, 615, 624, 627, 643, 644], "mujoco_instal": 27, "valueerror": [27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 330, 331, 332, 333, 337, 376, 378, 380, 383, 384, 402, 403, 404, 568, 570, 573, 574, 576, 577, 578, 579, 581, 583, 589, 635], "bad": 27, "fds_to_keep": 27, "new_shap": 27, "permut": [27, 107, 248, 268, 626, 643, 644], "idea": [28, 101, 102, 369, 616, 625, 628, 637, 638], "introductori": 28, "intro": [28, 624, 625], "dai": [28, 643], "2022": [28, 29, 643], "spin": [28, 124, 125, 644], "hug": [28, 329, 332, 635], "syllabu": 28, "lectur": 28, "awesom": 28, "curat": 28, "succinct": [28, 628], "summari": [28, 246, 279, 280, 622, 623, 624, 625], "reddit": 28, "reagent": 28, "orient": [28, 85, 644], "baselines3": 28, "tf": 28, "bandit": [28, 147], "tensorflow": [28, 306], "kera": 28, "acm": 28, "dopamin": 28, "prototyp": [28, 420, 421, 626, 632], "salina": 28, "sequenti": [28, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 220, 241, 283, 284, 285, 326, 332, 337, 342, 346, 347, 349, 350, 352, 358, 364, 368, 369, 370, 371, 372, 376, 378, 380, 383, 384, 570, 601, 624, 625, 628, 638, 639, 640, 643, 644], "tianshou": 28, "eleg": 28, "rlpyt": 28, "rllib": 28, "industri": [28, 643], "grade": 28, "cherri": 28, "jaxrl": 28, "space": [28, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 87, 92, 93, 100, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 209, 214, 224, 231, 239, 242, 265, 273, 286, 288, 294, 297, 298, 309, 312, 313, 314, 317, 322, 337, 340, 342, 344, 345, 347, 348, 349, 354, 356, 357, 358, 368, 372, 373, 623, 624, 625, 626, 627, 628, 629, 637, 638, 639, 644], "mbrl": [28, 144], "rlmeta": 28, "light": 28, "elegantrl": 28, "cloud": 28, "mtrl": 28, "baselin": 28, "689": 29, "_torchrl": 29, "_zn8pybind116detail11type_casterin2at6tensoreve4loadens_6handleeb": 29, "colab": [29, 624, 625, 637, 638], "notebook": [29, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "24": [29, 84, 109, 129, 145, 146, 172, 183, 338, 341, 393, 621, 622, 623, 637, 639, 642], "pip3": [29, 622, 624, 625, 637, 638], "extra": [29, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 221, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 400, 401, 624, 625, 641], "url": [29, 86, 132, 186, 634], "org": [29, 35, 38, 65, 80, 81, 83, 85, 101, 102, 121, 122, 124, 125, 132, 136, 137, 142, 143, 145, 146, 147, 155, 163, 164, 221, 250, 275, 289, 290, 291, 292, 293, 294, 298, 299, 300, 306, 308, 309, 312, 315, 316, 317, 349, 350, 354, 355, 356, 357, 359, 360, 361, 362, 363, 364, 367, 368, 370, 371, 372, 386, 591, 633, 640], "whl": 29, "u": [29, 82, 639], "upgrad": 29, "lib_version_her": 29, "heavili": 30, "pyav": 30, "conveni": [30, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 221, 324, 402, 624, 637, 638, 639, 641], "knob": 30, "dispos": 30, "guid": [30, 152, 153, 156, 157, 264, 324, 593, 622, 638, 643], "clarifi": 30, "behind": [30, 259], "adjust": [30, 265, 622, 637, 638, 639], "ultim": [30, 303, 320, 321], "ffmpeg": 30, "whatev": [30, 326, 332, 337, 622], "fed": [30, 638, 641], "feed": [30, 250, 277, 366, 376, 378, 380, 384, 622, 637, 638, 641], "suppos": [30, 150, 410, 644], "snippet": [30, 250, 275, 622], "gave": 30, "extrem": [30, 150, 158, 349, 351, 365, 368, 370, 380], "blurri": [30, 626], "stitch": 30, "my_exp": [30, 631], "pixels_onli": [30, 124, 125, 129, 131, 132, 155, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 622, 623, 631, 632, 643, 644], "my_video": [30, 631], "record_env": [30, 631, 632], "codec": 30, "h264": 30, "constant": [30, 101, 102, 221, 246, 264, 622, 624, 625, 644], "crf": 30, "17": [30, 84, 108, 109, 130, 150, 180, 214, 226, 622, 623], "preset": 30, "allow_non": 31, "unwrap": [31, 233, 272, 405, 495], "seealso": 31, "randompolici": [32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 221, 255, 630, 641], "tensordictmodulebas": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 220, 243, 297, 313, 326, 332, 337, 341, 376, 378, 380, 384, 468, 625], "signatur": [32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 66, 68, 69, 88, 89, 112, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 218, 225, 239, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384, 622, 626, 627, 639], "undergon": [32, 34, 35, 36, 38, 42, 44, 47, 50], "env_obs_kei": [32, 34, 35, 36, 38, 42, 44, 47, 50], "mustn": [32, 34, 35, 36, 38, 42, 44, 47, 50], "policy_factori": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 422, 423, 424, 425], "exclus": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 63, 68, 72, 73, 78, 83, 86, 87, 102, 108, 109, 176, 182, 218, 234, 236, 243, 297, 298, 302, 304, 306, 313, 314, 325, 327, 328, 330, 331, 334, 372, 373, 377, 379, 381, 382, 385, 386, 387, 388, 389, 390, 401, 566], "lifespan": [32, 34, 35, 36, 38, 42, 44, 47, 52, 53, 623], "divis": [32, 34, 35, 36, 38, 42, 44, 47, 78, 83, 102, 108, 109, 280, 638], "endless": [32, 34, 35, 36, 38, 42, 44, 47, 185, 594], "env_devic": [32, 34, 35, 36, 38, 42, 44, 47, 50, 422, 423, 424, 425, 623], "sit": [32, 34, 35, 36, 38, 42, 44, 47, 50, 419, 623], "cast": [32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 277, 278, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 344, 351, 365, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 637, 644], "create_env_kwarg": [32, 34, 35, 36, 38, 50, 120, 127, 145, 150, 158, 270, 422, 423, 424, 425, 442, 622, 644], "span": [32, 34, 35, 36, 38, 42, 44, 47, 50, 83, 102, 108, 109, 436, 437], "n_step": [32, 34, 35, 36, 38, 42, 44, 47, 50, 341, 506, 623, 624, 637, 638], "independ": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 80, 150, 158, 186, 236, 244, 265, 274, 324, 349, 368, 402, 587, 615, 622, 623, 625, 638, 641, 643], "ignor": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 93, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 231, 234, 259, 268, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 306, 307, 308, 309, 311, 312, 314, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 348, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 569, 577, 582, 584, 634, 635, 641], "mainli": [32, 34, 35, 36, 38, 42, 44, 47, 50, 170, 171, 172, 175, 401, 637, 638, 639], "round": [32, 34, 35, 36, 38, 42, 44, 47, 50, 78, 123, 192, 324, 434, 615], "closest": [32, 34, 35, 36, 38, 42, 44, 47, 50], "postproc": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 255, 422, 423, 424, 425, 623, 641], "post": [32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 81, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 594], "multistep": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 623], "explorationtyp": [32, 34, 35, 36, 38, 42, 44, 47, 50, 342, 366, 410, 622, 623, 624, 625, 628, 637, 643], "boolm": [32, 35, 36, 38], "preemptive_threshold": [32, 35, 36, 38], "ratio": [32, 35, 36, 38, 351, 368, 416, 418, 622, 624], "finish": [32, 34, 35, 36, 38, 50, 52, 130, 180, 255, 326, 332, 337, 575, 644], "earli": [32, 35, 36, 38, 101, 102, 130, 180, 263, 326, 332, 337, 643], "num_thread": [32, 35, 36, 38, 86, 87, 130, 150, 158, 176, 180, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 583, 584], "num_sub_thread": [32, 35, 36, 38, 150, 158], "plu": [32, 35, 36, 38, 150, 158, 326, 332, 337, 594, 639], "harm": [32, 35, 36, 38, 150, 158], "set_trunc": [32, 34, 35, 36, 38, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 422, 423, 424, 425], "add_truncated_kei": [32, 34, 35, 36, 38, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272], "track_policy_vers": [32, 34, 35, 36, 38, 52, 53, 191, 422, 423, 424, 425, 594], "policyvers": [32, 34, 35, 36, 38, 52, 53, 594], "mediat": [32, 34, 35, 36, 38, 52], "timeout": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 150, 184, 190, 192, 193, 197, 324, 326, 332, 337, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 581, 582, 583, 584, 585, 587, 589, 615], "close_env": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 52], "cascade_execut": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "attr_path": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "caller": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 324, 326, 332, 337, 376, 378, 380, 383, 384, 582], "_receiver_schem": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "_set_dist_connection_info": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "connection_info_ref": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "enable_profil": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "get_cached_weight": [32, 35, 36, 38], "get_model": [32, 34, 35, 36, 38, 52, 53, 568, 570, 573, 574, 576, 581, 583, 589], "value_net": [32, 34, 35, 36, 38, 52, 53, 354, 356, 370, 386, 387, 388, 389, 624, 626, 628, 629, 632], "recogn": [32, 34, 35, 36, 38, 52, 53, 402], "get_policy_vers": [32, 34, 35, 36, 38, 52, 53], "uuid": [32, 34, 35, 36, 38, 52, 53, 191, 396, 623, 644], "disabl": [32, 34, 35, 36, 38, 52, 53, 57, 59, 61, 62, 64, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 303, 321, 326, 332, 337, 376, 378, 380, 383, 384, 391, 420, 571, 622, 637, 638], "getattr_env": [32, 34, 35, 36, 38, 52, 53], "attr": [32, 34, 35, 36, 38, 52, 53], "getattr_polici": [32, 34, 35, 36, 38, 52, 53], "getattr_rb": [32, 34, 35, 36, 38, 52, 53], "increment_vers": [32, 34, 35, 36, 37, 38, 39, 40, 41, 46, 49, 52, 53, 54, 55, 191], "increment": [32, 34, 35, 36, 37, 38, 39, 40, 41, 46, 49, 52, 53, 54, 55, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180, 191, 246, 365, 594], "init_updat": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "load_state_dict": [32, 34, 35, 36, 38, 50, 52, 53, 86, 87, 88, 90, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 418, 622], "ordereddict": [32, 34, 35, 36, 38, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 279, 280, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384, 623], "form": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 302, 304, 317, 326, 332, 337, 345, 349, 351, 365, 368, 376, 378, 380, 383, 384, 416, 421, 628], "worker0": [32, 35, 36, 38], "state_dict0": [32, 35, 36, 38], "worker1": [32, 35, 36, 38, 615], "state_dict1": [32, 35, 36, 38], "policy_vers": [32, 34, 35, 36, 38, 52, 53, 191, 594], "profile_config": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "_base": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "profileconfig": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "policy_or_weight": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54], "deleg": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 176, 194, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 639], "trained_polici": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "mirror": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "conflict": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 171, 326, 332, 337], "register_scheme_receiv": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "weight_recv_schem": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "weightsyncschem": [32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53], "synchronize_weight": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 569, 570, 576], "hierarchi": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 324], "immedi": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 402, 403, 404, 568, 570, 573, 574, 576, 578, 581, 583, 589, 615, 637, 638], "reset_idx": [32, 35, 36, 38], "abc": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 60, 61, 65, 67, 68, 69, 71, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 219, 220, 221, 222, 223, 225, 228, 229, 232, 236, 238, 242, 246, 247, 252, 254, 255, 256, 257, 258, 262, 264, 265, 266, 268, 271, 272, 273, 279, 280, 282, 288, 295, 303, 305, 306, 310, 320, 326, 332, 337, 376, 378, 380, 383, 384, 411, 412, 419, 564, 565], "static_se": [32, 34, 35, 36, 38, 50, 52, 53, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272], "integ": [32, 34, 35, 36, 38, 52, 53, 56, 61, 62, 64, 102, 108, 109, 110, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180, 191, 214, 217, 233, 237, 246, 263, 280, 288, 305, 352, 357, 364, 371, 626, 641], "env_fn": [32, 34, 35, 36, 38, 52, 53, 127, 564, 565], "env_fn_parallel": [32, 34, 35, 36, 38, 52, 53], "300": [32, 34, 35, 36, 38, 52, 53, 108, 109, 292, 293], "out_se": [32, 34, 35, 36, 38, 52, 53, 644], "raise_on_error": [32, 34, 35, 36, 38, 52, 402], "irrevers": [32, 35, 36, 38], "pipe": [32, 34, 35, 36, 38, 52, 150], "tqdm": [32, 34, 35, 36, 38, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 416, 622, 624, 625, 637, 638, 639], "ale_pi": [32, 34, 35, 36, 38, 52, 626, 644], "progress": [32, 34, 35, 36, 38, 52, 53, 324, 408, 409, 410, 416, 418, 420, 421, 475, 623, 625, 644], "bar": [32, 34, 35, 36, 38, 52, 95, 97, 116, 324, 408, 409, 410, 416, 420, 421, 475, 623], "pbar": [32, 34, 35, 36, 38, 52, 78, 79, 80, 81, 82, 83, 84, 85, 622, 624, 625, 637, 638, 639], "100_000": [32, 34, 35, 36, 38, 52, 626, 632], "prec_wc": [32, 34, 35, 36, 38, 52], "wc": [32, 34, 35, 36, 38, 52], "write_count": [32, 34, 35, 36, 38, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 418], "set_descript": [32, 34, 35, 36, 38, 52, 622, 624, 625, 637, 638, 639], "f": [32, 34, 35, 36, 38, 52, 84, 88, 121, 122, 130, 136, 137, 180, 188, 190, 193, 195, 196, 267, 282, 384, 386, 387, 388, 389, 390, 615, 622, 623, 624, 625, 626, 632, 635, 637, 638, 639, 641, 644], "worker_id": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589], "actor_weight": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "critic_weight": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "Will": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 86, 87, 102, 108, 145, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 393, 615], "_get_server_weight": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54], "typeerror": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "weight_updat": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 422, 423, 424, 425, 623], "weightupdaterbas": [32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55], "localweightsupdaterbas": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "remoteweightsupdaterbas": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "num_rollout": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "warmup_rollout": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "save_path": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "pathlib": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 95, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 416, 420, 421, 626], "record_shap": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "profile_memori": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "with_stack": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "with_flop": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "on_trace_readi": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "warmup": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "jit": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 137], "trace": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 626], "collector_profile_": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "json": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 187, 190, 634], "flop": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "chrome": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "worker_": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "overhead": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 208, 212, 325, 327, 328, 330, 331, 345, 377, 379, 381, 382, 385], "viewer": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "tensorboard": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 393, 397, 399, 416, 420, 464, 475, 631, 643], "plugin": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "implic": [33, 42, 43, 44, 45, 47, 48], "notimplementederror": [33, 42, 43, 44, 45, 47, 48, 622], "env_creat": [34, 127, 622], "interactiontyp": [34, 42, 44, 47, 50, 167, 210, 342, 345, 410], "return_same_td": [34, 423], "interruptor": [34, 423], "use_buff": [34, 35, 36, 38, 150, 158, 422, 423, 424, 425], "extend_buff": [34, 35, 36, 38, 422, 423, 424, 425], "local_init_rb": [34, 35, 36, 38, 422, 423, 424, 425], "trust_polici": [34, 35, 36, 38, 50, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 422, 423, 424, 425], "compile_polici": [34, 35, 36, 38, 422, 423, 424, 425], "cudagraph_polici": [34, 35, 36, 38, 422, 423, 424, 425], "no_cuda_sync": [34, 35, 36, 38, 50, 422, 423, 424, 425], "cautious": [34, 368], "whole": [34, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 342, 352, 371, 376, 378, 380, 383, 384, 406, 622, 624], "_interruptor": 34, "start_collect": 34, "stop_collect": 34, "preeptiv": 34, "trust": [34, 35, 36, 38, 50, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 227, 304, 380], "cudagraphmodul": [34, 35, 36, 38, 50, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "behaviour": [34, 35, 36, 38, 326, 332, 337, 376, 378, 380, 384, 625, 626, 643], "bypass": [34, 35, 36, 38, 81, 628], "isaaclab": [34, 35, 36, 38, 131, 135], "maniskil": [34, 35, 36, 38], "crash": [34, 35, 36, 38, 255], "Not": [34, 54, 61, 68, 121, 122, 136, 270, 302, 304, 332, 583, 585, 589], "env_mak": [34, 35, 38, 50, 66, 120, 562, 644], "2000": [34, 35, 38, 133, 393, 624, 641], "int64": [34, 35, 38, 52, 56, 57, 59, 61, 62, 64, 72, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 101, 108, 120, 123, 126, 130, 138, 141, 142, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 214, 218, 226, 233, 248, 255, 263, 297, 298, 312, 313, 314, 325, 327, 328, 330, 331, 342, 377, 379, 381, 382, 385, 624, 625, 626, 627, 628, 630, 631, 639, 641, 644], "del": [34, 35, 38, 52, 622, 623, 624, 636, 637, 641, 643, 644], "chunk": [34, 52, 53, 88, 626, 628], "policy_state_dict": [34, 52, 53], "env_state_dict": [34, 52, 53], "safe": [35, 38, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 102, 108, 176, 286, 297, 298, 312, 313, 314, 319, 320, 325, 327, 328, 330, 331, 340, 342, 344, 345, 347, 377, 379, 381, 382, 385, 571, 573, 574, 576, 581, 583, 589, 601, 643], "guard": [35, 38], "doc": [35, 38, 132, 135, 136, 137, 147, 155, 186, 401, 623, 626, 637, 638, 641], "depopul": [35, 36, 38], "mutual": [35, 36, 38], "collector_class": [35, 36, 38, 42, 44, 47, 49, 50, 572, 573], "deriv": [35, 36, 38, 42, 44, 47, 50, 86, 87, 176, 295, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 416], "fake": [35, 36, 38, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 622, 623, 626], "multiprocessedweightupdat": [35, 36, 38], "multiprocessweightsyncschem": [35, 36, 38, 569], "get_server_weight": 37, "policy_weight": [37, 39, 40, 46, 49], "all_worker_id": [37, 39, 40, 41, 46, 49, 54, 55], "scope": [37, 39, 40, 41, 46, 49, 54, 55, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 626, 644], "classmethod": [37, 39, 40, 41, 46, 49, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 239, 275, 282, 288, 289, 311, 324, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_polici": [37, 39, 40, 41, 46, 49, 54, 55], "back": [37, 39, 41, 46, 49, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 74, 75, 76, 77, 79, 86, 87, 89, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 199, 269, 278, 297, 298, 313, 314, 325, 327, 328, 330, 331, 340, 342, 344, 345, 377, 379, 381, 382, 385, 584, 624, 626, 637, 638, 639, 641], "post_hook": [37, 39, 40, 41, 46, 49, 54, 55], "push_weight": [37, 39, 40, 41, 46, 49, 54, 55], "noth": [37, 39, 40, 41, 46, 49, 54, 138, 179, 571, 622, 624], "register_collector": [37, 39, 40, 41, 46, 49, 54, 55, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 326, 332, 337], "register_post_hook": [37, 39, 40, 41, 46, 49, 54, 55], "remote_collector": [39, 50, 574, 576], "max_interv": 39, "_maybe_map_weight": [39, 41, 46, 49, 54], "_sync_weights_with_work": [39, 41, 46, 49, 54], "_skip_upd": 39, "interv": [39, 214, 267, 392, 393, 407, 419, 420, 421, 475, 623, 639], "weight_gett": 40, "vanillaweightsend": 40, "update_weight": [40, 46, 49, 324, 419, 567, 586, 588, 589, 594], "piec": [41, 94, 104, 115, 118, 119, 622, 623, 624, 631, 637, 638, 639, 641], "_push_weight": 41, "unchang": [41, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 231, 243, 250, 265, 271, 272, 275, 277, 301, 326, 332, 337, 344, 376, 378, 380, 383, 384, 393, 412, 587, 588, 622, 641], "__call__": [41, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 326, 332, 337, 345, 376, 378, 380, 383, 384], "proxi": [41, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 176, 310, 325, 327, 328, 330, 331, 342, 377, 379, 381, 382, 385], "weakref": 41, "exporationtyp": [42, 44, 47], "_singl": [42, 44, 47, 50, 565], "collector_kwarg": [42, 44, 47, 50], "num_workers_per_collector": [42, 44, 47, 50], "slurm_kwarg": [42, 44, 47], "update_after_each_batch": [42, 44, 47, 50], "max_weight_update_interv": [42, 44, 47, 50], "update_interv": [42, 44], "tcp_port": [42, 44, 47, 51], "string": [42, 44, 47, 63, 88, 89, 96, 120, 123, 126, 130, 138, 142, 148, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 239, 250, 263, 269, 277, 297, 302, 304, 313, 324, 325, 326, 329, 332, 337, 341, 342, 376, 378, 380, 383, 384, 392, 409, 414, 594, 622, 624, 625, 634, 641], "respect": [42, 44, 47, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 219, 225, 229, 232, 244, 250, 251, 260, 265, 271, 272, 275, 277, 316, 322, 326, 332, 337, 344, 349, 351, 365, 368, 370, 376, 378, 380, 383, 384, 386, 388, 389, 411, 624, 625, 637, 638], "subnod": [42, 44, 47, 50], "fashion": [42, 47, 50, 86, 87, 109, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "distributed_back": [42, 44], "ucc": [42, 44, 47], "turn": [42, 44, 47, 50, 53, 60, 71, 86, 87, 88, 123, 137, 150, 160, 170, 176, 226, 238, 271, 274, 278, 297, 325, 327, 328, 330, 331, 377, 379, 380, 381, 382, 385, 386, 391, 410, 594, 622, 623, 625, 628, 639, 640], "submitit_delai": [42, 51], "former": [42, 44, 47, 56, 65, 68, 72, 73, 79, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 338, 341, 348, 622], "whilst": [42, 44, 47, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "latter": [42, 44, 47, 79, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 326, 332, 337, 338, 341, 348, 368, 376, 378, 380, 383, 384, 564, 565], "homonym": [42, 44, 47, 639], "visit": [42, 44, 47, 175], "facebookincub": [42, 44, 47], "tcp": [42, 44, 47, 51], "port": [42, 44, 47, 51, 54, 161, 324, 335, 336, 582, 589], "10003": [42, 44, 47, 51], "distributedweightupdat": 42, "distributedweightsyncschem": [42, 46], "liter": [44, 86, 120, 165, 170, 171, 172, 174, 175, 178, 182, 183, 185, 191, 324, 325, 327, 328, 330, 331, 332, 337, 380, 384, 571, 573, 574, 576, 580, 581, 583, 589], "frequenc": [44, 337, 421, 622], "favor": [46, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 326, 332, 337, 376, 378, 380, 383, 384, 594, 624], "restart": 46, "less": [46, 86, 87, 101, 102, 145, 176, 325, 327, 328, 330, 331, 332, 377, 379, 381, 382, 385, 564, 565, 624, 625, 641, 643], "visible_devic": 47, "tensorpipe_opt": 47, "experiment": [47, 54, 56, 64, 78, 342, 345, 420, 421], "tensorpiperpcbackendopt": 47, "rpcweightupdat": 47, "rpcweightsyncschem": 47, "collector_info": [49, 572, 573], "collector_rref": [49, 572, 573], "_td": [50, 88, 127, 360, 368], "ray_init_config": [50, 53, 66, 402, 404], "remote_config": [50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "num_collector": [50, 564, 565, 622, 623], "use_env_cr": [50, 566], "autodetect": 50, "num_cpu": [50, 53, 66, 192, 193, 194, 243, 329, 402, 403, 404, 615], "num_gpu": [50, 53, 66, 194, 243, 329, 402, 403, 615], "equat": [50, 83, 130, 180, 279, 280, 312, 351, 624, 627, 639], "exce": [50, 641], "indefinit": 50, "rayreplaybuff": [50, 65, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "enfoc": 50, "rayweightupdat": 50, "rayweightsyncschem": 50, "lazili": [50, 86, 87, 96, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 639], "defer": [50, 337], "distributed_collector": [50, 66], "add_collector": 50, "shutdown_rai": [50, 66], "kill": [50, 402], "local_polici": 50, "stop_remote_collector": 50, "num_job": 51, "tcpport": 51, "submitit_main_conf": 51, "slurm_cpus_per_task": 51, "slurm_gpus_per_nod": 51, "slurm_partit": 51, "timeout_min": 51, "submitit_collection_conf": 51, "delai": [51, 286, 339, 372, 629], "jump": [51, 627], "host": [51, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "satellit": 51, "rendezv": 51, "hang": 51, "forev": 51, "default_config": [51, 289, 294, 311], "default_slurm_conf_main": 51, "default_slurm_conf": 51, "randompolicyfrom": 51, "boundedcontinu": [51, 58, 60, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 239, 242, 273, 624, 637, 638, 639, 644], "dialog_turns_per_batch": [52, 53, 594], "yield_only_last_step": [52, 53], "yield_completed_trajectori": [52, 53], "total_dialog_turn": [52, 53, 88], "async_env": [52, 53], "flatten_data": [52, 53], "simplifi": [52, 55, 65, 209, 329, 628, 639, 641], "vllm": [52, 54, 55, 178, 324, 333, 334, 335, 336, 337, 582, 583, 584, 585, 586, 587, 588, 589, 594, 634], "vllmwrapper": [52, 170, 178, 326, 332, 594, 635], "mocking_class": [52, 270], "dummystrdataload": 52, "llmenv": [52, 173, 181, 185], "llm_model": 52, "gpt2": [52, 138, 179, 289, 294, 311, 329, 332, 337, 615], "token": [52, 87, 88, 89, 138, 170, 171, 172, 174, 175, 177, 178, 179, 181, 182, 183, 184, 188, 189, 193, 195, 196, 198, 324, 325, 326, 329, 330, 332, 337, 376, 378, 380, 384, 402, 403, 404, 530, 594, 596, 615, 634, 635], "get_token": 52, "pad_token": [52, 195, 196, 384], "eos_token": [52, 174, 195, 196, 384], "from_dataload": [52, 170, 171, 172, 175, 178, 185], "from_text": [52, 87, 89, 178, 185, 384], "group_repeat": [52, 170, 171, 172, 175, 178, 181, 185], "attention_mask": [52, 178, 332, 337], "22": [52, 83, 90, 108, 109, 278, 622, 623, 639], "text": [52, 81, 86, 87, 88, 89, 138, 170, 171, 172, 174, 175, 177, 178, 179, 187, 189, 190, 193, 195, 196, 203, 312, 324, 325, 326, 329, 331, 332, 333, 337, 383, 384, 594, 596, 624, 626, 634], "nontensorstack": [52, 63, 87, 96, 120, 123, 138, 172, 175, 179, 185, 199, 239, 269, 273], "plsgqejeyd": 52, "text_respons": [52, 172, 175, 177, 178, 180, 183, 193, 384, 594, 634], "ec": 52, "tjbjz3perwhz": 52, "tokens_respons": [52, 178], "as_remot": [52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "cl": [52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 623, 626], "quantiti": [52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "reserv": [52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "alia": [52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 349, 350, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 390, 574, 576], "get_policy_model": [52, 53], "rayllmcollector": [52, 594], "is_initi": [52, 53, 329, 615], "sync_it": 53, "lightweight": [53, 197, 626, 631], "dialog": [53, 88], "yeild": 53, "idl": [53, 150], "somehwat": 53, "serializ": [53, 150, 158, 329], "v2": [54, 55, 86, 87, 136, 137, 156, 157, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 625], "master_address": [54, 324, 335, 336, 582, 589], "master": [54, 324, 335, 336, 582, 589, 637, 638], "address": [54, 324, 335, 336, 402, 404, 582, 589, 594, 641], "localhost": [54, 161, 335, 336, 589], "master_port": [54, 324, 335, 336, 582, 589, 594], "model_metadata": [54, 55, 582, 587, 588], "tupl": [54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 98, 102, 108, 112, 114, 120, 123, 124, 125, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 241, 246, 287, 290, 296, 297, 298, 302, 304, 305, 307, 311, 313, 314, 315, 316, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 350, 351, 352, 353, 357, 358, 360, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 409, 410, 413, 474, 544, 545, 546, 548, 549, 550, 552, 554, 559, 582, 587, 588, 590, 634, 641, 643], "metadata": [54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 79, 86, 87, 91, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 324, 325, 327, 328, 330, 331, 352, 372, 377, 379, 381, 382, 385, 587, 589, 590, 594, 624, 627, 629, 630, 637, 638, 644], "vllm_tp_size": 54, "vllmupdaterv2": [54, 594], "asyncvllm": [54, 333, 337, 582, 585, 594], "vllm_engin": [54, 55, 582, 583, 585, 587, 588, 589, 594], "reliabl": [54, 594], "get_model_metadata": [54, 55, 324, 594], "transformerswrapp": [54, 55, 170, 195, 196, 326, 329, 337, 384, 586, 594, 635], "rlvllmengin": [55, 334, 589], "vllmupdat": [55, 594], "get_tp_siz": [55, 324], "push_weights_from_transform": 55, "transformers_model": [55, 635], "pretrainedmodel": 55, "push_weights_from_transformers_optim": 55, "rollout_tensordict": 56, "_nestedkei": [56, 70, 71, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 178, 179, 180, 212, 219, 220, 221, 222, 223, 228, 229, 232, 236, 238, 241, 242, 246, 247, 251, 252, 254, 255, 256, 257, 258, 262, 264, 265, 266, 268, 271, 273, 280, 326, 332, 337], "nestedkei": [56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 188, 195, 196, 199, 207, 212, 213, 214, 215, 219, 220, 221, 222, 223, 224, 228, 229, 230, 231, 232, 233, 234, 236, 238, 239, 240, 241, 242, 246, 247, 248, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 279, 280, 286, 287, 301, 312, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 345, 351, 354, 365, 368, 377, 379, 381, 382, 383, 385, 391, 393, 409], "as_nest": 56, "x": [56, 68, 83, 86, 87, 109, 138, 176, 179, 239, 241, 268, 273, 282, 287, 288, 297, 300, 302, 304, 305, 313, 325, 326, 327, 328, 330, 331, 332, 337, 338, 342, 376, 377, 378, 379, 380, 381, 382, 384, 385, 391, 393, 416, 594, 622, 626, 637, 639, 641, 643], "max": [56, 64, 72, 101, 102, 114, 137, 177, 231, 266, 312, 350, 351, 352, 358, 367, 369, 371, 380, 409, 420, 594, 622, 624, 625, 626, 632], "durat": [56, 638], "meta": [56, 74, 79, 86, 87, 89, 128, 132, 176, 190, 325, 327, 328, 330, 331, 349, 351, 365, 368, 370, 377, 379, 381, 382, 385, 624, 637, 638, 641], "aren": [56, 264, 625], "eventu": [56, 625, 639], "recov": [56, 79, 81, 83, 84, 85, 86, 87, 108, 109, 176, 325, 327, 328, 330, 331, 346, 357, 364, 377, 379, 381, 382, 385, 636], "to_padded_tensor": 56, "nested_tensor": [56, 129, 131], "stride": [56, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 290, 291, 300, 326, 332, 337, 376, 378, 380, 383, 384, 466, 623, 626, 637, 643], "jag": 56, "focu": [56, 622, 623, 624, 626, 628, 629, 630, 637], "team": [56, 637, 638, 643], "cat": [56, 86, 87, 176, 185, 322, 325, 327, 328, 330, 331, 350, 352, 353, 364, 369, 371, 372, 373, 377, 379, 381, 382, 385, 637, 641, 643], "arang": [56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 108, 109, 214, 297, 306, 406, 641], "obs_": 56, "15": [56, 78, 79, 80, 81, 82, 83, 84, 85, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 190, 226, 312, 360, 622, 623, 639, 641], "trajectory_id": 56, "int32": [56, 58, 73, 75, 78, 83, 108, 136, 137, 148, 149, 160, 206, 341, 641], "data_split": 56, "got": [56, 630], "int8": [57, 126, 141, 152, 153, 219], "encod": [57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 74, 75, 76, 77, 86, 87, 121, 122, 126, 129, 130, 131, 132, 135, 136, 137, 145, 146, 148, 149, 155, 161, 162, 176, 180, 214, 231, 309, 310, 315, 317, 325, 326, 327, 328, 330, 331, 332, 337, 377, 379, 381, 382, 385, 402, 615, 623, 624, 625, 628, 639, 641], "unlik": [57, 68, 72, 73, 107, 130, 142, 143, 163, 164, 180, 341, 359, 368, 393, 570, 623, 626, 628, 630, 643], "null": [57, 58, 60, 63, 65, 70, 71, 72, 74, 75, 76, 77, 170, 178, 219, 239], "denot": [57, 638], "assert_is_in": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "belong": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 83, 278, 279, 345, 622, 630, 638], "cardin": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 297, 298, 314, 624], "outcom": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 295, 306, 319, 366, 376, 378, 380, 384, 637], "cartesian": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "clear_device_": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "is_in": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 644], "ndarrai": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 130, 176, 180, 312, 325, 327, 328, 330, 331, 348, 377, 379, 381, 382, 385, 391, 626, 637], "ignore_devic": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "arrai": [57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 74, 75, 76, 77, 86, 87, 90, 101, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 233, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 622, 637], "np": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 90, 130, 176, 180, 278, 325, 327, 328, 330, 331, 348, 377, 379, 381, 382, 385, 391, 626, 637, 639], "use_mask": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 152, 153], "erase_memoize_cach": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "memoiz": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 130, 180], "memoize_encod": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "broadcast": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 295, 324, 358, 371, 582, 587, 588, 589, 590, 594], "least": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 224, 243, 631, 644], "compliant": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "singleton": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 177, 288, 305, 634], "start_dim": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "end_dim": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "implements_for_spec": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "torch_funct": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "tensor_to_index": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "represent": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 250, 275, 277, 325, 326, 327, 328, 330, 331, 332, 337, 349, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 596, 622, 639, 640, 644], "exanpl": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "one_hot": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "categ": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 342], "to_categorical_spec": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "idx_one_hot": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "idx_categ": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "to_categor": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "make_neg_dim": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "convert": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 90, 120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 229, 232, 250, 265, 271, 272, 275, 277, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 344, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589, 596, 622, 623, 624, 639, 641], "shortcut": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 639, 644], "len": [57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 95, 97, 116, 185, 248, 288, 305, 384, 622, 625, 626, 630, 632, 637, 639, 640, 641, 643], "ndimens": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 622], "violat": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "primari": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 138, 179, 615, 630], "project": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 231, 286, 297, 298, 312, 313, 314, 340, 342, 344, 345, 400, 401, 465, 601, 643, 644], "uniformli": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 101, 102, 103, 366, 376, 378, 380, 384, 644], "normal": [57, 58, 59, 60, 61, 62, 63, 64, 67, 70, 71, 74, 75, 76, 77, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 246, 279, 280, 286, 288, 303, 305, 306, 315, 316, 320, 321, 342, 345, 351, 352, 365, 368, 383, 384, 410, 413, 566, 589, 625, 628, 638, 644], "drawn": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 265, 301, 342, 345, 624, 637, 638], "set_provisional_n": [57, 59, 61], "temporarili": [57, 59, 61, 93, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 630, 641], "dest": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 250, 275, 277, 344], "to_numpi": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "transformed_in": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 319, 566], "check_spec_encod": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "to_one_hot": [57, 59, 61, 62, 64], "hot": [57, 59, 61, 62, 64, 121, 122, 129, 131, 132, 135, 136, 137, 142, 143, 145, 146, 148, 149, 152, 153, 155, 161, 162, 163, 164, 214, 231, 297, 298, 310, 313, 314, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 625], "categ_sampl": [57, 59, 62, 64], "onehot_sampl": [57, 59, 62], "to_one_hot_spec": [57, 59, 61, 62, 64], "categoricalbox": [57, 59, 62, 64, 151, 628, 637, 638, 644], "type_check": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "unflatten": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 176, 218, 325, 327, 328, 330, 331, 341, 377, 379, 381, 382, 385], "unsqueez": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 190, 206, 215, 218, 221, 222, 268, 274, 529, 594, 622, 626, 637, 638, 639], "update_mask": [57, 59, 61, 62, 64], "leav": [57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 213, 259, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 622, 630, 641], "unmask": [57, 59, 61, 62, 64, 306], "ts": [57, 59, 61, 62, 64], "boundeddiscret": [58, 60, 624], "upper": [58, 106, 245], "continuousbox": [58, 60, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 239, 242, 265, 273, 624, 625, 637, 638, 639, 644], "provision": [59, 337], "descript": [60, 135, 163, 217, 380, 615, 623, 624], "akin": 60, "unnam": [60, 71], "constraint": [60, 144, 320, 601, 624, 637, 638], "data_cl": [60, 624, 625, 637, 638, 639, 644], "tensorclass": [60, 86, 87, 95, 97, 116, 176, 325, 326, 327, 328, 330, 331, 337, 377, 379, 381, 382, 385, 596], "enforc": [60, 88, 107, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 334, 337, 346, 351, 352, 368, 371, 376, 378, 380, 383, 384, 639], "step_mdp_stat": 60, "pixels_spec": 60, "observation_vector_spec": 60, "33": [60, 69, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 305, 326, 332, 337, 376, 378, 380, 383, 384, 623], "composite_spec": 60, "observation_vector": [60, 222, 622], "_nodefault": [60, 71], "is_empti": [60, 71, 639], "recurs": [60, 71, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 330, 331, 332, 337, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 626], "include_nest": [60, 71], "leaves_onli": [60, 71], "is_leaf": [60, 71, 626], "step_mdp_static_onli": [60, 71], "_compositespecitemsview": [60, 71], "_compositespeckeysview": [60, 71], "reflect": [60, 71, 131, 152, 153, 212, 239, 278, 366, 376, 378, 380, 384, 555, 623, 624, 625, 638], "lock_": [60, 71], "succeed": [60, 71, 239, 273], "ones_upd": [60, 71], "pop": [60, 71, 195, 225], "keyerror": [60, 71, 171, 172, 175, 201, 272, 368, 402, 403, 615], "rand_upd": [60, 71], "refine_nam": [60, 71], "refin": [60, 71, 83, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 594], "lift": [60, 71, 83], "coexist": [60, 71], "nice": [60, 71, 624, 627, 630], "ellipsi": [60, 71], "greedili": [60, 71, 628], "spec_refin": [60, 71], "selected_kei": [60, 71, 259, 622], "unlock_": [60, 71], "_compositespecvaluesview": [60, 71], "zeros_upd": [60, 71], "nvec": [61, 62], "remove_singleton": 61, "ax": [61, 637], "m": [61, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 231, 287, 326, 332, 337, 345, 376, 378, 380, 383, 384, 623, 639], "tensor_spec": [61, 64, 74, 213, 215, 265, 343, 357, 358, 368, 370], "neither": [61, 62, 83, 161, 639], "use_regist": [62, 64], "mone_hot": 62, "boxlist": 62, "example_data": [63, 87, 175, 178, 185], "feature_dim": 63, "conform": 63, "nontensordata": [63, 78, 83, 86, 87, 123, 148, 149, 176, 185, 199, 239, 269, 273, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 391], "left": [63, 78, 79, 83, 88, 102, 108, 173, 174, 177, 178, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 218, 225, 226, 228, 229, 230, 234, 241, 244, 250, 252, 253, 259, 263, 266, 269, 271, 273, 275, 277, 280, 301, 306, 326, 332, 337, 383, 490, 623, 624, 626, 630, 631], "device_typ": [63, 560], "templat": [63, 87, 89, 170, 171, 172, 175, 195, 196, 198, 325, 330, 331, 332, 337, 394, 594, 596], "randomli": [63, 83, 107, 160, 183, 215, 245, 246, 265, 301, 342, 345, 628, 637, 638, 639, 641], "unidimension": 64, "action_valu": [64, 296, 297, 298, 313, 314, 352, 358, 366, 376, 378, 380, 384, 625, 626, 628, 632], "keepdim": [64, 594], "chosen_action_valu": [64, 313, 314, 625, 626, 628], "priori": 64, "definit": [64, 110, 634], "one_hot_sampl": 64, "ep": [65, 72, 101, 102, 246, 279, 280, 312, 351, 380, 413, 431, 508, 518, 539, 540, 542, 543, 544, 545, 546, 549, 550, 551, 554, 622, 623, 625, 626, 629, 632], "1e": [65, 72, 101, 102, 246, 279, 280, 295, 299, 307, 319, 508, 518, 539, 540, 542, 543, 545, 546, 547, 549, 550, 551, 552, 554, 622, 623, 624, 638], "08": [65, 72, 101, 102, 508, 518, 539, 540, 545, 546, 549, 550, 551, 554, 622, 623, 624, 637, 638], "pin_memori": [65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 249, 622, 626, 643], "prefetch": [65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 622, 623, 625, 641], "dim_extend": [65, 68, 72, 73], "delayed_init": [65, 66, 68, 69, 72, 73], "schaul": [65, 101, 102], "quan": [65, 101, 102], "j": [65, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384, 625, 629], "antonogl": [65, 101, 102], "silver": [65, 101, 102], "2015": [65, 101, 102, 226], "arxiv": [65, 80, 83, 85, 101, 102, 121, 122, 124, 125, 136, 137, 142, 143, 145, 146, 155, 163, 164, 221, 250, 275, 289, 290, 291, 292, 293, 294, 298, 299, 300, 308, 309, 312, 315, 316, 317, 349, 350, 354, 355, 356, 357, 359, 360, 361, 362, 363, 364, 367, 368, 371, 372, 386, 640], "ab": [65, 80, 83, 85, 101, 102, 121, 122, 124, 125, 136, 137, 142, 143, 145, 146, 155, 163, 164, 220, 250, 275, 279, 289, 294, 299, 300, 308, 309, 315, 316, 317, 349, 350, 354, 355, 356, 357, 360, 361, 362, 364, 367, 368, 371, 640], "1511": [65, 101, 102, 300], "05952": [65, 101, 102], "expon": [65, 72, 101, 102], "\u03b1": [65, 72], "uniform": [65, 72, 101, 102, 326, 332, 337, 637], "delta": [65, 72, 319, 342, 345, 601, 637], "1_000": [65, 68, 72, 73, 637, 641], "mini": [65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 638], "decid": [65, 68, 72, 73, 615, 637, 643], "incompat": [65, 68, 72, 73, 370, 641], "drop_last": [65, 68, 72, 73, 107, 109, 435], "notion": [65, 68, 72, 73], "capac": [65, 68, 72, 73, 95, 97, 101, 102, 108, 116, 624, 630], "caution": [65, 68, 72, 73, 107, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 402, 644], "codebas": [65, 68, 72, 73, 639], "unbind": [65, 68, 72, 73, 86, 87, 176, 244, 325, 327, 328, 330, 331, 341, 377, 379, 381, 382, 384, 385, 594, 626], "transform_factori": [65, 66, 68, 69, 72, 73], "return_info": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 641], "tensordictprioritizedreplaybuff": [65, 643], "priority_weight": [65, 72, 101, 102, 641], "update_prior": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 412, 623, 641, 643], "36278465": 65, "invert": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 624], "default_remote_class_config": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "overriden": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "tempfil": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 95, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 562, 622, 623, 625, 626, 630, 637, 640, 641], "tensordictreplaybuff": [65, 66, 67, 68, 69, 72, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 108, 109, 114, 220, 221, 412, 440, 562, 622, 623, 625, 641], "1_000_000": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 108, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 622, 625, 637], "td_error": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 352, 353, 354, 356, 357, 358, 359, 364, 366, 369, 371, 372, 373, 376, 378, 380, 384, 622, 629, 641, 643], "update_tensordict_prior": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 622, 641, 643], "temporarydirectori": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 622, 623, 625, 626, 630, 637, 640, 641], "tmpdir": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 622, 623, 626, 637], "rb_load": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "empty_write_count": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "cursor": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "ambigu": [65, 66, 68, 69], "pytre": [65, 66, 68, 69, 72, 73, 86, 87, 98, 117, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "cut": [65, 66, 68, 69], "insert_transform": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 171, 172, 175, 216, 272], "insert": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 94, 104, 114, 115, 118, 119, 171, 172, 175, 195, 216, 221, 225, 262, 272, 274, 594], "__iter__": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 185], "register_load_hook": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "register_save_hook": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "set_sampl": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "set_storag": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "set_writ": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "far": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 175, 303, 320, 321, 380, 594, 632, 639, 644], "replay_buffer_cl": 66, "optiona": 66, "asyncio": [66, 120], "ray_buff": 66, "object_store_memori": 66, "600": [66, 631, 641], "await": 66, "invoc": 67, "friendli": [67, 317, 622], "public": [67, 82, 111, 250, 277], "include_info": [67, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "checkpoint": [68, 91, 93, 95, 99, 110, 111, 113, 117, 402, 418, 616, 641], "roundrobinwrit": [68, 78, 79, 80, 81, 82, 83, 84, 85, 434], "depth": [68, 74, 120, 123, 126, 130, 138, 144, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 288, 290, 291, 292, 293, 297, 299, 300, 305, 308, 309, 466, 467, 470, 471, 472, 623, 627, 629, 630, 636, 637, 638, 641], "_pytre": [68, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 641], "tree_map": [68, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 641], "assert0": [68, 641], "writerensembl": [69, 112], "sample_from_al": [69, 78, 106], "num_buffer_sampl": [69, 106], "_c": [69, 72], "ensembl": [69, 106, 112, 113, 119, 344, 369, 438, 439], "forbidden": 69, "collat": [69, 171, 172, 175], "rb0": 69, "rb1": 69, "another_kei": 69, "pixels33": 69, "0x13a2ef430": 69, "0x13a2f9310": 69, "interpolationmod": [69, 625], "bilinear": [69, 254, 515, 625], "0x13a2f9220": 69, "0x13a2f9f70": 69, "tensordictroundrobinwrit": [69, 73], "0x13a2d9b50": 69, "0x13a2f95b0": 69, "0x128648260": 69, "data0": [69, 96], "randint": [69, 86, 87, 176, 185, 268, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 626, 641], "255": [69, 268, 626, 641], "244": [69, 250, 277], "data1": [69, 96, 643], "thrown": [70, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 641], "heterogen": [70, 71, 96, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 622, 623], "semant": [70, 71, 129, 131, 640], "priority_kei": [72, 73, 101, 352, 354, 357, 358, 359, 364, 366, 369, 371, 372, 373, 376, 378, 380, 384, 641, 643], "reduct": [72, 101, 102, 114, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 380, 384, 409, 431, 474], "prioritizedreplaybuff": [72, 643], "min": [72, 101, 102, 114, 312, 350, 351, 352, 358, 367, 369, 371, 376, 380, 409, 623, 624], "median": [72, 101, 102, 114, 130, 136, 137, 180, 214, 342, 345], "_encode_memo_dict": 74, "possess": [74, 79], "describ": [74, 86, 87, 176, 202, 222, 319, 320, 325, 327, 328, 330, 331, 343, 354, 377, 379, 381, 382, 385, 396, 622, 624, 637, 638, 639, 644], "make_composite_from_td": [74, 639], "educ": 74, "guess": 74, "knowledg": [74, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 629, 631], "dataset_id": [78, 79, 80, 81, 83, 84, 85], "num_proc": 78, "slice_len": [78, 83, 102, 108, 109, 393, 436, 437, 625], "strict_len": 78, "mp_start_method": [78, 79, 80, 81, 82, 83, 84, 85, 150, 158, 270, 622, 623, 636, 643, 644], "arari": 78, "2600": 78, "million": 78, "consequ": [78, 93, 630], "50x10": 78, "available_dataset": [78, 79, 80, 81, 82, 83, 84, 85, 108, 109], "ataridqn": 78, "greater": [78, 102, 108, 109, 226, 242, 244, 302, 304, 326, 332, 337, 352, 622, 623], "strict_length": [78, 83, 102, 108, 109, 393, 436, 437, 625], "shorter": [78, 83, 102, 108, 109], "Be": [78, 83, 102, 108, 109], "game_nam": 78, "krull": 78, "1d": [78, 101, 102, 108, 109, 114], "1m": [78, 83, 555, 622, 624, 625], "cheapli": 78, "invalid_rang": 78, "999998": 78, "999999": 78, "add_count": 78, "84": [78, 90, 108, 254, 485, 490, 515, 622, 623, 625, 626, 639], "valueestim": [78, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 622, 637, 638], "convolut": [78, 288, 290, 291, 466, 626, 628], "2657628": 78, "2657629": 78, "2657630": 78, "2657631": 78, "2657632": 78, "2657633": 78, "2657634": 78, "2657635": 78, "2657636": 78, "2657637": 78, "2657638": 78, "2657639": 78, "2657640": 78, "2657641": 78, "2657642": 78, "2657643": 78, "2657644": 78, "2657645": 78, "2657646": 78, "2657647": 78, "2657648": 78, "2657649": 78, "2657650": 78, "2657651": 78, "2657652": 78, "2657653": 78, "2657654": 78, "2657655": 78, "2657656": 78, "2657657": 78, "2657658": 78, "2657659": 78, "2657660": 78, "2657661": 78, "2657662": 78, "2657663": 78, "2657664": 78, "2657665": 78, "2657666": 78, "2657667": 78, "2657668": 78, "2657669": 78, "2657670": 78, "2657671": 78, "2657672": 78, "2657673": 78, "2657674": 78, "2657675": 78, "2657676": 78, "2657677": 78, "2657678": 78, "2657679": 78, "2657680": 78, "2657681": 78, "2657682": 78, "2657683": 78, "2657684": 78, "2657685": 78, "2657686": 78, "2657687": 78, "2657688": 78, "2657689": 78, "2657690": 78, "2657691": 78, "1995687": 78, "1995688": 78, "1995689": 78, "1995690": 78, "1995691": 78, "1995692": 78, "1995693": 78, "1995694": 78, "1995695": 78, "1995696": 78, "1995697": 78, "1995698": 78, "1995699": 78, "1995700": 78, "1995701": 78, "1995702": 78, "1995703": 78, "1995704": 78, "1995705": 78, "1995706": 78, "1995707": 78, "1995708": 78, "1995709": 78, "1995710": 78, "1995711": 78, "1995712": 78, "1995713": 78, "1995714": 78, "1995715": 78, "1995716": 78, "1995717": 78, "1995718": 78, "1995719": 78, "1995720": 78, "1995721": 78, "1995722": 78, "1995723": 78, "1995724": 78, "1995725": 78, "1995726": 78, "1995727": 78, "1995728": 78, "1995729": 78, "1995730": 78, "1995731": 78, "1995732": 78, "1995733": 78, "1995734": 78, "1995735": 78, "1995736": 78, "1995737": 78, "1995738": 78, "1995739": 78, "1995740": 78, "1995741": 78, "1995742": 78, "1995743": 78, "1995744": 78, "1995745": 78, "1995746": 78, "1995747": 78, "1995748": 78, "1995749": 78, "1995750": 78, "replaybufferensembl": [78, 106, 112, 119], "untouch": [78, 83, 86, 87, 88, 173, 174, 176, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 273, 280, 325, 327, 328, 330, 331, 377, 379, 381, 382, 383, 385], "_max_run": 78, "dataset_asterix": 78, "asterix": [78, 644], "dataset_pong": 78, "buffer_id": [78, 106, 112], "hidden": [78, 150, 158, 220, 283, 284, 285, 290, 299, 302, 304, 308, 309, 315, 316, 344, 347, 351, 365, 368, 625, 636, 643], "data_path": [78, 79, 80, 81, 82, 83, 84, 85], "data_path_root": [78, 79, 80, 81, 82, 83, 84, 85], "delet": [78, 79, 80, 81, 82, 83, 84, 85, 97, 222, 262, 401, 640], "fn": [78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 273, 307, 326, 332, 337, 376, 378, 380, 383, 384, 533, 564, 565], "chunksiz": [78, 79, 80, 81, 82, 83, 84, 85], "num_chunk": [78, 79, 80, 81, 82, 83, 84, 85], "max_tasks_per_child": [78, 79, 80, 81, 82, 83, 84, 85], "worker_thread": [78, 79, 80, 81, 82, 83, 84, 85], "index_with_gener": [78, 79, 80, 81, 82, 83, 84, 85], "num_fram": [78, 79, 80, 81, 82, 83, 84, 85], "unitari": [78, 79, 80, 81, 82, 83, 84, 85, 639], "subsequ": [78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 326, 332, 337, 376, 378, 380, 383, 384, 569, 577, 625, 637], "minariexperiencereplai": [78, 79, 80, 82, 83, 84, 85], "distance_from_origin": [78, 79, 80, 81, 82, 83, 84, 85], "forward_reward": [78, 79, 80, 81, 82, 83, 84, 85], "qpo": [78, 79, 80, 81, 82, 83, 84, 85], "qvel": [78, 79, 80, 81, 82, 83, 84, 85], "reward_ctrl": [78, 79, 80, 81, 82, 83, 84, 85, 130, 150, 180], "reward_forward": [78, 79, 80, 81, 82, 83, 84, 85], "reward_surv": [78, 79, 80, 81, 82, 83, 84, 85], "x_posit": [78, 79, 80, 81, 82, 83, 84, 85, 130, 150, 180], "x_veloc": [78, 79, 80, 81, 82, 83, 84, 85, 130, 150, 180], "y_posit": [78, 79, 80, 81, 82, 83, 84, 85], "y_veloc": [78, 79, 80, 81, 82, 83, 84, 85], "achieved_go": [78, 79, 80, 81, 82, 83, 84, 85], "desired_go": [78, 79, 80, 81, 82, 83, 84, 85], "27": [78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 108, 109, 121, 122, 150, 158, 176, 226, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 622, 623, 637, 639], "_collate_id": [78, 79, 80, 81, 82, 83, 84, 85], "0x120e21dc0": [78, 79, 80, 81, 82, 83, 84, 85], "cattensor": [78, 79, 80, 81, 82, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 484, 622, 636, 639, 644], "cat_tensor": [78, 79, 80, 81, 82, 83, 84, 85], "cat_next_tensor": [78, 79, 80, 81, 82, 83, 84, 85], "func": [78, 79, 80, 81, 82, 83, 84, 85, 281], "new_storag": [78, 79, 80, 81, 82, 83, 84, 85], "31": [78, 79, 80, 81, 82, 83, 84, 85, 108, 136, 137, 622, 623, 639], "full_storag": [78, 79, 80, 81, 82, 83, 84, 85], "0x168406fc0": [78, 79, 80, 81, 82, 83, 84, 85], "from_env": 79, "use_truncated_as_don": 79, "direct_download": 79, "terminate_on_end": 79, "env_kwarg": [79, 84, 85, 218, 480, 564, 565, 622], "d4rl": [79, 85], "reconstruct": [79, 108, 109, 361, 622, 644], "regard": [79, 85, 298, 349, 359, 368, 622, 624, 639], "get_dataset": 79, "qlearning_dataset": 79, "fewer": [79, 102, 108], "unexpectedli": 79, "traj_split": 79, "observationnorm": [79, 279, 280, 508, 566, 622, 623, 624, 625, 643], "maze2d": 79, "umaz": 79, "loc": [79, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180, 241, 246, 257, 279, 280, 283, 284, 285, 303, 307, 320, 321, 342, 345, 347, 349, 350, 352, 364, 368, 369, 370, 371, 508, 518, 556, 566, 601, 622, 623, 624, 625, 628, 638, 643], "gen": 80, "dgrl": 80, "accompani": [80, 218, 263], "gap": 80, "2312": 80, "05742": 80, "gen_dgrl": 80, "procgen": 80, "bigfish": 80, "bossfight": 80, "1m_e": 80, "1m_": 80, "comma": [80, 626], "npy": 80, "mmap": [80, 84, 85], "minut": [80, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 635, 636, 637, 638, 639, 640, 641, 644], "huggingfac": [80, 85, 177, 332], "internet": [80, 85], "connect": [80, 85, 161, 190, 567, 568, 570, 571, 573, 574, 575, 576, 578, 581, 583, 589], "load_from_local_minari": 81, "minari": 81, "websit": [81, 83, 634], "currenrtli": 81, "minari_data": 81, "door": 81, "human": [81, 171, 639], "torchrl_logg": [81, 632, 634], "28": [81, 108, 109, 378, 380, 623, 637, 644], "39": [81, 136, 137, 622, 623, 639], "door_body_po": 81, "openml": [82, 147, 455], "dua": 82, "graff": 82, "2017": 82, "uci": [82, 123], "archiv": 82, "ic": 82, "edu": 82, "ml": [82, 161, 162, 324], "scikit": [82, 147], "sklearn": [82, 147], "panda": 82, "adult_num": [82, 147], "adult_onehot": [82, 147], "mushroom_num": [82, 147], "mushroom_onehot": [82, 147], "covertyp": [82, 147], "shuttl": [82, 147], "magic": [82, 147, 626, 627], "shuffl": [83, 107, 109, 171, 172, 175, 435, 638], "embodi": [83, 640], "collabor": 83, "21": [83, 84, 108, 109, 150, 152, 153, 158, 226, 622, 623, 624, 636, 639], "institut": 83, "demonstr": [83, 594, 624, 626, 630, 634, 635, 637, 638, 639, 641, 644], "527": 83, "skill": 83, "160266": 83, "googl": [83, 84, 121, 122, 142, 143, 148, 149, 175, 177, 624, 625, 634, 637, 638], "open_x_embodi": 83, "2310": [83, 155], "08864": 83, "language_instruct": 83, "get_non_tensor": 83, "nor": [83, 161], "insuffici": 83, "chosen": [83, 163, 164, 264, 265, 314, 393, 615, 631], "openx": 83, "__will": 83, "change__": 83, "crop": [83, 223, 251, 393, 490], "compli": 83, "modal": [83, 326, 332, 337, 622], "cmu_stretch": [83, 393], "discount": [83, 127, 255, 350, 356, 359, 360, 362, 386, 387, 388, 389, 420, 623, 624, 637, 638], "is_init": [83, 85, 220, 240, 302, 304, 312, 341, 386, 625, 626], "language_embed": 83, "512": [83, 300, 623, 626], "green": [83, 637], "garbag": [83, 570], "lid": 83, "roboset": 84, "h5": [84, 85, 86, 87, 93, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "roboh": [84, 155, 458], "excludetransform": [84, 259, 496, 641], "fk1": 84, "v4": [84, 130, 150, 180, 214, 254, 622, 624, 640, 643], "expert": 84, "fk1_microopenrandom_v2d": 84, "concis": [84, 629], "20": [84, 108, 109, 114, 120, 123, 126, 130, 134, 138, 148, 149, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 264, 300, 378, 380, 402, 406, 547, 623, 624, 626, 635, 637, 638, 641, 644], "18": [84, 108, 109, 156, 157, 163, 164, 270, 622, 623, 624, 638, 639, 644], "23": [84, 109, 226, 282, 622, 623, 624], "19": [84, 108, 109, 114, 226, 621, 623, 638, 639, 642], "75": [84, 108, 541, 623, 625, 638], "totensor": 85, "image_s": 85, "v": [85, 279, 283, 357, 364, 371, 608, 622, 623], "npz": 85, "2206": [85, 145, 146, 624], "04779": [85, 350, 356], "vd4rl": 85, "squar": [85, 223, 228, 303, 320, 321, 351, 368, 380, 393, 594], "rectangular": [85, 288], "walker_walk": 85, "64px": 85, "height": [85, 223, 228, 254, 485, 490], "veloc": [85, 120, 123, 124, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 637, 638, 639, 644], "audio": 86, "function_cal": 86, "_wrap_td_method": 86, "wrapped_func": 86, "0x10e809ee0": 86, "mime_typ": 86, "function_nam": 86, "function_arg": 86, "copy_exist": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "return_earli": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "share_non_tensor": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "robust_kei": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_ani": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "auto_batch_s": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "batch_dim": [86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 566], "incur": [86, 87, 121, 122, 136, 137, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "involv": [86, 87, 129, 131, 132, 142, 143, 155, 176, 218, 221, 270, 302, 304, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 627, 629], "opinion": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "term": [86, 87, 96, 176, 188, 195, 241, 325, 327, 328, 330, 331, 349, 358, 368, 377, 379, 381, 382, 385, 419, 623, 624, 627, 628, 638], "obj": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_dataclass": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "namedtupl": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 325, 326, 327, 328, 330, 331, 332, 337, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385], "from_namedtupl": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_dict": [86, 87, 176, 185, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_tupl": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_struct_arrai": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "hdf5": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_h5": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "dest_cl": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "as_tensorclass": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "convers": [86, 87, 121, 122, 136, 137, 170, 172, 175, 176, 186, 195, 196, 209, 325, 327, 328, 330, 331, 377, 379, 380, 381, 382, 385, 568, 571, 573, 574, 576, 581, 583, 589, 594, 596, 634, 635], "persistenttensordict": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "key1": [86, 87, 176, 222, 262, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 406, 414, 643], "key2": [86, 87, 176, 222, 262, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 406, 414, 643], "as_modul": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "use_state_dict": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "lazy_stack": [86, 87, 88, 89, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 384, 385, 594, 636], "expand_ident": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "ensebml": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "vmap": [86, 87, 176, 325, 327, 328, 330, 331, 344, 347, 350, 352, 358, 364, 366, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 608], "tensordictparam": [86, 87, 176, 325, 327, 328, 330, 331, 345, 377, 379, 381, 382, 385], "densli": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "dens": [86, 87, 120, 176, 306, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 594], "reinstanti": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "tempt": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "orign": [86, 87, 176, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 384, 385], "longer": [86, 87, 95, 176, 189, 282, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 594, 623, 625, 632, 637, 638, 641], "empty_modul": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "n_model": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "bia": [86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 239, 250, 265, 270, 271, 272, 275, 277, 288, 290, 291, 292, 293, 299, 300, 301, 302, 304, 305, 307, 312, 325, 326, 327, 328, 330, 331, 332, 337, 344, 352, 366, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 622, 623, 624, 625, 626, 638], "exec_modul": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "to_modul": [86, 87, 176, 325, 327, 328, 330, 331, 344, 347, 377, 379, 381, 382, 385, 622, 643], "backprop": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "named_tupl": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "a_tensor": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "a_str": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "nt": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "to_namedtupl": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "genericdict": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_pytre": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "biject": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "castabl": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "surject": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "weird": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "weirdlookingclass": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "weird_kei": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "pytree_recon": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "to_pytre": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_remote_init": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "processgroup": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "init_remot": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "src": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "struct_arrai": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "rex": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "fido": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "u10": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "ag": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "i4": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "f4": [86, 87, 123, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "x_recon": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "to_struct_arrai": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_tensordict": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "non_tensordict": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "my_tupl": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "fromkei": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "getattr": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "load_memmap": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "load_": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "load_memmap_": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "non_block": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 325, 326, 327, 328, 330, 331, 332, 337, 344, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385], "robust": [86, 87, 176, 251, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 594], "decod": [86, 87, 138, 176, 179, 207, 308, 324, 325, 326, 327, 328, 330, 331, 332, 337, 377, 379, 381, 382, 385, 594], "emit": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "saved_td": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "td_load": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "_subclass": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "faketensormod": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "faketensor": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "strict": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 325, 326, 327, 328, 330, 331, 332, 337, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 615, 626], "from_flatten": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "attemptedli": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "destin": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 220, 229, 230, 232, 239, 270, 272, 275, 279, 325, 326, 327, 328, 330, 331, 332, 337, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 419, 420, 475, 580], "maybe_dense_stack": [86, 87, 176, 185, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "existsok": [86, 87, 95, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "mimic": [86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "non_tensor": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "charact": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 624, 626], "throw": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 644], "cross": [86, 87, 176, 325, 326, 327, 328, 330, 331, 332, 337, 377, 379, 381, 382, 385, 592], "anymor": [86, 87, 176, 272, 325, 327, 328, 330, 331, 344, 377, 379, 381, 382, 385], "tensordictfutur": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "serialis": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "deepli": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "memmap_": [86, 87, 176, 279, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "memmap_lik": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "contentless": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "memmap_refresh_": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "refresh": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 632, 637, 638], "saved_path": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "setattr": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "tent": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "keep_var": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 325, 326, 327, 328, 330, 331, 332, 337, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385], "to_tensordict": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "retain_non": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "discrard": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "contentbas": 87, "is_complet": 87, "tool_cal": 87, "tool_respons": [87, 193, 594], "apply_chat_templ": [87, 89, 170, 193, 384, 594, 634], "autotoken": [87, 89, 170, 171, 172, 174, 175, 182, 183, 189, 193, 195, 196, 325, 330, 331, 332, 337, 384, 594, 634, 635], "autoprocessor": 87, "add_generation_prompt": [87, 89, 195, 196, 325, 384], "chat_templ": [87, 198, 325, 332, 337, 384], "chat_template_nam": [87, 89, 325, 330, 331, 332, 337, 384], "continue_final_messag": 87, "return_tensor": [87, 195, 330], "return_dict": [87, 89, 196], "return_assistant_tokens_mask": [87, 89, 195, 196], "chat": [87, 89, 170, 171, 172, 175, 184, 193, 195, 196, 198, 325, 330, 331, 332, 337, 384, 594, 596, 635], "pretrainedtoken": [87, 170, 181, 332, 337], "prompt": [87, 88, 170, 171, 172, 173, 175, 177, 178, 183, 185, 190, 193, 324, 325, 327, 329, 330, 331, 332, 337, 380, 383, 594, 635], "im_start": [87, 172, 175, 193, 594], "assist": [87, 89, 170, 172, 175, 183, 189, 190, 193, 195, 196, 332, 337, 380, 384, 594, 596, 625, 634, 635], "preval": 87, "messag": [87, 89, 170, 183, 187, 568, 569, 570, 571, 573, 574, 576, 577, 578, 581, 583, 589, 594, 635], "pt": [87, 195, 330, 395, 462], "assistant_mask": 87, "qwen": [87, 172, 175, 183, 193, 324, 332, 333, 334, 337, 384, 594, 634, 635], "dialogpt": 87, "falcon": 87, "deepseek": 87, "chatml_format": [87, 332, 337, 384], "default_spec": [87, 325, 327, 328, 330, 331], "set_list_to_stack": [87, 175, 190, 193, 195, 196, 197, 594, 634], "foo": [87, 95, 97, 116, 641, 644], "from_chat": [87, 89, 170, 195, 196, 332, 337, 384, 635], "from_pretrain": [87, 89, 138, 172, 175, 179, 183, 193, 195, 196, 324, 329, 332, 337, 384, 594, 634, 635], "qwen2": [87, 172, 175, 183, 193, 324, 333, 334, 337, 594, 634, 635], "7b": [87, 89, 324, 594, 634], "nyou": [87, 175, 635], "im_end": [87, 172, 183, 193, 594, 634], "nwrite": 87, "capit": [87, 634, 635], "franc": [87, 634, 635], "germani": 87, "pari": [87, 175, 634, 635], "berlin": 87, "answer": [87, 172, 174, 175, 177, 183, 594, 634], "topk_siz": 88, "prompt_kei": [88, 177, 383], "rewards_kei": [88, 383], "k": [88, 287, 326, 332, 337, 608], "topk": 88, "selector": [88, 634], "25": [88, 226, 474, 615, 622, 623, 625, 637], "wrote": 88, "top3": 88, "r3": 88, "as_padded_tensor": [88, 178, 185, 196, 326, 332, 337], "add_modul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "init_weight": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "fill_": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 623, 625], "net": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 291, 293, 296, 300, 326, 332, 337, 349, 350, 352, 358, 364, 368, 369, 370, 371, 376, 378, 380, 383, 384, 466, 467, 470, 472, 562, 623, 639, 640, 643], "requires_grad": [88, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 270, 272, 326, 332, 337, 345, 352, 371, 376, 378, 380, 383, 384, 445], "bfloat16": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "datatyp": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 641], "member": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 366, 376, 378, 380, 383, 384, 393], "xdoctest": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 239, 250, 265, 270, 271, 272, 275, 277, 326, 332, 337, 344, 352, 366, 371, 376, 378, 380, 383, 384], "buf": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "20l": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 366, 376, 378, 380, 383, 384], "1l": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 366, 376, 378, 380, 383, 384], "5l": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 366, 376, 378, 380, 383, 384], "doubl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 229, 230, 232, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 354, 359, 369, 376, 378, 380, 383, 384, 583, 584, 585, 586, 622, 623, 624, 625, 644], "eval": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 279, 326, 332, 337, 351, 368, 376, 378, 380, 383, 384, 622, 623, 624], "evalu": [88, 120, 123, 126, 130, 131, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 272, 295, 306, 310, 321, 326, 332, 337, 369, 376, 378, 380, 383, 384, 557, 558, 615, 623, 624, 632], "batchnorm": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 326, 332, 337, 376, 378, 380, 383, 384], "extra_repr": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "transformthatmeasuresbyt": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 383], "byte": [88, 90, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 383], "bytes_in_td": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 383], "get_buff": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "docstr": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 627, 628], "get_submodul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "explan": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "qualifi": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "referenc": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "get_extra_st": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 376, 378, 380, 383, 384], "set_extra_st": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 376, 378, 380, 383, 384], "picklabl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 376, 378, 380, 383, 384], "get_paramet": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "sai": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 637, 640, 644], "net_b": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "net_c": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "conv": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 326, 332, 337, 376, 378, 380, 383, 384, 623, 626], "conv2d": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 290, 291, 300, 326, 332, 337, 376, 378, 380, 383, 384, 626], "kernel_s": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 290, 291, 300, 308, 326, 332, 337, 376, 378, 380, 383, 384, 466, 623, 643], "diagram": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "degre": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 326, 332, 337, 376, 378, 380, 383, 384], "named_modul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "o": [88, 91, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "half": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384, 622], "ipu": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "descend": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384], "get_swap_module_params_on_convers": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384], "persist": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 212, 239, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384, 402, 615], "preserv": [88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 344, 352, 371, 376, 378, 380, 383, 384], "missing_kei": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384], "unexpected_kei": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384], "l": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 624, 639], "idx": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "mtia": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "named_buff": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "remove_dupl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 366, 376, 378, 380, 383, 384], "prepend": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 366, 376, 378, 380, 383, 384, 626], "running_var": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "named_children": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "conv4": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "conv5": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "memo": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "named_paramet": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 326, 332, 337, 366, 376, 378, 380, 383, 384], "register_backward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "removablehandl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_full_backward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_buff": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "running_mean": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "alongsid": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 594, 615, 631], "num_featur": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_forward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "with_kwarg": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "always_cal": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_module_forward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "regardless": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 351, 365, 368, 376, 378, 380, 383, 384], "register_forward_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "And": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 629], "forward_pr": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_module_forward_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "rule": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 326, 332, 337, 345, 376, 378, 380, 383, 384, 624], "ordinarili": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "grad_input": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "grad_output": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "technic": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 623, 625, 626, 628], "register_module_full_backward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_full_backward_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "backward_pr": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_module_full_backward_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_load_state_dict_post_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "incompatible_kei": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_load_state_dict_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "local_metadata": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "error_msg": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "noqa": [88, 120, 123, 126, 130, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 644], "b950": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_modul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_paramet": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_state_dict_post_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_state_dict_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "requires_grad_": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 626], "autograd": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384], "freez": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 376, 378, 380, 383, 384], "finetun": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "gan": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "set_submodul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "share_memori": [88, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 622], "share_memory_": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 643], "averag": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 279, 280, 312, 326, 332, 337, 352, 360, 361, 371, 376, 378, 380, 383, 384, 413, 594, 622, 624], "shallow": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384, 625], "detach": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 352, 363, 366, 371, 372, 376, 378, 380, 383, 384, 386, 387, 388, 389, 622], "memory_format": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "channels_last": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "pin": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "4d": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "ignore_w": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "1913": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "3420": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "5113": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "2325": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "torch_doctest_cuda1": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "gpu1": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "1914": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "5112": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "2324": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "float16": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "cdoubl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "3741": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "2382": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "5593": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "4443": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "complex128": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "6122": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "1150": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384, 622], "to_empti": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "transform_done_spec": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 230, 243, 262, 269, 271, 273, 383], "transform_env_batch_s": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 271, 383], "transform_env_devic": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 230, 271, 383], "transform_full_done_spec": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 273, 280, 383], "dst_type": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "xpu": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "set_to_non": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "template_nam": 89, "inverse_pars": 89, "model_family_keyword": 89, "llama": 89, "mistral": 89, "histori": [89, 170, 171, 172, 174, 175, 178, 183, 184, 186, 189, 190, 193, 195, 196, 197, 325, 326, 329, 330, 331, 332, 337, 384, 594, 634], "jinja2": 89, "pars": [89, 174, 186, 198, 200, 203, 330, 331, 594, 596, 634, 641], "parser": [89, 135, 174, 186, 187, 197, 203, 563, 566, 594], "llama_templ": 89, "inst": 89, "elif": [89, 594, 622, 623, 634], "endgener": 89, "endif": 89, "endfor": 89, "parse_llama_text": 89, "findal": 89, "dotal": 89, "user_cont": 89, "assistant_cont": 89, "strip": [89, 623], "hf": 89, "hello": [89, 170, 195, 196, 324, 332, 333, 337, 384, 402, 615], "hi": [89, 332, 337], "Or": [89, 156, 157], "compression_fn": 90, "decompression_fn": 90, "compression_level": 90, "decompress": 90, "sensori": 90, "zstd": 90, "verifi": [90, 171, 368], "attach": [90, 95, 96, 97, 98, 110, 112, 116, 623], "entiti": [90, 95, 96, 97, 98, 110, 112, 116], "to_bytestream": 90, "data_to_bytestream": 90, "compact": [92, 93, 100], "shift": [92, 93, 100, 386, 387, 388, 389, 624], "checkpoint_fil": 93, "h5_kwarg": 93, "iff": 93, "suffix": [93, 410], "h5py": 93, "create_dataset": 93, "increas": [93, 221, 266, 312, 351, 368, 380, 384, 637, 638], "immut": [94, 120, 123, 126, 130, 138, 150, 154, 158, 159, 170, 171, 172, 175, 178, 179, 180, 253, 272], "scratch_dir": [95, 622, 623, 625, 630, 637, 640, 641], "shared_init": [95, 97, 427, 429], "auto_cleanup": 95, "mistak": [95, 97, 116], "overewritten": 95, "cleanup": [95, 192, 324, 337, 571, 573, 574, 576, 581, 583, 589, 592], "exit": 95, "ctrl": 95, "sigterm": 95, "temp": [95, 615], "main_ckpt_dir": 95, "rb_memmap": 95, "10_000_000": 95, "myclass": [95, 97, 116], "clean": [95, 184, 324, 329, 403, 568, 570, 571, 573, 574, 576, 578, 581, 583, 589, 594, 615], "lazystacktensordict": 96, "heterougen": 96, "linearli": 96, "densifi": 96, "unlimit": [96, 98], "st": 96, "consolid": 97, "cleanup_memmap": 97, "expans": [97, 366, 376, 378, 380, 384], "ram": [97, 129, 131, 631, 641], "zero_": [97, 116, 206], "liststoag": 99, "max_priority_within_buff": [101, 102], "proport": [101, 641], "magnitud": [101, 102, 622, 637], "tempor": [101, 302, 304, 387, 388], "focus": [101, 102, 615, 622, 629], "p_i": [101, 102], "delta_i": [101, 102], "epsilon": [101, 102, 246, 286, 301, 312, 413, 623, 624, 625, 628], "frac": [101, 102, 624], "sum_j": [101, 102], "p_j": [101, 102], "w_i": [101, 102], "cdot": [101, 102, 384], "aggress": [101, 102, 384], "bias": [101, 102, 622], "toward": [101, 102, 277], "unbias": [101, 102], "anneal": [101, 102, 312, 623, 628, 637], "guidelin": [101, 102], "math": [101, 102, 190], "data_0": 101, "data_1": 101, "smoothen": 101, "tdrb": 101, "pack": [101, 332, 624, 627, 644], "nd": [101, 102], "sum_tre": [101, 102], "min_tre": [101, 102], "end_kei": [102, 108, 109, 436, 437, 625], "traj_kei": [102, 108, 109, 436, 437, 641], "cache_valu": [102, 108, 109, 436, 437, 625], "truncated_kei": [102, 108, 109, 255, 263, 436, 437, 524], "closer": [102, 643], "commonli": [102, 108, 109, 644], "readili": [102, 108, 109, 345], "conjunct": [102, 108, 109, 623], "buffer0": [102, 108], "immutablewrit": [102, 108], "buffer1": [102, 108], "other_sampl": [102, 108], "short": [102, 108, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 332, 623, 624, 627, 628, 638, 641], "tolist": [102, 594], "120110917137936e": 102, "06": [102, 295, 319, 542, 552, 622, 623, 624, 637], "roundrobin": [104, 115], "consum": [107, 109, 341, 623, 624, 630, 638, 641], "incomplet": [107, 109, 183], "fresh": [107, 185, 570, 578], "haven": [107, 640], "remain": [107, 183, 191, 220, 230, 231, 241, 243, 264, 326, 332, 337, 594, 615, 629], "draw": [107, 301], "use_gpu": [108, 109, 436, 437], "acceler": [108, 109, 130, 180, 637, 638], "ep_1": [108, 109], "ep_2": [108, 109], "73": [108, 623, 637], "74": [108, 623], "76": [108, 622, 623, 639], "77": [108, 623, 639], "41": [108, 622, 623], "42": [108, 305, 349, 350, 352, 353, 357, 364, 371, 622, 623, 639], "43": [108, 623], "44": [108, 623], "45": [108, 623, 639], "67": [108, 623, 636], "68": [108, 623, 639], "69": [108, 623], "70": [108, 623, 624, 637], "71": [108, 623], "80": [108, 121, 122, 622, 623, 624, 637, 638], "82": [108, 622, 623, 639], "83": [108, 623], "78": [108, 622, 623, 639], "79": [108, 622, 623], "320": [108, 109, 124, 125, 623, 644], "550": [108, 109], "700": [108, 109], "robosetexperiencereplai": [108, 109], "dataid": [108, 109], "counter": [109, 191, 226, 270, 341, 408, 626], "request": [109, 201, 218, 251, 324, 330, 567, 615], "51": [109, 623], "__len__": 110, "rank_kei": 114, "flat": [114, 386], "get_insert_index": 114, "themselv": [120, 623], "maybe_dens": 120, "maker": [120, 566, 623], "min_get": [120, 154, 159], "sort": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 222, 312], "another_act": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "discretebox": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "mutabl": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "action_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 624, 638], "had": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 628, 630], "all_act": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "any_don": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "_callabletransform": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180], "auto_specs_": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "observation_kei": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "action_spac": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 233, 297, 298, 313, 314, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 625, 626, 628, 632], "discrep": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 349, 351, 353, 354, 365, 368, 370], "broken": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180], "check_dtyp": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180], "rng": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 639], "revert": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 326, 332, 337, 376, 378, 380, 384, 628, 641], "accomplish": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 627, 634], "done_keys_group": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "another_don": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "done_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "empty_cach": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 194, 272], "env_batch_s": [120, 154, 159], "fake_tensordict": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 623, 626], "recip": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 338, 341, 348, 570], "afterward": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 338, 341, 348, 637, 644], "envnam": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "full_action_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 637, 638], "full_done_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "full_observation_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "full_reward_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "pipeline_st": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "full_state_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "input_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "is_spec_lock": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "maybe_reset": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "speak": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 227, 345, 622], "observation_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "output_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "register_gym": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 627], "entry_point": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "info_kei": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "reward_threshold": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "nondeterminist": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "max_episode_step": [120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "order_enforc": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "autoreset": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "disable_env_check": [120, 123, 126, 129, 130, 138, 145, 146, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 448, 452], "apply_api_compat": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "nasium": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 209], "dmcontrolenv": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 393, 446, 622, 627, 636, 644], "dmc": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "cheetah": [120, 123, 124, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 393, 622, 644], "removeemptyspec": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 513], "threshold": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 301, 350, 351, 378, 380, 594, 624], "learnt": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 562], "checker": [120, 123, 126, 129, 130, 138, 145, 146, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "stepapicompat": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "deem": [120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180], "task_nam": [120, 123, 124, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 446], "envgym": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0855": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0215": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0881": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0412": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "1101": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0080": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0254": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0424": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "9609e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "02": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 280, 622, 623, 624, 632, 637], "9776e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "04": [120, 123, 126, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 267, 280, 622, 623, 624, 638], "6347e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "03": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 246, 267, 622, 623, 624, 637, 638], "3842e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5338e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "3064e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0381e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "6656e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "05": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 267, 368, 622, 623, 624, 637, 638, 639], "0204e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0833": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0275": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0612": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0770": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "1256": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0082": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0186": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0476": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "2221": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "2256": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5930": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "6937": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5865": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5479": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0187": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "6825": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5224": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0018": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "1005": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0335": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 227], "0268": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0133": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0627": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0074": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0488": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 639], "0353": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0075": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0069": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0098": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0058": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0033": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0157": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0004": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 267], "0381": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0452": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "11355747": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "04257728": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "00408397": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "04155852": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0389733": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "01409826": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0978704": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "08808327": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "03970837": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "00535434": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "02353762": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "05116226": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "02788907": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "06848346": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "05154399": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0371798": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "05128025": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "selecttransform": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 520], "dydact": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "ant": [120, 121, 122, 123, 126, 130, 133, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 640], "gym_env": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 643], "reset_kei": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 258, 264, 265, 266, 525, 637], "multitask": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "multiag": [120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 351, 365, 368], "another_reward": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "reward_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "auto_cast_to_devic": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 638], "soon": [120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "__sort": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "as__": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "categorical_action_encod": [120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 209, 226, 445, 448, 452, 626], "argmaxmodul": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "argmax": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 298, 314, 626, 628], "n_ob": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 241, 341, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 629], "n_act": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 241, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 629], "ourselv": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 624, 644], "emul": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "input_td": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "rollout_td": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "state_kei": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "state_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "prevail": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 222, 258, 326], "newli": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "next_tensordict": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 218, 222, 234, 235, 236, 249, 252, 253, 259, 262, 275, 279, 594], "precomput": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "_stepmdp": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212], "exclude_act": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212], "retain": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "next_data": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "reset_data": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 190, 594, 644], "2106": [121, 122, 355, 372], "13281": [121, 122], "cache_clear_frequ": [121, 122, 445], "leak": [121, 122, 324], "frame_skip": [121, 122, 124, 125, 129, 130, 131, 132, 136, 137, 139, 140, 145, 146, 155, 180, 237, 408, 410, 420, 421, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 475, 499, 555, 622, 623, 624, 643], "allow_done_after_reset": [121, 122, 124, 125, 126, 129, 131, 132, 135, 136, 137, 145, 146, 148, 149, 155, 161, 162, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461], "toler": [121, 122, 124, 125, 129, 131, 132, 135, 136, 137, 145, 146, 148, 149, 155, 161, 162, 194, 295, 319, 324], "is_avail": [121, 122, 622, 623, 624, 625, 637, 638, 640], "els": [121, 122, 185, 218, 308, 615, 622, 623, 624, 625, 634, 635, 637, 638, 639, 640], "87": [121, 122, 623, 639], "acrobot": [121, 122, 124, 125, 644], "advant": [121, 122, 136, 137], "timer": [121, 122, 130, 136, 137, 180, 528], "timeit": [121, 122, 136, 137, 626], "310": [121, 122], "00": [121, 122, 217, 621, 622, 623, 624, 625, 637, 638, 639, 642], "ms": [121, 122, 136, 137], "268": [121, 122], "433": [121, 122], "213": [121, 122], "8605": [121, 122], "pipelineenv": 122, "get_environ": 122, "san": 123, "fen": [123, 148, 149], "pgn": 123, "legal": [123, 215], "board": [123, 160], "include_san": 123, "algebra": [123, 639], "notat": 123, "include_fen": 123, "forsyth": 123, "edward": 123, "include_pgn": 123, "portabl": [123, 615, 631], "include_legal_mov": 123, "include_hash": 123, "hash": [123, 138, 179, 501], "mask_act": 123, "subset": [123, 639, 640], "29275": 123, "rnbqkbnr": [123, 148, 149], "pppppppp": [123, 148, 149], "kqkq": [123, 148, 149], "legal_mov": 123, "219": 123, "5p2": 123, "ppppp1pp": 123, "event": [123, 306, 310, 317, 641], "white": 123, "96": [123, 622, 623, 638], "kq": 123, "5n2": 123, "rnbqkb1r": 123, "nf3": 123, "na6": 123, "c4": 123, "f6": 123, "h4": 123, "rb8": 123, "na3": 123, "ra": 123, "get_legal_mov": 123, "dm_control": [124, 125, 446, 622, 636, 644], "2006": [124, 125, 226, 350, 356], "12983": [124, 125], "240": [124, 125, 643, 644], "swingup": [124, 125, 644], "swingup_spars": [124, 125, 644], "ball_in_cup": [124, 125, 644], "catch": [124, 125, 626, 644], "balance_spars": [124, 125, 644], "three_pol": [124, 125, 644], "two_pol": [124, 125, 644], "finger": [124, 125, 644], "turn_easi": [124, 125, 644], "turn_hard": [124, 125, 644], "fish": [124, 125, 644], "upright": [124, 125, 623, 644], "swim": [124, 125, 644], "hopper": [124, 125, 644], "hop": [124, 125, 644], "humanoid": [124, 125, 150, 158, 636, 644], "walk": [124, 125, 150, 158, 623, 636, 644], "run_pure_st": [124, 125, 644], "bring_bal": [124, 125, 644], "bring_peg": [124, 125, 644], "insert_bal": [124, 125, 644], "insert_peg": [124, 125, 644], "point_mass": [124, 125, 644], "reacher": [124, 125, 644], "swimmer": [124, 125, 644], "swimmer6": [124, 125, 644], "swimmer15": [124, 125, 644], "walker": [124, 125, 644], "dog": [124, 125, 644], "trot": [124, 125, 644], "humanoid_cmu": [124, 125, 644], "lqr": [124, 125, 644], "lqr_2_1": [124, 125, 644], "lqr_6_2": [124, 125, 644], "quadrup": [124, 125, 644], "escap": [124, 125, 644], "stacker": [124, 125, 644], "stack_2": [124, 125, 626, 644], "stack_4": [124, 125, 626, 644], "deviceless": 126, "run_type_check": [126, 144], "hint": 126, "counterenv": 126, "creator": [127, 557, 558, 564, 565, 566], "substitut": [127, 264, 279, 628], "vecnorm": [127, 280, 539, 540, 566], "test_env1": 127, "observation_count": [127, 644], "test_env2": 127, "ps": 127, "p1": 127, "p2": 127, "9934": 127, "make_vari": [127, 270], "variant": [127, 270], "trajcount": [127, 531], "env_creator_pendulum": 127, "env_creator_cartpol": 127, "env_str": 128, "device_map": 128, "asyncvectorenv": 129, "pixel_observ": [129, 131, 132, 155], "pixelobservationwrapp": [129, 131, 132, 155], "adventur": [129, 131, 644], "airraid": [129, 131, 644], "alien": [129, 131, 644], "time_limit": 129, "timelimit": [129, 142, 143, 163, 164], "default_info_dict_read": [129, 130, 131, 150, 180], "reader": [129, 130, 131, 150, 180, 623], "set_info_dict_read": [129, 130, 131, 150, 180, 627], "info_dict": [129, 130, 131, 150, 180], "gymlikeenv": [129, 131, 180], "auto_register_info_dict": [129, 130, 131, 150, 180], "multibinari": [129, 131], "multidiscret": [129, 131], "rag": [129, 131], "gym_conversion_exampl": [129, 131], "info_dict_read": [130, 150, 180], "ignore_priv": [130, 180], "baseinfodictread": [130, 180], "tensordictprim": [130, 150, 180, 287, 302, 304, 526, 625], "succe": [130, 150, 180, 589], "underscor": [130, 180], "primer": [130, 170, 171, 172, 175, 178, 180, 185, 194, 265, 287, 302, 304, 317, 625], "halfcheetah": [130, 150, 180, 214, 254, 622, 643], "reward_run": [130, 150, 180], "raise_if_clos": [130, 180], "fast_encod": [130, 180], "memoize_cach": [130, 180], "adaptive_autorang": [130, 180], "4f": [130, 180, 384, 624, 625, 639], "fp": [130, 180, 393, 398, 400, 401], "10141": [130, 180], "5742fp": [130, 180], "10576": [130, 180], "8388fp": [130, 180], "read_act": [130, 180], "read_don": [130, 180], "nonsens": [130, 180], "fallback": [130, 180, 324], "read_ob": [130, 180], "dictat": [130, 180, 242, 342, 345, 368, 622, 639], "read_reward": [130, 180], "gym_lik": [130, 180], "hoc": [130, 150, 180, 628], "dict_read": [130, 180], "my_info_kei": [130, 180], "some_env": [130, 180], "vecenv": 131, "vectorenv": 131, "convert_actions_to_numpi": [131, 448, 452], "missing_obs_valu": [131, 278, 448, 452], "vecgymenvtransform": [131, 538], "secur": [132, 634], "habitat3": 132, "ai": [132, 640], "habitatrenderpick": 132, "isaacgym": [133, 134, 450], "isaacgymwrapp": 133, "isaacgymenv": [134, 450], "webpag": 134, "isaac": [134, 135], "essenc": [134, 627], "scripts_isaaclab": 135, "managerbasedrlenv": 135, "app": 135, "applaunch": 135, "argpars": [135, 563, 566], "argumentpars": 135, "add_app_launcher_arg": 135, "args_cli": 135, "hydra_arg": 135, "parse_known_arg": 135, "app_launch": 135, "isaaclab_task": 135, "f401": [135, 644], "manager_bas": 135, "ant_env_cfg": 135, "antenvcfg": 135, "isaac_lab": 135, "cfg": [135, 466, 467, 470, 471, 472, 555, 556, 557, 558, 559, 560, 561, 562, 563, 566], "instadeepai": [136, 137], "2306": [136, 137, 280], "09884": [136, 137], "snake": [136, 137, 172], "grid": [136, 137, 393], "bodi": [136, 137], "body_st": [136, 137], "fruit_posit": [136, 137], "col": [136, 137], "row": [136, 137, 242], "head_posit": [136, 137], "tail": [136, 137], "game2048": [136, 137], "maze": [136, 137], "cleaner": [136, 137, 594, 635], "cvrp": [136, 137], "multicvrp": [136, 137], "minesweep": [136, 137], "rubikscub": [136, 137], "knapsack": [136, 137], "sudoku": [136, 137], "tsp": [136, 137], "connector": [136, 137], "mmst": [136, 137], "graphcolor": [136, 137], "partli": [136, 137], "scrambl": [136, 137], "robotwarehous": [136, 137], "tetri": [136, 137], "binpack": [136, 137], "jobshop": [136, 137], "0x1fca91910": 136, "122": [136, 137, 644], "40": [136, 137, 622, 623, 624, 637, 638], "0x1ff9baee0": 136, "134": [136, 137, 626], "0x1ff9ba7c0": 136, "172": [136, 137], "eager": [137, 334], "tdreset": [137, 636], "whichev": 137, "mctsforest": [138, 179], "vocab_s": [138, 178, 179, 530, 615], "vocabulari": [138, 178, 179, 199, 269], "omit": [138, 179, 185, 286, 301, 312, 411, 624, 629, 639, 641], "hashing_modul": [138, 179], "siphash": [138, 179], "text_output": [138, 179], "batch_decod": [138, 179], "text_kei": [138, 179, 326, 329, 332, 337], "gpt2token": [138, 179], "input_id": [138, 178, 179], "make_tensordict": [138, 179], "mo": [139, 140], "minecart": [139, 140], "mo_gym": [140, 242], "marl": [141, 166, 221, 262, 266, 358, 371, 627, 637, 638], "group_map": [141, 142, 143, 148, 149, 152, 153, 161, 162, 163, 164, 166, 637], "constructiuon": [141, 152, 153], "premad": [141, 142, 143, 152, 153, 163, 164], "all_in_one_group": [141, 148, 149, 166], "agent_0": [141, 152, 153, 161, 166, 262, 637], "agent_1": [141, 152, 153, 161, 166, 262], "agent_2": [141, 152, 153, 161, 166], "agent_3": [141, 161], "one_group_per_ag": [141, 152, 153], "meltingpot": [142, 143, 453], "2211": [142, 143], "13746": [142, 143], "melt": [142, 143], "pot": [142, 143], "novel": [142, 143, 629], "social": [142, 143], "situat": [142, 143, 178, 185], "familiar": [142, 143, 623, 634, 638, 644], "unfamiliar": [142, 143], "broad": [142, 143], "cooper": [142, 143, 637, 638], "decept": [142, 143], "reciproc": [142, 143], "stubborn": [142, 143], "substrat": [142, 143], "ml_collect": 142, "config_dict": 142, "configdict": 142, "horizon": [142, 143, 163, 164, 208, 624], "infinit": [142, 143, 163, 164, 171, 172, 175, 185, 280, 630, 641], "categorical_act": [142, 143, 148, 149, 152, 153, 156, 157, 161, 162, 163, 164], "agent_nam": [142, 143, 163, 164, 166], "agent_names_to_indices_map": [142, 143, 163, 164], "env_torchrl": [142, 143], "commons_harvest__open": [142, 143], "rgb": [142, 143], "144": [142, 143, 190], "collective_reward": [142, 143], "ready_to_shoot": [142, 143], "88": [142, 143, 156, 157, 622, 623], "substrate_config": 143, "get_config": 143, "mp_env": 143, "build_from_config": 143, "default_player_rol": 143, "mymbenv": 144, "world_model": [144, 361], "hidden_observ": 144, "worldmodelwrapp": [144, 601], "activation_class": [144, 288, 290, 291, 292, 293, 299, 300, 305, 466, 467, 623, 628, 637, 638, 643], "relu": [144, 294, 307, 326, 332, 337, 601, 626], "activate_last_lay": [144, 293, 305, 467], "sail": [145, 146], "sg": [145, 146], "10558": [145, 146], "readthedoc": [145, 148, 149], "en": [145, 148, 149], "python_interfac": 145, "envpoolmixin": 146, "env_bas": 146, "task_id": 146, "env_typ": 146, "gym_reset_return_info": 146, "envpool_env": 146, "www": [147, 306], "fetch_openml": 147, "dataset_nam": 147, "106": 147, "openspiel": [148, 149, 456], "open_spiel": [148, 149], "game_str": 148, "return_st": [148, 149, 152, 153], "4672": [148, 149, 623], "current_play": [148, 149], "674": 148, "2048": [148, 149, 623, 640], "add_nois": [148, 149], "amazon": [148, 149], "backgammon": [148, 149, 644], "restor": [148, 149, 594, 616], "td_restor": [148, 149], "pyspiel": 149, "load_gam": 149, "new_initial_st": 149, "3009": 149, "my_env_fun": [150, 158], "custom_attribute_list": [150, 158], "custom_attribut": [150, 158], "custom_method_list": [150, 158], "custom_method": [150, 158], "deploi": [150, 158, 218, 626], "share_individual_td": [150, 158], "shared_memori": [150, 158], "policy_proof": [150, 158], "ll": [150, 158, 226, 622, 623, 624, 625, 627, 628, 629, 630, 632, 634, 638, 644], "serial_for_singl": [150, 158, 623], "circular": [150, 158, 622], "daemon": [150, 158], "auto_wrap_env": [150, 158], "list_of_kwarg": [150, 158], "sharabl": [150, 158], "com_veloc": [150, 158], "head_height": [150, 158], "joint_angl": [150, 158], "torso_vert": [150, 158], "batched_pipe_timeout": 150, "stringent": [150, 624, 637, 638], "penv": [150, 270], "env_fix": 150, "influenc": 150, "thumb": [150, 624], "update_kwarg": [150, 158], "th": [151, 236, 274, 639], "thdot": [151, 639], "max_spe": [151, 639], "max_torqu": [151, 639], "dt": [151, 312, 639], "gen_param": [151, 639], "gravit": [151, 639], "torqu": [151, 639], "pettingzoo": [152, 153, 457, 637, 638], "pet": [152, 153], "zoo": [152, 153], "__": [152, 153], "aecenv": [152, 153], "dead": [152, 153], "done_on_ani": [152, 153, 637], "compulsori": [152, 153], "adversary_0": [152, 153, 637], "adversari": [152, 153, 363, 637], "sisl": 152, "multiwalker_v9": 152, "aec": [152, 153], "n_piston": [152, 153], "pistonball_v6": [152, 153], "piston": [152, 153], "piston_0": [152, 153], "piston_1": [152, 153], "piston_20": [152, 153], "tictactoe_v3": [152, 153], "player": [152, 153, 160], "player_1": [152, 153], "player_2": [152, 153], "butterfli": 153, "_setup": [154, 159], "async_reset_send": [154, 159], "async_reset_recv": [154, 159], "vikashplu": 155, "wiki": 155, "06828": 155, "from_depth": 155, "smacv2": [156, 157, 459], "starcraft": [156, 157], "challeng": [156, 157, 627, 639, 640], "10gen_terran": [156, 157], "10gen_zerg": [156, 157], "10gen_protoss": [156, 157], "3m": [156, 157], "8m": [156, 157], "25m": [156, 157], "5m_vs_6m": [156, 157], "8m_vs_9m": [156, 157], "10m_vs_11m": [156, 157], "27m_vs_30m": [156, 157], "mmm": [156, 157], "mmm2": [156, 157], "2s3z": [156, 157], "3s5z": [156, 157], "3s5z_vs_3s6z": [156, 157], "3s_vs_3z": [156, 157], "3s_vs_4z": [156, 157], "3s_vs_5z": [156, 157], "1c3s5z": [156, 157], "2m_vs_1z": [156, 157], "corridor": [156, 157], "6h_vs_8z": [156, 157], "2s_vs_1sc": [156, 157], "so_many_banel": [156, 157], "bane_vs_ban": [156, 157], "2c_vs_64zg": [156, 157], "old": [156, 157, 272, 280, 365, 644], "smac": [156, 157], "map_nam": [156, 157], "176": [156, 157], "battle_won": [156, 157], "dead_al": [156, 157], "dead_enemi": [156, 157], "episode_limit": [156, 157], "322": [156, 157, 183], "procedur": [156, 157, 324], "distribution_config": [156, 157], "n_unit": [156, 157], "n_enemi": [156, 157], "team_gen": [156, 157], "dist_typ": [156, 157], "weighted_team": [156, 157], "unit_typ": [156, 157], "marin": [156, 157], "maraud": [156, 157], "medivac": [156, 157], "exception_unit_typ": [156, 157], "start_posit": [156, 157], "surrounded_and_reflect": [156, 157], "map_x": [156, 157], "map_i": [156, 157], "capability_config": [156, 157], "131": [156, 157], "starcraft2env": 157, "tic": 160, "tac": 160, "toe": 160, "single_play": 160, "player1": 160, "desired_batch_s": 160, "player0": 160, "uniti": [161, 162], "technolog": [161, 162], "llapi": [161, 162], "mlagents_env": [161, 162], "unityenviron": [161, 162], "file_nam": 161, "registered_nam": 161, "3dball": 161, "group_0": 161, "vectorsensor_size8": 161, "continuous_act": [161, 163, 164, 391, 637, 638], "agent_10": 161, "agent_11": 161, "agent_4": 161, "agent_5": 161, "agent_6": 161, "agent_7": 161, "agent_8": 161, "agent_9": 161, "group_reward": 161, "proroklab": [163, 164], "vectorizedmultiagentsimul": [163, 164], "2207": [163, 164], "03530": [163, 164], "basescenario": 163, "defaultt": 163, "sparsiti": 163, "unbatched_action_spec": [163, 164], "unbatched_observation_spec": [163, 164], "unbatched_reward_spec": [163, 164], "het_spec": [163, 164], "het_specs_map": [163, 164], "flock": [163, 164, 391], "agent_collision_rew": [163, 164], "agent_distance_rew": [163, 164], "ca": 166, "environment4": 166, "get_group_map": 166, "probabilist": [167, 241, 342, 349, 368, 601, 624, 643], "sumbodul": 169, "blank": [170, 594], "canva": [170, 594], "fundament": [170, 594, 630], "intention": [170, 594], "data_kei": [170, 171, 172, 175, 178, 194], "dialogu": 170, "klrewardtransform": [170, 188, 195, 196, 503, 594], "kl": [170, 188, 189, 195, 196, 241, 361, 365, 376, 380, 384, 594], "diverg": [170, 188, 189, 195, 196, 241, 342, 345, 361, 365, 380, 384, 594], "pythoninterpret": [170, 192, 594, 615], "dataloadingprim": [170, 171, 178, 194, 265, 594], "addthinkingprompt": [170, 594], "input_mod": [170, 171, 172, 174, 175, 195, 196, 326, 329, 332, 337, 594, 635], "system_prompt": [170, 171, 172, 175, 193, 594, 615, 634], "template_kwarg": [170, 171, 172, 175], "system_rol": [170, 594], "user_rol": [170, 594], "policy_rol": 170, "response_kei": 170, "datasetchatenv": 170, "gsm8kenv": [170, 171, 174, 181, 183, 594], "ifevalenv": [170, 171, 594], "response_data": 170, "next_ob": [170, 246, 386, 387, 388, 389, 643], "mont": [170, 171, 172, 175, 178, 185, 349, 351, 365, 368, 380, 383, 622], "carlo": [170, 171, 172, 175, 178, 185, 349, 351, 365, 368, 380, 383, 622], "pull": [171, 641], "rlhf": [171, 241, 380], "feedback": [171, 420, 594, 632, 643], "rlvr": 171, "batch_size_dl": [171, 172, 175, 181], "apply_templ": [171, 172, 175, 193, 634], "ray_backend": [171, 172, 175], "dataloader_actor_nam": [171, 172, 175], "thin": [171, 180], "chatenv": [171, 172, 175, 180, 186, 190, 193, 197, 592, 615, 634], "reset_dataload": [171, 172, 175, 185, 194], "set_missing_toler": [171, 172, 175, 194, 272], "gsm8k": [172, 173, 181, 594], "compute_reward": [172, 175], "gsm8k_dataload": 172, "3b": [172, 175, 183, 193, 324, 333, 334, 337], "question": [172, 175, 634, 641, 643], "bought": 172, "sandwich": 172, "he": 172, "paid": 172, "calcul": [172, 190, 197, 255, 349, 351, 356, 365, 368, 370, 372, 380, 386, 418], "breed": 172, "36": [172, 623], "mari": 172, "saw": [172, 631, 639, 641], "reward_answ": [172, 174, 594], "reward_contain": [172, 174, 594], "reward_right": [172, 174, 594], "reward_think": [172, 174, 594], "snak": 172, "set_done_if_answ": [174, 177, 594], "make_gsm8k_env": 174, "sentenc": 174, "extract_tag": [174, 594], "xml": [174, 197, 203, 594], "ifev": [175, 177, 594], "ifeval_dataload": 175, "pprint": [175, 594], "instruction_id_list": [175, 177], "detectable_cont": 175, "number_placehold": 175, "num_highlight": 175, "num_": 175, "respond": 175, "plan": [175, 615], "week": 175, "europ": 175, "trip": 175, "london": 175, "rome": 175, "cap": [175, 624, 641], "restaur": 175, "prompt_level_strict_acc": [176, 177], "inst_level_strict_acc": [176, 177], "prompt_level_loose_acc": [176, 177], "inst_level_loose_acc": [176, 177], "instruction_ids_kei": 177, "keyword_args_kei": 177, "id_kei": 177, "response_column": 177, "score_kei": 177, "ifeval_scor": 177, "aggregate_reward": 177, "_scorer": 177, "ifevalscoredata": [177, 594], "format_weight": 177, "scorer": 177, "IF": 177, "co": [177, 233, 324, 639], "column": 177, "builder": [177, 181, 616, 623, 644], "think_block": 177, "answer_block": [177, 594], "langdetect": 177, "nltk": 177, "immutabledict": 177, "default_reward_aggreg": [177, 594], "tier": 177, "eo": [177, 337], "metric": [177, 351, 368, 380, 403, 409, 416, 418, 420, 421, 475, 622], "multipli": [177, 178, 185, 349, 350, 351, 352, 358, 365, 367, 368, 369, 371, 380, 413, 622, 637], "penalti": [177, 182, 188, 326, 332, 337, 363, 365, 376], "formula": [177, 241, 303, 320, 321, 349, 351, 365, 368, 380, 624], "format_scor": [177, 594], "quality_bonu": 177, "structure_multipli": 177, "complexity_scal": 177, "everyth": [177, 623, 624, 625, 631, 632], "incent": 177, "languag": [178, 594, 635], "tailor": [178, 643], "cot": [178, 594], "token_kei": 178, "str_kei": 178, "attention_kei": 178, "assign_reward": 178, "has_attent": 178, "assign_don": 178, "batchless": 178, "eos_token_id": [178, 332, 635], "pretrainedtokenizerbas": [178, 199, 269], "stack_method": [178, 185, 194], "as_nested_tensor": [178, 185, 326, 332, 337], "bert": [178, 199, 269], "uncas": [178, 199, 269], "tokens_in": 178, "tokens_out": 178, "grpo": [178, 185, 376, 378, 380], "mlgym": [180, 182, 594], "get_library_nam": 180, "prisonersdilemma": 182, "reward_wrong_format": 182, "mlgymenv": [182, 594], "wrongli": 182, "cond": [183, 226, 227, 489, 626], "random_prompt": 183, "edit_last_turn": 183, "zero_reward": 183, "undo_don": 183, "egocentr": 183, "reconsid": 183, "But": [183, 615, 636], "me": [183, 187, 190, 634], "wrong_answ": 183, "natalia": 183, "sold": 183, "48": [183, 622, 623, 639], "friend": 183, "april": 183, "she": [183, 641], "72": [183, 622, 623], "altogeth": [183, 227], "undon": 183, "correct_answ": 183, "allowed_domain": [184, 634], "tool_nam": [184, 190, 193, 197, 203], "web": [184, 626, 634], "brows": [184, 634], "browser": [184, 190, 634], "click": [184, 634], "llm_tool": 184, "use_ray_servic": [185, 189, 195, 243], "mappabl": 185, "dataloader_factori": [185, 194], "unrel": 185, "dl": 185, "raydataloadingprim": 185, "endless_dataload": [185, 194], "set_capture_non_tensor_stack": 185, "dummydataload": 185, "generate_random_str": 185, "ascii_lowercas": 185, "__next__": 185, "zxwvupirska": 185, "stringa": 185, "zxwvupirsk": 185, "roll": 185, "init_st": 185, "nngcmflsana": 185, "vrrbnhzpmga": 185, "nngcmflsan": 185, "vrrb": 185, "dummytensordataload": 185, "max_length": [185, 199, 269, 626, 632], "generate_random_tensor": 185, "pad_tensor": 185, "padding_length": 185, "data_spec": 185, "toolregistri": 186, "llmtoolpars": [186, 197], "stop_on_error": 186, "pass_state_to_tool": 186, "pluggabl": 186, "xmlblockpars": [186, 197], "websearch": 186, "schema_in": [186, 201, 202], "schema_out": [186, 201, 202], "titl": [186, 624, 625, 626, 638, 639], "gen_log_probs_full_kei": [188, 195], "log_prob": [188, 195, 295, 306, 310, 321, 326, 329, 332, 337, 345, 352, 358, 371, 376, 378, 380, 384, 635], "ref_log_probs_full_kei": [188, 195], "ref_log_prob": [188, 195, 196, 376, 378, 380, 384], "kl_kei": [188, 195], "kl_penalti": [188, 195], "add_to_reward": [188, 195], "coeff": [188, 195, 351, 365, 368], "padding_sid": [188, 189, 195, 196, 306, 326, 332, 337], "retrievelogprob": [188, 189, 195, 384], "retrievekl": [188, 189, 196], "pad_output": [188, 195, 196, 326, 329, 332, 337, 635], "gen_log_prob": [188, 195], "pad_sequ": [188, 189, 195, 196], "next_td": [188, 195], "kl_transform": 188, "gen_log_probs_kei": 188, "ref_log_probs_kei": 188, "coef": [188, 241], "chathistori": [189, 195, 196, 330, 331, 332, 337, 635], "ref_model": [189, 195, 196], "llmwrapperbas": [189, 195, 196, 332, 337, 380], "ref_model_factori": [189, 195], "assistant_onli": [189, 195, 196, 384], "upcom": [189, 195, 366, 376, 378, 380, 384, 622], "actor_nam": [189, 194, 195, 243, 329], "gen_model": [189, 195], "klcomput": [189, 195, 196], "tool_call_pattern": [190, 197], "mcp": 190, "npx": 190, "uvx": 190, "browsermcp": 190, "regex": [190, 197, 594], "tool_name_with_serv": 190, "args_json": [190, 197], "os": [190, 623, 635], "deno": 190, "deno_path": 190, "expandus": 190, "stdio": 190, "sqrt": [190, 312], "pi": [190, 626, 637, 638, 639], "run_python_cod": 190, "python_cod": 190, "linkedlist": [190, 635], "successfulli": [190, 193, 585, 594, 634, 635, 640], "textcont": 190, "nresult": 190, "141592653589793": 190, "return_valu": 190, "n15": 190, "annot": [190, 634], "curl": 190, "fssl": 190, "land": 190, "sh": 190, "version_typ": 191, "llmcollector": [191, 195, 326, 332, 337, 594], "tracker": [191, 240], "current_vers": 191, "uuid4": 191, "pool_siz": [192, 193, 615], "get_servic": [192, 193, 615], "python_executor": [192, 193, 615], "max_concurr": [192, 193, 329, 402, 615], "robin": [192, 324, 434, 615], "stdout": 192, "stderr": 192, "returncod": 192, "service_nam": [193, 404, 615], "namespac": [193, 402, 404, 563, 566, 592], "tooltransformbas": 193, "boilerpl": 193, "inject": 193, "nprint": 193, "pythonexecutorservic": [193, 594, 615], "reus": [194, 290, 401, 594], "create_dataload": 194, "primer1": 194, "primer2": 194, "travers": 194, "missing_toler": [194, 199, 269], "reset_par": [194, 271], "set_contain": [194, 271], "ahead": [195, 644], "from_collector": 195, "get_new_vers": [195, 326, 329, 332, 337], "gen_model_factori": 195, "consciou": [195, 196], "identif": [195, 196], "history_kei": [195, 332, 337], "tokenizer_kwarg": [195, 196, 326, 332, 337, 384], "assit": [195, 196, 384], "rayretrievekl": 195, "optconfig": [195, 196, 384], "optforcausallm": [195, 196, 384], "weather": [195, 196, 384], "facebook": [195, 196, 384], "opt": [195, 196, 384], "125m": [195, 196, 384], "return_log_prob": [195, 196, 241, 283, 284, 285, 332, 337, 342, 345, 347, 370, 384, 470, 624, 628, 635, 637, 638, 643], "log_probs_kei": [195, 196, 326, 329, 332, 337], "chat_histori": [195, 196, 332, 337, 635], "log_probs_full_kei": 196, "batchabl": 196, "tool_schema": 197, "mcptooltransform": [197, 594], "schema": [197, 202], "unknown": [197, 622], "use_raw_nontensor": [199, 239, 269, 273], "additional_token": [199, 269], "skip_special_token": [199, 269, 326, 331, 332, 337], "add_special_token": [199, 269], "return_attention_mask": [199, 269], "call_before_reset": [199, 269], "test_input_spec": [199, 273], "visibl": [200, 402, 403, 404, 592, 638], "label": [200, 622, 637, 641], "correl": [200, 312], "toolservic": 201, "addservic": 201, "optional_tag": 203, "nsome": 203, "list_of_tensordict": [204, 205], "unsqueeze_null_shap": 206, "dynamic_shap": 206, "model_bas": [207, 208], "dreamer": [207, 208, 299, 360, 361, 362], "model_based_env": [207, 360], "dreamerenv": [207, 360], "model_based_env_ev": 207, "imagin": [208, 323], "spec_typ": 209, "convert_specnam": 209, "remap_state_to_observ": 209, "spectyp": 209, "unus": 209, "probabilistictdmodul": [210, 305, 342, 345, 410], "keep_oth": [212, 639], "exclude_reward": 212, "exclude_don": 212, "next_": 212, "mdp": [212, 627, 639], "write_full_fals": 213, "_terminated_or_trunc": 213, "num_interv": [214, 477], "out_action_kei": [214, 477], "samplingstrategi": 214, "optino": 214, "intenum": 214, "action_disc": 214, "qualnam": [214, 318, 374], "boundari": [214, 318, 348, 374, 624, 626, 637, 638], "masker": 215, "finit": [215, 235, 628, 641], "maskedenv": 215, "ones_lik": [215, 303, 306, 320], "scatter": 215, "fill_float": [217, 479], "fill_int": [217, 479], "fill_bool": [217, 479], "someenvclass": 217, "autoresetenv": 217, "fooenv": 217, "sign": [217, 260, 386, 637], "envtyp": 217, "3633e": 217, "4877e": 217, "2849e": 217, "7584e": 217, "6609e": 217, "6166e": 217, "8366e": 217, "2761e": 217, "5685e": 217, "4102e": 217, "8111e": 217, "9959e": 217, "0865e": 217, "5644e": 217, "2119e": 217, "2542e": 217, "9952e": 217, "4059e": 217, "2094e": 217, "9009e": 217, "5140e": 217, "3554e": 217, "2920e": 217, "7893e": 217, "6429e": 217, "3057e": 217, "2867e": 217, "6963e": 217, "3818e": 217, "2576e": 217, "2679e": 217, "1640e": 217, "6972e": 217, "0212e": 217, "5959e": 217, "4637e": 217, "3121e": 217, "2168e": 217, "5232e": 217, "7704e": 217, "7457e": 217, "4127e": 217, "1064e": 217, "0854e": 217, "5712e": 217, "2189e": 217, "5235e": 217, "8289e": 217, "0009e": 217, "0257e": 217, "8893e": 217, "5872e": 217, "9405e": 217, "7766e": 217, "0403e": 217, "0626e": 217, "2959e": 217, "7263e": 217, "2775e": 217, "9564e": 217, "0411e": 217, "6769e": 217, "6354e": 217, "8698e": 217, "1765e": 217, "6292e": 217, "5375e": 217, "1820e": 217, "7023e": 217, "5836e": 217, "9016e": 217, "4826e": 217, "6191e": 217, "6387e": 217, "8667e": 217, "2056e": 217, "1147e": 217, "5991e": 217, "0278e": 217, "5219e": 217, "3067e": 217, "6617e": 217, "3322e": 217, "2629e": 217, "4599e": 217, "7298e": 217, "5848e": 217, "0148e": 217, "5745e": 217, "6982e": 217, "7877e": 217, "3527e": 217, "7285e": 217, "6668e": 217, "0583e": 217, "6956e": 217, "3962e": 217, "9845e": 217, "5015e": 217, "5903e": 217, "9993e": 217, "9418e": 217, "0196e": 217, "6557e": 217, "2109e": 217, "8997e": 217, "1507e": 217, "7363e": 217, "0310e": 217, "9574e": 217, "8980e": 217, "0090e": 217, "reshape_fn": [218, 480, 626], "reset_func": [218, 480], "tensordict_batch_s": 218, "tensordict_reset": [218, 639], "biner": 219, "burn_in": [220, 482], "burn": 220, "burnt": 220, "grumodul": [220, 265, 601, 625], "gru_modul": [220, 302], "input_s": [220, 265, 302, 304, 625, 626], "hidden_s": [220, 265, 302, 304, 625, 626], "default_recurrent_mod": [220, 302, 304], "burn_in_transform": 220, "gru": [220, 265, 302, 626], "num_lay": [220, 302, 304, 308, 309, 626], "86": [220, 622, 623], "3008": [220, 623], "37": [220, 622, 623, 624], "0344": 220, "padding_valu": [221, 306, 326, 332, 337], "as_invers": 221, "movement": [221, 368], "propos": [221, 233, 625, 641], "pdf": [221, 289, 290, 291, 292, 293, 298, 312, 352, 359, 363, 369, 372, 386], "1312": [221, 623], "5602": 221, "unsqueezetransform": [221, 534, 639, 641], "consumpt": 221, "pictur": 221, "pixels_trsf": [221, 641], "grayscal": [221, 500, 623, 625, 626, 641, 644], "data_exclud": [221, 641], "mitig": 221, "make_rb_transform_and_sampl": 221, "sampler_kwarg": 221, "redund": [221, 594, 625], "fly": [221, 279, 365, 594, 624, 639, 641, 644], "del_kei": [222, 262, 275, 636, 639], "unsqueeze_if_oor": 222, "observation_posit": 222, "observation_veloc": 222, "center": [223, 393, 551], "width": [223, 228, 254, 485, 490], "scalar": [224, 256, 286, 291, 293, 301, 312, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 386, 387, 388, 389, 409, 623, 629, 639], "rewardsc": [225, 272, 518, 622, 623, 625], "rewardclip": [225, 517], "transform_list": 225, "condition": 226, "switch": [226, 272, 280, 303, 321, 391, 615, 635], "unalt": 226, "criteria": [226, 332], "mod": [226, 241, 287, 302, 304, 326, 332, 337, 341, 345, 348, 376, 378, 380, 384, 625, 626, 632], "policy_switch": 226, "step_count_tot": 226, "step_count_main": 226, "0322": 226, "1540": 226, "0111": 226, "3190": 226, "0299": 226, "1544": 226, "0181": 226, "3280": 226, "0276": 226, "1550": [226, 626], "0255": 226, "3414": 226, "0253": 226, "1558": 226, "0334": 226, "3596": [226, 623], "0230": 226, "1569": 226, "0422": 226, "3828": 226, "0206": 226, "1582": 226, "0519": 226, "4117": 226, "1598": 226, "0629": 226, "4469": 226, "0156": 226, "1617": 226, "0753": 226, "4891": 226, "0130": 226, "1639": 226, "0895": 226, "5394": 226, "0104": 226, "1665": 226, "1058": 226, "5987": 226, "0076": 226, "1696": [226, 623], "1246": 226, "6685": 226, "0047": 226, "1732": 226, "1463": 226, "7504": 226, "0016": 226, "1774": 226, "1715": 226, "8459": 226, "0020": 226, "0150": 226, "1884": 226, "6117": 226, "0017": 226, "2071": 226, "3838": 226, "0105": 226, "2115": [226, 639], "5110": 226, "exectu": 227, "palliat": [227, 628], "inner_count": 227, "middle_env": 227, "middle_count": 227, "auto_unwrap": [227, 272, 405, 444], "9670": 227, "2546": [227, 624], "9669": 227, "9802": 227, "1981": 227, "1601": 227, "9926": 227, "1214": 227, "5556": 227, "9994": 227, "7622": 227, "9984": 227, "0561": 227, "7933": 227, "9895": [227, 623], "1445": 227, "7779": 227, "dtype_in": 229, "dtype_out": 229, "scan": [229, 232, 317, 346, 347], "resp": [229, 232], "anticip": [229, 232], "not_transform": [229, 232], "orig_devic": 230, "unspecifi": 230, "num_actions_effect": 231, "max_act": 231, "include_forward": 231, "num_act": [231, 288, 358, 493, 626, 628], "action_out": 231, "inde": [231, 624, 626, 639], "eol_kei": [233, 495], "life": [233, 495, 640], "lives_kei": [233, 495], "eol_attribut": [233, 495], "breakout": 233, "210": [233, 248, 626, 644], "160": [233, 248, 623, 626, 644], "eol_transform": 233, "eol": 233, "dqnloss": [233, 349, 350, 352, 353, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 374, 376, 378, 380, 384, 559, 608, 623, 625, 626, 632], "register_kei": 233, "loss_or_advantag": 233, "lossmodul": [233, 416, 420, 421, 561, 562, 608], "valueestimatorbas": [233, 366, 376, 378, 380, 384], "excluded_kei": 234, "first_dim": 236, "last_dim": 236, "allow_positive_dim": [236, 262, 274], "frameskip": 236, "repeatedli": [237, 624, 638], "hash_fn": 239, "repertoir": 239, "reproducible_hash": 239, "unarytransform": [239, 533], "observation_str": 239, "tobyt": [239, 273], "observation_hash": 239, "x08": 239, "x8b": 239, "xbexav": 239, "xbf": 239, "x00": 239, "xee": 239, "xb5": 239, "x17": 239, "x8f": 239, "xbe": [239, 273], "x88": 239, "xccu": 239, "xc0vr": 239, "get_input_from_hash": 239, "hash_tensor": 239, "bit": [239, 624, 625, 627, 637, 638, 641], "init_kei": [240, 341, 502], "log_prob_kei": [241, 329, 345], "sample_log_prob": [241, 283, 284, 285, 342, 345, 347, 368, 376, 378, 380], "pi_curr": 241, "pi_0": 241, "overfit": 241, "get_dist": [241, 326, 329, 332, 337, 345, 346], "frozen": [241, 279, 280], "normalparamextractor": [241, 283, 284, 285, 342, 347, 349, 350, 352, 358, 364, 368, 369, 370, 371, 372, 373, 601, 624, 628, 638, 643], "probabilisticactor": [241, 283, 284, 285, 349, 350, 352, 355, 357, 358, 364, 367, 368, 369, 370, 371, 372, 373, 601, 622, 624, 628, 637, 638], "tanhnorm": [241, 283, 284, 285, 342, 347, 349, 350, 352, 364, 368, 369, 370, 371, 372, 373, 470, 601, 624, 638, 643], "reward_kl": 241, "apply_": 241, "copy_": [241, 622], "mogymwrapp": 242, "mo_env": 242, "sea": 242, "treasur": 242, "so_env": 242, "module_factori": 243, "At": [243, 267, 301, 317, 623, 624, 625, 630, 636, 639, 640], "observation_spec_transform": 243, "done_spec_transform": 243, "reward_spec_transform": 243, "state_spec_transform": 243, "action_spec_transform": 243, "stack_reward": [244, 505], "stack_observ": [244, 505], "auto_batch_size_": 244, "macro": [244, 341], "trial": 245, "standard_norm": [246, 257, 279, 280, 508, 518, 622, 623, 625], "affin": [246, 257, 279, 280], "recover": 246, "set_default_tensor_typ": 246, "doubletensor": 246, "isclos": 246, "rubric": [246, 326, 332, 337, 347, 376, 378, 380, 384], "init_stat": [246, 622, 623, 624, 625], "3752e": 246, "5087e": 246, "9294e": 246, "9636": 246, "5608": 246, "6408": 246, "num_it": [246, 623, 624], "reduce_dim": [246, 622, 623, 624, 625], "cat_dim": [246, 622, 623, 624, 625], "keep_dim": [246, 341, 623, 625], "statist": [246, 279, 280, 324, 333, 370, 420, 421, 566, 622, 623, 624, 644], "gaussian": [246, 265, 286, 311, 624, 626, 637], "empir": [246, 342, 345, 622, 624, 638], "3d": 246, "reorder": 248, "in_keys_in": [248, 274], "channel": [248, 268, 308, 309, 623], "r3m": [250, 511, 640], "resnet": [250, 275, 277], "visual": [250, 275, 277, 393, 619, 624, 637, 639], "embed": [250, 275, 276, 277, 283, 284, 285, 290, 315, 322, 340, 344, 345, 640], "ego4d": [250, 275, 277], "univers": [250, 275, 277, 332, 627], "suraj": [250, 275], "nair": [250, 275], "aravind": [250, 275], "rajeswaran": [250, 275], "vikash": [250, 275, 277], "kumar": [250, 275, 277], "chelsea": [250, 275], "finn": [250, 275], "abhinav": [250, 275], "gupta": [250, 275], "2203": [250, 275, 640], "12601": [250, 275, 640], "_init": [250, 275, 622], "resnet50": [250, 277, 640], "model_nam": [250, 275, 277, 324, 333, 334, 396, 511, 615], "resnet34": 250, "resnet18": [250, 511], "r3m_vec": [250, 640], "stack_imag": [250, 277], "tread": [250, 277], "hub": [250, 277, 627], "resnet50_weight": [250, 277], "imagenet1k_v1": [250, 277], "download_path": [250, 277], "tensor_pixels_kei": [250, 277], "sub_seq_len": 251, "sample_dim": [251, 622], "hesit": 251, "improp": 251, "dummyenv": 252, "another_oth": 252, "other_reward": 252, "create_copi": 253, "stuff": [253, 630], "newnam": 253, "gamma": [255, 349, 350, 352, 353, 354, 356, 358, 359, 360, 362, 364, 366, 368, 369, 370, 371, 372, 373, 374, 376, 378, 380, 384, 386, 387, 388, 389, 420, 474, 506, 516, 562, 608, 622, 623, 624, 637, 638, 643], "r2g": 255, "99": [255, 279, 362, 420, 506, 516, 539, 540, 548, 551, 562, 608, 622, 623, 624, 626, 629, 632, 637, 638, 643], "reward_to_go": 255, "bernoulli_": 255, "9010": 255, "9404": 255, "9701": 255, "9900": 255, "0000": [255, 266, 267, 301, 348, 624, 625], "clamp_min": [256, 517], "clamp_max": [256, 517], "clip_min": 256, "clip_max": 256, "episode_": 258, "reward1": 258, "reward2": 258, "episode_reward": [258, 637, 638], "keep_reward": 259, "keep_don": 259, "logical_or": 260, "in_key_inv": 262, "unstack": 262, "update_don": [263, 524], "disjunct": 263, "recognis": 263, "target_return": [264, 525], "default_valu": [265, 625], "expand_spec": 265, "single_default_valu": 265, "call_before_env_reset": 265, "unit": [265, 299, 308, 309, 315, 316, 624, 635], "scala": 265, "mykei": 265, "__unless": 265, "exists__": 265, "get_primers_from_modul": [265, 287, 302, 304], "recurrent_st": [265, 302, 304, 625], "10th": 266, "0216": 266, "1149": 266, "1990": [266, 639], "2749": 266, "3281": 266, "9290": 266, "3702": 266, "8978": 266, "time_kei": [267, 528], "elaps": [267, 631], "monitor": [267, 324, 326, 332, 337, 351, 368, 418, 420, 568, 627], "expend": 267, "_polici": 267, "time_reset": 267, "time_polici": 267, "time_step": [267, 341], "0882": 267, "0002": [267, 624], "5797e": 267, "6289e": 267, "7990e": 267, "0824e": 267, "0837e": 267, "6056e": 267, "2016e": 267, "1062e": 267, "7009e": 267, "from_int": [268, 529], "shape_toler": [268, 529], "ri": 268, "traj_count": [270, 531], "traj": 270, "countingenv": 270, "make_env_c0": 270, "make_env_c1": 270, "smoothli": 272, "add_1": [272, 626], "cache_spec": [272, 444], "shown": [272, 594, 626, 634, 636, 637, 638, 641], "inv_fn": 273, "unari": 273, "durin": 273, "ommit": 273, "observation_trsf": 273, "xbc": 273, "x7f": 273, "x859": 273, "x81": 273, "x9a": 273, "xbd": 273, "xb8t8": 273, "test_output_spec": 273, "danger": 274, "vc1": [275, 535], "vc1_vec": 275, "untrain": 275, "make_noload_model": 275, "naiv": [275, 627], "vip": [276, 277, 536, 537, 640], "implicit": [277, 357, 364, 588, 641], "jason": 277, "ma": 277, "shagun": 277, "sodhani": 277, "dinesh": 277, "jayaraman": 277, "osbert": 277, "bastani": 277, "ami": 277, "zhang": 277, "vip_vec": 277, "final_nam": 278, "sb3": 278, "terminal_obs_read": 278, "vecnormv2": [279, 540], "new_api": [279, 280], "to_observation_norm": [279, 280], "frozen_copi": [279, 280], "shared_td": 279, "race": [279, 577], "decai": [279, 280, 286, 301, 413, 539, 540, 622, 623, 625, 644], "underflow": [279, 413], "build_td_for_shared_vecnorm": 279, "memmori": 279, "td_share": 279, "unfreez": [279, 280], "train_env": 279, "eval_env": 279, "9999": 280, "shared_data": 280, "reduce_batch_dim": 280, "varianc": [280, 303, 307, 320, 321, 368, 622, 624, 638], "weigh": 280, "_cast_int_to_float": 280, "env_trsf": 280, "observation_norm": 280, "reward_norm": [280, 413], "unnorm": [280, 306, 310], "7967": 280, "1238": 280, "5911": 280, "5275": 280, "8585": 280, "5028": 280, "2505": 280, "3169": [280, 348], "1332": 280, "1235": 280, "6596e": 280, "3072e": 280, "9170e": 280, "9255e": 280, "9131e": 280, "4671e": 280, "3760e": 280, "2058e": 280, "3484e": 280, "6185e": 280, "1456": 280, "1862": 280, "2053": 280, "2605": 280, "4046": 280, "5185": 280, "8023": 280, "1364": 280, "6183": 280, "5406": 280, "0920": 280, "1492": 280, "2702": 280, "3917": 280, "5001": 280, "7947": 280, "0160": 280, "3347": 280, "9082": 280, "9679": 280, "2199": 280, "2918": 280, "1668": 280, "2083": 280, "4981": 280, "5046": [280, 639], "7950": 280, "9791": 280, "1484": 280, "4182": 280, "2201": 280, "0403": 280, "5206": 280, "7791": 280, "8282": [280, 626], "2279": 280, "2907": 280, "4929": 280, "7793": 280, "8626": 280, "1832": 280, "local_env": 280, "testifi": 280, "4307": 280, "9613": 280, "state_dim": [281, 289, 294, 308, 311, 315, 316], "action_dim": [281, 289, 290, 292, 294, 311, 316, 622, 636], "gsde": [281, 369, 566], "gsdemodul": 281, "module_nam": [282, 366, 376, 378, 380, 384], "from_vers": 282, "to_vers": 282, "class_method": 282, "intersect": 282, "import_modul": 282, "get_class_that_defined_method": 282, "module_set": 282, "setters_dict": 282, "pyver": 282, "setter": [282, 286], "setter_dict": 282, "actorvalueoper": [283, 351, 365, 368, 601, 628], "get_policy_oper": [283, 284, 285, 351, 365, 368], "standalon": [283, 284, 285, 626, 628], "tdmodul": [283, 284, 285, 562], "get_critic_oper": 283, "common_oper": [283, 285], "policy_oper": [283, 284, 285], "value_oper": [283, 284, 285], "valueoper": [283, 284, 285, 349, 350, 351, 352, 353, 358, 364, 365, 368, 369, 370, 371, 372, 373, 472, 562, 601, 608, 622, 624, 629], "module_hidden": [283, 285], "td_module_hidden": [283, 285], "safemodul": [283, 285, 345, 349, 350, 352, 357, 358, 364, 368, 369, 370, 371, 372, 373, 557, 558, 562, 601, 643], "module_act": [283, 285], "td_module_act": [283, 284, 285], "module_valu": [283, 284, 285], "td_module_valu": [283, 284, 285], "state_action_valu": [283, 322, 350, 352, 357, 364, 371, 562, 622, 637, 643], "td_modul": [283, 284, 285, 322, 340, 342, 344, 345, 347, 628, 643], "td_clone": [283, 284, 285], "tensordictmodulewrapp": [283, 557, 558, 562], "get_policy_head": [283, 284, 285], "safesequenti": [283, 284, 285], "head": [283, 285, 345, 351, 365, 368], "get_value_head": [283, 284, 285], "get_value_oper": [283, 284, 285, 351, 365, 368], "action_modul": 284, "actorcriticoper": [285, 601, 628], "actorcriticwrapp": [285, 601, 622], "po": 286, "sigma_init": [286, 637], "sigma_end": [286, 637], "annealing_num_step": [286, 301, 312, 622, 623, 625, 626, 628, 632, 637], "sigma": [286, 303, 312, 320, 321, 384, 624, 637], "omiss": [286, 301, 312], "consistentdropout": 287, "input_shap": 287, "batcht": 287, "make_tensordict_prim": [287, 302, 304, 625], "input_dtyp": 287, "get_default_dtyp": [287, 413], "mask_6127171760": 287, "seq": [287, 302, 304, 326, 332, 337, 341, 376, 378, 380, 384, 625, 626, 632, 636], "env0": [287, 644], "elu": [288, 290, 291, 292, 293, 299, 300, 623, 643], "activation_kwarg": [288, 305, 466, 467], "norm_class": [288, 290, 291, 305, 466, 467], "norm_kwarg": [288, 305, 466, 467], "bias_last_lay": [288, 290, 291, 292, 293, 300, 305, 466, 467], "aggregator_class": [288, 290, 291, 466, 623, 625, 643], "squashdim": [288, 290, 300, 601, 643], "aggregator_kwarg": [288, 290, 291, 466, 623, 625], "squeeze_output": [288, 290, 291, 466, 623, 625], "lazyconv2d": [288, 290, 291, 300, 309], "cell": [288, 302, 304, 305, 624, 626, 627, 628, 629, 630, 631, 632], "cnet": 288, "34": [288, 305, 368, 622, 623], "35": [288, 305, 622, 623, 635], "default_atari_dqn": [288, 626], "semin": 288, "transformer_config": [289, 311], "decision_transform": [289, 311], "decisiontransform": [289, 311, 601], "dtconfig": [289, 294, 311], "2202": [289, 294, 367], "05607": [289, 294, 367], "return_to_go": [289, 294, 311], "conv_net_kwarg": [290, 291], "mlp_net_kwarg": [290, 291, 292], "use_avg_pool": [290, 291], "WITH": [290, 291, 292, 293, 312], "1509": [290, 291, 292, 293, 312, 354], "02971": [290, 291, 292, 293, 312], "maximis": [290, 292, 623, 624, 638], "ndims_in": [290, 338, 626], "avgpool": [290, 291], "lazylinear": [290, 291, 292, 293, 300, 305, 308, 316, 624, 628, 639, 640], "2304": [290, 623], "adaptiveavgpool2d": [291, 623, 625], "output_s": [291, 623, 625], "squeeze2dlay": 291, "400": [292, 293, 631, 638, 641], "mlp_net_kwargs_net1": 293, "mlp_net_kwargs_net2": 293, "mlp1": 293, "mlp2": 293, "desdescrib": 294, "n_embd": 294, "n_layer": 294, "n_head": 294, "n_inner": 294, "n_posit": 294, "resid_pdrop": 294, "attn_pdrop": 294, "gpt2config": 294, "atol": [295, 319], "rtol": [295, 319], "batch_shap": [295, 310, 319], "event_shap": [295, 319], "absolut": [295, 319, 622], "_instanc": 295, "densiti": [295, 306, 310, 321], "mass": [295, 306, 310, 321, 639], "rsampl": [295, 310, 345], "sample_shap": [295, 306, 310], "softmax": [296, 297, 298, 310], "qvaluemodul": [297, 313, 625, 626, 628, 632], "distributionaldqnnet": [297, 601], "make_log_softmax": 297, "character": [297, 313, 340, 342, 344, 641], "overflow": [297, 298, 313, 314, 320, 340, 342, 344, 345], "var_num": [297, 298, 314], "mult": [297, 298, 313, 314], "action_value_kei": [297, 298, 313, 314, 352, 366, 376, 378, 380, 384], "action_mask_kei": [297, 298, 301, 313, 314], "nbin": 297, "log_softmax": 297, "qvalue_actor": [297, 313], "greedi": [298, 301, 314, 326, 332, 337, 601, 623, 625, 626, 628], "1707": [298, 359, 368], "06887": [298, 359], "my_action_valu": [298, 314], "chanc": 298, "std_bia": 299, "std_min_val": 299, "belief": [299, 308, 315, 316, 317], "1912": [299, 360, 361, 362], "01603": [299, 360, 361, 362], "softplu": [299, 307], "out_features_valu": 300, "cnn_kwarg": [300, 623], "mlp_kwarg": [300, 623], "duel": [300, 601], "cnn": [300, 623, 626, 628, 643], "06581": 300, "eps_init": [301, 312, 623, 625, 626, 628, 632], "eps_end": [301, 312, 623], "explorative_polici": [301, 312], "9055": 301, "9277": 301, "6295": 301, "2532": 301, "grad_fn": [301, 340, 345], "addbackward0": 301, "embedd": [302, 304], "grucel": [302, 344], "python_bas": [302, 304], "custom_kei": [302, 304], "hasn": [302, 304], "set_recurrent_mod": [302, 304, 625], "recurrent_mod": [302, 304], "rnn": [302, 304, 315, 358, 371, 386, 625, 626, 628], "rs": [302, 622], "gru_module_train": 302, "policy_train": [302, 384], "traj_td": 302, "make_cudnn_bas": [302, 304], "make_python_bas": [302, 304, 626], "supplementari": [302, 304, 624, 644], "That": [302, 304, 624, 637], "dealt": [302, 304], "poorli": [302, 304], "meth": [302, 304, 366, 639], "lstmmodul": [302, 601, 625, 626], "data_collector": [302, 304, 623], "upscal": [303, 320, 321], "tanh_loc": [303, 320, 321], "event_dim": [303, 319, 320], "poor": [303, 320, 321], "explos": [303, 320, 321], "full_lik": [303, 320], "fill_valu": [303, 320], "lstmcell": [304, 626], "b_ih": 304, "b_hh": 304, "recurrent_state_h": [304, 625], "recurrent_state_c": [304, 625], "triplet": [304, 313, 314], "lstm_modul": 304, "rs_h": 304, "rs_c": 304, "single_bias_last_lay": [305, 467], "layer_class": [305, 467], "layer_kwarg": [305, 467], "perceptron": [305, 467, 628], "noisylinear": [305, 623], "noisylazylinear": 305, "neg_inf": 306, "inf": 306, "use_cross_entropi": 306, "api_doc": 306, "tf_agent": 306, "sparse_mask": 306, "cross_entropi": 306, "1203": 306, "0928": 306, "0831": 306, "1972": 306, "entropi": [306, 310, 349, 350, 351, 352, 357, 358, 364, 365, 367, 368, 369, 371, 372, 373, 376, 377, 379, 380, 381, 382, 420, 421, 638], "scale_map": [307, 470], "biased_softplus_1": [307, 470], "scale_lb": [307, 315, 316, 470], "normal_param": 307, "latent_dim": 308, "1803": [308, 309], "10122": [308, 309], "rnn_hidden_dim": [308, 315, 316], "rnn_hidden": 308, "in_channel": 309, "latent": [309, 317], "grad_method": 310, "reparamgradientstrategi": [310, 601], "passthrough": 310, "relaxedonehot": 310, "inres": 311, "mu": [311, 312, 624], "ornstein": [312, 601, 622, 626], "uhlenbeck": [312, 601, 622, 626], "ou": [312, 622], "noise_t": 312, "noise_": 312, "theta": [312, 624, 639], "sigma_t": 312, "sigma_": 312, "ou_prev_nois": 312, "ou_step": 312, "x0": 312, "sigma_min": 312, "n_steps_ann": 312, "is_init_kei": 312, "_ou_prev_nois": 312, "_ou_step": 312, "tensordict_modul": [313, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 357, 358, 364, 368, 369, 370, 371, 372, 373, 626], "chose": 314, "hidden_dim": [315, 316], "obs_embed_dim": 315, "posterior": [315, 317, 361], "rssm": [315, 316, 317, 361], "1811": [315, 316, 317], "04551": [315, 316, 317], "obs_embed": 315, "posterior_mean": 315, "posterior_std": 315, "dream": 316, "prior_mean": 316, "prior_std": 316, "rssm_prior": 317, "rssm_posterior": 317, "use_scan": 317, "_higher_order_op": 317, "characterist": [317, 594, 622, 639], "compile_step": 317, "compile_backend": 317, "inductor": 317, "compile_mod": 317, "s_": [317, 594, 634], "s_t": 317, "a_t": 317, "b_t": 317, "a_": 317, "evid": 317, "o_t": 317, "b_": 317, "o_": 317, "amend": 317, "safe_tanh": 320, "tanhtransform": 320, "get_mod": [320, 345], "custommodul": 322, "imaginari": 323, "transition_model": 323, "reward_model": 323, "get_reward_oper": 323, "get_transition_model_oper": 323, "engine_arg": 324, "asyncenginearg": [324, 333], "num_replica": [324, 333, 337, 582, 589, 594], "actor_class": 324, "enable_prefix_cach": 324, "replica": [324, 333, 337, 589], "placement": 324, "samplingparam": 324, "num_devic": [324, 333, 334], "max_model_len": 324, "4096": [324, 623], "sampling_param": [324, 333], "temperatur": [324, 326, 332, 337, 350, 357, 364], "max_token": [324, 326, 332, 337], "tensor_parallel_s": [324, 333], "actor_index": 324, "fault": 324, "resili": 324, "collective_rpc": [324, 585], "create_load_balanc": 324, "kv": 324, "loadbalanc": 324, "rout": 324, "smart": 324, "lb": 324, "selected_actor_index": 324, "select_actor": 324, "prefix_length": 324, "overload_threshold": 324, "enable_fp32_output": [324, 333, 334], "fp32": [324, 333, 334], "prompt_token_id": 324, "use_tqdm": 324, "lora_request": 324, "prompt_adapter_request": 324, "guided_options_request": 324, "timeout_second": 324, "requestoutput": 324, "tokensprompt": 324, "lora": 324, "get_cache_usag": 324, "fraction": [324, 349, 351, 368], "get_master_address": 324, "get_master_port": 324, "get_num_unfinished_request": 324, "unfinish": 324, "get_random_actor_index": 324, "init_weight_update_group": 324, "asyncvllmengineservic": 324, "asyncllmengin": 324, "parameter_nam": 324, "to_text": [325, 331], "to_token": [325, 330], "logprob": [326, 332, 337, 635], "input_kei": [326, 332, 337, 635], "attention_mask_kei": [326, 332, 337], "generate_kwarg": [326, 329, 332, 337, 635], "max_new_token": [326, 329, 332, 337, 635], "num_return_sequ": [326, 332, 337], "top_p": [326, 332, 337], "nucleu": [326, 332, 337], "top_k": [326, 332, 337], "repetition_penalti": [326, 332, 337], "do_sampl": [326, 332, 337], "num_beam": [326, 332, 337], "beam": [326, 332, 337], "length_penalti": [326, 332, 337], "early_stop": [326, 332, 337], "stop_sequ": [326, 332, 337], "win": 326, "pad_model_input": [326, 332, 337], "num_sampl": [326, 329, 332, 337], "tokens_kei": [326, 329, 332, 337], "masks_kei": [326, 329, 332, 337], "min_batch_s": [326, 332, 337], "max_batch_s": [326, 332, 337], "batching_timeout": [326, 332, 337], "suffic": [326, 332, 337], "busi": [326, 332, 337, 615], "cleanup_batch": [326, 329, 332, 337], "flush": [326, 332, 337], "cancel": [326, 332, 337], "pend": [326, 332, 337, 575], "_batch_queu": [326, 332, 337], "tensordict_out": [326, 332, 337, 644], "logits_onli": [326, 332, 337], "get_batching_st": [326, 329, 332, 337], "logits_kei": [326, 332, 337], "llmmaskedcategor": 326, "alter": [326, 329, 332, 337, 341, 366], "is_tdmodule_compat": [326, 332, 337, 376, 378, 380, 384], "weak": [326, 332, 337], "reset_out_kei": [326, 332, 337, 376, 378, 380, 384], "select_out_kei": [326, 332, 337, 349, 350, 352, 353, 357, 358, 364, 368, 369, 371, 372, 373, 376, 378, 380, 384, 626], "reset_parameters_recurs": [326, 332, 337, 366, 376, 378, 380, 384], "old_param": [326, 332, 337], "bork": [326, 332, 337], "dork": [326, 332, 337], "reset_paramet": [326, 332, 337], "complic": [326, 332, 337, 376, 378, 380, 384, 639, 641, 644], "out_keys_sourc": [326, 332, 337, 376, 378, 380, 384], "z": [326, 332, 337, 376, 378, 380, 384], "all_attention_mask": [328, 332, 337, 635], "all_assistant_mask": [328, 332, 337, 635], "validate_model": 329, "automodelforcausallm": [329, 332, 635], "remote_wrapp": 329, "tensordict_input": 329, "dist_params_kei": 329, "dist_sample_kei": 329, "get_dist_with_prompt_mask": [329, 337], "to_histori": [330, 331], "wast": 332, "simpler": [332, 583, 623, 627, 635], "unsur": 332, "overlong": 332, "tokenization_util": [332, 337], "output_scor": 332, "discourag": [332, 337, 624, 639], "pad_token_id": [332, 635], "bad_words_id": 332, "force_words_id": 332, "no_repeat_ngram_s": 332, "gram": 332, "encoder_repetition_penalti": 332, "repetit": [332, 624, 627, 630], "num_beam_group": 332, "diversity_penalti": 332, "return_dict_in_gener": 332, "repeat_interleave_caus": 332, "sequence_length": 332, "_create_block_diagonal_attention_mask": 332, "causal": 332, "data_parallel_s": 333, "pipeline_parallel_s": 333, "_model": [333, 334], "make_ray_work": 334, "enforce_eag": 334, "rayllmwork": 334, "localllmwrapp": 334, "world_siz": [335, 336, 582, 589], "statelessprocessgroup": [335, 336], "plane": [335, 336], "pyncclcommun": [335, 336], "async_engin": 337, "presence_penalti": 337, "frequency_penalti": 337, "ignore_eo": 337, "prompt_logprob": 337, "detoken": 337, "include_stop_str_in_output": 337, "spaces_between_special_token": 337, "sampling_typ": 337, "temperature_last": 337, "top_p_last": 337, "top_k_last": 337, "assistant_mask_kei": 337, "set_token": 337, "additivegaussianmodul": [339, 601, 628, 637], "_spec": 339, "translat": [340, 342, 626], "3635": 340, "0340": 340, "1476": 340, "3911": 340, "1664": [340, 623], "5455": 340, "2247": 340, "4583": 340, "2916": 340, "2160": 340, "5337": 340, "5193": 340, "addmmbackward0": 340, "lookahead": 341, "window": [341, 637, 641, 643], "n_action": [341, 350, 352, 354, 356, 367, 369, 371], "reshape_cat": 341, "actor_bas": 341, "obs_cat": 341, "obs_cat_reshap": 341, "action_orig": 341, "multistepenvwrapp": 341, "ego": 341, "default_interaction_typ": [342, 345, 628], "interaction_typ": [342, 345], "set_interaction_typ": [342, 345], "compositedistribut": [342, 345, 349, 368, 628], "distribution_map": [342, 345], "name_map": [342, 345], "distribution_kwarg": [342, 345, 624, 637, 638], "cache_dist": [342, 345], "n_empirical_estim": [342, 345], "compound": [342, 628], "cube": 343, "functionalmodul": 344, "functionalmodulewithbuff": 344, "td_fmodul": 344, "td_function": 344, "td_state": 344, "params_repeat": 344, "td_vmap": [344, 347], "random_sampl": [344, 345], "suppli": 345, "paliat": 345, "get_median": 345, "get_mean": 345, "sample_key_nam": 345, "_log_prob": 345, "composite_lp_aggreg": 345, "induc": 345, "clampbackward0": 345, "anihil": 345, "probabilistictensordictsequenti": [346, 349, 351, 365, 368, 370, 557, 558, 643], "partial_toler": [346, 347, 636], "AND": [346, 347, 352], "tensordictsequ": 347, "safeprobabilisticmodul": 347, "spec1": 347, "net1": 347, "module1": 347, "td_module1": 347, "spec2": 347, "module2": 347, "td_module2": 347, "9944": 348, "9991": 348, "3020": 348, "2299": 348, "5418": 348, "2989": [348, 626], "6849": 348, "2690": 348, "9649": 348, "5686": 348, "8602": 348, "0315": [348, 639], "8455": 348, "6027": 348, "4746": 348, "7843": 348, "7782": 348, "2111": 348, "5115": 348, "4687": 348, "5760": 348, "1602": 349, "01783v2": 349, "entropy_bonu": [349, 351, 365, 368, 380, 474, 624], "favour": [349, 351, 365, 368, 380], "samples_mc_entropi": [349, 351, 365, 367, 368, 380, 474], "entropy_coeff": [349, 351, 365, 368, 380, 474], "critic_coeff": [349, 351, 365, 368, 474], "loss_critic_typ": [349, 351, 365, 368, 370, 474, 624], "l1": [349, 351, 353, 354, 358, 365, 368, 369, 370, 372, 373, 622], "l2": [349, 351, 353, 354, 355, 356, 358, 361, 362, 365, 368, 369, 370, 372, 373, 622, 637], "smooth_l1": [349, 350, 351, 352, 353, 354, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 474, 624], "separate_loss": [349, 351, 352, 353, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 474], "advantage_kei": [349, 351, 365, 368, 370, 380, 383, 386, 387, 388, 389, 474], "value_target_kei": [349, 351, 365, 368, 370, 386, 387, 388, 389, 474], "value_target": [349, 351, 365, 368, 370, 386, 387, 388, 389, 624, 638], "ddp": [349, 351, 365, 368, 370], "fsdp": [349, 351, 365, 368, 370], "divid": [349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 380, 555, 622, 637, 638, 639], "clip_valu": [349, 351, 365, 368, 370, 380, 474], "loss_crit": [349, 368, 624, 638], "loss_entropi": [349, 368, 377, 379, 381, 382, 624, 638], "loss_object": [349, 368, 377, 379, 381, 382, 624, 638], "recur": [349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 386, 387, 388, 389, 390, 628], "next_reward": [349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 386, 387, 388, 389], "next_don": [349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 386, 387, 388, 389], "next_termin": [349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 386, 387, 388, 389], "loss_obj": 349, "next_observ": [349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 636], "sacloss": [349, 415, 421, 608], "default_kei": [349, 350, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 373, 384, 390], "_acceptedkei": [349, 350, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 390], "make_value_estim": [349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 374, 376, 378, 380, 384, 622, 623, 637, 638, 643], "value_typ": [349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 622], "hyperparam": [349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 622], "enum": [349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 622], "default_value_estim": [349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 622, 643], "default_value_kwarg": [349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 622], "dqn_loss": [349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 374, 376, 378, 380, 384], "td1": [349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 622], "cql": [350, 356], "conserv": [350, 356], "qvalue_network": [350, 352, 357, 358, 364, 369, 371, 372, 373, 415, 421], "unti": [350, 352, 364, 369, 371, 372, 373], "loss_funct": [350, 352, 353, 354, 355, 356, 357, 358, 364, 369, 371, 372, 373, 384, 622, 637], "alpha_init": [350, 352, 358, 367, 369, 371], "min_alpha": [350, 352, 358, 367, 369, 371], "max_alpha": [350, 352, 358, 367, 369, 371], "fixed_alpha": [350, 352, 358, 367, 369, 371], "target_entropi": [350, 352, 358, 367, 369, 371], "prod": [350, 352, 367, 369, 371], "delay_actor": [350, 353, 371, 372, 373], "delay_qvalu": [350, 358, 369, 371, 372, 373], "min_q_weight": 350, "max_q_backup": 350, "backup": 350, "deterministic_backup": 350, "num_random": 350, "with_lagrang": 350, "lagrang": 350, "lagrange_thresh": 350, "deactivate_vmap": [350, 352, 358, 364, 369, 371, 372, 373, 386, 387, 388, 389], "valueclass": [350, 352, 353, 358, 369, 371, 372, 373], "qvalu": [350, 352, 357, 358, 364, 369, 371, 372, 373], "loss_actor": [350, 352, 353, 357, 358, 364, 369, 370, 371, 372, 373, 411, 622, 629, 637], "loss_actor_bc": 350, "loss_alpha": [350, 352, 358, 369, 371], "loss_cql": [350, 356], "loss_qvalu": [350, 352, 356, 357, 358, 364, 369, 371, 372, 373], "loss_alpha_prim": 350, "ess": [351, 368, 376, 377, 379, 380, 381, 382], "coupl": [351, 368, 587, 625, 628, 629, 639, 641], "clip_epsilon": [351, 380, 624, 638], "head_nam": [351, 365, 368], "ppo_entropy_coeffici": [351, 365, 368], "normalize_advantag": [351, 365, 368, 474, 638], "normalize_advantage_exclude_dim": [351, 365, 368, 474], "multiobject": [351, 365, 368], "value_kei": [351, 365, 368, 386, 387, 388, 389, 474, 622], "somemodul": [351, 365, 368], "actor_head": [351, 365, 368], "someactor": [351, 365, 368], "value_head": [351, 365, 368], "somevalu": [351, 365, 368], "crossq": 352, "IN": 352, "FOR": 352, "simplic": [352, 623, 624, 630, 640, 641, 643], "openreview": [352, 369], "pczqttstix": 352, "qvalue_loss": [352, 372], "actor_loss": [352, 372], "alpha_loss": [352, 358, 371], "num_qvalue_net": [352, 357, 358, 364, 369, 371, 372, 373], "maybe_init_target_entropi": 352, "fault_toler": 352, "target_entropy_buff": 352, "delay_valu": [353, 354, 356, 359, 370, 371, 623, 625, 626, 632, 637], "loss_valu": [353, 357, 364, 370, 371, 622, 624, 629, 637, 638], "pred_valu": [353, 356, 372, 373, 622, 629], "pred_value_max": [353, 622, 629], "target_valu": [353, 356, 369, 372, 373, 622, 629], "target_value_max": [353, 622, 629], "qvalueactor": [354, 356, 623, 625], "double_dqn": 354, "06461": 354, "mult_one_hot": [354, 357, 358], "loss_val": [354, 356, 384, 608, 622, 624, 625, 626, 629, 630, 632, 637, 638, 641], "01345": 355, "distanc": [356, 365, 386, 638], "dcql_loss": 356, "iql": [357, 364, 622, 637, 638], "2110": [357, 364], "06169": [357, 364], "expectil": [357, 364], "tau": [357, 364, 622, 623, 637], "antmaz": [357, 364], "sticht": [357, 364], "onehotcategor": [357, 358, 601], "target_entropy_weight": 358, "skip_done_st": [358, 371], "disctount": 359, "distributionalqvalueactor": 359, "input_tensordict": [359, 622], "actor_model": 360, "imagination_horizon": 360, "unrol": 360, "discount_loss": [360, 362], "lambda_kl": 361, "lambda_reco": 361, "lambda_reward": 361, "reco_loss": 361, "reward_loss": 361, "free_nat": 361, "nat": 361, "delayed_clamp": 361, "global_averag": 361, "value_loss": 362, "fake_data": 362, "gail": 363, "1606": 363, "03476": 363, "discriminator_network": 363, "use_grad_penalti": 363, "gp_lambda": 363, "discrimin": 363, "qvalueclass": 364, "loss_value_diff": 364, "diff": 364, "old_polici": 365, "new_polici": 365, "apart": [365, 638], "dtarg": 365, "samples_mc_kl": 365, "analyt": 365, "decrement": 365, "loss_": [366, 411, 608, 622, 629], "equip": [366, 625, 626, 628], "gh": 366, "_forward_value_estimator_kei": 366, "value_estim": [366, 376, 378, 380, 384, 386, 387, 388, 389, 390, 622, 638], "myloss": 366, "action2": 366, "augment": [366, 594, 630, 632, 641], "set_exploration_typ": [366, 410, 624, 625, 626, 628, 637, 643], "deterministic_sampling_mod": 366, "convert_to_funct": [366, 376, 378, 380, 384, 622], "expand_dim": [366, 376, 378, 380, 384], "create_target_param": [366, 376, 378, 380, 384, 622], "compare_against": [366, 376, 378, 380, 384, 622], "isol": [366, 376, 378, 380, 384, 402, 404, 589, 592, 626], "_param": [366, 376, 378, 380, 384], "resampl": [366, 376, 378, 380, 384], "_target_param": [366, 376, 378, 380, 384], "from_stateful_net": [366, 376, 378, 380, 384], "network_nam": [366, 376, 378, 380, 384], "stateful_net": [366, 376, 378, 380, 384], "get_stateful_net": [366, 376, 378, 380, 384], "Such": [366, 376, 378, 380, 384], "blend": [366, 376, 378, 380, 384], "vmap_random": [366, 375, 376, 378, 380, 384], "add_random_modul": [366, 376, 378, 380, 384, 608], "proxim": [368, 420, 475, 624, 638], "flavor": [368, 622, 637, 638, 643], "clipppoloss": [368, 608, 624, 638], "klpenppoloss": [368, 608], "06347": 368, "log_explained_vari": [368, 474], "explain": [368, 626, 640], "explained_vari": 368, "wors": 368, "gae": [368, 420, 475, 608, 622, 624, 638], "ppo_loss": 368, "tdlambda": [368, 622], "base_lay": 368, "action_log_prob": [368, 624, 628, 638], "randn_lik": 368, "kl_approx": [368, 377, 379, 381, 382], "samplelogprob": 368, "gripper": 368, "composite_entropi": 368, "0234": 368, "set_composite_lp_aggreg": [368, 638], "redq": 369, "ay8zfzm0tdd": 369, "sub_sample_len": 369, "subsampl": [369, 406], "action_log_prob_actor": 369, "state_action_value_actor": [369, 372, 373], "connectionist": 370, "william": 370, "1992": 370, "doi": 370, "1007": 370, "bf00992696": 370, "actor_net": [370, 622, 624], "1801": 371, "01290": 371, "1812": 371, "05905": 371, "minimalist": 372, "06860": 372, "policy_nois": [372, 373], "noise_clip": [372, 373], "td3_bc": 372, "bc_loss": 372, "lmbd": 372, "next_state_valu": [372, 373], "td0": [374, 622, 637], "cispo": 376, "eps_low": [376, 380], "eps_high": [376, 380], "minimax": 376, "m1": 376, "llmoutputtyp": [376, 378, 380], "output_typ": [376, 378, 380], "cispolossoutput": [376, 592], "tensor_kei": [376, 378, 380, 386, 387, 388, 389, 390], "grpoloss": [376, 378, 592, 594], "my_advantage_kei": [376, 378, 380], "clip_fract": [377, 379, 381, 382], "loss_kl_to_ref": [377, 379, 381, 382, 384, 385], "kl_to_ref": [377, 379, 381, 382, 385], "loss_kl_to_infer": [377, 379, 381, 382], "kl_to_infer": [377, 379, 381, 382], "asymmetr": [378, 380], "eq": [378, 380], "dapolossoutput": [378, 592], "instabl": 380, "diagnost": 380, "masking_strategi": 380, "sft": [380, 384], "surrog": 380, "symmetr": 380, "dapo": [380, 592], "kl_mask_threshold": 380, "pi_theta": 380, "pi_ref": 380, "drift": 380, "token_mean": 380, "prompt_mean": 380, "kl_to_ref_coeff": [380, 384], "kl_to_inference_coeff": 380, "grpolossoutput": [380, 383, 592], "grpo_siz": 383, "hit": 383, "supervis": [384, 629, 630, 641, 644], "normalize_by_seq_length": 384, "minor_sft": 384, "minorsft": 384, "shime": 384, "xie": 384, "hong": 384, "chen": 384, "fred": 384, "yu": 384, "zey": 384, "sun": 384, "xiuyu": 384, "wu": 384, "2024": 384, "minor": [384, 637], "_chat_templ": 384, "policy_ref": 384, "txt_start": 384, "zip": [384, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "loss_sft": [384, 385], "1506": 386, "02438": 386, "exponenti": [386, 387, 388, 389, 413], "lmbda": [386, 389, 420, 622, 624, 638], "average_ga": [386, 624], "skip_exist": [386, 387, 388, 389], "get_default_devic": [386, 387, 388, 389, 390], "time_dim": [386, 388, 389], "auto_reset_env": 386, "next_valu": [386, 387, 388, 389, 390], "gradient_mod": 386, "value_error": [386, 387, 388, 389, 390], "marker": [386, 622], "trajecotri": 386, "fair": 386, "target_param": [386, 387, 388, 389, 390, 622, 638], "98": [386, 387, 388, 389, 622, 623, 639], "94": [386, 389, 622, 623], "unpack": [386, 387, 388, 389], "aka": [387, 623, 637], "average_reward": [387, 388, 389], "tdestim": [387, 388, 390], "infti": 388, "valuefunctionbas": 390, "preproc": [391, 626, 637], "as_non_tensor": [391, 637], "render_method": 391, "pass_tensordict": 391, "syntact": 391, "sugar": 391, "relax": 391, "out_file_bas": 392, "skip_reset": 392, "center_crop": 393, "make_grid": 393, "log_video": 393, "csv": [393, 395, 397, 462, 623, 631, 632], "log_dir": [393, 394, 395, 397, 399, 401, 462, 464, 465, 623, 632], "cheetah_video": 393, "run_video": 393, "openxexperiencereplai": 393, "sec": [393, 626, 639], "video_fp": [393, 395, 398, 462, 465], "run_video_0": 393, "cur_dir": 395, "csv_log": 395, "add_video": 395, "video_": 395, "experiment_nam": [396, 397], "logger_typ": 397, "logger_nam": 397, "mlflow": [397, 398], "wandb_kwarg": 397, "mlflow_kwarg": 397, "trackio_kwarg": 397, "tracking_uri": 398, "uri": 398, "datastor": 398, "tb_log": [399, 464], "tensoarboard": 399, "td_log": 399, "trackio": 400, "save_dir": [401, 465], "resum": 401, "uncategor": 401, "torchrl_servic": [402, 404], "discoveri": 402, "instantli": 402, "tokenizerclass": [402, 404], "modelclass": 402, "tok": 402, "service_factori": [402, 403, 615], "max_restart": 402, "register_with_opt": [402, 615], "actor_opt": [402, 615], "constructor_kwarg": 402, "readabl": 402, "concern": [402, 582, 594, 629], "model_path": 402, "ongo": [402, 403], "destruct": [402, 403], "init_kwarg": 404, "servicebas": [404, 615], "unsupport": [404, 577], "my_funct": 405, "sub_traj_len": 406, "min_sub_traj_len": 406, "register_op": [406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 417, 419, 623], "process_optim_batch": [406, 412, 413], "td_out": [406, 414], "_process_optim_batch_hook": 406, "batch_subsampl": 406, "clear_cuda": 407, "pre_optim_step": 407, "log_pbar": [408, 409, 410, 413, 623], "count_fram": 408, "pre_steps_log": [408, 409], "count_frames_log": 408, "lognam": 409, "include_std": 409, "log_reward": [409, 420, 421, 623], "r_train": 409, "log_action_norm": 409, "action_norm": 409, "percentag": 409, "log_don": 409, "done_percentag": 409, "record_interv": [410, 622, 623], "record_fram": [410, 555, 622, 623], "policy_explor": [410, 562, 622, 623, 626, 628, 632], "log_kei": [410, 623], "underestim": 410, "r_evalu": [410, 622], "loss_compon": 411, "appl": 411, "optimizer_hook": 411, "flatten_tensordict": [412, 623], "max_dim": 412, "rb_trainer": 412, "batch_process": [412, 413, 414], "post_loss": 412, "999": [413, 544, 545, 546, 549, 550, 554, 623], "jitter": 413, "finfo": 413, "default_dtyp": 413, "update_reward_stat": 413, "normalize_reward": 413, "make_train": 414, "_process_batch_hook": 414, "select_kei": 414, "target_params_updat": 415, "targetnetupdat": [415, 421, 559, 561, 562], "target_net_updat": [415, 421, 562, 622, 623], "softupd": [415, 622, 623, 625, 626, 629, 632, 637], "target_net_updater_hook": 415, "post_optim": [415, 623], "versatil": [416, 627], "optim_steps_per_batch": [416, 420, 421, 475, 623], "clip_grad_norm": [416, 420, 421, 475], "clip_norm": [416, 420, 421, 475], "progress_bar": [416, 420, 421, 475], "save_trainer_interv": [416, 420, 421, 475], "log_interv": [416, 420, 421, 475, 623], "save_trainer_fil": [416, 420, 421, 475], "async_collect": [416, 418, 420, 475], "utd": [416, 418, 622, 625], "utd_ratio": 416, "log_tim": [416, 420, 475], "logtim": [416, 420], "updateweight": [416, 420, 475, 616, 623], "load_from_fil": [416, 420, 421], "update_count": 418, "utdr_hook": 418, "update_weights_interv": [419, 623], "policy_weights_gett": 419, "weight_update_map": [419, 420, 475], "post_step": [419, 623], "num_epoch": [420, 475, 624, 638], "enable_log": [420, 421], "log_act": [420, 421], "log_observ": [420, 421], "add_ga": [420, 475], "ppotrainerconfig": 420, "welcom": [420, 594, 627], "elsewher": 421, "3e": [421, 624, 625, 637, 638], "configbas": [422, 423, 424, 425], "storageensemblewrit": 439, "batched_env_typ": 442, "make_batched_env": 442, "make_gym_env": 448, "mogymenv": 452, "meltingpotenv": 453, "openmlenv": 455, "openspielenv": 456, "pettingzooenv": [457, 637], "robohiveenv": 458, "smacv2env": 459, "unity_mlag": 460, "unitymlagentsenv": 460, "activationconfig": [466, 467], "normconfig": 466, "aggregatorconfig": 466, "layerconfig": 467, "valuemodelconfig": 468, "mlpconfig": [470, 471, 472], "eval_mod": 470, "extract_normal_param": 470, "param_kei": 470, "_make_tanh_normal_model": 470, "_make_tensordict_modul": 471, "_make_value_model": 472, "networkconfig": 472, "loss_typ": [473, 474], "_make_ppo_loss": 474, "_make_ppo_train": 475, "sensibl": 475, "batchsizetransform": [480, 626], "binarizereward": 481, "burnintransform": 482, "centercrop": 485, "cliptransform": 486, "conditionalpolicyswitch": 488, "dtypecasttransform": 491, "devicecasttransform": 492, "discreteactionproject": 493, "gym_transform": 495, "endoflifetransform": 495, "exclude_kei": 496, "finitetensordictcheck": 497, "flattenobserv": 498, "frameskiptransform": 499, "linearisereward": 504, "multiact": 505, "rb_transform": 506, "multisteptransform": 506, "noopresetenv": [507, 643, 644], "permutetransform": 509, "pinmemorytransform": 510, "r3mtransform": [511, 640], "crop_siz": 512, "randomcroptensordict": [512, 622], "key_map": 514, "reward2gotransform": 516, "include_kei": 520, "signtransform": 521, "squeezetransform": 522, "targetreturn": 525, "primer_spec": 526, "timemaxpool": 527, "vc1transform": 535, "viprewardtransform": 536, "viptransform": 537, "lambd": 541, "t0": [541, 626, 632], "weight_decai": [541, 542, 543, 544, 545, 546, 548, 549, 550, 551, 553, 622, 623], "foreach": [541, 542, 543, 545, 549, 551, 552, 553], "maxim": [541, 542, 543, 545, 551, 552, 553, 622, 629, 639], "asgd": 541, "rho": 542, "adadelta": 542, "lr_decai": 543, "initial_accumulator_valu": 543, "adagrad": 543, "amsgrad": [544, 545], "fuse": 545, "adamw": 545, "002": [546, 549], "adamax": 546, "max_it": 547, "max_ev": 547, "tolerance_grad": 547, "07": [547, 622, 623, 624, 637], "tolerance_chang": 547, "09": [547, 622, 623, 624, 637], "history_s": 547, "line_search_fn": 547, "lbfg": 547, "lion": 548, "momentum_decai": 549, "004": 549, "nadam": 549, "radam": 550, "momentum": [551, 553], "rmsprop": 551, "eta": 552, "step_siz": 552, "rprop": 552, "dampen": 553, "nesterov": 553, "sgd": 553, "sparseadam": 554, "dictconfig": [555, 556, 557, 558, 560, 561, 562, 563, 566], "unknowingli": 555, "annealing_fram": [555, 622], "init_env_step": [555, 556, 622], "proof_environ": [556, 622], "sta": 556, "ot": 556, "actor_model_explor": [557, 558, 622], "make_env_kwarg": [557, 558], "replayargsconfig": 560, "constitu": 562, "egreedywrapp": 562, "ddpgloss": [562, 608, 622, 629, 637, 643], "env_proof": 562, "obs_spec": 562, "net_valu": 562, "dir": [562, 623], "gettempdir": 562, "transformed_env_constructor": 563, "num_env_per_collector": [564, 565], "_multi_sync": 565, "video_tag": 566, "norm_obs_onli": 566, "custom_env_mak": 566, "custom_env": 566, "return_transformed_env": 566, "action_dim_gsd": 566, "state_dim_gsd": 566, "obs_norm_state_dict": 566, "weights_buff": 567, "ONE": [567, 572, 575, 581], "receive_initial_weight": 567, "interf": 567, "surround": [567, 638], "send_initial_weight": 567, "send_weight": [567, 572, 575, 577, 579, 582, 584], "send_weights_async": [567, 569, 572, 575], "acknowledg": [567, 568, 569, 570, 573, 574, 576, 577, 578, 581, 583, 589], "wait_ack": [567, 569, 572, 575], "setup_connection_and_weights_on_send": [567, 569, 572, 575, 577, 579], "3600": 568, "get_store_info": 568, "hour": 568, "apply_weight": [568, 570, 571, 573, 574, 576, 578, 580, 581, 583, 585, 587, 589], "rendez": [568, 570, 573, 574, 576, 578, 581, 583, 589], "vou": [568, 570, 573, 574, 576, 578, 581, 583, 589], "_setup_connection_and_weights_on_sender_impl": [568, 569, 570, 573, 574, 576, 578, 581, 583, 589], "_setup_connection_and_weights_on_receiver_impl": [568, 570, 573, 574, 576, 578, 581, 583, 589], "create_transport": [568, 570, 571, 573, 574, 576, 578, 581, 583, 589], "_run_process": [568, 570, 571, 573, 574, 576, 578, 581, 583, 589], "prepare_weight": [568, 570, 571, 573, 574, 576, 578, 581, 583, 589], "lookup": [568, 570, 571, 573, 574, 576, 578, 581, 583, 589, 623], "sharedmemweightsyncschem": [568, 570, 571, 573, 574, 576, 581, 583, 589], "receiver_transport": [568, 570, 571, 573, 574, 576, 578, 581, 583, 589], "sender_transport": [568, 570, 571, 573, 574, 576, 578, 581, 583, 589], "shared_transport": [568, 570, 571, 573, 574, 576, 578, 581, 583, 589], "weight_queu": 569, "ack_queu": 569, "listen": [570, 578], "phase": [570, 638, 641], "benefici": 570, "transmiss": [570, 574, 575, 576, 578, 580], "wait_async": [570, 578], "_unique_weight": [570, 578], "_receiver_shared_weight": [570, 578], "worker_rank": [572, 573], "deadlock": 572, "somecollector": 574, "transform_modul": 574, "connection_info_nam": [574, 575, 576], "collis": [574, 576, 637, 638], "remote_actor": [574, 575, 576], "connection_info": 575, "set_model": 575, "_setup_distributed_connection_send": 575, "pure": 577, "register_weight": 577, "params_map": [577, 581], "basecontext": 577, "init_queu": 577, "send_ack": 577, "60": [577, 623, 624, 635, 637, 638, 643], "unique_weight": 577, "_send_instruct": 578, "notifi": 578, "extract_a": 580, "extract_weight": [580, 590], "device_map_fn": 581, "gpus_per_replica": [582, 589, 594], "init_all_workers_group": [582, 587, 588, 589, 594], "check_connect": [582, 584], "mono": 582, "remote_addr": [583, 584], "local_addr": [583, 584], "tmp": 583, "mnt": 583, "nf": 583, "mount": 583, "create_receiv": [583, 585, 589], "vllmdoublebufferweightreceiv": 583, "llm_engin": 583, "model_executor": 583, "create_send": [583, 586, 589], "vllmdoublebufferweightsend": 583, "vllmdoublebuffertransport": 583, "vllmdoublebuffersyncschem": [585, 586, 594], "load_weight": 585, "poll_and_appli": [585, 587], "_update_weights_with_nccl_broadcast_simpl": 585, "180": 585, "register_model": [586, 588, 589, 594], "vllmweightsyncschem": [587, 588, 594], "get_actor": 587, "particip": [587, 589], "torchrpcvllmreceiv": 587, "rpc_sync": 587, "get_metadata": 587, "grpc": 588, "vllmcollectivetransport": [588, 589], "bandwidth": 588, "torchrpcvllmsend": 588, "rpc_async": 588, "prepare_rec": 588, "tp_size": 589, "dp_size": 589, "pp_size": 589, "approxim": [589, 638, 644], "handshak": 589, "12345": 589, "vllmweightsend": 589, "vllmweightreceiv": 589, "init_send": 589, "sender_actor": 589, "init_receiv": 589, "receiver_actor": 589, "llmlossoutput": 592, "cispoloss": 592, "mcadvantag": 592, "sftloss": [592, 594], "sftlossoutput": 592, "topkrewardselector": 592, "sweep": 592, "journei": 593, "textbook": 593, "highlight": [593, 637], "ever": [593, 638], "bump": 593, "pr": [593, 594], "five": [594, 623], "make_polici": 594, "29500": 594, "_weight_send": 594, "training_model": 594, "policy_version_track": 594, "migrat": 594, "ref_servic": 594, "step_data": 594, "gsm8krewardpars": 594, "ifevalscor": 594, "excel": 594, "bsz": 594, "num_token": 594, "predetermin": 594, "hasattr": [594, 622], "text_complet": 594, "sophist": [594, 624, 638], "format_compon": 594, "structure_scor": 594, "think_scor": 594, "answer_scor": 594, "completion_bonu": 594, "potential_answ": 594, "compl": 594, "et": 594, "parseerror": 594, "unnecessari": 594, "\u03b5": 601, "satisfi": 601, "consistentdropoutmodul": 601, "egreedymodul": [601, 623, 625, 626, 628, 632], "ornsteinuhlenbeckprocessmodul": [601, 622, 628], "duelingcnndqnet": [601, 623], "ddpgcnnactor": 601, "ddpgcnnqnet": 601, "ddpgmlpactor": [601, 622], "ddpgmlpqnet": [601, 622], "onlinedtactor": 601, "dtactor": 601, "dreameractor": 601, "obsencod": 601, "obsdecod": 601, "rssmposterior": 601, "rssmprior": 601, "rssmrollout": 601, "independentnorm": 601, "tanhdelta": [601, 622, 637], "truncatednorm": 601, "reusabl": [608, 622, 641], "trainabl": [608, 622, 629, 640], "\u03bb": 608, "customiz": [608, 625], "total_loss": [608, 629], "distributionaldqnloss": [608, 623], "iqlloss": 608, "discreteiqlloss": 608, "cqlloss": 608, "discretecqlloss": 608, "ppoloss": 608, "a2closs": 608, "reinforceloss": 608, "discretesacloss": 608, "td3loss": 608, "redqloss": 608, "crossqloss": 608, "td3bcloss": 608, "gailloss": 608, "dtloss": 608, "onlinedtloss": 608, "dreameractorloss": 608, "dreamermodelloss": 608, "dreamervalueloss": 608, "agnost": [615, 634], "monarch": 615, "anywher": 615, "tenant": 615, "my_namespac": 615, "tokenizerservic": 615, "50000": 615, "my_servic": 615, "myserviceclass": 615, "arg1": 615, "value1": 615, "arg2": 615, "value2": 615, "gpu_servic": 615, "gpuservic": 615, "collid": [615, 626, 638], "register_servic": 615, "shared_token": 615, "use_servic": 615, "worker2": 615, "train_servic": 615, "eval_servic": 615, "30000": 615, "infrequ": 615, "use_distributed_servic": 615, "queu": 615, "persistentpythonprocess": 615, "_lock": 615, "next_idx": 615, "python_executor_fast": 615, "python_executor_heavi": 615, "fast_env": 615, "heavy_env": 615, "mycustomservic": 615, "param1": 615, "tokenizer_servic": 615, "servicecontext": 615, "__enter__": 615, "__exit__": 615, "myservic": 615, "stick": [615, 626], "distributed_servic": 615, "python_executor_servic": 615, "test_servic": 615, "test_python_executor_servic": 615, "ref_llm": [615, 634], "torchsnapshot": 616, "logscalar": [616, 623], "mlflowlogg": 616, "trackiologg": 616, "get_logg": 616, "generate_exp_nam": 616, "batchsubsampl": 616, "clearcudacach": 616, "countframeslog": 616, "optimizerhook": [616, 623], "logvalidationreward": [616, 622, 623], "replaybuffertrain": [616, 623], "rewardnorm": 616, "selectkei": 616, "targetnetupdaterhook": 616, "utdrhook": 616, "galleri": [621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "mem": [621, 642], "mb": [621, 642], "coding_ddpg": [621, 622, 642], "497": [621, 622, 642], "multiagent_competitive_ddpg": [621, 637, 642], "633": [621, 637, 642], "coding_dqn": [621, 623, 642], "000": [621, 625, 642], "coding_ppo": [621, 624, 642], "dqn_with_rnn": [621, 625, 642], "llm_wrapper": [621, 635, 642], "multi_task": [621, 636, 642], "multiagent_ppo": [621, 638, 642], "pretrained_model": [621, 640, 642], "rb_tutori": [621, 641, 642], "torchrl_env": [621, 642, 644], "author": [622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 637, 638, 639, 641, 644], "vincent": [622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 639, 641, 644], "moen": [622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 639, 641, 644], "assembl": 622, "ground": [622, 639], "transpar": [622, 625], "bash": 622, "is_fork": [622, 623, 624, 625, 637, 638, 640], "get_start_method": [622, 623, 624, 625, 637, 638, 640], "collector_devic": 622, "swappabl": 622, "smth": 622, "loss_dict": 622, "oblivi": [622, 624, 641], "elementari": 622, "didact": [622, 626], "dilut": 622, "pessimist": [622, 623, 624], "target_actor_network_param": 622, "actor_in_kei": 622, "actor_crit": 622, "compromis": 622, "td0estim": 622, "td1estim": 622, "tdlambdaestim": 622, "hp": 622, "_value_estim": 622, "hold_out_param": 622, "_loss_actor": 622, "td_copi": 622, "actor_network_param": [622, 637], "value_network_param": [622, 637], "distance_loss": 622, "_loss_valu": 622, "pred_val": 622, "target_value_network_param": 622, "smooth": [622, 623, 629], "pow": 622, "glue": 622, "_forward": 622, "remaind": 622, "env_librari": 622, "env_task": 622, "env_arg": [622, 623], "torchr": 622, "rescal": 622, "presum": 622, "make_transformed_env": 622, "reward_sc": 622, "parallel_env_constructor": 622, "env_per_collector": 622, "transform_state_dict": 622, "make_t_env": 622, "seem": [622, 625, 627], "cheat": 622, "10m": 622, "nutshel": 622, "cautiou": 622, "thousand": [622, 625], "get_env_stat": 622, "proof_env": 622, "5000": [622, 623, 624, 626, 632], "recal": [622, 624, 634, 641], "materi": 622, "make_ddpg_actor": 622, "q_net": 622, "qnet": 622, "suggest": [622, 638], "tight": 622, "10_000": [622, 624], "traj_len": [622, 625], "make_record": 622, "recorder_obj": 622, "pick": [622, 623, 628, 634], "make_replay_buff": 622, "buffer_s": [622, 623, 625], "random_crop_len": 622, "prb": 622, "buffer_scratch_dir": [622, 623, 625, 630, 640], "dataflow": 622, "ceil_div": 622, "update_to_data": 622, "realiz": 622, "ve": [622, 625, 632, 634], "_must_": 622, "outdat": 622, "trick": [622, 623], "despit": 622, "hardupd": [622, 629], "optimizer_actor": 622, "optimizer_valu": 622, "total_collection_step": 622, "rewards_ev": 622, "collected_fram": 622, "r0": 622, "numel": [622, 624, 626, 632, 637, 640, 641], "current_fram": [622, 637], "sampled_tensordict": 622, "gn1": 622, "clip_grad_norm_": [622, 624, 637, 638, 639], "gn2": 622, "gn": [622, 639], "td_record": 622, "rn": 622, "2f": 622, "800": [622, 623], "2479": 622, "84it": 622, "1600": [622, 623], "1403": [622, 624], "12it": [622, 623], "2400": [622, 623], "1743": 622, "68it": [622, 623, 624], "3200": [622, 623], "1942": 622, "4000": [622, 623, 624], "2082": 622, "64it": [622, 623, 625], "4800": [622, 623], "2191": 622, "15it": [622, 623], "56": [622, 623, 639], "5600": 622, "2269": 622, "96it": 622, "62": [622, 623], "65": [622, 623], "237": 622, "59": [622, 623], "6400": 622, "1549": 622, "19it": [622, 623], "341": 622, "89": [622, 623], "7200": 622, "1284": 622, "34it": 622, "145": 622, "197": 622, "57": [622, 623], "8000": [622, 624], "223": 622, "246": 622, "95": [622, 623, 624, 625], "8800": 622, "1031": 622, "39it": 622, "446": 622, "61": [622, 623], "498": 622, "9600": 622, "861": 622, "52": [622, 623, 624], "119": 622, "384": [622, 623], "54": [622, 623, 637], "10400it": 622, "773": 622, "91it": [622, 623], "185": 622, "313": 622, "plot": [622, 624, 625, 637, 638, 639], "mention": [622, 625, 641, 644], "matplotlib": [622, 624, 625, 626, 637, 638, 639, 641, 644], "pyplot": [622, 624, 625, 626, 637, 638, 639, 641, 644], "plt": [622, 624, 625, 626, 637, 638, 639, 641, 644], "legend": [622, 637], "xlabel": [622, 625, 638, 639], "ylabel": [622, 638], "tight_layout": 622, "concret": [622, 624, 634], "takeawai": [622, 623, 626, 634], "distpatch": 622, "jupyt": [622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "ipynb": [622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "sphinx": [622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 643, 644], "road": 623, "aspect": [623, 629], "highest": [623, 628], "prerequisit": [623, 625, 634], "amort": [623, 624], "cart": 623, "pole": 623, "un": 623, "actuat": 623, "frictionless": 623, "is_notebook": 623, "shell": 623, "get_ipython": 623, "__class__": [623, 635], "zmqinteractiveshel": 623, "qtconsol": 623, "terminalinteractiveshel": 623, "ipython": [623, 638, 639], "nameerror": [623, 635, 637], "umbrella": 623, "misplac": 623, "misus": 623, "64x64": 623, "motion": [623, 639], "obs_norm_sd": 623, "mp_context": [623, 636, 644], "get_norm_stat": 623, "test_env": 623, "mathbb": 623, "rightarrow": 623, "make_model": 623, "dummy_env": 623, "init_bia": 623, "exploration_modul": [623, 625, 626, 628, 632], "eps_greedy_v": 623, "eps_greedy_val_env": 623, "actor_explor": 623, "get_replay_buff": 623, "n_optim": [623, 629, 630], "parametriz": 623, "get_collector": 623, "bunch": 623, "ubiquit": [623, 627], "get_loss_modul": 623, "target_updat": [623, 637], "995": [623, 624], "hopefulli": 623, "sensit": [623, 625], "variat": 623, "2e": [623, 639], "wd": 623, "upd": 623, "harder": [623, 643], "5_000": 623, "500000": 623, "005": [623, 637], "mandatori": [623, 624, 638, 639], "fairer": 623, "budget": 623, "dqn_exp_": 623, "uuid1": [623, 644], "0737": 623, "cumbersom": 623, "buffer_hook": 623, "trainerhookbas": 623, "aliv": 623, "total_reward": 623, "ti": 623, "72it": 623, "3688": 623, "_std": 623, "1462": 623, "9259": 623, "53it": 623, "4295": 623, "1204": 623, "01it": [623, 624, 637], "3415": 623, "1504": 623, "58it": 623, "3566": 623, "1519": 623, "3991": 623, "1374": 623, "58": [623, 639], "224": [623, 639], "49": 623, "70it": 623, "47": 623, "41it": 623, "288": 623, "80it": [623, 639], "3445": 623, "1524": 623, "11it": 623, "352": 623, "40it": 623, "53": [623, 639], "20it": 623, "416": 623, "14it": 623, "448": 623, "56it": 623, "480": [623, 640], "99it": [623, 624], "95it": 623, "3778": 623, "1485": 623, "544": 623, "27it": 623, "3808": 623, "1498": 623, "576": 623, "13it": [623, 624], "608": 623, "4021": 623, "1384": 623, "640": 623, "63": 623, "3535": 623, "1561": 623, "672": 623, "87it": 623, "704": 623, "05it": [623, 637], "3869": 623, "1461": 623, "736": [623, 626], "94it": 623, "1536": 623, "768": [623, 639], "832": 623, "864": 623, "93it": 623, "896": 623, "928": 623, "59it": 623, "4082": 623, "1378": 623, "960": 623, "81it": 623, "992": 623, "31it": 623, "1056": 623, "66it": [623, 625], "1088": 623, "06it": 623, "1120": 623, "1152": 623, "4173": 623, "1331": 623, "1184": 623, "1216": 623, "1248": 623, "78it": [623, 624, 639], "1280": 623, "24it": 623, "1344": 623, "46it": [623, 624], "1376": 623, "1408": 623, "1440": 623, "29it": 623, "1472": 623, "26it": 623, "3718": 623, "1477": 623, "55": 623, "1568": 623, "61it": 623, "1632": 623, "1728": 623, "03it": 623, "1760": 623, "1792": 623, "55it": 623, "1824": 623, "49it": 623, "1856": 623, "1888": 623, "85it": 623, "1920": 623, "1952": 623, "52it": 623, "1984": 623, "2016": 623, "83it": 623, "2080": 623, "75it": 623, "2112": 623, "2144": 623, "18it": 623, "2176": 623, "51it": 623, "2208": 623, "97it": 623, "2240": 623, "28it": 623, "2272": 623, "09it": 623, "10it": 623, "2336": 623, "89it": 623, "2368": 623, "07it": [623, 624], "77it": 623, "2432": 623, "2464": 623, "2496": 623, "73it": 623, "2528": 623, "76it": [623, 639], "2560": 623, "21it": 623, "2592": 623, "2624": 623, "2656": 623, "2688": 623, "67it": [623, 639], "2720": 623, "2752": 623, "2784": 623, "2816": 623, "2848": 623, "00it": 623, "2880": 623, "16it": 623, "2912": 623, "25it": 623, "2944": 623, "62it": 623, "2976": 623, "3040": 623, "3072": 623, "22it": 623, "3104": 623, "17it": 623, "3136": [623, 626], "3168": 623, "88it": 623, "3232": 623, "0909": 623, "3264": 623, "66": 623, "3296": 623, "3328": 623, "3360": 623, "33it": 623, "3392": 623, "3424": 623, "3456": 623, "42it": 623, "3488": 623, "3520": 623, "3552": 623, "3584": 623, "3616": 623, "69it": [623, 639], "3648": 623, "3680": 623, "3712": 623, "3744": 623, "3776": 623, "38it": 623, "3840": 623, "3872": 623, "3904": 623, "3936": 623, "3968": 623, "4032": 623, "4064": 623, "44it": 623, "4128": 623, "4160": 623, "43it": 623, "4192": 623, "4224": 623, "85": 623, "4256": 623, "4288": 623, "4320": 623, "4352": 623, "71it": [623, 624, 639], "4384": 623, "4416": 623, "4448": 623, "90": [623, 624, 637], "4480": 623, "4512": 623, "91": [623, 624], "4544": 623, "92": 623, "4576": 623, "4608": 623, "93": [623, 638], "4640": 623, "4704": 623, "4736": 623, "4768": 623, "04it": 623, "97": [623, 639], "4832": 623, "4864": 623, "4896": 623, "4928": 623, "4960": 623, "4992": 623, "74it": 623, "5024it": 623, "print_csv_files_in_fold": 623, "folder_path": 623, "csv_file": 623, "output_str": 623, "dirpath": 623, "endswith": 623, "yr": [623, 626, 640, 641], "7r52b6851h76_ltpq30gy8f40000gn": [623, 626, 640, 641], "tmpm7ncewnl": 623, "dqn_exp_f62d8f6c": 623, "f26e": 623, "11f0": [623, 644], "919f": 623, "afd6db88a225": 623, "grad_norm_0": 623, "502547264099121": 623, "370267868041992": 623, "6163973808288574": 623, "572138786315918": 623, "2857439517974854": 623, "7632076740264893": 623, "625221252441406": 623, "5397262573242188": 623, "4898245334625244": 623, "37784188985824585": 623, "4294527471065521": 623, "39912936091423035": 623, "32328468561172485": 623, "18408268690109253": 623, "27264344692230225": 623, "2559831440448761": 623, "29441505670547485": 623, "3235989212989807": 623, "29620054364204407": 623, "1996915340423584": 623, "23214533925056458": 623, "090909004211426": 623, "10000001639127731": 623, "14853504300117493": 623, "12037014216184616": 623, "13742616772651672": 623, "qvaluenetwork": 623, "worst": 623, "accuraci": 623, "fanci": [623, 630], "921": 623, "talk": 624, "six": 624, "invent": 624, "theta_k": 624, "pi_": 624, "exceed": 624, "indispens": 624, "loader": 624, "analyz": 624, "lingua": 624, "franca": 624, "defaultdict": [624, 639], "max_grad_norm": [624, 637, 638], "sub_batch_s": 624, "entropy_ep": [624, 638], "inverteddoublependulum": 624, "transmit": 624, "stai": 624, "told": 624, "confid": [624, 637, 638], "ran": 624, "f_": 624, "mu_": 624, "difficulti": [624, 644], "brought": [624, 625, 628], "d_ob": 624, "d_action": 624, "said": 624, "value_modul": [624, 643], "briefli": [624, 637, 638], "refil": [624, 638], "easiest": [624, 629, 637, 638], "hide": [624, 637, 638], "mathemat": [624, 637, 638], "tradeoff": [624, 638], "advantage_modul": 624, "entropy_coef": [624, 638], "critic_coef": 624, "lr_schedul": [624, 639], "cosineannealinglr": [624, 639], "eval_str": 624, "tensordict_data": [624, 638], "data_view": [624, 638], "subdata": [624, 637, 638], "cum_reward_str": 624, "stepcount_str": 624, "param_group": [624, 637], "lr_str": 624, "eval_rollout": 624, "969": 624, "5813": 624, "0935": 624, "0003": 624, "949": 624, "1157": 624, "3000": 624, "937": 624, "929": 624, "37it": 624, "1653": 624, "951": 624, "2007": 624, "6000": 624, "35it": 624, "7000": 624, "983": 624, "2408": 624, "2447": 624, "9000": 624, "1018": 624, "2572": 624, "figsiz": [624, 639], "subplot": [624, 637, 639, 644], "916": [624, 639], "84x84": [625, 626], "accessori": 625, "stamp": 625, "backbon": [625, 628, 636, 643], "emb": 625, "n_cell": 625, "bidirect": 625, "wouldn": 625, "qval": 625, "stoch_polici": 625, "opportun": [625, 637], "uniniti": 625, "again": [625, 626, 627, 628, 630, 638, 640, 641, 644], "strongli": 625, "sake": [625, 640, 641], "longest": 625, "enough": [625, 641], "163": [625, 640], "23it": 625, "227": 625, "150": 625, "271": 625, "60it": 625, "242": 625, "257": 625, "strong": 626, "impress": 626, "edg": 626, "arduino": 626, "raspberri": 626, "alon": 626, "examplifi": 626, "ship": 626, "nearest": 626, "value_mlp": [626, 632], "init_rand_step": [626, 632], "total_count": [626, 632], "total_episod": [626, 632], "screen": [626, 637], "color": [626, 637], "clearer": [626, 628], "unblock": 626, "policy_transform": 626, "fake_td": 626, "exported_polici": 626, "div": 626, "graph_modul": 626, "print_read": 626, "graphmodul": 626, "p_module_1_module_0_module_0_module_0_0_weight": 626, "f32": 626, "p_module_1_module_0_module_0_module_0_0_bia": 626, "p_module_1_module_0_module_0_module_0_2_weight": 626, "p_module_1_module_0_module_0_module_0_2_bia": 626, "p_module_1_module_0_module_0_module_0_4_weight": 626, "p_module_1_module_0_module_0_module_0_4_bia": 626, "p_module_1_module_0_module_0_module_1_0_weight": 626, "p_module_1_module_0_module_0_module_1_0_bia": 626, "p_module_1_module_0_module_0_module_1_2_weight": 626, "p_module_1_module_0_module_0_module_1_2_bia": 626, "b_module_1_module_1_eps_init": 626, "b_module_1_module_1_eps_end": 626, "b_module_1_module_1_ep": 626, "u8": 626, "vmoen": [626, 643], "aten": 626, "_assert_tensor_metadata_default": 626, "_assert_tensor_metadata": 626, "upsample_nearest2d": 626, "vec": 626, "getitem": 626, "getitem_1": 626, "getitem_2": 626, "mul": 626, "mul_1": 626, "587": 626, "mul_2": 626, "_assert_tensor_metadata_default_1": 626, "to_1": 626, "unsqueeze_1": 626, "553": 626, "_conv_forward": 626, "143": 626, "conv2d_1": 626, "relu_1": 626, "conv2d_2": 626, "relu_2": 626, "using_int": 626, "relu_3": 626, "linear_1": 626, "615": 626, "action_func_map": 626, "i64": 626, "_assert_tensor_metadata_default_2": 626, "to_2": 626, "620": 626, "action_value_func": 626, "unsqueeze_2": 626, "group0": 626, "group0_agent0_ob": 626, "group0_agent0": 626, "agent0_ob": 626, "obvious": 626, "digress": 626, "exported_stochastic_polici": 626, "175": 626, "action_tensordict": 626, "lt": 626, "b8": 626, "177": 626, "expand_as_right": 626, "201": 626, "204": 626, "hidden0": 626, "hidden1": 626, "recurrent_polici": 626, "happi": 626, "fake_ob": 626, "fake_hidden0": 626, "fake_hidden1": 626, "fake_is_init": 626, "exported_recurrent_polici": 626, "p_module_1_lstm_weight_ih_l0": 626, "p_module_1_lstm_weight_hh_l0": 626, "p_module_1_lstm_bias_ih_l0": 626, "p_module_1_lstm_bias_hh_l0": 626, "p_module_1_lstm_weight_ih_l1": 626, "p_module_1_lstm_weight_hh_l1": 626, "p_module_1_lstm_bias_ih_l1": 626, "p_module_1_lstm_bias_hh_l1": 626, "p_module_2_module_0_weight": 626, "p_module_2_module_0_bia": 626, "p_module_2_module_2_weight": 626, "p_module_2_module_2_bia": 626, "p_module_2_module_4_weight": 626, "p_module_2_module_4_bia": 626, "642": 626, "tensordict_exec": 626, "_run_modul": 626, "unsqueeze_3": 626, "703": 626, "tensordict_shap": 626, "unsqueeze_4": 626, "unsqueeze_5": 626, "unsqueeze_6": 626, "unsqueeze_7": 626, "705": 626, "is_init_expand": 626, "unsqueeze_8": 626, "unsqueeze_9": 626, "unsqueeze_10": 626, "737": 626, "zeros_lik": [626, 639], "738": 626, "739": 626, "where_1": 626, "745": 626, "_lstm": 626, "select_1": 626, "transpos": 626, "transpose_1": 626, "308": 626, "hx": 626, "unbind_1": 626, "getitem_3": 626, "unbind_2": 626, "getitem_4": 626, "getitem_5": 626, "getitem_6": 626, "getitem_7": 626, "getitem_8": 626, "sigmoid": 626, "sigmoid_1": 626, "sigmoid_2": 626, "tanh_1": 626, "linear_2": 626, "linear_3": 626, "add_2": 626, "chunk_1": 626, "getitem_9": 626, "getitem_10": 626, "getitem_11": 626, "getitem_12": 626, "sigmoid_3": 626, "sigmoid_4": 626, "tanh_2": 626, "sigmoid_5": 626, "mul_3": 626, "mul_4": 626, "add_3": 626, "tanh_3": 626, "mul_5": 626, "stack_1": 626, "transpose_2": 626, "transpose_3": 626, "stack_3": 626, "758": 626, "reshape_1": 626, "reshape_2": 626, "reshape_3": 626, "reshape_4": 626, "linear_4": 626, "432": 626, "tanh_4": 626, "linear_5": 626, "tanh_5": 626, "linear_6": 626, "squeeze_1": 626, "squeeze_2": 626, "squeeze_3": 626, "squeeze_4": 626, "squeeze_5": 626, "squeeze_6": 626, "platform": [626, 643], "aoti": 626, "_inductor": 626, "aoti_compile_and_packag": 626, "aoti_load_packag": 626, "pt2": 626, "pkg_path": 626, "package_path": 626, "compiled_modul": 626, "cpython": 626, "maco": 626, "aarch64": 626, "copyreg": 626, "futurewarn": 626, "treespec": 626, "leafspec": 626, "__new__": 626, "tmpoqb__b3a": 626, "onnxruntim": 626, "showcas": [626, 639], "plenti": 626, "tensorrt": 626, "android": 626, "aleinterfac": 626, "rom": 626, "loadrom": 626, "get_rom_path": 626, "reset_gam": 626, "screen_ob": 626, "getscreenrgb": 626, "tick_param": 626, "bottom": 626, "labelleft": 626, "labelbottom": 626, "imshow": [626, 644], "onnx_file_path": 626, "dynamo": 626, "as_tensor": 626, "ort_sess": 626, "inferencesess": 626, "cpuexecutionprovid": 626, "onnxruntime_input": 626, "get_input": 626, "onnx_result": 626, "onnx_polici": 626, "onnxruntime_output": 626, "num_step": 626, "decomposit": 626, "took": 626, "301": 626, "9249": 626, "msec": 626, "3019": 626, "828": 626, "deploy": 626, "086": 626, "topic": [627, 628, 629], "straight": 627, "backtrack": 627, "reset_with_act": 627, "7471": 627, "stepped_data": 627, "spatial": 627, "useless": 627, "policyless": 627, "glanc": 627, "appreci": 627, "examin": [627, 637], "013": 627, "tackl": 628, "intric": 628, "delv": 628, "extractor": 628, "analog": 628, "realm": 628, "exploration_polici": [628, 637], "2d": [628, 637, 638], "innov": [628, 629], "rollout_explor": 628, "027": 628, "sole": 629, "n_collect": 629, "get_next_batch": 629, "ddpg_loss": 629, "prove": 629, "reliev": 629, "030": 629, "accustom": 630, "surprisingli": 630, "matter": 630, "art": [630, 637, 638], "pseudo": [630, 639], "countless": 630, "yourself": [630, 637, 638], "434": 630, "chapter": 631, "everywher": 631, "log_scalar": 631, "my_scalar": 631, "excess": 631, "048": 631, "lesson": 632, "voluntarili": 632, "training_loop": 632, "video_record": 632, "arbitrarili": 632, "num": 632, "t1": 632, "conclud": [632, 640], "637": 632, "tutorials_python": 633, "tutorials_jupyt": 633, "playwright": 634, "autom": 634, "__future__": 634, "browsertransform": 634, "filterwarn": [634, 635], "browser_transform": 634, "rewardtransform": 634, "last_item": 634, "execute_tool_act": 634, "current_st": 634, "nllm": 634, "nenviron": 634, "button": 634, "css": 634, "btnk": 634, "extract_typ": 634, "llm_browser": 634, "suppress": 635, "vllm_use_v1": 635, "5b": 635, "canada": 635, "vllm_wrapper": 635, "data_histori": 635, "nload": 635, "transformers_token": 635, "transformers_wrapp": 635, "result_tf": 635, "151643": 635, "navigationopt": 635, "icod": 635, "nicod": 635, "nwhat": 635, "ottawa": 635, "lauderdal": 635, "endoftext": 635, "data_text": 635, "vllm_text_wrapp": 635, "result_vllm_text": 635, "nvllm": 635, "transformers_text_wrapp": 635, "result_tf_text": 635, "vllm_logprobs_wrapp": 635, "result_vllm_lp": 635, "transformers_logprobs_wrapp": 635, "result_tf_lp": 635, "ntensorclass": 635, "analysi": 635, "ntext": 635, "__annotations__": 635, "ntoken": 635, "nlogprob": 635, "nmask": 635, "nerror": 635, "invalid_mod": 635, "nrl": 635, "env_stat": 635, "action_output": 635, "753": 635, "env1_obs_kei": 636, "observation_stand": 636, "env2_obs_kei": 636, "observation_walk": 636, "tdreset1": 636, "tdreset2": 636, "policy_common": 636, "policy_stand": 636, "policy_walk": 636, "env1_mak": 636, "env2_mak": 636, "_single_task": 636, "td_rollout": 636, "390": 636, "matteo": [637, 638], "bettini": [637, 638], "benchmarl": [637, 638], "simple_tag": 637, "maddpg": [637, 638], "multiagentparticleenviron": 637, "mpe": 637, "centralis": [637, 638], "tie": [637, 638], "iddpg": [637, 638], "optimis": [637, 638], "sutton": [637, 638], "richard": 637, "andrew": 637, "barto": [637, 638], "mit": 637, "press": 637, "2018": 637, "mathbf": [637, 638], "decentralis": [637, 638], "literatur": [637, 638], "overcom": [637, 638], "stationari": [637, 638], "establish": 637, "gui": [637, 638], "multiagentmlp": [637, 638], "is_sphinx": 637, "__sphinx_build__": 637, "n_iter": [637, 638, 639], "evad": 637, "iteration_when_stop_training_evad": 637, "memory_s": 637, "n_optimiser_step": 637, "train_batch_s": 637, "polyak_tau": 637, "furthermor": [637, 638], "chaser": 637, "red": 637, "circl": [637, 638], "touch": [637, 639], "penal": [637, 638], "obstacl": 637, "drag": [637, 638], "elast": [637, 638], "Their": [637, 638], "imped": 637, "n_chaser": 637, "n_evad": 637, "n_obstacl": 637, "use_vma": 637, "simple_tag_v3": 637, "num_good": 637, "num_adversari": 637, "num_obstacl": 637, "max_cycl": 637, "num_vmas_env": [637, 638], "num_good_ag": 637, "num_landmark": 637, "adversary_1": 637, "four": [637, 638, 639], "n_agents_in_that_group": 637, "stress": [637, 638], "paramount": [637, 638], "n_rollout_step": [637, 638], "evolut": [637, 638], "group_nam": 637, "n_agents_in_group": 637, "signifi": [637, 638], "agents_exploration_polici": 637, "utilis": [637, 638], "homogen": [637, 638], "n_obs_per_ag": [637, 638], "n_actions_per_ag": [637, 638], "share_parameters_polici": [637, 638], "policy_net": [637, 638], "n_agent_input": [637, 638], "n_agent_output": [637, 638], "share_param": [637, 638], "_agent": 637, "grant": [637, 638], "converg": [637, 638], "share_parameters_crit": [637, 638], "obs_act": 637, "cat_modul": 637, "critic_modul": 637, "fantast": [637, 638], "reset_td": 637, "interfer": 637, "subject": [637, 639], "flatten_kei": 637, "process_batch": 637, "group_shap": 637, "get_item_shap": [637, 638], "nested_done_kei": 637, "nested_terminated_kei": 637, "desc": [637, 638], "episode_reward_mean_": 637, "episode_reward_mean_map": 637, "train_group_map": 637, "group_batch": 637, "_group": 637, "loss_nam": 637, "episode_reward_mean": [637, 638], "episode_reward_mean_adversari": 637, "episode_reward_mean_ag": 637, "104": 637, "948": 637, "1154": 637, "661": 637, "1030": 637, "proce": 637, "fig": [637, 641], "set_ylabel": 637, "axvlin": 637, "orang": 637, "set_xlabel": 637, "video_logg": 637, "vmas_log": 637, "env_with_rend": 637, "vmas_rend": 637, "print_log_dir": 637, "profici": [637, 638], "qmix": [637, 638], "lidar": 638, "sensor": 638, "mappo": 638, "ippo": 638, "_t": [638, 639], "analys": 638, "visualis": 638, "vmas_devic": 638, "6_000": 638, "minibatch_s": 638, "generalis": 638, "simd": 638, "warp": 638, "todai": 638, "dot": [638, 639], "scenario_nam": 638, "final_rew": 638, "agent_collis": 638, "critic_net": 638, "minibatch": 638, "episode_reward_mean_list": 638, "critic_network_param": 638, "target_critic_network_param": 638, "7215316891670227": 638, "050596803426742554": 638, "8369178771972656": 638, "2151118516921997": 638, "6499273777008057": 638, "xvfb": 638, "pyvirtualdisplai": 638, "1400": 638, "900": 638, "pil": 638, "rendering_callback": 638, "fromarrai": 638, "gif": 638, "save_al": 638, "append_imag": 638, "412": 638, "freeli": 639, "undertaken": 639, "broader": 639, "wider": 639, "acquaint": 639, "avenu": 639, "_apply_to_composit": 639, "default_x": 639, "default_i": 639, "upward": 639, "angular": 639, "sin": 639, "theta_t": 639, "rad": 639, "theta_": 639, "angl": 639, "new_th": 639, "new_thdot": 639, "g_forc": 639, "angle_norm": 639, "albeit": 639, "high_th": 639, "high_thdot": 639, "low_th": 639, "low_thdot": 639, "trivial": 639, "irrelev": 639, "_make_spec": 639, "td_param": 639, "render_fp": 639, "random_": 639, "_make_step": 639, "staticmethod": 639, "skeleton": 639, "sine": 639, "cosin": 639, "sintransform": 639, "costransform": 639, "t_sin": 639, "t_co": 639, "cat_transform": 639, "simple_rollout": 639, "_data": 639, "unexplor": 639, "recreat": 639, "20_000": 639, "init_td": 639, "traj_return": 639, "last_reward": 639, "is_ipython": 639, "inlin": 639, "get_backend": 639, "ion": 639, "gcf": 639, "clear_output": 639, "0748": 639, "519": 639, "0499": 639, "4472": 639, "073": 639, "0685": 639, "0408": 639, "552": 639, "36it": 639, "5154": 639, "9086": 639, "523": 639, "9496": 639, "151": 639, "2608": 639, "5713": 639, "6924": 639, "0866": 639, "1453": 639, "6700": 639, "476": 639, "7778": 639, "7849": 639, "3729": 639, "3500": 639, "7010": 639, "4668": 639, "481": 639, "82it": 639, "9443": 639, "9948": 639, "827": 639, "9183": 639, "8877": 639, "9464": 639, "6394": 639, "0086": 639, "5781": 639, "135": 639, "8833": 639, "2043": 639, "8178": 639, "6492": 639, "3180": 639, "0474": 639, "261": 639, "1177": 639, "9164": 639, "355": 639, "4344": 639, "6101": 639, "367": 639, "86it": 639, "2369": 639, "7775": 639, "206": 639, "6540": 639, "2563": 639, "588": 639, "5841": 639, "3193": 639, "064": 639, "6218": 639, "4440": 639, "215": 639, "4630": 639, "5536": 639, "7140": 639, "9322": 639, "9174": 639, "8955": 639, "488": 639, "0757": 639, "5952": 639, "289": 639, "0834": 639, "3326": 639, "226": 639, "9349": 639, "174": 639, "502": 639, "env_transform": [640, 644], "wiser": 640, "_storag": [640, 641], "tmpwsm528hf": 640, "499": 640, "batteri": 641, "gc": 641, "filesystem": 641, "buffer_list": 641, "lowest": 641, "medium": 641, "buffer_lazytensor": 641, "tempdir": 641, "buffer_lazymemmap": 641, "tmpt97euyu8": 641, "fullest": 641, "mydata": 641, "buffer_lazi": 641, "_i": 641, "artifici": 641, "0893e": 641, "hamper": 641, "hist": 641, "recycl": 641, "reappear": 641, "unfold": 641, "problemat": 641, "4th": 641, "4703": 641, "tensordictmaxvaluewrit": 641, "360": 641, "demo": 643, "icml": 643, "fb": 643, "invest": 643, "media": 643, "predominantli": 643, "data2": 643, "sub_key1": 643, "scturctur": 643, "data_stack": 643, "data_sampl": 643, "_sampler": 643, "_sum_tre": 643, "modulenotfounderror": 643, "backbone_modul": 643, "params_expand": 643, "exec_sequ": 643, "tensordict_exp": 643, "base_modul": 643, "roughli": 643, "tensordicts_prealloc": 643, "tensordicts_stack": 643, "tensordict_rollout": [643, 644], "automatical": 643, "particularili": 643, "concatmodul": 643, "loss_td": 643, "contributor": 643, "curiou": 643, "nascent": 643, "torchrl_demo": 643, "unsupervis": 644, "pygam": 644, "_build_env": 644, "amidar": 644, "assault": 644, "asteroid": 644, "atlanti": 644, "atlantis2": 644, "9408": 644, "deserv": 644, "__episode__": 644, "__trajectory__": 644, "void": 644, "reproduct": 644, "tensordict_tprim": 644, "axesimag": 644, "0x143800290": 644, "inconsist": 644, "wrapper1": 644, "wrapper2": 644, "obviou": 644, "truth": 644, "env_transformed_bi": 644, "stanc": 644, "transformeddistribut": 644, "base_dist": 644, "concat": 644, "mofidi": 644, "transformedenviron": 644, "moderet": 644, "computation": 644, "incom": 644, "amongst": 644, "has_cuda": 644, "device_count": 644, "worri": 644, "convention": 644, "markovian": 644, "3288080526": 644, "bar_": 644, "get_someth": 644, "bar_bee4cba8": 644, "f26c": 644, "bba5": 644, "9bf9e431fd31": 644, "aargh": 644, "is_clos": 644, "foo_list": 644, "_dispatch_caller_parallel": 644, "0x1439a3e60": 644, "bar_c05bba1": 644, "9798": 644, "7fb4bdae8ec1": 644, "bar_c069d9c8": 644, "9370": 644, "3f43e2fb0b23": 644, "bar_c06a8f8a": 644, "ab3f": 644, "97502ba9dfaa": 644, "121": 644, "evolv": 644, "steadi": 644, "approx": 644, "0406": 644, "2210": 644, "0511": 644, "1628": 644, "1473": 644, "1931": 644, "sd": 644, "_extra_st": 644, "observation_ssq": 644, "observation_sum": 644, "reward_count": 644, "reward_ssq": 644, "reward_sum": 644, "1349": 644, "3643": 644, "0270": 644, "1424": 644, "2114": 644, "3046": 644, "absor": 644, "375": 644}, "objects": {"torchrl": [[31, 0, 1, "", "auto_unwrap_transformed_env"], [282, 0, 1, "", "implement_for"], [405, 0, 1, "", "set_auto_unwrap_transformed_env"]], "torchrl.collectors": [[32, 0, 1, "", "AsyncCollector"], [33, 0, 1, "", "BaseCollector"], [34, 0, 1, "", "Collector"], [35, 0, 1, "", "MultiAsyncCollector"], [36, 0, 1, "", "MultiCollector"], [37, 0, 1, "", "MultiProcessedWeightUpdater"], [38, 0, 1, "", "MultiSyncCollector"], [39, 0, 1, "", "RayWeightUpdater"], [40, 0, 1, "", "VanillaWeightUpdater"], [41, 0, 1, "", "WeightUpdaterBase"]], "torchrl.collectors.AsyncCollector": [[32, 1, 1, "", "async_shutdown"], [32, 1, 1, "", "cascade_execute"], [32, 1, 1, "", "enable_profile"], [32, 1, 1, "", "get_cached_weights"], [32, 1, 1, "", "get_model"], [32, 1, 1, "", "get_policy_version"], [32, 1, 1, "", "getattr_env"], [32, 1, 1, "", "getattr_policy"], [32, 1, 1, "", "getattr_rb"], [32, 1, 1, "", "increment_version"], [32, 1, 1, "", "init_updater"], [32, 1, 1, "", "load_state_dict"], [32, 1, 1, "", "pause"], [32, 2, 1, "", "policy_version"], [32, 2, 1, "", "profile_config"], [32, 1, 1, "", "receive_weights"], [32, 1, 1, "", "register_scheme_receiver"], [32, 1, 1, "", "reset"], [32, 1, 1, "", "set_seed"], [32, 1, 1, "", "shutdown"], [32, 1, 1, "", "start"], [32, 1, 1, "", "state_dict"], [32, 1, 1, "", "update_policy_weights_"], [32, 2, 1, "", "worker_idx"]], "torchrl.collectors.BaseCollector": [[33, 1, 1, "", "async_shutdown"], [33, 1, 1, "", "cascade_execute"], [33, 1, 1, "", "enable_profile"], [33, 1, 1, "", "init_updater"], [33, 1, 1, "", "pause"], [33, 2, 1, "", "profile_config"], [33, 1, 1, "", "receive_weights"], [33, 1, 1, "", "register_scheme_receiver"], [33, 1, 1, "", "start"], [33, 1, 1, "", "update_policy_weights_"], [33, 2, 1, "", "worker_idx"]], "torchrl.collectors.Collector": [[34, 1, 1, "", "async_shutdown"], [34, 1, 1, "", "cascade_execute"], [34, 1, 1, "", "enable_profile"], [34, 1, 1, "", "get_model"], [34, 1, 1, "", "get_policy_version"], [34, 1, 1, "", "getattr_env"], [34, 1, 1, "", "getattr_policy"], [34, 1, 1, "", "getattr_rb"], [34, 1, 1, "", "increment_version"], [34, 1, 1, "", "init_updater"], [34, 1, 1, "", "iterator"], [34, 1, 1, "", "load_state_dict"], [34, 1, 1, "", "pause"], [34, 2, 1, "", "policy_version"], [34, 2, 1, "", "profile_config"], [34, 1, 1, "", "receive_weights"], [34, 1, 1, "", "register_scheme_receiver"], [34, 1, 1, "", "reset"], [34, 1, 1, "", "rollout"], [34, 1, 1, "", "set_seed"], [34, 1, 1, "", "shutdown"], [34, 1, 1, "", "start"], [34, 1, 1, "", "state_dict"], [34, 1, 1, "", "update_policy_weights_"], [34, 2, 1, "", "worker_idx"]], "torchrl.collectors.MultiAsyncCollector": [[35, 1, 1, "", "async_shutdown"], [35, 1, 1, "", "cascade_execute"], [35, 1, 1, "", "enable_profile"], [35, 1, 1, "", "get_cached_weights"], [35, 1, 1, "", "get_model"], [35, 1, 1, "", "get_policy_version"], [35, 1, 1, "", "getattr_env"], [35, 1, 1, "", "getattr_policy"], [35, 1, 1, "", "getattr_rb"], [35, 1, 1, "", "increment_version"], [35, 1, 1, "", "init_updater"], [35, 1, 1, "", "load_state_dict"], [35, 1, 1, "", "pause"], [35, 2, 1, "", "policy_version"], [35, 2, 1, "", "profile_config"], [35, 1, 1, "", "receive_weights"], [35, 1, 1, "", "register_scheme_receiver"], [35, 1, 1, "", "reset"], [35, 1, 1, "", "set_seed"], [35, 1, 1, "", "shutdown"], [35, 1, 1, "", "start"], [35, 1, 1, "", "state_dict"], [35, 1, 1, "", "update_policy_weights_"], [35, 2, 1, "", "worker_idx"]], "torchrl.collectors.MultiCollector": [[36, 1, 1, "", "async_shutdown"], [36, 1, 1, "", "cascade_execute"], [36, 1, 1, "", "enable_profile"], [36, 1, 1, "", "get_cached_weights"], [36, 1, 1, "", "get_model"], [36, 1, 1, "", "get_policy_version"], [36, 1, 1, "", "getattr_env"], [36, 1, 1, "", "getattr_policy"], [36, 1, 1, "", "getattr_rb"], [36, 1, 1, "", "increment_version"], [36, 1, 1, "", "init_updater"], [36, 1, 1, "", "load_state_dict"], [36, 1, 1, "", "pause"], [36, 2, 1, "", "policy_version"], [36, 2, 1, "", "profile_config"], [36, 1, 1, "", "receive_weights"], [36, 1, 1, "", "register_scheme_receiver"], [36, 1, 1, "", "reset"], [36, 1, 1, "", "set_seed"], [36, 1, 1, "", "shutdown"], [36, 1, 1, "", "start"], [36, 1, 1, "", "state_dict"], [36, 1, 1, "", "update_policy_weights_"], [36, 2, 1, "", "worker_idx"]], "torchrl.collectors.MultiProcessedWeightUpdater": [[37, 1, 1, "", "all_worker_ids"], [37, 2, 1, "", "collector"], [37, 2, 1, "", "collectors"], [37, 1, 1, "", "from_policy"], [37, 1, 1, "", "increment_version"], [37, 1, 1, "", "init"], [37, 2, 1, "", "post_hooks"], [37, 1, 1, "", "push_weights"], [37, 1, 1, "", "register_collector"], [37, 1, 1, "", "register_post_hook"]], "torchrl.collectors.MultiSyncCollector": [[38, 1, 1, "", "async_shutdown"], [38, 1, 1, "", "cascade_execute"], [38, 1, 1, "", "enable_profile"], [38, 1, 1, "", "get_cached_weights"], [38, 1, 1, "", "get_model"], [38, 1, 1, "", "get_policy_version"], [38, 1, 1, "", "getattr_env"], [38, 1, 1, "", "getattr_policy"], [38, 1, 1, "", "getattr_rb"], [38, 1, 1, "", "increment_version"], [38, 1, 1, "", "init_updater"], [38, 1, 1, "", "load_state_dict"], [38, 1, 1, "", "pause"], [38, 2, 1, "", "policy_version"], [38, 2, 1, "", "profile_config"], [38, 1, 1, "", "receive_weights"], [38, 1, 1, "", "register_scheme_receiver"], [38, 1, 1, "", "reset"], [38, 1, 1, "", "set_seed"], [38, 1, 1, "", "shutdown"], [38, 1, 1, "", "start"], [38, 1, 1, "", "state_dict"], [38, 1, 1, "", "update_policy_weights_"], [38, 2, 1, "", "worker_idx"]], "torchrl.collectors.RayWeightUpdater": [[39, 1, 1, "", "_get_server_weights"], [39, 1, 1, "", "_maybe_map_weights"], [39, 1, 1, "", "_skip_update"], [39, 1, 1, "", "_sync_weights_with_worker"], [39, 1, 1, "id0", "all_worker_ids"], [39, 2, 1, "", "collector"], [39, 2, 1, "", "collectors"], [39, 1, 1, "", "from_policy"], [39, 1, 1, "", "increment_version"], [39, 1, 1, "", "init"], [39, 2, 1, "", "post_hooks"], [39, 1, 1, "", "push_weights"], [39, 1, 1, "", "register_collector"], [39, 1, 1, "", "register_post_hook"]], "torchrl.collectors.VanillaWeightUpdater": [[40, 1, 1, "", "all_worker_ids"], [40, 2, 1, "", "collector"], [40, 2, 1, "", "collectors"], [40, 1, 1, "", "from_policy"], [40, 1, 1, "", "increment_version"], [40, 1, 1, "", "init"], [40, 2, 1, "", "post_hooks"], [40, 1, 1, "", "push_weights"], [40, 1, 1, "", "register_collector"], [40, 1, 1, "", "register_post_hook"]], "torchrl.collectors.WeightUpdaterBase": [[41, 1, 1, "", "all_worker_ids"], [41, 2, 1, "", "collector"], [41, 2, 1, "", "collectors"], [41, 1, 1, "id0", "from_policy"], [41, 1, 1, "", "increment_version"], [41, 1, 1, "", "init"], [41, 2, 1, "", "post_hooks"], [41, 1, 1, "id1", "push_weights"], [41, 1, 1, "id2", "register_collector"], [41, 1, 1, "", "register_post_hook"]], "torchrl.collectors.distributed": [[42, 0, 1, "", "DistributedCollector"], [43, 0, 1, "", "DistributedDataCollector"], [44, 0, 1, "", "DistributedSyncCollector"], [45, 0, 1, "", "DistributedSyncDataCollector"], [46, 0, 1, "", "DistributedWeightUpdater"], [47, 0, 1, "", "RPCCollector"], [48, 0, 1, "", "RPCDataCollector"], [49, 0, 1, "", "RPCWeightUpdater"], [50, 0, 1, "", "RayCollector"], [51, 0, 1, "", "submitit_delayed_launcher"]], "torchrl.collectors.distributed.DistributedCollector": [[42, 1, 1, "", "async_shutdown"], [42, 1, 1, "", "cascade_execute"], [42, 1, 1, "", "enable_profile"], [42, 1, 1, "", "init_updater"], [42, 1, 1, "", "pause"], [42, 2, 1, "", "profile_config"], [42, 1, 1, "", "receive_weights"], [42, 1, 1, "", "register_scheme_receiver"], [42, 1, 1, "", "start"], [42, 1, 1, "", "update_policy_weights_"], [42, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.DistributedDataCollector": [[43, 1, 1, "", "async_shutdown"], [43, 1, 1, "", "cascade_execute"], [43, 1, 1, "", "enable_profile"], [43, 1, 1, "", "init_updater"], [43, 1, 1, "", "pause"], [43, 2, 1, "", "profile_config"], [43, 1, 1, "", "receive_weights"], [43, 1, 1, "", "register_scheme_receiver"], [43, 1, 1, "", "start"], [43, 1, 1, "", "update_policy_weights_"], [43, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.DistributedSyncCollector": [[44, 1, 1, "", "async_shutdown"], [44, 1, 1, "", "cascade_execute"], [44, 1, 1, "", "enable_profile"], [44, 1, 1, "", "init_updater"], [44, 1, 1, "", "pause"], [44, 2, 1, "", "profile_config"], [44, 1, 1, "", "receive_weights"], [44, 1, 1, "", "register_scheme_receiver"], [44, 1, 1, "", "start"], [44, 1, 1, "", "update_policy_weights_"], [44, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.DistributedSyncDataCollector": [[45, 1, 1, "", "async_shutdown"], [45, 1, 1, "", "cascade_execute"], [45, 1, 1, "", "enable_profile"], [45, 1, 1, "", "init_updater"], [45, 1, 1, "", "pause"], [45, 2, 1, "", "profile_config"], [45, 1, 1, "", "receive_weights"], [45, 1, 1, "", "register_scheme_receiver"], [45, 1, 1, "", "start"], [45, 1, 1, "", "update_policy_weights_"], [45, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.DistributedWeightUpdater": [[46, 1, 1, "", "_get_server_weights"], [46, 1, 1, "", "_maybe_map_weights"], [46, 1, 1, "", "_sync_weights_with_worker"], [46, 1, 1, "id0", "all_worker_ids"], [46, 2, 1, "", "collector"], [46, 2, 1, "", "collectors"], [46, 1, 1, "", "from_policy"], [46, 1, 1, "", "increment_version"], [46, 1, 1, "", "init"], [46, 2, 1, "", "post_hooks"], [46, 1, 1, "", "push_weights"], [46, 1, 1, "", "register_collector"], [46, 1, 1, "", "register_post_hook"], [46, 1, 1, "", "update_weights"]], "torchrl.collectors.distributed.RPCCollector": [[47, 1, 1, "", "async_shutdown"], [47, 1, 1, "", "cascade_execute"], [47, 1, 1, "", "enable_profile"], [47, 1, 1, "", "init_updater"], [47, 1, 1, "", "pause"], [47, 2, 1, "", "profile_config"], [47, 1, 1, "", "receive_weights"], [47, 1, 1, "", "register_scheme_receiver"], [47, 1, 1, "", "start"], [47, 1, 1, "", "update_policy_weights_"], [47, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.RPCDataCollector": [[48, 1, 1, "", "async_shutdown"], [48, 1, 1, "", "cascade_execute"], [48, 1, 1, "", "enable_profile"], [48, 1, 1, "", "init_updater"], [48, 1, 1, "", "pause"], [48, 2, 1, "", "profile_config"], [48, 1, 1, "", "receive_weights"], [48, 1, 1, "", "register_scheme_receiver"], [48, 1, 1, "", "start"], [48, 1, 1, "", "update_policy_weights_"], [48, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.RPCWeightUpdater": [[49, 1, 1, "", "_get_server_weights"], [49, 1, 1, "", "_maybe_map_weights"], [49, 1, 1, "", "_sync_weights_with_worker"], [49, 1, 1, "id0", "all_worker_ids"], [49, 2, 1, "", "collector"], [49, 2, 1, "", "collectors"], [49, 1, 1, "", "from_policy"], [49, 1, 1, "", "increment_version"], [49, 1, 1, "", "init"], [49, 2, 1, "", "post_hooks"], [49, 1, 1, "", "push_weights"], [49, 1, 1, "", "register_collector"], [49, 1, 1, "", "register_post_hook"], [49, 1, 1, "", "update_weights"]], "torchrl.collectors.distributed.RayCollector": [[50, 1, 1, "", "add_collectors"], [50, 1, 1, "", "async_shutdown"], [50, 1, 1, "", "cascade_execute"], [50, 1, 1, "", "enable_profile"], [50, 1, 1, "", "init_updater"], [50, 1, 1, "", "load_state_dict"], [50, 1, 1, "", "local_policy"], [50, 1, 1, "", "pause"], [50, 2, 1, "", "profile_config"], [50, 1, 1, "", "receive_weights"], [50, 1, 1, "", "register_scheme_receiver"], [50, 2, 1, "", "remote_collectors"], [50, 1, 1, "", "set_seed"], [50, 1, 1, "", "shutdown"], [50, 1, 1, "", "start"], [50, 1, 1, "", "state_dict"], [50, 1, 1, "", "stop_remote_collectors"], [50, 1, 1, "", "update_policy_weights_"], [50, 2, 1, "", "worker_idx"]], "torchrl.collectors.llm": [[52, 0, 1, "", "LLMCollector"], [53, 0, 1, "", "RayLLMCollector"], [54, 0, 1, "", "vLLMUpdater"], [55, 0, 1, "", "vLLMUpdaterV2"]], "torchrl.collectors.llm.LLMCollector": [[52, 1, 1, "", "as_remote"], [52, 1, 1, "", "async_shutdown"], [52, 1, 1, "", "cascade_execute"], [52, 2, 1, "", "dialog_turns_per_batch"], [52, 1, 1, "", "enable_profile"], [52, 1, 1, "", "get_model"], [52, 1, 1, "", "get_policy_model"], [52, 1, 1, "", "get_policy_version"], [52, 1, 1, "", "getattr_env"], [52, 1, 1, "", "getattr_policy"], [52, 1, 1, "", "getattr_rb"], [52, 1, 1, "", "increment_version"], [52, 1, 1, "", "init_updater"], [52, 1, 1, "", "is_initialized"], [52, 1, 1, "", "iterator"], [52, 1, 1, "", "load_state_dict"], [52, 1, 1, "", "pause"], [52, 2, 1, "", "policy_version"], [52, 2, 1, "", "profile_config"], [52, 1, 1, "", "receive_weights"], [52, 1, 1, "", "register_scheme_receiver"], [52, 1, 1, "", "reset"], [52, 2, 1, "", "rollout"], [52, 1, 1, "", "set_seed"], [52, 1, 1, "", "shutdown"], [52, 1, 1, "", "start"], [52, 1, 1, "", "state_dict"], [52, 1, 1, "", "update_policy_weights_"], [52, 2, 1, "", "worker_idx"]], "torchrl.collectors.llm.RayLLMCollector": [[53, 1, 1, "", "as_remote"], [53, 1, 1, "", "async_shutdown"], [53, 1, 1, "", "cascade_execute"], [53, 2, 1, "", "dialog_turns_per_batch"], [53, 1, 1, "", "enable_profile"], [53, 1, 1, "", "get_model"], [53, 1, 1, "", "get_policy_model"], [53, 1, 1, "", "get_policy_version"], [53, 1, 1, "", "getattr_env"], [53, 1, 1, "", "getattr_policy"], [53, 1, 1, "", "getattr_rb"], [53, 1, 1, "", "increment_version"], [53, 1, 1, "", "init_updater"], [53, 1, 1, "", "is_initialized"], [53, 1, 1, "", "iterator"], [53, 1, 1, "", "load_state_dict"], [53, 1, 1, "", "next"], [53, 1, 1, "", "pause"], [53, 2, 1, "", "policy_version"], [53, 2, 1, "", "profile_config"], [53, 1, 1, "", "receive_weights"], [53, 1, 1, "", "register_scheme_receiver"], [53, 1, 1, "", "reset"], [53, 2, 1, "", "rollout"], [53, 1, 1, "", "set_seed"], [53, 1, 1, "", "shutdown"], [53, 1, 1, "", "start"], [53, 1, 1, "", "state_dict"], [53, 2, 1, "", "total_dialog_turns"], [53, 1, 1, "", "update_policy_weights_"], [53, 2, 1, "", "weight_updater"], [53, 2, 1, "", "worker_idx"]], "torchrl.collectors.llm.vLLMUpdater": [[54, 1, 1, "", "_get_server_weights"], [54, 1, 1, "", "_maybe_map_weights"], [54, 1, 1, "", "_sync_weights_with_worker"], [54, 1, 1, "id0", "all_worker_ids"], [54, 2, 1, "", "collector"], [54, 2, 1, "", "collectors"], [54, 1, 1, "", "from_policy"], [54, 1, 1, "", "get_model_metadata"], [54, 1, 1, "", "increment_version"], [54, 1, 1, "id1", "init"], [54, 2, 1, "", "post_hooks"], [54, 1, 1, "", "push_weights"], [54, 1, 1, "", "register_collector"], [54, 1, 1, "", "register_post_hook"]], "torchrl.collectors.llm.vLLMUpdaterV2": [[55, 1, 1, "", "all_worker_ids"], [55, 2, 1, "", "collector"], [55, 2, 1, "", "collectors"], [55, 1, 1, "", "from_policy"], [55, 1, 1, "", "get_model_metadata"], [55, 1, 1, "", "get_tp_size"], [55, 1, 1, "", "increment_version"], [55, 1, 1, "", "init"], [55, 2, 1, "", "post_hooks"], [55, 1, 1, "", "push_weights"], [55, 1, 1, "", "push_weights_from_transformers"], [55, 1, 1, "", "push_weights_from_transformers_optimized"], [55, 1, 1, "", "register_collector"], [55, 1, 1, "", "register_post_hook"]], "torchrl.collectors.utils": [[56, 3, 1, "", "split_trajectories"]], "torchrl.data": [[57, 0, 1, "", "Binary"], [58, 0, 1, "", "Bounded"], [59, 0, 1, "", "Categorical"], [60, 0, 1, "", "Composite"], [61, 0, 1, "", "MultiCategorical"], [62, 0, 1, "", "MultiOneHot"], [63, 0, 1, "", "NonTensor"], [64, 0, 1, "", "OneHot"], [65, 0, 1, "", "PrioritizedReplayBuffer"], [66, 0, 1, "", "RayReplayBuffer"], [67, 0, 1, "", "RemoteTensorDictReplayBuffer"], [68, 0, 1, "", "ReplayBuffer"], [69, 0, 1, "", "ReplayBufferEnsemble"], [70, 0, 1, "", "Stacked"], [71, 0, 1, "", "StackedComposite"], [72, 0, 1, "", "TensorDictPrioritizedReplayBuffer"], [73, 0, 1, "", "TensorDictReplayBuffer"], [74, 0, 1, "", "TensorSpec"], [75, 0, 1, "", "Unbounded"], [76, 0, 1, "", "UnboundedContinuous"], [77, 0, 1, "", "UnboundedDiscrete"]], "torchrl.data.Binary": [[57, 1, 1, "", "assert_is_in"], [57, 1, 1, "", "cardinality"], [57, 1, 1, "", "clear_device_"], [57, 1, 1, "", "clone"], [57, 1, 1, "", "contains"], [57, 1, 1, "", "cpu"], [57, 1, 1, "", "cuda"], [57, 4, 1, "", "device"], [57, 1, 1, "", "encode"], [57, 1, 1, "", "enumerate"], [57, 1, 1, "", "erase_memoize_cache"], [57, 1, 1, "", "expand"], [57, 1, 1, "", "flatten"], [57, 1, 1, "", "implements_for_spec"], [57, 1, 1, "", "index"], [57, 1, 1, "", "is_in"], [57, 1, 1, "", "make_neg_dim"], [57, 1, 1, "", "memoize_encode"], [57, 2, 1, "", "ndim"], [57, 1, 1, "", "ndimension"], [57, 1, 1, "", "one"], [57, 1, 1, "", "ones"], [57, 1, 1, "", "project"], [57, 1, 1, "", "rand"], [57, 1, 1, "", "reshape"], [57, 1, 1, "", "sample"], [57, 1, 1, "", "set_provisional_n"], [57, 1, 1, "", "squeeze"], [57, 1, 1, "", "to"], [57, 1, 1, "", "to_categorical"], [57, 1, 1, "", "to_categorical_spec"], [57, 1, 1, "", "to_numpy"], [57, 1, 1, "", "to_one_hot"], [57, 1, 1, "", "to_one_hot_spec"], [57, 1, 1, "", "type_check"], [57, 1, 1, "", "unflatten"], [57, 1, 1, "", "unsqueeze"], [57, 1, 1, "", "update_mask"], [57, 1, 1, "", "view"], [57, 1, 1, "", "zero"], [57, 1, 1, "", "zeros"]], "torchrl.data.Bounded": [[58, 1, 1, "", "assert_is_in"], [58, 1, 1, "", "cardinality"], [58, 1, 1, "", "clear_device_"], [58, 1, 1, "", "clone"], [58, 1, 1, "", "contains"], [58, 1, 1, "", "cpu"], [58, 1, 1, "", "cuda"], [58, 2, 1, "", "device"], [58, 1, 1, "", "encode"], [58, 1, 1, "", "enumerate"], [58, 1, 1, "", "erase_memoize_cache"], [58, 1, 1, "", "expand"], [58, 1, 1, "", "flatten"], [58, 1, 1, "", "implements_for_spec"], [58, 1, 1, "", "index"], [58, 1, 1, "", "is_in"], [58, 1, 1, "", "make_neg_dim"], [58, 1, 1, "", "memoize_encode"], [58, 2, 1, "", "ndim"], [58, 1, 1, "", "ndimension"], [58, 1, 1, "", "one"], [58, 1, 1, "", "ones"], [58, 1, 1, "", "project"], [58, 1, 1, "", "rand"], [58, 1, 1, "", "reshape"], [58, 1, 1, "", "sample"], [58, 1, 1, "", "squeeze"], [58, 1, 1, "", "to"], [58, 1, 1, "", "to_numpy"], [58, 1, 1, "", "type_check"], [58, 1, 1, "", "unflatten"], [58, 1, 1, "", "unsqueeze"], [58, 1, 1, "", "view"], [58, 1, 1, "", "zero"], [58, 1, 1, "", "zeros"]], "torchrl.data.Categorical": [[59, 1, 1, "", "assert_is_in"], [59, 1, 1, "", "cardinality"], [59, 1, 1, "", "clear_device_"], [59, 1, 1, "", "clone"], [59, 1, 1, "", "contains"], [59, 1, 1, "", "cpu"], [59, 1, 1, "", "cuda"], [59, 4, 1, "", "device"], [59, 1, 1, "", "encode"], [59, 1, 1, "", "enumerate"], [59, 1, 1, "", "erase_memoize_cache"], [59, 1, 1, "", "expand"], [59, 1, 1, "", "flatten"], [59, 1, 1, "", "implements_for_spec"], [59, 1, 1, "", "index"], [59, 1, 1, "", "is_in"], [59, 1, 1, "", "make_neg_dim"], [59, 1, 1, "", "memoize_encode"], [59, 2, 1, "", "ndim"], [59, 1, 1, "", "ndimension"], [59, 1, 1, "", "one"], [59, 1, 1, "", "ones"], [59, 1, 1, "", "project"], [59, 1, 1, "", "rand"], [59, 1, 1, "", "reshape"], [59, 1, 1, "", "sample"], [59, 1, 1, "", "set_provisional_n"], [59, 1, 1, "", "squeeze"], [59, 1, 1, "", "to"], [59, 1, 1, "", "to_categorical"], [59, 1, 1, "", "to_categorical_spec"], [59, 1, 1, "", "to_numpy"], [59, 1, 1, "", "to_one_hot"], [59, 1, 1, "", "to_one_hot_spec"], [59, 1, 1, "", "type_check"], [59, 1, 1, "", "unflatten"], [59, 1, 1, "", "unsqueeze"], [59, 1, 1, "", "update_mask"], [59, 1, 1, "", "view"], [59, 1, 1, "", "zero"], [59, 1, 1, "", "zeros"]], "torchrl.data.Composite": [[60, 1, 1, "", "assert_is_in"], [60, 1, 1, "", "cardinality"], [60, 1, 1, "", "clear_device_"], [60, 1, 1, "", "clone"], [60, 1, 1, "", "contains"], [60, 1, 1, "", "cpu"], [60, 1, 1, "", "cuda"], [60, 2, 1, "", "device"], [60, 1, 1, "", "empty"], [60, 1, 1, "", "encode"], [60, 1, 1, "", "enumerate"], [60, 1, 1, "", "erase_memoize_cache"], [60, 1, 1, "", "expand"], [60, 1, 1, "", "flatten"], [60, 1, 1, "", "get"], [60, 1, 1, "", "implements_for_spec"], [60, 1, 1, "", "index"], [60, 1, 1, "", "is_empty"], [60, 1, 1, "", "is_in"], [60, 1, 1, "", "items"], [60, 1, 1, "", "keys"], [60, 1, 1, "", "lock_"], [60, 1, 1, "", "make_neg_dim"], [60, 1, 1, "", "memoize_encode"], [60, 2, 1, "", "names"], [60, 2, 1, "", "ndim"], [60, 1, 1, "", "ndimension"], [60, 1, 1, "", "one"], [60, 1, 1, "", "ones"], [60, 1, 1, "", "ones_update"], [60, 1, 1, "", "pop"], [60, 1, 1, "", "project"], [60, 1, 1, "", "rand"], [60, 1, 1, "", "rand_update"], [60, 1, 1, "", "refine_names"], [60, 1, 1, "", "reshape"], [60, 1, 1, "", "sample"], [60, 1, 1, "", "separates"], [60, 1, 1, "", "set"], [60, 1, 1, "", "squeeze"], [60, 1, 1, "", "to"], [60, 1, 1, "", "to_numpy"], [60, 1, 1, "", "type_check"], [60, 1, 1, "", "unflatten"], [60, 1, 1, "", "unlock_"], [60, 1, 1, "", "unsqueeze"], [60, 1, 1, "", "values"], [60, 1, 1, "", "view"], [60, 1, 1, "", "zero"], [60, 1, 1, "", "zeros"], [60, 1, 1, "", "zeros_update"]], "torchrl.data.MultiCategorical": [[61, 1, 1, "", "assert_is_in"], [61, 1, 1, "", "cardinality"], [61, 1, 1, "", "clear_device_"], [61, 1, 1, "", "clone"], [61, 1, 1, "", "contains"], [61, 1, 1, "", "cpu"], [61, 1, 1, "", "cuda"], [61, 4, 1, "", "device"], [61, 1, 1, "", "encode"], [61, 1, 1, "", "enumerate"], [61, 1, 1, "", "erase_memoize_cache"], [61, 1, 1, "", "expand"], [61, 1, 1, "", "flatten"], [61, 1, 1, "", "implements_for_spec"], [61, 1, 1, "", "index"], [61, 1, 1, "", "is_in"], [61, 1, 1, "", "make_neg_dim"], [61, 1, 1, "", "memoize_encode"], [61, 2, 1, "", "ndim"], [61, 1, 1, "", "ndimension"], [61, 1, 1, "", "one"], [61, 1, 1, "", "ones"], [61, 1, 1, "", "project"], [61, 1, 1, "", "rand"], [61, 1, 1, "", "reshape"], [61, 1, 1, "", "sample"], [61, 1, 1, "", "set_provisional_n"], [61, 1, 1, "", "squeeze"], [61, 1, 1, "", "to"], [61, 1, 1, "", "to_categorical"], [61, 1, 1, "", "to_categorical_spec"], [61, 1, 1, "", "to_numpy"], [61, 1, 1, "", "to_one_hot"], [61, 1, 1, "", "to_one_hot_spec"], [61, 1, 1, "", "type_check"], [61, 1, 1, "", "unflatten"], [61, 1, 1, "", "unsqueeze"], [61, 1, 1, "", "update_mask"], [61, 1, 1, "", "view"], [61, 1, 1, "", "zero"], [61, 1, 1, "", "zeros"]], "torchrl.data.MultiOneHot": [[62, 1, 1, "", "assert_is_in"], [62, 1, 1, "", "cardinality"], [62, 1, 1, "", "clear_device_"], [62, 1, 1, "", "clone"], [62, 1, 1, "", "contains"], [62, 1, 1, "", "cpu"], [62, 1, 1, "", "cuda"], [62, 4, 1, "", "device"], [62, 1, 1, "", "encode"], [62, 1, 1, "", "enumerate"], [62, 1, 1, "", "erase_memoize_cache"], [62, 1, 1, "", "expand"], [62, 1, 1, "", "flatten"], [62, 1, 1, "", "implements_for_spec"], [62, 1, 1, "", "index"], [62, 1, 1, "", "is_in"], [62, 1, 1, "", "make_neg_dim"], [62, 1, 1, "", "memoize_encode"], [62, 2, 1, "", "ndim"], [62, 1, 1, "", "ndimension"], [62, 1, 1, "", "one"], [62, 1, 1, "", "ones"], [62, 1, 1, "", "project"], [62, 1, 1, "", "rand"], [62, 1, 1, "", "reshape"], [62, 1, 1, "", "sample"], [62, 1, 1, "", "squeeze"], [62, 1, 1, "", "to"], [62, 1, 1, "", "to_categorical"], [62, 1, 1, "", "to_categorical_spec"], [62, 1, 1, "", "to_numpy"], [62, 1, 1, "", "to_one_hot"], [62, 1, 1, "", "to_one_hot_spec"], [62, 1, 1, "", "type_check"], [62, 1, 1, "", "unflatten"], [62, 1, 1, "", "unsqueeze"], [62, 1, 1, "", "update_mask"], [62, 1, 1, "", "view"], [62, 1, 1, "", "zero"], [62, 1, 1, "", "zeros"]], "torchrl.data.NonTensor": [[63, 1, 1, "", "assert_is_in"], [63, 1, 1, "", "cardinality"], [63, 1, 1, "", "clear_device_"], [63, 1, 1, "", "clone"], [63, 1, 1, "", "contains"], [63, 1, 1, "", "cpu"], [63, 1, 1, "", "cuda"], [63, 2, 1, "", "device"], [63, 1, 1, "", "encode"], [63, 1, 1, "", "enumerate"], [63, 1, 1, "", "erase_memoize_cache"], [63, 1, 1, "", "expand"], [63, 1, 1, "", "flatten"], [63, 1, 1, "", "implements_for_spec"], [63, 1, 1, "", "index"], [63, 1, 1, "", "is_in"], [63, 1, 1, "", "make_neg_dim"], [63, 1, 1, "", "memoize_encode"], [63, 2, 1, "", "ndim"], [63, 1, 1, "", "ndimension"], [63, 1, 1, "", "one"], [63, 1, 1, "", "ones"], [63, 1, 1, "", "project"], [63, 1, 1, "", "rand"], [63, 1, 1, "", "reshape"], [63, 1, 1, "", "sample"], [63, 1, 1, "", "squeeze"], [63, 1, 1, "", "to"], [63, 1, 1, "", "to_numpy"], [63, 1, 1, "", "type_check"], [63, 1, 1, "", "unflatten"], [63, 1, 1, "", "unsqueeze"], [63, 1, 1, "", "view"], [63, 1, 1, "", "zero"], [63, 1, 1, "", "zeros"]], "torchrl.data.OneHot": [[64, 1, 1, "", "assert_is_in"], [64, 1, 1, "", "cardinality"], [64, 1, 1, "", "clear_device_"], [64, 1, 1, "", "clone"], [64, 1, 1, "", "contains"], [64, 1, 1, "", "cpu"], [64, 1, 1, "", "cuda"], [64, 4, 1, "", "device"], [64, 1, 1, "", "encode"], [64, 1, 1, "", "enumerate"], [64, 1, 1, "", "erase_memoize_cache"], [64, 1, 1, "", "expand"], [64, 1, 1, "", "flatten"], [64, 1, 1, "", "implements_for_spec"], [64, 1, 1, "", "index"], [64, 1, 1, "", "is_in"], [64, 1, 1, "", "make_neg_dim"], [64, 1, 1, "", "memoize_encode"], [64, 2, 1, "", "ndim"], [64, 1, 1, "", "ndimension"], [64, 1, 1, "", "one"], [64, 1, 1, "", "ones"], [64, 1, 1, "", "project"], [64, 1, 1, "", "rand"], [64, 1, 1, "", "reshape"], [64, 1, 1, "", "sample"], [64, 1, 1, "", "squeeze"], [64, 1, 1, "", "to"], [64, 1, 1, "", "to_categorical"], [64, 1, 1, "", "to_categorical_spec"], [64, 1, 1, "", "to_numpy"], [64, 1, 1, "", "to_one_hot"], [64, 1, 1, "", "to_one_hot_spec"], [64, 1, 1, "", "type_check"], [64, 1, 1, "", "unflatten"], [64, 1, 1, "", "unsqueeze"], [64, 1, 1, "", "update_mask"], [64, 1, 1, "", "view"], [64, 1, 1, "", "zero"], [64, 1, 1, "", "zeros"]], "torchrl.data.PrioritizedReplayBuffer": [[65, 1, 1, "", "add"], [65, 1, 1, "", "append_transform"], [65, 1, 1, "", "as_remote"], [65, 2, 1, "", "batch_size"], [65, 1, 1, "", "dump"], [65, 1, 1, "", "dumps"], [65, 1, 1, "", "empty"], [65, 1, 1, "", "extend"], [65, 2, 1, "", "initialized"], [65, 1, 1, "", "insert_transform"], [65, 1, 1, "", "load"], [65, 1, 1, "", "loads"], [65, 1, 1, "", "next"], [65, 1, 1, "", "register_load_hook"], [65, 1, 1, "", "register_save_hook"], [65, 1, 1, "", "sample"], [65, 2, 1, "", "sampler"], [65, 1, 1, "", "save"], [65, 1, 1, "", "set_sampler"], [65, 1, 1, "", "set_storage"], [65, 1, 1, "", "set_writer"], [65, 2, 1, "", "storage"], [65, 2, 1, "", "transform"], [65, 2, 1, "", "write_count"], [65, 2, 1, "", "writer"]], "torchrl.data.RayReplayBuffer": [[66, 1, 1, "", "add"], [66, 1, 1, "", "append_transform"], [66, 1, 1, "", "as_remote"], [66, 2, 1, "", "batch_size"], [66, 1, 1, "", "close"], [66, 1, 1, "", "dump"], [66, 1, 1, "", "dumps"], [66, 1, 1, "", "empty"], [66, 1, 1, "", "extend"], [66, 2, 1, "", "initialized"], [66, 1, 1, "", "insert_transform"], [66, 1, 1, "", "load"], [66, 1, 1, "", "loads"], [66, 1, 1, "", "next"], [66, 1, 1, "", "register_load_hook"], [66, 1, 1, "", "register_save_hook"], [66, 1, 1, "", "sample"], [66, 2, 1, "", "sampler"], [66, 1, 1, "", "save"], [66, 1, 1, "", "set_sampler"], [66, 1, 1, "", "set_storage"], [66, 1, 1, "", "set_writer"], [66, 2, 1, "", "storage"], [66, 2, 1, "", "transform"], [66, 2, 1, "", "write_count"], [66, 2, 1, "", "writer"]], "torchrl.data.RemoteTensorDictReplayBuffer": [[67, 1, 1, "", "add"], [67, 1, 1, "", "append_transform"], [67, 1, 1, "", "as_remote"], [67, 2, 1, "", "batch_size"], [67, 1, 1, "", "dump"], [67, 1, 1, "", "dumps"], [67, 1, 1, "", "empty"], [67, 1, 1, "", "extend"], [67, 2, 1, "", "initialized"], [67, 1, 1, "", "insert_transform"], [67, 1, 1, "", "load"], [67, 1, 1, "", "loads"], [67, 1, 1, "", "next"], [67, 1, 1, "", "register_load_hook"], [67, 1, 1, "", "register_save_hook"], [67, 1, 1, "", "sample"], [67, 2, 1, "", "sampler"], [67, 1, 1, "", "save"], [67, 1, 1, "", "set_sampler"], [67, 1, 1, "", "set_storage"], [67, 1, 1, "", "set_writer"], [67, 2, 1, "", "storage"], [67, 2, 1, "", "transform"], [67, 2, 1, "", "write_count"], [67, 2, 1, "", "writer"]], "torchrl.data.ReplayBuffer": [[68, 1, 1, "", "add"], [68, 1, 1, "", "append_transform"], [68, 1, 1, "", "as_remote"], [68, 2, 1, "", "batch_size"], [68, 1, 1, "", "dump"], [68, 1, 1, "", "dumps"], [68, 1, 1, "", "empty"], [68, 1, 1, "", "extend"], [68, 2, 1, "", "initialized"], [68, 1, 1, "", "insert_transform"], [68, 1, 1, "", "load"], [68, 1, 1, "", "loads"], [68, 1, 1, "", "next"], [68, 1, 1, "", "register_load_hook"], [68, 1, 1, "", "register_save_hook"], [68, 1, 1, "", "sample"], [68, 2, 1, "", "sampler"], [68, 1, 1, "", "save"], [68, 1, 1, "", "set_sampler"], [68, 1, 1, "", "set_storage"], [68, 1, 1, "", "set_writer"], [68, 2, 1, "", "storage"], [68, 2, 1, "", "transform"], [68, 2, 1, "", "write_count"], [68, 2, 1, "", "writer"]], "torchrl.data.ReplayBufferEnsemble": [[69, 1, 1, "", "add"], [69, 1, 1, "", "append_transform"], [69, 1, 1, "", "as_remote"], [69, 2, 1, "", "batch_size"], [69, 1, 1, "", "dump"], [69, 1, 1, "", "dumps"], [69, 1, 1, "", "empty"], [69, 1, 1, "", "extend"], [69, 2, 1, "", "initialized"], [69, 1, 1, "", "insert_transform"], [69, 1, 1, "", "load"], [69, 1, 1, "", "loads"], [69, 1, 1, "", "next"], [69, 1, 1, "", "register_load_hook"], [69, 1, 1, "", "register_save_hook"], [69, 1, 1, "", "sample"], [69, 2, 1, "", "sampler"], [69, 1, 1, "", "save"], [69, 1, 1, "", "set_sampler"], [69, 1, 1, "", "set_storage"], [69, 1, 1, "", "set_writer"], [69, 2, 1, "", "storage"], [69, 2, 1, "", "transform"], [69, 2, 1, "", "write_count"], [69, 2, 1, "", "writer"]], "torchrl.data.Stacked": [[70, 1, 1, "", "assert_is_in"], [70, 1, 1, "", "cardinality"], [70, 1, 1, "", "clear_device_"], [70, 1, 1, "", "clone"], [70, 1, 1, "", "contains"], [70, 1, 1, "", "cpu"], [70, 1, 1, "", "cuda"], [70, 2, 1, "", "device"], [70, 1, 1, "", "encode"], [70, 1, 1, "", "enumerate"], [70, 1, 1, "", "erase_memoize_cache"], [70, 1, 1, "", "expand"], [70, 1, 1, "", "flatten"], [70, 1, 1, "", "implements_for_spec"], [70, 1, 1, "", "index"], [70, 1, 1, "", "is_in"], [70, 1, 1, "", "make_neg_dim"], [70, 1, 1, "", "memoize_encode"], [70, 2, 1, "", "ndim"], [70, 1, 1, "", "ndimension"], [70, 1, 1, "", "one"], [70, 1, 1, "", "ones"], [70, 1, 1, "", "project"], [70, 1, 1, "", "rand"], [70, 1, 1, "", "reshape"], [70, 1, 1, "", "sample"], [70, 1, 1, "", "squeeze"], [70, 1, 1, "", "to"], [70, 1, 1, "", "to_numpy"], [70, 1, 1, "", "type_check"], [70, 1, 1, "", "unflatten"], [70, 1, 1, "", "unsqueeze"], [70, 1, 1, "", "view"], [70, 1, 1, "", "zero"], [70, 1, 1, "", "zeros"]], "torchrl.data.StackedComposite": [[71, 1, 1, "", "assert_is_in"], [71, 1, 1, "", "cardinality"], [71, 1, 1, "", "clear_device_"], [71, 1, 1, "", "clone"], [71, 1, 1, "", "contains"], [71, 1, 1, "", "cpu"], [71, 1, 1, "", "cuda"], [71, 2, 1, "", "device"], [71, 1, 1, "", "empty"], [71, 1, 1, "", "encode"], [71, 1, 1, "", "enumerate"], [71, 1, 1, "", "erase_memoize_cache"], [71, 1, 1, "", "expand"], [71, 1, 1, "", "flatten"], [71, 1, 1, "", "get"], [71, 1, 1, "", "implements_for_spec"], [71, 1, 1, "", "index"], [71, 1, 1, "", "is_empty"], [71, 1, 1, "", "is_in"], [71, 1, 1, "", "items"], [71, 1, 1, "", "keys"], [71, 1, 1, "", "lock_"], [71, 1, 1, "", "make_neg_dim"], [71, 1, 1, "", "memoize_encode"], [71, 2, 1, "", "names"], [71, 2, 1, "", "ndim"], [71, 1, 1, "", "ndimension"], [71, 1, 1, "", "one"], [71, 1, 1, "", "ones"], [71, 1, 1, "", "ones_update"], [71, 1, 1, "", "pop"], [71, 1, 1, "", "project"], [71, 1, 1, "", "rand"], [71, 1, 1, "", "rand_update"], [71, 1, 1, "", "refine_names"], [71, 1, 1, "", "reshape"], [71, 1, 1, "", "sample"], [71, 1, 1, "", "separates"], [71, 1, 1, "", "set"], [71, 1, 1, "", "squeeze"], [71, 1, 1, "", "to"], [71, 1, 1, "", "to_numpy"], [71, 1, 1, "", "type_check"], [71, 1, 1, "", "unflatten"], [71, 1, 1, "", "unlock_"], [71, 1, 1, "", "unsqueeze"], [71, 1, 1, "", "values"], [71, 1, 1, "", "view"], [71, 1, 1, "", "zero"], [71, 1, 1, "", "zeros"], [71, 1, 1, "", "zeros_update"]], "torchrl.data.TensorDictPrioritizedReplayBuffer": [[72, 1, 1, "", "add"], [72, 1, 1, "", "append_transform"], [72, 1, 1, "", "as_remote"], [72, 2, 1, "", "batch_size"], [72, 1, 1, "", "dump"], [72, 1, 1, "", "dumps"], [72, 1, 1, "", "empty"], [72, 1, 1, "", "extend"], [72, 2, 1, "", "initialized"], [72, 1, 1, "", "insert_transform"], [72, 1, 1, "", "load"], [72, 1, 1, "", "loads"], [72, 1, 1, "", "next"], [72, 1, 1, "", "register_load_hook"], [72, 1, 1, "", "register_save_hook"], [72, 1, 1, "", "sample"], [72, 2, 1, "", "sampler"], [72, 1, 1, "", "save"], [72, 1, 1, "", "set_sampler"], [72, 1, 1, "", "set_storage"], [72, 1, 1, "", "set_writer"], [72, 2, 1, "", "storage"], [72, 2, 1, "", "transform"], [72, 2, 1, "", "write_count"], [72, 2, 1, "", "writer"]], "torchrl.data.TensorDictReplayBuffer": [[73, 1, 1, "", "add"], [73, 1, 1, "", "append_transform"], [73, 1, 1, "", "as_remote"], [73, 2, 1, "", "batch_size"], [73, 1, 1, "", "dump"], [73, 1, 1, "", "dumps"], [73, 1, 1, "", "empty"], [73, 1, 1, "", "extend"], [73, 2, 1, "", "initialized"], [73, 1, 1, "", "insert_transform"], [73, 1, 1, "", "load"], [73, 1, 1, "", "loads"], [73, 1, 1, "", "next"], [73, 1, 1, "", "register_load_hook"], [73, 1, 1, "", "register_save_hook"], [73, 1, 1, "", "sample"], [73, 2, 1, "", "sampler"], [73, 1, 1, "", "save"], [73, 1, 1, "", "set_sampler"], [73, 1, 1, "", "set_storage"], [73, 1, 1, "", "set_writer"], [73, 2, 1, "", "storage"], [73, 2, 1, "", "transform"], [73, 2, 1, "", "write_count"], [73, 2, 1, "", "writer"]], "torchrl.data.TensorSpec": [[74, 1, 1, "", "assert_is_in"], [74, 1, 1, "", "cardinality"], [74, 1, 1, "", "clear_device_"], [74, 1, 1, "", "clone"], [74, 1, 1, "", "contains"], [74, 1, 1, "", "cpu"], [74, 1, 1, "", "cuda"], [74, 2, 1, "", "device"], [74, 1, 1, "", "encode"], [74, 1, 1, "", "enumerate"], [74, 1, 1, "", "erase_memoize_cache"], [74, 1, 1, "", "expand"], [74, 1, 1, "", "flatten"], [74, 1, 1, "", "implements_for_spec"], [74, 1, 1, "", "index"], [74, 1, 1, "", "is_in"], [74, 1, 1, "", "make_neg_dim"], [74, 1, 1, "", "memoize_encode"], [74, 2, 1, "", "ndim"], [74, 1, 1, "", "ndimension"], [74, 1, 1, "", "one"], [74, 1, 1, "", "ones"], [74, 1, 1, "", "project"], [74, 1, 1, "", "rand"], [74, 1, 1, "", "reshape"], [74, 1, 1, "", "sample"], [74, 1, 1, "", "squeeze"], [74, 1, 1, "", "to"], [74, 1, 1, "", "to_numpy"], [74, 1, 1, "", "type_check"], [74, 1, 1, "", "unflatten"], [74, 1, 1, "", "unsqueeze"], [74, 1, 1, "", "view"], [74, 1, 1, "", "zero"], [74, 1, 1, "", "zeros"]], "torchrl.data.Unbounded": [[75, 1, 1, "", "assert_is_in"], [75, 1, 1, "", "cardinality"], [75, 1, 1, "", "clear_device_"], [75, 1, 1, "", "clone"], [75, 1, 1, "", "contains"], [75, 1, 1, "", "cpu"], [75, 1, 1, "", "cuda"], [75, 2, 1, "", "device"], [75, 1, 1, "", "encode"], [75, 1, 1, "", "enumerate"], [75, 1, 1, "", "erase_memoize_cache"], [75, 1, 1, "", "expand"], [75, 1, 1, "", "flatten"], [75, 1, 1, "", "implements_for_spec"], [75, 1, 1, "", "index"], [75, 1, 1, "", "is_in"], [75, 1, 1, "", "make_neg_dim"], [75, 1, 1, "", "memoize_encode"], [75, 2, 1, "", "ndim"], [75, 1, 1, "", "ndimension"], [75, 1, 1, "", "one"], [75, 1, 1, "", "ones"], [75, 1, 1, "", "project"], [75, 1, 1, "", "rand"], [75, 1, 1, "", "reshape"], [75, 1, 1, "", "sample"], [75, 1, 1, "", "squeeze"], [75, 1, 1, "", "to"], [75, 1, 1, "", "to_numpy"], [75, 1, 1, "", "type_check"], [75, 1, 1, "", "unflatten"], [75, 1, 1, "", "unsqueeze"], [75, 1, 1, "", "view"], [75, 1, 1, "", "zero"], [75, 1, 1, "", "zeros"]], "torchrl.data.UnboundedContinuous": [[76, 1, 1, "", "assert_is_in"], [76, 1, 1, "", "cardinality"], [76, 1, 1, "", "clear_device_"], [76, 1, 1, "", "clone"], [76, 1, 1, "", "contains"], [76, 1, 1, "", "cpu"], [76, 1, 1, "", "cuda"], [76, 2, 1, "", "device"], [76, 1, 1, "", "encode"], [76, 1, 1, "", "enumerate"], [76, 1, 1, "", "erase_memoize_cache"], [76, 1, 1, "", "expand"], [76, 1, 1, "", "flatten"], [76, 1, 1, "", "implements_for_spec"], [76, 1, 1, "", "index"], [76, 1, 1, "", "is_in"], [76, 1, 1, "", "make_neg_dim"], [76, 1, 1, "", "memoize_encode"], [76, 2, 1, "", "ndim"], [76, 1, 1, "", "ndimension"], [76, 1, 1, "", "one"], [76, 1, 1, "", "ones"], [76, 1, 1, "", "project"], [76, 1, 1, "", "rand"], [76, 1, 1, "", "reshape"], [76, 1, 1, "", "sample"], [76, 1, 1, "", "squeeze"], [76, 1, 1, "", "to"], [76, 1, 1, "", "to_numpy"], [76, 1, 1, "", "type_check"], [76, 1, 1, "", "unflatten"], [76, 1, 1, "", "unsqueeze"], [76, 1, 1, "", "view"], [76, 1, 1, "", "zero"], [76, 1, 1, "", "zeros"]], "torchrl.data.UnboundedDiscrete": [[77, 1, 1, "", "assert_is_in"], [77, 1, 1, "", "cardinality"], [77, 1, 1, "", "clear_device_"], [77, 1, 1, "", "clone"], [77, 1, 1, "", "contains"], [77, 1, 1, "", "cpu"], [77, 1, 1, "", "cuda"], [77, 2, 1, "", "device"], [77, 1, 1, "", "encode"], [77, 1, 1, "", "enumerate"], [77, 1, 1, "", "erase_memoize_cache"], [77, 1, 1, "", "expand"], [77, 1, 1, "", "flatten"], [77, 1, 1, "", "implements_for_spec"], [77, 1, 1, "", "index"], [77, 1, 1, "", "is_in"], [77, 1, 1, "", "make_neg_dim"], [77, 1, 1, "", "memoize_encode"], [77, 2, 1, "", "ndim"], [77, 1, 1, "", "ndimension"], [77, 1, 1, "", "one"], [77, 1, 1, "", "ones"], [77, 1, 1, "", "project"], [77, 1, 1, "", "rand"], [77, 1, 1, "", "reshape"], [77, 1, 1, "", "sample"], [77, 1, 1, "", "squeeze"], [77, 1, 1, "", "to"], [77, 1, 1, "", "to_numpy"], [77, 1, 1, "", "type_check"], [77, 1, 1, "", "unflatten"], [77, 1, 1, "", "unsqueeze"], [77, 1, 1, "", "view"], [77, 1, 1, "", "zero"], [77, 1, 1, "", "zeros"]], "torchrl.data.datasets": [[78, 0, 1, "", "AtariDQNExperienceReplay"], [79, 0, 1, "", "D4RLExperienceReplay"], [80, 0, 1, "", "GenDGRLExperienceReplay"], [81, 0, 1, "", "MinariExperienceReplay"], [82, 0, 1, "", "OpenMLExperienceReplay"], [83, 0, 1, "", "OpenXExperienceReplay"], [84, 0, 1, "", "RobosetExperienceReplay"], [85, 0, 1, "", "VD4RLExperienceReplay"]], "torchrl.data.datasets.AtariDQNExperienceReplay": [[78, 1, 1, "", "add"], [78, 1, 1, "", "append_transform"], [78, 1, 1, "", "as_remote"], [78, 2, 1, "", "batch_size"], [78, 2, 1, "", "data_path"], [78, 2, 1, "", "data_path_root"], [78, 1, 1, "", "delete"], [78, 1, 1, "", "dump"], [78, 1, 1, "", "dumps"], [78, 1, 1, "", "empty"], [78, 1, 1, "", "extend"], [78, 2, 1, "", "initialized"], [78, 1, 1, "", "insert_transform"], [78, 1, 1, "", "load"], [78, 1, 1, "", "loads"], [78, 1, 1, "", "next"], [78, 1, 1, "", "preprocess"], [78, 1, 1, "", "register_load_hook"], [78, 1, 1, "", "register_save_hook"], [78, 1, 1, "", "sample"], [78, 2, 1, "", "sampler"], [78, 1, 1, "", "save"], [78, 1, 1, "", "set_sampler"], [78, 1, 1, "", "set_storage"], [78, 1, 1, "", "set_writer"], [78, 2, 1, "", "storage"], [78, 2, 1, "", "transform"], [78, 2, 1, "", "write_count"], [78, 2, 1, "", "writer"]], "torchrl.data.datasets.D4RLExperienceReplay": [[79, 1, 1, "", "add"], [79, 1, 1, "", "append_transform"], [79, 1, 1, "", "as_remote"], [79, 2, 1, "", "batch_size"], [79, 2, 1, "", "data_path"], [79, 2, 1, "", "data_path_root"], [79, 1, 1, "", "delete"], [79, 1, 1, "", "dump"], [79, 1, 1, "", "dumps"], [79, 1, 1, "", "empty"], [79, 1, 1, "", "extend"], [79, 2, 1, "", "initialized"], [79, 1, 1, "", "insert_transform"], [79, 1, 1, "", "load"], [79, 1, 1, "", "loads"], [79, 1, 1, "", "next"], [79, 1, 1, "", "preprocess"], [79, 1, 1, "", "register_load_hook"], [79, 1, 1, "", "register_save_hook"], [79, 1, 1, "", "sample"], [79, 2, 1, "", "sampler"], [79, 1, 1, "", "save"], [79, 1, 1, "", "set_sampler"], [79, 1, 1, "", "set_storage"], [79, 1, 1, "", "set_writer"], [79, 2, 1, "", "storage"], [79, 2, 1, "", "transform"], [79, 2, 1, "", "write_count"], [79, 2, 1, "", "writer"]], "torchrl.data.datasets.GenDGRLExperienceReplay": [[80, 1, 1, "", "add"], [80, 1, 1, "", "append_transform"], [80, 1, 1, "", "as_remote"], [80, 2, 1, "", "batch_size"], [80, 2, 1, "", "data_path"], [80, 2, 1, "", "data_path_root"], [80, 1, 1, "", "delete"], [80, 1, 1, "", "dump"], [80, 1, 1, "", "dumps"], [80, 1, 1, "", "empty"], [80, 1, 1, "", "extend"], [80, 2, 1, "", "initialized"], [80, 1, 1, "", "insert_transform"], [80, 1, 1, "", "load"], [80, 1, 1, "", "loads"], [80, 1, 1, "", "next"], [80, 1, 1, "", "preprocess"], [80, 1, 1, "", "register_load_hook"], [80, 1, 1, "", "register_save_hook"], [80, 1, 1, "", "sample"], [80, 2, 1, "", "sampler"], [80, 1, 1, "", "save"], [80, 1, 1, "", "set_sampler"], [80, 1, 1, "", "set_storage"], [80, 1, 1, "", "set_writer"], [80, 2, 1, "", "storage"], [80, 2, 1, "", "transform"], [80, 2, 1, "", "write_count"], [80, 2, 1, "", "writer"]], "torchrl.data.datasets.MinariExperienceReplay": [[81, 1, 1, "", "add"], [81, 1, 1, "", "append_transform"], [81, 1, 1, "", "as_remote"], [81, 2, 1, "", "batch_size"], [81, 2, 1, "", "data_path"], [81, 2, 1, "", "data_path_root"], [81, 1, 1, "", "delete"], [81, 1, 1, "", "dump"], [81, 1, 1, "", "dumps"], [81, 1, 1, "", "empty"], [81, 1, 1, "", "extend"], [81, 2, 1, "", "initialized"], [81, 1, 1, "", "insert_transform"], [81, 1, 1, "", "load"], [81, 1, 1, "", "loads"], [81, 1, 1, "", "next"], [81, 1, 1, "", "preprocess"], [81, 1, 1, "", "register_load_hook"], [81, 1, 1, "", "register_save_hook"], [81, 1, 1, "", "sample"], [81, 2, 1, "", "sampler"], [81, 1, 1, "", "save"], [81, 1, 1, "", "set_sampler"], [81, 1, 1, "", "set_storage"], [81, 1, 1, "", "set_writer"], [81, 2, 1, "", "storage"], [81, 2, 1, "", "transform"], [81, 2, 1, "", "write_count"], [81, 2, 1, "", "writer"]], "torchrl.data.datasets.OpenMLExperienceReplay": [[82, 1, 1, "", "add"], [82, 1, 1, "", "append_transform"], [82, 1, 1, "", "as_remote"], [82, 2, 1, "", "batch_size"], [82, 2, 1, "", "data_path"], [82, 2, 1, "", "data_path_root"], [82, 1, 1, "", "delete"], [82, 1, 1, "", "dump"], [82, 1, 1, "", "dumps"], [82, 1, 1, "", "empty"], [82, 1, 1, "", "extend"], [82, 2, 1, "", "initialized"], [82, 1, 1, "", "insert_transform"], [82, 1, 1, "", "load"], [82, 1, 1, "", "loads"], [82, 1, 1, "", "next"], [82, 1, 1, "", "preprocess"], [82, 1, 1, "", "register_load_hook"], [82, 1, 1, "", "register_save_hook"], [82, 1, 1, "", "sample"], [82, 2, 1, "", "sampler"], [82, 1, 1, "", "save"], [82, 1, 1, "", "set_sampler"], [82, 1, 1, "", "set_storage"], [82, 1, 1, "", "set_writer"], [82, 2, 1, "", "storage"], [82, 2, 1, "", "transform"], [82, 2, 1, "", "write_count"], [82, 2, 1, "", "writer"]], "torchrl.data.datasets.OpenXExperienceReplay": [[83, 1, 1, "", "add"], [83, 1, 1, "", "append_transform"], [83, 1, 1, "", "as_remote"], [83, 2, 1, "", "batch_size"], [83, 2, 1, "", "data_path"], [83, 2, 1, "", "data_path_root"], [83, 1, 1, "", "delete"], [83, 1, 1, "", "dump"], [83, 1, 1, "", "dumps"], [83, 1, 1, "", "empty"], [83, 1, 1, "", "extend"], [83, 2, 1, "", "initialized"], [83, 1, 1, "", "insert_transform"], [83, 1, 1, "", "load"], [83, 1, 1, "", "loads"], [83, 1, 1, "", "next"], [83, 1, 1, "", "preprocess"], [83, 1, 1, "", "register_load_hook"], [83, 1, 1, "", "register_save_hook"], [83, 1, 1, "", "sample"], [83, 2, 1, "", "sampler"], [83, 1, 1, "", "save"], [83, 1, 1, "", "set_sampler"], [83, 1, 1, "", "set_storage"], [83, 1, 1, "", "set_writer"], [83, 2, 1, "", "storage"], [83, 2, 1, "", "transform"], [83, 2, 1, "", "write_count"], [83, 2, 1, "", "writer"]], "torchrl.data.datasets.RobosetExperienceReplay": [[84, 1, 1, "", "add"], [84, 1, 1, "", "append_transform"], [84, 1, 1, "", "as_remote"], [84, 2, 1, "", "batch_size"], [84, 2, 1, "", "data_path"], [84, 2, 1, "", "data_path_root"], [84, 1, 1, "", "delete"], [84, 1, 1, "", "dump"], [84, 1, 1, "", "dumps"], [84, 1, 1, "", "empty"], [84, 1, 1, "", "extend"], [84, 2, 1, "", "initialized"], [84, 1, 1, "", "insert_transform"], [84, 1, 1, "", "load"], [84, 1, 1, "", "loads"], [84, 1, 1, "", "next"], [84, 1, 1, "", "preprocess"], [84, 1, 1, "", "register_load_hook"], [84, 1, 1, "", "register_save_hook"], [84, 1, 1, "", "sample"], [84, 2, 1, "", "sampler"], [84, 1, 1, "", "save"], [84, 1, 1, "", "set_sampler"], [84, 1, 1, "", "set_storage"], [84, 1, 1, "", "set_writer"], [84, 2, 1, "", "storage"], [84, 2, 1, "", "transform"], [84, 2, 1, "", "write_count"], [84, 2, 1, "", "writer"]], "torchrl.data.datasets.VD4RLExperienceReplay": [[85, 1, 1, "", "add"], [85, 1, 1, "", "append_transform"], [85, 1, 1, "", "as_remote"], [85, 2, 1, "", "batch_size"], [85, 2, 1, "", "data_path"], [85, 2, 1, "", "data_path_root"], [85, 1, 1, "", "delete"], [85, 1, 1, "", "dump"], [85, 1, 1, "", "dumps"], [85, 1, 1, "", "empty"], [85, 1, 1, "", "extend"], [85, 2, 1, "", "initialized"], [85, 1, 1, "", "insert_transform"], [85, 1, 1, "", "load"], [85, 1, 1, "", "loads"], [85, 1, 1, "", "next"], [85, 1, 1, "", "preprocess"], [85, 1, 1, "", "register_load_hook"], [85, 1, 1, "", "register_save_hook"], [85, 1, 1, "", "sample"], [85, 2, 1, "", "sampler"], [85, 1, 1, "", "save"], [85, 1, 1, "", "set_sampler"], [85, 1, 1, "", "set_storage"], [85, 1, 1, "", "set_writer"], [85, 2, 1, "", "storage"], [85, 2, 1, "", "transform"], [85, 2, 1, "", "write_count"], [85, 2, 1, "", "writer"]], "torchrl.data.llm": [[86, 0, 1, "", "ContentBase"], [87, 0, 1, "", "History"], [88, 0, 1, "", "TopKRewardSelector"], [89, 0, 1, "", "add_chat_template"]], "torchrl.data.llm.ContentBase": [[86, 1, 1, "", "cat"], [86, 2, 1, "", "device"], [86, 1, 1, "", "dumps"], [86, 1, 1, "", "fields"], [86, 1, 1, "", "from_any"], [86, 1, 1, "", "from_dataclass"], [86, 1, 1, "", "from_h5"], [86, 1, 1, "", "from_modules"], [86, 1, 1, "", "from_namedtuple"], [86, 1, 1, "", "from_pytree"], [86, 1, 1, "", "from_remote_init"], [86, 1, 1, "", "from_struct_array"], [86, 1, 1, "", "from_tensordict"], [86, 1, 1, "", "from_tuple"], [86, 1, 1, "", "fromkeys"], [86, 1, 1, "", "get"], [86, 1, 1, "", "lazy_stack"], [86, 1, 1, "", "load"], [86, 1, 1, "", "load_"], [86, 1, 1, "", "load_memmap"], [86, 1, 1, "", "load_state_dict"], [86, 1, 1, "", "maybe_dense_stack"], [86, 1, 1, "", "memmap"], [86, 1, 1, "", "memmap_"], [86, 1, 1, "", "memmap_like"], [86, 1, 1, "", "memmap_refresh_"], [86, 1, 1, "", "save"], [86, 1, 1, "", "set"], [86, 1, 1, "", "stack"], [86, 1, 1, "", "state_dict"], [86, 1, 1, "", "to_tensordict"], [86, 1, 1, "", "unbind"]], "torchrl.data.llm.History": [[87, 1, 1, "", "append"], [87, 1, 1, "", "apply_chat_template"], [87, 1, 1, "", "cat"], [87, 1, 1, "", "default_spec"], [87, 2, 1, "", "device"], [87, 1, 1, "", "dumps"], [87, 1, 1, "", "fields"], [87, 1, 1, "", "from_any"], [87, 1, 1, "", "from_chats"], [87, 1, 1, "", "from_dataclass"], [87, 1, 1, "", "from_h5"], [87, 1, 1, "", "from_modules"], [87, 1, 1, "", "from_namedtuple"], [87, 1, 1, "", "from_pytree"], [87, 1, 1, "", "from_remote_init"], [87, 1, 1, "", "from_struct_array"], [87, 1, 1, "", "from_tensordict"], [87, 1, 1, "", "from_text"], [87, 1, 1, "", "from_tuple"], [87, 1, 1, "", "fromkeys"], [87, 1, 1, "", "get"], [87, 1, 1, "", "lazy_stack"], [87, 1, 1, "", "load"], [87, 1, 1, "", "load_"], [87, 1, 1, "", "load_memmap"], [87, 1, 1, "", "load_state_dict"], [87, 1, 1, "", "maybe_dense_stack"], [87, 1, 1, "", "memmap"], [87, 1, 1, "", "memmap_"], [87, 1, 1, "", "memmap_like"], [87, 1, 1, "", "memmap_refresh_"], [87, 1, 1, "", "save"], [87, 1, 1, "", "set"], [87, 1, 1, "", "stack"], [87, 1, 1, "", "state_dict"], [87, 1, 1, "", "to_tensordict"], [87, 1, 1, "", "unbind"]], "torchrl.data.llm.TopKRewardSelector": [[88, 1, 1, "", "add_module"], [88, 1, 1, "", "apply"], [88, 1, 1, "", "bfloat16"], [88, 1, 1, "", "buffers"], [88, 1, 1, "", "children"], [88, 1, 1, "", "close"], [88, 2, 1, "", "collector"], [88, 1, 1, "", "compile"], [88, 2, 1, "", "container"], [88, 1, 1, "", "cpu"], [88, 1, 1, "", "cuda"], [88, 1, 1, "", "double"], [88, 1, 1, "", "eval"], [88, 1, 1, "", "extra_repr"], [88, 1, 1, "", "float"], [88, 1, 1, "", "forward"], [88, 1, 1, "", "get_buffer"], [88, 1, 1, "", "get_extra_state"], [88, 1, 1, "", "get_parameter"], [88, 1, 1, "", "get_submodule"], [88, 1, 1, "", "half"], [88, 1, 1, "", "init"], [88, 1, 1, "", "inv"], [88, 1, 1, "", "ipu"], [88, 1, 1, "", "load_state_dict"], [88, 1, 1, "", "modules"], [88, 1, 1, "", "mtia"], [88, 1, 1, "", "named_buffers"], [88, 1, 1, "", "named_children"], [88, 1, 1, "", "named_modules"], [88, 1, 1, "", "named_parameters"], [88, 1, 1, "", "parameters"], [88, 2, 1, "", "parent"], [88, 1, 1, "", "register_backward_hook"], [88, 1, 1, "", "register_buffer"], [88, 1, 1, "", "register_forward_hook"], [88, 1, 1, "", "register_forward_pre_hook"], [88, 1, 1, "", "register_full_backward_hook"], [88, 1, 1, "", "register_full_backward_pre_hook"], [88, 1, 1, "", "register_load_state_dict_post_hook"], [88, 1, 1, "", "register_load_state_dict_pre_hook"], [88, 1, 1, "", "register_module"], [88, 1, 1, "", "register_parameter"], [88, 1, 1, "", "register_state_dict_post_hook"], [88, 1, 1, "", "register_state_dict_pre_hook"], [88, 1, 1, "", "requires_grad_"], [88, 1, 1, "", "set_extra_state"], [88, 1, 1, "", "set_submodule"], [88, 1, 1, "", "share_memory"], [88, 1, 1, "", "state_dict"], [88, 1, 1, "", "to"], [88, 1, 1, "", "to_empty"], [88, 1, 1, "", "train"], [88, 1, 1, "", "transform_action_spec"], [88, 1, 1, "", "transform_done_spec"], [88, 1, 1, "", "transform_env_batch_size"], [88, 1, 1, "", "transform_env_device"], [88, 1, 1, "", "transform_input_spec"], [88, 1, 1, "", "transform_observation_spec"], [88, 1, 1, "", "transform_output_spec"], [88, 1, 1, "", "transform_reward_spec"], [88, 1, 1, "", "transform_state_spec"], [88, 1, 1, "", "type"], [88, 1, 1, "", "xpu"], [88, 1, 1, "", "zero_grad"]], "torchrl.data.replay_buffers": [[90, 0, 1, "", "CompressedListStorage"], [91, 0, 1, "", "CompressedListStorageCheckpointer"], [92, 0, 1, "", "FlatStorageCheckpointer"], [93, 0, 1, "", "H5StorageCheckpointer"], [94, 0, 1, "", "ImmutableDatasetWriter"], [95, 0, 1, "", "LazyMemmapStorage"], [96, 0, 1, "", "LazyStackStorage"], [97, 0, 1, "", "LazyTensorStorage"], [98, 0, 1, "", "ListStorage"], [99, 0, 1, "", "ListStorageCheckpointer"], [100, 0, 1, "", "NestedStorageCheckpointer"], [101, 0, 1, "", "PrioritizedSampler"], [102, 0, 1, "", "PrioritizedSliceSampler"], [103, 0, 1, "", "RandomSampler"], [104, 0, 1, "", "RoundRobinWriter"], [105, 0, 1, "", "Sampler"], [106, 0, 1, "", "SamplerEnsemble"], [107, 0, 1, "", "SamplerWithoutReplacement"], [108, 0, 1, "", "SliceSampler"], [109, 0, 1, "", "SliceSamplerWithoutReplacement"], [110, 0, 1, "", "Storage"], [111, 0, 1, "", "StorageCheckpointerBase"], [112, 0, 1, "", "StorageEnsemble"], [113, 0, 1, "", "StorageEnsembleCheckpointer"], [114, 0, 1, "", "TensorDictMaxValueWriter"], [115, 0, 1, "", "TensorDictRoundRobinWriter"], [116, 0, 1, "", "TensorStorage"], [117, 0, 1, "", "TensorStorageCheckpointer"], [118, 0, 1, "", "Writer"], [119, 0, 1, "", "WriterEnsemble"]], "torchrl.data.replay_buffers.CompressedListStorage": [[90, 1, 1, "", "attach"], [90, 1, 1, "", "bytes"], [90, 1, 1, "", "dump"], [90, 1, 1, "", "load"], [90, 1, 1, "", "load_state_dict"], [90, 1, 1, "", "save"], [90, 1, 1, "", "state_dict"], [90, 1, 1, "", "to_bytestream"]], "torchrl.data.replay_buffers.CompressedListStorageCheckpointer": [[91, 1, 1, "", "dumps"], [91, 1, 1, "", "loads"]], "torchrl.data.replay_buffers.ImmutableDatasetWriter": [[94, 1, 1, "", "add"], [94, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.LazyMemmapStorage": [[95, 1, 1, "", "attach"], [95, 1, 1, "", "cleanup"], [95, 1, 1, "", "dump"], [95, 1, 1, "", "load"], [95, 1, 1, "", "save"]], "torchrl.data.replay_buffers.LazyStackStorage": [[96, 1, 1, "", "attach"], [96, 1, 1, "", "dump"], [96, 1, 1, "", "load"], [96, 1, 1, "", "save"]], "torchrl.data.replay_buffers.LazyTensorStorage": [[97, 1, 1, "", "attach"], [97, 1, 1, "", "dump"], [97, 1, 1, "", "load"], [97, 1, 1, "", "save"]], "torchrl.data.replay_buffers.ListStorage": [[98, 1, 1, "", "attach"], [98, 1, 1, "", "dump"], [98, 1, 1, "", "load"], [98, 1, 1, "", "save"]], "torchrl.data.replay_buffers.PrioritizedSampler": [[101, 1, 1, "", "update_priority"]], "torchrl.data.replay_buffers.PrioritizedSliceSampler": [[102, 1, 1, "", "update_priority"]], "torchrl.data.replay_buffers.RoundRobinWriter": [[104, 1, 1, "", "add"], [104, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.Storage": [[110, 1, 1, "", "attach"], [110, 1, 1, "", "dump"], [110, 1, 1, "", "load"], [110, 1, 1, "", "save"]], "torchrl.data.replay_buffers.StorageEnsemble": [[112, 1, 1, "", "attach"], [112, 1, 1, "", "dump"], [112, 1, 1, "", "load"], [112, 1, 1, "", "save"]], "torchrl.data.replay_buffers.TensorDictMaxValueWriter": [[114, 1, 1, "", "add"], [114, 1, 1, "", "extend"], [114, 1, 1, "", "get_insert_index"]], "torchrl.data.replay_buffers.TensorDictRoundRobinWriter": [[115, 1, 1, "", "add"], [115, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.TensorStorage": [[116, 1, 1, "", "attach"], [116, 1, 1, "", "dump"], [116, 1, 1, "", "load"], [116, 1, 1, "", "save"]], "torchrl.data.replay_buffers.Writer": [[118, 1, 1, "", "add"], [118, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.WriterEnsemble": [[119, 1, 1, "", "add"], [119, 1, 1, "", "extend"]], "torchrl.envs": [[120, 0, 1, "", "AsyncEnvPool"], [121, 3, 1, "", "BraxEnv"], [122, 3, 1, "", "BraxWrapper"], [123, 0, 1, "", "ChessEnv"], [124, 3, 1, "", "DMControlEnv"], [125, 3, 1, "", "DMControlWrapper"], [126, 0, 1, "", "EnvBase"], [127, 0, 1, "", "EnvCreator"], [128, 0, 1, "", "EnvMetaData"], [129, 3, 1, "", "GymEnv"], [130, 0, 1, "", "GymLikeEnv"], [131, 3, 1, "", "GymWrapper"], [132, 3, 1, "", "HabitatEnv"], [133, 3, 1, "", "IsaacGymEnv"], [134, 3, 1, "", "IsaacGymWrapper"], [135, 3, 1, "", "IsaacLabWrapper"], [136, 3, 1, "", "JumanjiEnv"], [137, 3, 1, "", "JumanjiWrapper"], [138, 0, 1, "", "LLMHashingEnv"], [139, 3, 1, "", "MOGymEnv"], [140, 3, 1, "", "MOGymWrapper"], [141, 3, 1, "", "MarlGroupMapType"], [142, 3, 1, "", "MeltingpotEnv"], [143, 3, 1, "", "MeltingpotWrapper"], [144, 3, 1, "", "ModelBasedEnvBase"], [145, 3, 1, "", "MultiThreadedEnv"], [146, 3, 1, "", "MultiThreadedEnvWrapper"], [147, 3, 1, "", "OpenMLEnv"], [148, 3, 1, "", "OpenSpielEnv"], [149, 3, 1, "", "OpenSpielWrapper"], [150, 0, 1, "", "ParallelEnv"], [151, 0, 1, "", "PendulumEnv"], [152, 3, 1, "", "PettingZooEnv"], [153, 3, 1, "", "PettingZooWrapper"], [154, 0, 1, "", "ProcessorAsyncEnvPool"], [155, 3, 1, "", "RoboHiveEnv"], [156, 3, 1, "", "SMACv2Env"], [157, 3, 1, "", "SMACv2Wrapper"], [158, 0, 1, "", "SerialEnv"], [159, 0, 1, "", "ThreadingAsyncEnvPool"], [160, 0, 1, "", "TicTacToeEnv"], [161, 3, 1, "", "UnityMLAgentsEnv"], [162, 3, 1, "", "UnityMLAgentsWrapper"], [163, 3, 1, "", "VmasEnv"], [164, 3, 1, "", "VmasWrapper"], [165, 3, 1, "", "check_env_specs"], [166, 3, 1, "", "check_marl_grouping"], [167, 3, 1, "", "exploration_type"], [168, 3, 1, "", "get_available_libraries"], [169, 3, 1, "", "gym_backend"], [206, 3, 1, "", "make_composite_from_td"], [144, 1, 1, "", "rand_step"], [209, 3, 1, "", "register_gym_spec_conversion"], [144, 1, 1, "", "reset"], [144, 1, 1, "", "rollout"], [210, 3, 1, "", "set_exploration_type"], [211, 3, 1, "", "set_gym_backend"], [144, 1, 1, "", "set_seed"], [144, 1, 1, "", "step"], [212, 3, 1, "", "step_mdp"], [213, 3, 1, "", "terminated_or_truncated"]], "torchrl.envs.AsyncEnvPool": [[120, 2, 1, "", "action_key"], [120, 2, 1, "", "action_keys"], [120, 2, 1, "", "action_spec"], [120, 2, 1, "", "action_spec_unbatched"], [120, 1, 1, "", "add_module"], [120, 1, 1, "", "add_truncated_keys"], [120, 1, 1, "", "all_actions"], [120, 1, 1, "", "any_done"], [120, 1, 1, "", "append_transform"], [120, 1, 1, "", "apply"], [120, 1, 1, "", "auto_specs_"], [120, 2, 1, "", "batch_dims"], [120, 2, 1, "", "batch_locked"], [120, 2, 1, "", "batch_size"], [120, 1, 1, "", "bfloat16"], [120, 1, 1, "", "buffers"], [120, 1, 1, "", "cardinality"], [120, 1, 1, "", "check_env_specs"], [120, 1, 1, "", "children"], [120, 2, 1, "", "collector"], [120, 1, 1, "", "compile"], [120, 1, 1, "", "cpu"], [120, 1, 1, "", "cuda"], [120, 2, 1, "", "done_key"], [120, 2, 1, "", "done_keys"], [120, 2, 1, "", "done_keys_groups"], [120, 2, 1, "", "done_spec"], [120, 2, 1, "", "done_spec_unbatched"], [120, 1, 1, "", "double"], [120, 1, 1, "", "empty_cache"], [120, 2, 1, "", "env_batch_sizes"], [120, 1, 1, "", "eval"], [120, 1, 1, "", "extra_repr"], [120, 1, 1, "", "fake_tensordict"], [120, 1, 1, "", "float"], [120, 1, 1, "", "forward"], [120, 2, 1, "", "full_action_spec"], [120, 2, 1, "", "full_action_spec_unbatched"], [120, 2, 1, "", "full_done_spec"], [120, 2, 1, "", "full_done_spec_unbatched"], [120, 2, 1, "", "full_observation_spec_unbatched"], [120, 2, 1, "", "full_reward_spec"], [120, 2, 1, "", "full_reward_spec_unbatched"], [120, 2, 1, "", "full_state_spec"], [120, 2, 1, "", "full_state_spec_unbatched"], [120, 1, 1, "", "get_buffer"], [120, 1, 1, "", "get_extra_state"], [120, 1, 1, "", "get_parameter"], [120, 1, 1, "", "get_submodule"], [120, 1, 1, "", "half"], [120, 2, 1, "", "input_spec"], [120, 2, 1, "", "input_spec_unbatched"], [120, 1, 1, "", "ipu"], [120, 2, 1, "", "is_spec_locked"], [120, 1, 1, "", "load_state_dict"], [120, 1, 1, "", "maybe_reset"], [120, 1, 1, "", "modules"], [120, 1, 1, "", "mtia"], [120, 1, 1, "", "named_buffers"], [120, 1, 1, "", "named_children"], [120, 1, 1, "", "named_modules"], [120, 1, 1, "", "named_parameters"], [120, 2, 1, "", "observation_keys"], [120, 2, 1, "", "observation_spec"], [120, 2, 1, "", "observation_spec_unbatched"], [120, 2, 1, "", "output_spec"], [120, 2, 1, "", "output_spec_unbatched"], [120, 1, 1, "", "parameters"], [120, 1, 1, "", "rand_action"], [120, 1, 1, "", "rand_step"], [120, 1, 1, "", "register_backward_hook"], [120, 1, 1, "", "register_buffer"], [120, 1, 1, "", "register_collector"], [120, 1, 1, "", "register_forward_hook"], [120, 1, 1, "", "register_forward_pre_hook"], [120, 1, 1, "", "register_full_backward_hook"], [120, 1, 1, "", "register_full_backward_pre_hook"], [120, 1, 1, "", "register_gym"], [120, 1, 1, "", "register_load_state_dict_post_hook"], [120, 1, 1, "", "register_load_state_dict_pre_hook"], [120, 1, 1, "", "register_module"], [120, 1, 1, "", "register_parameter"], [120, 1, 1, "", "register_state_dict_post_hook"], [120, 1, 1, "", "register_state_dict_pre_hook"], [120, 1, 1, "", "requires_grad_"], [120, 1, 1, "", "reset"], [120, 2, 1, "", "reset_keys"], [120, 2, 1, "", "reward_key"], [120, 2, 1, "", "reward_keys"], [120, 2, 1, "", "reward_spec"], [120, 2, 1, "", "reward_spec_unbatched"], [120, 1, 1, "", "rollout"], [120, 1, 1, "", "set_extra_state"], [120, 1, 1, "", "set_seed"], [120, 1, 1, "", "set_spec_lock_"], [120, 1, 1, "", "set_submodule"], [120, 2, 1, "", "shape"], [120, 1, 1, "", "share_memory"], [120, 2, 1, "", "specs"], [120, 1, 1, "", "state_dict"], [120, 2, 1, "", "state_keys"], [120, 2, 1, "", "state_spec"], [120, 2, 1, "", "state_spec_unbatched"], [120, 1, 1, "", "step"], [120, 1, 1, "", "step_and_maybe_reset"], [120, 1, 1, "", "step_mdp"], [120, 1, 1, "", "to"], [120, 1, 1, "", "to_empty"], [120, 1, 1, "", "train"], [120, 1, 1, "", "type"], [120, 1, 1, "", "xpu"], [120, 1, 1, "", "zero_grad"]], "torchrl.envs.ChessEnv": [[123, 2, 1, "", "action_key"], [123, 2, 1, "", "action_keys"], [123, 2, 1, "", "action_spec"], [123, 2, 1, "", "action_spec_unbatched"], [123, 1, 1, "", "add_module"], [123, 1, 1, "", "add_truncated_keys"], [123, 1, 1, "", "all_actions"], [123, 1, 1, "", "any_done"], [123, 1, 1, "", "append_transform"], [123, 1, 1, "", "apply"], [123, 1, 1, "", "auto_specs_"], [123, 2, 1, "", "batch_dims"], [123, 2, 1, "", "batch_locked"], [123, 2, 1, "", "batch_size"], [123, 1, 1, "", "bfloat16"], [123, 1, 1, "", "buffers"], [123, 1, 1, "", "cardinality"], [123, 1, 1, "", "check_env_specs"], [123, 1, 1, "", "children"], [123, 2, 1, "", "collector"], [123, 1, 1, "", "compile"], [123, 1, 1, "", "cpu"], [123, 1, 1, "", "cuda"], [123, 2, 1, "", "done_key"], [123, 2, 1, "", "done_keys"], [123, 2, 1, "", "done_keys_groups"], [123, 2, 1, "", "done_spec"], [123, 2, 1, "", "done_spec_unbatched"], [123, 1, 1, "", "double"], [123, 1, 1, "", "empty_cache"], [123, 1, 1, "", "eval"], [123, 1, 1, "", "extra_repr"], [123, 1, 1, "", "fake_tensordict"], [123, 1, 1, "", "float"], [123, 1, 1, "", "forward"], [123, 2, 1, "", "full_action_spec"], [123, 2, 1, "", "full_action_spec_unbatched"], [123, 2, 1, "", "full_done_spec"], [123, 2, 1, "", "full_done_spec_unbatched"], [123, 2, 1, "", "full_observation_spec_unbatched"], [123, 2, 1, "", "full_reward_spec"], [123, 2, 1, "", "full_reward_spec_unbatched"], [123, 2, 1, "", "full_state_spec"], [123, 2, 1, "", "full_state_spec_unbatched"], [123, 1, 1, "", "get_buffer"], [123, 1, 1, "", "get_extra_state"], [123, 1, 1, "", "get_legal_moves"], [123, 1, 1, "", "get_parameter"], [123, 1, 1, "", "get_submodule"], [123, 1, 1, "", "half"], [123, 2, 1, "", "input_spec"], [123, 2, 1, "", "input_spec_unbatched"], [123, 1, 1, "", "ipu"], [123, 2, 1, "", "is_spec_locked"], [123, 1, 1, "", "load_state_dict"], [123, 1, 1, "", "maybe_reset"], [123, 1, 1, "", "modules"], [123, 1, 1, "", "mtia"], [123, 1, 1, "", "named_buffers"], [123, 1, 1, "", "named_children"], [123, 1, 1, "", "named_modules"], [123, 1, 1, "", "named_parameters"], [123, 2, 1, "", "observation_keys"], [123, 2, 1, "", "observation_spec"], [123, 2, 1, "", "observation_spec_unbatched"], [123, 2, 1, "", "output_spec"], [123, 2, 1, "", "output_spec_unbatched"], [123, 1, 1, "", "parameters"], [123, 1, 1, "", "rand_action"], [123, 1, 1, "", "rand_step"], [123, 1, 1, "", "register_backward_hook"], [123, 1, 1, "", "register_buffer"], [123, 1, 1, "", "register_collector"], [123, 1, 1, "", "register_forward_hook"], [123, 1, 1, "", "register_forward_pre_hook"], [123, 1, 1, "", "register_full_backward_hook"], [123, 1, 1, "", "register_full_backward_pre_hook"], [123, 1, 1, "", "register_gym"], [123, 1, 1, "", "register_load_state_dict_post_hook"], [123, 1, 1, "", "register_load_state_dict_pre_hook"], [123, 1, 1, "", "register_module"], [123, 1, 1, "", "register_parameter"], [123, 1, 1, "", "register_state_dict_post_hook"], [123, 1, 1, "", "register_state_dict_pre_hook"], [123, 1, 1, "", "requires_grad_"], [123, 1, 1, "", "reset"], [123, 2, 1, "", "reset_keys"], [123, 2, 1, "", "reward_key"], [123, 2, 1, "", "reward_keys"], [123, 2, 1, "", "reward_spec"], [123, 2, 1, "", "reward_spec_unbatched"], [123, 1, 1, "", "rollout"], [123, 1, 1, "", "set_extra_state"], [123, 1, 1, "", "set_seed"], [123, 1, 1, "", "set_spec_lock_"], [123, 1, 1, "", "set_submodule"], [123, 2, 1, "", "shape"], [123, 1, 1, "", "share_memory"], [123, 2, 1, "", "specs"], [123, 1, 1, "", "state_dict"], [123, 2, 1, "", "state_keys"], [123, 2, 1, "", "state_spec"], [123, 2, 1, "", "state_spec_unbatched"], [123, 1, 1, "", "step"], [123, 1, 1, "", "step_and_maybe_reset"], [123, 1, 1, "", "step_mdp"], [123, 1, 1, "", "to"], [123, 1, 1, "", "to_empty"], [123, 1, 1, "", "train"], [123, 1, 1, "", "type"], [123, 1, 1, "", "xpu"], [123, 1, 1, "", "zero_grad"]], "torchrl.envs.EnvBase": [[126, 2, 1, "", "action_key"], [126, 2, 1, "", "action_keys"], [126, 2, 1, "", "action_spec"], [126, 2, 1, "", "action_spec_unbatched"], [126, 1, 1, "", "add_module"], [126, 1, 1, "", "add_truncated_keys"], [126, 1, 1, "", "all_actions"], [126, 1, 1, "", "any_done"], [126, 1, 1, "", "append_transform"], [126, 1, 1, "", "apply"], [126, 1, 1, "", "auto_specs_"], [126, 2, 1, "", "batch_dims"], [126, 2, 1, "", "batch_locked"], [126, 2, 1, "", "batch_size"], [126, 1, 1, "", "bfloat16"], [126, 1, 1, "", "buffers"], [126, 1, 1, "", "cardinality"], [126, 1, 1, "", "check_env_specs"], [126, 1, 1, "", "children"], [126, 2, 1, "", "collector"], [126, 1, 1, "", "compile"], [126, 1, 1, "", "cpu"], [126, 1, 1, "", "cuda"], [126, 2, 1, "", "done_key"], [126, 2, 1, "", "done_keys"], [126, 2, 1, "", "done_keys_groups"], [126, 2, 1, "", "done_spec"], [126, 2, 1, "", "done_spec_unbatched"], [126, 1, 1, "", "double"], [126, 1, 1, "", "empty_cache"], [126, 1, 1, "", "eval"], [126, 1, 1, "", "extra_repr"], [126, 1, 1, "", "fake_tensordict"], [126, 1, 1, "", "float"], [126, 1, 1, "", "forward"], [126, 2, 1, "", "full_action_spec"], [126, 2, 1, "", "full_action_spec_unbatched"], [126, 2, 1, "", "full_done_spec"], [126, 2, 1, "", "full_done_spec_unbatched"], [126, 2, 1, "", "full_observation_spec_unbatched"], [126, 2, 1, "", "full_reward_spec"], [126, 2, 1, "", "full_reward_spec_unbatched"], [126, 2, 1, "", "full_state_spec"], [126, 2, 1, "", "full_state_spec_unbatched"], [126, 1, 1, "", "get_buffer"], [126, 1, 1, "", "get_extra_state"], [126, 1, 1, "", "get_parameter"], [126, 1, 1, "", "get_submodule"], [126, 1, 1, "", "half"], [126, 2, 1, "", "input_spec"], [126, 2, 1, "", "input_spec_unbatched"], [126, 1, 1, "", "ipu"], [126, 2, 1, "", "is_spec_locked"], [126, 1, 1, "", "load_state_dict"], [126, 1, 1, "", "maybe_reset"], [126, 1, 1, "", "modules"], [126, 1, 1, "", "mtia"], [126, 1, 1, "", "named_buffers"], [126, 1, 1, "", "named_children"], [126, 1, 1, "", "named_modules"], [126, 1, 1, "", "named_parameters"], [126, 2, 1, "", "observation_keys"], [126, 2, 1, "", "observation_spec"], [126, 2, 1, "", "observation_spec_unbatched"], [126, 2, 1, "", "output_spec"], [126, 2, 1, "", "output_spec_unbatched"], [126, 1, 1, "", "parameters"], [126, 1, 1, "", "rand_action"], [126, 1, 1, "id0", "rand_step"], [126, 1, 1, "", "register_backward_hook"], [126, 1, 1, "", "register_buffer"], [126, 1, 1, "", "register_collector"], [126, 1, 1, "", "register_forward_hook"], [126, 1, 1, "", "register_forward_pre_hook"], [126, 1, 1, "", "register_full_backward_hook"], [126, 1, 1, "", "register_full_backward_pre_hook"], [126, 1, 1, "", "register_gym"], [126, 1, 1, "", "register_load_state_dict_post_hook"], [126, 1, 1, "", "register_load_state_dict_pre_hook"], [126, 1, 1, "", "register_module"], [126, 1, 1, "", "register_parameter"], [126, 1, 1, "", "register_state_dict_post_hook"], [126, 1, 1, "", "register_state_dict_pre_hook"], [126, 1, 1, "", "requires_grad_"], [126, 1, 1, "id1", "reset"], [126, 2, 1, "", "reset_keys"], [126, 2, 1, "", "reward_key"], [126, 2, 1, "", "reward_keys"], [126, 2, 1, "", "reward_spec"], [126, 2, 1, "", "reward_spec_unbatched"], [126, 1, 1, "id2", "rollout"], [126, 1, 1, "", "set_extra_state"], [126, 1, 1, "id3", "set_seed"], [126, 1, 1, "", "set_spec_lock_"], [126, 1, 1, "", "set_submodule"], [126, 2, 1, "", "shape"], [126, 1, 1, "", "share_memory"], [126, 2, 1, "", "specs"], [126, 1, 1, "", "state_dict"], [126, 2, 1, "", "state_keys"], [126, 2, 1, "", "state_spec"], [126, 2, 1, "", "state_spec_unbatched"], [126, 1, 1, "id4", "step"], [126, 1, 1, "", "step_and_maybe_reset"], [126, 1, 1, "", "step_mdp"], [126, 1, 1, "", "to"], [126, 1, 1, "", "to_empty"], [126, 1, 1, "", "train"], [126, 1, 1, "", "type"], [126, 1, 1, "", "xpu"], [126, 1, 1, "", "zero_grad"]], "torchrl.envs.EnvCreator": [[127, 1, 1, "", "make_variant"]], "torchrl.envs.GymLikeEnv": [[130, 2, 1, "", "action_key"], [130, 2, 1, "", "action_keys"], [130, 2, 1, "", "action_spec"], [130, 2, 1, "", "action_spec_unbatched"], [130, 1, 1, "", "add_module"], [130, 1, 1, "", "add_truncated_keys"], [130, 1, 1, "", "all_actions"], [130, 1, 1, "", "any_done"], [130, 1, 1, "", "append_transform"], [130, 1, 1, "", "apply"], [130, 1, 1, "", "auto_register_info_dict"], [130, 1, 1, "", "auto_specs_"], [130, 2, 1, "", "batch_dims"], [130, 2, 1, "", "batch_locked"], [130, 2, 1, "", "batch_size"], [130, 1, 1, "", "bfloat16"], [130, 1, 1, "", "buffers"], [130, 1, 1, "", "cardinality"], [130, 1, 1, "", "check_env_specs"], [130, 1, 1, "", "children"], [130, 1, 1, "", "close"], [130, 2, 1, "", "collector"], [130, 1, 1, "", "compile"], [130, 1, 1, "", "cpu"], [130, 1, 1, "", "cuda"], [130, 2, 1, "", "done_key"], [130, 2, 1, "", "done_keys"], [130, 2, 1, "", "done_keys_groups"], [130, 2, 1, "", "done_spec"], [130, 2, 1, "", "done_spec_unbatched"], [130, 1, 1, "", "double"], [130, 1, 1, "", "empty_cache"], [130, 1, 1, "", "eval"], [130, 1, 1, "", "extra_repr"], [130, 1, 1, "", "fake_tensordict"], [130, 1, 1, "", "fast_encoding"], [130, 1, 1, "", "float"], [130, 1, 1, "", "forward"], [130, 2, 1, "", "full_action_spec"], [130, 2, 1, "", "full_action_spec_unbatched"], [130, 2, 1, "", "full_done_spec"], [130, 2, 1, "", "full_done_spec_unbatched"], [130, 2, 1, "", "full_observation_spec_unbatched"], [130, 2, 1, "", "full_reward_spec"], [130, 2, 1, "", "full_reward_spec_unbatched"], [130, 2, 1, "", "full_state_spec"], [130, 2, 1, "", "full_state_spec_unbatched"], [130, 1, 1, "", "get_buffer"], [130, 1, 1, "", "get_extra_state"], [130, 1, 1, "", "get_parameter"], [130, 1, 1, "", "get_submodule"], [130, 1, 1, "", "half"], [130, 2, 1, "", "input_spec"], [130, 2, 1, "", "input_spec_unbatched"], [130, 1, 1, "", "ipu"], [130, 2, 1, "", "is_spec_locked"], [130, 1, 1, "", "load_state_dict"], [130, 1, 1, "", "maybe_reset"], [130, 1, 1, "", "modules"], [130, 1, 1, "", "mtia"], [130, 1, 1, "", "named_buffers"], [130, 1, 1, "", "named_children"], [130, 1, 1, "", "named_modules"], [130, 1, 1, "", "named_parameters"], [130, 2, 1, "", "observation_keys"], [130, 2, 1, "", "observation_spec"], [130, 2, 1, "", "observation_spec_unbatched"], [130, 2, 1, "", "output_spec"], [130, 2, 1, "", "output_spec_unbatched"], [130, 1, 1, "", "parameters"], [130, 1, 1, "", "rand_action"], [130, 1, 1, "", "rand_step"], [130, 1, 1, "", "read_action"], [130, 1, 1, "", "read_done"], [130, 1, 1, "", "read_obs"], [130, 1, 1, "", "read_reward"], [130, 1, 1, "", "register_backward_hook"], [130, 1, 1, "", "register_buffer"], [130, 1, 1, "", "register_collector"], [130, 1, 1, "", "register_forward_hook"], [130, 1, 1, "", "register_forward_pre_hook"], [130, 1, 1, "", "register_full_backward_hook"], [130, 1, 1, "", "register_full_backward_pre_hook"], [130, 1, 1, "", "register_gym"], [130, 1, 1, "", "register_load_state_dict_post_hook"], [130, 1, 1, "", "register_load_state_dict_pre_hook"], [130, 1, 1, "", "register_module"], [130, 1, 1, "", "register_parameter"], [130, 1, 1, "", "register_state_dict_post_hook"], [130, 1, 1, "", "register_state_dict_pre_hook"], [130, 1, 1, "", "requires_grad_"], [130, 1, 1, "", "reset"], [130, 2, 1, "", "reset_keys"], [130, 2, 1, "", "reward_key"], [130, 2, 1, "", "reward_keys"], [130, 2, 1, "", "reward_spec"], [130, 2, 1, "", "reward_spec_unbatched"], [130, 1, 1, "", "rollout"], [130, 1, 1, "", "set_extra_state"], [130, 1, 1, "", "set_info_dict_reader"], [130, 1, 1, "", "set_seed"], [130, 1, 1, "", "set_spec_lock_"], [130, 1, 1, "", "set_submodule"], [130, 2, 1, "", "shape"], [130, 1, 1, "", "share_memory"], [130, 2, 1, "", "specs"], [130, 1, 1, "", "state_dict"], [130, 2, 1, "", "state_keys"], [130, 2, 1, "", "state_spec"], [130, 2, 1, "", "state_spec_unbatched"], [130, 1, 1, "", "step"], [130, 1, 1, "", "step_and_maybe_reset"], [130, 1, 1, "", "step_mdp"], [130, 1, 1, "", "to"], [130, 1, 1, "", "to_empty"], [130, 1, 1, "", "train"], [130, 1, 1, "", "type"], [130, 1, 1, "", "xpu"], [130, 1, 1, "", "zero_grad"]], "torchrl.envs.LLMHashingEnv": [[138, 2, 1, "", "action_key"], [138, 2, 1, "", "action_keys"], [138, 2, 1, "", "action_spec"], [138, 2, 1, "", "action_spec_unbatched"], [138, 1, 1, "", "add_module"], [138, 1, 1, "", "add_truncated_keys"], [138, 1, 1, "", "all_actions"], [138, 1, 1, "", "any_done"], [138, 1, 1, "", "append_transform"], [138, 1, 1, "", "apply"], [138, 1, 1, "", "auto_specs_"], [138, 2, 1, "", "batch_dims"], [138, 2, 1, "", "batch_locked"], [138, 2, 1, "", "batch_size"], [138, 1, 1, "", "bfloat16"], [138, 1, 1, "", "buffers"], [138, 1, 1, "", "cardinality"], [138, 1, 1, "", "check_env_specs"], [138, 1, 1, "", "children"], [138, 2, 1, "", "collector"], [138, 1, 1, "", "compile"], [138, 1, 1, "", "cpu"], [138, 1, 1, "", "cuda"], [138, 2, 1, "", "done_key"], [138, 2, 1, "", "done_keys"], [138, 2, 1, "", "done_keys_groups"], [138, 2, 1, "", "done_spec"], [138, 2, 1, "", "done_spec_unbatched"], [138, 1, 1, "", "double"], [138, 1, 1, "", "empty_cache"], [138, 1, 1, "", "eval"], [138, 1, 1, "", "extra_repr"], [138, 1, 1, "", "fake_tensordict"], [138, 1, 1, "", "float"], [138, 1, 1, "", "forward"], [138, 2, 1, "", "full_action_spec"], [138, 2, 1, "", "full_action_spec_unbatched"], [138, 2, 1, "", "full_done_spec"], [138, 2, 1, "", "full_done_spec_unbatched"], [138, 2, 1, "", "full_observation_spec_unbatched"], [138, 2, 1, "", "full_reward_spec"], [138, 2, 1, "", "full_reward_spec_unbatched"], [138, 2, 1, "", "full_state_spec"], [138, 2, 1, "", "full_state_spec_unbatched"], [138, 1, 1, "", "get_buffer"], [138, 1, 1, "", "get_extra_state"], [138, 1, 1, "", "get_parameter"], [138, 1, 1, "", "get_submodule"], [138, 1, 1, "", "half"], [138, 2, 1, "", "input_spec"], [138, 2, 1, "", "input_spec_unbatched"], [138, 1, 1, "", "ipu"], [138, 2, 1, "", "is_spec_locked"], [138, 1, 1, "", "load_state_dict"], [138, 1, 1, "", "make_tensordict"], [138, 1, 1, "", "maybe_reset"], [138, 1, 1, "", "modules"], [138, 1, 1, "", "mtia"], [138, 1, 1, "", "named_buffers"], [138, 1, 1, "", "named_children"], [138, 1, 1, "", "named_modules"], [138, 1, 1, "", "named_parameters"], [138, 2, 1, "", "observation_keys"], [138, 2, 1, "", "observation_spec"], [138, 2, 1, "", "observation_spec_unbatched"], [138, 2, 1, "", "output_spec"], [138, 2, 1, "", "output_spec_unbatched"], [138, 1, 1, "", "parameters"], [138, 1, 1, "", "rand_action"], [138, 1, 1, "", "rand_step"], [138, 1, 1, "", "register_backward_hook"], [138, 1, 1, "", "register_buffer"], [138, 1, 1, "", "register_collector"], [138, 1, 1, "", "register_forward_hook"], [138, 1, 1, "", "register_forward_pre_hook"], [138, 1, 1, "", "register_full_backward_hook"], [138, 1, 1, "", "register_full_backward_pre_hook"], [138, 1, 1, "", "register_gym"], [138, 1, 1, "", "register_load_state_dict_post_hook"], [138, 1, 1, "", "register_load_state_dict_pre_hook"], [138, 1, 1, "", "register_module"], [138, 1, 1, "", "register_parameter"], [138, 1, 1, "", "register_state_dict_post_hook"], [138, 1, 1, "", "register_state_dict_pre_hook"], [138, 1, 1, "", "requires_grad_"], [138, 1, 1, "", "reset"], [138, 2, 1, "", "reset_keys"], [138, 2, 1, "", "reward_key"], [138, 2, 1, "", "reward_keys"], [138, 2, 1, "", "reward_spec"], [138, 2, 1, "", "reward_spec_unbatched"], [138, 1, 1, "", "rollout"], [138, 1, 1, "", "set_extra_state"], [138, 1, 1, "", "set_seed"], [138, 1, 1, "", "set_spec_lock_"], [138, 1, 1, "", "set_submodule"], [138, 2, 1, "", "shape"], [138, 1, 1, "", "share_memory"], [138, 2, 1, "", "specs"], [138, 1, 1, "", "state_dict"], [138, 2, 1, "", "state_keys"], [138, 2, 1, "", "state_spec"], [138, 2, 1, "", "state_spec_unbatched"], [138, 1, 1, "", "step"], [138, 1, 1, "", "step_and_maybe_reset"], [138, 1, 1, "", "step_mdp"], [138, 1, 1, "", "to"], [138, 1, 1, "", "to_empty"], [138, 1, 1, "", "train"], [138, 1, 1, "", "type"], [138, 1, 1, "", "xpu"], [138, 1, 1, "", "zero_grad"]], "torchrl.envs.ParallelEnv": [[150, 2, 1, "", "action_key"], [150, 2, 1, "", "action_keys"], [150, 2, 1, "", "action_spec"], [150, 2, 1, "", "action_spec_unbatched"], [150, 1, 1, "", "add_module"], [150, 1, 1, "", "add_truncated_keys"], [150, 1, 1, "", "all_actions"], [150, 1, 1, "", "any_done"], [150, 1, 1, "", "append_transform"], [150, 1, 1, "", "apply"], [150, 1, 1, "", "auto_specs_"], [150, 2, 1, "", "batch_dims"], [150, 2, 1, "", "batch_locked"], [150, 2, 1, "", "batch_size"], [150, 1, 1, "", "bfloat16"], [150, 1, 1, "", "buffers"], [150, 1, 1, "", "cardinality"], [150, 1, 1, "", "check_env_specs"], [150, 1, 1, "", "children"], [150, 2, 1, "", "collector"], [150, 1, 1, "", "compile"], [150, 1, 1, "", "cpu"], [150, 1, 1, "", "cuda"], [150, 2, 1, "", "done_key"], [150, 2, 1, "", "done_keys"], [150, 2, 1, "", "done_keys_groups"], [150, 2, 1, "", "done_spec"], [150, 2, 1, "", "done_spec_unbatched"], [150, 1, 1, "", "double"], [150, 1, 1, "", "empty_cache"], [150, 1, 1, "", "eval"], [150, 1, 1, "", "extra_repr"], [150, 1, 1, "", "fake_tensordict"], [150, 1, 1, "", "float"], [150, 1, 1, "", "forward"], [150, 2, 1, "", "full_action_spec"], [150, 2, 1, "", "full_action_spec_unbatched"], [150, 2, 1, "", "full_done_spec"], [150, 2, 1, "", "full_done_spec_unbatched"], [150, 2, 1, "", "full_observation_spec_unbatched"], [150, 2, 1, "", "full_reward_spec"], [150, 2, 1, "", "full_reward_spec_unbatched"], [150, 2, 1, "", "full_state_spec"], [150, 2, 1, "", "full_state_spec_unbatched"], [150, 1, 1, "", "get_buffer"], [150, 1, 1, "", "get_extra_state"], [150, 1, 1, "", "get_parameter"], [150, 1, 1, "", "get_submodule"], [150, 1, 1, "", "half"], [150, 2, 1, "", "input_spec"], [150, 2, 1, "", "input_spec_unbatched"], [150, 1, 1, "", "ipu"], [150, 2, 1, "", "is_spec_locked"], [150, 1, 1, "", "load_state_dict"], [150, 1, 1, "", "maybe_reset"], [150, 1, 1, "", "modules"], [150, 1, 1, "", "mtia"], [150, 1, 1, "", "named_buffers"], [150, 1, 1, "", "named_children"], [150, 1, 1, "", "named_modules"], [150, 1, 1, "", "named_parameters"], [150, 2, 1, "", "observation_keys"], [150, 2, 1, "", "observation_spec"], [150, 2, 1, "", "observation_spec_unbatched"], [150, 2, 1, "", "output_spec"], [150, 2, 1, "", "output_spec_unbatched"], [150, 1, 1, "", "parameters"], [150, 1, 1, "", "rand_action"], [150, 1, 1, "", "rand_step"], [150, 1, 1, "", "register_backward_hook"], [150, 1, 1, "", "register_buffer"], [150, 1, 1, "", "register_collector"], [150, 1, 1, "", "register_forward_hook"], [150, 1, 1, "", "register_forward_pre_hook"], [150, 1, 1, "", "register_full_backward_hook"], [150, 1, 1, "", "register_full_backward_pre_hook"], [150, 1, 1, "", "register_gym"], [150, 1, 1, "", "register_load_state_dict_post_hook"], [150, 1, 1, "", "register_load_state_dict_pre_hook"], [150, 1, 1, "", "register_module"], [150, 1, 1, "", "register_parameter"], [150, 1, 1, "", "register_state_dict_post_hook"], [150, 1, 1, "", "register_state_dict_pre_hook"], [150, 1, 1, "", "requires_grad_"], [150, 1, 1, "", "reset"], [150, 2, 1, "", "reset_keys"], [150, 2, 1, "", "reward_key"], [150, 2, 1, "", "reward_keys"], [150, 2, 1, "", "reward_spec"], [150, 2, 1, "", "reward_spec_unbatched"], [150, 1, 1, "", "rollout"], [150, 1, 1, "", "set_extra_state"], [150, 1, 1, "", "set_seed"], [150, 1, 1, "", "set_spec_lock_"], [150, 1, 1, "", "set_submodule"], [150, 2, 1, "", "shape"], [150, 1, 1, "", "share_memory"], [150, 2, 1, "", "specs"], [150, 1, 1, "", "state_dict"], [150, 2, 1, "", "state_keys"], [150, 2, 1, "", "state_spec"], [150, 2, 1, "", "state_spec_unbatched"], [150, 1, 1, "", "step"], [150, 1, 1, "", "step_and_maybe_reset"], [150, 1, 1, "", "step_mdp"], [150, 1, 1, "", "to"], [150, 1, 1, "", "to_empty"], [150, 1, 1, "", "train"], [150, 1, 1, "", "type"], [150, 1, 1, "", "update_kwargs"], [150, 1, 1, "", "xpu"], [150, 1, 1, "", "zero_grad"]], "torchrl.envs.PendulumEnv": [[151, 2, 1, "", "action_key"], [151, 2, 1, "", "action_keys"], [151, 2, 1, "", "action_spec"], [151, 2, 1, "", "action_spec_unbatched"], [151, 1, 1, "", "add_module"], [151, 1, 1, "", "add_truncated_keys"], [151, 1, 1, "", "all_actions"], [151, 1, 1, "", "any_done"], [151, 1, 1, "", "append_transform"], [151, 1, 1, "", "apply"], [151, 1, 1, "", "auto_specs_"], [151, 2, 1, "", "batch_dims"], [151, 2, 1, "", "batch_size"], [151, 1, 1, "", "bfloat16"], [151, 1, 1, "", "buffers"], [151, 1, 1, "", "cardinality"], [151, 1, 1, "", "check_env_specs"], [151, 1, 1, "", "children"], [151, 2, 1, "", "collector"], [151, 1, 1, "", "compile"], [151, 1, 1, "", "cpu"], [151, 1, 1, "", "cuda"], [151, 2, 1, "", "done_key"], [151, 2, 1, "", "done_keys"], [151, 2, 1, "", "done_keys_groups"], [151, 2, 1, "", "done_spec"], [151, 2, 1, "", "done_spec_unbatched"], [151, 1, 1, "", "double"], [151, 1, 1, "", "empty_cache"], [151, 1, 1, "", "eval"], [151, 1, 1, "", "extra_repr"], [151, 1, 1, "", "fake_tensordict"], [151, 1, 1, "", "float"], [151, 1, 1, "", "forward"], [151, 2, 1, "", "full_action_spec"], [151, 2, 1, "", "full_action_spec_unbatched"], [151, 2, 1, "", "full_done_spec"], [151, 2, 1, "", "full_done_spec_unbatched"], [151, 2, 1, "", "full_observation_spec_unbatched"], [151, 2, 1, "", "full_reward_spec"], [151, 2, 1, "", "full_reward_spec_unbatched"], [151, 2, 1, "", "full_state_spec"], [151, 2, 1, "", "full_state_spec_unbatched"], [151, 1, 1, "", "gen_params"], [151, 1, 1, "", "get_buffer"], [151, 1, 1, "", "get_extra_state"], [151, 1, 1, "", "get_parameter"], [151, 1, 1, "", "get_submodule"], [151, 1, 1, "", "half"], [151, 2, 1, "", "input_spec"], [151, 2, 1, "", "input_spec_unbatched"], [151, 1, 1, "", "ipu"], [151, 2, 1, "", "is_spec_locked"], [151, 1, 1, "", "load_state_dict"], [151, 1, 1, "", "maybe_reset"], [151, 1, 1, "", "modules"], [151, 1, 1, "", "mtia"], [151, 1, 1, "", "named_buffers"], [151, 1, 1, "", "named_children"], [151, 1, 1, "", "named_modules"], [151, 1, 1, "", "named_parameters"], [151, 2, 1, "", "observation_keys"], [151, 2, 1, "", "observation_spec"], [151, 2, 1, "", "observation_spec_unbatched"], [151, 2, 1, "", "output_spec"], [151, 2, 1, "", "output_spec_unbatched"], [151, 1, 1, "", "parameters"], [151, 1, 1, "", "rand_action"], [151, 1, 1, "", "rand_step"], [151, 1, 1, "", "register_backward_hook"], [151, 1, 1, "", "register_buffer"], [151, 1, 1, "", "register_collector"], [151, 1, 1, "", "register_forward_hook"], [151, 1, 1, "", "register_forward_pre_hook"], [151, 1, 1, "", "register_full_backward_hook"], [151, 1, 1, "", "register_full_backward_pre_hook"], [151, 1, 1, "", "register_gym"], [151, 1, 1, "", "register_load_state_dict_post_hook"], [151, 1, 1, "", "register_load_state_dict_pre_hook"], [151, 1, 1, "", "register_module"], [151, 1, 1, "", "register_parameter"], [151, 1, 1, "", "register_state_dict_post_hook"], [151, 1, 1, "", "register_state_dict_pre_hook"], [151, 1, 1, "", "requires_grad_"], [151, 1, 1, "", "reset"], [151, 2, 1, "", "reset_keys"], [151, 2, 1, "", "reward_key"], [151, 2, 1, "", "reward_keys"], [151, 2, 1, "", "reward_spec"], [151, 2, 1, "", "reward_spec_unbatched"], [151, 1, 1, "", "rollout"], [151, 1, 1, "", "set_extra_state"], [151, 1, 1, "", "set_seed"], [151, 1, 1, "", "set_spec_lock_"], [151, 1, 1, "", "set_submodule"], [151, 2, 1, "", "shape"], [151, 1, 1, "", "share_memory"], [151, 2, 1, "", "specs"], [151, 1, 1, "", "state_dict"], [151, 2, 1, "", "state_keys"], [151, 2, 1, "", "state_spec"], [151, 2, 1, "", "state_spec_unbatched"], [151, 1, 1, "", "step"], [151, 1, 1, "", "step_and_maybe_reset"], [151, 1, 1, "", "step_mdp"], [151, 1, 1, "", "to"], [151, 1, 1, "", "to_empty"], [151, 1, 1, "", "train"], [151, 1, 1, "", "type"], [151, 1, 1, "", "xpu"], [151, 1, 1, "", "zero_grad"]], "torchrl.envs.ProcessorAsyncEnvPool": [[154, 1, 1, "", "_setup"], [154, 2, 1, "", "action_key"], [154, 2, 1, "", "action_keys"], [154, 2, 1, "", "action_spec"], [154, 2, 1, "", "action_spec_unbatched"], [154, 1, 1, "", "add_module"], [154, 1, 1, "", "add_truncated_keys"], [154, 1, 1, "", "all_actions"], [154, 1, 1, "", "any_done"], [154, 1, 1, "", "append_transform"], [154, 1, 1, "", "apply"], [154, 1, 1, "", "async_reset_recv"], [154, 1, 1, "", "async_reset_send"], [154, 1, 1, "", "async_step_recv"], [154, 1, 1, "", "async_step_send"], [154, 1, 1, "", "auto_specs_"], [154, 2, 1, "", "batch_dims"], [154, 2, 1, "", "batch_locked"], [154, 2, 1, "", "batch_size"], [154, 1, 1, "", "bfloat16"], [154, 1, 1, "", "buffers"], [154, 1, 1, "", "cardinality"], [154, 1, 1, "", "check_env_specs"], [154, 1, 1, "", "children"], [154, 2, 1, "", "collector"], [154, 1, 1, "", "compile"], [154, 1, 1, "", "cpu"], [154, 1, 1, "", "cuda"], [154, 2, 1, "", "done_key"], [154, 2, 1, "", "done_keys"], [154, 2, 1, "", "done_keys_groups"], [154, 2, 1, "", "done_spec"], [154, 2, 1, "", "done_spec_unbatched"], [154, 1, 1, "", "double"], [154, 1, 1, "", "empty_cache"], [154, 2, 1, "", "env_batch_sizes"], [154, 1, 1, "", "eval"], [154, 1, 1, "", "extra_repr"], [154, 1, 1, "", "fake_tensordict"], [154, 1, 1, "", "float"], [154, 1, 1, "", "forward"], [154, 2, 1, "", "full_action_spec"], [154, 2, 1, "", "full_action_spec_unbatched"], [154, 2, 1, "", "full_done_spec"], [154, 2, 1, "", "full_done_spec_unbatched"], [154, 2, 1, "", "full_observation_spec_unbatched"], [154, 2, 1, "", "full_reward_spec"], [154, 2, 1, "", "full_reward_spec_unbatched"], [154, 2, 1, "", "full_state_spec"], [154, 2, 1, "", "full_state_spec_unbatched"], [154, 1, 1, "", "get_buffer"], [154, 1, 1, "", "get_extra_state"], [154, 1, 1, "", "get_parameter"], [154, 1, 1, "", "get_submodule"], [154, 1, 1, "", "half"], [154, 2, 1, "", "input_spec"], [154, 2, 1, "", "input_spec_unbatched"], [154, 1, 1, "", "ipu"], [154, 2, 1, "", "is_spec_locked"], [154, 1, 1, "", "load_state_dict"], [154, 1, 1, "", "maybe_reset"], [154, 1, 1, "", "modules"], [154, 1, 1, "", "mtia"], [154, 1, 1, "", "named_buffers"], [154, 1, 1, "", "named_children"], [154, 1, 1, "", "named_modules"], [154, 1, 1, "", "named_parameters"], [154, 2, 1, "", "observation_keys"], [154, 2, 1, "", "observation_spec"], [154, 2, 1, "", "observation_spec_unbatched"], [154, 2, 1, "", "output_spec"], [154, 2, 1, "", "output_spec_unbatched"], [154, 1, 1, "", "parameters"], [154, 1, 1, "", "rand_action"], [154, 1, 1, "", "rand_step"], [154, 1, 1, "", "register_backward_hook"], [154, 1, 1, "", "register_buffer"], [154, 1, 1, "", "register_collector"], [154, 1, 1, "", "register_forward_hook"], [154, 1, 1, "", "register_forward_pre_hook"], [154, 1, 1, "", "register_full_backward_hook"], [154, 1, 1, "", "register_full_backward_pre_hook"], [154, 1, 1, "", "register_gym"], [154, 1, 1, "", "register_load_state_dict_post_hook"], [154, 1, 1, "", "register_load_state_dict_pre_hook"], [154, 1, 1, "", "register_module"], [154, 1, 1, "", "register_parameter"], [154, 1, 1, "", "register_state_dict_post_hook"], [154, 1, 1, "", "register_state_dict_pre_hook"], [154, 1, 1, "", "requires_grad_"], [154, 1, 1, "", "reset"], [154, 2, 1, "", "reset_keys"], [154, 2, 1, "", "reward_key"], [154, 2, 1, "", "reward_keys"], [154, 2, 1, "", "reward_spec"], [154, 2, 1, "", "reward_spec_unbatched"], [154, 1, 1, "", "rollout"], [154, 1, 1, "", "set_extra_state"], [154, 1, 1, "", "set_seed"], [154, 1, 1, "", "set_spec_lock_"], [154, 1, 1, "", "set_submodule"], [154, 2, 1, "", "shape"], [154, 1, 1, "", "share_memory"], [154, 1, 1, "", "shutdown"], [154, 2, 1, "", "specs"], [154, 1, 1, "", "state_dict"], [154, 2, 1, "", "state_keys"], [154, 2, 1, "", "state_spec"], [154, 2, 1, "", "state_spec_unbatched"], [154, 1, 1, "", "step"], [154, 1, 1, "", "step_and_maybe_reset"], [154, 1, 1, "", "step_mdp"], [154, 1, 1, "", "to"], [154, 1, 1, "", "to_empty"], [154, 1, 1, "", "train"], [154, 1, 1, "", "type"], [154, 1, 1, "", "xpu"], [154, 1, 1, "", "zero_grad"]], "torchrl.envs.SerialEnv": [[158, 2, 1, "", "action_key"], [158, 2, 1, "", "action_keys"], [158, 2, 1, "", "action_spec"], [158, 2, 1, "", "action_spec_unbatched"], [158, 1, 1, "", "add_module"], [158, 1, 1, "", "add_truncated_keys"], [158, 1, 1, "", "all_actions"], [158, 1, 1, "", "any_done"], [158, 1, 1, "", "append_transform"], [158, 1, 1, "", "apply"], [158, 1, 1, "", "auto_specs_"], [158, 2, 1, "", "batch_dims"], [158, 2, 1, "", "batch_locked"], [158, 2, 1, "", "batch_size"], [158, 1, 1, "", "bfloat16"], [158, 1, 1, "", "buffers"], [158, 1, 1, "", "cardinality"], [158, 1, 1, "", "check_env_specs"], [158, 1, 1, "", "children"], [158, 2, 1, "", "collector"], [158, 1, 1, "", "compile"], [158, 1, 1, "", "cpu"], [158, 1, 1, "", "cuda"], [158, 2, 1, "", "done_key"], [158, 2, 1, "", "done_keys"], [158, 2, 1, "", "done_keys_groups"], [158, 2, 1, "", "done_spec"], [158, 2, 1, "", "done_spec_unbatched"], [158, 1, 1, "", "double"], [158, 1, 1, "", "empty_cache"], [158, 1, 1, "", "eval"], [158, 1, 1, "", "extra_repr"], [158, 1, 1, "", "fake_tensordict"], [158, 1, 1, "", "float"], [158, 1, 1, "", "forward"], [158, 2, 1, "", "full_action_spec"], [158, 2, 1, "", "full_action_spec_unbatched"], [158, 2, 1, "", "full_done_spec"], [158, 2, 1, "", "full_done_spec_unbatched"], [158, 2, 1, "", "full_observation_spec_unbatched"], [158, 2, 1, "", "full_reward_spec"], [158, 2, 1, "", "full_reward_spec_unbatched"], [158, 2, 1, "", "full_state_spec"], [158, 2, 1, "", "full_state_spec_unbatched"], [158, 1, 1, "", "get_buffer"], [158, 1, 1, "", "get_extra_state"], [158, 1, 1, "", "get_parameter"], [158, 1, 1, "", "get_submodule"], [158, 1, 1, "", "half"], [158, 2, 1, "", "input_spec"], [158, 2, 1, "", "input_spec_unbatched"], [158, 1, 1, "", "ipu"], [158, 2, 1, "", "is_spec_locked"], [158, 1, 1, "", "load_state_dict"], [158, 1, 1, "", "maybe_reset"], [158, 1, 1, "", "modules"], [158, 1, 1, "", "mtia"], [158, 1, 1, "", "named_buffers"], [158, 1, 1, "", "named_children"], [158, 1, 1, "", "named_modules"], [158, 1, 1, "", "named_parameters"], [158, 2, 1, "", "observation_keys"], [158, 2, 1, "", "observation_spec"], [158, 2, 1, "", "observation_spec_unbatched"], [158, 2, 1, "", "output_spec"], [158, 2, 1, "", "output_spec_unbatched"], [158, 1, 1, "", "parameters"], [158, 1, 1, "", "rand_action"], [158, 1, 1, "", "rand_step"], [158, 1, 1, "", "register_backward_hook"], [158, 1, 1, "", "register_buffer"], [158, 1, 1, "", "register_collector"], [158, 1, 1, "", "register_forward_hook"], [158, 1, 1, "", "register_forward_pre_hook"], [158, 1, 1, "", "register_full_backward_hook"], [158, 1, 1, "", "register_full_backward_pre_hook"], [158, 1, 1, "", "register_gym"], [158, 1, 1, "", "register_load_state_dict_post_hook"], [158, 1, 1, "", "register_load_state_dict_pre_hook"], [158, 1, 1, "", "register_module"], [158, 1, 1, "", "register_parameter"], [158, 1, 1, "", "register_state_dict_post_hook"], [158, 1, 1, "", "register_state_dict_pre_hook"], [158, 1, 1, "", "requires_grad_"], [158, 1, 1, "", "reset"], [158, 2, 1, "", "reset_keys"], [158, 2, 1, "", "reward_key"], [158, 2, 1, "", "reward_keys"], [158, 2, 1, "", "reward_spec"], [158, 2, 1, "", "reward_spec_unbatched"], [158, 1, 1, "", "rollout"], [158, 1, 1, "", "set_extra_state"], [158, 1, 1, "", "set_seed"], [158, 1, 1, "", "set_spec_lock_"], [158, 1, 1, "", "set_submodule"], [158, 2, 1, "", "shape"], [158, 1, 1, "", "share_memory"], [158, 2, 1, "", "specs"], [158, 1, 1, "", "state_dict"], [158, 2, 1, "", "state_keys"], [158, 2, 1, "", "state_spec"], [158, 2, 1, "", "state_spec_unbatched"], [158, 1, 1, "", "step"], [158, 1, 1, "", "step_and_maybe_reset"], [158, 1, 1, "", "step_mdp"], [158, 1, 1, "", "to"], [158, 1, 1, "", "to_empty"], [158, 1, 1, "", "train"], [158, 1, 1, "", "type"], [158, 1, 1, "", "update_kwargs"], [158, 1, 1, "", "xpu"], [158, 1, 1, "", "zero_grad"]], "torchrl.envs.ThreadingAsyncEnvPool": [[159, 1, 1, "", "_setup"], [159, 2, 1, "", "action_key"], [159, 2, 1, "", "action_keys"], [159, 2, 1, "", "action_spec"], [159, 2, 1, "", "action_spec_unbatched"], [159, 1, 1, "", "add_module"], [159, 1, 1, "", "add_truncated_keys"], [159, 1, 1, "", "all_actions"], [159, 1, 1, "", "any_done"], [159, 1, 1, "", "append_transform"], [159, 1, 1, "", "apply"], [159, 1, 1, "", "async_reset_recv"], [159, 1, 1, "", "async_reset_send"], [159, 1, 1, "", "async_step_recv"], [159, 1, 1, "", "async_step_send"], [159, 1, 1, "", "auto_specs_"], [159, 2, 1, "", "batch_dims"], [159, 2, 1, "", "batch_locked"], [159, 2, 1, "", "batch_size"], [159, 1, 1, "", "bfloat16"], [159, 1, 1, "", "buffers"], [159, 1, 1, "", "cardinality"], [159, 1, 1, "", "check_env_specs"], [159, 1, 1, "", "children"], [159, 2, 1, "", "collector"], [159, 1, 1, "", "compile"], [159, 1, 1, "", "cpu"], [159, 1, 1, "", "cuda"], [159, 2, 1, "", "done_key"], [159, 2, 1, "", "done_keys"], [159, 2, 1, "", "done_keys_groups"], [159, 2, 1, "", "done_spec"], [159, 2, 1, "", "done_spec_unbatched"], [159, 1, 1, "", "double"], [159, 1, 1, "", "empty_cache"], [159, 2, 1, "", "env_batch_sizes"], [159, 1, 1, "", "eval"], [159, 1, 1, "", "extra_repr"], [159, 1, 1, "", "fake_tensordict"], [159, 1, 1, "", "float"], [159, 1, 1, "", "forward"], [159, 2, 1, "", "full_action_spec"], [159, 2, 1, "", "full_action_spec_unbatched"], [159, 2, 1, "", "full_done_spec"], [159, 2, 1, "", "full_done_spec_unbatched"], [159, 2, 1, "", "full_observation_spec_unbatched"], [159, 2, 1, "", "full_reward_spec"], [159, 2, 1, "", "full_reward_spec_unbatched"], [159, 2, 1, "", "full_state_spec"], [159, 2, 1, "", "full_state_spec_unbatched"], [159, 1, 1, "", "get_buffer"], [159, 1, 1, "", "get_extra_state"], [159, 1, 1, "", "get_parameter"], [159, 1, 1, "", "get_submodule"], [159, 1, 1, "", "half"], [159, 2, 1, "", "input_spec"], [159, 2, 1, "", "input_spec_unbatched"], [159, 1, 1, "", "ipu"], [159, 2, 1, "", "is_spec_locked"], [159, 1, 1, "", "load_state_dict"], [159, 1, 1, "", "maybe_reset"], [159, 1, 1, "", "modules"], [159, 1, 1, "", "mtia"], [159, 1, 1, "", "named_buffers"], [159, 1, 1, "", "named_children"], [159, 1, 1, "", "named_modules"], [159, 1, 1, "", "named_parameters"], [159, 2, 1, "", "observation_keys"], [159, 2, 1, "", "observation_spec"], [159, 2, 1, "", "observation_spec_unbatched"], [159, 2, 1, "", "output_spec"], [159, 2, 1, "", "output_spec_unbatched"], [159, 1, 1, "", "parameters"], [159, 1, 1, "", "rand_action"], [159, 1, 1, "", "rand_step"], [159, 1, 1, "", "register_backward_hook"], [159, 1, 1, "", "register_buffer"], [159, 1, 1, "", "register_collector"], [159, 1, 1, "", "register_forward_hook"], [159, 1, 1, "", "register_forward_pre_hook"], [159, 1, 1, "", "register_full_backward_hook"], [159, 1, 1, "", "register_full_backward_pre_hook"], [159, 1, 1, "", "register_gym"], [159, 1, 1, "", "register_load_state_dict_post_hook"], [159, 1, 1, "", "register_load_state_dict_pre_hook"], [159, 1, 1, "", "register_module"], [159, 1, 1, "", "register_parameter"], [159, 1, 1, "", "register_state_dict_post_hook"], [159, 1, 1, "", "register_state_dict_pre_hook"], [159, 1, 1, "", "requires_grad_"], [159, 1, 1, "", "reset"], [159, 2, 1, "", "reset_keys"], [159, 2, 1, "", "reward_key"], [159, 2, 1, "", "reward_keys"], [159, 2, 1, "", "reward_spec"], [159, 2, 1, "", "reward_spec_unbatched"], [159, 1, 1, "", "rollout"], [159, 1, 1, "", "set_extra_state"], [159, 1, 1, "", "set_seed"], [159, 1, 1, "", "set_spec_lock_"], [159, 1, 1, "", "set_submodule"], [159, 2, 1, "", "shape"], [159, 1, 1, "", "share_memory"], [159, 1, 1, "", "shutdown"], [159, 2, 1, "", "specs"], [159, 1, 1, "", "state_dict"], [159, 2, 1, "", "state_keys"], [159, 2, 1, "", "state_spec"], [159, 2, 1, "", "state_spec_unbatched"], [159, 1, 1, "", "step"], [159, 1, 1, "", "step_and_maybe_reset"], [159, 1, 1, "", "step_mdp"], [159, 1, 1, "", "to"], [159, 1, 1, "", "to_empty"], [159, 1, 1, "", "train"], [159, 1, 1, "", "type"], [159, 1, 1, "", "xpu"], [159, 1, 1, "", "zero_grad"]], "torchrl.envs.TicTacToeEnv": [[160, 2, 1, "", "action_key"], [160, 2, 1, "", "action_keys"], [160, 2, 1, "", "action_spec"], [160, 2, 1, "", "action_spec_unbatched"], [160, 1, 1, "", "add_module"], [160, 1, 1, "", "add_truncated_keys"], [160, 1, 1, "", "all_actions"], [160, 1, 1, "", "any_done"], [160, 1, 1, "", "append_transform"], [160, 1, 1, "", "apply"], [160, 1, 1, "", "auto_specs_"], [160, 2, 1, "", "batch_dims"], [160, 2, 1, "", "batch_size"], [160, 1, 1, "", "bfloat16"], [160, 1, 1, "", "buffers"], [160, 1, 1, "", "cardinality"], [160, 1, 1, "", "check_env_specs"], [160, 1, 1, "", "children"], [160, 2, 1, "", "collector"], [160, 1, 1, "", "compile"], [160, 1, 1, "", "cpu"], [160, 1, 1, "", "cuda"], [160, 2, 1, "", "done_key"], [160, 2, 1, "", "done_keys"], [160, 2, 1, "", "done_keys_groups"], [160, 2, 1, "", "done_spec"], [160, 2, 1, "", "done_spec_unbatched"], [160, 1, 1, "", "double"], [160, 1, 1, "", "empty_cache"], [160, 1, 1, "", "eval"], [160, 1, 1, "", "extra_repr"], [160, 1, 1, "", "fake_tensordict"], [160, 1, 1, "", "float"], [160, 1, 1, "", "forward"], [160, 2, 1, "", "full_action_spec"], [160, 2, 1, "", "full_action_spec_unbatched"], [160, 2, 1, "", "full_done_spec"], [160, 2, 1, "", "full_done_spec_unbatched"], [160, 2, 1, "", "full_observation_spec_unbatched"], [160, 2, 1, "", "full_reward_spec"], [160, 2, 1, "", "full_reward_spec_unbatched"], [160, 2, 1, "", "full_state_spec"], [160, 2, 1, "", "full_state_spec_unbatched"], [160, 1, 1, "", "get_buffer"], [160, 1, 1, "", "get_extra_state"], [160, 1, 1, "", "get_parameter"], [160, 1, 1, "", "get_submodule"], [160, 1, 1, "", "half"], [160, 2, 1, "", "input_spec"], [160, 2, 1, "", "input_spec_unbatched"], [160, 1, 1, "", "ipu"], [160, 2, 1, "", "is_spec_locked"], [160, 1, 1, "", "load_state_dict"], [160, 1, 1, "", "maybe_reset"], [160, 1, 1, "", "modules"], [160, 1, 1, "", "mtia"], [160, 1, 1, "", "named_buffers"], [160, 1, 1, "", "named_children"], [160, 1, 1, "", "named_modules"], [160, 1, 1, "", "named_parameters"], [160, 2, 1, "", "observation_keys"], [160, 2, 1, "", "observation_spec"], [160, 2, 1, "", "observation_spec_unbatched"], [160, 2, 1, "", "output_spec"], [160, 2, 1, "", "output_spec_unbatched"], [160, 1, 1, "", "parameters"], [160, 1, 1, "", "rand_action"], [160, 1, 1, "", "rand_step"], [160, 1, 1, "", "register_backward_hook"], [160, 1, 1, "", "register_buffer"], [160, 1, 1, "", "register_collector"], [160, 1, 1, "", "register_forward_hook"], [160, 1, 1, "", "register_forward_pre_hook"], [160, 1, 1, "", "register_full_backward_hook"], [160, 1, 1, "", "register_full_backward_pre_hook"], [160, 1, 1, "", "register_gym"], [160, 1, 1, "", "register_load_state_dict_post_hook"], [160, 1, 1, "", "register_load_state_dict_pre_hook"], [160, 1, 1, "", "register_module"], [160, 1, 1, "", "register_parameter"], [160, 1, 1, "", "register_state_dict_post_hook"], [160, 1, 1, "", "register_state_dict_pre_hook"], [160, 1, 1, "", "requires_grad_"], [160, 1, 1, "", "reset"], [160, 2, 1, "", "reset_keys"], [160, 2, 1, "", "reward_key"], [160, 2, 1, "", "reward_keys"], [160, 2, 1, "", "reward_spec"], [160, 2, 1, "", "reward_spec_unbatched"], [160, 1, 1, "", "rollout"], [160, 1, 1, "", "set_extra_state"], [160, 1, 1, "", "set_seed"], [160, 1, 1, "", "set_spec_lock_"], [160, 1, 1, "", "set_submodule"], [160, 2, 1, "", "shape"], [160, 1, 1, "", "share_memory"], [160, 2, 1, "", "specs"], [160, 1, 1, "", "state_dict"], [160, 2, 1, "", "state_keys"], [160, 2, 1, "", "state_spec"], [160, 2, 1, "", "state_spec_unbatched"], [160, 1, 1, "", "step"], [160, 1, 1, "", "step_and_maybe_reset"], [160, 1, 1, "", "step_mdp"], [160, 1, 1, "", "to"], [160, 1, 1, "", "to_empty"], [160, 1, 1, "", "train"], [160, 1, 1, "", "type"], [160, 1, 1, "", "xpu"], [160, 1, 1, "", "zero_grad"]], "torchrl.envs.llm": [[170, 0, 1, "", "ChatEnv"], [171, 0, 1, "", "DatasetChatEnv"], [172, 0, 1, "", "GSM8KEnv"], [173, 0, 1, "", "GSM8KPrepareQuestion"], [174, 0, 1, "", "GSM8KRewardParser"], [175, 0, 1, "", "IFEvalEnv"], [176, 0, 1, "", "IFEvalScoreData"], [177, 0, 1, "", "IfEvalScorer"], [178, 0, 1, "", "LLMEnv"], [179, 0, 1, "", "LLMHashingEnv"], [180, 0, 1, "", "MLGymWrapper"], [181, 0, 1, "", "make_gsm8k_env"], [182, 0, 1, "", "make_mlgym"]], "torchrl.envs.llm.ChatEnv": [[170, 2, 1, "", "action_key"], [170, 2, 1, "", "action_keys"], [170, 2, 1, "", "action_spec"], [170, 2, 1, "", "action_spec_unbatched"], [170, 1, 1, "", "add_module"], [170, 1, 1, "", "add_truncated_keys"], [170, 1, 1, "", "all_actions"], [170, 1, 1, "", "any_done"], [170, 1, 1, "", "append_transform"], [170, 1, 1, "", "apply"], [170, 1, 1, "", "auto_specs_"], [170, 2, 1, "", "batch_dims"], [170, 2, 1, "", "batch_locked"], [170, 2, 1, "", "batch_size"], [170, 1, 1, "", "bfloat16"], [170, 1, 1, "", "buffers"], [170, 1, 1, "", "cardinality"], [170, 1, 1, "", "check_env_specs"], [170, 1, 1, "", "children"], [170, 2, 1, "", "collector"], [170, 1, 1, "", "compile"], [170, 1, 1, "", "cpu"], [170, 1, 1, "", "cuda"], [170, 2, 1, "", "done_key"], [170, 2, 1, "", "done_keys"], [170, 2, 1, "", "done_keys_groups"], [170, 2, 1, "", "done_spec"], [170, 2, 1, "", "done_spec_unbatched"], [170, 1, 1, "", "double"], [170, 1, 1, "", "empty_cache"], [170, 1, 1, "", "eval"], [170, 1, 1, "", "extra_repr"], [170, 1, 1, "", "fake_tensordict"], [170, 1, 1, "", "float"], [170, 1, 1, "", "forward"], [170, 1, 1, "", "from_dataloader"], [170, 2, 1, "", "full_action_spec"], [170, 2, 1, "", "full_action_spec_unbatched"], [170, 2, 1, "", "full_done_spec"], [170, 2, 1, "", "full_done_spec_unbatched"], [170, 2, 1, "", "full_observation_spec_unbatched"], [170, 2, 1, "", "full_reward_spec"], [170, 2, 1, "", "full_reward_spec_unbatched"], [170, 2, 1, "", "full_state_spec"], [170, 2, 1, "", "full_state_spec_unbatched"], [170, 1, 1, "", "get_buffer"], [170, 1, 1, "", "get_extra_state"], [170, 1, 1, "", "get_parameter"], [170, 1, 1, "", "get_submodule"], [170, 1, 1, "", "half"], [170, 2, 1, "", "input_spec"], [170, 2, 1, "", "input_spec_unbatched"], [170, 1, 1, "", "ipu"], [170, 2, 1, "", "is_spec_locked"], [170, 1, 1, "", "load_state_dict"], [170, 1, 1, "", "maybe_reset"], [170, 1, 1, "", "modules"], [170, 1, 1, "", "mtia"], [170, 1, 1, "", "named_buffers"], [170, 1, 1, "", "named_children"], [170, 1, 1, "", "named_modules"], [170, 1, 1, "", "named_parameters"], [170, 2, 1, "", "observation_keys"], [170, 2, 1, "", "observation_spec"], [170, 2, 1, "", "observation_spec_unbatched"], [170, 2, 1, "", "output_spec"], [170, 2, 1, "", "output_spec_unbatched"], [170, 1, 1, "", "parameters"], [170, 1, 1, "", "rand_action"], [170, 1, 1, "", "rand_step"], [170, 1, 1, "", "register_backward_hook"], [170, 1, 1, "", "register_buffer"], [170, 1, 1, "", "register_collector"], [170, 1, 1, "", "register_forward_hook"], [170, 1, 1, "", "register_forward_pre_hook"], [170, 1, 1, "", "register_full_backward_hook"], [170, 1, 1, "", "register_full_backward_pre_hook"], [170, 1, 1, "", "register_gym"], [170, 1, 1, "", "register_load_state_dict_post_hook"], [170, 1, 1, "", "register_load_state_dict_pre_hook"], [170, 1, 1, "", "register_module"], [170, 1, 1, "", "register_parameter"], [170, 1, 1, "", "register_state_dict_post_hook"], [170, 1, 1, "", "register_state_dict_pre_hook"], [170, 1, 1, "", "requires_grad_"], [170, 1, 1, "id0", "reset"], [170, 2, 1, "", "reset_keys"], [170, 2, 1, "", "reward_key"], [170, 2, 1, "", "reward_keys"], [170, 2, 1, "", "reward_spec"], [170, 2, 1, "", "reward_spec_unbatched"], [170, 1, 1, "", "rollout"], [170, 1, 1, "", "set_extra_state"], [170, 1, 1, "", "set_seed"], [170, 1, 1, "", "set_spec_lock_"], [170, 1, 1, "", "set_submodule"], [170, 2, 1, "", "shape"], [170, 1, 1, "", "share_memory"], [170, 2, 1, "", "specs"], [170, 1, 1, "", "state_dict"], [170, 2, 1, "", "state_keys"], [170, 2, 1, "", "state_spec"], [170, 2, 1, "", "state_spec_unbatched"], [170, 1, 1, "id1", "step"], [170, 1, 1, "", "step_and_maybe_reset"], [170, 1, 1, "", "step_mdp"], [170, 1, 1, "", "to"], [170, 1, 1, "", "to_empty"], [170, 1, 1, "", "train"], [170, 1, 1, "", "type"], [170, 1, 1, "", "xpu"], [170, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.DatasetChatEnv": [[171, 2, 1, "", "action_key"], [171, 2, 1, "", "action_keys"], [171, 2, 1, "", "action_spec"], [171, 2, 1, "", "action_spec_unbatched"], [171, 1, 1, "", "add_module"], [171, 1, 1, "", "add_truncated_keys"], [171, 1, 1, "", "all_actions"], [171, 1, 1, "", "any_done"], [171, 1, 1, "", "append_transform"], [171, 1, 1, "", "apply"], [171, 1, 1, "", "auto_specs_"], [171, 2, 1, "", "batch_dims"], [171, 2, 1, "", "batch_locked"], [171, 2, 1, "", "batch_size"], [171, 1, 1, "", "bfloat16"], [171, 1, 1, "", "buffers"], [171, 1, 1, "", "cardinality"], [171, 1, 1, "", "check_env_specs"], [171, 1, 1, "", "children"], [171, 2, 1, "", "collector"], [171, 1, 1, "", "compile"], [171, 1, 1, "", "cpu"], [171, 1, 1, "", "cuda"], [171, 2, 1, "", "done_key"], [171, 2, 1, "", "done_keys"], [171, 2, 1, "", "done_keys_groups"], [171, 2, 1, "", "done_spec"], [171, 2, 1, "", "done_spec_unbatched"], [171, 1, 1, "", "double"], [171, 1, 1, "", "empty_cache"], [171, 1, 1, "", "eval"], [171, 1, 1, "", "extra_repr"], [171, 1, 1, "", "fake_tensordict"], [171, 1, 1, "", "float"], [171, 1, 1, "", "forward"], [171, 1, 1, "", "from_dataloader"], [171, 2, 1, "", "full_action_spec"], [171, 2, 1, "", "full_action_spec_unbatched"], [171, 2, 1, "", "full_done_spec"], [171, 2, 1, "", "full_done_spec_unbatched"], [171, 2, 1, "", "full_observation_spec_unbatched"], [171, 2, 1, "", "full_reward_spec"], [171, 2, 1, "", "full_reward_spec_unbatched"], [171, 2, 1, "", "full_state_spec"], [171, 2, 1, "", "full_state_spec_unbatched"], [171, 1, 1, "", "get_buffer"], [171, 1, 1, "", "get_extra_state"], [171, 1, 1, "", "get_parameter"], [171, 1, 1, "", "get_submodule"], [171, 1, 1, "", "half"], [171, 2, 1, "", "input_spec"], [171, 2, 1, "", "input_spec_unbatched"], [171, 1, 1, "", "insert_transform"], [171, 1, 1, "", "ipu"], [171, 2, 1, "", "is_spec_locked"], [171, 1, 1, "", "load_state_dict"], [171, 1, 1, "", "maybe_reset"], [171, 1, 1, "", "modules"], [171, 1, 1, "", "mtia"], [171, 1, 1, "", "named_buffers"], [171, 1, 1, "", "named_children"], [171, 1, 1, "", "named_modules"], [171, 1, 1, "", "named_parameters"], [171, 2, 1, "", "observation_keys"], [171, 2, 1, "", "observation_spec"], [171, 2, 1, "", "observation_spec_unbatched"], [171, 2, 1, "", "output_spec"], [171, 2, 1, "", "output_spec_unbatched"], [171, 1, 1, "", "parameters"], [171, 1, 1, "", "rand_action"], [171, 1, 1, "", "rand_step"], [171, 1, 1, "", "register_backward_hook"], [171, 1, 1, "", "register_buffer"], [171, 1, 1, "", "register_collector"], [171, 1, 1, "", "register_forward_hook"], [171, 1, 1, "", "register_forward_pre_hook"], [171, 1, 1, "", "register_full_backward_hook"], [171, 1, 1, "", "register_full_backward_pre_hook"], [171, 1, 1, "", "register_gym"], [171, 1, 1, "", "register_load_state_dict_post_hook"], [171, 1, 1, "", "register_load_state_dict_pre_hook"], [171, 1, 1, "", "register_module"], [171, 1, 1, "", "register_parameter"], [171, 1, 1, "", "register_state_dict_post_hook"], [171, 1, 1, "", "register_state_dict_pre_hook"], [171, 1, 1, "", "requires_grad_"], [171, 1, 1, "", "reset"], [171, 1, 1, "", "reset_dataloader"], [171, 2, 1, "", "reset_keys"], [171, 2, 1, "", "reward_key"], [171, 2, 1, "", "reward_keys"], [171, 2, 1, "", "reward_spec"], [171, 2, 1, "", "reward_spec_unbatched"], [171, 1, 1, "", "rollout"], [171, 1, 1, "", "set_extra_state"], [171, 1, 1, "", "set_missing_tolerance"], [171, 1, 1, "", "set_seed"], [171, 1, 1, "", "set_spec_lock_"], [171, 1, 1, "", "set_submodule"], [171, 2, 1, "", "shape"], [171, 1, 1, "", "share_memory"], [171, 2, 1, "", "specs"], [171, 1, 1, "", "state_dict"], [171, 2, 1, "", "state_keys"], [171, 2, 1, "", "state_spec"], [171, 2, 1, "", "state_spec_unbatched"], [171, 1, 1, "", "step"], [171, 1, 1, "", "step_and_maybe_reset"], [171, 1, 1, "", "step_mdp"], [171, 1, 1, "", "to"], [171, 1, 1, "", "to_empty"], [171, 1, 1, "", "train"], [171, 1, 1, "", "type"], [171, 1, 1, "", "xpu"], [171, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KEnv": [[172, 2, 1, "", "action_key"], [172, 2, 1, "", "action_keys"], [172, 2, 1, "", "action_spec"], [172, 2, 1, "", "action_spec_unbatched"], [172, 1, 1, "", "add_module"], [172, 1, 1, "", "add_truncated_keys"], [172, 1, 1, "", "all_actions"], [172, 1, 1, "", "any_done"], [172, 1, 1, "", "append_transform"], [172, 1, 1, "", "apply"], [172, 1, 1, "", "auto_specs_"], [172, 2, 1, "", "batch_dims"], [172, 2, 1, "", "batch_locked"], [172, 2, 1, "", "batch_size"], [172, 1, 1, "", "bfloat16"], [172, 1, 1, "", "buffers"], [172, 1, 1, "", "cardinality"], [172, 1, 1, "", "check_env_specs"], [172, 1, 1, "", "children"], [172, 2, 1, "", "collector"], [172, 1, 1, "", "compile"], [172, 1, 1, "", "cpu"], [172, 1, 1, "", "cuda"], [172, 2, 1, "", "done_key"], [172, 2, 1, "", "done_keys"], [172, 2, 1, "", "done_keys_groups"], [172, 2, 1, "", "done_spec"], [172, 2, 1, "", "done_spec_unbatched"], [172, 1, 1, "", "double"], [172, 1, 1, "", "empty_cache"], [172, 1, 1, "", "eval"], [172, 1, 1, "", "extra_repr"], [172, 1, 1, "", "fake_tensordict"], [172, 1, 1, "", "float"], [172, 1, 1, "", "forward"], [172, 1, 1, "", "from_dataloader"], [172, 2, 1, "", "full_action_spec"], [172, 2, 1, "", "full_action_spec_unbatched"], [172, 2, 1, "", "full_done_spec"], [172, 2, 1, "", "full_done_spec_unbatched"], [172, 2, 1, "", "full_observation_spec_unbatched"], [172, 2, 1, "", "full_reward_spec"], [172, 2, 1, "", "full_reward_spec_unbatched"], [172, 2, 1, "", "full_state_spec"], [172, 2, 1, "", "full_state_spec_unbatched"], [172, 1, 1, "", "get_buffer"], [172, 1, 1, "", "get_extra_state"], [172, 1, 1, "", "get_parameter"], [172, 1, 1, "", "get_submodule"], [172, 1, 1, "", "half"], [172, 2, 1, "", "input_spec"], [172, 2, 1, "", "input_spec_unbatched"], [172, 1, 1, "", "insert_transform"], [172, 1, 1, "", "ipu"], [172, 2, 1, "", "is_spec_locked"], [172, 1, 1, "", "load_state_dict"], [172, 1, 1, "", "maybe_reset"], [172, 1, 1, "", "modules"], [172, 1, 1, "", "mtia"], [172, 1, 1, "", "named_buffers"], [172, 1, 1, "", "named_children"], [172, 1, 1, "", "named_modules"], [172, 1, 1, "", "named_parameters"], [172, 2, 1, "", "observation_keys"], [172, 2, 1, "", "observation_spec"], [172, 2, 1, "", "observation_spec_unbatched"], [172, 2, 1, "", "output_spec"], [172, 2, 1, "", "output_spec_unbatched"], [172, 1, 1, "", "parameters"], [172, 1, 1, "", "rand_action"], [172, 1, 1, "", "rand_step"], [172, 1, 1, "", "register_backward_hook"], [172, 1, 1, "", "register_buffer"], [172, 1, 1, "", "register_collector"], [172, 1, 1, "", "register_forward_hook"], [172, 1, 1, "", "register_forward_pre_hook"], [172, 1, 1, "", "register_full_backward_hook"], [172, 1, 1, "", "register_full_backward_pre_hook"], [172, 1, 1, "", "register_gym"], [172, 1, 1, "", "register_load_state_dict_post_hook"], [172, 1, 1, "", "register_load_state_dict_pre_hook"], [172, 1, 1, "", "register_module"], [172, 1, 1, "", "register_parameter"], [172, 1, 1, "", "register_state_dict_post_hook"], [172, 1, 1, "", "register_state_dict_pre_hook"], [172, 1, 1, "", "requires_grad_"], [172, 1, 1, "", "reset"], [172, 1, 1, "", "reset_dataloader"], [172, 2, 1, "", "reset_keys"], [172, 2, 1, "", "reward_key"], [172, 2, 1, "", "reward_keys"], [172, 2, 1, "", "reward_spec"], [172, 2, 1, "", "reward_spec_unbatched"], [172, 1, 1, "", "rollout"], [172, 1, 1, "", "set_extra_state"], [172, 1, 1, "", "set_missing_tolerance"], [172, 1, 1, "", "set_seed"], [172, 1, 1, "", "set_spec_lock_"], [172, 1, 1, "", "set_submodule"], [172, 2, 1, "", "shape"], [172, 1, 1, "", "share_memory"], [172, 2, 1, "", "specs"], [172, 1, 1, "", "state_dict"], [172, 2, 1, "", "state_keys"], [172, 2, 1, "", "state_spec"], [172, 2, 1, "", "state_spec_unbatched"], [172, 1, 1, "", "step"], [172, 1, 1, "", "step_and_maybe_reset"], [172, 1, 1, "", "step_mdp"], [172, 1, 1, "", "to"], [172, 1, 1, "", "to_empty"], [172, 1, 1, "", "train"], [172, 1, 1, "", "type"], [172, 1, 1, "", "xpu"], [172, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KPrepareQuestion": [[173, 1, 1, "", "add_module"], [173, 1, 1, "", "apply"], [173, 1, 1, "", "bfloat16"], [173, 1, 1, "", "buffers"], [173, 1, 1, "", "children"], [173, 1, 1, "", "close"], [173, 2, 1, "", "collector"], [173, 1, 1, "", "compile"], [173, 2, 1, "", "container"], [173, 1, 1, "", "cpu"], [173, 1, 1, "", "cuda"], [173, 1, 1, "", "double"], [173, 1, 1, "", "eval"], [173, 1, 1, "", "extra_repr"], [173, 1, 1, "", "float"], [173, 1, 1, "", "forward"], [173, 1, 1, "", "get_buffer"], [173, 1, 1, "", "get_extra_state"], [173, 1, 1, "", "get_parameter"], [173, 1, 1, "", "get_submodule"], [173, 1, 1, "", "half"], [173, 1, 1, "", "init"], [173, 1, 1, "", "inv"], [173, 1, 1, "", "ipu"], [173, 1, 1, "", "load_state_dict"], [173, 1, 1, "", "modules"], [173, 1, 1, "", "mtia"], [173, 1, 1, "", "named_buffers"], [173, 1, 1, "", "named_children"], [173, 1, 1, "", "named_modules"], [173, 1, 1, "", "named_parameters"], [173, 1, 1, "", "parameters"], [173, 2, 1, "", "parent"], [173, 1, 1, "", "register_backward_hook"], [173, 1, 1, "", "register_buffer"], [173, 1, 1, "", "register_forward_hook"], [173, 1, 1, "", "register_forward_pre_hook"], [173, 1, 1, "", "register_full_backward_hook"], [173, 1, 1, "", "register_full_backward_pre_hook"], [173, 1, 1, "", "register_load_state_dict_post_hook"], [173, 1, 1, "", "register_load_state_dict_pre_hook"], [173, 1, 1, "", "register_module"], [173, 1, 1, "", "register_parameter"], [173, 1, 1, "", "register_state_dict_post_hook"], [173, 1, 1, "", "register_state_dict_pre_hook"], [173, 1, 1, "", "requires_grad_"], [173, 1, 1, "", "set_extra_state"], [173, 1, 1, "", "set_submodule"], [173, 1, 1, "", "share_memory"], [173, 1, 1, "", "state_dict"], [173, 1, 1, "", "to"], [173, 1, 1, "", "to_empty"], [173, 1, 1, "", "train"], [173, 1, 1, "", "transform_action_spec"], [173, 1, 1, "", "transform_done_spec"], [173, 1, 1, "", "transform_env_batch_size"], [173, 1, 1, "", "transform_env_device"], [173, 1, 1, "", "transform_input_spec"], [173, 1, 1, "", "transform_observation_spec"], [173, 1, 1, "", "transform_output_spec"], [173, 1, 1, "", "transform_reward_spec"], [173, 1, 1, "", "transform_state_spec"], [173, 1, 1, "", "type"], [173, 1, 1, "", "xpu"], [173, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KRewardParser": [[174, 1, 1, "", "add_module"], [174, 1, 1, "", "apply"], [174, 1, 1, "", "bfloat16"], [174, 1, 1, "", "buffers"], [174, 1, 1, "", "children"], [174, 1, 1, "", "close"], [174, 2, 1, "", "collector"], [174, 1, 1, "", "compile"], [174, 2, 1, "", "container"], [174, 1, 1, "", "cpu"], [174, 1, 1, "", "cuda"], [174, 1, 1, "", "double"], [174, 1, 1, "", "eval"], [174, 1, 1, "", "extra_repr"], [174, 1, 1, "", "extract_tags"], [174, 1, 1, "", "float"], [174, 1, 1, "", "forward"], [174, 1, 1, "", "get_buffer"], [174, 1, 1, "", "get_extra_state"], [174, 1, 1, "", "get_parameter"], [174, 1, 1, "", "get_submodule"], [174, 1, 1, "", "half"], [174, 1, 1, "", "init"], [174, 1, 1, "", "inv"], [174, 1, 1, "", "ipu"], [174, 1, 1, "", "load_state_dict"], [174, 1, 1, "", "modules"], [174, 1, 1, "", "mtia"], [174, 1, 1, "", "named_buffers"], [174, 1, 1, "", "named_children"], [174, 1, 1, "", "named_modules"], [174, 1, 1, "", "named_parameters"], [174, 1, 1, "", "parameters"], [174, 2, 1, "", "parent"], [174, 1, 1, "", "register_backward_hook"], [174, 1, 1, "", "register_buffer"], [174, 1, 1, "", "register_forward_hook"], [174, 1, 1, "", "register_forward_pre_hook"], [174, 1, 1, "", "register_full_backward_hook"], [174, 1, 1, "", "register_full_backward_pre_hook"], [174, 1, 1, "", "register_load_state_dict_post_hook"], [174, 1, 1, "", "register_load_state_dict_pre_hook"], [174, 1, 1, "", "register_module"], [174, 1, 1, "", "register_parameter"], [174, 1, 1, "", "register_state_dict_post_hook"], [174, 1, 1, "", "register_state_dict_pre_hook"], [174, 1, 1, "", "requires_grad_"], [174, 1, 1, "", "set_extra_state"], [174, 1, 1, "", "set_submodule"], [174, 1, 1, "", "share_memory"], [174, 1, 1, "", "state_dict"], [174, 1, 1, "", "to"], [174, 1, 1, "", "to_empty"], [174, 1, 1, "", "train"], [174, 1, 1, "", "transform_action_spec"], [174, 1, 1, "", "transform_done_spec"], [174, 1, 1, "", "transform_env_batch_size"], [174, 1, 1, "", "transform_env_device"], [174, 1, 1, "", "transform_input_spec"], [174, 1, 1, "", "transform_observation_spec"], [174, 1, 1, "", "transform_output_spec"], [174, 1, 1, "", "transform_reward_spec"], [174, 1, 1, "", "transform_state_spec"], [174, 1, 1, "", "type"], [174, 1, 1, "", "xpu"], [174, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.IFEvalEnv": [[175, 2, 1, "", "action_key"], [175, 2, 1, "", "action_keys"], [175, 2, 1, "", "action_spec"], [175, 2, 1, "", "action_spec_unbatched"], [175, 1, 1, "", "add_module"], [175, 1, 1, "", "add_truncated_keys"], [175, 1, 1, "", "all_actions"], [175, 1, 1, "", "any_done"], [175, 1, 1, "", "append_transform"], [175, 1, 1, "", "apply"], [175, 1, 1, "", "auto_specs_"], [175, 2, 1, "", "batch_dims"], [175, 2, 1, "", "batch_locked"], [175, 2, 1, "", "batch_size"], [175, 1, 1, "", "bfloat16"], [175, 1, 1, "", "buffers"], [175, 1, 1, "", "cardinality"], [175, 1, 1, "", "check_env_specs"], [175, 1, 1, "", "children"], [175, 2, 1, "", "collector"], [175, 1, 1, "", "compile"], [175, 1, 1, "", "cpu"], [175, 1, 1, "", "cuda"], [175, 2, 1, "", "done_key"], [175, 2, 1, "", "done_keys"], [175, 2, 1, "", "done_keys_groups"], [175, 2, 1, "", "done_spec"], [175, 2, 1, "", "done_spec_unbatched"], [175, 1, 1, "", "double"], [175, 1, 1, "", "empty_cache"], [175, 1, 1, "", "eval"], [175, 1, 1, "", "extra_repr"], [175, 1, 1, "", "fake_tensordict"], [175, 1, 1, "", "float"], [175, 1, 1, "", "forward"], [175, 1, 1, "", "from_dataloader"], [175, 2, 1, "", "full_action_spec"], [175, 2, 1, "", "full_action_spec_unbatched"], [175, 2, 1, "", "full_done_spec"], [175, 2, 1, "", "full_done_spec_unbatched"], [175, 2, 1, "", "full_observation_spec_unbatched"], [175, 2, 1, "", "full_reward_spec"], [175, 2, 1, "", "full_reward_spec_unbatched"], [175, 2, 1, "", "full_state_spec"], [175, 2, 1, "", "full_state_spec_unbatched"], [175, 1, 1, "", "get_buffer"], [175, 1, 1, "", "get_extra_state"], [175, 1, 1, "", "get_parameter"], [175, 1, 1, "", "get_submodule"], [175, 1, 1, "", "half"], [175, 2, 1, "", "input_spec"], [175, 2, 1, "", "input_spec_unbatched"], [175, 1, 1, "", "insert_transform"], [175, 1, 1, "", "ipu"], [175, 2, 1, "", "is_spec_locked"], [175, 1, 1, "", "load_state_dict"], [175, 1, 1, "", "maybe_reset"], [175, 1, 1, "", "modules"], [175, 1, 1, "", "mtia"], [175, 1, 1, "", "named_buffers"], [175, 1, 1, "", "named_children"], [175, 1, 1, "", "named_modules"], [175, 1, 1, "", "named_parameters"], [175, 2, 1, "", "observation_keys"], [175, 2, 1, "", "observation_spec"], [175, 2, 1, "", "observation_spec_unbatched"], [175, 2, 1, "", "output_spec"], [175, 2, 1, "", "output_spec_unbatched"], [175, 1, 1, "", "parameters"], [175, 1, 1, "", "rand_action"], [175, 1, 1, "", "rand_step"], [175, 1, 1, "", "register_backward_hook"], [175, 1, 1, "", "register_buffer"], [175, 1, 1, "", "register_collector"], [175, 1, 1, "", "register_forward_hook"], [175, 1, 1, "", "register_forward_pre_hook"], [175, 1, 1, "", "register_full_backward_hook"], [175, 1, 1, "", "register_full_backward_pre_hook"], [175, 1, 1, "", "register_gym"], [175, 1, 1, "", "register_load_state_dict_post_hook"], [175, 1, 1, "", "register_load_state_dict_pre_hook"], [175, 1, 1, "", "register_module"], [175, 1, 1, "", "register_parameter"], [175, 1, 1, "", "register_state_dict_post_hook"], [175, 1, 1, "", "register_state_dict_pre_hook"], [175, 1, 1, "", "requires_grad_"], [175, 1, 1, "", "reset"], [175, 1, 1, "", "reset_dataloader"], [175, 2, 1, "", "reset_keys"], [175, 2, 1, "", "reward_key"], [175, 2, 1, "", "reward_keys"], [175, 2, 1, "", "reward_spec"], [175, 2, 1, "", "reward_spec_unbatched"], [175, 1, 1, "", "rollout"], [175, 1, 1, "", "set_extra_state"], [175, 1, 1, "", "set_missing_tolerance"], [175, 1, 1, "", "set_seed"], [175, 1, 1, "", "set_spec_lock_"], [175, 1, 1, "", "set_submodule"], [175, 2, 1, "", "shape"], [175, 1, 1, "", "share_memory"], [175, 2, 1, "", "specs"], [175, 1, 1, "", "state_dict"], [175, 2, 1, "", "state_keys"], [175, 2, 1, "", "state_spec"], [175, 2, 1, "", "state_spec_unbatched"], [175, 1, 1, "", "step"], [175, 1, 1, "", "step_and_maybe_reset"], [175, 1, 1, "", "step_mdp"], [175, 1, 1, "", "to"], [175, 1, 1, "", "to_empty"], [175, 1, 1, "", "train"], [175, 1, 1, "", "type"], [175, 1, 1, "", "xpu"], [175, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.IFEvalScoreData": [[176, 1, 1, "", "cat"], [176, 2, 1, "", "device"], [176, 1, 1, "", "dumps"], [176, 1, 1, "", "fields"], [176, 1, 1, "", "from_any"], [176, 1, 1, "", "from_dataclass"], [176, 1, 1, "", "from_h5"], [176, 1, 1, "", "from_modules"], [176, 1, 1, "", "from_namedtuple"], [176, 1, 1, "", "from_pytree"], [176, 1, 1, "", "from_remote_init"], [176, 1, 1, "", "from_struct_array"], [176, 1, 1, "", "from_tensordict"], [176, 1, 1, "", "from_tuple"], [176, 1, 1, "", "fromkeys"], [176, 1, 1, "", "get"], [176, 1, 1, "", "lazy_stack"], [176, 1, 1, "", "load"], [176, 1, 1, "", "load_"], [176, 1, 1, "", "load_memmap"], [176, 1, 1, "", "load_state_dict"], [176, 1, 1, "", "maybe_dense_stack"], [176, 1, 1, "", "memmap"], [176, 1, 1, "", "memmap_"], [176, 1, 1, "", "memmap_like"], [176, 1, 1, "", "memmap_refresh_"], [176, 1, 1, "", "save"], [176, 1, 1, "", "set"], [176, 1, 1, "", "stack"], [176, 1, 1, "", "state_dict"], [176, 1, 1, "", "to_tensordict"], [176, 1, 1, "", "unbind"]], "torchrl.envs.llm.IfEvalScorer": [[177, 1, 1, "", "add_module"], [177, 1, 1, "", "apply"], [177, 1, 1, "", "bfloat16"], [177, 1, 1, "", "buffers"], [177, 1, 1, "", "children"], [177, 1, 1, "", "close"], [177, 2, 1, "", "collector"], [177, 1, 1, "", "compile"], [177, 2, 1, "", "container"], [177, 1, 1, "", "cpu"], [177, 1, 1, "", "cuda"], [177, 1, 1, "", "default_reward_aggregator"], [177, 1, 1, "", "double"], [177, 1, 1, "", "eval"], [177, 1, 1, "", "extra_repr"], [177, 1, 1, "", "float"], [177, 1, 1, "", "forward"], [177, 1, 1, "", "get_buffer"], [177, 1, 1, "", "get_extra_state"], [177, 1, 1, "", "get_parameter"], [177, 1, 1, "", "get_submodule"], [177, 1, 1, "", "half"], [177, 1, 1, "", "init"], [177, 1, 1, "", "inv"], [177, 1, 1, "", "ipu"], [177, 1, 1, "", "load_state_dict"], [177, 1, 1, "", "modules"], [177, 1, 1, "", "mtia"], [177, 1, 1, "", "named_buffers"], [177, 1, 1, "", "named_children"], [177, 1, 1, "", "named_modules"], [177, 1, 1, "", "named_parameters"], [177, 1, 1, "", "parameters"], [177, 2, 1, "", "parent"], [177, 1, 1, "", "register_backward_hook"], [177, 1, 1, "", "register_buffer"], [177, 1, 1, "", "register_forward_hook"], [177, 1, 1, "", "register_forward_pre_hook"], [177, 1, 1, "", "register_full_backward_hook"], [177, 1, 1, "", "register_full_backward_pre_hook"], [177, 1, 1, "", "register_load_state_dict_post_hook"], [177, 1, 1, "", "register_load_state_dict_pre_hook"], [177, 1, 1, "", "register_module"], [177, 1, 1, "", "register_parameter"], [177, 1, 1, "", "register_state_dict_post_hook"], [177, 1, 1, "", "register_state_dict_pre_hook"], [177, 1, 1, "", "requires_grad_"], [177, 1, 1, "", "set_extra_state"], [177, 1, 1, "", "set_submodule"], [177, 1, 1, "", "share_memory"], [177, 1, 1, "", "state_dict"], [177, 1, 1, "", "to"], [177, 1, 1, "", "to_empty"], [177, 1, 1, "", "train"], [177, 1, 1, "", "transform_action_spec"], [177, 1, 1, "", "transform_done_spec"], [177, 1, 1, "", "transform_env_batch_size"], [177, 1, 1, "", "transform_env_device"], [177, 1, 1, "", "transform_input_spec"], [177, 1, 1, "", "transform_observation_spec"], [177, 1, 1, "", "transform_output_spec"], [177, 1, 1, "", "transform_reward_spec"], [177, 1, 1, "", "transform_state_spec"], [177, 1, 1, "", "type"], [177, 1, 1, "", "xpu"], [177, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.LLMEnv": [[178, 2, 1, "", "action_key"], [178, 2, 1, "", "action_keys"], [178, 2, 1, "", "action_spec"], [178, 2, 1, "", "action_spec_unbatched"], [178, 1, 1, "", "add_module"], [178, 1, 1, "", "add_truncated_keys"], [178, 1, 1, "", "all_actions"], [178, 1, 1, "", "any_done"], [178, 1, 1, "", "append_transform"], [178, 1, 1, "", "apply"], [178, 1, 1, "", "auto_specs_"], [178, 2, 1, "", "batch_dims"], [178, 2, 1, "", "batch_locked"], [178, 2, 1, "", "batch_size"], [178, 1, 1, "", "bfloat16"], [178, 1, 1, "", "buffers"], [178, 1, 1, "", "cardinality"], [178, 1, 1, "", "check_env_specs"], [178, 1, 1, "", "children"], [178, 2, 1, "", "collector"], [178, 1, 1, "", "compile"], [178, 1, 1, "", "cpu"], [178, 1, 1, "", "cuda"], [178, 2, 1, "", "done_key"], [178, 2, 1, "", "done_keys"], [178, 2, 1, "", "done_keys_groups"], [178, 2, 1, "", "done_spec"], [178, 2, 1, "", "done_spec_unbatched"], [178, 1, 1, "", "double"], [178, 1, 1, "", "empty_cache"], [178, 1, 1, "", "eval"], [178, 1, 1, "", "extra_repr"], [178, 1, 1, "", "fake_tensordict"], [178, 1, 1, "", "float"], [178, 1, 1, "", "forward"], [178, 1, 1, "id0", "from_dataloader"], [178, 2, 1, "", "full_action_spec"], [178, 2, 1, "", "full_action_spec_unbatched"], [178, 2, 1, "", "full_done_spec"], [178, 2, 1, "", "full_done_spec_unbatched"], [178, 2, 1, "", "full_observation_spec_unbatched"], [178, 2, 1, "", "full_reward_spec"], [178, 2, 1, "", "full_reward_spec_unbatched"], [178, 2, 1, "", "full_state_spec"], [178, 2, 1, "", "full_state_spec_unbatched"], [178, 1, 1, "", "get_buffer"], [178, 1, 1, "", "get_extra_state"], [178, 1, 1, "", "get_parameter"], [178, 1, 1, "", "get_submodule"], [178, 1, 1, "", "half"], [178, 2, 1, "", "input_spec"], [178, 2, 1, "", "input_spec_unbatched"], [178, 1, 1, "", "ipu"], [178, 2, 1, "", "is_spec_locked"], [178, 1, 1, "", "load_state_dict"], [178, 1, 1, "", "maybe_reset"], [178, 1, 1, "", "modules"], [178, 1, 1, "", "mtia"], [178, 1, 1, "", "named_buffers"], [178, 1, 1, "", "named_children"], [178, 1, 1, "", "named_modules"], [178, 1, 1, "", "named_parameters"], [178, 2, 1, "", "observation_keys"], [178, 2, 1, "", "observation_spec"], [178, 2, 1, "", "observation_spec_unbatched"], [178, 2, 1, "", "output_spec"], [178, 2, 1, "", "output_spec_unbatched"], [178, 1, 1, "", "parameters"], [178, 1, 1, "", "rand_action"], [178, 1, 1, "", "rand_step"], [178, 1, 1, "", "register_backward_hook"], [178, 1, 1, "", "register_buffer"], [178, 1, 1, "", "register_collector"], [178, 1, 1, "", "register_forward_hook"], [178, 1, 1, "", "register_forward_pre_hook"], [178, 1, 1, "", "register_full_backward_hook"], [178, 1, 1, "", "register_full_backward_pre_hook"], [178, 1, 1, "", "register_gym"], [178, 1, 1, "", "register_load_state_dict_post_hook"], [178, 1, 1, "", "register_load_state_dict_pre_hook"], [178, 1, 1, "", "register_module"], [178, 1, 1, "", "register_parameter"], [178, 1, 1, "", "register_state_dict_post_hook"], [178, 1, 1, "", "register_state_dict_pre_hook"], [178, 1, 1, "", "requires_grad_"], [178, 1, 1, "", "reset"], [178, 2, 1, "", "reset_keys"], [178, 2, 1, "", "reward_key"], [178, 2, 1, "", "reward_keys"], [178, 2, 1, "", "reward_spec"], [178, 2, 1, "", "reward_spec_unbatched"], [178, 1, 1, "", "rollout"], [178, 1, 1, "", "set_extra_state"], [178, 1, 1, "", "set_seed"], [178, 1, 1, "", "set_spec_lock_"], [178, 1, 1, "", "set_submodule"], [178, 2, 1, "", "shape"], [178, 1, 1, "", "share_memory"], [178, 2, 1, "", "specs"], [178, 1, 1, "", "state_dict"], [178, 2, 1, "", "state_keys"], [178, 2, 1, "", "state_spec"], [178, 2, 1, "", "state_spec_unbatched"], [178, 1, 1, "", "step"], [178, 1, 1, "", "step_and_maybe_reset"], [178, 1, 1, "", "step_mdp"], [178, 1, 1, "", "to"], [178, 1, 1, "", "to_empty"], [178, 1, 1, "", "train"], [178, 1, 1, "", "type"], [178, 1, 1, "", "xpu"], [178, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.LLMHashingEnv": [[179, 2, 1, "", "action_key"], [179, 2, 1, "", "action_keys"], [179, 2, 1, "", "action_spec"], [179, 2, 1, "", "action_spec_unbatched"], [179, 1, 1, "", "add_module"], [179, 1, 1, "", "add_truncated_keys"], [179, 1, 1, "", "all_actions"], [179, 1, 1, "", "any_done"], [179, 1, 1, "", "append_transform"], [179, 1, 1, "", "apply"], [179, 1, 1, "", "auto_specs_"], [179, 2, 1, "", "batch_dims"], [179, 2, 1, "", "batch_locked"], [179, 2, 1, "", "batch_size"], [179, 1, 1, "", "bfloat16"], [179, 1, 1, "", "buffers"], [179, 1, 1, "", "cardinality"], [179, 1, 1, "", "check_env_specs"], [179, 1, 1, "", "children"], [179, 2, 1, "", "collector"], [179, 1, 1, "", "compile"], [179, 1, 1, "", "cpu"], [179, 1, 1, "", "cuda"], [179, 2, 1, "", "done_key"], [179, 2, 1, "", "done_keys"], [179, 2, 1, "", "done_keys_groups"], [179, 2, 1, "", "done_spec"], [179, 2, 1, "", "done_spec_unbatched"], [179, 1, 1, "", "double"], [179, 1, 1, "", "empty_cache"], [179, 1, 1, "", "eval"], [179, 1, 1, "", "extra_repr"], [179, 1, 1, "", "fake_tensordict"], [179, 1, 1, "", "float"], [179, 1, 1, "", "forward"], [179, 2, 1, "", "full_action_spec"], [179, 2, 1, "", "full_action_spec_unbatched"], [179, 2, 1, "", "full_done_spec"], [179, 2, 1, "", "full_done_spec_unbatched"], [179, 2, 1, "", "full_observation_spec_unbatched"], [179, 2, 1, "", "full_reward_spec"], [179, 2, 1, "", "full_reward_spec_unbatched"], [179, 2, 1, "", "full_state_spec"], [179, 2, 1, "", "full_state_spec_unbatched"], [179, 1, 1, "", "get_buffer"], [179, 1, 1, "", "get_extra_state"], [179, 1, 1, "", "get_parameter"], [179, 1, 1, "", "get_submodule"], [179, 1, 1, "", "half"], [179, 2, 1, "", "input_spec"], [179, 2, 1, "", "input_spec_unbatched"], [179, 1, 1, "", "ipu"], [179, 2, 1, "", "is_spec_locked"], [179, 1, 1, "", "load_state_dict"], [179, 1, 1, "", "make_tensordict"], [179, 1, 1, "", "maybe_reset"], [179, 1, 1, "", "modules"], [179, 1, 1, "", "mtia"], [179, 1, 1, "", "named_buffers"], [179, 1, 1, "", "named_children"], [179, 1, 1, "", "named_modules"], [179, 1, 1, "", "named_parameters"], [179, 2, 1, "", "observation_keys"], [179, 2, 1, "", "observation_spec"], [179, 2, 1, "", "observation_spec_unbatched"], [179, 2, 1, "", "output_spec"], [179, 2, 1, "", "output_spec_unbatched"], [179, 1, 1, "", "parameters"], [179, 1, 1, "", "rand_action"], [179, 1, 1, "", "rand_step"], [179, 1, 1, "", "register_backward_hook"], [179, 1, 1, "", "register_buffer"], [179, 1, 1, "", "register_collector"], [179, 1, 1, "", "register_forward_hook"], [179, 1, 1, "", "register_forward_pre_hook"], [179, 1, 1, "", "register_full_backward_hook"], [179, 1, 1, "", "register_full_backward_pre_hook"], [179, 1, 1, "", "register_gym"], [179, 1, 1, "", "register_load_state_dict_post_hook"], [179, 1, 1, "", "register_load_state_dict_pre_hook"], [179, 1, 1, "", "register_module"], [179, 1, 1, "", "register_parameter"], [179, 1, 1, "", "register_state_dict_post_hook"], [179, 1, 1, "", "register_state_dict_pre_hook"], [179, 1, 1, "", "requires_grad_"], [179, 1, 1, "", "reset"], [179, 2, 1, "", "reset_keys"], [179, 2, 1, "", "reward_key"], [179, 2, 1, "", "reward_keys"], [179, 2, 1, "", "reward_spec"], [179, 2, 1, "", "reward_spec_unbatched"], [179, 1, 1, "", "rollout"], [179, 1, 1, "", "set_extra_state"], [179, 1, 1, "", "set_seed"], [179, 1, 1, "", "set_spec_lock_"], [179, 1, 1, "", "set_submodule"], [179, 2, 1, "", "shape"], [179, 1, 1, "", "share_memory"], [179, 2, 1, "", "specs"], [179, 1, 1, "", "state_dict"], [179, 2, 1, "", "state_keys"], [179, 2, 1, "", "state_spec"], [179, 2, 1, "", "state_spec_unbatched"], [179, 1, 1, "", "step"], [179, 1, 1, "", "step_and_maybe_reset"], [179, 1, 1, "", "step_mdp"], [179, 1, 1, "", "to"], [179, 1, 1, "", "to_empty"], [179, 1, 1, "", "train"], [179, 1, 1, "", "type"], [179, 1, 1, "", "xpu"], [179, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.MLGymWrapper": [[180, 2, 1, "", "action_key"], [180, 2, 1, "", "action_keys"], [180, 2, 1, "", "action_spec"], [180, 2, 1, "", "action_spec_unbatched"], [180, 1, 1, "", "add_module"], [180, 1, 1, "", "add_truncated_keys"], [180, 1, 1, "", "all_actions"], [180, 1, 1, "", "any_done"], [180, 1, 1, "", "append_transform"], [180, 1, 1, "", "apply"], [180, 1, 1, "", "auto_register_info_dict"], [180, 1, 1, "", "auto_specs_"], [180, 2, 1, "", "batch_dims"], [180, 2, 1, "", "batch_locked"], [180, 2, 1, "", "batch_size"], [180, 1, 1, "", "bfloat16"], [180, 1, 1, "", "buffers"], [180, 1, 1, "", "cardinality"], [180, 1, 1, "", "check_env_specs"], [180, 1, 1, "", "children"], [180, 1, 1, "", "close"], [180, 2, 1, "", "collector"], [180, 1, 1, "", "compile"], [180, 1, 1, "", "cpu"], [180, 1, 1, "", "cuda"], [180, 2, 1, "", "done_key"], [180, 2, 1, "", "done_keys"], [180, 2, 1, "", "done_keys_groups"], [180, 2, 1, "", "done_spec"], [180, 2, 1, "", "done_spec_unbatched"], [180, 1, 1, "", "double"], [180, 1, 1, "", "empty_cache"], [180, 1, 1, "", "eval"], [180, 1, 1, "", "extra_repr"], [180, 1, 1, "", "fake_tensordict"], [180, 1, 1, "", "fast_encoding"], [180, 1, 1, "", "float"], [180, 1, 1, "", "forward"], [180, 2, 1, "", "full_action_spec"], [180, 2, 1, "", "full_action_spec_unbatched"], [180, 2, 1, "", "full_done_spec"], [180, 2, 1, "", "full_done_spec_unbatched"], [180, 2, 1, "", "full_observation_spec_unbatched"], [180, 2, 1, "", "full_reward_spec"], [180, 2, 1, "", "full_reward_spec_unbatched"], [180, 2, 1, "", "full_state_spec"], [180, 2, 1, "", "full_state_spec_unbatched"], [180, 1, 1, "", "get_buffer"], [180, 1, 1, "", "get_extra_state"], [180, 1, 1, "", "get_library_name"], [180, 1, 1, "", "get_parameter"], [180, 1, 1, "", "get_submodule"], [180, 1, 1, "", "half"], [180, 2, 1, "", "input_spec"], [180, 2, 1, "", "input_spec_unbatched"], [180, 1, 1, "", "ipu"], [180, 2, 1, "", "is_spec_locked"], [180, 1, 1, "", "load_state_dict"], [180, 1, 1, "", "maybe_reset"], [180, 1, 1, "", "modules"], [180, 1, 1, "", "mtia"], [180, 1, 1, "", "named_buffers"], [180, 1, 1, "", "named_children"], [180, 1, 1, "", "named_modules"], [180, 1, 1, "", "named_parameters"], [180, 2, 1, "", "observation_keys"], [180, 2, 1, "", "observation_spec"], [180, 2, 1, "", "observation_spec_unbatched"], [180, 2, 1, "", "output_spec"], [180, 2, 1, "", "output_spec_unbatched"], [180, 1, 1, "", "parameters"], [180, 1, 1, "", "rand_action"], [180, 1, 1, "", "rand_step"], [180, 1, 1, "", "read_action"], [180, 1, 1, "", "read_done"], [180, 1, 1, "", "read_obs"], [180, 1, 1, "", "read_reward"], [180, 1, 1, "", "register_backward_hook"], [180, 1, 1, "", "register_buffer"], [180, 1, 1, "", "register_collector"], [180, 1, 1, "", "register_forward_hook"], [180, 1, 1, "", "register_forward_pre_hook"], [180, 1, 1, "", "register_full_backward_hook"], [180, 1, 1, "", "register_full_backward_pre_hook"], [180, 1, 1, "", "register_gym"], [180, 1, 1, "", "register_load_state_dict_post_hook"], [180, 1, 1, "", "register_load_state_dict_pre_hook"], [180, 1, 1, "", "register_module"], [180, 1, 1, "", "register_parameter"], [180, 1, 1, "", "register_state_dict_post_hook"], [180, 1, 1, "", "register_state_dict_pre_hook"], [180, 1, 1, "", "requires_grad_"], [180, 1, 1, "", "reset"], [180, 2, 1, "", "reset_keys"], [180, 2, 1, "", "reward_key"], [180, 2, 1, "", "reward_keys"], [180, 2, 1, "", "reward_spec"], [180, 2, 1, "", "reward_spec_unbatched"], [180, 1, 1, "", "rollout"], [180, 1, 1, "", "set_extra_state"], [180, 1, 1, "", "set_info_dict_reader"], [180, 1, 1, "", "set_seed"], [180, 1, 1, "", "set_spec_lock_"], [180, 1, 1, "", "set_submodule"], [180, 2, 1, "", "shape"], [180, 1, 1, "", "share_memory"], [180, 2, 1, "", "specs"], [180, 1, 1, "", "state_dict"], [180, 2, 1, "", "state_keys"], [180, 2, 1, "", "state_spec"], [180, 2, 1, "", "state_spec_unbatched"], [180, 1, 1, "", "step"], [180, 1, 1, "", "step_and_maybe_reset"], [180, 1, 1, "", "step_mdp"], [180, 1, 1, "", "to"], [180, 1, 1, "", "to_empty"], [180, 1, 1, "", "train"], [180, 1, 1, "", "type"], [180, 1, 1, "", "xpu"], [180, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms": [[183, 0, 1, "", "AddThinkingPrompt"], [184, 0, 1, "", "BrowserTransform"], [185, 0, 1, "", "DataLoadingPrimer"], [186, 0, 1, "", "ExecuteToolsInOrder"], [187, 0, 1, "", "JSONCallParser"], [188, 0, 1, "", "KLComputation"], [189, 0, 1, "", "KLRewardTransform"], [190, 0, 1, "", "MCPToolTransform"], [191, 0, 1, "", "PolicyVersion"], [192, 0, 1, "", "PythonExecutorService"], [193, 0, 1, "", "PythonInterpreter"], [194, 0, 1, "", "RayDataLoadingPrimer"], [195, 0, 1, "", "RetrieveKL"], [196, 0, 1, "", "RetrieveLogProb"], [197, 0, 1, "", "SimpleToolTransform"], [198, 0, 1, "", "TemplateTransform"], [199, 0, 1, "", "Tokenizer"], [200, 0, 1, "", "ToolCall"], [201, 0, 1, "", "ToolRegistry"], [202, 0, 1, "", "ToolService"], [203, 0, 1, "", "XMLBlockParser"], [204, 0, 1, "", "as_nested_tensor"], [205, 0, 1, "", "as_padded_tensor"]], "torchrl.envs.llm.transforms.AddThinkingPrompt": [[183, 1, 1, "", "add_module"], [183, 1, 1, "", "apply"], [183, 1, 1, "", "bfloat16"], [183, 1, 1, "", "buffers"], [183, 1, 1, "", "children"], [183, 1, 1, "", "close"], [183, 2, 1, "", "collector"], [183, 1, 1, "", "compile"], [183, 2, 1, "", "container"], [183, 1, 1, "", "cpu"], [183, 1, 1, "", "cuda"], [183, 1, 1, "", "double"], [183, 1, 1, "", "eval"], [183, 1, 1, "", "extra_repr"], [183, 1, 1, "", "float"], [183, 1, 1, "", "forward"], [183, 1, 1, "", "get_buffer"], [183, 1, 1, "", "get_extra_state"], [183, 1, 1, "", "get_parameter"], [183, 1, 1, "", "get_submodule"], [183, 1, 1, "", "half"], [183, 1, 1, "", "init"], [183, 1, 1, "", "inv"], [183, 1, 1, "", "ipu"], [183, 1, 1, "", "load_state_dict"], [183, 1, 1, "", "modules"], [183, 1, 1, "", "mtia"], [183, 1, 1, "", "named_buffers"], [183, 1, 1, "", "named_children"], [183, 1, 1, "", "named_modules"], [183, 1, 1, "", "named_parameters"], [183, 1, 1, "", "parameters"], [183, 2, 1, "", "parent"], [183, 1, 1, "", "register_backward_hook"], [183, 1, 1, "", "register_buffer"], [183, 1, 1, "", "register_forward_hook"], [183, 1, 1, "", "register_forward_pre_hook"], [183, 1, 1, "", "register_full_backward_hook"], [183, 1, 1, "", "register_full_backward_pre_hook"], [183, 1, 1, "", "register_load_state_dict_post_hook"], [183, 1, 1, "", "register_load_state_dict_pre_hook"], [183, 1, 1, "", "register_module"], [183, 1, 1, "", "register_parameter"], [183, 1, 1, "", "register_state_dict_post_hook"], [183, 1, 1, "", "register_state_dict_pre_hook"], [183, 1, 1, "", "requires_grad_"], [183, 1, 1, "", "set_extra_state"], [183, 1, 1, "", "set_submodule"], [183, 1, 1, "", "share_memory"], [183, 1, 1, "", "state_dict"], [183, 1, 1, "", "to"], [183, 1, 1, "", "to_empty"], [183, 1, 1, "", "train"], [183, 1, 1, "", "transform_action_spec"], [183, 1, 1, "", "transform_done_spec"], [183, 1, 1, "", "transform_env_batch_size"], [183, 1, 1, "", "transform_env_device"], [183, 1, 1, "", "transform_input_spec"], [183, 1, 1, "", "transform_observation_spec"], [183, 1, 1, "", "transform_output_spec"], [183, 1, 1, "", "transform_reward_spec"], [183, 1, 1, "", "transform_state_spec"], [183, 1, 1, "", "type"], [183, 1, 1, "", "xpu"], [183, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.BrowserTransform": [[184, 1, 1, "", "add_module"], [184, 1, 1, "", "apply"], [184, 1, 1, "", "bfloat16"], [184, 1, 1, "", "buffers"], [184, 1, 1, "", "children"], [184, 1, 1, "", "clone"], [184, 1, 1, "", "close"], [184, 2, 1, "", "collector"], [184, 1, 1, "", "compile"], [184, 2, 1, "", "container"], [184, 1, 1, "", "cpu"], [184, 1, 1, "", "cuda"], [184, 1, 1, "", "double"], [184, 1, 1, "", "eval"], [184, 1, 1, "", "extra_repr"], [184, 1, 1, "", "float"], [184, 1, 1, "", "forward"], [184, 1, 1, "", "get_buffer"], [184, 1, 1, "", "get_extra_state"], [184, 1, 1, "", "get_parameter"], [184, 1, 1, "", "get_submodule"], [184, 1, 1, "", "half"], [184, 1, 1, "", "init"], [184, 1, 1, "", "inv"], [184, 1, 1, "", "ipu"], [184, 1, 1, "", "load_state_dict"], [184, 1, 1, "", "modules"], [184, 1, 1, "", "mtia"], [184, 1, 1, "", "named_buffers"], [184, 1, 1, "", "named_children"], [184, 1, 1, "", "named_modules"], [184, 1, 1, "", "named_parameters"], [184, 1, 1, "", "parameters"], [184, 2, 1, "", "parent"], [184, 1, 1, "", "register_backward_hook"], [184, 1, 1, "", "register_buffer"], [184, 1, 1, "", "register_forward_hook"], [184, 1, 1, "", "register_forward_pre_hook"], [184, 1, 1, "", "register_full_backward_hook"], [184, 1, 1, "", "register_full_backward_pre_hook"], [184, 1, 1, "", "register_load_state_dict_post_hook"], [184, 1, 1, "", "register_load_state_dict_pre_hook"], [184, 1, 1, "", "register_module"], [184, 1, 1, "", "register_parameter"], [184, 1, 1, "", "register_state_dict_post_hook"], [184, 1, 1, "", "register_state_dict_pre_hook"], [184, 1, 1, "", "requires_grad_"], [184, 1, 1, "", "set_extra_state"], [184, 1, 1, "", "set_submodule"], [184, 1, 1, "", "share_memory"], [184, 1, 1, "", "state_dict"], [184, 1, 1, "", "to"], [184, 1, 1, "", "to_empty"], [184, 1, 1, "", "train"], [184, 1, 1, "", "transform_action_spec"], [184, 1, 1, "", "transform_done_spec"], [184, 1, 1, "", "transform_env_batch_size"], [184, 1, 1, "", "transform_env_device"], [184, 1, 1, "", "transform_input_spec"], [184, 1, 1, "", "transform_observation_spec"], [184, 1, 1, "", "transform_output_spec"], [184, 1, 1, "", "transform_reward_spec"], [184, 1, 1, "", "transform_state_spec"], [184, 1, 1, "", "type"], [184, 1, 1, "", "xpu"], [184, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.DataLoadingPrimer": [[185, 1, 1, "", "add_module"], [185, 1, 1, "", "apply"], [185, 1, 1, "", "bfloat16"], [185, 1, 1, "", "buffers"], [185, 1, 1, "", "children"], [185, 1, 1, "", "close"], [185, 2, 1, "", "collector"], [185, 1, 1, "", "compile"], [185, 2, 1, "", "container"], [185, 1, 1, "", "cpu"], [185, 1, 1, "", "cuda"], [185, 1, 1, "", "double"], [185, 1, 1, "", "eval"], [185, 1, 1, "", "extra_repr"], [185, 1, 1, "", "float"], [185, 1, 1, "", "forward"], [185, 1, 1, "", "get_buffer"], [185, 1, 1, "", "get_extra_state"], [185, 1, 1, "", "get_parameter"], [185, 1, 1, "", "get_submodule"], [185, 1, 1, "", "half"], [185, 1, 1, "", "init"], [185, 1, 1, "", "inv"], [185, 1, 1, "", "ipu"], [185, 1, 1, "", "load_state_dict"], [185, 1, 1, "", "modules"], [185, 1, 1, "", "mtia"], [185, 1, 1, "", "named_buffers"], [185, 1, 1, "", "named_children"], [185, 1, 1, "", "named_modules"], [185, 1, 1, "", "named_parameters"], [185, 1, 1, "", "parameters"], [185, 2, 1, "", "parent"], [185, 1, 1, "", "register_backward_hook"], [185, 1, 1, "", "register_buffer"], [185, 1, 1, "", "register_forward_hook"], [185, 1, 1, "", "register_forward_pre_hook"], [185, 1, 1, "", "register_full_backward_hook"], [185, 1, 1, "", "register_full_backward_pre_hook"], [185, 1, 1, "", "register_load_state_dict_post_hook"], [185, 1, 1, "", "register_load_state_dict_pre_hook"], [185, 1, 1, "", "register_module"], [185, 1, 1, "", "register_parameter"], [185, 1, 1, "", "register_state_dict_post_hook"], [185, 1, 1, "", "register_state_dict_pre_hook"], [185, 1, 1, "", "requires_grad_"], [185, 1, 1, "", "reset_dataloader"], [185, 1, 1, "", "set_extra_state"], [185, 1, 1, "", "set_submodule"], [185, 1, 1, "", "share_memory"], [185, 1, 1, "", "state_dict"], [185, 1, 1, "", "to"], [185, 1, 1, "", "to_empty"], [185, 1, 1, "", "train"], [185, 1, 1, "", "transform_action_spec"], [185, 1, 1, "", "transform_done_spec"], [185, 1, 1, "", "transform_env_batch_size"], [185, 1, 1, "", "transform_env_device"], [185, 1, 1, "", "transform_input_spec"], [185, 1, 1, "", "transform_observation_spec"], [185, 1, 1, "", "transform_output_spec"], [185, 1, 1, "", "transform_reward_spec"], [185, 1, 1, "", "transform_state_spec"], [185, 1, 1, "", "type"], [185, 1, 1, "", "xpu"], [185, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.ExecuteToolsInOrder": [[186, 1, 1, "", "add_module"], [186, 1, 1, "", "apply"], [186, 1, 1, "", "bfloat16"], [186, 1, 1, "", "buffers"], [186, 1, 1, "", "children"], [186, 1, 1, "", "close"], [186, 2, 1, "", "collector"], [186, 1, 1, "", "compile"], [186, 2, 1, "", "container"], [186, 1, 1, "", "cpu"], [186, 1, 1, "", "cuda"], [186, 1, 1, "", "double"], [186, 1, 1, "", "eval"], [186, 1, 1, "", "extra_repr"], [186, 1, 1, "", "float"], [186, 1, 1, "", "forward"], [186, 1, 1, "", "get_buffer"], [186, 1, 1, "", "get_extra_state"], [186, 1, 1, "", "get_parameter"], [186, 1, 1, "", "get_submodule"], [186, 1, 1, "", "half"], [186, 1, 1, "", "init"], [186, 1, 1, "", "inv"], [186, 1, 1, "", "ipu"], [186, 1, 1, "", "load_state_dict"], [186, 1, 1, "", "modules"], [186, 1, 1, "", "mtia"], [186, 1, 1, "", "named_buffers"], [186, 1, 1, "", "named_children"], [186, 1, 1, "", "named_modules"], [186, 1, 1, "", "named_parameters"], [186, 1, 1, "", "parameters"], [186, 2, 1, "", "parent"], [186, 1, 1, "", "register_backward_hook"], [186, 1, 1, "", "register_buffer"], [186, 1, 1, "", "register_forward_hook"], [186, 1, 1, "", "register_forward_pre_hook"], [186, 1, 1, "", "register_full_backward_hook"], [186, 1, 1, "", "register_full_backward_pre_hook"], [186, 1, 1, "", "register_load_state_dict_post_hook"], [186, 1, 1, "", "register_load_state_dict_pre_hook"], [186, 1, 1, "", "register_module"], [186, 1, 1, "", "register_parameter"], [186, 1, 1, "", "register_state_dict_post_hook"], [186, 1, 1, "", "register_state_dict_pre_hook"], [186, 1, 1, "", "requires_grad_"], [186, 1, 1, "", "set_extra_state"], [186, 1, 1, "", "set_submodule"], [186, 1, 1, "", "share_memory"], [186, 1, 1, "", "state_dict"], [186, 1, 1, "", "to"], [186, 1, 1, "", "to_empty"], [186, 1, 1, "", "train"], [186, 1, 1, "", "transform_action_spec"], [186, 1, 1, "", "transform_done_spec"], [186, 1, 1, "", "transform_env_batch_size"], [186, 1, 1, "", "transform_env_device"], [186, 1, 1, "", "transform_input_spec"], [186, 1, 1, "", "transform_observation_spec"], [186, 1, 1, "", "transform_output_spec"], [186, 1, 1, "", "transform_reward_spec"], [186, 1, 1, "", "transform_state_spec"], [186, 1, 1, "", "type"], [186, 1, 1, "", "xpu"], [186, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.KLComputation": [[188, 1, 1, "", "add_module"], [188, 1, 1, "", "apply"], [188, 1, 1, "", "bfloat16"], [188, 1, 1, "", "buffers"], [188, 1, 1, "", "children"], [188, 1, 1, "", "close"], [188, 2, 1, "", "collector"], [188, 1, 1, "", "compile"], [188, 2, 1, "", "container"], [188, 1, 1, "", "cpu"], [188, 1, 1, "", "cuda"], [188, 1, 1, "", "double"], [188, 1, 1, "", "eval"], [188, 1, 1, "", "extra_repr"], [188, 1, 1, "", "float"], [188, 1, 1, "", "forward"], [188, 1, 1, "", "get_buffer"], [188, 1, 1, "", "get_extra_state"], [188, 1, 1, "", "get_parameter"], [188, 1, 1, "", "get_submodule"], [188, 1, 1, "", "half"], [188, 1, 1, "", "init"], [188, 1, 1, "", "inv"], [188, 1, 1, "", "ipu"], [188, 1, 1, "", "load_state_dict"], [188, 1, 1, "", "modules"], [188, 1, 1, "", "mtia"], [188, 1, 1, "", "named_buffers"], [188, 1, 1, "", "named_children"], [188, 1, 1, "", "named_modules"], [188, 1, 1, "", "named_parameters"], [188, 1, 1, "", "parameters"], [188, 2, 1, "", "parent"], [188, 1, 1, "", "register_backward_hook"], [188, 1, 1, "", "register_buffer"], [188, 1, 1, "", "register_forward_hook"], [188, 1, 1, "", "register_forward_pre_hook"], [188, 1, 1, "", "register_full_backward_hook"], [188, 1, 1, "", "register_full_backward_pre_hook"], [188, 1, 1, "", "register_load_state_dict_post_hook"], [188, 1, 1, "", "register_load_state_dict_pre_hook"], [188, 1, 1, "", "register_module"], [188, 1, 1, "", "register_parameter"], [188, 1, 1, "", "register_state_dict_post_hook"], [188, 1, 1, "", "register_state_dict_pre_hook"], [188, 1, 1, "", "requires_grad_"], [188, 1, 1, "", "set_extra_state"], [188, 1, 1, "", "set_submodule"], [188, 1, 1, "", "share_memory"], [188, 1, 1, "", "state_dict"], [188, 1, 1, "", "to"], [188, 1, 1, "", "to_empty"], [188, 1, 1, "", "train"], [188, 1, 1, "", "transform_action_spec"], [188, 1, 1, "", "transform_done_spec"], [188, 1, 1, "", "transform_env_batch_size"], [188, 1, 1, "", "transform_env_device"], [188, 1, 1, "", "transform_input_spec"], [188, 1, 1, "", "transform_observation_spec"], [188, 1, 1, "", "transform_output_spec"], [188, 1, 1, "", "transform_reward_spec"], [188, 1, 1, "", "transform_state_spec"], [188, 1, 1, "", "type"], [188, 1, 1, "", "xpu"], [188, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.KLRewardTransform": [[189, 1, 1, "", "add_module"], [189, 1, 1, "", "apply"], [189, 1, 1, "", "bfloat16"], [189, 1, 1, "", "buffers"], [189, 1, 1, "", "children"], [189, 1, 1, "", "close"], [189, 2, 1, "", "collector"], [189, 1, 1, "", "compile"], [189, 2, 1, "", "container"], [189, 1, 1, "", "cpu"], [189, 1, 1, "", "cuda"], [189, 1, 1, "", "double"], [189, 1, 1, "", "eval"], [189, 1, 1, "", "extra_repr"], [189, 1, 1, "", "float"], [189, 1, 1, "", "forward"], [189, 1, 1, "", "get_buffer"], [189, 1, 1, "", "get_extra_state"], [189, 1, 1, "", "get_parameter"], [189, 1, 1, "", "get_submodule"], [189, 1, 1, "", "half"], [189, 1, 1, "", "init"], [189, 1, 1, "", "inv"], [189, 1, 1, "", "ipu"], [189, 1, 1, "", "load_state_dict"], [189, 1, 1, "", "modules"], [189, 1, 1, "", "mtia"], [189, 1, 1, "", "named_buffers"], [189, 1, 1, "", "named_children"], [189, 1, 1, "", "named_modules"], [189, 1, 1, "", "named_parameters"], [189, 1, 1, "", "parameters"], [189, 2, 1, "", "parent"], [189, 1, 1, "", "register_backward_hook"], [189, 1, 1, "", "register_buffer"], [189, 1, 1, "", "register_forward_hook"], [189, 1, 1, "", "register_forward_pre_hook"], [189, 1, 1, "", "register_full_backward_hook"], [189, 1, 1, "", "register_full_backward_pre_hook"], [189, 1, 1, "", "register_load_state_dict_post_hook"], [189, 1, 1, "", "register_load_state_dict_pre_hook"], [189, 1, 1, "", "register_module"], [189, 1, 1, "", "register_parameter"], [189, 1, 1, "", "register_state_dict_post_hook"], [189, 1, 1, "", "register_state_dict_pre_hook"], [189, 1, 1, "", "requires_grad_"], [189, 1, 1, "", "set_extra_state"], [189, 1, 1, "", "set_submodule"], [189, 1, 1, "", "share_memory"], [189, 1, 1, "", "state_dict"], [189, 1, 1, "", "to"], [189, 1, 1, "", "to_empty"], [189, 1, 1, "", "train"], [189, 1, 1, "", "transform_action_spec"], [189, 1, 1, "", "transform_done_spec"], [189, 1, 1, "", "transform_env_batch_size"], [189, 1, 1, "", "transform_env_device"], [189, 1, 1, "", "transform_input_spec"], [189, 1, 1, "", "transform_observation_spec"], [189, 1, 1, "", "transform_output_spec"], [189, 1, 1, "", "transform_reward_spec"], [189, 1, 1, "", "transform_state_spec"], [189, 1, 1, "", "type"], [189, 1, 1, "", "xpu"], [189, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.MCPToolTransform": [[190, 1, 1, "", "add_module"], [190, 1, 1, "", "apply"], [190, 1, 1, "", "bfloat16"], [190, 1, 1, "", "buffers"], [190, 1, 1, "", "children"], [190, 1, 1, "", "close"], [190, 2, 1, "", "collector"], [190, 1, 1, "", "compile"], [190, 2, 1, "", "container"], [190, 1, 1, "", "cpu"], [190, 1, 1, "", "cuda"], [190, 1, 1, "", "double"], [190, 1, 1, "", "eval"], [190, 1, 1, "", "extra_repr"], [190, 1, 1, "", "float"], [190, 1, 1, "", "forward"], [190, 1, 1, "", "get_buffer"], [190, 1, 1, "", "get_extra_state"], [190, 1, 1, "", "get_parameter"], [190, 1, 1, "", "get_submodule"], [190, 1, 1, "", "half"], [190, 1, 1, "", "init"], [190, 1, 1, "", "inv"], [190, 1, 1, "", "ipu"], [190, 1, 1, "", "load_state_dict"], [190, 1, 1, "", "modules"], [190, 1, 1, "", "mtia"], [190, 1, 1, "", "named_buffers"], [190, 1, 1, "", "named_children"], [190, 1, 1, "", "named_modules"], [190, 1, 1, "", "named_parameters"], [190, 1, 1, "", "parameters"], [190, 2, 1, "", "parent"], [190, 1, 1, "", "register_backward_hook"], [190, 1, 1, "", "register_buffer"], [190, 1, 1, "", "register_forward_hook"], [190, 1, 1, "", "register_forward_pre_hook"], [190, 1, 1, "", "register_full_backward_hook"], [190, 1, 1, "", "register_full_backward_pre_hook"], [190, 1, 1, "", "register_load_state_dict_post_hook"], [190, 1, 1, "", "register_load_state_dict_pre_hook"], [190, 1, 1, "", "register_module"], [190, 1, 1, "", "register_parameter"], [190, 1, 1, "", "register_state_dict_post_hook"], [190, 1, 1, "", "register_state_dict_pre_hook"], [190, 1, 1, "", "requires_grad_"], [190, 1, 1, "", "set_extra_state"], [190, 1, 1, "", "set_submodule"], [190, 1, 1, "", "share_memory"], [190, 1, 1, "", "state_dict"], [190, 1, 1, "", "to"], [190, 1, 1, "", "to_empty"], [190, 1, 1, "", "train"], [190, 1, 1, "", "transform_action_spec"], [190, 1, 1, "", "transform_done_spec"], [190, 1, 1, "", "transform_env_batch_size"], [190, 1, 1, "", "transform_env_device"], [190, 1, 1, "", "transform_input_spec"], [190, 1, 1, "", "transform_observation_spec"], [190, 1, 1, "", "transform_output_spec"], [190, 1, 1, "", "transform_reward_spec"], [190, 1, 1, "", "transform_state_spec"], [190, 1, 1, "", "type"], [190, 1, 1, "", "xpu"], [190, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.PolicyVersion": [[191, 1, 1, "", "add_module"], [191, 1, 1, "", "apply"], [191, 1, 1, "", "bfloat16"], [191, 1, 1, "", "buffers"], [191, 1, 1, "", "children"], [191, 1, 1, "", "close"], [191, 2, 1, "", "collector"], [191, 1, 1, "", "compile"], [191, 2, 1, "", "container"], [191, 1, 1, "", "cpu"], [191, 1, 1, "", "cuda"], [191, 1, 1, "", "double"], [191, 1, 1, "", "eval"], [191, 1, 1, "", "extra_repr"], [191, 1, 1, "", "float"], [191, 1, 1, "", "forward"], [191, 1, 1, "", "get_buffer"], [191, 1, 1, "", "get_extra_state"], [191, 1, 1, "", "get_parameter"], [191, 1, 1, "", "get_submodule"], [191, 1, 1, "", "half"], [191, 1, 1, "", "increment_version"], [191, 1, 1, "", "init"], [191, 1, 1, "", "inv"], [191, 1, 1, "", "ipu"], [191, 1, 1, "", "load_state_dict"], [191, 1, 1, "", "modules"], [191, 1, 1, "", "mtia"], [191, 1, 1, "", "named_buffers"], [191, 1, 1, "", "named_children"], [191, 1, 1, "", "named_modules"], [191, 1, 1, "", "named_parameters"], [191, 1, 1, "", "parameters"], [191, 2, 1, "", "parent"], [191, 1, 1, "", "register_backward_hook"], [191, 1, 1, "", "register_buffer"], [191, 1, 1, "", "register_forward_hook"], [191, 1, 1, "", "register_forward_pre_hook"], [191, 1, 1, "", "register_full_backward_hook"], [191, 1, 1, "", "register_full_backward_pre_hook"], [191, 1, 1, "", "register_load_state_dict_post_hook"], [191, 1, 1, "", "register_load_state_dict_pre_hook"], [191, 1, 1, "", "register_module"], [191, 1, 1, "", "register_parameter"], [191, 1, 1, "", "register_state_dict_post_hook"], [191, 1, 1, "", "register_state_dict_pre_hook"], [191, 1, 1, "", "requires_grad_"], [191, 1, 1, "", "set_extra_state"], [191, 1, 1, "", "set_submodule"], [191, 1, 1, "", "share_memory"], [191, 1, 1, "", "state_dict"], [191, 1, 1, "", "to"], [191, 1, 1, "", "to_empty"], [191, 1, 1, "", "train"], [191, 1, 1, "", "transform_action_spec"], [191, 1, 1, "", "transform_done_spec"], [191, 1, 1, "", "transform_env_batch_size"], [191, 1, 1, "", "transform_env_device"], [191, 1, 1, "", "transform_input_spec"], [191, 1, 1, "", "transform_observation_spec"], [191, 1, 1, "", "transform_output_spec"], [191, 1, 1, "", "transform_reward_spec"], [191, 1, 1, "", "transform_state_spec"], [191, 1, 1, "", "type"], [191, 2, 1, "", "version"], [191, 1, 1, "", "xpu"], [191, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.PythonExecutorService": [[192, 1, 1, "", "cleanup"], [192, 1, 1, "", "execute"]], "torchrl.envs.llm.transforms.PythonInterpreter": [[193, 1, 1, "", "add_module"], [193, 1, 1, "", "apply"], [193, 1, 1, "", "bfloat16"], [193, 1, 1, "", "buffers"], [193, 1, 1, "", "children"], [193, 1, 1, "", "clone"], [193, 1, 1, "", "close"], [193, 2, 1, "", "collector"], [193, 1, 1, "", "compile"], [193, 2, 1, "", "container"], [193, 1, 1, "", "cpu"], [193, 1, 1, "", "cuda"], [193, 1, 1, "", "double"], [193, 1, 1, "", "eval"], [193, 1, 1, "", "extra_repr"], [193, 1, 1, "", "float"], [193, 1, 1, "", "forward"], [193, 1, 1, "", "get_buffer"], [193, 1, 1, "", "get_extra_state"], [193, 1, 1, "", "get_parameter"], [193, 1, 1, "", "get_submodule"], [193, 1, 1, "", "half"], [193, 1, 1, "", "init"], [193, 1, 1, "", "inv"], [193, 1, 1, "", "ipu"], [193, 1, 1, "", "load_state_dict"], [193, 1, 1, "", "modules"], [193, 1, 1, "", "mtia"], [193, 1, 1, "", "named_buffers"], [193, 1, 1, "", "named_children"], [193, 1, 1, "", "named_modules"], [193, 1, 1, "", "named_parameters"], [193, 1, 1, "", "parameters"], [193, 2, 1, "", "parent"], [193, 1, 1, "", "register_backward_hook"], [193, 1, 1, "", "register_buffer"], [193, 1, 1, "", "register_forward_hook"], [193, 1, 1, "", "register_forward_pre_hook"], [193, 1, 1, "", "register_full_backward_hook"], [193, 1, 1, "", "register_full_backward_pre_hook"], [193, 1, 1, "", "register_load_state_dict_post_hook"], [193, 1, 1, "", "register_load_state_dict_pre_hook"], [193, 1, 1, "", "register_module"], [193, 1, 1, "", "register_parameter"], [193, 1, 1, "", "register_state_dict_post_hook"], [193, 1, 1, "", "register_state_dict_pre_hook"], [193, 1, 1, "", "requires_grad_"], [193, 1, 1, "", "set_extra_state"], [193, 1, 1, "", "set_submodule"], [193, 1, 1, "", "share_memory"], [193, 1, 1, "", "state_dict"], [193, 1, 1, "", "to"], [193, 1, 1, "", "to_empty"], [193, 1, 1, "", "train"], [193, 1, 1, "", "transform_action_spec"], [193, 1, 1, "", "transform_done_spec"], [193, 1, 1, "", "transform_env_batch_size"], [193, 1, 1, "", "transform_env_device"], [193, 1, 1, "", "transform_input_spec"], [193, 1, 1, "", "transform_observation_spec"], [193, 1, 1, "", "transform_output_spec"], [193, 1, 1, "", "transform_reward_spec"], [193, 1, 1, "", "transform_state_spec"], [193, 1, 1, "", "type"], [193, 1, 1, "", "xpu"], [193, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.RayDataLoadingPrimer": [[194, 1, 1, "", "add_module"], [194, 1, 1, "", "apply"], [194, 2, 1, "", "base_env"], [194, 1, 1, "", "bfloat16"], [194, 1, 1, "", "buffers"], [194, 1, 1, "", "children"], [194, 1, 1, "", "clone"], [194, 1, 1, "", "close"], [194, 2, 1, "", "collector"], [194, 1, 1, "", "compile"], [194, 2, 1, "", "container"], [194, 1, 1, "", "cpu"], [194, 1, 1, "", "cuda"], [194, 2, 1, "", "data_keys"], [194, 2, 1, "", "dataloader"], [194, 2, 1, "", "device"], [194, 1, 1, "", "double"], [194, 1, 1, "", "dump"], [194, 1, 1, "", "empty_cache"], [194, 2, 1, "", "endless_dataloader"], [194, 1, 1, "", "eval"], [194, 1, 1, "", "extra_repr"], [194, 1, 1, "", "float"], [194, 1, 1, "", "forward"], [194, 1, 1, "", "get_buffer"], [194, 1, 1, "", "get_extra_state"], [194, 1, 1, "", "get_parameter"], [194, 1, 1, "", "get_submodule"], [194, 1, 1, "", "half"], [194, 2, 1, "", "in_keys"], [194, 2, 1, "", "in_keys_inv"], [194, 1, 1, "", "init"], [194, 1, 1, "", "inv"], [194, 1, 1, "", "ipu"], [194, 1, 1, "", "load_state_dict"], [194, 2, 1, "", "missing_tolerance"], [194, 1, 1, "", "modules"], [194, 1, 1, "", "mtia"], [194, 1, 1, "", "named_buffers"], [194, 1, 1, "", "named_children"], [194, 1, 1, "", "named_modules"], [194, 1, 1, "", "named_parameters"], [194, 2, 1, "", "out_keys"], [194, 2, 1, "", "out_keys_inv"], [194, 1, 1, "", "parameters"], [194, 2, 1, "", "parent"], [194, 2, 1, "", "primers"], [194, 1, 1, "", "register_backward_hook"], [194, 1, 1, "", "register_buffer"], [194, 1, 1, "", "register_forward_hook"], [194, 1, 1, "", "register_forward_pre_hook"], [194, 1, 1, "", "register_full_backward_hook"], [194, 1, 1, "", "register_full_backward_pre_hook"], [194, 1, 1, "", "register_load_state_dict_post_hook"], [194, 1, 1, "", "register_load_state_dict_pre_hook"], [194, 1, 1, "", "register_module"], [194, 1, 1, "", "register_parameter"], [194, 1, 1, "", "register_state_dict_post_hook"], [194, 1, 1, "", "register_state_dict_pre_hook"], [194, 2, 1, "", "repeats"], [194, 1, 1, "", "requires_grad_"], [194, 1, 1, "", "reset_dataloader"], [194, 1, 1, "", "reset_parent"], [194, 1, 1, "", "set_container"], [194, 1, 1, "", "set_extra_state"], [194, 1, 1, "", "set_missing_tolerance"], [194, 1, 1, "", "set_submodule"], [194, 1, 1, "", "share_memory"], [194, 2, 1, "", "stack_method"], [194, 1, 1, "", "state_dict"], [194, 1, 1, "", "to"], [194, 1, 1, "", "to_empty"], [194, 1, 1, "", "train"], [194, 1, 1, "", "transform_action_spec"], [194, 1, 1, "", "transform_done_spec"], [194, 1, 1, "", "transform_env_batch_size"], [194, 1, 1, "", "transform_env_device"], [194, 1, 1, "", "transform_input_spec"], [194, 1, 1, "", "transform_observation_spec"], [194, 1, 1, "", "transform_output_spec"], [194, 1, 1, "", "transform_reward_spec"], [194, 1, 1, "", "transform_state_spec"], [194, 1, 1, "", "type"], [194, 1, 1, "", "xpu"], [194, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.RetrieveKL": [[195, 1, 1, "", "add_module"], [195, 1, 1, "", "append"], [195, 1, 1, "", "apply"], [195, 1, 1, "", "bfloat16"], [195, 1, 1, "", "buffers"], [195, 1, 1, "", "children"], [195, 1, 1, "", "close"], [195, 2, 1, "", "collector"], [195, 1, 1, "", "compile"], [195, 2, 1, "", "container"], [195, 1, 1, "", "cpu"], [195, 1, 1, "", "cuda"], [195, 1, 1, "", "double"], [195, 1, 1, "", "eval"], [195, 1, 1, "", "extra_repr"], [195, 1, 1, "", "float"], [195, 1, 1, "", "forward"], [195, 1, 1, "", "get_buffer"], [195, 1, 1, "", "get_extra_state"], [195, 1, 1, "", "get_parameter"], [195, 1, 1, "", "get_submodule"], [195, 1, 1, "", "half"], [195, 1, 1, "", "init"], [195, 1, 1, "", "insert"], [195, 1, 1, "", "inv"], [195, 1, 1, "", "ipu"], [195, 1, 1, "", "load_state_dict"], [195, 1, 1, "", "modules"], [195, 1, 1, "", "mtia"], [195, 1, 1, "", "named_buffers"], [195, 1, 1, "", "named_children"], [195, 1, 1, "", "named_modules"], [195, 1, 1, "", "named_parameters"], [195, 1, 1, "", "parameters"], [195, 2, 1, "", "parent"], [195, 1, 1, "", "pop"], [195, 1, 1, "", "register_backward_hook"], [195, 1, 1, "", "register_buffer"], [195, 1, 1, "", "register_forward_hook"], [195, 1, 1, "", "register_forward_pre_hook"], [195, 1, 1, "", "register_full_backward_hook"], [195, 1, 1, "", "register_full_backward_pre_hook"], [195, 1, 1, "", "register_load_state_dict_post_hook"], [195, 1, 1, "", "register_load_state_dict_pre_hook"], [195, 1, 1, "", "register_module"], [195, 1, 1, "", "register_parameter"], [195, 1, 1, "", "register_state_dict_post_hook"], [195, 1, 1, "", "register_state_dict_pre_hook"], [195, 1, 1, "", "requires_grad_"], [195, 1, 1, "", "set_extra_state"], [195, 1, 1, "", "set_submodule"], [195, 1, 1, "", "share_memory"], [195, 1, 1, "", "state_dict"], [195, 1, 1, "", "to"], [195, 1, 1, "", "to_empty"], [195, 1, 1, "", "train"], [195, 1, 1, "", "transform_action_spec"], [195, 1, 1, "", "transform_done_spec"], [195, 1, 1, "", "transform_env_batch_size"], [195, 1, 1, "", "transform_env_device"], [195, 1, 1, "", "transform_input_spec"], [195, 1, 1, "", "transform_observation_spec"], [195, 1, 1, "", "transform_output_spec"], [195, 1, 1, "", "transform_reward_spec"], [195, 1, 1, "", "transform_state_spec"], [195, 1, 1, "", "type"], [195, 1, 1, "", "xpu"], [195, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.RetrieveLogProb": [[196, 1, 1, "", "add_module"], [196, 1, 1, "", "apply"], [196, 1, 1, "", "bfloat16"], [196, 1, 1, "", "buffers"], [196, 1, 1, "", "children"], [196, 1, 1, "", "close"], [196, 2, 1, "", "collector"], [196, 1, 1, "", "compile"], [196, 2, 1, "", "container"], [196, 1, 1, "", "cpu"], [196, 1, 1, "", "cuda"], [196, 1, 1, "", "double"], [196, 1, 1, "", "eval"], [196, 1, 1, "", "extra_repr"], [196, 1, 1, "", "float"], [196, 1, 1, "", "forward"], [196, 1, 1, "", "get_buffer"], [196, 1, 1, "", "get_extra_state"], [196, 1, 1, "", "get_parameter"], [196, 1, 1, "", "get_submodule"], [196, 1, 1, "", "half"], [196, 1, 1, "", "init"], [196, 1, 1, "", "inv"], [196, 1, 1, "", "ipu"], [196, 1, 1, "", "load_state_dict"], [196, 1, 1, "", "modules"], [196, 1, 1, "", "mtia"], [196, 1, 1, "", "named_buffers"], [196, 1, 1, "", "named_children"], [196, 1, 1, "", "named_modules"], [196, 1, 1, "", "named_parameters"], [196, 1, 1, "", "parameters"], [196, 2, 1, "", "parent"], [196, 1, 1, "", "register_backward_hook"], [196, 1, 1, "", "register_buffer"], [196, 1, 1, "", "register_forward_hook"], [196, 1, 1, "", "register_forward_pre_hook"], [196, 1, 1, "", "register_full_backward_hook"], [196, 1, 1, "", "register_full_backward_pre_hook"], [196, 1, 1, "", "register_load_state_dict_post_hook"], [196, 1, 1, "", "register_load_state_dict_pre_hook"], [196, 1, 1, "", "register_module"], [196, 1, 1, "", "register_parameter"], [196, 1, 1, "", "register_state_dict_post_hook"], [196, 1, 1, "", "register_state_dict_pre_hook"], [196, 1, 1, "", "requires_grad_"], [196, 1, 1, "", "set_extra_state"], [196, 1, 1, "", "set_submodule"], [196, 1, 1, "", "share_memory"], [196, 1, 1, "", "state_dict"], [196, 1, 1, "", "to"], [196, 1, 1, "", "to_empty"], [196, 1, 1, "", "train"], [196, 1, 1, "", "transform_action_spec"], [196, 1, 1, "", "transform_done_spec"], [196, 1, 1, "", "transform_env_batch_size"], [196, 1, 1, "", "transform_env_device"], [196, 1, 1, "", "transform_input_spec"], [196, 1, 1, "", "transform_observation_spec"], [196, 1, 1, "", "transform_output_spec"], [196, 1, 1, "", "transform_reward_spec"], [196, 1, 1, "", "transform_state_spec"], [196, 1, 1, "", "type"], [196, 1, 1, "", "xpu"], [196, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.SimpleToolTransform": [[197, 1, 1, "", "add_module"], [197, 1, 1, "", "apply"], [197, 1, 1, "", "bfloat16"], [197, 1, 1, "", "buffers"], [197, 1, 1, "", "children"], [197, 1, 1, "", "close"], [197, 2, 1, "", "collector"], [197, 1, 1, "", "compile"], [197, 2, 1, "", "container"], [197, 1, 1, "", "cpu"], [197, 1, 1, "", "cuda"], [197, 1, 1, "", "double"], [197, 1, 1, "", "eval"], [197, 1, 1, "", "extra_repr"], [197, 1, 1, "", "float"], [197, 1, 1, "", "forward"], [197, 1, 1, "", "get_buffer"], [197, 1, 1, "", "get_extra_state"], [197, 1, 1, "", "get_parameter"], [197, 1, 1, "", "get_submodule"], [197, 1, 1, "", "half"], [197, 1, 1, "", "init"], [197, 1, 1, "", "inv"], [197, 1, 1, "", "ipu"], [197, 1, 1, "", "load_state_dict"], [197, 1, 1, "", "modules"], [197, 1, 1, "", "mtia"], [197, 1, 1, "", "named_buffers"], [197, 1, 1, "", "named_children"], [197, 1, 1, "", "named_modules"], [197, 1, 1, "", "named_parameters"], [197, 1, 1, "", "parameters"], [197, 2, 1, "", "parent"], [197, 1, 1, "", "register_backward_hook"], [197, 1, 1, "", "register_buffer"], [197, 1, 1, "", "register_forward_hook"], [197, 1, 1, "", "register_forward_pre_hook"], [197, 1, 1, "", "register_full_backward_hook"], [197, 1, 1, "", "register_full_backward_pre_hook"], [197, 1, 1, "", "register_load_state_dict_post_hook"], [197, 1, 1, "", "register_load_state_dict_pre_hook"], [197, 1, 1, "", "register_module"], [197, 1, 1, "", "register_parameter"], [197, 1, 1, "", "register_state_dict_post_hook"], [197, 1, 1, "", "register_state_dict_pre_hook"], [197, 1, 1, "", "requires_grad_"], [197, 1, 1, "", "set_extra_state"], [197, 1, 1, "", "set_submodule"], [197, 1, 1, "", "share_memory"], [197, 1, 1, "", "state_dict"], [197, 1, 1, "", "to"], [197, 1, 1, "", "to_empty"], [197, 1, 1, "", "train"], [197, 1, 1, "", "transform_action_spec"], [197, 1, 1, "", "transform_done_spec"], [197, 1, 1, "", "transform_env_batch_size"], [197, 1, 1, "", "transform_env_device"], [197, 1, 1, "", "transform_input_spec"], [197, 1, 1, "", "transform_observation_spec"], [197, 1, 1, "", "transform_output_spec"], [197, 1, 1, "", "transform_reward_spec"], [197, 1, 1, "", "transform_state_spec"], [197, 1, 1, "", "type"], [197, 1, 1, "", "xpu"], [197, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.TemplateTransform": [[198, 1, 1, "", "add_module"], [198, 1, 1, "", "apply"], [198, 1, 1, "", "bfloat16"], [198, 1, 1, "", "buffers"], [198, 1, 1, "", "children"], [198, 1, 1, "", "close"], [198, 2, 1, "", "collector"], [198, 1, 1, "", "compile"], [198, 2, 1, "", "container"], [198, 1, 1, "", "cpu"], [198, 1, 1, "", "cuda"], [198, 1, 1, "", "double"], [198, 1, 1, "", "eval"], [198, 1, 1, "", "extra_repr"], [198, 1, 1, "", "float"], [198, 1, 1, "", "forward"], [198, 1, 1, "", "get_buffer"], [198, 1, 1, "", "get_extra_state"], [198, 1, 1, "", "get_parameter"], [198, 1, 1, "", "get_submodule"], [198, 1, 1, "", "half"], [198, 1, 1, "", "init"], [198, 1, 1, "", "inv"], [198, 1, 1, "", "ipu"], [198, 1, 1, "", "load_state_dict"], [198, 1, 1, "", "modules"], [198, 1, 1, "", "mtia"], [198, 1, 1, "", "named_buffers"], [198, 1, 1, "", "named_children"], [198, 1, 1, "", "named_modules"], [198, 1, 1, "", "named_parameters"], [198, 1, 1, "", "parameters"], [198, 2, 1, "", "parent"], [198, 1, 1, "", "register_backward_hook"], [198, 1, 1, "", "register_buffer"], [198, 1, 1, "", "register_forward_hook"], [198, 1, 1, "", "register_forward_pre_hook"], [198, 1, 1, "", "register_full_backward_hook"], [198, 1, 1, "", "register_full_backward_pre_hook"], [198, 1, 1, "", "register_load_state_dict_post_hook"], [198, 1, 1, "", "register_load_state_dict_pre_hook"], [198, 1, 1, "", "register_module"], [198, 1, 1, "", "register_parameter"], [198, 1, 1, "", "register_state_dict_post_hook"], [198, 1, 1, "", "register_state_dict_pre_hook"], [198, 1, 1, "", "requires_grad_"], [198, 1, 1, "", "set_extra_state"], [198, 1, 1, "", "set_submodule"], [198, 1, 1, "", "share_memory"], [198, 1, 1, "", "state_dict"], [198, 1, 1, "", "to"], [198, 1, 1, "", "to_empty"], [198, 1, 1, "", "train"], [198, 1, 1, "", "transform_action_spec"], [198, 1, 1, "", "transform_done_spec"], [198, 1, 1, "", "transform_env_batch_size"], [198, 1, 1, "", "transform_env_device"], [198, 1, 1, "", "transform_input_spec"], [198, 1, 1, "", "transform_observation_spec"], [198, 1, 1, "", "transform_output_spec"], [198, 1, 1, "", "transform_reward_spec"], [198, 1, 1, "", "transform_state_spec"], [198, 1, 1, "", "type"], [198, 1, 1, "", "xpu"], [198, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.Tokenizer": [[199, 1, 1, "", "add_module"], [199, 1, 1, "", "apply"], [199, 1, 1, "", "bfloat16"], [199, 1, 1, "", "buffers"], [199, 1, 1, "", "children"], [199, 1, 1, "", "close"], [199, 2, 1, "", "collector"], [199, 1, 1, "", "compile"], [199, 2, 1, "", "container"], [199, 1, 1, "", "cpu"], [199, 1, 1, "", "cuda"], [199, 1, 1, "", "double"], [199, 1, 1, "", "eval"], [199, 1, 1, "", "extra_repr"], [199, 1, 1, "", "float"], [199, 1, 1, "", "forward"], [199, 1, 1, "", "get_buffer"], [199, 1, 1, "", "get_extra_state"], [199, 1, 1, "", "get_parameter"], [199, 1, 1, "", "get_submodule"], [199, 1, 1, "", "half"], [199, 1, 1, "", "init"], [199, 1, 1, "", "inv"], [199, 1, 1, "", "ipu"], [199, 1, 1, "", "load_state_dict"], [199, 1, 1, "", "modules"], [199, 1, 1, "", "mtia"], [199, 1, 1, "", "named_buffers"], [199, 1, 1, "", "named_children"], [199, 1, 1, "", "named_modules"], [199, 1, 1, "", "named_parameters"], [199, 1, 1, "", "parameters"], [199, 2, 1, "", "parent"], [199, 1, 1, "", "register_backward_hook"], [199, 1, 1, "", "register_buffer"], [199, 1, 1, "", "register_forward_hook"], [199, 1, 1, "", "register_forward_pre_hook"], [199, 1, 1, "", "register_full_backward_hook"], [199, 1, 1, "", "register_full_backward_pre_hook"], [199, 1, 1, "", "register_load_state_dict_post_hook"], [199, 1, 1, "", "register_load_state_dict_pre_hook"], [199, 1, 1, "", "register_module"], [199, 1, 1, "", "register_parameter"], [199, 1, 1, "", "register_state_dict_post_hook"], [199, 1, 1, "", "register_state_dict_pre_hook"], [199, 1, 1, "", "requires_grad_"], [199, 1, 1, "", "set_extra_state"], [199, 1, 1, "", "set_submodule"], [199, 1, 1, "", "share_memory"], [199, 1, 1, "", "state_dict"], [199, 1, 1, "", "to"], [199, 1, 1, "", "to_empty"], [199, 1, 1, "", "train"], [199, 1, 1, "", "transform_action_spec"], [199, 1, 1, "", "transform_done_spec"], [199, 1, 1, "", "transform_env_batch_size"], [199, 1, 1, "", "transform_env_device"], [199, 1, 1, "", "transform_input_spec"], [199, 1, 1, "", "transform_observation_spec"], [199, 1, 1, "", "transform_output_spec"], [199, 1, 1, "", "transform_reward_spec"], [199, 1, 1, "", "transform_state_spec"], [199, 1, 1, "", "type"], [199, 1, 1, "", "xpu"], [199, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.ToolRegistry": [[201, 1, 1, "", "get"], [201, 1, 1, "", "register"]], "torchrl.envs.model_based.dreamer": [[207, 3, 1, "", "DreamerDecoder"], [208, 3, 1, "", "DreamerEnv"]], "torchrl.envs.transforms": [[214, 0, 1, "", "ActionDiscretizer"], [215, 0, 1, "", "ActionMask"], [216, 0, 1, "", "AutoResetEnv"], [217, 0, 1, "", "AutoResetTransform"], [218, 0, 1, "", "BatchSizeTransform"], [219, 0, 1, "", "BinarizeReward"], [220, 0, 1, "", "BurnInTransform"], [221, 0, 1, "", "CatFrames"], [222, 0, 1, "", "CatTensors"], [223, 0, 1, "", "CenterCrop"], [224, 0, 1, "", "ClipTransform"], [225, 0, 1, "", "Compose"], [226, 0, 1, "", "ConditionalPolicySwitch"], [227, 0, 1, "", "ConditionalSkip"], [228, 0, 1, "", "Crop"], [229, 0, 1, "", "DTypeCastTransform"], [230, 0, 1, "", "DeviceCastTransform"], [231, 0, 1, "", "DiscreteActionProjection"], [232, 0, 1, "", "DoubleToFloat"], [233, 0, 1, "", "EndOfLifeTransform"], [234, 0, 1, "", "ExcludeTransform"], [235, 0, 1, "", "FiniteTensorDictCheck"], [236, 0, 1, "", "FlattenObservation"], [237, 0, 1, "", "FrameSkipTransform"], [238, 0, 1, "", "GrayScale"], [239, 0, 1, "", "Hash"], [240, 0, 1, "", "InitTracker"], [241, 0, 1, "", "KLRewardTransform"], [242, 0, 1, "", "LineariseRewards"], [243, 0, 1, "", "ModuleTransform"], [244, 0, 1, "", "MultiAction"], [245, 0, 1, "", "NoopResetEnv"], [246, 0, 1, "", "ObservationNorm"], [247, 0, 1, "", "ObservationTransform"], [248, 0, 1, "", "PermuteTransform"], [249, 0, 1, "", "PinMemoryTransform"], [250, 0, 1, "", "R3MTransform"], [251, 0, 1, "", "RandomCropTensorDict"], [252, 0, 1, "", "RemoveEmptySpecs"], [253, 0, 1, "", "RenameTransform"], [254, 0, 1, "", "Resize"], [255, 0, 1, "", "Reward2GoTransform"], [256, 0, 1, "", "RewardClipping"], [257, 0, 1, "", "RewardScaling"], [258, 0, 1, "", "RewardSum"], [259, 0, 1, "", "SelectTransform"], [260, 0, 1, "", "SignTransform"], [261, 0, 1, "", "SqueezeTransform"], [262, 0, 1, "", "Stack"], [263, 0, 1, "", "StepCounter"], [264, 0, 1, "", "TargetReturn"], [265, 0, 1, "", "TensorDictPrimer"], [266, 0, 1, "", "TimeMaxPool"], [267, 0, 1, "", "Timer"], [268, 0, 1, "", "ToTensorImage"], [269, 0, 1, "", "Tokenizer"], [270, 0, 1, "", "TrajCounter"], [271, 0, 1, "", "Transform"], [272, 0, 1, "", "TransformedEnv"], [273, 0, 1, "", "UnaryTransform"], [274, 0, 1, "", "UnsqueezeTransform"], [275, 0, 1, "", "VC1Transform"], [276, 0, 1, "", "VIPRewardTransform"], [277, 0, 1, "", "VIPTransform"], [278, 0, 1, "", "VecGymEnvTransform"], [279, 0, 1, "", "VecNorm"], [280, 0, 1, "", "VecNormV2"], [281, 0, 1, "", "gSDENoise"]], "torchrl.envs.transforms.ActionDiscretizer": [[214, 0, 1, "", "SamplingStrategy"], [214, 1, 1, "", "inv"], [214, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.ActionMask": [[215, 1, 1, "", "forward"]], "torchrl.envs.transforms.AutoResetEnv": [[216, 1, 1, "", "insert_transform"]], "torchrl.envs.transforms.AutoResetTransform": [[217, 1, 1, "", "forward"]], "torchrl.envs.transforms.BatchSizeTransform": [[218, 1, 1, "", "forward"], [218, 1, 1, "", "transform_env_batch_size"], [218, 1, 1, "", "transform_input_spec"], [218, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.BinarizeReward": [[219, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.BurnInTransform": [[220, 1, 1, "", "forward"]], "torchrl.envs.transforms.CatFrames": [[221, 1, 1, "", "forward"], [221, 1, 1, "", "make_rb_transform_and_sampler"], [221, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CatTensors": [[222, 1, 1, "", "forward"], [222, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CenterCrop": [[223, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ClipTransform": [[224, 1, 1, "", "transform_observation_spec"], [224, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.Compose": [[225, 1, 1, "", "append"], [225, 1, 1, "", "close"], [225, 1, 1, "", "forward"], [225, 1, 1, "", "init"], [225, 1, 1, "", "insert"], [225, 1, 1, "", "pop"], [225, 1, 1, "", "to"], [225, 1, 1, "", "transform_action_spec"], [225, 1, 1, "", "transform_env_batch_size"], [225, 1, 1, "", "transform_env_device"], [225, 1, 1, "", "transform_input_spec"], [225, 1, 1, "", "transform_observation_spec"], [225, 1, 1, "", "transform_output_spec"], [225, 1, 1, "", "transform_reward_spec"], [225, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.ConditionalPolicySwitch": [[226, 1, 1, "", "forward"]], "torchrl.envs.transforms.ConditionalSkip": [[227, 1, 1, "", "forward"]], "torchrl.envs.transforms.Crop": [[228, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.DTypeCastTransform": [[229, 1, 1, "", "forward"], [229, 1, 1, "", "transform_input_spec"], [229, 1, 1, "", "transform_observation_spec"], [229, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.DeviceCastTransform": [[230, 1, 1, "", "forward"], [230, 1, 1, "", "transform_action_spec"], [230, 1, 1, "", "transform_done_spec"], [230, 1, 1, "", "transform_env_device"], [230, 1, 1, "", "transform_input_spec"], [230, 1, 1, "", "transform_observation_spec"], [230, 1, 1, "", "transform_output_spec"], [230, 1, 1, "", "transform_reward_spec"], [230, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.DiscreteActionProjection": [[231, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.EndOfLifeTransform": [[233, 1, 1, "", "forward"], [233, 1, 1, "", "register_keys"], [233, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ExcludeTransform": [[234, 1, 1, "", "forward"], [234, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.FiniteTensorDictCheck": [[235, 1, 1, "", "forward"]], "torchrl.envs.transforms.FlattenObservation": [[236, 1, 1, "", "forward"], [236, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.FrameSkipTransform": [[237, 1, 1, "", "forward"]], "torchrl.envs.transforms.GrayScale": [[238, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Hash": [[239, 1, 1, "", "get_input_from_hash"], [239, 1, 1, "", "reproducible_hash"], [239, 1, 1, "", "state_dict"]], "torchrl.envs.transforms.InitTracker": [[240, 1, 1, "", "forward"], [240, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.KLRewardTransform": [[241, 1, 1, "", "forward"], [241, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.LineariseRewards": [[242, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.ModuleTransform": [[243, 1, 1, "", "forward"], [243, 1, 1, "", "transform_action_spec"], [243, 1, 1, "", "transform_done_spec"], [243, 1, 1, "", "transform_observation_spec"], [243, 1, 1, "", "transform_reward_spec"], [243, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.MultiAction": [[244, 1, 1, "", "transform_input_spec"], [244, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.ObservationNorm": [[246, 1, 1, "", "init_stats"], [246, 1, 1, "", "transform_action_spec"], [246, 1, 1, "", "transform_observation_spec"], [246, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.PermuteTransform": [[248, 1, 1, "", "transform_input_spec"], [248, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.PinMemoryTransform": [[249, 1, 1, "", "forward"]], "torchrl.envs.transforms.R3MTransform": [[250, 1, 1, "", "to"]], "torchrl.envs.transforms.RandomCropTensorDict": [[251, 1, 1, "", "forward"]], "torchrl.envs.transforms.RemoveEmptySpecs": [[252, 1, 1, "", "forward"], [252, 1, 1, "", "transform_input_spec"], [252, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.RenameTransform": [[253, 1, 1, "", "forward"], [253, 1, 1, "", "transform_input_spec"], [253, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.Resize": [[254, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Reward2GoTransform": [[255, 1, 1, "", "forward"]], "torchrl.envs.transforms.RewardClipping": [[256, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardScaling": [[257, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardSum": [[258, 1, 1, "", "forward"], [258, 1, 1, "", "transform_input_spec"], [258, 1, 1, "", "transform_observation_spec"], [258, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.SelectTransform": [[259, 1, 1, "", "forward"], [259, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.SignTransform": [[260, 1, 1, "", "transform_observation_spec"], [260, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.Stack": [[262, 1, 1, "", "forward"], [262, 1, 1, "", "transform_done_spec"], [262, 1, 1, "", "transform_input_spec"], [262, 1, 1, "", "transform_observation_spec"], [262, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.StepCounter": [[263, 1, 1, "", "forward"], [263, 1, 1, "", "transform_input_spec"], [263, 1, 1, "", "transform_observation_spec"], [263, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.TargetReturn": [[264, 1, 1, "", "forward"], [264, 1, 1, "", "transform_input_spec"], [264, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TensorDictPrimer": [[265, 1, 1, "", "forward"], [265, 1, 1, "", "to"], [265, 1, 1, "", "transform_input_spec"], [265, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TimeMaxPool": [[266, 1, 1, "", "forward"], [266, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Timer": [[267, 1, 1, "", "forward"], [267, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ToTensorImage": [[268, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Tokenizer": [[269, 1, 1, "", "forward"], [269, 1, 1, "", "transform_done_spec"], [269, 1, 1, "", "transform_input_spec"], [269, 1, 1, "", "transform_observation_spec"], [269, 1, 1, "", "transform_output_spec"], [269, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.TrajCounter": [[270, 1, 1, "", "forward"], [270, 1, 1, "", "load_state_dict"], [270, 1, 1, "", "state_dict"], [270, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Transform": [[271, 1, 1, "", "clone"], [271, 1, 1, "", "close"], [271, 2, 1, "", "collector"], [271, 2, 1, "", "container"], [271, 1, 1, "", "forward"], [271, 1, 1, "", "init"], [271, 1, 1, "", "inv"], [271, 2, 1, "", "parent"], [271, 1, 1, "", "reset_parent"], [271, 1, 1, "", "set_container"], [271, 1, 1, "", "to"], [271, 1, 1, "", "transform_action_spec"], [271, 1, 1, "", "transform_done_spec"], [271, 1, 1, "", "transform_env_batch_size"], [271, 1, 1, "", "transform_env_device"], [271, 1, 1, "", "transform_input_spec"], [271, 1, 1, "", "transform_observation_spec"], [271, 1, 1, "", "transform_output_spec"], [271, 1, 1, "", "transform_reward_spec"], [271, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.TransformedEnv": [[272, 1, 1, "", "add_truncated_keys"], [272, 1, 1, "", "append_transform"], [272, 2, 1, "", "batch_locked"], [272, 2, 1, "", "batch_size"], [272, 1, 1, "", "empty_cache"], [272, 1, 1, "", "eval"], [272, 2, 1, "", "input_spec"], [272, 1, 1, "", "insert_transform"], [272, 1, 1, "", "load_state_dict"], [272, 2, 1, "", "output_spec"], [272, 1, 1, "", "rand_action"], [272, 1, 1, "", "set_missing_tolerance"], [272, 1, 1, "", "set_seed"], [272, 1, 1, "", "state_dict"], [272, 1, 1, "", "to"], [272, 1, 1, "", "train"]], "torchrl.envs.transforms.UnaryTransform": [[273, 1, 1, "", "transform_action_spec"], [273, 1, 1, "", "transform_done_spec"], [273, 1, 1, "", "transform_input_spec"], [273, 1, 1, "", "transform_observation_spec"], [273, 1, 1, "", "transform_output_spec"], [273, 1, 1, "", "transform_reward_spec"], [273, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.UnsqueezeTransform": [[274, 1, 1, "", "transform_action_spec"], [274, 1, 1, "", "transform_observation_spec"], [274, 1, 1, "", "transform_reward_spec"], [274, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.VC1Transform": [[275, 1, 1, "", "forward"], [275, 1, 1, "", "make_noload_model"], [275, 1, 1, "", "to"], [275, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VIPRewardTransform": [[276, 1, 1, "", "forward"], [276, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.VIPTransform": [[277, 1, 1, "", "to"]], "torchrl.envs.transforms.VecGymEnvTransform": [[278, 1, 1, "", "forward"], [278, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VecNorm": [[279, 1, 1, "", "build_td_for_shared_vecnorm"], [279, 1, 1, "", "forward"], [279, 1, 1, "", "freeze"], [279, 1, 1, "", "frozen_copy"], [279, 1, 1, "", "get_extra_state"], [279, 2, 1, "", "loc"], [279, 2, 1, "", "scale"], [279, 1, 1, "", "set_extra_state"], [279, 2, 1, "", "standard_normal"], [279, 1, 1, "", "to_observation_norm"], [279, 1, 1, "", "transform_observation_spec"], [279, 1, 1, "", "unfreeze"]], "torchrl.envs.transforms.VecNormV2": [[280, 1, 1, "", "clone"], [280, 1, 1, "id0", "freeze"], [280, 1, 1, "id1", "frozen_copy"], [280, 1, 1, "id2", "get_extra_state"], [280, 2, 1, "id3", "loc"], [280, 2, 1, "id4", "scale"], [280, 1, 1, "id5", "set_extra_state"], [280, 2, 1, "id6", "standard_normal"], [280, 1, 1, "", "to_observation_norm"], [280, 1, 1, "id7", "transform_observation_spec"], [280, 1, 1, "id8", "transform_output_spec"], [280, 1, 1, "id9", "transform_reward_spec"], [280, 1, 1, "id10", "unfreeze"]], "torchrl.implement_for": [[282, 1, 1, "", "get_class_that_defined_method"], [282, 1, 1, "", "import_module"], [282, 1, 1, "", "module_set"], [282, 1, 1, "", "reset"]], "torchrl.modules": [[283, 0, 1, "", "ActorCriticOperator"], [284, 0, 1, "", "ActorCriticWrapper"], [285, 0, 1, "", "ActorValueOperator"], [286, 0, 1, "", "AdditiveGaussianModule"], [287, 0, 1, "", "ConsistentDropoutModule"], [288, 0, 1, "", "ConvNet"], [289, 0, 1, "", "DTActor"], [290, 0, 1, "", "DdpgCnnActor"], [291, 0, 1, "", "DdpgCnnQNet"], [292, 0, 1, "", "DdpgMlpActor"], [293, 0, 1, "", "DdpgMlpQNet"], [294, 0, 1, "", "DecisionTransformer"], [295, 0, 1, "", "Delta"], [296, 0, 1, "", "DistributionalDQNnet"], [297, 0, 1, "", "DistributionalQValueActor"], [298, 0, 1, "", "DistributionalQValueModule"], [299, 0, 1, "", "DreamerActor"], [300, 0, 1, "", "DuelingCnnDQNet"], [301, 0, 1, "", "EGreedyModule"], [302, 0, 1, "", "GRUModule"], [303, 0, 1, "", "IndependentNormal"], [304, 0, 1, "", "LSTMModule"], [305, 0, 1, "", "MLP"], [306, 0, 1, "", "MaskedCategorical"], [307, 0, 1, "", "NormalParamExtractor"], [308, 0, 1, "", "ObsDecoder"], [309, 0, 1, "", "ObsEncoder"], [310, 0, 1, "", "OneHotCategorical"], [311, 0, 1, "", "OnlineDTActor"], [312, 0, 1, "", "OrnsteinUhlenbeckProcessModule"], [313, 0, 1, "", "QValueActor"], [314, 0, 1, "", "QValueModule"], [315, 0, 1, "", "RSSMPosterior"], [316, 0, 1, "", "RSSMPrior"], [317, 0, 1, "", "RSSMRollout"], [318, 0, 1, "", "ReparamGradientStrategy"], [319, 0, 1, "", "TanhDelta"], [320, 0, 1, "", "TanhNormal"], [321, 0, 1, "", "TruncatedNormal"], [322, 0, 1, "", "ValueOperator"], [323, 0, 1, "", "WorldModelWrapper"], [339, 0, 1, "", "set_exploration_modules_spec_from_env"]], "torchrl.modules.ActorCriticOperator": [[283, 1, 1, "", "get_critic_operator"], [283, 1, 1, "", "get_policy_head"], [283, 1, 1, "", "get_value_head"], [283, 1, 1, "", "get_value_operator"]], "torchrl.modules.ActorCriticWrapper": [[284, 1, 1, "", "get_policy_head"], [284, 1, 1, "", "get_policy_operator"], [284, 1, 1, "", "get_value_head"], [284, 1, 1, "", "get_value_operator"]], "torchrl.modules.ActorValueOperator": [[285, 1, 1, "", "get_policy_head"], [285, 1, 1, "", "get_policy_operator"], [285, 1, 1, "", "get_value_head"], [285, 1, 1, "", "get_value_operator"]], "torchrl.modules.AdditiveGaussianModule": [[286, 1, 1, "", "forward"], [286, 1, 1, "", "step"]], "torchrl.modules.ConsistentDropoutModule": [[287, 1, 1, "", "forward"], [287, 1, 1, "", "make_tensordict_primer"]], "torchrl.modules.ConvNet": [[288, 1, 1, "", "default_atari_dqn"], [288, 1, 1, "", "forward"]], "torchrl.modules.DTActor": [[289, 1, 1, "", "default_config"], [289, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnActor": [[290, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnQNet": [[291, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpActor": [[292, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpQNet": [[293, 1, 1, "", "forward"]], "torchrl.modules.DecisionTransformer": [[294, 0, 1, "", "DTConfig"], [294, 1, 1, "", "forward"]], "torchrl.modules.Delta": [[295, 1, 1, "", "expand"], [295, 1, 1, "", "log_prob"], [295, 2, 1, "", "mean"], [295, 2, 1, "", "mode"], [295, 1, 1, "", "rsample"], [295, 1, 1, "", "sample"]], "torchrl.modules.DistributionalDQNnet": [[296, 1, 1, "", "forward"]], "torchrl.modules.DistributionalQValueModule": [[298, 1, 1, "", "forward"]], "torchrl.modules.DreamerActor": [[299, 1, 1, "", "forward"]], "torchrl.modules.DuelingCnnDQNet": [[300, 1, 1, "", "forward"]], "torchrl.modules.EGreedyModule": [[301, 1, 1, "", "forward"], [301, 1, 1, "", "step"]], "torchrl.modules.GRUModule": [[302, 1, 1, "", "forward"], [302, 1, 1, "", "make_cudnn_based"], [302, 1, 1, "", "make_python_based"], [302, 1, 1, "id0", "make_tensordict_primer"], [302, 1, 1, "", "set_recurrent_mode"]], "torchrl.modules.IndependentNormal": [[303, 2, 1, "", "mode"]], "torchrl.modules.LSTMModule": [[304, 1, 1, "", "forward"], [304, 1, 1, "", "make_cudnn_based"], [304, 1, 1, "", "make_python_based"], [304, 1, 1, "id0", "make_tensordict_primer"], [304, 1, 1, "", "set_recurrent_mode"]], "torchrl.modules.MLP": [[305, 1, 1, "", "forward"]], "torchrl.modules.MaskedCategorical": [[306, 1, 1, "", "entropy"], [306, 1, 1, "", "log_prob"], [306, 2, 1, "", "padding_value"], [306, 1, 1, "", "sample"]], "torchrl.modules.NormalParamExtractor": [[307, 1, 1, "", "forward"]], "torchrl.modules.ObsDecoder": [[308, 1, 1, "", "forward"]], "torchrl.modules.ObsEncoder": [[309, 1, 1, "", "forward"]], "torchrl.modules.OneHotCategorical": [[310, 1, 1, "", "entropy"], [310, 1, 1, "", "log_prob"], [310, 2, 1, "", "mode"], [310, 1, 1, "", "rsample"], [310, 1, 1, "", "sample"]], "torchrl.modules.OnlineDTActor": [[311, 1, 1, "", "default_config"], [311, 1, 1, "", "forward"]], "torchrl.modules.OrnsteinUhlenbeckProcessModule": [[312, 1, 1, "", "forward"], [312, 1, 1, "", "step"]], "torchrl.modules.QValueModule": [[314, 1, 1, "", "forward"]], "torchrl.modules.RSSMPosterior": [[315, 1, 1, "", "forward"]], "torchrl.modules.RSSMPrior": [[316, 1, 1, "", "forward"]], "torchrl.modules.RSSMRollout": [[317, 1, 1, "", "forward"]], "torchrl.modules.TanhDelta": [[319, 2, 1, "", "mean"], [319, 2, 1, "", "mode"]], "torchrl.modules.TanhNormal": [[320, 1, 1, "", "get_mode"], [320, 2, 1, "", "mean"], [320, 2, 1, "", "mode"], [320, 2, 1, "", "support"]], "torchrl.modules.TruncatedNormal": [[321, 1, 1, "", "log_prob"], [321, 2, 1, "", "mode"]], "torchrl.modules.WorldModelWrapper": [[323, 1, 1, "", "get_reward_operator"], [323, 1, 1, "", "get_transition_model_operator"]], "torchrl.modules.llm": [[324, 0, 1, "", "AsyncVLLM"], [325, 0, 1, "", "ChatHistory"], [326, 0, 1, "", "LLMWrapperBase"], [327, 0, 1, "", "LogProbs"], [328, 0, 1, "", "Masks"], [329, 0, 1, "", "RemoteTransformersWrapper"], [330, 0, 1, "", "Text"], [331, 0, 1, "", "Tokens"], [332, 0, 1, "", "TransformersWrapper"], [333, 0, 1, "", "make_async_vllm_engine"], [334, 0, 1, "", "make_vllm_worker"], [335, 0, 1, "", "stateless_init_process_group"], [336, 0, 1, "", "stateless_init_process_group_async"], [337, 0, 1, "", "vLLMWrapper"]], "torchrl.modules.llm.AsyncVLLM": [[324, 1, 1, "", "collective_rpc"], [324, 1, 1, "", "create_load_balancer"], [324, 1, 1, "", "from_pretrained"], [324, 1, 1, "", "generate"], [324, 1, 1, "", "get_cache_usage"], [324, 1, 1, "", "get_master_address"], [324, 1, 1, "", "get_master_port"], [324, 1, 1, "", "get_model_metadata"], [324, 1, 1, "", "get_num_unfinished_requests"], [324, 1, 1, "", "get_random_actor_index"], [324, 1, 1, "", "get_tp_size"], [324, 1, 1, "", "init_weight_update_group"], [324, 1, 1, "", "launch"], [324, 1, 1, "", "shutdown"], [324, 1, 1, "", "update_weights"]], "torchrl.modules.llm.ChatHistory": [[325, 1, 1, "", "cat"], [325, 1, 1, "", "default_spec"], [325, 2, 1, "", "device"], [325, 1, 1, "", "dumps"], [325, 1, 1, "", "fields"], [325, 1, 1, "", "from_any"], [325, 1, 1, "", "from_dataclass"], [325, 1, 1, "", "from_h5"], [325, 1, 1, "", "from_modules"], [325, 1, 1, "", "from_namedtuple"], [325, 1, 1, "", "from_pytree"], [325, 1, 1, "", "from_remote_init"], [325, 1, 1, "", "from_struct_array"], [325, 1, 1, "", "from_tensordict"], [325, 1, 1, "", "from_tuple"], [325, 1, 1, "", "fromkeys"], [325, 1, 1, "", "get"], [325, 1, 1, "", "lazy_stack"], [325, 1, 1, "", "load"], [325, 1, 1, "", "load_"], [325, 1, 1, "", "load_memmap"], [325, 1, 1, "", "load_state_dict"], [325, 1, 1, "", "maybe_dense_stack"], [325, 1, 1, "", "memmap"], [325, 1, 1, "", "memmap_"], [325, 1, 1, "", "memmap_like"], [325, 1, 1, "", "memmap_refresh_"], [325, 1, 1, "", "save"], [325, 1, 1, "", "set"], [325, 1, 1, "", "stack"], [325, 1, 1, "", "state_dict"], [325, 1, 1, "", "to_tensordict"], [325, 1, 1, "", "to_text"], [325, 1, 1, "", "to_tokens"], [325, 1, 1, "", "unbind"]], "torchrl.modules.llm.LLMWrapperBase": [[326, 1, 1, "", "add_module"], [326, 1, 1, "", "apply"], [326, 2, 1, "", "batching"], [326, 1, 1, "", "bfloat16"], [326, 1, 1, "", "buffers"], [326, 1, 1, "", "children"], [326, 1, 1, "", "cleanup_batching"], [326, 2, 1, "", "collector"], [326, 1, 1, "", "compile"], [326, 1, 1, "", "cpu"], [326, 1, 1, "", "cuda"], [326, 1, 1, "", "double"], [326, 1, 1, "", "eval"], [326, 1, 1, "", "extra_repr"], [326, 1, 1, "", "float"], [326, 1, 1, "", "forward"], [326, 1, 1, "", "get_batching_state"], [326, 1, 1, "", "get_buffer"], [326, 1, 1, "", "get_dist"], [326, 1, 1, "", "get_extra_state"], [326, 1, 1, "", "get_new_version"], [326, 1, 1, "", "get_parameter"], [326, 1, 1, "", "get_submodule"], [326, 1, 1, "", "half"], [326, 1, 1, "", "ipu"], [326, 1, 1, "", "is_tdmodule_compatible"], [326, 1, 1, "", "load_state_dict"], [326, 1, 1, "", "modules"], [326, 1, 1, "", "mtia"], [326, 1, 1, "", "named_buffers"], [326, 1, 1, "", "named_children"], [326, 1, 1, "", "named_modules"], [326, 1, 1, "", "named_parameters"], [326, 1, 1, "", "parameters"], [326, 1, 1, "", "register_backward_hook"], [326, 1, 1, "", "register_buffer"], [326, 1, 1, "", "register_collector"], [326, 1, 1, "", "register_forward_hook"], [326, 1, 1, "", "register_forward_pre_hook"], [326, 1, 1, "", "register_full_backward_hook"], [326, 1, 1, "", "register_full_backward_pre_hook"], [326, 1, 1, "", "register_load_state_dict_post_hook"], [326, 1, 1, "", "register_load_state_dict_pre_hook"], [326, 1, 1, "", "register_module"], [326, 1, 1, "", "register_parameter"], [326, 1, 1, "", "register_state_dict_post_hook"], [326, 1, 1, "", "register_state_dict_pre_hook"], [326, 1, 1, "", "requires_grad_"], [326, 1, 1, "", "reset_out_keys"], [326, 1, 1, "", "reset_parameters_recursive"], [326, 1, 1, "", "select_out_keys"], [326, 1, 1, "", "set_extra_state"], [326, 1, 1, "", "set_submodule"], [326, 1, 1, "", "share_memory"], [326, 1, 1, "", "state_dict"], [326, 1, 1, "", "to"], [326, 1, 1, "", "to_empty"], [326, 1, 1, "", "train"], [326, 1, 1, "", "type"], [326, 1, 1, "", "xpu"], [326, 1, 1, "", "zero_grad"]], "torchrl.modules.llm.LogProbs": [[327, 1, 1, "", "cat"], [327, 1, 1, "", "default_spec"], [327, 2, 1, "", "device"], [327, 1, 1, "", "dumps"], [327, 1, 1, "", "fields"], [327, 1, 1, "", "from_any"], [327, 1, 1, "", "from_dataclass"], [327, 1, 1, "", "from_h5"], [327, 1, 1, "", "from_modules"], [327, 1, 1, "", "from_namedtuple"], [327, 1, 1, "", "from_pytree"], [327, 1, 1, "", "from_remote_init"], [327, 1, 1, "", "from_struct_array"], [327, 1, 1, "", "from_tensordict"], [327, 1, 1, "", "from_tuple"], [327, 1, 1, "", "fromkeys"], [327, 1, 1, "", "get"], [327, 1, 1, "", "lazy_stack"], [327, 1, 1, "", "load"], [327, 1, 1, "", "load_"], [327, 1, 1, "", "load_memmap"], [327, 1, 1, "", "load_state_dict"], [327, 1, 1, "", "maybe_dense_stack"], [327, 1, 1, "", "memmap"], [327, 1, 1, "", "memmap_"], [327, 1, 1, "", "memmap_like"], [327, 1, 1, "", "memmap_refresh_"], [327, 1, 1, "", "save"], [327, 1, 1, "", "set"], [327, 1, 1, "", "stack"], [327, 1, 1, "", "state_dict"], [327, 1, 1, "", "to_tensordict"], [327, 1, 1, "", "unbind"]], "torchrl.modules.llm.Masks": [[328, 1, 1, "", "cat"], [328, 1, 1, "", "default_spec"], [328, 2, 1, "", "device"], [328, 1, 1, "", "dumps"], [328, 1, 1, "", "fields"], [328, 1, 1, "", "from_any"], [328, 1, 1, "", "from_dataclass"], [328, 1, 1, "", "from_h5"], [328, 1, 1, "", "from_modules"], [328, 1, 1, "", "from_namedtuple"], [328, 1, 1, "", "from_pytree"], [328, 1, 1, "", "from_remote_init"], [328, 1, 1, "", "from_struct_array"], [328, 1, 1, "", "from_tensordict"], [328, 1, 1, "", "from_tuple"], [328, 1, 1, "", "fromkeys"], [328, 1, 1, "", "get"], [328, 1, 1, "", "lazy_stack"], [328, 1, 1, "", "load"], [328, 1, 1, "", "load_"], [328, 1, 1, "", "load_memmap"], [328, 1, 1, "", "load_state_dict"], [328, 1, 1, "", "maybe_dense_stack"], [328, 1, 1, "", "memmap"], [328, 1, 1, "", "memmap_"], [328, 1, 1, "", "memmap_like"], [328, 1, 1, "", "memmap_refresh_"], [328, 1, 1, "", "save"], [328, 1, 1, "", "set"], [328, 1, 1, "", "stack"], [328, 1, 1, "", "state_dict"], [328, 1, 1, "", "to_tensordict"], [328, 1, 1, "", "unbind"]], "torchrl.modules.llm.RemoteTransformersWrapper": [[329, 2, 1, "", "batching"], [329, 1, 1, "", "cleanup_batching"], [329, 2, 1, "", "collector"], [329, 2, 1, "", "device"], [329, 2, 1, "", "dist_params_keys"], [329, 2, 1, "", "dist_sample_keys"], [329, 2, 1, "", "generate"], [329, 1, 1, "", "get_batching_state"], [329, 1, 1, "", "get_dist"], [329, 1, 1, "", "get_dist_with_prompt_mask"], [329, 1, 1, "", "get_new_version"], [329, 2, 1, "", "in_keys"], [329, 2, 1, "", "inplace"], [329, 2, 1, "", "layout"], [329, 1, 1, "", "log_prob"], [329, 2, 1, "", "log_prob_keys"], [329, 2, 1, "", "log_probs_key"], [329, 2, 1, "", "masks_key"], [329, 2, 1, "", "num_samples"], [329, 2, 1, "", "out_keys"], [329, 2, 1, "", "pad_output"], [329, 2, 1, "", "text_key"], [329, 2, 1, "", "tokens_key"]], "torchrl.modules.llm.Text": [[330, 1, 1, "", "cat"], [330, 1, 1, "", "default_spec"], [330, 2, 1, "", "device"], [330, 1, 1, "", "dumps"], [330, 1, 1, "", "fields"], [330, 1, 1, "", "from_any"], [330, 1, 1, "", "from_dataclass"], [330, 1, 1, "", "from_h5"], [330, 1, 1, "", "from_modules"], [330, 1, 1, "", "from_namedtuple"], [330, 1, 1, "", "from_pytree"], [330, 1, 1, "", "from_remote_init"], [330, 1, 1, "", "from_struct_array"], [330, 1, 1, "", "from_tensordict"], [330, 1, 1, "", "from_tuple"], [330, 1, 1, "", "fromkeys"], [330, 1, 1, "", "get"], [330, 1, 1, "", "lazy_stack"], [330, 1, 1, "", "load"], [330, 1, 1, "", "load_"], [330, 1, 1, "", "load_memmap"], [330, 1, 1, "", "load_state_dict"], [330, 1, 1, "", "maybe_dense_stack"], [330, 1, 1, "", "memmap"], [330, 1, 1, "", "memmap_"], [330, 1, 1, "", "memmap_like"], [330, 1, 1, "", "memmap_refresh_"], [330, 1, 1, "", "save"], [330, 1, 1, "", "set"], [330, 1, 1, "", "stack"], [330, 1, 1, "", "state_dict"], [330, 1, 1, "", "to_history"], [330, 1, 1, "", "to_tensordict"], [330, 1, 1, "", "to_tokens"], [330, 1, 1, "", "unbind"]], "torchrl.modules.llm.Tokens": [[331, 1, 1, "", "cat"], [331, 1, 1, "", "default_spec"], [331, 2, 1, "", "device"], [331, 1, 1, "", "dumps"], [331, 1, 1, "", "fields"], [331, 1, 1, "", "from_any"], [331, 1, 1, "", "from_dataclass"], [331, 1, 1, "", "from_h5"], [331, 1, 1, "", "from_modules"], [331, 1, 1, "", "from_namedtuple"], [331, 1, 1, "", "from_pytree"], [331, 1, 1, "", "from_remote_init"], [331, 1, 1, "", "from_struct_array"], [331, 1, 1, "", "from_tensordict"], [331, 1, 1, "", "from_tuple"], [331, 1, 1, "", "fromkeys"], [331, 1, 1, "", "get"], [331, 1, 1, "", "lazy_stack"], [331, 1, 1, "", "load"], [331, 1, 1, "", "load_"], [331, 1, 1, "", "load_memmap"], [331, 1, 1, "", "load_state_dict"], [331, 1, 1, "", "maybe_dense_stack"], [331, 1, 1, "", "memmap"], [331, 1, 1, "", "memmap_"], [331, 1, 1, "", "memmap_like"], [331, 1, 1, "", "memmap_refresh_"], [331, 1, 1, "", "save"], [331, 1, 1, "", "set"], [331, 1, 1, "", "stack"], [331, 1, 1, "", "state_dict"], [331, 1, 1, "", "to_history"], [331, 1, 1, "", "to_tensordict"], [331, 1, 1, "", "to_text"], [331, 1, 1, "", "unbind"]], "torchrl.modules.llm.TransformersWrapper": [[332, 1, 1, "", "add_module"], [332, 1, 1, "", "apply"], [332, 2, 1, "", "batching"], [332, 1, 1, "", "bfloat16"], [332, 1, 1, "", "buffers"], [332, 1, 1, "", "children"], [332, 1, 1, "", "cleanup_batching"], [332, 2, 1, "", "collector"], [332, 1, 1, "", "compile"], [332, 1, 1, "", "cpu"], [332, 1, 1, "", "cuda"], [332, 1, 1, "", "double"], [332, 1, 1, "", "eval"], [332, 1, 1, "", "extra_repr"], [332, 1, 1, "", "float"], [332, 1, 1, "", "forward"], [332, 1, 1, "", "get_batching_state"], [332, 1, 1, "", "get_buffer"], [332, 1, 1, "", "get_dist"], [332, 1, 1, "", "get_extra_state"], [332, 1, 1, "", "get_new_version"], [332, 1, 1, "", "get_parameter"], [332, 1, 1, "", "get_submodule"], [332, 1, 1, "", "half"], [332, 1, 1, "", "ipu"], [332, 1, 1, "", "is_tdmodule_compatible"], [332, 1, 1, "", "load_state_dict"], [332, 1, 1, "", "modules"], [332, 1, 1, "", "mtia"], [332, 1, 1, "", "named_buffers"], [332, 1, 1, "", "named_children"], [332, 1, 1, "", "named_modules"], [332, 1, 1, "", "named_parameters"], [332, 1, 1, "", "parameters"], [332, 1, 1, "", "register_backward_hook"], [332, 1, 1, "", "register_buffer"], [332, 1, 1, "", "register_collector"], [332, 1, 1, "", "register_forward_hook"], [332, 1, 1, "", "register_forward_pre_hook"], [332, 1, 1, "", "register_full_backward_hook"], [332, 1, 1, "", "register_full_backward_pre_hook"], [332, 1, 1, "", "register_load_state_dict_post_hook"], [332, 1, 1, "", "register_load_state_dict_pre_hook"], [332, 1, 1, "", "register_module"], [332, 1, 1, "", "register_parameter"], [332, 1, 1, "", "register_state_dict_post_hook"], [332, 1, 1, "", "register_state_dict_pre_hook"], [332, 1, 1, "", "repeat_interleave_causal"], [332, 1, 1, "", "requires_grad_"], [332, 1, 1, "", "reset_out_keys"], [332, 1, 1, "", "reset_parameters_recursive"], [332, 1, 1, "", "select_out_keys"], [332, 1, 1, "", "set_extra_state"], [332, 1, 1, "", "set_submodule"], [332, 1, 1, "", "share_memory"], [332, 1, 1, "", "state_dict"], [332, 1, 1, "", "to"], [332, 1, 1, "", "to_empty"], [332, 1, 1, "", "train"], [332, 1, 1, "", "type"], [332, 1, 1, "", "xpu"], [332, 1, 1, "", "zero_grad"]], "torchrl.modules.llm.vLLMWrapper": [[337, 1, 1, "", "add_module"], [337, 1, 1, "", "apply"], [337, 2, 1, "", "batching"], [337, 1, 1, "", "bfloat16"], [337, 1, 1, "", "buffers"], [337, 1, 1, "", "children"], [337, 1, 1, "", "cleanup_batching"], [337, 2, 1, "", "collector"], [337, 1, 1, "", "compile"], [337, 1, 1, "", "cpu"], [337, 1, 1, "", "cuda"], [337, 1, 1, "", "double"], [337, 1, 1, "", "eval"], [337, 1, 1, "", "extra_repr"], [337, 1, 1, "", "float"], [337, 1, 1, "", "forward"], [337, 1, 1, "", "get_batching_state"], [337, 1, 1, "", "get_buffer"], [337, 1, 1, "", "get_dist"], [337, 1, 1, "", "get_dist_with_prompt_mask"], [337, 1, 1, "", "get_extra_state"], [337, 1, 1, "", "get_new_version"], [337, 1, 1, "", "get_parameter"], [337, 1, 1, "", "get_submodule"], [337, 1, 1, "", "half"], [337, 1, 1, "", "ipu"], [337, 1, 1, "", "is_tdmodule_compatible"], [337, 1, 1, "", "load_state_dict"], [337, 1, 1, "", "modules"], [337, 1, 1, "", "mtia"], [337, 1, 1, "", "named_buffers"], [337, 1, 1, "", "named_children"], [337, 1, 1, "", "named_modules"], [337, 1, 1, "", "named_parameters"], [337, 1, 1, "", "parameters"], [337, 1, 1, "", "register_backward_hook"], [337, 1, 1, "", "register_buffer"], [337, 1, 1, "", "register_collector"], [337, 1, 1, "", "register_forward_hook"], [337, 1, 1, "", "register_forward_pre_hook"], [337, 1, 1, "", "register_full_backward_hook"], [337, 1, 1, "", "register_full_backward_pre_hook"], [337, 1, 1, "", "register_load_state_dict_post_hook"], [337, 1, 1, "", "register_load_state_dict_pre_hook"], [337, 1, 1, "", "register_module"], [337, 1, 1, "", "register_parameter"], [337, 1, 1, "", "register_state_dict_post_hook"], [337, 1, 1, "", "register_state_dict_pre_hook"], [337, 1, 1, "", "requires_grad_"], [337, 1, 1, "", "reset_out_keys"], [337, 1, 1, "", "reset_parameters_recursive"], [337, 1, 1, "", "select_out_keys"], [337, 1, 1, "", "set_extra_state"], [337, 1, 1, "", "set_submodule"], [337, 1, 1, "", "set_tokenizer"], [337, 1, 1, "", "share_memory"], [337, 1, 1, "", "state_dict"], [337, 1, 1, "", "to"], [337, 1, 1, "", "to_empty"], [337, 1, 1, "", "train"], [337, 1, 1, "", "type"], [337, 1, 1, "", "xpu"], [337, 1, 1, "", "zero_grad"]], "torchrl.modules.models.utils": [[338, 0, 1, "", "SquashDims"]], "torchrl.modules.models.utils.SquashDims": [[338, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module": [[340, 0, 1, "", "Actor"], [341, 0, 1, "", "MultiStepActorWrapper"], [342, 0, 1, "", "ProbabilisticActor"], [343, 0, 1, "", "RandomPolicy"], [344, 0, 1, "", "SafeModule"], [345, 0, 1, "", "SafeProbabilisticModule"], [346, 0, 1, "", "SafeProbabilisticTensorDictSequential"], [347, 0, 1, "", "SafeSequential"], [348, 0, 1, "", "TanhModule"]], "torchrl.modules.tensordict_module.MultiStepActorWrapper": [[341, 1, 1, "", "forward"], [341, 2, 1, "", "init_key"]], "torchrl.modules.tensordict_module.SafeModule": [[344, 1, 1, "", "random"], [344, 1, 1, "", "random_sample"], [344, 1, 1, "", "to"]], "torchrl.modules.tensordict_module.SafeProbabilisticModule": [[345, 1, 1, "", "random"], [345, 1, 1, "", "random_sample"]], "torchrl.modules.tensordict_module.TanhModule": [[348, 1, 1, "", "forward"]], "torchrl.objectives": [[349, 0, 1, "", "A2CLoss"], [350, 0, 1, "", "CQLLoss"], [351, 0, 1, "", "ClipPPOLoss"], [352, 0, 1, "", "CrossQLoss"], [353, 0, 1, "", "DDPGLoss"], [354, 0, 1, "", "DQNLoss"], [355, 0, 1, "", "DTLoss"], [356, 0, 1, "", "DiscreteCQLLoss"], [357, 0, 1, "", "DiscreteIQLLoss"], [358, 0, 1, "", "DiscreteSACLoss"], [359, 0, 1, "", "DistributionalDQNLoss"], [360, 0, 1, "", "DreamerActorLoss"], [361, 0, 1, "", "DreamerModelLoss"], [362, 0, 1, "", "DreamerValueLoss"], [363, 0, 1, "", "GAILLoss"], [364, 0, 1, "", "IQLLoss"], [365, 0, 1, "", "KLPENPPOLoss"], [366, 0, 1, "", "LossModule"], [367, 0, 1, "", "OnlineDTLoss"], [368, 0, 1, "", "PPOLoss"], [369, 0, 1, "", "REDQLoss"], [370, 0, 1, "", "ReinforceLoss"], [371, 0, 1, "", "SACLoss"], [372, 0, 1, "", "TD3BCLoss"], [373, 0, 1, "", "TD3Loss"], [374, 0, 1, "", "ValueEstimators"], [375, 0, 1, "", "add_random_module"]], "torchrl.objectives.A2CLoss": [[349, 4, 1, "", "default_keys"], [349, 1, 1, "", "forward"], [349, 2, 1, "", "functional"], [349, 1, 1, "", "loss_critic"], [349, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.CQLLoss": [[350, 4, 1, "", "default_keys"], [350, 1, 1, "", "forward"], [350, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ClipPPOLoss": [[351, 1, 1, "", "forward"]], "torchrl.objectives.CrossQLoss": [[352, 1, 1, "", "actor_loss"], [352, 1, 1, "", "alpha_loss"], [352, 4, 1, "", "default_keys"], [352, 1, 1, "", "forward"], [352, 1, 1, "", "load_state_dict"], [352, 1, 1, "", "make_value_estimator"], [352, 1, 1, "", "maybe_init_target_entropy"], [352, 1, 1, "", "qvalue_loss"], [352, 1, 1, "", "set_keys"], [352, 1, 1, "", "state_dict"], [352, 2, 1, "", "target_entropy_buffer"]], "torchrl.objectives.DDPGLoss": [[353, 4, 1, "", "default_keys"], [353, 1, 1, "", "forward"], [353, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DQNLoss": [[354, 4, 1, "", "default_keys"], [354, 1, 1, "", "forward"], [354, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DTLoss": [[355, 4, 1, "", "default_keys"], [355, 1, 1, "", "forward"]], "torchrl.objectives.DiscreteCQLLoss": [[356, 4, 1, "", "default_keys"], [356, 1, 1, "", "forward"], [356, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DiscreteIQLLoss": [[357, 4, 1, "", "default_keys"], [357, 1, 1, "", "forward"]], "torchrl.objectives.DiscreteSACLoss": [[358, 1, 1, "", "alpha_loss"], [358, 4, 1, "", "default_keys"], [358, 1, 1, "", "forward"], [358, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DistributionalDQNLoss": [[359, 4, 1, "", "default_keys"], [359, 1, 1, "", "forward"], [359, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerActorLoss": [[360, 4, 1, "", "default_keys"], [360, 1, 1, "", "forward"], [360, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerModelLoss": [[361, 4, 1, "", "default_keys"], [361, 1, 1, "", "forward"]], "torchrl.objectives.DreamerValueLoss": [[362, 4, 1, "", "default_keys"], [362, 1, 1, "", "forward"]], "torchrl.objectives.GAILLoss": [[363, 4, 1, "", "default_keys"], [363, 1, 1, "", "forward"]], "torchrl.objectives.IQLLoss": [[364, 4, 1, "", "default_keys"], [364, 1, 1, "", "forward"], [364, 1, 1, "", "loss_value_diff"], [364, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.KLPENPPOLoss": [[365, 1, 1, "", "forward"]], "torchrl.objectives.LossModule": [[366, 1, 1, "", "convert_to_functional"], [366, 1, 1, "", "forward"], [366, 1, 1, "", "from_stateful_net"], [366, 2, 1, "", "functional"], [366, 1, 1, "", "get_stateful_net"], [366, 1, 1, "", "make_value_estimator"], [366, 1, 1, "", "named_parameters"], [366, 1, 1, "", "parameters"], [366, 1, 1, "", "reset_parameters_recursive"], [366, 1, 1, "", "set_keys"], [366, 2, 1, "", "value_estimator"], [366, 2, 1, "", "vmap_randomness"]], "torchrl.objectives.OnlineDTLoss": [[367, 4, 1, "", "default_keys"], [367, 1, 1, "", "forward"]], "torchrl.objectives.PPOLoss": [[368, 4, 1, "", "default_keys"], [368, 1, 1, "", "forward"], [368, 2, 1, "", "functional"], [368, 1, 1, "", "loss_critic"], [368, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.REDQLoss": [[369, 4, 1, "", "default_keys"], [369, 1, 1, "", "forward"], [369, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ReinforceLoss": [[370, 4, 1, "", "default_keys"], [370, 1, 1, "", "forward"], [370, 2, 1, "", "functional"], [370, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.SACLoss": [[371, 1, 1, "", "alpha_loss"], [371, 4, 1, "", "default_keys"], [371, 1, 1, "", "forward"], [371, 1, 1, "", "load_state_dict"], [371, 1, 1, "", "make_value_estimator"], [371, 1, 1, "", "state_dict"]], "torchrl.objectives.TD3BCLoss": [[372, 1, 1, "", "actor_loss"], [372, 4, 1, "", "default_keys"], [372, 1, 1, "", "forward"], [372, 1, 1, "", "make_value_estimator"], [372, 1, 1, "", "qvalue_loss"]], "torchrl.objectives.TD3Loss": [[373, 4, 1, "", "default_keys"], [373, 1, 1, "", "forward"], [373, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.llm": [[376, 0, 1, "", "CISPOLoss"], [377, 0, 1, "", "CISPOLossOutput"], [378, 0, 1, "", "DAPO"], [379, 0, 1, "", "DAPOLossOutput"], [380, 0, 1, "", "GRPOLoss"], [381, 0, 1, "", "GRPOLossOutput"], [382, 0, 1, "", "LLMLossOutput"], [383, 0, 1, "", "MCAdvantage"], [384, 0, 1, "", "SFTLoss"], [385, 0, 1, "", "SFTLossOutput"]], "torchrl.objectives.llm.CISPOLoss": [[376, 1, 1, "", "add_module"], [376, 1, 1, "", "apply"], [376, 1, 1, "", "bfloat16"], [376, 1, 1, "", "buffers"], [376, 1, 1, "", "children"], [376, 1, 1, "", "compile"], [376, 1, 1, "", "convert_to_functional"], [376, 1, 1, "", "cpu"], [376, 1, 1, "", "cuda"], [376, 1, 1, "", "double"], [376, 1, 1, "", "eval"], [376, 1, 1, "", "extra_repr"], [376, 1, 1, "", "float"], [376, 1, 1, "", "forward"], [376, 1, 1, "", "from_stateful_net"], [376, 2, 1, "", "functional"], [376, 1, 1, "", "get_buffer"], [376, 1, 1, "", "get_extra_state"], [376, 1, 1, "", "get_parameter"], [376, 1, 1, "", "get_stateful_net"], [376, 1, 1, "", "get_submodule"], [376, 1, 1, "", "half"], [376, 1, 1, "", "ipu"], [376, 1, 1, "", "is_tdmodule_compatible"], [376, 1, 1, "", "load_state_dict"], [376, 1, 1, "", "make_value_estimator"], [376, 1, 1, "", "modules"], [376, 1, 1, "", "mtia"], [376, 1, 1, "", "named_buffers"], [376, 1, 1, "", "named_children"], [376, 1, 1, "", "named_modules"], [376, 1, 1, "", "named_parameters"], [376, 4, 1, "", "output_type"], [376, 1, 1, "", "parameters"], [376, 1, 1, "", "register_backward_hook"], [376, 1, 1, "", "register_buffer"], [376, 1, 1, "", "register_forward_hook"], [376, 1, 1, "", "register_forward_pre_hook"], [376, 1, 1, "", "register_full_backward_hook"], [376, 1, 1, "", "register_full_backward_pre_hook"], [376, 1, 1, "", "register_load_state_dict_post_hook"], [376, 1, 1, "", "register_load_state_dict_pre_hook"], [376, 1, 1, "", "register_module"], [376, 1, 1, "", "register_parameter"], [376, 1, 1, "", "register_state_dict_post_hook"], [376, 1, 1, "", "register_state_dict_pre_hook"], [376, 1, 1, "", "requires_grad_"], [376, 1, 1, "", "reset_out_keys"], [376, 1, 1, "", "reset_parameters_recursive"], [376, 1, 1, "", "select_out_keys"], [376, 1, 1, "", "set_extra_state"], [376, 1, 1, "", "set_keys"], [376, 1, 1, "", "set_submodule"], [376, 1, 1, "", "share_memory"], [376, 1, 1, "", "state_dict"], [376, 2, 1, "", "tensor_keys"], [376, 1, 1, "", "to"], [376, 1, 1, "", "to_empty"], [376, 1, 1, "", "train"], [376, 1, 1, "", "type"], [376, 2, 1, "", "value_estimator"], [376, 2, 1, "", "vmap_randomness"], [376, 1, 1, "", "xpu"], [376, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.CISPOLossOutput": [[377, 1, 1, "", "cat"], [377, 2, 1, "", "device"], [377, 1, 1, "", "dumps"], [377, 1, 1, "", "fields"], [377, 1, 1, "", "from_any"], [377, 1, 1, "", "from_dataclass"], [377, 1, 1, "", "from_h5"], [377, 1, 1, "", "from_modules"], [377, 1, 1, "", "from_namedtuple"], [377, 1, 1, "", "from_pytree"], [377, 1, 1, "", "from_remote_init"], [377, 1, 1, "", "from_struct_array"], [377, 1, 1, "", "from_tensordict"], [377, 1, 1, "", "from_tuple"], [377, 1, 1, "", "fromkeys"], [377, 1, 1, "", "get"], [377, 1, 1, "", "lazy_stack"], [377, 1, 1, "", "load"], [377, 1, 1, "", "load_"], [377, 1, 1, "", "load_memmap"], [377, 1, 1, "", "load_state_dict"], [377, 1, 1, "", "maybe_dense_stack"], [377, 1, 1, "", "memmap"], [377, 1, 1, "", "memmap_"], [377, 1, 1, "", "memmap_like"], [377, 1, 1, "", "memmap_refresh_"], [377, 1, 1, "", "save"], [377, 1, 1, "", "set"], [377, 1, 1, "", "stack"], [377, 1, 1, "", "state_dict"], [377, 1, 1, "", "to_tensordict"], [377, 1, 1, "", "unbind"]], "torchrl.objectives.llm.DAPO": [[378, 1, 1, "", "add_module"], [378, 1, 1, "", "apply"], [378, 1, 1, "", "bfloat16"], [378, 1, 1, "", "buffers"], [378, 1, 1, "", "children"], [378, 1, 1, "", "compile"], [378, 1, 1, "", "convert_to_functional"], [378, 1, 1, "", "cpu"], [378, 1, 1, "", "cuda"], [378, 1, 1, "", "double"], [378, 1, 1, "", "eval"], [378, 1, 1, "", "extra_repr"], [378, 1, 1, "", "float"], [378, 1, 1, "", "forward"], [378, 1, 1, "", "from_stateful_net"], [378, 2, 1, "", "functional"], [378, 1, 1, "", "get_buffer"], [378, 1, 1, "", "get_extra_state"], [378, 1, 1, "", "get_parameter"], [378, 1, 1, "", "get_stateful_net"], [378, 1, 1, "", "get_submodule"], [378, 1, 1, "", "half"], [378, 1, 1, "", "ipu"], [378, 1, 1, "", "is_tdmodule_compatible"], [378, 1, 1, "", "load_state_dict"], [378, 1, 1, "", "make_value_estimator"], [378, 1, 1, "", "modules"], [378, 1, 1, "", "mtia"], [378, 1, 1, "", "named_buffers"], [378, 1, 1, "", "named_children"], [378, 1, 1, "", "named_modules"], [378, 1, 1, "", "named_parameters"], [378, 4, 1, "", "output_type"], [378, 1, 1, "", "parameters"], [378, 1, 1, "", "register_backward_hook"], [378, 1, 1, "", "register_buffer"], [378, 1, 1, "", "register_forward_hook"], [378, 1, 1, "", "register_forward_pre_hook"], [378, 1, 1, "", "register_full_backward_hook"], [378, 1, 1, "", "register_full_backward_pre_hook"], [378, 1, 1, "", "register_load_state_dict_post_hook"], [378, 1, 1, "", "register_load_state_dict_pre_hook"], [378, 1, 1, "", "register_module"], [378, 1, 1, "", "register_parameter"], [378, 1, 1, "", "register_state_dict_post_hook"], [378, 1, 1, "", "register_state_dict_pre_hook"], [378, 1, 1, "", "requires_grad_"], [378, 1, 1, "", "reset_out_keys"], [378, 1, 1, "", "reset_parameters_recursive"], [378, 1, 1, "", "select_out_keys"], [378, 1, 1, "", "set_extra_state"], [378, 1, 1, "", "set_keys"], [378, 1, 1, "", "set_submodule"], [378, 1, 1, "", "share_memory"], [378, 1, 1, "", "state_dict"], [378, 2, 1, "", "tensor_keys"], [378, 1, 1, "", "to"], [378, 1, 1, "", "to_empty"], [378, 1, 1, "", "train"], [378, 1, 1, "", "type"], [378, 2, 1, "", "value_estimator"], [378, 2, 1, "", "vmap_randomness"], [378, 1, 1, "", "xpu"], [378, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.DAPOLossOutput": [[379, 1, 1, "", "cat"], [379, 2, 1, "", "device"], [379, 1, 1, "", "dumps"], [379, 1, 1, "", "fields"], [379, 1, 1, "", "from_any"], [379, 1, 1, "", "from_dataclass"], [379, 1, 1, "", "from_h5"], [379, 1, 1, "", "from_modules"], [379, 1, 1, "", "from_namedtuple"], [379, 1, 1, "", "from_pytree"], [379, 1, 1, "", "from_remote_init"], [379, 1, 1, "", "from_struct_array"], [379, 1, 1, "", "from_tensordict"], [379, 1, 1, "", "from_tuple"], [379, 1, 1, "", "fromkeys"], [379, 1, 1, "", "get"], [379, 1, 1, "", "lazy_stack"], [379, 1, 1, "", "load"], [379, 1, 1, "", "load_"], [379, 1, 1, "", "load_memmap"], [379, 1, 1, "", "load_state_dict"], [379, 1, 1, "", "maybe_dense_stack"], [379, 1, 1, "", "memmap"], [379, 1, 1, "", "memmap_"], [379, 1, 1, "", "memmap_like"], [379, 1, 1, "", "memmap_refresh_"], [379, 1, 1, "", "save"], [379, 1, 1, "", "set"], [379, 1, 1, "", "stack"], [379, 1, 1, "", "state_dict"], [379, 1, 1, "", "to_tensordict"], [379, 1, 1, "", "unbind"]], "torchrl.objectives.llm.GRPOLoss": [[380, 1, 1, "", "add_module"], [380, 1, 1, "", "apply"], [380, 1, 1, "", "bfloat16"], [380, 1, 1, "", "buffers"], [380, 1, 1, "", "children"], [380, 1, 1, "", "compile"], [380, 1, 1, "", "convert_to_functional"], [380, 1, 1, "", "cpu"], [380, 1, 1, "", "cuda"], [380, 1, 1, "", "double"], [380, 1, 1, "", "eval"], [380, 1, 1, "", "extra_repr"], [380, 1, 1, "", "float"], [380, 1, 1, "", "forward"], [380, 1, 1, "", "from_stateful_net"], [380, 2, 1, "", "functional"], [380, 1, 1, "", "get_buffer"], [380, 1, 1, "", "get_extra_state"], [380, 1, 1, "", "get_parameter"], [380, 1, 1, "", "get_stateful_net"], [380, 1, 1, "", "get_submodule"], [380, 1, 1, "", "half"], [380, 1, 1, "", "ipu"], [380, 1, 1, "", "is_tdmodule_compatible"], [380, 1, 1, "", "load_state_dict"], [380, 1, 1, "", "make_value_estimator"], [380, 1, 1, "", "modules"], [380, 1, 1, "", "mtia"], [380, 1, 1, "", "named_buffers"], [380, 1, 1, "", "named_children"], [380, 1, 1, "", "named_modules"], [380, 1, 1, "", "named_parameters"], [380, 4, 1, "", "output_type"], [380, 1, 1, "", "parameters"], [380, 1, 1, "", "register_backward_hook"], [380, 1, 1, "", "register_buffer"], [380, 1, 1, "", "register_forward_hook"], [380, 1, 1, "", "register_forward_pre_hook"], [380, 1, 1, "", "register_full_backward_hook"], [380, 1, 1, "", "register_full_backward_pre_hook"], [380, 1, 1, "", "register_load_state_dict_post_hook"], [380, 1, 1, "", "register_load_state_dict_pre_hook"], [380, 1, 1, "", "register_module"], [380, 1, 1, "", "register_parameter"], [380, 1, 1, "", "register_state_dict_post_hook"], [380, 1, 1, "", "register_state_dict_pre_hook"], [380, 1, 1, "", "requires_grad_"], [380, 1, 1, "", "reset_out_keys"], [380, 1, 1, "", "reset_parameters_recursive"], [380, 1, 1, "", "select_out_keys"], [380, 1, 1, "", "set_extra_state"], [380, 1, 1, "", "set_keys"], [380, 1, 1, "", "set_submodule"], [380, 1, 1, "", "share_memory"], [380, 1, 1, "", "state_dict"], [380, 2, 1, "", "tensor_keys"], [380, 1, 1, "", "to"], [380, 1, 1, "", "to_empty"], [380, 1, 1, "", "train"], [380, 1, 1, "", "type"], [380, 2, 1, "", "value_estimator"], [380, 2, 1, "", "vmap_randomness"], [380, 1, 1, "", "xpu"], [380, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.GRPOLossOutput": [[381, 1, 1, "", "cat"], [381, 2, 1, "", "device"], [381, 1, 1, "", "dumps"], [381, 1, 1, "", "fields"], [381, 1, 1, "", "from_any"], [381, 1, 1, "", "from_dataclass"], [381, 1, 1, "", "from_h5"], [381, 1, 1, "", "from_modules"], [381, 1, 1, "", "from_namedtuple"], [381, 1, 1, "", "from_pytree"], [381, 1, 1, "", "from_remote_init"], [381, 1, 1, "", "from_struct_array"], [381, 1, 1, "", "from_tensordict"], [381, 1, 1, "", "from_tuple"], [381, 1, 1, "", "fromkeys"], [381, 1, 1, "", "get"], [381, 1, 1, "", "lazy_stack"], [381, 1, 1, "", "load"], [381, 1, 1, "", "load_"], [381, 1, 1, "", "load_memmap"], [381, 1, 1, "", "load_state_dict"], [381, 1, 1, "", "maybe_dense_stack"], [381, 1, 1, "", "memmap"], [381, 1, 1, "", "memmap_"], [381, 1, 1, "", "memmap_like"], [381, 1, 1, "", "memmap_refresh_"], [381, 1, 1, "", "save"], [381, 1, 1, "", "set"], [381, 1, 1, "", "stack"], [381, 1, 1, "", "state_dict"], [381, 1, 1, "", "to_tensordict"], [381, 1, 1, "", "unbind"]], "torchrl.objectives.llm.LLMLossOutput": [[382, 1, 1, "", "cat"], [382, 2, 1, "", "device"], [382, 1, 1, "", "dumps"], [382, 1, 1, "", "fields"], [382, 1, 1, "", "from_any"], [382, 1, 1, "", "from_dataclass"], [382, 1, 1, "", "from_h5"], [382, 1, 1, "", "from_modules"], [382, 1, 1, "", "from_namedtuple"], [382, 1, 1, "", "from_pytree"], [382, 1, 1, "", "from_remote_init"], [382, 1, 1, "", "from_struct_array"], [382, 1, 1, "", "from_tensordict"], [382, 1, 1, "", "from_tuple"], [382, 1, 1, "", "fromkeys"], [382, 1, 1, "", "get"], [382, 1, 1, "", "lazy_stack"], [382, 1, 1, "", "load"], [382, 1, 1, "", "load_"], [382, 1, 1, "", "load_memmap"], [382, 1, 1, "", "load_state_dict"], [382, 1, 1, "", "maybe_dense_stack"], [382, 1, 1, "", "memmap"], [382, 1, 1, "", "memmap_"], [382, 1, 1, "", "memmap_like"], [382, 1, 1, "", "memmap_refresh_"], [382, 1, 1, "", "save"], [382, 1, 1, "", "set"], [382, 1, 1, "", "stack"], [382, 1, 1, "", "state_dict"], [382, 1, 1, "", "to_tensordict"], [382, 1, 1, "", "unbind"]], "torchrl.objectives.llm.MCAdvantage": [[383, 1, 1, "", "add_module"], [383, 1, 1, "", "apply"], [383, 1, 1, "", "bfloat16"], [383, 1, 1, "", "buffers"], [383, 1, 1, "", "children"], [383, 1, 1, "", "close"], [383, 2, 1, "", "collector"], [383, 1, 1, "", "compile"], [383, 2, 1, "", "container"], [383, 1, 1, "", "cpu"], [383, 1, 1, "", "cuda"], [383, 1, 1, "", "double"], [383, 1, 1, "", "eval"], [383, 1, 1, "", "extra_repr"], [383, 1, 1, "", "float"], [383, 1, 1, "", "forward"], [383, 1, 1, "", "get_buffer"], [383, 1, 1, "", "get_extra_state"], [383, 1, 1, "", "get_parameter"], [383, 1, 1, "", "get_submodule"], [383, 1, 1, "", "half"], [383, 1, 1, "", "init"], [383, 1, 1, "", "inv"], [383, 1, 1, "", "ipu"], [383, 1, 1, "", "load_state_dict"], [383, 1, 1, "", "modules"], [383, 1, 1, "", "mtia"], [383, 1, 1, "", "named_buffers"], [383, 1, 1, "", "named_children"], [383, 1, 1, "", "named_modules"], [383, 1, 1, "", "named_parameters"], [383, 1, 1, "", "parameters"], [383, 2, 1, "", "parent"], [383, 1, 1, "", "register_backward_hook"], [383, 1, 1, "", "register_buffer"], [383, 1, 1, "", "register_forward_hook"], [383, 1, 1, "", "register_forward_pre_hook"], [383, 1, 1, "", "register_full_backward_hook"], [383, 1, 1, "", "register_full_backward_pre_hook"], [383, 1, 1, "", "register_load_state_dict_post_hook"], [383, 1, 1, "", "register_load_state_dict_pre_hook"], [383, 1, 1, "", "register_module"], [383, 1, 1, "", "register_parameter"], [383, 1, 1, "", "register_state_dict_post_hook"], [383, 1, 1, "", "register_state_dict_pre_hook"], [383, 1, 1, "", "requires_grad_"], [383, 1, 1, "", "set_extra_state"], [383, 1, 1, "", "set_submodule"], [383, 1, 1, "", "share_memory"], [383, 1, 1, "", "state_dict"], [383, 1, 1, "", "to"], [383, 1, 1, "", "to_empty"], [383, 1, 1, "", "train"], [383, 1, 1, "", "transform_action_spec"], [383, 1, 1, "", "transform_done_spec"], [383, 1, 1, "", "transform_env_batch_size"], [383, 1, 1, "", "transform_env_device"], [383, 1, 1, "", "transform_input_spec"], [383, 1, 1, "", "transform_observation_spec"], [383, 1, 1, "", "transform_output_spec"], [383, 1, 1, "", "transform_reward_spec"], [383, 1, 1, "", "transform_state_spec"], [383, 1, 1, "", "type"], [383, 1, 1, "", "xpu"], [383, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.SFTLoss": [[384, 1, 1, "", "add_module"], [384, 1, 1, "", "apply"], [384, 1, 1, "", "bfloat16"], [384, 1, 1, "", "buffers"], [384, 1, 1, "", "children"], [384, 1, 1, "", "compile"], [384, 1, 1, "", "convert_to_functional"], [384, 1, 1, "", "cpu"], [384, 1, 1, "", "cuda"], [384, 4, 1, "", "default_keys"], [384, 1, 1, "", "double"], [384, 1, 1, "", "eval"], [384, 1, 1, "", "extra_repr"], [384, 1, 1, "", "float"], [384, 1, 1, "", "forward"], [384, 1, 1, "", "from_stateful_net"], [384, 2, 1, "", "functional"], [384, 1, 1, "", "get_buffer"], [384, 1, 1, "", "get_extra_state"], [384, 1, 1, "", "get_parameter"], [384, 1, 1, "", "get_stateful_net"], [384, 1, 1, "", "get_submodule"], [384, 1, 1, "", "half"], [384, 1, 1, "", "ipu"], [384, 1, 1, "", "is_tdmodule_compatible"], [384, 1, 1, "", "load_state_dict"], [384, 1, 1, "", "make_value_estimator"], [384, 1, 1, "", "modules"], [384, 1, 1, "", "mtia"], [384, 1, 1, "", "named_buffers"], [384, 1, 1, "", "named_children"], [384, 1, 1, "", "named_modules"], [384, 1, 1, "", "named_parameters"], [384, 1, 1, "", "parameters"], [384, 1, 1, "", "register_backward_hook"], [384, 1, 1, "", "register_buffer"], [384, 1, 1, "", "register_forward_hook"], [384, 1, 1, "", "register_forward_pre_hook"], [384, 1, 1, "", "register_full_backward_hook"], [384, 1, 1, "", "register_full_backward_pre_hook"], [384, 1, 1, "", "register_load_state_dict_post_hook"], [384, 1, 1, "", "register_load_state_dict_pre_hook"], [384, 1, 1, "", "register_module"], [384, 1, 1, "", "register_parameter"], [384, 1, 1, "", "register_state_dict_post_hook"], [384, 1, 1, "", "register_state_dict_pre_hook"], [384, 1, 1, "", "requires_grad_"], [384, 1, 1, "", "reset_out_keys"], [384, 1, 1, "", "reset_parameters_recursive"], [384, 1, 1, "", "select_out_keys"], [384, 1, 1, "", "set_extra_state"], [384, 1, 1, "", "set_keys"], [384, 1, 1, "", "set_submodule"], [384, 1, 1, "", "share_memory"], [384, 1, 1, "", "state_dict"], [384, 1, 1, "", "to"], [384, 1, 1, "", "to_empty"], [384, 1, 1, "", "train"], [384, 1, 1, "", "type"], [384, 2, 1, "", "value_estimator"], [384, 2, 1, "", "vmap_randomness"], [384, 1, 1, "", "xpu"], [384, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.SFTLossOutput": [[385, 1, 1, "", "cat"], [385, 2, 1, "", "device"], [385, 1, 1, "", "dumps"], [385, 1, 1, "", "fields"], [385, 1, 1, "", "from_any"], [385, 1, 1, "", "from_dataclass"], [385, 1, 1, "", "from_h5"], [385, 1, 1, "", "from_modules"], [385, 1, 1, "", "from_namedtuple"], [385, 1, 1, "", "from_pytree"], [385, 1, 1, "", "from_remote_init"], [385, 1, 1, "", "from_struct_array"], [385, 1, 1, "", "from_tensordict"], [385, 1, 1, "", "from_tuple"], [385, 1, 1, "", "fromkeys"], [385, 1, 1, "", "get"], [385, 1, 1, "", "lazy_stack"], [385, 1, 1, "", "load"], [385, 1, 1, "", "load_"], [385, 1, 1, "", "load_memmap"], [385, 1, 1, "", "load_state_dict"], [385, 1, 1, "", "maybe_dense_stack"], [385, 1, 1, "", "memmap"], [385, 1, 1, "", "memmap_"], [385, 1, 1, "", "memmap_like"], [385, 1, 1, "", "memmap_refresh_"], [385, 1, 1, "", "save"], [385, 1, 1, "", "set"], [385, 1, 1, "", "stack"], [385, 1, 1, "", "state_dict"], [385, 1, 1, "", "to_tensordict"], [385, 1, 1, "", "unbind"]], "torchrl.objectives.value": [[386, 0, 1, "", "GAE"], [387, 0, 1, "", "TD0Estimator"], [388, 0, 1, "", "TD1Estimator"], [389, 0, 1, "", "TDLambdaEstimator"], [390, 0, 1, "", "ValueEstimatorBase"]], "torchrl.objectives.value.GAE": [[386, 1, 1, "", "forward"], [386, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD0Estimator": [[387, 1, 1, "", "forward"], [387, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD1Estimator": [[388, 1, 1, "", "forward"], [388, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TDLambdaEstimator": [[389, 1, 1, "", "forward"], [389, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.ValueEstimatorBase": [[390, 4, 1, "", "default_keys"], [390, 1, 1, "", "forward"], [390, 1, 1, "", "set_keys"], [390, 1, 1, "", "value_estimate"]], "torchrl.record": [[391, 3, 1, "", "PixelRenderTransform"], [392, 3, 1, "", "TensorDictRecorder"], [393, 3, 1, "", "VideoRecorder"]], "torchrl.record.loggers": [[394, 3, 1, "", "Logger"], [396, 3, 1, "", "generate_exp_name"], [397, 3, 1, "", "get_logger"]], "torchrl.record.loggers.csv": [[395, 3, 1, "", "CSVLogger"]], "torchrl.record.loggers.mlflow": [[398, 3, 1, "", "MLFlowLogger"]], "torchrl.record.loggers.tensorboard": [[399, 3, 1, "", "TensorboardLogger"]], "torchrl.record.loggers.trackio": [[400, 3, 1, "", "TrackioLogger"]], "torchrl.record.loggers.wandb": [[401, 3, 1, "", "WandbLogger"]], "torchrl.services": [[402, 0, 1, "", "RayService"], [403, 0, 1, "", "ServiceBase"], [404, 0, 1, "", "get_services"]], "torchrl.services.RayService": [[402, 1, 1, "", "get"], [402, 1, 1, "", "list"], [402, 1, 1, "", "register"], [402, 1, 1, "", "register_with_options"], [402, 1, 1, "", "reset"], [402, 1, 1, "", "shutdown"]], "torchrl.services.ServiceBase": [[403, 1, 1, "", "get"], [403, 1, 1, "", "list"], [403, 1, 1, "", "register"], [403, 1, 1, "", "reset"]], "torchrl.trainers": [[406, 0, 1, "", "BatchSubSampler"], [407, 0, 1, "", "ClearCudaCache"], [408, 0, 1, "", "CountFramesLog"], [409, 0, 1, "", "LogScalar"], [410, 0, 1, "", "LogValidationReward"], [411, 0, 1, "", "OptimizerHook"], [412, 0, 1, "", "ReplayBufferTrainer"], [413, 0, 1, "", "RewardNormalizer"], [414, 0, 1, "", "SelectKeys"], [415, 0, 1, "", "TargetNetUpdaterHook"], [416, 0, 1, "", "Trainer"], [417, 0, 1, "", "TrainerHookBase"], [418, 0, 1, "", "UTDRHook"], [419, 0, 1, "", "UpdateWeights"]], "torchrl.trainers.BatchSubSampler": [[406, 1, 1, "", "register"]], "torchrl.trainers.ClearCudaCache": [[407, 1, 1, "", "register"]], "torchrl.trainers.CountFramesLog": [[408, 1, 1, "", "register"]], "torchrl.trainers.LogScalar": [[409, 1, 1, "", "register"]], "torchrl.trainers.LogValidationReward": [[410, 1, 1, "", "register"]], "torchrl.trainers.OptimizerHook": [[411, 1, 1, "", "register"]], "torchrl.trainers.ReplayBufferTrainer": [[412, 1, 1, "", "register"]], "torchrl.trainers.RewardNormalizer": [[413, 1, 1, "", "register"]], "torchrl.trainers.SelectKeys": [[414, 1, 1, "", "register"]], "torchrl.trainers.TargetNetUpdaterHook": [[415, 1, 1, "", "register"]], "torchrl.trainers.Trainer": [[416, 1, 1, "", "load_from_file"]], "torchrl.trainers.TrainerHookBase": [[417, 1, 1, "", "register"]], "torchrl.trainers.UTDRHook": [[418, 1, 1, "", "load_state_dict"], [418, 1, 1, "", "register"], [418, 1, 1, "", "state_dict"]], "torchrl.trainers.UpdateWeights": [[419, 1, 1, "", "register"]], "torchrl.trainers.algorithms": [[420, 0, 1, "", "PPOTrainer"], [421, 0, 1, "", "SACTrainer"]], "torchrl.trainers.algorithms.PPOTrainer": [[420, 1, 1, "", "load_from_file"]], "torchrl.trainers.algorithms.SACTrainer": [[421, 1, 1, "", "load_from_file"]], "torchrl.trainers.algorithms.configs.collectors": [[422, 0, 1, "", "AsyncCollectorConfig"], [423, 0, 1, "", "CollectorConfig"], [424, 0, 1, "", "MultiAsyncCollectorConfig"], [425, 0, 1, "", "MultiSyncCollectorConfig"]], "torchrl.trainers.algorithms.configs.common": [[426, 0, 1, "", "ConfigBase"]], "torchrl.trainers.algorithms.configs.data": [[427, 0, 1, "", "LazyMemmapStorageConfig"], [428, 0, 1, "", "LazyStackStorageConfig"], [429, 0, 1, "", "LazyTensorStorageConfig"], [430, 0, 1, "", "ListStorageConfig"], [431, 0, 1, "", "PrioritizedSamplerConfig"], [432, 0, 1, "", "RandomSamplerConfig"], [433, 0, 1, "", "ReplayBufferConfig"], [434, 0, 1, "", "RoundRobinWriterConfig"], [435, 0, 1, "", "SamplerWithoutReplacementConfig"], [436, 0, 1, "", "SliceSamplerConfig"], [437, 0, 1, "", "SliceSamplerWithoutReplacementConfig"], [438, 0, 1, "", "StorageEnsembleConfig"], [439, 0, 1, "", "StorageEnsembleWriterConfig"], [440, 0, 1, "", "TensorDictReplayBufferConfig"], [441, 0, 1, "", "TensorStorageConfig"]], "torchrl.trainers.algorithms.configs.envs": [[442, 0, 1, "", "BatchedEnvConfig"], [443, 0, 1, "", "EnvConfig"], [444, 0, 1, "", "TransformedEnvConfig"]], "torchrl.trainers.algorithms.configs.envs_libs": [[445, 0, 1, "", "BraxEnvConfig"], [446, 0, 1, "", "DMControlEnvConfig"], [447, 0, 1, "", "EnvLibsConfig"], [448, 0, 1, "", "GymEnvConfig"], [449, 0, 1, "", "HabitatEnvConfig"], [450, 0, 1, "", "IsaacGymEnvConfig"], [451, 0, 1, "", "JumanjiEnvConfig"], [452, 0, 1, "", "MOGymEnvConfig"], [453, 0, 1, "", "MeltingpotEnvConfig"], [454, 0, 1, "", "MultiThreadedEnvConfig"], [455, 0, 1, "", "OpenMLEnvConfig"], [456, 0, 1, "", "OpenSpielEnvConfig"], [457, 0, 1, "", "PettingZooEnvConfig"], [458, 0, 1, "", "RoboHiveEnvConfig"], [459, 0, 1, "", "SMACv2EnvConfig"], [460, 0, 1, "", "UnityMLAgentsEnvConfig"], [461, 0, 1, "", "VmasEnvConfig"]], "torchrl.trainers.algorithms.configs.logging": [[462, 0, 1, "", "CSVLoggerConfig"], [463, 0, 1, "", "LoggerConfig"], [464, 0, 1, "", "TensorboardLoggerConfig"], [465, 0, 1, "", "WandbLoggerConfig"]], "torchrl.trainers.algorithms.configs.modules": [[466, 0, 1, "", "ConvNetConfig"], [467, 0, 1, "", "MLPConfig"], [468, 0, 1, "", "ModelConfig"], [469, 0, 1, "", "NetworkConfig"], [470, 0, 1, "", "TanhNormalModelConfig"], [471, 0, 1, "", "TensorDictModuleConfig"], [472, 0, 1, "", "ValueModelConfig"]], "torchrl.trainers.algorithms.configs.objectives": [[473, 0, 1, "", "LossConfig"], [474, 0, 1, "", "PPOLossConfig"]], "torchrl.trainers.algorithms.configs.trainers": [[475, 0, 1, "", "PPOTrainerConfig"], [476, 0, 1, "", "TrainerConfig"]], "torchrl.trainers.algorithms.configs.transforms": [[477, 0, 1, "", "ActionDiscretizerConfig"], [478, 0, 1, "", "ActionMaskConfig"], [479, 0, 1, "", "AutoResetTransformConfig"], [480, 0, 1, "", "BatchSizeTransformConfig"], [481, 0, 1, "", "BinarizeRewardConfig"], [482, 0, 1, "", "BurnInTransformConfig"], [483, 0, 1, "", "CatFramesConfig"], [484, 0, 1, "", "CatTensorsConfig"], [485, 0, 1, "", "CenterCropConfig"], [486, 0, 1, "", "ClipTransformConfig"], [487, 0, 1, "", "ComposeConfig"], [488, 0, 1, "", "ConditionalPolicySwitchConfig"], [489, 0, 1, "", "ConditionalSkipConfig"], [490, 0, 1, "", "CropConfig"], [491, 0, 1, "", "DTypeCastTransformConfig"], [492, 0, 1, "", "DeviceCastTransformConfig"], [493, 0, 1, "", "DiscreteActionProjectionConfig"], [494, 0, 1, "", "DoubleToFloatConfig"], [495, 0, 1, "", "EndOfLifeTransformConfig"], [496, 0, 1, "", "ExcludeTransformConfig"], [497, 0, 1, "", "FiniteTensorDictCheckConfig"], [498, 0, 1, "", "FlattenObservationConfig"], [499, 0, 1, "", "FrameSkipTransformConfig"], [500, 0, 1, "", "GrayScaleConfig"], [501, 0, 1, "", "HashConfig"], [502, 0, 1, "", "InitTrackerConfig"], [503, 0, 1, "", "KLRewardTransformConfig"], [504, 0, 1, "", "LineariseRewardsConfig"], [505, 0, 1, "", "MultiActionConfig"], [506, 0, 1, "", "MultiStepTransformConfig"], [507, 0, 1, "", "NoopResetEnvConfig"], [508, 0, 1, "", "ObservationNormConfig"], [509, 0, 1, "", "PermuteTransformConfig"], [510, 0, 1, "", "PinMemoryTransformConfig"], [511, 0, 1, "", "R3MTransformConfig"], [512, 0, 1, "", "RandomCropTensorDictConfig"], [513, 0, 1, "", "RemoveEmptySpecsConfig"], [514, 0, 1, "", "RenameTransformConfig"], [515, 0, 1, "", "ResizeConfig"], [516, 0, 1, "", "Reward2GoTransformConfig"], [517, 0, 1, "", "RewardClippingConfig"], [518, 0, 1, "", "RewardScalingConfig"], [519, 0, 1, "", "RewardSumConfig"], [520, 0, 1, "", "SelectTransformConfig"], [521, 0, 1, "", "SignTransformConfig"], [522, 0, 1, "", "SqueezeTransformConfig"], [523, 0, 1, "", "StackConfig"], [524, 0, 1, "", "StepCounterConfig"], [525, 0, 1, "", "TargetReturnConfig"], [526, 0, 1, "", "TensorDictPrimerConfig"], [527, 0, 1, "", "TimeMaxPoolConfig"], [528, 0, 1, "", "TimerConfig"], [529, 0, 1, "", "ToTensorImageConfig"], [530, 0, 1, "", "TokenizerConfig"], [531, 0, 1, "", "TrajCounterConfig"], [532, 0, 1, "", "TransformConfig"], [533, 0, 1, "", "UnaryTransformConfig"], [534, 0, 1, "", "UnsqueezeTransformConfig"], [535, 0, 1, "", "VC1TransformConfig"], [536, 0, 1, "", "VIPRewardTransformConfig"], [537, 0, 1, "", "VIPTransformConfig"], [538, 0, 1, "", "VecGymEnvTransformConfig"], [539, 0, 1, "", "VecNormConfig"], [540, 0, 1, "", "VecNormV2Config"]], "torchrl.trainers.algorithms.configs.utils": [[541, 0, 1, "", "ASGDConfig"], [542, 0, 1, "", "AdadeltaConfig"], [543, 0, 1, "", "AdagradConfig"], [544, 0, 1, "", "AdamConfig"], [545, 0, 1, "", "AdamWConfig"], [546, 0, 1, "", "AdamaxConfig"], [547, 0, 1, "", "LBFGSConfig"], [548, 0, 1, "", "LionConfig"], [549, 0, 1, "", "NAdamConfig"], [550, 0, 1, "", "RAdamConfig"], [551, 0, 1, "", "RMSpropConfig"], [552, 0, 1, "", "RpropConfig"], [553, 0, 1, "", "SGDConfig"], [554, 0, 1, "", "SparseAdamConfig"]], "torchrl.trainers.helpers": [[555, 3, 1, "", "correct_for_frame_skip"], [556, 3, 1, "", "get_stats_random_rollout"], [557, 3, 1, "", "make_collector_offpolicy"], [558, 3, 1, "", "make_collector_onpolicy"], [559, 3, 1, "", "make_dqn_loss"], [560, 3, 1, "", "make_replay_buffer"], [561, 3, 1, "", "make_target_updater"], [562, 3, 1, "", "make_trainer"], [563, 3, 1, "", "parallel_env_constructor"], [564, 3, 1, "", "sync_async_collector"], [565, 3, 1, "", "sync_sync_collector"], [566, 3, 1, "", "transformed_env_constructor"]], "torchrl.weight_update": [[567, 0, 1, "", "DistributedTransport"], [568, 0, 1, "", "DistributedWeightSyncScheme"], [569, 0, 1, "", "MPTransport"], [570, 0, 1, "", "MultiProcessWeightSyncScheme"], [571, 0, 1, "", "NoWeightSyncScheme"], [572, 0, 1, "", "RPCTransport"], [573, 0, 1, "", "RPCWeightSyncScheme"], [574, 0, 1, "", "RayModuleTransformScheme"], [575, 0, 1, "", "RayTransport"], [576, 0, 1, "", "RayWeightSyncScheme"], [577, 0, 1, "", "SharedMemTransport"], [578, 0, 1, "", "SharedMemWeightSyncScheme"], [579, 0, 1, "", "TransportBackend"], [580, 0, 1, "", "WeightStrategy"], [581, 0, 1, "", "WeightSyncScheme"]], "torchrl.weight_update.DistributedTransport": [[567, 1, 1, "", "receive_initial_weights"], [567, 1, 1, "", "receive_weights"], [567, 1, 1, "", "send_initial_weights"], [567, 1, 1, "", "send_weights"], [567, 1, 1, "", "send_weights_async"], [567, 1, 1, "", "setup_connection_and_weights_on_receiver"], [567, 1, 1, "", "setup_connection_and_weights_on_sender"], [567, 1, 1, "", "wait_ack"]], "torchrl.weight_update.DistributedWeightSyncScheme": [[568, 1, 1, "", "apply_weights"], [568, 1, 1, "", "connect"], [568, 2, 1, "", "context"], [568, 1, 1, "", "create_transport"], [568, 1, 1, "", "init_on_receiver"], [568, 1, 1, "", "init_on_sender"], [568, 2, 1, "", "model"], [568, 2, 1, "", "model_id"], [568, 1, 1, "", "prepare_weights"], [568, 1, 1, "", "receive"], [568, 2, 1, "", "receiver_transport"], [568, 1, 1, "", "send"], [568, 2, 1, "", "sender_transports"], [568, 2, 1, "", "shared_transport"], [568, 1, 1, "", "shutdown"], [568, 2, 1, "", "weights"], [568, 2, 1, "", "worker_idx"]], "torchrl.weight_update.MPTransport": [[569, 1, 1, "", "receive_weights"], [569, 1, 1, "", "send_weights_async"], [569, 1, 1, "", "setup_connection_and_weights_on_receiver"], [569, 1, 1, "", "setup_connection_and_weights_on_sender"]], "torchrl.weight_update.MultiProcessWeightSyncScheme": [[570, 1, 1, "", "apply_weights"], [570, 1, 1, "", "connect"], [570, 2, 1, "", "context"], [570, 1, 1, "", "create_transport"], [570, 1, 1, "", "init_on_receiver"], [570, 1, 1, "", "init_on_sender"], [570, 2, 1, "", "model"], [570, 2, 1, "", "model_id"], [570, 1, 1, "", "prepare_weights"], [570, 1, 1, "", "receive"], [570, 2, 1, "", "receiver_transport"], [570, 1, 1, "", "send"], [570, 2, 1, "", "sender_transports"], [570, 2, 1, "", "shared_transport"], [570, 1, 1, "", "shutdown"], [570, 2, 1, "", "weights"], [570, 2, 1, "", "worker_idx"]], "torchrl.weight_update.NoWeightSyncScheme": [[571, 1, 1, "", "apply_weights"], [571, 1, 1, "", "connect"], [571, 2, 1, "", "context"], [571, 1, 1, "", "create_transport"], [571, 1, 1, "", "init_on_receiver"], [571, 1, 1, "", "init_on_sender"], [571, 2, 1, "", "model"], [571, 2, 1, "", "model_id"], [571, 1, 1, "", "prepare_weights"], [571, 1, 1, "", "receive"], [571, 2, 1, "", "receiver_transport"], [571, 1, 1, "", "send"], [571, 2, 1, "", "sender_transports"], [571, 2, 1, "", "shared_transport"], [571, 1, 1, "", "shutdown"], [571, 2, 1, "", "weights"], [571, 2, 1, "", "worker_idx"]], "torchrl.weight_update.RPCTransport": [[572, 1, 1, "", "receive_weights"], [572, 1, 1, "", "send_weights"], [572, 1, 1, "", "send_weights_async"], [572, 1, 1, "", "setup_connection_and_weights_on_receiver"], [572, 1, 1, "", "setup_connection_and_weights_on_sender"], [572, 1, 1, "", "wait_ack"]], "torchrl.weight_update.RPCWeightSyncScheme": [[573, 1, 1, "", "apply_weights"], [573, 1, 1, "", "connect"], [573, 2, 1, "", "context"], [573, 1, 1, "", "create_transport"], [573, 1, 1, "", "init_on_receiver"], [573, 1, 1, "", "init_on_sender"], [573, 2, 1, "", "model"], [573, 2, 1, "", "model_id"], [573, 1, 1, "", "prepare_weights"], [573, 1, 1, "", "receive"], [573, 2, 1, "", "receiver_transport"], [573, 1, 1, "", "send"], [573, 2, 1, "", "sender_transports"], [573, 2, 1, "", "shared_transport"], [573, 1, 1, "", "shutdown"], [573, 2, 1, "", "weights"], [573, 2, 1, "", "worker_idx"]], "torchrl.weight_update.RayModuleTransformScheme": [[574, 1, 1, "", "apply_weights"], [574, 1, 1, "", "connect"], [574, 2, 1, "", "connection_info_name"], [574, 2, 1, "", "context"], [574, 1, 1, "", "create_transport"], [574, 1, 1, "", "init_on_receiver"], [574, 1, 1, "", "init_on_sender"], [574, 2, 1, "", "model"], [574, 2, 1, "", "model_id"], [574, 1, 1, "", "prepare_weights"], [574, 1, 1, "", "receive"], [574, 2, 1, "", "receiver_transport"], [574, 1, 1, "", "send"], [574, 2, 1, "", "sender_transports"], [574, 2, 1, "", "shared_transport"], [574, 1, 1, "", "shutdown"], [574, 2, 1, "", "weights"], [574, 2, 1, "", "worker_idx"]], "torchrl.weight_update.RayTransport": [[575, 1, 1, "", "receive_weights"], [575, 1, 1, "", "send_weights"], [575, 1, 1, "", "send_weights_async"], [575, 1, 1, "", "set_model"], [575, 1, 1, "", "setup_connection_and_weights_on_receiver"], [575, 1, 1, "", "setup_connection_and_weights_on_sender"], [575, 1, 1, "", "wait_ack"]], "torchrl.weight_update.RayWeightSyncScheme": [[576, 1, 1, "", "apply_weights"], [576, 1, 1, "", "connect"], [576, 2, 1, "", "connection_info_name"], [576, 2, 1, "", "context"], [576, 1, 1, "", "create_transport"], [576, 1, 1, "", "init_on_receiver"], [576, 1, 1, "", "init_on_sender"], [576, 2, 1, "", "model"], [576, 2, 1, "", "model_id"], [576, 1, 1, "", "prepare_weights"], [576, 1, 1, "", "receive"], [576, 2, 1, "", "receiver_transport"], [576, 1, 1, "", "send"], [576, 2, 1, "", "sender_transports"], [576, 2, 1, "", "shared_transport"], [576, 1, 1, "", "shutdown"], [576, 2, 1, "", "weights"], [576, 2, 1, "", "worker_idx"]], "torchrl.weight_update.SharedMemTransport": [[577, 1, 1, "", "receive_weights"], [577, 1, 1, "", "register_weights"], [577, 1, 1, "", "send_ack"], [577, 1, 1, "", "send_weights"], [577, 1, 1, "", "setup_connection_and_weights_on_receiver"], [577, 1, 1, "", "setup_connection_and_weights_on_sender"], [577, 2, 1, "", "unique_weights"]], "torchrl.weight_update.SharedMemWeightSyncScheme": [[578, 1, 1, "", "apply_weights"], [578, 1, 1, "", "connect"], [578, 2, 1, "", "context"], [578, 1, 1, "", "create_transport"], [578, 1, 1, "", "init_on_receiver"], [578, 1, 1, "", "init_on_sender"], [578, 2, 1, "", "model"], [578, 2, 1, "", "model_id"], [578, 1, 1, "", "prepare_weights"], [578, 1, 1, "", "receive"], [578, 2, 1, "", "receiver_transport"], [578, 1, 1, "", "send"], [578, 2, 1, "", "sender_transports"], [578, 2, 1, "", "shared_transport"], [578, 1, 1, "", "shutdown"], [578, 2, 1, "", "weights"], [578, 2, 1, "", "worker_idx"]], "torchrl.weight_update.TransportBackend": [[579, 1, 1, "", "receive_weights"], [579, 1, 1, "", "send_weights"], [579, 1, 1, "", "setup_connection_and_weights_on_receiver"], [579, 1, 1, "", "setup_connection_and_weights_on_sender"]], "torchrl.weight_update.WeightStrategy": [[580, 1, 1, "", "apply_weights"], [580, 1, 1, "", "extract_weights"]], "torchrl.weight_update.WeightSyncScheme": [[581, 1, 1, "", "apply_weights"], [581, 1, 1, "", "connect"], [581, 2, 1, "", "context"], [581, 1, 1, "", "create_transport"], [581, 1, 1, "", "init_on_receiver"], [581, 1, 1, "", "init_on_sender"], [581, 2, 1, "", "model"], [581, 2, 1, "", "model_id"], [581, 1, 1, "", "prepare_weights"], [581, 1, 1, "", "receive"], [581, 2, 1, "", "receiver_transport"], [581, 1, 1, "", "send"], [581, 2, 1, "", "sender_transports"], [581, 2, 1, "", "shared_transport"], [581, 1, 1, "", "shutdown"], [581, 2, 1, "", "weights"], [581, 2, 1, "", "worker_idx"]], "torchrl.weight_update.llm": [[582, 0, 1, "", "VLLMCollectiveTransport"], [583, 0, 1, "", "VLLMDoubleBufferSyncScheme"], [584, 0, 1, "", "VLLMDoubleBufferTransport"], [585, 0, 1, "", "VLLMDoubleBufferWeightReceiver"], [586, 0, 1, "", "VLLMDoubleBufferWeightSender"], [587, 0, 1, "", "VLLMWeightReceiver"], [588, 0, 1, "", "VLLMWeightSender"], [589, 0, 1, "", "VLLMWeightSyncScheme"], [590, 0, 1, "", "get_model_metadata"]], "torchrl.weight_update.llm.VLLMCollectiveTransport": [[582, 1, 1, "", "check_connection"], [582, 1, 1, "", "init_all_workers_group"], [582, 1, 1, "", "receive_weights"], [582, 1, 1, "", "send_weights"]], "torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme": [[583, 1, 1, "", "apply_weights"], [583, 1, 1, "", "connect"], [583, 2, 1, "", "context"], [583, 1, 1, "", "create_receiver"], [583, 1, 1, "", "create_sender"], [583, 1, 1, "", "create_transport"], [583, 1, 1, "", "init_on_receiver"], [583, 1, 1, "", "init_on_sender"], [583, 2, 1, "", "model"], [583, 2, 1, "", "model_id"], [583, 1, 1, "", "prepare_weights"], [583, 1, 1, "", "receive"], [583, 2, 1, "", "receiver_transport"], [583, 1, 1, "", "send"], [583, 2, 1, "", "sender_transports"], [583, 2, 1, "", "shared_transport"], [583, 1, 1, "", "shutdown"], [583, 2, 1, "", "weights"], [583, 2, 1, "", "worker_idx"]], "torchrl.weight_update.llm.VLLMDoubleBufferTransport": [[584, 1, 1, "", "check_connection"], [584, 1, 1, "", "receive_weights"], [584, 1, 1, "", "send_weights"]], "torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver": [[585, 1, 1, "", "apply_weights"], [585, 1, 1, "", "poll_and_apply"]], "torchrl.weight_update.llm.VLLMDoubleBufferWeightSender": [[586, 1, 1, "", "register_model"], [586, 1, 1, "", "update_weights"]], "torchrl.weight_update.llm.VLLMWeightReceiver": [[587, 1, 1, "", "apply_weights"], [587, 1, 1, "", "init_all_workers_group"], [587, 1, 1, "", "poll_and_apply"]], "torchrl.weight_update.llm.VLLMWeightSender": [[588, 1, 1, "", "init_all_workers_group"], [588, 1, 1, "", "register_model"], [588, 1, 1, "", "update_weights"]], "torchrl.weight_update.llm.VLLMWeightSyncScheme": [[589, 1, 1, "", "apply_weights"], [589, 1, 1, "", "connect"], [589, 2, 1, "", "context"], [589, 1, 1, "", "create_receiver"], [589, 1, 1, "", "create_sender"], [589, 1, 1, "", "create_transport"], [589, 1, 1, "", "init_on_receiver"], [589, 1, 1, "", "init_on_sender"], [589, 2, 1, "", "model"], [589, 2, 1, "", "model_id"], [589, 1, 1, "", "prepare_weights"], [589, 1, 1, "", "receive"], [589, 2, 1, "", "receiver_transport"], [589, 1, 1, "", "send"], [589, 2, 1, "", "sender_transports"], [589, 2, 1, "", "shared_transport"], [589, 1, 1, "", "shutdown"], [589, 2, 1, "", "weights"], [589, 2, 1, "", "worker_idx"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:property", "3": "py:function", "4": "py:attribute"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "property", "Python property"], "3": ["py", "function", "Python function"], "4": ["py", "attribute", "Python attribute"]}, "titleterms": {"torchrl": [0, 1, 7, 10, 11, 16, 17, 25, 28, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 601, 608, 616, 620, 622, 623, 624, 626, 628, 634, 635, 637, 638, 639, 643, 644], "instal": [0, 25, 26, 634, 643], "get": [0, 7, 615, 627, 628, 629, 630, 631, 632], "start": [0, 7, 615, 627, 628, 629, 630, 631, 632, 634], "tutori": [0, 624, 637, 638], "basic": [0, 2, 7, 615, 617, 634, 641], "intermedi": [0, 27], "advanc": [0, 615], "refer": [0, 592, 615], "knowledg": [0, 593], "base": [0, 7, 17, 26, 593, 594, 606, 614, 626], "indic": 0, "tabl": 0, "collector": [1, 2, 3, 4, 5, 6, 34, 422, 423, 424, 425, 595, 622, 623, 624, 625, 630, 632, 637, 638, 643], "packag": [1, 10, 16, 601, 608, 616, 620], "multicollector": [1, 5, 36], "api": [1, 17, 592, 615], "kei": [1, 10, 16, 21, 594, 601, 608, 615, 616], "featur": [1, 10, 16, 601, 608, 615, 616], "quick": [1, 7, 10, 16, 594, 601, 608, 616], "exampl": [1, 6, 7, 10, 16, 22, 30, 594, 601, 608, 615, 616, 623, 635, 641], "legaci": [1, 3, 6, 594], "name": [1, 3], "document": [1, 10, 16, 28, 594, 601, 608, 616], "section": [1, 10, 16, 594, 601, 608, 616], "batch": [2, 17, 22, 622, 639, 641], "size": [2, 17, 622, 641], "polici": [2, 23, 594, 613, 622, 624, 625, 626, 628, 632, 636, 637, 638, 639], "copi": 2, "distribut": [3, 604], "replai": [4, 7, 12, 21, 622, 623, 624, 625, 630, 632, 637, 638, 641, 643], "buffer": [4, 7, 12, 21, 622, 623, 624, 625, 630, 632, 637, 638, 641, 643], "interoper": 4, "helper": [4, 17, 605, 607, 634], "function": [4, 23, 594, 623, 624, 629, 637, 638, 643], "singl": [5, 23], "node": 5, "data": [5, 7, 10, 11, 12, 23, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 596, 598, 622, 623, 624, 630, 632, 637, 638, 643], "us": [5, 6, 21, 23, 25, 28, 625, 640, 641, 643], "run": [5, 7, 627, 644], "asynchron": 5, "weight": [6, 594, 595], "synchron": [6, 595], "lifecycl": 6, "phase": 6, "1": [6, 26, 634, 635], "initi": 6, "No": 6, "commun": 6, "2": [6, 26, 634, 635], "connect": 6, "rendez": 6, "vou": 6, "3": [6, 634, 635], "ongo": 6, "updat": [6, 594, 622], "scheme": [6, 595], "specif": [6, 17, 594, 617, 636], "behavior": 6, "sharedmemweightsyncschem": [6, 578], "multiprocessweightsyncschem": [6, 570], "distributedweightsyncschem": [6, 568], "rpcweightsyncschem": [6, 573], "rayweightsyncschem": [6, 576], "raymoduletransformschem": [6, 574], "background": 6, "thread": 6, "architectur": [6, 594], "usag": [6, 7, 615], "sync": [6, 643], "standalon": 6, "transport": 6, "interfac": [6, 594], "timeout": 6, "support": [6, 12], "avail": [6, 7, 18, 21], "configur": [7, 615, 634], "system": [7, 14], "simpl": [7, 626, 639], "categori": 7, "group": [7, 637], "more": [7, 641], "complex": [7, 641], "parallel": [7, 22, 622, 636, 644], "environ": [7, 17, 18, 19, 21, 22, 23, 25, 26, 594, 597, 622, 623, 624, 625, 627, 632, 634, 635, 636, 637, 638, 639, 643, 644], "transform": [7, 21, 271, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 594, 600, 622, 624, 627, 635, 637, 638, 639, 641, 643, 644], "option": [7, 26, 615], "complet": 7, "train": [7, 23, 27, 618, 622, 624, 625, 626, 629, 632, 637, 638, 639], "experi": [7, 622, 639], "hyperparamet": [7, 623, 624, 637, 638], "sweep": 7, "custom": [7, 17, 30, 615, 639, 641], "file": 7, "store": [7, 623, 641], "implement": [7, 23], "detail": [7, 22], "class": [7, 12, 17, 22, 596, 598, 604, 639, 643], "librari": [7, 18, 643], "model": [7, 23, 606, 622, 623, 625, 626, 629, 640, 643], "network": [7, 603, 622, 623, 624, 625, 628, 637, 638], "collect": [7, 623, 624, 630], "storag": [7, 12, 15, 110, 622, 630, 641], "optim": [7, 23, 622, 623, 629, 632], "log": [7, 462, 463, 464, 465, 631, 635], "creat": [7, 627], "best": [7, 615], "practic": [7, 615], "futur": 7, "extens": 7, "dataset": 11, "episod": [11, 23], "ted": [11, 627], "format": 11, "core": [12, 594], "compos": [12, 225], "type": 12, "choos": 12, "sampl": [12, 13, 641], "index": 12, "strategi": [13, 605], "writer": [13, 118], "tensorspec": [14, 74], "backend": 15, "perform": [15, 615, 634], "env": [16, 17, 442, 443, 444, 639, 643, 644], "spec": [17, 18, 21, 639, 644], "lock": [17, 22], "method": [17, 609, 611, 613, 614, 622], "nativ": 17, "domain": 17, "wrapper": [18, 594, 598, 628, 635], "auto": 18, "reset": [18, 22, 639, 644], "dynam": [18, 23, 641], "multi": [19, 636, 637, 638], "agent": [19, 23, 637, 638], "record": [20, 619, 622, 631], "video": [20, 30, 631], "forward": [21, 23, 622], "invers": 21, "understand": 21, "tensor": [21, 641], "expos": 21, "outsid": 21, "world": [21, 606], "design": [21, 594, 632], "your": [21, 23, 25, 622, 626, 632, 639], "own": [21, 632], "tip": 21, "subclass": 21, "clone": [21, 26], "mask": [21, 328], "action": [21, 23, 625, 639], "vector": [22, 643], "partial": 22, "step": [22, 622, 624, 627, 630, 634, 637, 638, 641, 644], "async": [22, 643], "thing": [23, 622, 639], "consid": 23, "when": [23, 26], "debug": 23, "rl": [23, 28, 606, 611, 627, 629, 635, 643], "gener": [23, 30], "have": 23, "you": 23, "valid": [23, 635], "algorithm": [23, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 617], "few": 23, "small": 23, "toi": 23, "problem": 23, "known": 23, "return": 23, "e": 23, "g": 23, "gridworld": 23, "mountaincar": 23, "visual": 23, "Be": 23, "veri": 23, "care": 23, "ani": 23, "augment": 23, "doe": 23, "entropi": 23, "converg": 23, "too": [23, 27], "quickli": 23, "slowli": 23, "chang": [23, 643], "drastic": 23, "reward": [23, 594, 596], "beyond": 23, "go": 23, "up": [23, 25], "Is": 23, "favor": 23, "compon": [23, 594, 610], "i": 23, "veloc": 23, "vs": 23, "l2": 23, "magnitud": 23, "task": [23, 594, 636], "horizon": 23, "extrem": 23, "long": 23, "ar": 23, "normal": [23, 622, 623, 624], "standard": 23, "explor": [23, 605, 622, 623, 628, 635], "valu": [23, 602, 603, 610, 614, 622, 624, 625, 628], "loss": [23, 612, 622, 623, 624, 625, 632, 637, 638], "earli": 23, "roughli": 23, "uniformli": 23, "random": [23, 637, 638], "intrins": 23, "decai": 23, "learn": [23, 624, 637, 638], "progress": 23, "singleton": 23, "remain": 23, "constant": [23, 623], "increas": 23, "an": [23, 624, 625, 627, 639], "can": 23, "low": 23, "also": [23, 615], "offlin": [23, 611], "observ": [23, 622], "space": 23, "effect": [23, 639], "dramat": 23, "dure": [23, 26], "high": 23, "dimension": 23, "work": [24, 25, 26, 615, 626], "gym": [24, 643, 644], "what": 24, "openai": 24, "version": [24, 26, 29, 594], "habitat": 25, "lab": 25, "set": [25, 30], "from": [25, 26], "pip": [25, 26], "common": [25, 26, 27, 426, 610], "issu": [25, 26, 29], "mujoco": 26, "prerequisit": [26, 622], "render": [26, 30, 632, 637, 638, 644], "all": 26, "new": 26, "bindindg": 26, "old": 26, "bind": 26, "py": 26, "repo": [26, 28], "import": [26, 622, 635], "pytorch": [27, 28, 29, 626], "error": [27, 635], "solut": 27, "gradient": [27, 613], "relat": 27, "newcom": 27, "my": 27, "slow": 27, "bug": 27, "resourc": 28, "paper": 28, "functorch": 28, "blog": 28, "websit": 28, "educ": 28, "forum": 28, "how": [29, 615], "reproduc": [29, 639], "workaround": 29, "customis": 30, "tweak": 30, "principl": 30, "auto_unwrap_transformed_env": 31, "asynccollector": 32, "basecollector": 33, "multiasynccollector": 35, "multiprocessedweightupdat": 37, "multisynccollector": 38, "rayweightupdat": 39, "vanillaweightupdat": 40, "weightupdaterbas": 41, "distributedcollector": 42, "distributeddatacollector": 43, "distributedsynccollector": 44, "distributedsyncdatacollector": 45, "distributedweightupdat": 46, "rpccollector": 47, "rpcdatacollector": 48, "rpcweightupdat": 49, "raycollector": 50, "submitit_delayed_launch": 51, "llmcollector": 52, "rayllmcollector": 53, "vllmupdat": 54, "vllmupdaterv2": 55, "split_trajectori": 56, "binari": [57, 626], "bound": 58, "categor": 59, "composit": 60, "multicategor": 61, "multionehot": 62, "nontensor": 63, "onehot": 64, "prioritizedreplaybuff": 65, "rayreplaybuff": 66, "remotetensordictreplaybuff": 67, "replaybuff": 68, "replaybufferensembl": 69, "stack": [70, 262], "stackedcomposit": 71, "tensordictprioritizedreplaybuff": 72, "tensordictreplaybuff": 73, "unbound": 75, "unboundedcontinu": 76, "unboundeddiscret": 77, "ataridqnexperiencereplai": 78, "d4rlexperiencereplai": 79, "gendgrlexperiencereplai": 80, "minariexperiencereplai": 81, "openmlexperiencereplai": 82, "openxexperiencereplai": 83, "robosetexperiencereplai": 84, "vd4rlexperiencereplai": 85, "contentbas": 86, "histori": [87, 596, 635], "topkrewardselector": 88, "add_chat_templ": 89, "compressedliststorag": 90, "compressedliststoragecheckpoint": 91, "flatstoragecheckpoint": 92, "h5storagecheckpoint": 93, "immutabledatasetwrit": 94, "lazymemmapstorag": 95, "lazystackstorag": 96, "lazytensorstorag": 97, "liststorag": 98, "liststoragecheckpoint": 99, "nestedstoragecheckpoint": 100, "prioritizedsampl": 101, "prioritizedslicesampl": 102, "randomsampl": 103, "roundrobinwrit": 104, "sampler": 105, "samplerensembl": 106, "samplerwithoutreplac": 107, "slicesampl": 108, "slicesamplerwithoutreplac": 109, "storagecheckpointerbas": 111, "storageensembl": 112, "storageensemblecheckpoint": 113, "tensordictmaxvaluewrit": 114, "tensordictroundrobinwrit": 115, "tensorstorag": 116, "tensorstoragecheckpoint": 117, "writerensembl": 119, "asyncenvpool": 120, "braxenv": 121, "braxwrapp": 122, "chessenv": 123, "dmcontrolenv": 124, "dmcontrolwrapp": 125, "envbas": [126, 639], "envcreat": 127, "envmetadata": 128, "gymenv": 129, "gymlikeenv": 130, "gymwrapp": 131, "habitatenv": 132, "isaacgymenv": 133, "isaacgymwrapp": 134, "isaaclabwrapp": 135, "jumanjienv": 136, "jumanjiwrapp": 137, "llmhashingenv": [138, 179], "mogymenv": 139, "mogymwrapp": 140, "marlgroupmaptyp": 141, "meltingpotenv": 142, "meltingpotwrapp": 143, "modelbasedenvbas": 144, "multithreadedenv": 145, "multithreadedenvwrapp": 146, "openmlenv": 147, "openspielenv": 148, "openspielwrapp": 149, "parallelenv": 150, "pendulumenv": 151, "pettingzooenv": 152, "pettingzoowrapp": 153, "processorasyncenvpool": 154, "robohiveenv": 155, "smacv2env": 156, "smacv2wrapp": 157, "serialenv": 158, "threadingasyncenvpool": 159, "tictactoeenv": 160, "unitymlagentsenv": 161, "unitymlagentswrapp": 162, "vmasenv": 163, "vmaswrapp": 164, "check_env_spec": 165, "check_marl_group": 166, "exploration_typ": 167, "get_available_librari": 168, "gym_backend": 169, "chatenv": [170, 594], "datasetchatenv": 171, "gsm8kenv": 172, "gsm8kpreparequest": 173, "gsm8krewardpars": 174, "ifevalenv": 175, "ifevalscoredata": 176, "ifevalscor": 177, "llmenv": 178, "mlgymwrapp": 180, "make_gsm8k_env": 181, "make_mlgym": 182, "addthinkingprompt": 183, "browsertransform": 184, "dataloadingprim": 185, "executetoolsinord": 186, "jsoncallpars": 187, "klcomput": 188, "klrewardtransform": [189, 241], "mcptooltransform": 190, "policyvers": 191, "pythonexecutorservic": 192, "pythoninterpret": 193, "raydataloadingprim": 194, "retrievekl": 195, "retrievelogprob": 196, "simpletooltransform": 197, "templatetransform": 198, "token": [199, 269, 331], "toolcal": 200, "toolregistri": 201, "toolservic": 202, "xmlblockpars": 203, "as_nested_tensor": 204, "as_padded_tensor": 205, "make_composite_from_td": 206, "dreamerdecod": 207, "dreamerenv": 208, "register_gym_spec_convers": 209, "set_exploration_typ": 210, "set_gym_backend": 211, "step_mdp": 212, "terminated_or_trunc": 213, "actiondiscret": 214, "actionmask": 215, "autoresetenv": 216, "autoresettransform": 217, "batchsizetransform": 218, "binarizereward": 219, "burnintransform": 220, "catfram": [221, 641], "cattensor": 222, "centercrop": 223, "cliptransform": 224, "conditionalpolicyswitch": 226, "conditionalskip": 227, "crop": 228, "dtypecasttransform": 229, "devicecasttransform": 230, "discreteactionproject": 231, "doubletofloat": 232, "endoflifetransform": 233, "excludetransform": 234, "finitetensordictcheck": 235, "flattenobserv": 236, "frameskiptransform": 237, "grayscal": 238, "hash": 239, "inittrack": 240, "linearisereward": 242, "moduletransform": 243, "multiact": 244, "noopresetenv": 245, "observationnorm": 246, "observationtransform": 247, "permutetransform": 248, "pinmemorytransform": 249, "r3mtransform": 250, "randomcroptensordict": 251, "removeemptyspec": 252, "renametransform": 253, "resiz": 254, "reward2gotransform": 255, "rewardclip": 256, "rewardsc": 257, "rewardsum": 258, "selecttransform": 259, "signtransform": 260, "squeezetransform": 261, "stepcount": 263, "targetreturn": 264, "tensordictprim": 265, "timemaxpool": 266, "timer": 267, "totensorimag": 268, "trajcount": 270, "transformedenv": 272, "unarytransform": 273, "unsqueezetransform": 274, "vc1transform": 275, "viprewardtransform": 276, "viptransform": 277, "vecgymenvtransform": 278, "vecnorm": [279, 644], "vecnormv2": 280, "gsdenois": 281, "implement_for": 282, "actorcriticoper": 283, "actorcriticwrapp": 284, "actorvalueoper": 285, "additivegaussianmodul": 286, "consistentdropoutmodul": 287, "convnet": 288, "dtactor": 289, "ddpgcnnactor": 290, "ddpgcnnqnet": 291, "ddpgmlpactor": 292, "ddpgmlpqnet": 293, "decisiontransform": 294, "delta": 295, "distributionaldqnnet": 296, "distributionalqvalueactor": 297, "distributionalqvaluemodul": 298, "dreameractor": 299, "duelingcnndqnet": 300, "egreedymodul": 301, "grumodul": 302, "independentnorm": 303, "lstmmodul": 304, "mlp": [305, 625], "maskedcategor": 306, "normalparamextractor": 307, "obsdecod": 308, "obsencod": 309, "onehotcategor": 310, "onlinedtactor": 311, "ornsteinuhlenbeckprocessmodul": 312, "qvalueactor": 313, "qvaluemodul": 314, "rssmposterior": 315, "rssmprior": 316, "rssmrollout": 317, "reparamgradientstrategi": 318, "tanhdelta": 319, "tanhnorm": 320, "truncatednorm": 321, "valueoper": 322, "worldmodelwrapp": 323, "asyncvllm": 324, "chathistori": 325, "llmwrapperbas": 326, "logprob": 327, "remotetransformerswrapp": 329, "text": [330, 635], "transformerswrapp": 332, "make_async_vllm_engin": 333, "make_vllm_work": 334, "stateless_init_process_group": 335, "stateless_init_process_group_async": 336, "vllmwrapper": 337, "squashdim": 338, "set_exploration_modules_spec_from_env": 339, "actor": [340, 602, 609, 622, 628], "multistepactorwrapp": 341, "probabilisticactor": 342, "randompolici": 343, "safemodul": [344, 602], "safeprobabilisticmodul": 345, "safeprobabilistictensordictsequenti": 346, "safesequenti": 347, "tanhmodul": 348, "a2closs": 349, "cqlloss": 350, "clipppoloss": 351, "crossqloss": 352, "ddpgloss": 353, "dqnloss": 354, "dtloss": 355, "discretecqlloss": 356, "discreteiqlloss": 357, "discretesacloss": 358, "distributionaldqnloss": 359, "dreameractorloss": 360, "dreamermodelloss": 361, "dreamervalueloss": 362, "gailloss": 363, "iqlloss": 364, "klpenppoloss": 365, "lossmodul": [366, 622, 629], "onlinedtloss": 367, "ppoloss": 368, "redqloss": 369, "reinforceloss": 370, "sacloss": 371, "td3bcloss": 372, "td3loss": 373, "valueestim": 374, "add_random_modul": 375, "cispoloss": 376, "cispolossoutput": 377, "dapo": 378, "dapolossoutput": 379, "grpoloss": 380, "grpolossoutput": 381, "llmlossoutput": 382, "mcadvantag": 383, "sftloss": 384, "sftlossoutput": 385, "gae": 386, "td0estim": 387, "td1estim": 388, "tdlambdaestim": 389, "valueestimatorbas": 390, "pixelrendertransform": 391, "tensordictrecord": 392, "videorecord": 393, "logger": [394, 619, 631, 632], "csvlogger": 395, "generate_exp_nam": 396, "get_logg": 397, "mlflowlogg": 398, "tensorboardlogg": 399, "trackiologg": 400, "wandblogg": 401, "rayservic": 402, "servicebas": 403, "get_servic": 404, "set_auto_unwrap_transformed_env": 405, "batchsubsampl": 406, "clearcudacach": 407, "countframeslog": 408, "logscalar": 409, "logvalidationreward": 410, "optimizerhook": 411, "replaybuffertrain": 412, "rewardnorm": 413, "selectkei": 414, "targetnetupdaterhook": 415, "trainer": [416, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 616, 617, 623], "trainerhookbas": 417, "utdrhook": 418, "updateweight": 419, "ppotrain": 420, "sactrain": 421, "config": [422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 643], "asynccollectorconfig": 422, "collectorconfig": 423, "multiasynccollectorconfig": 424, "multisynccollectorconfig": 425, "configbas": 426, "lazymemmapstorageconfig": 427, "lazystackstorageconfig": 428, "lazytensorstorageconfig": 429, "liststorageconfig": 430, "prioritizedsamplerconfig": 431, "randomsamplerconfig": 432, "replaybufferconfig": 433, "roundrobinwriterconfig": 434, "samplerwithoutreplacementconfig": 435, "slicesamplerconfig": 436, "slicesamplerwithoutreplacementconfig": 437, "storageensembleconfig": 438, "storageensemblewriterconfig": 439, "tensordictreplaybufferconfig": 440, "tensorstorageconfig": 441, "batchedenvconfig": 442, "envconfig": 443, "transformedenvconfig": 444, "envs_lib": [445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461], "braxenvconfig": 445, "dmcontrolenvconfig": 446, "envlibsconfig": 447, "gymenvconfig": 448, "habitatenvconfig": 449, "isaacgymenvconfig": 450, "jumanjienvconfig": 451, "mogymenvconfig": 452, "meltingpotenvconfig": 453, "multithreadedenvconfig": 454, "openmlenvconfig": 455, "openspielenvconfig": 456, "pettingzooenvconfig": 457, "robohiveenvconfig": 458, "smacv2envconfig": 459, "unitymlagentsenvconfig": 460, "vmasenvconfig": 461, "csvloggerconfig": 462, "loggerconfig": 463, "tensorboardloggerconfig": 464, "wandbloggerconfig": 465, "modul": [466, 467, 468, 469, 470, 471, 472, 601, 602, 612, 622, 625, 626, 628, 632, 643], "convnetconfig": 466, "mlpconfig": 467, "modelconfig": 468, "networkconfig": 469, "tanhnormalmodelconfig": 470, "tensordictmoduleconfig": 471, "valuemodelconfig": 472, "object": [473, 474, 594, 599, 608, 622, 629, 643], "lossconfig": 473, "ppolossconfig": 474, "ppotrainerconfig": 475, "trainerconfig": 476, "actiondiscretizerconfig": 477, "actionmaskconfig": 478, "autoresettransformconfig": 479, "batchsizetransformconfig": 480, "binarizerewardconfig": 481, "burnintransformconfig": 482, "catframesconfig": 483, "cattensorsconfig": 484, "centercropconfig": 485, "cliptransformconfig": 486, "composeconfig": 487, "conditionalpolicyswitchconfig": 488, "conditionalskipconfig": 489, "cropconfig": 490, "dtypecasttransformconfig": 491, "devicecasttransformconfig": 492, "discreteactionprojectionconfig": 493, "doubletofloatconfig": 494, "endoflifetransformconfig": 495, "excludetransformconfig": 496, "finitetensordictcheckconfig": 497, "flattenobservationconfig": 498, "frameskiptransformconfig": 499, "grayscaleconfig": 500, "hashconfig": 501, "inittrackerconfig": 502, "klrewardtransformconfig": 503, "lineariserewardsconfig": 504, "multiactionconfig": 505, "multisteptransformconfig": 506, "noopresetenvconfig": 507, "observationnormconfig": 508, "permutetransformconfig": 509, "pinmemorytransformconfig": 510, "r3mtransformconfig": 511, "randomcroptensordictconfig": 512, "removeemptyspecsconfig": 513, "renametransformconfig": 514, "resizeconfig": 515, "reward2gotransformconfig": 516, "rewardclippingconfig": 517, "rewardscalingconfig": 518, "rewardsumconfig": 519, "selecttransformconfig": 520, "signtransformconfig": 521, "squeezetransformconfig": 522, "stackconfig": 523, "stepcounterconfig": 524, "targetreturnconfig": 525, "tensordictprimerconfig": 526, "timemaxpoolconfig": 527, "timerconfig": 528, "totensorimageconfig": 529, "tokenizerconfig": 530, "trajcounterconfig": 531, "transformconfig": 532, "unarytransformconfig": 533, "unsqueezetransformconfig": 534, "vc1transformconfig": 535, "viprewardtransformconfig": 536, "viptransformconfig": 537, "vecgymenvtransformconfig": 538, "vecnormconfig": 539, "vecnormv2config": 540, "util": [541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 598, 607, 617, 619, 637], "asgdconfig": 541, "adadeltaconfig": 542, "adagradconfig": 543, "adamconfig": 544, "adamwconfig": 545, "adamaxconfig": 546, "lbfgsconfig": 547, "lionconfig": 548, "nadamconfig": 549, "radamconfig": 550, "rmspropconfig": 551, "rpropconfig": 552, "sgdconfig": 553, "sparseadamconfig": 554, "correct_for_frame_skip": 555, "get_stats_random_rollout": 556, "make_collector_offpolici": 557, "make_collector_onpolici": 558, "make_dqn_loss": 559, "make_replay_buff": 560, "make_target_updat": 561, "make_train": 562, "parallel_env_constructor": 563, "sync_async_collector": 564, "sync_sync_collector": 565, "transformed_env_constructor": 566, "distributedtransport": 567, "mptransport": 569, "noweightsyncschem": 571, "rpctransport": 572, "raytransport": 575, "sharedmemtransport": 577, "transportbackend": 579, "weightstrategi": 580, "weightsyncschem": 581, "vllmcollectivetransport": 582, "vllmdoublebuffersyncschem": 583, "vllmdoublebuffertransport": 584, "vllmdoublebufferweightreceiv": 585, "vllmdoublebufferweightsend": 586, "vllmweightreceiv": 587, "vllmweightsend": 588, "vllmweightsyncschem": 589, "get_model_metadata": 590, "readm": [591, 633], "tuto": [591, 633], "contribut": [593, 643], "content": 593, "llm": [594, 595, 597, 598, 599, 600, 634, 635], "track": 594, "deprec": 594, "integr": [594, 635, 641], "structur": [596, 598, 635, 641], "topk": 596, "selector": 596, "grpo": 599, "sft": 599, "tensordictmodul": [602, 626, 628, 643], "probabilist": [602, 628], "q": [602, 623, 625, 628], "critic": [603, 609, 637, 638], "estim": [610, 622], "other": [612, 641], "servic": 615, "registri": 615, "overview": [615, 622, 625], "registr": 615, "access": [615, 644], "cross": 615, "worker": 615, "visibl": 615, "namespac": 615, "isol": 615, "cleanup": 615, "python": 615, "executor": 615, "condit": 615, "pattern": 615, "It": 615, "consider": [615, 629], "multipl": 615, "see": 615, "hook": [617, 618, 623], "builder": 617, "_util": 620, "comput": [621, 623, 639, 642], "time": [621, 622, 642], "code": [622, 639], "ddpg": [622, 637], "setup": [622, 625, 634, 635], "The": 622, "__init__": 622, "put": 622, "togeth": [622, 639], "call": 622, "execut": [622, 634, 636, 639], "stat": 622, "build": [622, 623, 632, 634, 641], "evalu": 622, "construct": 622, "target": [622, 623, 629], "result": [622, 624, 634, 637, 638], "conclus": [622, 623, 624, 625, 626, 634, 635, 637, 638, 639, 641], "next": [622, 624, 627, 630, 637, 638, 641], "A": [623, 641], "dqn": [623, 625], "deep": 623, "paramet": [623, 624, 629], "regist": 623, "possibl": 623, "improv": 623, "reinforc": [624, 637, 638], "ppo": [624, 638], "defin": [624, 637, 638], "loop": [624, 625, 626, 632, 637, 638, 639], "recurr": [625, 626], "convolut": 625, "lstm": 625, "select": 625, "further": [625, 629], "read": 625, "export": 626, "introduct": [626, 643], "fast": 626, "recap": 626, "stochast": 626, "aotinductor": 626, "free": 626, "c": 626, "onnx": 626, "rollout": [627, 636, 637, 638, 639, 644], "s": [628, 629], "special": [628, 643], "output": 629, "first": 632, "tool": 634, "enabl": 634, "interact": 634, "4": [634, 635], "search": 634, "5": [634, 635], "extract": 634, "vllm": 635, "input": 635, "mode": 635, "probabl": 635, "onli": 635, "tensorclass": [635, 641], "6": 635, "handl": 635, "7": 635, "divers": 636, "competit": 637, "map": 637, "pendulum": 639, "write": 639, "_step": 639, "simul": 639, "_reset": 639, "metadata": 639, "_spec": 639, "shape": 639, "seed": [639, 644], "wrap": 639, "test": 639, "our": 639, "pretrain": 640, "vanilla": 641, "tensordict": [641, 643], "pytre": 641, "iter": 641, "over": 641, "fix": 641, "priorit": 641, "save": 641, "raw": 641, "imag": 641, "trajectori": 641, "sequenc": 643, "program": 643, "ensembl": 643, "meta": 643, "vmap": 643, "multiprocess": 643, "frame_skip": 644, "deepmind": 644, "control": 644, "devic": 644, "close": 644, "attribut": 644, "kwarg": 644}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 56}})
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c675b892-6412-4758-bd05-c6919740124f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torchrl.data import TensorDict\n",
    "from torchrl.data.tensordict.tensordict import TensorDictBase\n",
    "import functorch\n",
    "from torch import nn\n",
    "import torch\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "_RESET_OLD_TENSORDICT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996c25c2-bb72-447b-b2e8-25e0367094c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from functorch._src.vmap import _add_batch_dim, tree_unflatten, tree_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1c4caac-3160-4a06-a0d5-8ece79faabe0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class FunctionalModule(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the callable object returned by :func:`make_functional`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stateless_model):\n",
    "        super(FunctionalModule, self).__init__()\n",
    "        self.stateless_model = stateless_model\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_from(model, disable_autograd_tracking=False):\n",
    "        # TODO: We don't need to copy the model to create a stateless copy\n",
    "        model_copy = deepcopy(model)\n",
    "        param_tensordict = extract_weights(model_copy)\n",
    "        if disable_autograd_tracking:\n",
    "            tensordict_weights.apply(lambda x: x.requires_grad_(False), inplace=True)\n",
    "        return FunctionalModule(model_copy), param_tensordict\n",
    "\n",
    "    def forward(self, params, *args, **kwargs):\n",
    "        # Temporarily load the state back onto self.stateless_model\n",
    "        old_state = _swap_state(self.stateless_model, params, return_old_tensordict=_RESET_OLD_TENSORDICT)\n",
    "        try:\n",
    "            return self.stateless_model(*args, **kwargs)\n",
    "        finally:\n",
    "            # Remove the loaded state on self.stateless_model\n",
    "            if _RESET_OLD_TENSORDICT:\n",
    "                _swap_state(self.stateless_model, old_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1116d35-ae7f-4922-880a-b64eec6293be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_weights(model):\n",
    "    tensordict = TensorDict({}, [])\n",
    "    for name, param in list(model.named_parameters(recurse=False)):\n",
    "        setattr(model, name, None)\n",
    "        tensordict[name] = param\n",
    "    for name, module in model.named_children():\n",
    "        module_tensordict = extract_weights(module)\n",
    "        if module_tensordict is not None:\n",
    "            tensordict[name] = module_tensordict\n",
    "    if len(tensordict.keys()):\n",
    "        return tensordict\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def _swap_state(model, tensordict, return_old_tensordict=False):\n",
    "#     if return_old_tensordict:\n",
    "#         old_tensordict = tensordict.clone(recursive=False)\n",
    "#         old_tensordict.batch_size = []\n",
    "    \n",
    "    if return_old_tensordict:\n",
    "        old_tensordict = TensorDict({}, [], device=tensordict._device_safe())\n",
    "\n",
    "    for key, value in list(tensordict.items()):\n",
    "        if isinstance(value, TensorDictBase):\n",
    "            _swap_state(getattr(model, key), value)\n",
    "        else:\n",
    "            if return_old_tensordict:\n",
    "                old_attr = getattr(model, key)\n",
    "                if old_attr is None:\n",
    "                    old_attr = torch.tensor([]).view(*value.shape, 0)\n",
    "            delattr(model, key)\n",
    "            setattr(model, key, value)\n",
    "            if return_old_tensordict:\n",
    "                old_tensordict.set(key, old_attr)\n",
    "    if return_old_tensordict:\n",
    "        return old_tensordict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7dedee4-c4cf-4c44-9c19-01ed1861bf67",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (2): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(1, 2), nn.Linear(2, 3), nn.Sequential(nn.Linear(3, 4)))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2dfe604-5ecf-41b5-a29f-c13b92911852",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        0: TensorDict(\n",
      "            fields={\n",
      "                bias: Tensor(torch.Size([2]), dtype=torch.float32),\n",
      "                weight: Tensor(torch.Size([2, 1]), dtype=torch.float32)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        1: TensorDict(\n",
      "            fields={\n",
      "                bias: Tensor(torch.Size([3]), dtype=torch.float32),\n",
      "                weight: Tensor(torch.Size([3, 2]), dtype=torch.float32)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        2: TensorDict(\n",
      "            fields={\n",
      "                0: TensorDict(\n",
      "                    fields={\n",
      "                        bias: Tensor(torch.Size([4]), dtype=torch.float32),\n",
      "                        weight: Tensor(torch.Size([4, 3]), dtype=torch.float32)},\n",
      "                    batch_size=torch.Size([]),\n",
      "                    device=cpu,\n",
      "                    is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cpu,\n",
      "            is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "tensordict_weights = extract_weights(model)\n",
    "print(tensordict_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54c65da0-41e3-4fe0-bf68-ab5985ba0759",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.3050,  0.3137], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Â accessing weights\n",
    "tensordict_weights[\"0\", \"bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70b395c9-2b7d-414a-9b75-993c78da2e6d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.3050,  0.3137], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict_weights[\"0\"][\"bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95801c6c-4e8d-4586-bd76-4d8c8897db5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ade9d55-5916-4f37-ba77-e101421a2007",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        0.bias: Tensor(torch.Size([2]), dtype=torch.float32),\n",
      "        0.weight: Tensor(torch.Size([2, 1]), dtype=torch.float32),\n",
      "        1.bias: Tensor(torch.Size([3]), dtype=torch.float32),\n",
      "        1.weight: Tensor(torch.Size([3, 2]), dtype=torch.float32),\n",
      "        2.0.bias: Tensor(torch.Size([4]), dtype=torch.float32),\n",
      "        2.0.weight: Tensor(torch.Size([4, 3]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "# flatten - unflatten\n",
    "tensordict_weights_flatten = tensordict_weights.flatten_keys(separator=\".\", inplace=False)\n",
    "print(tensordict_weights_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2c93ed8-3156-4469-8f0c-e26d42bb6177",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        0: TensorDict(\n",
      "            fields={\n",
      "                bias: Tensor(torch.Size([2]), dtype=torch.float32),\n",
      "                weight: Tensor(torch.Size([2, 1]), dtype=torch.float32)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        1: TensorDict(\n",
      "            fields={\n",
      "                bias: Tensor(torch.Size([3]), dtype=torch.float32),\n",
      "                weight: Tensor(torch.Size([3, 2]), dtype=torch.float32)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        2: TensorDict(\n",
      "            fields={\n",
      "                0: TensorDict(\n",
      "                    fields={\n",
      "                        bias: Tensor(torch.Size([4]), dtype=torch.float32),\n",
      "                        weight: Tensor(torch.Size([4, 3]), dtype=torch.float32)},\n",
      "                    batch_size=torch.Size([]),\n",
      "                    device=cpu,\n",
      "                    is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cpu,\n",
      "            is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "tensordict_weights_unflatten = tensordict_weights_flatten.unflatten_keys(separator=\".\", inplace=False)\n",
    "print(tensordict_weights_unflatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98f4bb35-102b-4bb9-a717-87d8cf39ecec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchedTensor(lvl=0, bdim=0, value=\n",
       "    tensor([[-0.5027],\n",
       "            [-0.5578],\n",
       "            [ 0.0191]])\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BatchedTensor\n",
    "t = TensorDict({\"a\": torch.randn(3, 1), \"b\": TensorDict({\"c\": torch.randn(3, 1)}, [])}, [])\n",
    "t = t.apply(lambda x: _add_batch_dim(x, 0, 0))\n",
    "t[\"b\", \"c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "097c4f1f-f24b-4041-9209-2b41ccd78ae8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.3050,  0.3137])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# requires_grad to False\n",
    "tensordict_weights.apply(lambda x: x.requires_grad_(False), inplace=True)\n",
    "tensordict_weights[\"0\", \"bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f11e74e3-f0af-45dc-9e7a-b3138c4d6f10",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        0: TensorDict(\n",
       "            fields={\n",
       "                bias: Tensor(torch.Size([2]), dtype=torch.float32),\n",
       "                weight: Tensor(torch.Size([2, 1]), dtype=torch.float32)},\n",
       "            batch_size=torch.Size([]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        1: TensorDict(\n",
       "            fields={\n",
       "                bias: Tensor(torch.Size([3]), dtype=torch.float32),\n",
       "                weight: Tensor(torch.Size([3, 2]), dtype=torch.float32)},\n",
       "            batch_size=torch.Size([]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        2: TensorDict(\n",
       "            fields={\n",
       "                0: TensorDict(\n",
       "                    fields={\n",
       "                        bias: Tensor(torch.Size([4]), dtype=torch.float32),\n",
       "                        weight: Tensor(torch.Size([4, 3]), dtype=torch.float32)},\n",
       "                    batch_size=torch.Size([]),\n",
       "                    device=cpu,\n",
       "                    is_shared=False)},\n",
       "            batch_size=torch.Size([]),\n",
       "            device=cpu,\n",
       "            is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(1, 2), nn.Linear(2, 3), nn.Sequential(nn.Linear(3, 4)))\n",
    "\n",
    "fmodel, params = FunctionalModule._create_from(model)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdce2f30-cf3b-4bfd-957b-3b966f445d06",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1301,  0.8452,  0.6819, -0.7968], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmodel(params, torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2737adc2-5939-4562-a758-2c69673a07ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8535,  1.2261,  1.0852, -0.6828]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmodel(params, torch.randn(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e9c56f4-912a-41d5-ab18-ad1473c1eabb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functorch.vmap(torch.add, (0, 0))(torch.ones(10, 1), torch.ones(10, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15b8a7b3-1f4b-4b58-b875-e2b5cd436a3b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8134,  1.2813,  1.1436, -0.6662]],\n",
       "\n",
       "        [[ 0.3356,  1.9392,  1.8399, -0.4693]],\n",
       "\n",
       "        [[ 0.8799,  1.1897,  1.0466, -0.6937]],\n",
       "\n",
       "        [[ 0.7426,  1.3787,  1.2467, -0.6371]],\n",
       "\n",
       "        [[ 0.1707,  2.1663,  2.0803, -0.4013]],\n",
       "\n",
       "        [[ 0.7977,  1.3030,  1.1665, -0.6597]],\n",
       "\n",
       "        [[ 0.3470,  1.9236,  1.8234, -0.4740]],\n",
       "\n",
       "        [[ 0.5987,  1.5769,  1.4564, -0.5778]],\n",
       "\n",
       "        [[ 0.4835,  1.7356,  1.6245, -0.5302]],\n",
       "\n",
       "        [[ 1.1662,  0.7954,  0.6293, -0.8117]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10, 1, 1)\n",
    "functorch.vmap(fmodel, (None, 0))(params, x)  # works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8cb23f0-b4f3-44e2-9d7f-6480ea625d58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8134,  1.2813,  1.1436, -0.6662]],\n",
       "\n",
       "        [[ 0.3356,  1.9392,  1.8399, -0.4693]],\n",
       "\n",
       "        [[ 0.8799,  1.1897,  1.0466, -0.6937]],\n",
       "\n",
       "        [[ 0.7426,  1.3787,  1.2467, -0.6371]],\n",
       "\n",
       "        [[ 0.1707,  2.1663,  2.0803, -0.4013]],\n",
       "\n",
       "        [[ 0.7977,  1.3030,  1.1665, -0.6597]],\n",
       "\n",
       "        [[ 0.3470,  1.9236,  1.8234, -0.4740]],\n",
       "\n",
       "        [[ 0.5987,  1.5769,  1.4564, -0.5778]],\n",
       "\n",
       "        [[ 0.4835,  1.7356,  1.6245, -0.5302]],\n",
       "\n",
       "        [[ 1.1662,  0.7954,  0.6293, -0.8117]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functorch.vmap(fmodel, (0, 0))(params.expand(10), x)  # works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29d3ac4f-1984-491a-a7c1-49a9de70b3ca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460 Âµs Â± 26.4 Âµs per loop (mean Â± std. dev. of 7 runs, 1000 loops each)\n",
      "1.99 ms Â± 132 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "#Â benchmarking\n",
    "from functorch._src.make_functional import FunctionalModule as FunctionalModule_orig\n",
    "\n",
    "model = nn.Sequential(nn.Linear(1, 2), nn.Linear(2, 3), nn.Sequential(nn.Linear(3, 4)))\n",
    "%timeit FunctionalModule_orig._create_from(model)\n",
    "%timeit FunctionalModule._create_from(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f6a0de5-5cd6-4290-b105-83b5eb47cbf6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 Âµs Â± 7.79 Âµs per loop (mean Â± std. dev. of 7 runs, 1000 loops each)\n",
      "134 Âµs Â± 5.36 Âµs per loop (mean Â± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "module_orig, params_orig = FunctionalModule_orig._create_from(model)\n",
    "module, params = FunctionalModule._create_from(model)\n",
    "\n",
    "# fair comparison\n",
    "_RESET_OLD_TENSORDICT = True\n",
    "x = torch.randn(1)\n",
    "%timeit module_orig(params_orig, x)\n",
    "%timeit module(params, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "689c6b50-d113-42ff-86f2-908fe20b0497",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 Âµs Â± 12 Âµs per loop (mean Â± std. dev. of 7 runs, 1000 loops each)\n",
      "106 Âµs Â± 1.85 Âµs per loop (mean Â± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# unfair comparison -- does not swap back the params\n",
    "_RESET_OLD_TENSORDICT = False\n",
    "x = torch.randn(1)\n",
    "%timeit module_orig(params_orig, x)\n",
    "%timeit module(params, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa98f68-bdd2-4698-ab40-83f7e03d5a30",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

env:
  name: Isaac-Velocity-Flat-Anymal-C-v0
  seed: 0
  backend: isaaclab
  from_pixels: False
  # IsaacLab envs are pre-vectorized (e.g., 4096 parallel envs).
  # num_envs is controlled by IsaacLab's env config, not here.
  horizon: 1000

collector:
  # IsaacLab with 4096 envs: one env step = 4096 frames.
  # Must collect at least batch_length env steps per collection so the
  # SliceSampler can find contiguous sequences of batch_length.
  # 50 env steps * 4096 envs = 204800 frames.
  frames_per_batch: 204800
  # Must be >= frames_per_batch so we have enough data before training starts.
  init_random_frames: 204800
  # Number of gradient steps between weight syncs to collector policy.
  # Reduced from 50 because batch_size is 5x larger (50k vs 10k),
  # so each step processes more gradient signal.
  optim_steps_per_collect: 10

optimization:
  total_optim_steps: 100_000
  log_every: 100
  grad_clip: 100

  world_model_lr: 6e-4
  actor_lr: 8e-5
  value_lr: 8e-5
  kl_scale: 1.0
  free_nats: 3.0
  gamma: 0.99
  lmbda: 0.95
  imagination_horizon: 15
  compile:
    # Disabled for now: focus on getting stable training first.
    enabled: False
    backend: inductor
    cudagraphs: False
  # Autocast disabled: Dreamer's world model produces NaN grads with
  # mixed precision from iteration 1. Needs investigation.
  autocast: false

networks:
  exploration_noise: 0.3
  device:
  state_dim: 30
  rssm_hidden_dim: 200
  hidden_dim: 400
  activation: "elu"
  use_scan: False
  rssm_rollout:
    compile: False
    compile_backend: inductor
    compile_mode: reduce-overhead

replay_buffer:
  batch_size: 50000
  buffer_size: 1000000
  batch_length: 50
  scratch_dir: null
  prefetch: 32
  gpu_storage: false

logger:
  backend: wandb
  project: dreamer-isaac
  exp_name: ${env.name}-${env.seed}
  mode: online
  eval_every: 1000
  eval_rollout_steps: 500
  video: False
  video_skip: 1

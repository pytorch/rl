env:
  name: cheetah
  task: run
  seed: 0
  backend: dm_control
  frame_skip: 2
  from_pixels: True
  grayscale: False
  image_size : 64
  horizon: 500
  n_parallel_envs: 8
  device: cpu

collector:
  total_frames: 5_000_000
  init_random_frames: 3000
  frames_per_batch: 1000
  # Number of parallel collector workers (async mode)
  num_collectors: 8
  device:

optimization:
  train_every: 1000
  grad_clip: 100

  world_model_lr: 6e-4
  actor_lr: 8e-5
  value_lr: 8e-5
  kl_scale: 1.0
  free_nats: 3.0
  optim_steps_per_batch: 20
  gamma: 0.99
  lmbda: 0.95
  imagination_horizon: 15
  compile: True
  compile_backend: inductor # or cudagraphs
  compile_mode: reduce-overhead
  # Autocast options: false, true (=bfloat16), float16, bfloat16
  autocast: bfloat16

networks:
  exploration_noise: 0.3
  device:
  state_dim: 30
  rssm_hidden_dim: 200
  hidden_dim: 400
  activation: "elu"
  # Use torch.scan for RSSM rollout (faster, no graph breaks with torch.compile)
  use_scan: False


replay_buffer: 
  batch_size: 10000
  buffer_size: 1000000
  batch_length: 50
  scratch_dir: null
  prefetch: 8

logger:
  backend: wandb
  project: dreamer-v1
  exp_name: ${env.name}-${env.task}-${env.seed}
  mode: online
  # eval interval, in collection counts
  eval_iter: 10
  eval_rollout_steps: 500
  video: False

profiling:
  # Enable PyTorch profiling (overrides total_frames to profiling_total_frames)
  enabled: False
  # Total frames to collect when profiling (default: 5005 = 5 collection iters + buffer warmup)
  total_frames: 5005
  # Skip the first N optim steps (no profiling at all)
  skip_first: 1
  # Warmup steps (profiler runs but data discarded for warmup)
  warmup_steps: 1
  # Number of optim steps to profile (actual traced data)
  active_steps: 1
  # Export chrome trace to this file (if set)
  trace_file: dreamer_trace.json
  # Profile CUDA kernels (VERY heavy on GPU - 13GB vs 1GB trace!)
  profile_cuda: False
  # Record tensor shapes
  record_shapes: True
  # Profile memory usage
  profile_memory: True
  # Record Python call stacks
  with_stack: True
  # Compute FLOPs
  with_flops: True

env:
  name: cheetah
  task: run
  seed: 0
  backend: dm_control
  frame_skip: 2
  from_pixels: True
  grayscale: False
  image_size : 64
  horizon: 500
  n_parallel_envs: 8
  device: cpu

collector:
  init_random_frames: 10000
  frames_per_batch: 1000
  # Number of parallel collector workers (async mode)
  # On multi-GPU: must be <= num_gpus - 1 (cuda:0 reserved for training)
  num_collectors: 7
  device:

optimization:
  # Total number of optimization steps (the main training target)
  total_optim_steps: 100_000
  # Log metrics every N optim steps
  log_every: 100
  grad_clip: 100

  world_model_lr: 6e-4
  actor_lr: 8e-5
  value_lr: 8e-5
  kl_scale: 1.0
  free_nats: 3.0
  gamma: 0.99
  lmbda: 0.95
  imagination_horizon: 15
  compile:
    enabled: True
    backend: inductor # or cudagraphs
    mode: reduce-overhead
    # Which losses to compile (subset of: world_model, actor, value)
    losses: ["world_model", "actor", "value"]
  # Autocast options: false, true (=bfloat16), float16, bfloat16
  autocast: bfloat16

networks:
  exploration_noise: 0.3
  device:
  state_dim: 30
  rssm_hidden_dim: 200
  hidden_dim: 400
  activation: "elu"
  # Use torch.scan for RSSM rollout (faster, no graph breaks with torch.compile)
  use_scan: False
  rssm_rollout:
    # Compile only the per-timestep RSSM rollout step (keeps Python loop, avoids scan/unrolling).
    compile: False
    compile_backend: inductor
    compile_mode: reduce-overhead


replay_buffer: 
  batch_size: 10000
  buffer_size: 1000000
  batch_length: 50
  scratch_dir: null
  prefetch: 8

logger:
  backend: wandb
  project: dreamer-v1
  exp_name: ${env.name}-${env.task}-${env.seed}
  mode: online
  # eval interval, in optim steps
  eval_every: 1000
  eval_rollout_steps: 500
  # Video recording settings
  video: False
  video_skip: 1  # frames to skip (1 = record every frame, 2 = every other frame)

profiling:
  # Enable PyTorch profiling
  enabled: False
  # Total optim steps when profiling (overrides optimization.total_optim_steps)
  total_optim_steps: 50
  # Skip the first N optim steps (no profiling at all)
  skip_first: 1
  # Warmup steps (profiler runs but data discarded for warmup)
  warmup_steps: 1
  # Number of optim steps to profile (actual traced data)
  active_steps: 1
  # Export chrome trace to this file (if set)
  trace_file: dreamer_trace.json
  # Profile CUDA kernels (VERY heavy on GPU - 13GB vs 1GB trace!)
  profile_cuda: true
  # Record tensor shapes
  record_shapes: True
  # Profile memory usage
  profile_memory: True
  # Record Python call stacks
  with_stack: True
  # Compute FLOPs
  with_flops: True

# environment and task
env:
  name: HalfCheetah-v4
  task: ""
  library: gym
  stacked_frames: 20
  inference_context: 5
  n_samples_stats: 2000
  frame_skip: 1
  num_train_envs: 1
  num_eval_envs: 10
  reward_scaling: 0.001 # for r2g
  seed: 42
  target_return_mode: reduce
  eval_target_return: 6000
  collect_target_return: 12000
  backend: gym  # D4RL uses gym so we make sure gymnasium is hidden


# logger
logger:
  backend: wandb
  project_name: torchrl_example_odt
  group_name: null
  exp_name: oDT-HalfCheetah-medium-v2
  model_name: oDT
  pretrain_log_interval: 500 # record interval in frames
  finetune_log_interval: 1
  eval_steps: 1000
  video: False

# replay buffer
replay_buffer:
  dataset: halfcheetah-medium-v2
  batch_size: 256
  prb: 0
  stacked_frames: 20
  buffer_prefetch: 64
  capacity: 1_000_000
  scratch_dir:
  prefetch: 3

# optimizer
optim:
  device: null
  lr: 1.0e-4
  weight_decay: 5.0e-4
  batch_size: 256
  pretrain_gradient_steps: 10000
  updates_per_episode: 300
  warmup_steps: 10000
  clip_grad: 0.25

# loss
loss: 
  alpha_init: 0.1
  target_entropy: auto

# transformer model
transformer:
  n_embd: 512
  n_layer: 4
  n_head: 4
  n_inner: 2048 # 4*512
  activation: relu
  n_positions: 1024
  resid_pdrop: 0.1
  attn_pdrop: 0.1




<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>LLM Interface &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/pytorch.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx-design.min.css" type="text/css" />
  <link rel="stylesheet" href="../https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="VLLMWeightSyncScheme" href="generated/torchrl.weight_update.llm.VLLMWeightSyncScheme.html" />
    <link rel="prev" title="PixelRenderTransform" href="generated/torchrl.record.PixelRenderTransform.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://shiftlab.github.io/pytorch/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://shiftlab.github.io/pytorch/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/features">Features</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   
  <div>

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="../../versions.html"><span style="font-size:110%">main (0.10.0) &#x25BC</span></a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-0.html">Get started with Environments, TED and transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-1.html">Get started with TorchRL’s modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-2.html">Getting started with model optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-3.html">Get started with data collection and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-4.html">Get started with logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-5.html">Get started with your own first training loop</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/coding_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/multiagent_ppo.html">Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/torchrl_envs.html">TorchRL envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/pretrained_models.html">Using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/dqn_with_rnn.html">Recurrent DQN: Training recurrent policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/rb_tutorial.html">Using Replay Buffers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/export.html">Exporting TorchRL modules</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/multiagent_competitive_ddpg.html">Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/coding_ddpg.html">TorchRL objectives: Coding a DDPG loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/coding_dqn.html">TorchRL trainer: A DQN example</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">

      <section data-toggle="wy-nav-shift" class="pytorch-content-wrap">
        <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
          <div class="pytorch-breadcrumbs-wrapper">
            















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="index.html">API Reference</a> &gt;</li>
        
      <li>LLM Interface</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/reference/llms.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
          </div>

          <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
            Shortcuts
          </div>
        </div>

        <div class="pytorch-content-left">
    
    
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" class="pytorch-article">
              
  <section id="llm-interface">
<h1>LLM Interface<a class="headerlink" href="#llm-interface" title="Link to this heading">¶</a></h1>
<p id="ref-llms">TorchRL provides a comprehensive framework for LLM post-training and fine-tuning. The LLM API is built around five core concepts that work
together to create a complete reinforcement learning pipeline for language models.</p>
<section id="key-components">
<h2>Key Components<a class="headerlink" href="#key-components" title="Link to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p><strong>Data Structures</strong>: History class for conversation management, structured output classes</p></li>
<li><p><strong>LLM Wrappers</strong>: Unified interfaces for Transformers, vLLM, and AsyncVLLM</p></li>
<li><p><strong>Environments</strong>: ChatEnv, task-specific environments, and transforms</p></li>
<li><p><strong>Collectors</strong>: LLMCollector and RayLLMCollector for data collection</p></li>
<li><p><strong>Objectives</strong>: GRPOLoss, SFTLoss for training</p></li>
</ol>
</section>
<section id="quick-example">
<h2>Quick Example<a class="headerlink" href="#quick-example" title="Link to this heading">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchrl.modules.llm</span> <span class="kn">import</span> <span class="n">vLLMWrapper</span><span class="p">,</span> <span class="n">AsyncVLLM</span>
<span class="kn">from</span> <span class="nn">torchrl.envs.llm</span> <span class="kn">import</span> <span class="n">ChatEnv</span>
<span class="kn">from</span> <span class="nn">torchrl.collectors.llm</span> <span class="kn">import</span> <span class="n">LLMCollector</span>

<span class="c1"># Create vLLM engine</span>
<span class="n">engine</span> <span class="o">=</span> <span class="n">AsyncVLLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;Qwen/Qwen2.5-7B&quot;</span><span class="p">,</span> <span class="n">num_replicas</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">policy</span> <span class="o">=</span> <span class="n">vLLMWrapper</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">input_mode</span><span class="o">=</span><span class="s2">&quot;history&quot;</span><span class="p">)</span>

<span class="c1"># Create environment</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">ChatEnv</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>

<span class="c1"># Create collector</span>
<span class="n">collector</span> <span class="o">=</span> <span class="n">LLMCollector</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">policy</span><span class="p">,</span> <span class="n">dialog_turns_per_batch</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The LLM API is still under development and may change in the future.
Feedback, issues and PRs are welcome!</p>
</div>
</section>
<section id="documentation-sections">
<h2>Documentation Sections<a class="headerlink" href="#documentation-sections" title="Link to this heading">¶</a></h2>
<section id="policy-version-tracking">
<h3>Policy Version Tracking<a class="headerlink" href="#policy-version-tracking" title="Link to this heading">¶</a></h3>
<p>LLM Collectors also allow to track the version of the policy, which is useful for some use cases.
This is done by adding a <a class="reference internal" href="generated/torchrl.envs.llm.transforms.PolicyVersion.html#torchrl.envs.llm.transforms.PolicyVersion" title="torchrl.envs.llm.transforms.PolicyVersion"><code class="xref py py-class docutils literal notranslate"><span class="pre">PolicyVersion</span></code></a> transform to the environment, which is
then incremented by the collector after each weight update. To do this, one either provides the stateful version of the
transform, or a boolean to the collector constructor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torchrl.envs.llm.transforms</span> <span class="kn">import</span> <span class="n">PolicyVersion</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torchrl.collectors.llm</span> <span class="kn">import</span> <span class="n">LLMCollector</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torchrl.weight_update.llm</span> <span class="kn">import</span> <span class="n">VLLMWeightSyncScheme</span><span class="p">,</span> <span class="n">get_model_metadata</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">make_env</span><span class="p">()</span> <span class="c1"># place your code here</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">policy</span> <span class="o">=</span> <span class="n">make_policy</span><span class="p">()</span> <span class="c1"># place your code here</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scheme</span> <span class="o">=</span> <span class="n">VLLMWeightSyncScheme</span><span class="p">(</span><span class="n">master_port</span><span class="o">=</span><span class="mi">29500</span><span class="p">,</span> <span class="n">gpus_per_replica</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_replicas</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">collector</span> <span class="o">=</span> <span class="n">LLMCollector</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">,</span> <span class="n">weight_sync_schemes</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;policy&quot;</span><span class="p">:</span> <span class="n">scheme</span><span class="p">},</span> <span class="n">track_policy_version</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Get the sender and register model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sender</span> <span class="o">=</span> <span class="n">collector</span><span class="o">.</span><span class="n">_weight_senders</span><span class="p">[</span><span class="s2">&quot;policy&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sender</span><span class="o">.</span><span class="n">register_model</span><span class="p">(</span><span class="n">training_model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Initialize the collective group</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metadata</span> <span class="o">=</span> <span class="n">get_model_metadata</span><span class="p">(</span><span class="n">training_model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sender</span><span class="o">.</span><span class="n">init_all_workers_group</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span> <span class="n">vllm_engine</span><span class="o">=</span><span class="n">policy</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Update weights</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sender</span><span class="o">.</span><span class="n">update_weights</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">collector</span><span class="o">.</span><span class="n">policy_version_tracker</span><span class="o">.</span><span class="n">version</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># the policy version is written in the data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">collector</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;policy_version&quot;</span><span class="p">])</span>
</pre></div>
</div>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.weight_update.llm.VLLMWeightSyncScheme.html#torchrl.weight_update.llm.VLLMWeightSyncScheme" title="torchrl.weight_update.llm.VLLMWeightSyncScheme"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VLLMWeightSyncScheme</span></code></a>([master_address, ...])</p></td>
<td><p>Weight synchronization scheme for vLLM engines.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.weight_update.llm.VLLMWeightSender.html#torchrl.weight_update.llm.VLLMWeightSender" title="torchrl.weight_update.llm.VLLMWeightSender"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VLLMWeightSender</span></code></a>(scheme)</p></td>
<td><p>Sends weights to vLLM workers using collective communication.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.weight_update.llm.VLLMWeightReceiver.html#torchrl.weight_update.llm.VLLMWeightReceiver" title="torchrl.weight_update.llm.VLLMWeightReceiver"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VLLMWeightReceiver</span></code></a>(scheme, vllm_engine)</p></td>
<td><p>Receives weights in a vLLM worker using collective communication.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.weight_update.llm.VLLMCollectiveTransport.html#torchrl.weight_update.llm.VLLMCollectiveTransport" title="torchrl.weight_update.llm.VLLMCollectiveTransport"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VLLMCollectiveTransport</span></code></a>(master_address, ...)</p></td>
<td><p>Transport for vLLM using collective communication (NCCL).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme.html#torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme" title="torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VLLMDoubleBufferSyncScheme</span></code></a>(remote_addr[, ...])</p></td>
<td><p>Weight synchronization scheme for vLLM using double-buffered storage.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightSender.html#torchrl.weight_update.llm.VLLMDoubleBufferWeightSender" title="torchrl.weight_update.llm.VLLMDoubleBufferWeightSender"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VLLMDoubleBufferWeightSender</span></code></a>(scheme)</p></td>
<td><p>Sends weights to vLLM workers using double-buffered storage.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver.html#torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver" title="torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VLLMDoubleBufferWeightReceiver</span></code></a>(scheme, ...)</p></td>
<td><p>Receives weights in a vLLM worker using double-buffered storage.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.weight_update.llm.VLLMDoubleBufferTransport.html#torchrl.weight_update.llm.VLLMDoubleBufferTransport" title="torchrl.weight_update.llm.VLLMDoubleBufferTransport"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VLLMDoubleBufferTransport</span></code></a>(remote_addr[, ...])</p></td>
<td><p>Transport for vLLM using double-buffered memory-mapped storage.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.weight_update.llm.get_model_metadata.html#torchrl.weight_update.llm.get_model_metadata" title="torchrl.weight_update.llm.get_model_metadata"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_model_metadata</span></code></a>(model)</p></td>
<td><p>Extract model metadata from a model.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="legacy-weight-updaters-deprecated">
<h3>Legacy Weight Updaters (Deprecated)<a class="headerlink" href="#legacy-weight-updaters-deprecated" title="Link to this heading">¶</a></h3>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 0.11: </span>The <cite>vLLMUpdater</cite> and <cite>vLLMUpdaterV2</cite> classes are deprecated in favor of the new weight synchronization schemes
(<a class="reference internal" href="generated/torchrl.weight_update.llm.VLLMWeightSyncScheme.html#torchrl.weight_update.llm.VLLMWeightSyncScheme" title="torchrl.weight_update.llm.VLLMWeightSyncScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">VLLMWeightSyncScheme</span></code></a> and <a class="reference internal" href="generated/torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme.html#torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme" title="torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">VLLMDoubleBufferSyncScheme</span></code></a>).
These schemes provide better performance, more flexibility, and cleaner integration with collectors.
The legacy updaters will be removed in a future release.</p>
<p>The legacy weight updaters (<cite>vLLMUpdater</cite> and <cite>vLLMUpdaterV2</cite>) are still available but are no longer recommended.
Please migrate to the new weight synchronization schemes shown above.</p>
</div>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.collectors.llm.vLLMUpdater.html#torchrl.collectors.llm.vLLMUpdater" title="torchrl.collectors.llm.vLLMUpdater"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vLLMUpdater</span></code></a>(*args[, v2])</p></td>
<td><p>A class that sends weights to vLLM workers.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.collectors.llm.vLLMUpdaterV2.html#torchrl.collectors.llm.vLLMUpdaterV2" title="torchrl.collectors.llm.vLLMUpdaterV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vLLMUpdaterV2</span></code></a>(vllm_engine)</p></td>
<td><p>Simplified vLLM weight updater using the RLvLLMEngine interface.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.collectors.llm.LLMCollector.html#torchrl.collectors.llm.LLMCollector" title="torchrl.collectors.llm.LLMCollector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LLMCollector</span></code></a>(env, *[, policy, ...])</p></td>
<td><p>A simplified version of Collector for LLM inference.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.collectors.llm.RayLLMCollector.html#torchrl.collectors.llm.RayLLMCollector" title="torchrl.collectors.llm.RayLLMCollector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RayLLMCollector</span></code></a>(env, *[, policy, ...])</p></td>
<td><p>A lightweight Ray implementation of the LLM Collector that can be extended and sampled remotely.</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="environments">
<h2>Environments<a class="headerlink" href="#environments" title="Link to this heading">¶</a></h2>
<p>The environment layer orchestrates data loading, tool execution, reward computation, and formatting. When fine-tuning an LLM using TorchRL, the environment is a
crucial component of the inference pipeline, alongside the policy and collector.</p>
<section id="chatenv">
<h3>ChatEnv<a class="headerlink" href="#chatenv" title="Link to this heading">¶</a></h3>
<p><a class="reference internal" href="generated/torchrl.envs.llm.ChatEnv.html#torchrl.envs.llm.ChatEnv" title="torchrl.envs.llm.ChatEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ChatEnv</span></code></a> serves as a blank canvas for LLM environments - it’s a basic tool designed to be extended with transforms that add
specific functionality. The base ChatEnv provides the fundamental structure for managing conversation state using the
<a class="reference internal" href="generated/torchrl.data.llm.History.html#torchrl.data.llm.History" title="torchrl.data.llm.History"><code class="xref py py-class docutils literal notranslate"><span class="pre">History</span></code></a> format, but it’s intentionally minimal to allow maximum flexibility.</p>
<section id="core-functionality">
<h4>Core Functionality<a class="headerlink" href="#core-functionality" title="Link to this heading">¶</a></h4>
<p>ChatEnv operates in three main modes:
- <strong>History mode</strong>: Uses <a class="reference internal" href="generated/torchrl.data.llm.History.html#torchrl.data.llm.History" title="torchrl.data.llm.History"><code class="xref py py-class docutils literal notranslate"><span class="pre">History</span></code></a> objects for conversation management
- <strong>Text mode</strong>: Uses simple text strings for input/output
- <strong>Tokens mode</strong>: Uses tokenized data for input/output</p>
<p>The environment maintains conversation state by:
- <strong>Reset</strong>: Initializes a new conversation with an optional system prompt
- <strong>Step</strong>: Takes the LLM’s response and updates the conversation history, preparing the next prompt</p>
</section>
<section id="transform-based-architecture">
<h4>Transform-Based Architecture<a class="headerlink" href="#transform-based-architecture" title="Link to this heading">¶</a></h4>
<p>Transforms are the main way to extend ChatEnv with specific capabilities:</p>
<ul class="simple">
<li><p><strong>Reward computation</strong>: <a class="reference internal" href="generated/torchrl.envs.llm.transforms.KLRewardTransform.html#torchrl.envs.llm.transforms.KLRewardTransform" title="torchrl.envs.llm.transforms.KLRewardTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">KLRewardTransform</span></code></a> for KL divergence rewards</p></li>
<li><p><strong>Tool execution</strong>: <a class="reference internal" href="generated/torchrl.envs.llm.transforms.PythonInterpreter.html#torchrl.envs.llm.transforms.PythonInterpreter" title="torchrl.envs.llm.transforms.PythonInterpreter"><code class="xref py py-class docutils literal notranslate"><span class="pre">PythonInterpreter</span></code></a> for Python code
execution, <a class="reference internal" href="generated/torchrl.envs.llm.transforms.MCPToolTransform.html#torchrl.envs.llm.transforms.MCPToolTransform" title="torchrl.envs.llm.transforms.MCPToolTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCPToolTransform</span></code></a> for general tool calling.</p></li>
<li><p><strong>Data loading</strong>: <a class="reference internal" href="generated/torchrl.envs.llm.transforms.DataLoadingPrimer.html#torchrl.envs.llm.transforms.DataLoadingPrimer" title="torchrl.envs.llm.transforms.DataLoadingPrimer"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoadingPrimer</span></code></a> for loading prompts from datasets</p></li>
<li><p><strong>Thinking prompts</strong>: <a class="reference internal" href="generated/torchrl.envs.llm.transforms.AddThinkingPrompt.html#torchrl.envs.llm.transforms.AddThinkingPrompt" title="torchrl.envs.llm.transforms.AddThinkingPrompt"><code class="xref py py-class docutils literal notranslate"><span class="pre">AddThinkingPrompt</span></code></a> for chain-of-thought reasoning</p></li>
<li><p><strong>Policy tracking</strong>: <a class="reference internal" href="generated/torchrl.envs.llm.transforms.PolicyVersion.html#torchrl.envs.llm.transforms.PolicyVersion" title="torchrl.envs.llm.transforms.PolicyVersion"><code class="xref py py-class docutils literal notranslate"><span class="pre">PolicyVersion</span></code></a> for version control</p></li>
<li><p><strong>Step counting</strong>: Built-in step tracking and reset management using <a class="reference internal" href="generated/torchrl.envs.transforms.StepCounter.html#torchrl.envs.transforms.StepCounter" title="torchrl.envs.transforms.StepCounter"><code class="xref py py-class docutils literal notranslate"><span class="pre">StepCounter</span></code></a>.</p></li>
</ul>
</section>
<section id="integration-with-llm-wrappers">
<h4>Integration with LLM Wrappers<a class="headerlink" href="#integration-with-llm-wrappers" title="Link to this heading">¶</a></h4>
<p id="ref-env-llm-step">ChatEnv is designed to work seamlessly with both <a class="reference internal" href="generated/torchrl.modules.llm.TransformersWrapper.html#torchrl.modules.llm.TransformersWrapper" title="torchrl.modules.llm.TransformersWrapper"><code class="xref py py-class docutils literal notranslate"><span class="pre">TransformersWrapper</span></code></a> and <a class="reference internal" href="generated/torchrl.modules.llm.vLLMWrapper.html#torchrl.modules.llm.vLLMWrapper" title="torchrl.modules.llm.vLLMWrapper"><code class="xref py py-class docutils literal notranslate"><span class="pre">vLLMWrapper</span></code></a>.
The environment handles the conversation state management while the wrapper handles the actual LLM inference, creating a clean separation of concerns.</p>
<p>On each call to <cite>step</cite>, the environment:</p>
<ul class="simple">
<li><p>Takes the LLM’s output, specifically the <cite>full</cite> field, which contains the entire conversation so far, including the new response (e.g., <cite>history.full</cite>, <cite>text.full</cite>, <cite>tokens.full</cite>).</p></li>
<li><p>Sets this <cite>full</cite> field as the new <cite>prompt</cite> for the next LLM step (e.g., <cite>td[“next”, “history”].prompt</cite>, <cite>td[“next”, “text”].prompt</cite>, <cite>td[“next”, “tokens”].prompt</cite>).</p></li>
<li><p>Optionally, applies transforms to insert new user messages, tool calls, or other modifications to the conversation before the next LLM step to refine the prompt.</p></li>
</ul>
<p>This mechanism enables seamless multi-turn interactions and supports complex workflows such as tool use and reward shaping.</p>
</section>
</section>
<section id="task-specific-environments">
<h3>Task-Specific Environments<a class="headerlink" href="#task-specific-environments" title="Link to this heading">¶</a></h3>
<p>We provide a few task-specific environments, such as <a class="reference internal" href="generated/torchrl.envs.llm.GSM8KEnv.html#torchrl.envs.llm.GSM8KEnv" title="torchrl.envs.llm.GSM8KEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">GSM8KEnv</span></code></a> for the GSM8K dataset,
<a class="reference internal" href="generated/torchrl.envs.llm.IFEvalEnv.html#torchrl.envs.llm.IFEvalEnv" title="torchrl.envs.llm.IFEvalEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">IFEvalEnv</span></code></a> for the IFEval dataset, and <code class="xref py py-class docutils literal notranslate"><span class="pre">MLGymEnv</span></code> for MLGym integration.</p>
<p>These environments wrap a <a class="reference internal" href="generated/torchrl.envs.llm.ChatEnv.html#torchrl.envs.llm.ChatEnv" title="torchrl.envs.llm.ChatEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ChatEnv</span></code></a> and add a <a class="reference internal" href="generated/torchrl.envs.llm.transforms.DataLoadingPrimer.html#torchrl.envs.llm.transforms.DataLoadingPrimer" title="torchrl.envs.llm.transforms.DataLoadingPrimer"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoadingPrimer</span></code></a> transform
(plus an optional reward parsing transform) in a <code class="xref py py-class docutils literal notranslate"><span class="pre">TransformedEnv</span></code> class.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.ChatEnv.html#torchrl.envs.llm.ChatEnv" title="torchrl.envs.llm.ChatEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ChatEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>A chat-based environment for LLMs, designed as a blank canvas for conversation and RL.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.DatasetChatEnv.html#torchrl.envs.llm.DatasetChatEnv" title="torchrl.envs.llm.DatasetChatEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DatasetChatEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>Base class for chat environment with queries pulled from a dataset.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.GSM8KEnv.html#torchrl.envs.llm.GSM8KEnv" title="torchrl.envs.llm.GSM8KEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GSM8KEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>GSM8K dataset environment.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.make_gsm8k_env.html#torchrl.envs.llm.make_gsm8k_env" title="torchrl.envs.llm.make_gsm8k_env"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_gsm8k_env</span></code></a>([dataset, num_envs, repeats, ...])</p></td>
<td><p>A builder for an LLMEnv-based GSM8K environment.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.GSM8KPrepareQuestion.html#torchrl.envs.llm.GSM8KPrepareQuestion" title="torchrl.envs.llm.GSM8KPrepareQuestion"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GSM8KPrepareQuestion</span></code></a>([in_keys, out_keys])</p></td>
<td><p>A transform to prepare the prompt when using GSM8k within an LLMEnv.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.IFEvalEnv.html#torchrl.envs.llm.IFEvalEnv" title="torchrl.envs.llm.IFEvalEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">IFEvalEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>A chat environment based on the IFEval dataset.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.IfEvalScorer.html#torchrl.envs.llm.IfEvalScorer" title="torchrl.envs.llm.IfEvalScorer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">IfEvalScorer</span></code></a>(*[, instruction_ids_key, ...])</p></td>
<td><p>Scorer for the IF-Eval task.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.IFEvalScoreData.html#torchrl.envs.llm.IFEvalScoreData" title="torchrl.envs.llm.IFEvalScoreData"><code class="xref py py-obj docutils literal notranslate"><span class="pre">IFEvalScoreData</span></code></a>(prompt_level_strict_acc, ...)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.LLMEnv.html#torchrl.envs.llm.LLMEnv" title="torchrl.envs.llm.LLMEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LLMEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>A text generation environment for language models.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.LLMHashingEnv.html#torchrl.envs.llm.LLMHashingEnv" title="torchrl.envs.llm.LLMHashingEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LLMHashingEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>A text generation environment that uses a hashing module to identify unique observations.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.make_mlgym.html#torchrl.envs.llm.make_mlgym" title="torchrl.envs.llm.make_mlgym"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_mlgym</span></code></a>(*[, task, tasks, tokenizer, ...])</p></td>
<td><p>Wraps an MLGymEnv in a TorchRL Environment.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.MLGymWrapper.html#torchrl.envs.llm.MLGymWrapper" title="torchrl.envs.llm.MLGymWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MLGymWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>A thin wrapper for MLGym environments.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.GSM8KRewardParser.html#torchrl.envs.llm.GSM8KRewardParser" title="torchrl.envs.llm.GSM8KRewardParser"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GSM8KRewardParser</span></code></a>(tokenizer[, in_keys, ...])</p></td>
<td><p>Reward parser for GSM8KEnv or make_gsm8k_env.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="transforms">
<h3>Transforms<a class="headerlink" href="#transforms" title="Link to this heading">¶</a></h3>
<p>Transforms are used to modify the data before it is passed to the LLM.
Tools are usually implemented as transforms, and appended to a base environment
such as <a class="reference internal" href="generated/torchrl.envs.llm.ChatEnv.html#torchrl.envs.llm.ChatEnv" title="torchrl.envs.llm.ChatEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ChatEnv</span></code></a>.</p>
<p>An example of a tool transform is the <a class="reference internal" href="generated/torchrl.envs.llm.transforms.PythonInterpreter.html#torchrl.envs.llm.transforms.PythonInterpreter" title="torchrl.envs.llm.transforms.PythonInterpreter"><code class="xref py py-class docutils literal notranslate"><span class="pre">PythonInterpreter</span></code></a> transform, which is used
to execute Python code in the context of the LLM. The PythonInterpreter can optionally use a shared
<a class="reference internal" href="generated/torchrl.envs.llm.transforms.PythonExecutorService.html#torchrl.envs.llm.transforms.PythonExecutorService" title="torchrl.envs.llm.transforms.PythonExecutorService"><code class="xref py py-class docutils literal notranslate"><span class="pre">PythonExecutorService</span></code></a> for efficient resource usage across multiple environments.
See <a class="reference internal" href="services.html"><span class="doc">Service Registry</span></a> for more details on the service registry system.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torchrl.envs.llm.transforms</span> <span class="kn">import</span> <span class="n">PythonInterpreter</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torchrl.envs.llm</span> <span class="kn">import</span> <span class="n">ChatEnv</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensordict</span> <span class="kn">import</span> <span class="n">TensorDict</span><span class="p">,</span> <span class="n">set_list_to_stack</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_list_to_stack</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;Qwen/Qwen2.5-7B-Instruct&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">base_env</span> <span class="o">=</span> <span class="n">ChatEnv</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">system_prompt</span><span class="o">=</span><span class="s2">&quot;You are an assistant that can execute Python code. Decorate your code with ```python``` tags.&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">user_role</span><span class="o">=</span><span class="s2">&quot;user&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">system_role</span><span class="o">=</span><span class="s2">&quot;system&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">batch_size</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">base_env</span><span class="o">.</span><span class="n">append_transform</span><span class="p">(</span><span class="n">PythonInterpreter</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Pass the reset data - the prompt - to the environment</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reset_data</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">TensorDict</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">text</span><span class="o">=</span><span class="s2">&quot;Let&#39;s write a Python function that returns the square of a number.&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">batch_size</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Simulate an action - i.e., a response from the LLM (as if we were an LLM)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">action</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Here is a block of code to be executed in python:</span>
<span class="gp">... </span><span class="s2">```python</span>
<span class="gp">... </span><span class="s2">def square(x):</span>
<span class="gp">... </span><span class="s2">    return x * x</span>
<span class="gp">... </span><span class="s2">print(&#39;testing the square function with input 2:&#39;, square(2))</span>
<span class="gp">... </span><span class="s2">```</span>
<span class="gp">... </span><span class="s2">&lt;|im_end|&gt;</span>
<span class="gp">... </span><span class="s2">&quot;&quot;&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">step_data</span> <span class="o">=</span> <span class="n">reset_data</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;text_response&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">action</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="p">,</span> <span class="n">s_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step_and_maybe_reset</span><span class="p">(</span><span class="n">reset_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The history is a stack of chat messages.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#  The python interpreter transform has executed the code in the last message.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pprint</span><span class="p">(</span><span class="n">s_</span><span class="p">[</span><span class="s2">&quot;history&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">))</span>
<span class="go">[&#39;&lt;|im_start|&gt;system\n&#39;</span>
<span class="go"> &#39;You are an assistant that can execute Python code. Decorate your code with &#39;</span>
<span class="go"> &#39;```python``` tags.&lt;|im_end|&gt;\n&#39;</span>
<span class="go"> &#39;&lt;|im_start|&gt;user\n&#39;</span>
<span class="go"> &quot;Let&#39;s write a Python function that returns the square of a &quot;</span>
<span class="go"> &#39;number.&lt;|im_end|&gt;\n&#39;</span>
<span class="go"> &#39;&lt;|im_start|&gt;assistant\n&#39;</span>
<span class="go"> &#39;Here is a block of code to be executed in python:\n&#39;</span>
<span class="go"> &#39;```python\n&#39;</span>
<span class="go"> &#39;def square(x):\n&#39;</span>
<span class="go"> &#39;    return x * x\n&#39;</span>
<span class="go"> &quot;print(&#39;testing the square function with input 2:&#39;, square(2))\n&quot;</span>
<span class="go"> &#39;```&lt;|im_end|&gt;\n&#39;</span>
<span class="go"> &#39;&lt;|im_start|&gt;user\n&#39;</span>
<span class="go"> &#39;&lt;tool_response&gt;\n&#39;</span>
<span class="go"> &#39;Code block 1 executed successfully:\n&#39;</span>
<span class="go"> &#39;testing the square function with input 2: 4\n&#39;</span>
<span class="go"> &#39;\n&#39;</span>
<span class="go"> &#39;&lt;/tool_response&gt;&lt;|im_end|&gt;\n&#39;</span>
<span class="go"> &#39;&lt;|im_start|&gt;assistant\n&#39;]</span>
</pre></div>
</div>
<p>Similarly, environments that load data from a dataset are just special instances of the <a class="reference internal" href="generated/torchrl.envs.llm.ChatEnv.html#torchrl.envs.llm.ChatEnv" title="torchrl.envs.llm.ChatEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ChatEnv</span></code></a>
augmented with a <a class="reference internal" href="generated/torchrl.envs.llm.transforms.DataLoadingPrimer.html#torchrl.envs.llm.transforms.DataLoadingPrimer" title="torchrl.envs.llm.transforms.DataLoadingPrimer"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoadingPrimer</span></code></a> transforms (and some dedicated reward parsing
transforms).</p>
<section id="designing-reward-transforms">
<h4>Designing Reward Transforms<a class="headerlink" href="#designing-reward-transforms" title="Link to this heading">¶</a></h4>
<p>When designing reward transforms for LLM environments, several key considerations must be
addressed to ensure proper integration with the training pipeline.
The examples of <a class="reference internal" href="generated/torchrl.envs.llm.GSM8KRewardParser.html#torchrl.envs.llm.GSM8KRewardParser" title="torchrl.envs.llm.GSM8KRewardParser"><code class="xref py py-class docutils literal notranslate"><span class="pre">GSM8KRewardParser</span></code></a> and
<a class="reference internal" href="generated/torchrl.envs.llm.IfEvalScorer.html#torchrl.envs.llm.IfEvalScorer" title="torchrl.envs.llm.IfEvalScorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">IfEvalScorer</span></code></a> provide excellent templates for reward transform design.</p>
<p><strong>Reward Shape Requirements</strong></p>
<p>The reward tensor must have the same number of dimensions as the logits, which is typically
two more dimensions than the environment batch size:</p>
<ul class="simple">
<li><p><strong>Sparse rewards</strong>: Shape <code class="docutils literal notranslate"><span class="pre">(*bsz,</span> <span class="pre">1,</span> <span class="pre">1)</span></code> - single reward per sequence</p></li>
<li><p><strong>Dense rewards</strong>: Shape <code class="docutils literal notranslate"><span class="pre">(*bsz,</span> <span class="pre">num_tokens,</span> <span class="pre">1)</span></code> - per-token rewards</p></li>
</ul>
<p>This shape requirement ensures compatibility with the loss computation pipeline.
For example, in the GSM8K reward parser:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Rewards need to have shape broadcastable to [batch x tokens x 1]</span>
<span class="n">tds</span> <span class="o">=</span> <span class="n">tds</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<p><strong>Done State Management</strong></p>
<p>It is crucial to properly manage the done state to prevent endless generation. Common strategies include:</p>
<ol class="arabic simple">
<li><p><strong>Completion-based termination</strong>: Set done when the response is complete (e.g., <code class="docutils literal notranslate"><span class="pre">History.complete=True</span></code>)</p></li>
<li><p><strong>Content-based termination</strong>: Set done when specific content is detected (e.g., <code class="docutils literal notranslate"><span class="pre">&lt;answer&gt;</span></code> blocks)</p></li>
<li><p><strong>Step-based termination</strong>: Use <a class="reference internal" href="generated/torchrl.envs.transforms.StepCounter.html#torchrl.envs.transforms.StepCounter" title="torchrl.envs.transforms.StepCounter"><code class="xref py py-class docutils literal notranslate"><span class="pre">StepCounter</span></code></a> for predetermined step limits</p></li>
</ol>
<p>Example from IFEvalScorer:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">set_done_if_answer</span> <span class="ow">and</span> <span class="nb">bool</span><span class="p">(</span><span class="n">answer_blocks</span><span class="p">):</span>
    <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;done&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="o">...</span><span class="p">))</span>
    <span class="n">next_tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;terminated&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="o">...</span><span class="p">))</span>
</pre></div>
</div>
<p><strong>Input Mode Handling</strong></p>
<p>Reward transforms must handle different input modes correctly:</p>
<ul class="simple">
<li><p><strong>History mode</strong>: Extract text from <code class="docutils literal notranslate"><span class="pre">(&quot;history&quot;,</span> <span class="pre">&quot;full&quot;)</span></code> or <code class="docutils literal notranslate"><span class="pre">(&quot;history&quot;,</span> <span class="pre">&quot;response&quot;)</span></code></p></li>
<li><p><strong>Text mode</strong>: Use text directly from <code class="docutils literal notranslate"><span class="pre">(&quot;text&quot;,</span> <span class="pre">&quot;full&quot;)</span></code> or <code class="docutils literal notranslate"><span class="pre">(&quot;text&quot;,</span> <span class="pre">&quot;response&quot;)</span></code></p></li>
<li><p><strong>Tokens mode</strong>: Decode tokens from <code class="docutils literal notranslate"><span class="pre">(&quot;tokens&quot;,</span> <span class="pre">&quot;full&quot;)</span></code> or <code class="docutils literal notranslate"><span class="pre">(&quot;tokens&quot;,</span> <span class="pre">&quot;response&quot;)</span></code></p></li>
</ul>
<p>The GSM8K reward parser demonstrates this pattern:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">input_mode</span> <span class="o">==</span> <span class="s2">&quot;history&quot;</span><span class="p">:</span>
    <span class="n">responses</span> <span class="o">=</span> <span class="n">lazy_stack</span><span class="p">([</span><span class="n">r</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">responses</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">)])</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">responses</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">):</span>
        <span class="n">text_completion</span> <span class="o">=</span> <span class="n">responses</span><span class="o">.</span><span class="n">content</span>
<span class="k">elif</span> <span class="n">input_mode</span> <span class="o">==</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span>
    <span class="n">text_completion</span> <span class="o">=</span> <span class="n">responses</span>
<span class="k">elif</span> <span class="n">input_mode</span> <span class="o">==</span> <span class="s2">&quot;tokens&quot;</span><span class="p">:</span>
    <span class="n">text_completion</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">responses</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</pre></div>
</div>
<p><strong>Specification Management</strong></p>
<p>Accurate specification of reward and observation specs is essential for proper environment initialization. Both GSM8K and IFEval provide good examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transform_reward_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward_spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">reward_spec</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">reward_spec</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="n">Composite</span><span class="p">(</span>
            <span class="n">reward_answer</span><span class="o">=</span><span class="n">Unbounded</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span>
            <span class="n">reward_think</span><span class="o">=</span><span class="n">Unbounded</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span>
            <span class="n">reward_right</span><span class="o">=</span><span class="n">Unbounded</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span>
            <span class="n">reward_contained</span><span class="o">=</span><span class="n">Unbounded</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span>
            <span class="n">reward</span><span class="o">=</span><span class="n">Unbounded</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span>
            <span class="n">success</span><span class="o">=</span><span class="n">Unbounded</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">),</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">reward_spec</span>
</pre></div>
</div>
<p><strong>Batch Processing Considerations</strong></p>
<p>For efficient processing, handle batched data appropriately:</p>
<ol class="arabic simple">
<li><p><strong>Flatten batch dimensions</strong>: Use <code class="docutils literal notranslate"><span class="pre">tensordict.view(-1)</span></code> for processing</p></li>
<li><p><strong>Reshape results</strong>: Restore original batch structure after processing</p></li>
<li><p><strong>Handle variable-length sequences</strong>: Use proper padding and masking</p></li>
</ol>
<p><strong>Reward Aggregation Strategies</strong></p>
<p>Consider different reward aggregation approaches:</p>
<ol class="arabic simple">
<li><p><strong>Simple aggregation</strong>: Sum or average multiple reward components</p></li>
<li><p><strong>Weighted aggregation</strong>: Apply different weights to different components</p></li>
<li><p><strong>Conditional rewards</strong>: Base rewards on specific conditions or thresholds</p></li>
</ol>
<p>The IFEvalScorer demonstrates a sophisticated aggregation strategy:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">default_reward_aggregator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">score</span><span class="p">:</span> <span class="n">IFEvalScoreData</span><span class="p">,</span> <span class="o">...</span><span class="p">):</span>
    <span class="c1"># Format score (max 1.0)</span>
    <span class="n">format_score</span> <span class="o">=</span> <span class="p">(</span><span class="n">format_components</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Structure score (max 1.0)</span>
    <span class="n">structure_score</span> <span class="o">=</span> <span class="n">think_score</span> <span class="o">+</span> <span class="n">answer_score</span>

    <span class="c1"># Completion bonus (max 0.2)</span>
    <span class="n">completion_bonus</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">complete</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.2</span>

    <span class="k">return</span> <span class="n">format_score</span> <span class="o">+</span> <span class="n">structure_score</span> <span class="o">+</span> <span class="n">completion_bonus</span>
</pre></div>
</div>
<p><strong>Post-Processing in Replay Buffers</strong></p>
<p>Rewards can also be computed after the fact by appending transforms to the replay buffer. However, done state capture must remain in the environment transform since it needs to occur on-the-fly during data collection.</p>
<p><strong>Error Handling and Robustness</strong></p>
<p>Implement robust error handling for parsing failures:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="n">cot</span><span class="p">,</span> <span class="n">potential_answer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_tags</span><span class="p">(</span><span class="n">compl</span><span class="p">)</span>
<span class="k">except</span> <span class="n">ET</span><span class="o">.</span><span class="n">ParseError</span><span class="p">:</span>
    <span class="n">cot</span><span class="p">,</span> <span class="n">potential_answer</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Performance Considerations</strong></p>
<ol class="arabic simple">
<li><p><strong>Avoid redundant computations</strong>: Cache parsed results when possible</p></li>
<li><p><strong>Use efficient text processing</strong>: Leverage regex or XML parsing as appropriate</p></li>
<li><p><strong>Minimize memory allocations</strong>: Reuse tensors and avoid unnecessary copies</p></li>
</ol>
<p>By following these design principles, reward transforms can be effectively integrated into the LLM training pipeline while maintaining performance and reliability.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.transforms.AddThinkingPrompt.html#torchrl.envs.llm.transforms.AddThinkingPrompt" title="torchrl.envs.llm.transforms.AddThinkingPrompt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AddThinkingPrompt</span></code></a>(cond[, prompt, ...])</p></td>
<td><p>A transform that adds thinking prompts to encourage the LLM to reconsider its response.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.transforms.BrowserTransform.html#torchrl.envs.llm.transforms.BrowserTransform" title="torchrl.envs.llm.transforms.BrowserTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BrowserTransform</span></code></a>([allowed_domains, ...])</p></td>
<td><p>A transform that enables web browsing capabilities.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.transforms.DataLoadingPrimer.html#torchrl.envs.llm.transforms.DataLoadingPrimer" title="torchrl.envs.llm.transforms.DataLoadingPrimer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataLoadingPrimer</span></code></a>(*args[, use_ray_service])</p></td>
<td><p>A primer that loads data from a dataloader and converts it into a tensordict using <code class="docutils literal notranslate"><span class="pre">stack_method</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.transforms.KLComputation.html#torchrl.envs.llm.transforms.KLComputation" title="torchrl.envs.llm.transforms.KLComputation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KLComputation</span></code></a>([gen_log_probs_full_key, ...])</p></td>
<td><p>A transform to compute KL divergence between two log-prob tensors and optionally add it to the reward.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.transforms.KLRewardTransform.html#torchrl.envs.llm.transforms.KLRewardTransform" title="torchrl.envs.llm.transforms.KLRewardTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KLRewardTransform</span></code></a>(*args[, use_ray_service])</p></td>
<td><p>A legacy transform for computing KL divergence-based rewards.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.transforms.MCPToolTransform.html#torchrl.envs.llm.transforms.MCPToolTransform" title="torchrl.envs.llm.transforms.MCPToolTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MCPToolTransform</span></code></a>(servers[, ...])</p></td>
<td><p>A transform that executes tools via the Model Context Protocol (MCP).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.transforms.PolicyVersion.html#torchrl.envs.llm.transforms.PolicyVersion" title="torchrl.envs.llm.transforms.PolicyVersion"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PolicyVersion</span></code></a>(version_type, ] =)</p></td>
<td><p>A transform that keeps track of the version of the policy.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.transforms.PythonExecutorService.html#torchrl.envs.llm.transforms.PythonExecutorService" title="torchrl.envs.llm.transforms.PythonExecutorService"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PythonExecutorService</span></code></a>([pool_size, timeout])</p></td>
<td><p>Ray actor that manages a pool of persistent Python interpreters.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.transforms.PythonInterpreter.html#torchrl.envs.llm.transforms.PythonInterpreter" title="torchrl.envs.llm.transforms.PythonInterpreter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PythonInterpreter</span></code></a>([tokenizer, tool_name, ...])</p></td>
<td><p>A transform that executes Python code in the LLM response.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.transforms.RayDataLoadingPrimer.html#torchrl.envs.llm.transforms.RayDataLoadingPrimer" title="torchrl.envs.llm.transforms.RayDataLoadingPrimer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RayDataLoadingPrimer</span></code></a>(*[, dataloader, ...])</p></td>
<td><p>A <a class="reference internal" href="generated/torchrl.envs.llm.transforms.DataLoadingPrimer.html#torchrl.envs.llm.transforms.DataLoadingPrimer" title="torchrl.envs.llm.transforms.dataloading.DataLoadingPrimer"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoadingPrimer</span></code></a> that creates a single actor that can be shared by multiple environments.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.transforms.RetrieveKL.html#torchrl.envs.llm.transforms.RetrieveKL" title="torchrl.envs.llm.transforms.RetrieveKL"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RetrieveKL</span></code></a>(*args[, use_ray_service])</p></td>
<td><p>A transform to retrieve the KL divergence between two models' log-probabilities.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.transforms.RetrieveLogProb.html#torchrl.envs.llm.transforms.RetrieveLogProb" title="torchrl.envs.llm.transforms.RetrieveLogProb"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RetrieveLogProb</span></code></a>(model, *[, ...])</p></td>
<td><p>A transform to retrieve log-probabilities from a model for KL divergence computation.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.transforms.TemplateTransform.html#torchrl.envs.llm.transforms.TemplateTransform" title="torchrl.envs.llm.transforms.TemplateTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TemplateTransform</span></code></a>(tokenizer[, chat_template])</p></td>
<td><p>A transform that maps applies a chat template to an input string during the forward pass, and parses the strings to the template during backward.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.transforms.Tokenizer.html#torchrl.envs.llm.transforms.Tokenizer" title="torchrl.envs.llm.transforms.Tokenizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tokenizer</span></code></a>([in_keys, out_keys, in_keys_inv, ...])</p></td>
<td><p>Applies a tokenization operation on the specified inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.transforms.as_nested_tensor.html#torchrl.envs.llm.transforms.as_nested_tensor" title="torchrl.envs.llm.transforms.as_nested_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">as_nested_tensor</span></code></a>(list_of_tensordicts)</p></td>
<td><p>Stacks a list of tensordicts into a single tensordict with nested tensors.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.llm.transforms.as_padded_tensor.html#torchrl.envs.llm.transforms.as_padded_tensor" title="torchrl.envs.llm.transforms.as_padded_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">as_padded_tensor</span></code></a>(list_of_tensordicts[, dim, ...])</p></td>
<td><p>Stacks a list of tensordicts into a single tensordict with padded tensors.</p></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>
<section id="objectives">
<h2>Objectives<a class="headerlink" href="#objectives" title="Link to this heading">¶</a></h2>
<p>LLM post-training requires specialized loss functions that are adapted to the unique characteristics of language models.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.objectives.llm.LLMLossOutput.html#torchrl.objectives.llm.LLMLossOutput" title="torchrl.objectives.llm.LLMLossOutput"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LLMLossOutput</span></code></a>(loss_objective, clip_fraction, ...)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.objectives.llm.GRPOLoss.html#torchrl.objectives.llm.GRPOLoss" title="torchrl.objectives.llm.GRPOLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GRPOLoss</span></code></a>(*args, **kwargs)</p></td>
<td><p>GRPO loss.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.objectives.llm.GRPOLossOutput.html#torchrl.objectives.llm.GRPOLossOutput" title="torchrl.objectives.llm.GRPOLossOutput"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GRPOLossOutput</span></code></a>(loss_objective, ...[, ...])</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.objectives.llm.CISPOLoss.html#torchrl.objectives.llm.CISPOLoss" title="torchrl.objectives.llm.CISPOLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CISPOLoss</span></code></a>(*args, **kwargs)</p></td>
<td><p>CISPO (Clipped Importance Sampling Policy Optimization).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.objectives.llm.CISPOLossOutput.html#torchrl.objectives.llm.CISPOLossOutput" title="torchrl.objectives.llm.CISPOLossOutput"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CISPOLossOutput</span></code></a>(loss_objective, ...[, ...])</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.objectives.llm.DAPO.html#torchrl.objectives.llm.DAPO" title="torchrl.objectives.llm.DAPO"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DAPO</span></code></a>(*args, **kwargs)</p></td>
<td><p>DAPO (Clip-Higher over GRPO).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.objectives.llm.DAPOLossOutput.html#torchrl.objectives.llm.DAPOLossOutput" title="torchrl.objectives.llm.DAPOLossOutput"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DAPOLossOutput</span></code></a>(loss_objective, ...[, ...])</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.objectives.llm.MCAdvantage.html#torchrl.objectives.llm.MCAdvantage" title="torchrl.objectives.llm.MCAdvantage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MCAdvantage</span></code></a>(grpo_size[, prompt_key, ...])</p></td>
<td><p>Monte-Carlo advantage computation engine.</p></td>
</tr>
</tbody>
</table>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.objectives.llm.SFTLoss.html#torchrl.objectives.llm.SFTLoss" title="torchrl.objectives.llm.SFTLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SFTLoss</span></code></a>(*args, **kwargs)</p></td>
<td><p>Supervised fine-tuning loss.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.objectives.llm.SFTLossOutput.html#torchrl.objectives.llm.SFTLossOutput" title="torchrl.objectives.llm.SFTLossOutput"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SFTLossOutput</span></code></a>(loss_sft[, loss_kl_to_ref, ...])</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.data.llm.TopKRewardSelector.html#torchrl.data.llm.TopKRewardSelector" title="torchrl.data.llm.TopKRewardSelector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TopKRewardSelector</span></code></a>(total_dialog_turns, topk_size)</p></td>
<td><p>A replay-buffer transform that selects the top-k rewards for each prompt.</p></td>
</tr>
</tbody>
</table>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="generated/torchrl.weight_update.llm.VLLMWeightSyncScheme.html" class="btn btn-neutral float-right" title="VLLMWeightSyncScheme" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="generated/torchrl.record.PixelRenderTransform.html" class="btn btn-neutral" title="PixelRenderTransform" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">LLM Interface</a><ul>
<li><a class="reference internal" href="#key-components">Key Components</a></li>
<li><a class="reference internal" href="#quick-example">Quick Example</a></li>
<li><a class="reference internal" href="#documentation-sections">Documentation Sections</a><ul>
<li><a class="reference internal" href="#policy-version-tracking">Policy Version Tracking</a></li>
<li><a class="reference internal" href="#legacy-weight-updaters-deprecated">Legacy Weight Updaters (Deprecated)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#environments">Environments</a><ul>
<li><a class="reference internal" href="#chatenv">ChatEnv</a><ul>
<li><a class="reference internal" href="#core-functionality">Core Functionality</a></li>
<li><a class="reference internal" href="#transform-based-architecture">Transform-Based Architecture</a></li>
<li><a class="reference internal" href="#integration-with-llm-wrappers">Integration with LLM Wrappers</a></li>
</ul>
</li>
<li><a class="reference internal" href="#task-specific-environments">Task-Specific Environments</a></li>
<li><a class="reference internal" href="#transforms">Transforms</a><ul>
<li><a class="reference internal" href="#designing-reward-transforms">Designing Reward Transforms</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#objectives">Objectives</a><ul>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>
  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'main',
            LANGUAGE:'en',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="../_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="../_static/design-tabs.js"></script>
      <script type="text/javascript" src="../https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrl = $("#tutorial-type").text();
	      var githubLink = "https://github.com/pytorch/rl/blob/main/tutorials/sphinx-"  + tutorialUrl + ".py",
		  notebookLink = $(".sphx-glr-download-jupyter").find(".download.reference")[0].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/rl/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }

          var overwrite = function(_) {
              if ($(this).length > 0) {
                  $(this)[0].href = "https://github.com/pytorch/rl"
              }
          }
          // PC
          $(".main-menu a:contains('GitHub')").each(overwrite);
          // Mobile
          $(".main-menu a:contains('Github')").each(overwrite);
      });

      
       $(window).ready(function() {
           var original = window.sideMenus.bind;
           var startup = true;
           window.sideMenus.bind = function() {
               original();
               if (startup) {
                   $("#pytorch-right-menu a.reference.internal").each(function(i) {
                       if (this.classList.contains("not-expanded")) {
                           this.nextElementSibling.style.display = "block";
                           this.classList.remove("not-expanded");
                           this.classList.add("expanded");
                       }
                   });
                   startup = false;
               }
           };
       });
    </script>

    


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://shiftlab.github.io/pytorch/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://shiftlab.github.io/pytorch/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://shiftlab.github.io/pytorch/">PyTorch</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/get-started">Get Started</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/features">Features</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/ecosystem">Ecosystem</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/blog/">Blog</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://shiftlab.github.io/pytorch/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://shiftlab.github.io/pytorch/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    mobileMenu.bind();
    mobileTOC.bind();
    pytorchAnchors.bind();

    $(window).on("load", function() {
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
    })

    // Add class to links that have code blocks, since we cannot create links in code blocks
    $("article.pytorch-article a span.pre").each(function(e) {
      $(this).closest("a").addClass("has-code");
    });
  </script>
</body>
</html>
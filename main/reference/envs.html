


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchrl.envs package &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="EnvBase" href="generated/torchrl.envs.EnvBase.html" />
    <link rel="prev" title="MultiStepTransform" href="generated/torchrl.envs.transforms.rb_transforms.MultiStepTransform.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','UA-117752657-2');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="../../versions.html"><span style="font-size:110%">main (0.0.0+unknown) &#x25BC</span></a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-0.html">Get started with Environments, TED and transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-1.html">Get started with TorchRL’s modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-2.html">Getting started with model optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-3.html">Get started with data collection and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-4.html">Get started with logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting-started-5.html">Get started with your own first training loop</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/coding_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/torchrl_demo.html">Introduction to TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/multiagent_ppo.html">Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/torchrl_envs.html">TorchRL envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/pretrained_models.html">Using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/dqn_with_rnn.html">Recurrent DQN: Training recurrent policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/rb_tutorial.html">Using Replay Buffers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/export.html">Exporting TorchRL modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/llm_browser.html">TorchRL LLM: Building Tool-Enabled Environments</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/multiagent_competitive_ddpg.html">Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/coding_ddpg.html">TorchRL objectives: Coding a DDPG loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/coding_dqn.html">TorchRL trainer: A DQN example</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="index.html">API Reference</a> &gt;</li>
        
      <li>torchrl.envs package</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/reference/envs.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
    
    
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=UA-117752657-2"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="torchrl-envs-package">
<h1>torchrl.envs package<a class="headerlink" href="#torchrl-envs-package" title="Permalink to this heading">¶</a></h1>
<p id="environment-api">TorchRL offers an API to handle environments of different backends, such as gym,
dm-control, dm-lab, model-based environments as well as custom environments.
The goal is to be able to swap environments in an experiment with little or no effort,
even if these environments are simulated using different libraries.
TorchRL offers some out-of-the-box environment wrappers under <code class="xref py py-obj docutils literal notranslate"><span class="pre">torchrl.envs.libs</span></code>,
which we hope can be easily imitated for other libraries.
The parent class <a class="reference internal" href="generated/torchrl.envs.EnvBase.html#torchrl.envs.EnvBase" title="torchrl.envs.EnvBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">EnvBase</span></code></a> is a <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></a> subclass that implements
some typical environment methods using <code class="xref py py-class docutils literal notranslate"><span class="pre">tensordict.TensorDict</span></code> as a data organiser. This allows this
class to be generic and to handle an arbitrary number of input and outputs, as well as
nested or batched data structures.</p>
<p>Each env will have the following attributes:</p>
<ul class="simple">
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">env.batch_size</span></code>: a <a class="reference external" href="https://docs.pytorch.org/docs/stable/size.html#torch.Size" title="(in PyTorch v2.9)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Size</span></code></a> representing the number of envs
batched together.</p></li>
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">env.device</span></code>: the device where the input and output tensordict are expected to live.
The environment device does not mean that the actual step operations will be computed on device
(this is the responsibility of the backend, with which TorchRL can do little). The device of
an environment just represents the device where the data is to be expected when input to the
environment or retrieved from it. TorchRL takes care of mapping the data to the desired device.
This is especially useful for transforms (see below). For parametric environments (e.g.
model-based environments), the device does represent the hardware that will be used to
compute the operations.</p></li>
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">env.observation_spec</span></code>: a <a class="reference internal" href="generated/torchrl.data.Composite.html#torchrl.data.Composite" title="torchrl.data.Composite"><code class="xref py py-class docutils literal notranslate"><span class="pre">Composite</span></code></a> object
containing all the observation key-spec pairs.</p></li>
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">env.state_spec</span></code>: a <a class="reference internal" href="generated/torchrl.data.Composite.html#torchrl.data.Composite" title="torchrl.data.Composite"><code class="xref py py-class docutils literal notranslate"><span class="pre">Composite</span></code></a> object
containing all the input key-spec pairs (except action). For most stateful
environments, this container will be empty.</p></li>
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">env.action_spec</span></code>: a <a class="reference internal" href="generated/torchrl.data.TensorSpec.html#torchrl.data.TensorSpec" title="torchrl.data.TensorSpec"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorSpec</span></code></a> object
representing the action spec.</p></li>
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">env.reward_spec</span></code>: a <a class="reference internal" href="generated/torchrl.data.TensorSpec.html#torchrl.data.TensorSpec" title="torchrl.data.TensorSpec"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorSpec</span></code></a> object representing
the reward spec.</p></li>
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">env.done_spec</span></code>: a <a class="reference internal" href="generated/torchrl.data.TensorSpec.html#torchrl.data.TensorSpec" title="torchrl.data.TensorSpec"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorSpec</span></code></a> object representing
the done-flag spec. See the section on trajectory termination below.</p></li>
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">env.input_spec</span></code>: a <a class="reference internal" href="generated/torchrl.data.Composite.html#torchrl.data.Composite" title="torchrl.data.Composite"><code class="xref py py-class docutils literal notranslate"><span class="pre">Composite</span></code></a> object containing
all the input keys (<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;full_action_spec&quot;</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;full_state_spec&quot;</span></code>).</p></li>
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">env.output_spec</span></code>: a <a class="reference internal" href="generated/torchrl.data.Composite.html#torchrl.data.Composite" title="torchrl.data.Composite"><code class="xref py py-class docutils literal notranslate"><span class="pre">Composite</span></code></a> object containing
all the output keys (<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;full_observation_spec&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;full_reward_spec&quot;</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;full_done_spec&quot;</span></code>).</p></li>
</ul>
<p>If the environment carries non-tensor data, a <a class="reference internal" href="generated/torchrl.data.NonTensor.html#torchrl.data.NonTensor" title="torchrl.data.NonTensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">NonTensor</span></code></a>
instance can be used.</p>
<section id="env-specs-locks-and-batch-size">
<h2>Env specs: locks and batch size<a class="headerlink" href="#env-specs-locks-and-batch-size" title="Permalink to this heading">¶</a></h2>
<p id="environment-lock">Environment specs are locked by default (through a <code class="docutils literal notranslate"><span class="pre">spec_locked</span></code> arg passed to the env constructor).
Locking specs means that any modification of the spec (or its children if it is a <a class="reference internal" href="generated/torchrl.data.Composite.html#torchrl.data.Composite" title="torchrl.data.Composite"><code class="xref py py-class docutils literal notranslate"><span class="pre">Composite</span></code></a>
instance) will require to unlock it. This can be done via the <a class="reference internal" href="generated/torchrl.envs.EnvBase.html#torchrl.envs.EnvBase.set_spec_lock_" title="torchrl.envs.EnvBase.set_spec_lock_"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_spec_lock_()</span></code></a>.
The reason specs are locked by default is that it makes it easy to cache values such as action or reset keys and the
likes.
Unlocking an env should only be done if it expected that the specs will be modified often (which, in principle, should
be avoided).
Modifications of the specs such as <cite>env.observation_spec = new_spec</cite> are allowed: under the hood, TorchRL will erase
the cache, unlock the specs, make the modification and relock the specs if the env was previously locked.</p>
<p>Importantly, the environment spec shapes should contain the batch size, e.g.
an environment with <code class="xref py py-obj docutils literal notranslate"><span class="pre">env.batch_size</span> <span class="pre">==</span> <span class="pre">torch.Size([4])</span></code> should have
an <code class="xref py py-obj docutils literal notranslate"><span class="pre">env.action_spec</span></code> with shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Size([4,</span> <span class="pre">action_size])</span></code>.
This is helpful when preallocation tensors, checking shape consistency etc.</p>
</section>
<section id="env-methods">
<h2>Env methods<a class="headerlink" href="#env-methods" title="Permalink to this heading">¶</a></h2>
<p>With these, the following methods are implemented:</p>
<ul>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">env.reset()</span></code>: a reset method that may (but not necessarily requires to) take
a <code class="xref py py-class docutils literal notranslate"><span class="pre">tensordict.TensorDict</span></code> input. It return the first tensordict of a rollout, usually
containing a <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;done&quot;</span></code> state and a set of observations. If not present,
a <cite>“reward”</cite> key will be instantiated with 0s and the appropriate shape.</p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">env.step()</span></code>: a step method that takes a <code class="xref py py-class docutils literal notranslate"><span class="pre">tensordict.TensorDict</span></code> input
containing an input action as well as other inputs (for model-based or stateless
environments, for instance).</p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">env.step_and_maybe_reset()</span></code>: executes a step, and (partially) resets the
environments if it needs to. It returns the updated input with a <code class="docutils literal notranslate"><span class="pre">&quot;next&quot;</span></code>
key containing the data of the next step, as well as a tensordict containing
the input data for the next step (ie, reset or result or
<code class="xref py py-func docutils literal notranslate"><span class="pre">step_mdp()</span></code>)
This is done by reading the <code class="docutils literal notranslate"><span class="pre">done_keys</span></code> and
assigning a <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> signal to each done state. This method allows
to code non-stopping rollout functions with little effort:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">data</span><span class="p">,</span> <span class="n">data_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step_and_maybe_reset</span><span class="p">(</span><span class="n">data_</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">env.set_seed()</span></code>: a seeding method that will return the next seed
to be used in a multi-env setting. This next seed is deterministically computed
from the preceding one, such that one can seed multiple environments with a different
seed without risking to overlap seeds in consecutive experiments, while still
having reproducible results.</p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">env.rollout()</span></code>: executes a rollout in the environment for
a maximum number of steps (<code class="docutils literal notranslate"><span class="pre">max_steps=N</span></code>) and using a policy (<code class="docutils literal notranslate"><span class="pre">policy=model</span></code>).
The policy should be coded using a <code class="xref py py-class docutils literal notranslate"><span class="pre">tensordict.nn.TensorDictModule</span></code>
(or any other <code class="xref py py-class docutils literal notranslate"><span class="pre">tensordict.TensorDict</span></code>-compatible module).
The resulting <code class="xref py py-class docutils literal notranslate"><span class="pre">tensordict.TensorDict</span></code> instance will be marked with
a trailing <code class="docutils literal notranslate"><span class="pre">&quot;time&quot;</span></code> named dimension that can be used by other modules
to treat this batched dimension as it should.</p></li>
</ul>
<p>The following figure summarizes how a rollout is executed in torchrl.</p>
<figure class="align-default" id="id3">
<img alt="../_images/rollout.gif" src="../_images/rollout.gif" />
<figcaption>
<p><span class="caption-text">TorchRL rollouts using TensorDict.</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>In brief, a TensorDict is created by the <a class="reference internal" href="generated/torchrl.envs.EnvBase.html#id1" title="torchrl.envs.EnvBase.reset"><code class="xref py py-meth docutils literal notranslate"><span class="pre">reset()</span></code></a> method,
then populated with an action by the policy before being passed to the
<a class="reference internal" href="generated/torchrl.envs.EnvBase.html#id4" title="torchrl.envs.EnvBase.step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">step()</span></code></a> method which writes the observations, done flag(s) and
reward under the <code class="docutils literal notranslate"><span class="pre">&quot;next&quot;</span></code> entry. The result of this call is stored for
delivery and the <code class="docutils literal notranslate"><span class="pre">&quot;next&quot;</span></code> entry is gathered by the <code class="xref py py-func docutils literal notranslate"><span class="pre">step_mdp()</span></code>
function.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In general, all TorchRL environment have a <code class="docutils literal notranslate"><span class="pre">&quot;done&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;terminated&quot;</span></code>
entry in their output tensordict. If they are not present by design,
the <a class="reference internal" href="generated/torchrl.envs.EnvBase.html#torchrl.envs.EnvBase" title="torchrl.envs.EnvBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">EnvBase</span></code></a> metaclass will ensure that every done or terminated
is flanked with its dual.
In TorchRL, <code class="docutils literal notranslate"><span class="pre">&quot;done&quot;</span></code> strictly refers to the union of all the end-of-trajectory
signals and should be interpreted as “the last step of a trajectory” or
equivalently “a signal indicating the need to reset”.
If the environment provides it (eg, Gymnasium), the truncation entry is also
written in the <a class="reference internal" href="generated/torchrl.envs.EnvBase.html#id4" title="torchrl.envs.EnvBase.step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">EnvBase.step()</span></code></a> output under a <code class="docutils literal notranslate"><span class="pre">&quot;truncated&quot;</span></code> entry.
If the environment carries a single value, it will interpreted as a <code class="docutils literal notranslate"><span class="pre">&quot;terminated&quot;</span></code>
signal by default.
By default, TorchRL’s collectors and rollout methods will be looking for the <code class="docutils literal notranslate"><span class="pre">&quot;done&quot;</span></code>
entry to assess if the environment should be reset.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <cite>torchrl.collectors.utils.split_trajectories</cite> function can be used to
slice adjacent trajectories. It relies on a <code class="docutils literal notranslate"><span class="pre">&quot;traj_ids&quot;</span></code> entry in the
input tensordict, or to the junction of <code class="docutils literal notranslate"><span class="pre">&quot;done&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;truncated&quot;</span></code> key
if the <code class="docutils literal notranslate"><span class="pre">&quot;traj_ids&quot;</span></code> is missing.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In some contexts, it can be useful to mark the first step of a trajectory.
TorchRL provides such functionality through the <code class="xref py py-class docutils literal notranslate"><span class="pre">InitTracker</span></code>
transform.</p>
</div>
<p>Our environment <a class="reference internal" href="../tutorials/pendulum.html#pendulum-tuto"><span class="std std-ref">tutorial</span></a>
provides more information on how to design a custom environment from scratch.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.EnvBase.html#torchrl.envs.EnvBase" title="torchrl.envs.EnvBase"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EnvBase</span></code></a>(*args, **kwargs)</p></td>
<td><p>Abstract environment parent class.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.GymLikeEnv.html#torchrl.envs.GymLikeEnv" title="torchrl.envs.GymLikeEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GymLikeEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>A gym-like env is an environment.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.EnvMetaData.html#torchrl.envs.EnvMetaData" title="torchrl.envs.EnvMetaData"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EnvMetaData</span></code></a>(*, tensordict, specs, ...)</p></td>
<td><p>A class for environment meta-data storage and passing in multiprocessed settings.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="partial-steps-and-partial-resets">
<h2>Partial steps and partial resets<a class="headerlink" href="#partial-steps-and-partial-resets" title="Permalink to this heading">¶</a></h2>
<p>TorchRL allows environments to reset some but not all the environments, or run a step in one but not all environments.
If there is only one environment in the batch, then a partial reset / step is also allowed with the behavior detailed
below.</p>
<section id="batching-environments-and-locking-the-batch">
<h3>Batching environments and locking the batch<a class="headerlink" href="#batching-environments-and-locking-the-batch" title="Permalink to this heading">¶</a></h3>
<p id="ref-batch-locked">Before detailing what partial resets and partial steps do, we must distinguish cases where an environment has
a batch size of its own (mostly stateful environments) or when the environment is just a mere module that, given an
input of arbitrary size, batches the operations over all elements (mostly stateless environments).</p>
<p>This is controlled via the <code class="xref py py-attr docutils literal notranslate"><span class="pre">batch_locked</span></code> attribute: a batch-locked environment requires all input
tensordicts to have the same batch-size as the env’s. Typical examples of these environments are
<a class="reference internal" href="generated/torchrl.envs.GymEnv.html#torchrl.envs.GymEnv" title="torchrl.envs.GymEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">GymEnv</span></code></a> and related. Batch-unlocked envs are by contrast allowed to work with any input size.
Notable examples are <a class="reference internal" href="generated/torchrl.envs.BraxEnv.html#torchrl.envs.BraxEnv" title="torchrl.envs.BraxEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">BraxEnv</span></code></a> or <a class="reference internal" href="generated/torchrl.envs.JumanjiEnv.html#torchrl.envs.JumanjiEnv" title="torchrl.envs.JumanjiEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">JumanjiEnv</span></code></a>.</p>
<p>Executing partial steps in a batch-unlocked environment is straightforward: one just needs to mask the part of the
tensordict that does not need to be executed, pass the other part to <cite>step</cite> and merge the results with the previous
input.</p>
<p>Batched environments (<a class="reference internal" href="generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParallelEnv</span></code></a> and <a class="reference internal" href="generated/torchrl.envs.SerialEnv.html#torchrl.envs.SerialEnv" title="torchrl.envs.SerialEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">SerialEnv</span></code></a>) can also deal with
partial steps easily, they just pass the actions to the sub-environments that are required to be executed.</p>
<p>In all other cases, TorchRL assumes that the environment handles the partial steps correctly.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This means that custom environments may silently run the non-required steps as there is no way for torchrl
to control what happens within the <cite>_step</cite> method!</p>
</div>
</section>
<section id="partial-steps">
<h3>Partial Steps<a class="headerlink" href="#partial-steps" title="Permalink to this heading">¶</a></h3>
<p id="ref-partial-steps">Partial steps are controlled via the temporary key <cite>“_step”</cite> which points to a boolean mask of the
size of the tensordict that holds it. The classes armed to deal with this are:</p>
<ul class="simple">
<li><p>Batched environments: <a class="reference internal" href="generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParallelEnv</span></code></a> and <a class="reference internal" href="generated/torchrl.envs.SerialEnv.html#torchrl.envs.SerialEnv" title="torchrl.envs.SerialEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">SerialEnv</span></code></a> will dispatch the
action to and only to the environments where <cite>“_step”</cite> is <cite>True</cite>;</p></li>
<li><p>Batch-unlocked environments;</p></li>
<li><p>Unbatched environments (i.e., environments without batch size). In these environments, the <a class="reference internal" href="generated/torchrl.envs.EnvBase.html#id4" title="torchrl.envs.EnvBase.step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">step()</span></code></a>
method will first look for a <cite>“_step”</cite> entry and, if present, act accordingly.
If a <code class="xref py py-class docutils literal notranslate"><span class="pre">Transform</span></code> instance passes a <cite>“_step”</cite> entry to the tensordict, it is also captured by
<code class="xref py py-class docutils literal notranslate"><span class="pre">TransformedEnv</span></code>’s own <cite>_step</cite> method which will skip the <cite>base_env.step</cite> as well as any further
transformation.</p></li>
</ul>
<p>When dealing with partial steps, the strategy is always to use the step output and mask missing values with the previous
content of the input tensordict, if present, or a <cite>0</cite>-valued tensor if the tensor cannot be found. This means that
if the input tensordict does not contain all the previous observations, then the output tensordict will be 0-valued for
all the non-stepped elements. Within batched environments, data collectors and rollouts utils, this is an issue that
is not observed because these classes handle the passing of data properly.</p>
<p>Partial steps are an essential feature of <a class="reference internal" href="generated/torchrl.envs.EnvBase.html#id2" title="torchrl.envs.EnvBase.rollout"><code class="xref py py-meth docutils literal notranslate"><span class="pre">rollout()</span></code></a> when <cite>break_when_all_done</cite> is <cite>True</cite>,
as the environments with a <cite>True</cite> done state will need to be skipped during calls to <cite>_step</cite>.</p>
<p>The <code class="xref py py-class docutils literal notranslate"><span class="pre">ConditionalSkip</span></code> transform allows you to programmatically ask for (partial) step skips.</p>
</section>
<section id="partial-resets">
<h3>Partial Resets<a class="headerlink" href="#partial-resets" title="Permalink to this heading">¶</a></h3>
<p id="ref-partial-resets">Partial resets work pretty much like partial steps, but with the <cite>“_reset”</cite> entry.</p>
<p>The same restrictions of partial steps apply to partial resets.</p>
<p>Likewise, partial resets are an essential feature of <a class="reference internal" href="generated/torchrl.envs.EnvBase.html#id2" title="torchrl.envs.EnvBase.rollout"><code class="xref py py-meth docutils literal notranslate"><span class="pre">rollout()</span></code></a> when <cite>break_when_any_done</cite> is <cite>True</cite>,
as the environments with a <cite>True</cite> done state will need to be reset, but not others.</p>
<p>See te following paragraph for a deep dive in partial resets within batched and vectorized environments.</p>
</section>
</section>
<section id="vectorized-envs">
<h2>Vectorized envs<a class="headerlink" href="#vectorized-envs" title="Permalink to this heading">¶</a></h2>
<p>Vectorized (or better: parallel) environments is a common feature in Reinforcement Learning
where executing the environment step can be cpu-intensive.
Some libraries such as <a class="reference external" href="https://github.com/openai/gym3">gym3</a> or <a class="reference external" href="https://github.com/sail-sg/envpool">EnvPool</a>
offer interfaces to execute batches of environments simultaneously.
While they often offer a very competitive computational advantage, they do not
necessarily scale to the wide variety of environment libraries supported by TorchRL.
Therefore, TorchRL offers its own, generic <a class="reference internal" href="generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParallelEnv</span></code></a> class to run multiple
environments in parallel.
As this class inherits from <a class="reference internal" href="generated/torchrl.envs.SerialEnv.html#torchrl.envs.SerialEnv" title="torchrl.envs.SerialEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">SerialEnv</span></code></a>, it enjoys the exact same API as other environment.
Of course, a <a class="reference internal" href="generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParallelEnv</span></code></a> will have a batch size that corresponds to its environment count:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Given the library’s many optional dependencies (eg, Gym, Gymnasium, and many others)
warnings can quickly become quite annoying in multiprocessed / distributed settings.
By default, TorchRL filters out these warnings in sub-processes. If one still wishes to
see these warnings, they can be displayed by setting <code class="docutils literal notranslate"><span class="pre">torchrl.filter_warnings_subprocess=False</span></code>.</p>
</div>
<p>It is important that your environment specs match the input and output that it sends and receives, as
<a class="reference internal" href="generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParallelEnv</span></code></a> will create buffers from these specs to communicate with the spawn processes.
Check the <code class="xref py py-func docutils literal notranslate"><span class="pre">check_env_specs()</span></code> method for a sanity check.</p>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text">Parallel environment</span><a class="headerlink" href="#id4" title="Permalink to this code">¶</a></div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="o">&gt;&gt;&gt;</span> <span class="k">def</span><span class="w"> </span><span class="nf">make_env</span><span class="p">():</span>
     <span class="o">...</span>     <span class="k">return</span> <span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">from_pixels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">g</span><span class="o">=</span><span class="mf">9.81</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">check_env_specs</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>  <span class="c1"># this must pass for ParallelEnv to work</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">env</span> <span class="o">=</span> <span class="n">ParallelEnv</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">make_env</span><span class="p">)</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">])</span>
</pre></div>
</div>
</div>
<p><a class="reference internal" href="generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParallelEnv</span></code></a> allows to retrieve the attributes from its contained environments:
one can simply call:</p>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text">Parallel environment attributes</span><a class="headerlink" href="#id5" title="Permalink to this code">¶</a></div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">g</span>  <span class="c1"># gets the g-force of the various envs, which we set to 9.81 before</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
     <span class="mf">9.81</span>
</pre></div>
</div>
</div>
<p>TorchRL uses a private <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> key to indicate to the environment which
component (sub-environments or agents) should be reset.
This allows to reset some but not all of the components.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> key has two distinct functionalities:</p>
<ol class="arabic">
<li><p>During a call to <code class="xref py py-meth docutils literal notranslate"><span class="pre">_reset()</span></code>, the <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> key may or may
not be present in the input tensordict. TorchRL’s convention is that the
absence of the <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> key at a given <code class="docutils literal notranslate"><span class="pre">&quot;done&quot;</span></code> level indicates
a total reset of that level (unless a <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> key was found at a level
above, see details below).
If it is present, it is expected that those entries and only those components
where the <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> entry is <code class="docutils literal notranslate"><span class="pre">True</span></code> (along key and shape dimension) will be reset.</p>
<p>The way an environment deals with the <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> keys in its <code class="xref py py-meth docutils literal notranslate"><span class="pre">_reset()</span></code>
method is proper to its class.
Designing an environment that behaves according to <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> inputs is the
developer’s responsibility, as TorchRL has no control over the inner logic
of <code class="xref py py-meth docutils literal notranslate"><span class="pre">_reset()</span></code>. Nevertheless, the following point should be
kept in mind when designing that method.</p>
</li>
<li><p>After a call to <code class="xref py py-meth docutils literal notranslate"><span class="pre">_reset()</span></code>, the output will be masked with the
<code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> entries and the output of the previous <a class="reference internal" href="generated/torchrl.envs.EnvBase.html#id4" title="torchrl.envs.EnvBase.step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">step()</span></code></a>
will be written wherever the <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> was <code class="docutils literal notranslate"><span class="pre">False</span></code>. In practice, this
means that if a <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> modifies data that isn’t exposed by it, this
modification will be lost. After this masking operation, the <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code>
entries will be erased from the <a class="reference internal" href="generated/torchrl.envs.EnvBase.html#id1" title="torchrl.envs.EnvBase.reset"><code class="xref py py-meth docutils literal notranslate"><span class="pre">reset()</span></code></a> outputs.</p></li>
</ol>
<p>It must be pointed out that <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> is a private key, and it should only be
used when coding specific environment features that are internal facing.
In other words, this should NOT be used outside of the library, and developers
will keep the right to modify the logic of partial resets through <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code>
setting without preliminary warranty, as long as they don’t affect TorchRL
internal tests.</p>
<p>Finally, the following assumptions are made and should be kept in mind when
designing reset functionalities:</p>
<ul class="simple">
<li><p>Each <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> is paired with a <code class="docutils literal notranslate"><span class="pre">&quot;done&quot;</span></code> entry (+ <code class="docutils literal notranslate"><span class="pre">&quot;terminated&quot;</span></code> and,
possibly, <code class="docutils literal notranslate"><span class="pre">&quot;truncated&quot;</span></code>). This means that the following structure is not
allowed: <code class="docutils literal notranslate"><span class="pre">TensorDict({&quot;done&quot;:</span> <span class="pre">done,</span> <span class="pre">&quot;nested&quot;:</span> <span class="pre">{&quot;_reset&quot;:</span> <span class="pre">reset}},</span> <span class="pre">[])</span></code>, as
the <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> lives at a different nesting level than the <code class="docutils literal notranslate"><span class="pre">&quot;done&quot;</span></code>.</p></li>
<li><p>A reset at one level does not preclude the presence of a <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> at lower
levels, but it annihilates its effects. The reason is simply that
whether the <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> at the root level corresponds to an <code class="docutils literal notranslate"><span class="pre">all()</span></code>, <code class="docutils literal notranslate"><span class="pre">any()</span></code>
or custom call to the nested <code class="docutils literal notranslate"><span class="pre">&quot;done&quot;</span></code> entries cannot be known in advance,
and it is explicitly assumed that the <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> at the root was placed
there to supersede the nested values (for an example, have a look at
<code class="xref py py-class docutils literal notranslate"><span class="pre">PettingZooWrapper</span></code> implementation where each group has one or more
<code class="docutils literal notranslate"><span class="pre">&quot;done&quot;</span></code> entries associated which is aggregated at the root level with a
<code class="docutils literal notranslate"><span class="pre">any</span></code> or <code class="docutils literal notranslate"><span class="pre">all</span></code> logic depending on the task).</p></li>
<li><p>When calling <code class="xref py py-meth docutils literal notranslate"><span class="pre">env.reset(tensordict)()</span></code> with a partial <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> entry
that will reset some but not all the done sub-environments, the input data
should contain the data of the sub-environments that are __not__ being reset.
The reason for this constrain lies in the fact that the output of the
<code class="docutils literal notranslate"><span class="pre">env._reset(data)</span></code> can only be predicted for the entries that are reset.
For the others, TorchRL cannot know in advance if they will be meaningful or
not. For instance, one could perfectly just pad the values of the non-reset
components, in which case the non-reset data will be meaningless and should
be discarded.</p></li>
</ul>
<p>Below, we give some examples of the expected effect that <code class="docutils literal notranslate"><span class="pre">&quot;_reset&quot;</span></code> keys will
have on an environment returning zeros after reset:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># single reset at the root</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">({</span><span class="s2">&quot;val&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;_reset&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">]},</span> <span class="p">[])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;val&quot;</span><span class="p">))</span>  <span class="c1"># only the second value is 0</span>
<span class="go">tensor([1, 0])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># nested resets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">({</span>
<span class="gp">... </span>    <span class="p">(</span><span class="s2">&quot;agent0&quot;</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">):</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="s2">&quot;agent0&quot;</span><span class="p">,</span> <span class="s2">&quot;_reset&quot;</span><span class="p">):</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">],</span>
<span class="gp">... </span>    <span class="p">(</span><span class="s2">&quot;agent1&quot;</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">):</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">(</span><span class="s2">&quot;agent1&quot;</span><span class="p">,</span> <span class="s2">&quot;_reset&quot;</span><span class="p">):</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
<span class="gp">... </span><span class="p">},</span> <span class="p">[])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;agent0&quot;</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">)))</span>  <span class="c1"># only the second value is 0</span>
<span class="go">tensor([1, 0])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;agent1&quot;</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">)))</span>  <span class="c1"># only the first value is 0</span>
<span class="go">tensor([0, 2])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># nested resets are overridden by a &quot;_reset&quot; at the root</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">({</span>
<span class="gp">... </span>    <span class="s2">&quot;_reset&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">],</span>
<span class="gp">... </span>    <span class="p">(</span><span class="s2">&quot;agent0&quot;</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">):</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="s2">&quot;agent0&quot;</span><span class="p">,</span> <span class="s2">&quot;_reset&quot;</span><span class="p">):</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">],</span>
<span class="gp">... </span>    <span class="p">(</span><span class="s2">&quot;agent1&quot;</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">):</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">(</span><span class="s2">&quot;agent1&quot;</span><span class="p">,</span> <span class="s2">&quot;_reset&quot;</span><span class="p">):</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
<span class="gp">... </span><span class="p">},</span> <span class="p">[])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;agent0&quot;</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">)))</span>  <span class="c1"># reset at the root overrides nested</span>
<span class="go">tensor([0, 0])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;agent1&quot;</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">)))</span>  <span class="c1"># reset at the root overrides nested</span>
<span class="go">tensor([0, 0])</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id6">
<div class="code-block-caption"><span class="caption-text">Parallel environment reset</span><a class="headerlink" href="#id6" title="Permalink to this code">¶</a></div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="o">&gt;&gt;&gt;</span> <span class="n">tensordict</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">({</span><span class="s2">&quot;_reset&quot;</span><span class="p">:</span> <span class="p">[[</span><span class="kc">True</span><span class="p">],</span> <span class="p">[</span><span class="kc">False</span><span class="p">],</span> <span class="p">[</span><span class="kc">True</span><span class="p">],</span> <span class="p">[</span><span class="kc">True</span><span class="p">]]},</span> <span class="p">[</span><span class="mi">4</span><span class="p">])</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>  <span class="c1"># eliminates the &quot;_reset&quot; entry</span>
     <span class="n">TensorDict</span><span class="p">(</span>
         <span class="n">fields</span><span class="o">=</span><span class="p">{</span>
             <span class="n">terminated</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">),</span>
             <span class="n">done</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">),</span>
             <span class="n">pixels</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">),</span>
             <span class="n">truncated</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">),</span>
         <span class="n">batch_size</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">]),</span>
         <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
         <span class="n">is_shared</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><em>A note on performance</em>: launching a <a class="reference internal" href="generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParallelEnv</span></code></a> can take quite some time
as it requires to launch as many python instances as there are processes. Due to
the time that it takes to run <code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">torch</span></code> (and other imports), starting the
parallel env can be a bottleneck. This is why, for instance, TorchRL tests are so slow.
Once the environment is launched, a great speedup should be observed.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><em>TorchRL requires precise specs</em>: Another thing to take in consideration is
that <a class="reference internal" href="generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParallelEnv</span></code></a> (as well as data collectors)
will create data buffers based on the environment specs to pass data from one process
to another. This means that a misspecified spec (input, observation or reward) will
cause a breakage at runtime as the data can’t be written on the preallocated buffer.
In general, an environment should be tested using the <code class="xref py py-func docutils literal notranslate"><span class="pre">check_env_specs()</span></code>
test function before being used in a <a class="reference internal" href="generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParallelEnv</span></code></a>. This function will raise
an assertion error whenever the preallocated buffer and the collected data mismatch.</p>
</div>
<p>We also offer the <a class="reference internal" href="generated/torchrl.envs.SerialEnv.html#torchrl.envs.SerialEnv" title="torchrl.envs.SerialEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">SerialEnv</span></code></a> class that enjoys the exact same API but is executed
serially. This is mostly useful for testing purposes, when one wants to assess the
behavior of a <a class="reference internal" href="generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParallelEnv</span></code></a> without launching the subprocesses.</p>
<p>In addition to <a class="reference internal" href="generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParallelEnv</span></code></a>, which offers process-based parallelism, we also provide a way to create
multithreaded environments with <a class="reference internal" href="generated/torchrl.envs.MultiThreadedEnv.html#torchrl.envs.MultiThreadedEnv" title="torchrl.envs.MultiThreadedEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiThreadedEnv</span></code></a>. This class uses <a class="reference external" href="https://github.com/sail-sg/envpool">EnvPool</a>
library underneath, which allows for higher performance, but at the same time restricts flexibility - one can only
create environments implemented in <code class="docutils literal notranslate"><span class="pre">EnvPool</span></code>. This covers many popular RL environments types (Atari, Classic Control,
etc.), but one can not use an arbitrary TorchRL environment, as it is possible with <a class="reference internal" href="generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParallelEnv</span></code></a>. Run
<cite>benchmarks/benchmark_batched_envs.py</cite> to compare performance of different ways to parallelize batched environments.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.SerialEnv.html#torchrl.envs.SerialEnv" title="torchrl.envs.SerialEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SerialEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>Creates a series of environments in the same process.Batched environments allow the user to query an arbitrary method / attribute of the environment running remotely.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ParallelEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>Creates one environment per process.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.EnvCreator.html#torchrl.envs.EnvCreator" title="torchrl.envs.EnvCreator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EnvCreator</span></code></a>(create_env_fn[, ...])</p></td>
<td><p>Environment creator class.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="async-environments">
<h2>Async environments<a class="headerlink" href="#async-environments" title="Permalink to this heading">¶</a></h2>
<p>Asynchronous environments allow for parallel execution of multiple environments, which can significantly speed up the
data collection process in reinforcement learning.</p>
<p>The <cite>AsyncEnvPool</cite> class and its subclasses provide a flexible interface for managing these environments using different
backends, such as threading and multiprocessing.</p>
<p>The <cite>AsyncEnvPool</cite> class serves as a base class for asynchronous environment pools, providing a common interface for
managing multiple environments concurrently. It supports different backends for parallel execution, such as threading
and multiprocessing, and provides methods for asynchronous stepping and resetting of environments.</p>
<p>Contrary to <a class="reference internal" href="generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParallelEnv</span></code></a>, <a class="reference internal" href="generated/torchrl.envs.AsyncEnvPool.html#torchrl.envs.AsyncEnvPool" title="torchrl.envs.AsyncEnvPool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AsyncEnvPool</span></code></a> and its subclasses permit the
execution of a given set of sub-environments while another task performed, allowing for complex asynchronous jobs to be
run at the same time. For instance, it is possible to execute some environments while the policy is running based on
the output of others.</p>
<p>This family of classes is particularly interesting when dealing with environments that have a high (and/or variable)
latency.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This class and its subclasses should work when nested in with <code class="xref py py-class docutils literal notranslate"><span class="pre">TransformedEnv</span></code> and
batched environments, but users won’t currently be able to use the async features of the base environment when
it’s nested in these classes. One should prefer nested transformed envs within an <cite>AsyncEnvPool</cite> instead.
If this is not possible, please raise an issue.</p>
</div>
<section id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p><a class="reference internal" href="generated/torchrl.envs.AsyncEnvPool.html#torchrl.envs.AsyncEnvPool" title="torchrl.envs.AsyncEnvPool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AsyncEnvPool</span></code></a>: A base class for asynchronous environment pools. It determines the backend
implementation to use based on the provided arguments and manages the lifecycle of the environments.</p></li>
<li><p><a class="reference internal" href="generated/torchrl.envs.ProcessorAsyncEnvPool.html#torchrl.envs.ProcessorAsyncEnvPool" title="torchrl.envs.ProcessorAsyncEnvPool"><code class="xref py py-class docutils literal notranslate"><span class="pre">ProcessorAsyncEnvPool</span></code></a>: An implementation of <a class="reference internal" href="generated/torchrl.envs.AsyncEnvPool.html#torchrl.envs.AsyncEnvPool" title="torchrl.envs.AsyncEnvPool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AsyncEnvPool</span></code></a> using
multiprocessing for parallel execution of environments. This class manages a pool of environments, each running in
its own process, and provides methods for asynchronous stepping and resetting of environments using inter-process
communication. It is automatically instantiated when <cite>“multiprocessing”</cite> is passed as a backend during the
<a class="reference internal" href="generated/torchrl.envs.AsyncEnvPool.html#torchrl.envs.AsyncEnvPool" title="torchrl.envs.AsyncEnvPool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AsyncEnvPool</span></code></a> instantiation.</p></li>
<li><p><a class="reference internal" href="generated/torchrl.envs.ThreadingAsyncEnvPool.html#torchrl.envs.ThreadingAsyncEnvPool" title="torchrl.envs.ThreadingAsyncEnvPool"><code class="xref py py-class docutils literal notranslate"><span class="pre">ThreadingAsyncEnvPool</span></code></a>: An implementation of <a class="reference internal" href="generated/torchrl.envs.AsyncEnvPool.html#torchrl.envs.AsyncEnvPool" title="torchrl.envs.AsyncEnvPool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AsyncEnvPool</span></code></a> using
threading for parallel execution of environments. This class manages a pool of environments, each running in its own
thread, and provides methods for asynchronous stepping and resetting of environments using a thread pool executor.
It is automatically instantiated when <cite>“threading”</cite> is passed as a backend during the
<a class="reference internal" href="generated/torchrl.envs.AsyncEnvPool.html#torchrl.envs.AsyncEnvPool" title="torchrl.envs.AsyncEnvPool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AsyncEnvPool</span></code></a> instantiation.</p></li>
</ul>
</section>
<section id="example">
<h3>Example<a class="headerlink" href="#example" title="Permalink to this heading">¶</a></h3>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">partial</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs</span><span class="w"> </span><span class="kn">import</span> <span class="n">AsyncEnvPool</span><span class="p">,</span> <span class="n">GymEnv</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Choose backend</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">backend</span> <span class="o">=</span> <span class="s2">&quot;threading&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">AsyncEnvPool</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="p">[</span><span class="n">partial</span><span class="p">(</span><span class="n">GymEnv</span><span class="p">,</span> <span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">),</span> <span class="n">partial</span><span class="p">(</span><span class="n">GymEnv</span><span class="p">,</span> <span class="s2">&quot;CartPole-v1&quot;</span><span class="p">)],</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">stack</span><span class="o">=</span><span class="s2">&quot;lazy&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">backend</span><span class="o">=</span><span class="n">backend</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Execute a synchronous reset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reset</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">reset</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Execute a synchronous step</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">rand_step</span><span class="p">(</span><span class="n">reset</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Execute an asynchronous step in env 0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s0</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s0</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s0</span><span class="p">[</span><span class="s2">&quot;env_index&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span><span class="o">.</span><span class="n">async_step_send</span><span class="p">(</span><span class="n">s0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Receive data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s0_result</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">async_step_recv</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;result&#39;</span><span class="p">,</span> <span class="n">s0_result</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Close env</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.AsyncEnvPool.html#torchrl.envs.AsyncEnvPool" title="torchrl.envs.AsyncEnvPool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AsyncEnvPool</span></code></a>(*args, **kwargs)</p></td>
<td><p>A base class for asynchronous environment pools, providing a common interface for managing multiple environments concurrently.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.ProcessorAsyncEnvPool.html#torchrl.envs.ProcessorAsyncEnvPool" title="torchrl.envs.ProcessorAsyncEnvPool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ProcessorAsyncEnvPool</span></code></a>(*args, **kwargs)</p></td>
<td><p>An implementation of <cite>AsyncEnvPool</cite> using multiprocessing for parallel execution of environments.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.ThreadingAsyncEnvPool.html#torchrl.envs.ThreadingAsyncEnvPool" title="torchrl.envs.ThreadingAsyncEnvPool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ThreadingAsyncEnvPool</span></code></a>(*args, **kwargs)</p></td>
<td><p>An implementation of <cite>AsyncEnvPool</cite> using threading for parallel execution of environments.</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="custom-native-torchrl-environments">
<h2>Custom native TorchRL environments<a class="headerlink" href="#custom-native-torchrl-environments" title="Permalink to this heading">¶</a></h2>
<p>TorchRL offers a series of custom built-in environments.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.ChessEnv.html#torchrl.envs.ChessEnv" title="torchrl.envs.ChessEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ChessEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>A chess environment that follows the TorchRL API.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.PendulumEnv.html#torchrl.envs.PendulumEnv" title="torchrl.envs.PendulumEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PendulumEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>A stateless Pendulum environment.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.TicTacToeEnv.html#torchrl.envs.TicTacToeEnv" title="torchrl.envs.TicTacToeEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TicTacToeEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>A Tic-Tac-Toe implementation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.LLMHashingEnv.html#torchrl.envs.LLMHashingEnv" title="torchrl.envs.LLMHashingEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LLMHashingEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>A text generation environment that uses a hashing module to identify unique observations.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="multi-agent-environments">
<h2>Multi-agent environments<a class="headerlink" href="#multi-agent-environments" title="Permalink to this heading">¶</a></h2>
<p id="marl-environment-api">TorchRL supports multi-agent learning out-of-the-box.
<em>The same classes used in a single-agent learning pipeline can be seamlessly used in multi-agent contexts,
without any modification or dedicated multi-agent infrastructure.</em></p>
<p>In this view, environments play a core role for multi-agent. In multi-agent environments,
many decision-making agents act in a shared world.
Agents can observe different things, act in different ways and also be rewarded differently.
Therefore, many paradigms exist to model multi-agent environments (DecPODPs, Markov Games).
Some of the main differences between these paradigms include:</p>
<ul class="simple">
<li><p><strong>observation</strong> can be per-agent and also have some shared components</p></li>
<li><p><strong>reward</strong> can be per-agent or shared</p></li>
<li><p><strong>done</strong> (and <code class="docutils literal notranslate"><span class="pre">&quot;truncated&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;terminated&quot;</span></code>) can be per-agent or shared.</p></li>
</ul>
<p>TorchRL accommodates all these possible paradigms thanks to its <code class="xref py py-class docutils literal notranslate"><span class="pre">tensordict.TensorDict</span></code> data carrier.
In particular, in multi-agent environments, per-agent keys will be carried in a nested “agents” TensorDict.
This TensorDict will have the additional agent dimension and thus group data that is different for each agent.
The shared keys, on the other hand, will be kept in the first level, as in single-agent cases.</p>
<p>Let’s look at an example to understand this better. For this example we are going to use
<a class="reference external" href="https://github.com/proroklab/VectorizedMultiAgentSimulator">VMAS</a>, a multi-robot task simulator also
based on PyTorch, which runs parallel batched simulation on device.</p>
<p>We can create a VMAS environment and look at what the output from a random step looks like:</p>
<div class="literal-block-wrapper docutils container" id="id7">
<div class="code-block-caption"><span class="caption-text">Example of multi-agent step tensordict</span><a class="headerlink" href="#id7" title="Permalink to this code">¶</a></div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.libs.vmas</span><span class="w"> </span><span class="kn">import</span> <span class="n">VmasEnv</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">env</span> <span class="o">=</span> <span class="n">VmasEnv</span><span class="p">(</span><span class="s2">&quot;balance&quot;</span><span class="p">,</span> <span class="n">num_envs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_agents</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">td</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">rand_step</span><span class="p">()</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">td</span>
     <span class="n">TensorDict</span><span class="p">(</span>
         <span class="n">fields</span><span class="o">=</span><span class="p">{</span>
             <span class="n">agents</span><span class="p">:</span> <span class="n">TensorDict</span><span class="p">(</span>
                 <span class="n">fields</span><span class="o">=</span><span class="p">{</span>
                     <span class="n">action</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))},</span>
                 <span class="n">batch_size</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">])),</span>
             <span class="nb">next</span><span class="p">:</span> <span class="n">TensorDict</span><span class="p">(</span>
                 <span class="n">fields</span><span class="o">=</span><span class="p">{</span>
                     <span class="n">agents</span><span class="p">:</span> <span class="n">TensorDict</span><span class="p">(</span>
                         <span class="n">fields</span><span class="o">=</span><span class="p">{</span>
                             <span class="n">info</span><span class="p">:</span> <span class="n">TensorDict</span><span class="p">(</span>
                                 <span class="n">fields</span><span class="o">=</span><span class="p">{</span>
                                     <span class="n">ground_rew</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">])),</span>
                                     <span class="n">pos_rew</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))},</span>
                                 <span class="n">batch_size</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">])),</span>
                             <span class="n">observation</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">16</span><span class="p">])),</span>
                             <span class="n">reward</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))},</span>
                         <span class="n">batch_size</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">])),</span>
                     <span class="n">done</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))},</span>
                 <span class="n">batch_size</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">]))},</span>
         <span class="n">batch_size</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<p>We can observe that <em>keys that are shared by all agents</em>, such as <strong>done</strong> are present in the root tensordict with
batch size <cite>(num_envs,)</cite>, which represents the number of environments simulated.</p>
<p>On the other hand, <em>keys that are different between agents</em>, such as <strong>action</strong>, <strong>reward</strong>, <strong>observation</strong>,
and <strong>info</strong> are present in the nested “agents” tensordict with batch size <cite>(num_envs, n_agents)</cite>,
which represents the additional agent dimension.</p>
<p>Multi-agent tensor specs will follow the same style as in tensordicts.
Specs relating to values that vary between agents will need to be nested in the “agents” entry.</p>
<p>Here is an example of how specs can be created in a multi-agent environment where
only the done flag is shared across agents (as in VMAS):</p>
<div class="literal-block-wrapper docutils container" id="id8">
<div class="code-block-caption"><span class="caption-text">Example of multi-agent spec creation</span><a class="headerlink" href="#id8" title="Permalink to this code">¶</a></div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="o">&gt;&gt;&gt;</span> <span class="n">action_specs</span> <span class="o">=</span> <span class="p">[]</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">observation_specs</span> <span class="o">=</span> <span class="p">[]</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">reward_specs</span> <span class="o">=</span> <span class="p">[]</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">info_specs</span> <span class="o">=</span> <span class="p">[]</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">n_agents</span><span class="p">):</span>
     <span class="o">...</span>    <span class="n">action_specs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">agent_i_action_spec</span><span class="p">)</span>
     <span class="o">...</span>    <span class="n">reward_specs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">agent_i_reward_spec</span><span class="p">)</span>
     <span class="o">...</span>    <span class="n">observation_specs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">agent_i_observation_spec</span><span class="p">)</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">env</span><span class="o">.</span><span class="n">action_spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">(</span>
     <span class="o">...</span>    <span class="p">{</span>
     <span class="o">...</span>        <span class="s2">&quot;agents&quot;</span><span class="p">:</span> <span class="n">Composite</span><span class="p">(</span>
     <span class="o">...</span>            <span class="p">{</span><span class="s2">&quot;action&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">action_specs</span><span class="p">)},</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">n_agents</span><span class="p">,)</span>
     <span class="o">...</span>        <span class="p">)</span>
     <span class="o">...</span>    <span class="p">}</span>
     <span class="o">...</span><span class="p">)</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">env</span><span class="o">.</span><span class="n">reward_spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">(</span>
     <span class="o">...</span>    <span class="p">{</span>
     <span class="o">...</span>        <span class="s2">&quot;agents&quot;</span><span class="p">:</span> <span class="n">Composite</span><span class="p">(</span>
     <span class="o">...</span>            <span class="p">{</span><span class="s2">&quot;reward&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">reward_specs</span><span class="p">)},</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">n_agents</span><span class="p">,)</span>
     <span class="o">...</span>        <span class="p">)</span>
     <span class="o">...</span>    <span class="p">}</span>
     <span class="o">...</span><span class="p">)</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">(</span>
     <span class="o">...</span>    <span class="p">{</span>
     <span class="o">...</span>        <span class="s2">&quot;agents&quot;</span><span class="p">:</span> <span class="n">Composite</span><span class="p">(</span>
     <span class="o">...</span>            <span class="p">{</span><span class="s2">&quot;observation&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">observation_specs</span><span class="p">)},</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">n_agents</span><span class="p">,)</span>
     <span class="o">...</span>        <span class="p">)</span>
     <span class="o">...</span>    <span class="p">}</span>
     <span class="o">...</span><span class="p">)</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">env</span><span class="o">.</span><span class="n">done_spec</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span>
     <span class="o">...</span>    <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
     <span class="o">...</span>    <span class="n">shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">((</span><span class="mi">1</span><span class="p">,)),</span>
     <span class="o">...</span>    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
     <span class="o">...</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<p>As you can see, it is very simple! Per-agent keys will have the nested composite spec and shared keys will follow
single agent standards.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Since reward, done and action keys may have the additional “agent” prefix (e.g., <cite>(“agents”,”action”)</cite>),
the default keys used in the arguments of other TorchRL components (e.g. “action”) will not match exactly.
Therefore, TorchRL provides the <cite>env.action_key</cite>, <cite>env.reward_key</cite>, and <cite>env.done_key</cite> attributes,
which will automatically point to the right key to use. Make sure you pass these attributes to the various
components in TorchRL to inform them of the right key (e.g., the <cite>loss.set_keys()</cite> function).</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>TorchRL abstracts these nested specs away for ease of use.
This means that accessing <cite>env.reward_spec</cite> will always return the leaf
spec if the accessed spec is Composite. Therefore, if in the example above
we run <cite>env.reward_spec</cite> after env creation, we would get the same output as <cite>torch.stack(reward_specs)}</cite>.
To get the full composite spec with the “agents” key, you can run
<cite>env.output_spec[“full_reward_spec”]</cite>. The same is valid for action and done specs.
Note that <cite>env.reward_spec == env.output_spec[“full_reward_spec”][env.reward_key]</cite>.</p>
</div>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.MarlGroupMapType.html#torchrl.envs.MarlGroupMapType" title="torchrl.envs.MarlGroupMapType"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MarlGroupMapType</span></code></a>(value)</p></td>
<td><p>Marl Group Map Type.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.check_marl_grouping.html#torchrl.envs.check_marl_grouping" title="torchrl.envs.check_marl_grouping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">check_marl_grouping</span></code></a>(group_map, agent_names)</p></td>
<td><p>Check MARL group map.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="auto-resetting-envs">
<h2>Auto-resetting Envs<a class="headerlink" href="#auto-resetting-envs" title="Permalink to this heading">¶</a></h2>
<p id="autoresetting-envs">Auto-resetting environments are environments where calls to <a class="reference internal" href="generated/torchrl.envs.EnvBase.html#id1" title="torchrl.envs.EnvBase.reset"><code class="xref py py-meth docutils literal notranslate"><span class="pre">reset()</span></code></a> are not expected when
the environment reaches a <code class="docutils literal notranslate"><span class="pre">&quot;done&quot;</span></code> state during a rollout, as the reset happens automatically.
Usually, in such cases the observations delivered with the done and reward (which effectively result from performing the
action in the environment) are actually the first observations of a new episode, and not the last observations of the
current episode.</p>
<p>To handle these cases, torchrl provides a <code class="xref py py-class docutils literal notranslate"><span class="pre">AutoResetTransform</span></code> that will copy the observations
that result from the call to <cite>step</cite> to the next <cite>reset</cite> and skip the calls to <cite>reset</cite> during rollouts (in both
<a class="reference internal" href="generated/torchrl.envs.EnvBase.html#id2" title="torchrl.envs.EnvBase.rollout"><code class="xref py py-meth docutils literal notranslate"><span class="pre">rollout()</span></code></a> and <a class="reference internal" href="generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector" title="torchrl.collectors.SyncDataCollector"><code class="xref py py-class docutils literal notranslate"><span class="pre">SyncDataCollector</span></code></a> iterations).
This transform class also provides a fine-grained control over the behavior to be adopted for the invalid observations,
which can be masked with <cite>“nan”</cite> or any other values, or not masked at all.</p>
<p>To tell torchrl that an environment is auto-resetting, it is sufficient to provide an <code class="docutils literal notranslate"><span class="pre">auto_reset</span></code> argument
during construction. If provided, an <code class="docutils literal notranslate"><span class="pre">auto_reset_replace</span></code> argument can also control whether the values of the last
observation of an episode should be replaced with some placeholder or not.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs</span><span class="w"> </span><span class="kn">import</span> <span class="n">GymEnv</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs</span><span class="w"> </span><span class="kn">import</span> <span class="n">set_gym_backend</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span><span class="w"> </span><span class="nc">AutoResettingGymEnv</span><span class="p">(</span><span class="n">GymEnv</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">tensordict</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_step</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="n">tensordict</span><span class="p">[</span><span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
<span class="gp">... </span>            <span class="n">td_reset</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="gp">... </span>            <span class="n">tensordict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">td_reset</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">done_keys</span><span class="p">))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">tensordict</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="n">tensordict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;_reset&quot;</span> <span class="ow">in</span> <span class="n">tensordict</span><span class="p">:</span>
<span class="gp">... </span>            <span class="k">return</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_reset</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">set_gym_backend</span><span class="p">(</span><span class="s2">&quot;gym&quot;</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">env</span> <span class="o">=</span> <span class="n">AutoResettingGymEnv</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">auto_reset</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">auto_reset_replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">env</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">r</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">break_when_any_done</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
<span class="go">tensor([False, False, False, False, False, False, False, False, False, False,</span>
<span class="go">        False, False, False,  True, False, False, False, False, False, False,</span>
<span class="go">        False, False, False, False, False,  True, False, False, False, False])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;observation after reset are set as nan&quot;</span><span class="p">,</span> <span class="n">r</span><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;observation&quot;</span><span class="p">])</span>
<span class="go">observation after reset are set as nan tensor([[-4.3633e-02, -1.4877e-01,  1.2849e-02,  2.7584e-01],</span>
<span class="go">        [-4.6609e-02,  4.6166e-02,  1.8366e-02, -1.2761e-02],</span>
<span class="go">        [-4.5685e-02,  2.4102e-01,  1.8111e-02, -2.9959e-01],</span>
<span class="go">        [-4.0865e-02,  4.5644e-02,  1.2119e-02, -1.2542e-03],</span>
<span class="go">        [-3.9952e-02,  2.4059e-01,  1.2094e-02, -2.9009e-01],</span>
<span class="go">        [-3.5140e-02,  4.3554e-01,  6.2920e-03, -5.7893e-01],</span>
<span class="go">        [-2.6429e-02,  6.3057e-01, -5.2867e-03, -8.6963e-01],</span>
<span class="go">        [-1.3818e-02,  8.2576e-01, -2.2679e-02, -1.1640e+00],</span>
<span class="go">        [ 2.6972e-03,  1.0212e+00, -4.5959e-02, -1.4637e+00],</span>
<span class="go">        [ 2.3121e-02,  1.2168e+00, -7.5232e-02, -1.7704e+00],</span>
<span class="go">        [ 4.7457e-02,  1.4127e+00, -1.1064e-01, -2.0854e+00],</span>
<span class="go">        [ 7.5712e-02,  1.2189e+00, -1.5235e-01, -1.8289e+00],</span>
<span class="go">        [ 1.0009e-01,  1.0257e+00, -1.8893e-01, -1.5872e+00],</span>
<span class="go">        [        nan,         nan,         nan,         nan],</span>
<span class="go">        [-3.9405e-02, -1.7766e-01, -1.0403e-02,  3.0626e-01],</span>
<span class="go">        [-4.2959e-02, -3.7263e-01, -4.2775e-03,  5.9564e-01],</span>
<span class="go">        [-5.0411e-02, -5.6769e-01,  7.6354e-03,  8.8698e-01],</span>
<span class="go">        [-6.1765e-02, -7.6292e-01,  2.5375e-02,  1.1820e+00],</span>
<span class="go">        [-7.7023e-02, -9.5836e-01,  4.9016e-02,  1.4826e+00],</span>
<span class="go">        [-9.6191e-02, -7.6387e-01,  7.8667e-02,  1.2056e+00],</span>
<span class="go">        [-1.1147e-01, -9.5991e-01,  1.0278e-01,  1.5219e+00],</span>
<span class="go">        [-1.3067e-01, -7.6617e-01,  1.3322e-01,  1.2629e+00],</span>
<span class="go">        [-1.4599e-01, -5.7298e-01,  1.5848e-01,  1.0148e+00],</span>
<span class="go">        [-1.5745e-01, -7.6982e-01,  1.7877e-01,  1.3527e+00],</span>
<span class="go">        [-1.7285e-01, -9.6668e-01,  2.0583e-01,  1.6956e+00],</span>
<span class="go">        [        nan,         nan,         nan,         nan],</span>
<span class="go">        [-4.3962e-02,  1.9845e-01, -4.5015e-02, -2.5903e-01],</span>
<span class="go">        [-3.9993e-02,  3.9418e-01, -5.0196e-02, -5.6557e-01],</span>
<span class="go">        [-3.2109e-02,  5.8997e-01, -6.1507e-02, -8.7363e-01],</span>
<span class="go">        [-2.0310e-02,  3.9574e-01, -7.8980e-02, -6.0090e-01]])</span>
</pre></div>
</div>
</section>
<section id="dynamic-specs">
<h2>Dynamic Specs<a class="headerlink" href="#dynamic-specs" title="Permalink to this heading">¶</a></h2>
<p id="dynamic-envs">Running environments in parallel is usually done via the creation of memory buffers used to pass information from one
process to another. In some cases, it may be impossible to forecast whether an environment will or will not have
consistent inputs or outputs during a rollout, as their shape may be variable. We refer to this as dynamic specs.</p>
<p>TorchRL is capable of handling dynamic specs, but the batched environments and collectors will need to be made
aware of this feature. Note that, in practice, this is detected automatically.</p>
<p>To indicate that a tensor will have a variable size along a dimension, one can set the size value as <code class="docutils literal notranslate"><span class="pre">-1</span></code> for the
desired dimensions. Because the data cannot be stacked contiguously, calls to <code class="docutils literal notranslate"><span class="pre">env.rollout</span></code> need to be made with
the <code class="docutils literal notranslate"><span class="pre">return_contiguous=False</span></code> argument.
Here is a working example:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs</span><span class="w"> </span><span class="kn">import</span> <span class="n">EnvBase</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Unbounded</span><span class="p">,</span> <span class="n">Composite</span><span class="p">,</span> <span class="n">Bounded</span><span class="p">,</span> <span class="n">Binary</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">tensordict</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorDict</span><span class="p">,</span> <span class="n">TensorDictBase</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span><span class="w"> </span><span class="nc">EnvWithDynamicSpec</span><span class="p">(</span><span class="n">EnvBase</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_count</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="p">())</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">observation_spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">(</span>
<span class="gp">... </span>            <span class="n">observation</span><span class="o">=</span><span class="n">Unbounded</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
<span class="gp">... </span>        <span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">action_spec</span> <span class="o">=</span> <span class="n">Bounded</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,))</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">full_done_spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">(</span>
<span class="gp">... </span>            <span class="n">done</span><span class="o">=</span><span class="n">Binary</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">),</span>
<span class="gp">... </span>            <span class="n">terminated</span><span class="o">=</span><span class="n">Binary</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">),</span>
<span class="gp">... </span>            <span class="n">truncated</span><span class="o">=</span><span class="n">Binary</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">),</span>
<span class="gp">... </span>        <span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">reward_spec</span> <span class="o">=</span> <span class="n">Unbounded</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">max_count</span> <span class="o">=</span> <span class="n">max_count</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="gp">... </span>        <span class="n">data</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span>
<span class="gp">... </span>            <span class="p">{</span>
<span class="gp">... </span>                <span class="s2">&quot;observation&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
<span class="gp">... </span>                    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="gp">... </span>                    <span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_spec</span><span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
<span class="gp">... </span>                <span class="p">)</span>
<span class="gp">... </span>            <span class="p">}</span>
<span class="gp">... </span>        <span class="p">)</span>
<span class="gp">... </span>        <span class="n">data</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">done_spec</span><span class="o">.</span><span class="n">zero</span><span class="p">())</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">data</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="p">,</span>
<span class="gp">... </span>        <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
<span class="gp">... </span>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="gp">... </span>        <span class="n">done</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_count</span>
<span class="gp">... </span>        <span class="n">observation</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span>
<span class="gp">... </span>            <span class="p">{</span>
<span class="gp">... </span>                <span class="s2">&quot;observation&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
<span class="gp">... </span>                    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="gp">... </span>                    <span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_spec</span><span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
<span class="gp">... </span>                <span class="p">)</span>
<span class="gp">... </span>            <span class="p">}</span>
<span class="gp">... </span>        <span class="p">)</span>
<span class="gp">... </span>        <span class="n">done</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_done_spec</span><span class="o">.</span><span class="n">zero</span><span class="p">()</span> <span class="o">|</span> <span class="n">done</span>
<span class="gp">... </span>        <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_reward_spec</span><span class="o">.</span><span class="n">zero</span><span class="p">()</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">observation</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">done</span><span class="p">)</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">_set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">manual_seed</span> <span class="o">=</span> <span class="n">seed</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">seed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">EnvWithDynamicSpec</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">return_contiguous</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="go">LazyStackedTensorDict(</span>
<span class="go">    fields={</span>
<span class="go">        action: Tensor(shape=torch.Size([5, 2]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="go">        done: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="go">        next: LazyStackedTensorDict(</span>
<span class="go">            fields={</span>
<span class="go">                done: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="go">                observation: Tensor(shape=torch.Size([5, 3, -1, 2]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="go">                reward: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="go">                terminated: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="go">                truncated: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="go">            exclusive_fields={</span>
<span class="go">            },</span>
<span class="go">            batch_size=torch.Size([5]),</span>
<span class="go">            device=None,</span>
<span class="go">            is_shared=False,</span>
<span class="go">            stack_dim=0),</span>
<span class="go">        observation: Tensor(shape=torch.Size([5, 3, -1, 2]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="go">        terminated: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="go">        truncated: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="go">    exclusive_fields={</span>
<span class="go">    },</span>
<span class="go">    batch_size=torch.Size([5]),</span>
<span class="go">    device=None,</span>
<span class="go">    is_shared=False,</span>
<span class="go">    stack_dim=0)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The absence of memory buffers in <a class="reference internal" href="generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParallelEnv</span></code></a> and in
data collectors can impact performance of these classes dramatically. Any
such usage should be carefully benchmarked against a plain execution on a
single process, as serializing and deserializing large numbers of tensors
can be very expensive.</p>
</div>
<p>Currently, <code class="xref py py-func docutils literal notranslate"><span class="pre">check_env_specs()</span></code> will pass for dynamic specs where a shape varies along some
dimensions, but not when a key is present during a step and absent during others, or when the number of dimensions
varies.</p>
</section>
<section id="transforms">
<h2>Transforms<a class="headerlink" href="#transforms" title="Permalink to this heading">¶</a></h2>
<p id="id2">In most cases, the raw output of an environment must be treated before being passed to another object (such as a
policy or a value operator). To do this, TorchRL provides a set of transforms that aim at reproducing the transform
logic of <cite>torch.distributions.Transform</cite> and <cite>torchvision.transforms</cite>.
Our environment <a class="reference internal" href="../tutorials/pendulum.html#pendulum-tuto"><span class="std std-ref">tutorial</span></a>
provides more information on how to design a custom transform.</p>
<p>Transformed environments are build using the <a class="reference internal" href="generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv" title="torchrl.envs.transforms.TransformedEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">TransformedEnv</span></code></a> primitive.
Composed transforms are built using the <a class="reference internal" href="generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose" title="torchrl.envs.transforms.Compose"><code class="xref py py-class docutils literal notranslate"><span class="pre">Compose</span></code></a> class:</p>
<div class="literal-block-wrapper docutils container" id="id9">
<div class="code-block-caption"><span class="caption-text">Transformed environment</span><a class="headerlink" href="#id9" title="Permalink to this code">¶</a></div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="o">&gt;&gt;&gt;</span> <span class="n">base_env</span> <span class="o">=</span> <span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">from_pixels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">transform</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">(</span><span class="n">ToTensorImage</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pixels&quot;</span><span class="p">]),</span> <span class="n">Resize</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pixels&quot;</span><span class="p">]))</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">env</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span><span class="n">base_env</span><span class="p">,</span> <span class="n">transform</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Transforms are usually subclasses of <a class="reference internal" href="generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform" title="torchrl.envs.transforms.Transform"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transform</span></code></a>, although any
<code class="docutils literal notranslate"><span class="pre">Callable[[TensorDictBase],</span> <span class="pre">TensorDictBase]</span></code>.</p>
<p>By default, the transformed environment will inherit the device of the
<code class="xref py py-obj docutils literal notranslate"><span class="pre">base_env</span></code> that is passed to it. The transforms will then be executed on that device.
It is now apparent that this can bring a significant speedup depending on the kind of
operations that is to be computed.</p>
<p>A great advantage of environment wrappers is that one can consult the environment up to that wrapper.
The same can be achieved with TorchRL transformed environments: the <code class="docutils literal notranslate"><span class="pre">parent</span></code> attribute will
return a new <a class="reference internal" href="generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv" title="torchrl.envs.transforms.TransformedEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">TransformedEnv</span></code></a> with all the transforms up to the transform of interest.
Re-using the example above:</p>
<div class="literal-block-wrapper docutils container" id="id10">
<div class="code-block-caption"><span class="caption-text">Transform parent</span><a class="headerlink" href="#id10" title="Permalink to this code">¶</a></div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="o">&gt;&gt;&gt;</span> <span class="n">resize_parent</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">transform</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">parent</span>  <span class="c1"># returns the same as TransformedEnv(base_env, transform[:-1])</span>
</pre></div>
</div>
</div>
<p>Transformed environment can be used with vectorized environments.
Since each transform uses a <code class="docutils literal notranslate"><span class="pre">&quot;in_keys&quot;</span></code>/<code class="docutils literal notranslate"><span class="pre">&quot;out_keys&quot;</span></code> set of keyword argument, it is
also easy to root the transform graph to each component of the observation data (e.g.
pixels or states etc).</p>
<section id="forward-and-inverse-transforms">
<h3>Forward and inverse transforms<a class="headerlink" href="#forward-and-inverse-transforms" title="Permalink to this heading">¶</a></h3>
<p>Transforms also have an <code class="xref py py-meth docutils literal notranslate"><span class="pre">inv()</span></code> method that is called before the action is applied in reverse
order over the composed transform chain. This allows applying transforms to data in the environment before the action is
taken in the environment. The keys to be included in this inverse transform are passed through the <cite>“in_keys_inv”</cite>
keyword argument, and the out-keys default to these values in most cases:</p>
<div class="literal-block-wrapper docutils container" id="id11">
<div class="code-block-caption"><span class="caption-text">Inverse transform</span><a class="headerlink" href="#id11" title="Permalink to this code">¶</a></div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="o">&gt;&gt;&gt;</span> <span class="n">env</span><span class="o">.</span><span class="n">append_transform</span><span class="p">(</span><span class="n">DoubleToFloat</span><span class="p">(</span><span class="n">in_keys_inv</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]))</span>  <span class="c1"># will map the action from float32 to float64 before calling the base_env.step</span>
</pre></div>
</div>
</div>
<p>The following paragraphs detail how one can think about what is to be considered <cite>in_</cite> or <cite>out_</cite> features.</p>
<section id="understanding-transform-keys">
<h4>Understanding Transform Keys<a class="headerlink" href="#understanding-transform-keys" title="Permalink to this heading">¶</a></h4>
<p>In transforms, <cite>in_keys</cite> and <cite>out_keys</cite> define the interaction between the base environment and the outside world
(e.g., your policy):</p>
<ul class="simple">
<li><p><cite>in_keys</cite> refers to the base environment’s perspective (inner = <cite>base_env</cite> of the
<code class="xref py py-class docutils literal notranslate"><span class="pre">TransformedEnv</span></code>).</p></li>
<li><p><cite>out_keys</cite> refers to the outside world (outer = <cite>policy</cite>, <cite>agent</cite>, etc.).</p></li>
</ul>
<p>For example, with <cite>in_keys=[“obs”]</cite> and <cite>out_keys=[“obs_standardized”]</cite>, the policy will “see” a standardized
observation, while the base environment outputs a regular observation.</p>
<p>Similarly, for inverse keys:</p>
<ul class="simple">
<li><p><cite>in_keys_inv</cite> refers to entries as seen by the base environment.</p></li>
<li><p><cite>out_keys_inv</cite> refers to entries as seen or produced by the policy.</p></li>
</ul>
<p>The following figure illustrates this concept for the <code class="xref py py-class docutils literal notranslate"><span class="pre">RenameTransform</span></code> class: the input
<cite>TensorDict</cite> of the <cite>step</cite> function must include the <cite>out_keys_inv</cite> as they are part of the outside world. The
transform changes these names to match the names of the inner, base environment using the <cite>in_keys_inv</cite>.
The inverse process is executed with the output tensordict, where the <cite>in_keys</cite> are mapped to the corresponding
<cite>out_keys</cite>.</p>
<figure class="align-default" id="id12">
<img alt="../_images/rename_transform.png" src="../_images/rename_transform.png" />
<figcaption>
<p><span class="caption-text">Rename transform logic</span><a class="headerlink" href="#id12" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>During a call to <cite>inv</cite>, the transforms are executed in reversed order (compared to the forward / step mode).</p>
</div>
</section>
<section id="transforming-tensors-and-specs">
<h4>Transforming Tensors and Specs<a class="headerlink" href="#transforming-tensors-and-specs" title="Permalink to this heading">¶</a></h4>
<p>When transforming actual tensors (coming from the policy), the process is schematically represented as:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">td</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
</pre></div>
</div>
<p>This starts with the outermost transform to the innermost transform, ensuring the action value exposed to the policy
is properly transformed.</p>
<p>For transforming the action spec, the process should go from innermost to outermost (similar to observation specs):</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">transform_action_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action_spec</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">action_spec</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">transform_action_spec</span><span class="p">(</span><span class="n">action_spec</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">action_spec</span>
</pre></div>
</div>
<p>A pseudocode for a single transform_action_spec could be:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">transform_action_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action_spec</span><span class="p">):</span>
<span class="gp">... </span>   <span class="k">return</span> <span class="n">spec_from_random_values</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_apply_transform</span><span class="p">(</span><span class="n">action_spec</span><span class="o">.</span><span class="n">rand</span><span class="p">()))</span>
</pre></div>
</div>
<p>This approach ensures that the “outside” spec is inferred from the “inside” spec. Note that we did not call
<cite>_inv_apply_transform</cite> but <cite>_apply_transform</cite> on purpose!</p>
</section>
<section id="exposing-specs-to-the-outside-world">
<h4>Exposing Specs to the Outside World<a class="headerlink" href="#exposing-specs-to-the-outside-world" title="Permalink to this heading">¶</a></h4>
<p><cite>TransformedEnv</cite> will expose the specs corresponding to the <cite>out_keys_inv</cite> for actions and states.
For example, with <code class="xref py py-class docutils literal notranslate"><span class="pre">ActionDiscretizer</span></code>, the environment’s action (e.g., <cite>“action”</cite>) is a float-valued
tensor that should not be generated when using <a class="reference internal" href="generated/torchrl.envs.EnvBase.html#torchrl.envs.EnvBase.rand_action" title="torchrl.envs.EnvBase.rand_action"><code class="xref py py-meth docutils literal notranslate"><span class="pre">rand_action()</span></code></a> with the transformed
environment. Instead, <cite>“action_discrete”</cite> should be generated, and its continuous counterpart obtained from the
transform. Therefore, the user should see the <cite>“action_discrete”</cite> entry being exposed, but not <cite>“action”</cite>.</p>
</section>
</section>
<section id="designing-your-own-transform">
<h3>Designing your own Transform<a class="headerlink" href="#designing-your-own-transform" title="Permalink to this heading">¶</a></h3>
<p>To create a basic, custom transform, you need to subclass the <cite>Transform</cite> class and implement the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">_apply_transform()</span></code> method. Here’s an example of a simple transform that adds 1 to the observation
tensor:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span><span class="w"> </span><span class="nc">AddOneToObs</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="gp">... </span><span class="w">    </span><span class="sd">&quot;&quot;&quot;A transform that adds 1 to the observation tensor.&quot;&quot;&quot;</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">],</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">])</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">obs</span> <span class="o">+</span> <span class="mi">1</span>
</pre></div>
</div>
<section id="tips-for-subclassing-transform">
<h4>Tips for subclassing <cite>Transform</cite><a class="headerlink" href="#tips-for-subclassing-transform" title="Permalink to this heading">¶</a></h4>
<p>There are various ways of subclassing a transform. The things to take into considerations are:</p>
<ul class="simple">
<li><p>Is the transform identical for each tensor / item being transformed? Use
<code class="xref py py-meth docutils literal notranslate"><span class="pre">_apply_transform()</span></code> and <code class="xref py py-meth docutils literal notranslate"><span class="pre">_inv_apply_transform()</span></code>.</p></li>
<li><p>The transform needs access to the input data to env.step as well as output? Rewrite
<code class="xref py py-meth docutils literal notranslate"><span class="pre">_step()</span></code>.
Otherwise, rewrite <code class="xref py py-meth docutils literal notranslate"><span class="pre">_call()</span></code> (or <code class="xref py py-meth docutils literal notranslate"><span class="pre">_inv_call()</span></code>).</p></li>
<li><p>Is the transform to be used within a replay buffer? Overwrite <code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code>,
<code class="xref py py-meth docutils literal notranslate"><span class="pre">inv()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">_apply_transform()</span></code> or
<code class="xref py py-meth docutils literal notranslate"><span class="pre">_inv_apply_transform()</span></code>.</p></li>
<li><p>Within a transform, you can access (and make calls to) the parent environment using
<code class="xref py py-attr docutils literal notranslate"><span class="pre">parent</span></code> (the base env + all transforms till this one) or
<code class="xref py py-meth docutils literal notranslate"><span class="pre">container()</span></code> (The object that encapsulates the transform).</p></li>
<li><p>Don’t forget to edits the specs if needed: top level: <code class="xref py py-meth docutils literal notranslate"><span class="pre">transform_output_spec()</span></code>,
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transform_input_spec()</span></code>.
Leaf level: <code class="xref py py-meth docutils literal notranslate"><span class="pre">transform_observation_spec()</span></code>,
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transform_action_spec()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">transform_state_spec()</span></code>,
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transform_reward_spec()</span></code> and
<code class="xref py py-meth docutils literal notranslate"><span class="pre">transform_reward_spec()</span></code>.</p></li>
</ul>
<p>For practical examples, see the methods listed above.</p>
<p>You can use a transform in an environment by passing it to the TransformedEnv constructor:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span><span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">),</span> <span class="n">AddOneToObs</span><span class="p">())</span>
</pre></div>
</div>
<p>You can compose multiple transforms together using the Compose class:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">transform</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">(</span><span class="n">AddOneToObs</span><span class="p">(),</span> <span class="n">RewardSum</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span><span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">),</span> <span class="n">transform</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="inverse-transforms">
<h4>Inverse Transforms<a class="headerlink" href="#inverse-transforms" title="Permalink to this heading">¶</a></h4>
<p>Some transforms have an inverse transform that can be used to undo the transformation. For example, the AddOneToAction
transform has an inverse transform that subtracts 1 from the action tensor:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span><span class="w"> </span><span class="nc">AddOneToAction</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
<span class="gp">... </span><span class="w">    </span><span class="sd">&quot;&quot;&quot;A transform that adds 1 to the action tensor.&quot;&quot;&quot;</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="p">[],</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[],</span> <span class="n">in_keys_inv</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">],</span> <span class="n">out_keys_inv</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">])</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_apply_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">action</span> <span class="o">+</span> <span class="mi">1</span>
</pre></div>
</div>
</section>
<section id="using-a-transform-with-a-replay-buffer">
<h4>Using a Transform with a Replay Buffer<a class="headerlink" href="#using-a-transform-with-a-replay-buffer" title="Permalink to this heading">¶</a></h4>
<p>You can use a transform with a replay buffer by passing it to the ReplayBuffer constructor:</p>
</section>
</section>
<section id="cloning-transforms">
<h3>Cloning transforms<a class="headerlink" href="#cloning-transforms" title="Permalink to this heading">¶</a></h3>
<p>Because transforms appended to an environment are “registered” to this environment
through the <code class="docutils literal notranslate"><span class="pre">transform.parent</span></code> property, when manipulating transforms we should keep
in mind that the parent may come and go following what is being done with the transform.
Here are some examples: if we get a single transform from a <a class="reference internal" href="generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose" title="torchrl.envs.transforms.Compose"><code class="xref py py-class docutils literal notranslate"><span class="pre">Compose</span></code></a> object,
this transform will keep its parent:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">third_transform</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">transform</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">third_transform</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</pre></div>
</div>
<p>This means that using this transform for another environment is prohibited, as
the other environment would replace the parent and this may lead to unexpected
behviours. Fortunately, the <a class="reference internal" href="generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform" title="torchrl.envs.transforms.Transform"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transform</span></code></a> class comes with a <code class="xref py py-func docutils literal notranslate"><span class="pre">clone()</span></code>
method that will erase the parent while keeping the identity of all the
registered buffers:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">TransformedEnv</span><span class="p">(</span><span class="n">base_env</span><span class="p">,</span> <span class="n">third_transform</span><span class="p">)</span>  <span class="c1"># raises an Exception as third_transform already has a parent</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TransformedEnv</span><span class="p">(</span><span class="n">base_env</span><span class="p">,</span> <span class="n">third_transform</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>  <span class="c1"># works</span>
</pre></div>
</div>
<p>On a single process or if the buffers are placed in shared memory, this will
result in all the clone transforms to keep the same behavior even if the
buffers are changed in place (which is what will happen with the <a class="reference internal" href="generated/torchrl.envs.transforms.CatFrames.html#torchrl.envs.transforms.CatFrames" title="torchrl.envs.transforms.CatFrames"><code class="xref py py-class docutils literal notranslate"><span class="pre">CatFrames</span></code></a>
transform, for instance). In distributed settings, this may not hold and one
should be careful about the expected behavior of the cloned transforms in this
context.
Finally, notice that indexing multiple transforms from a <a class="reference internal" href="generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose" title="torchrl.envs.transforms.Compose"><code class="xref py py-class docutils literal notranslate"><span class="pre">Compose</span></code></a> transform
may also result in loss of parenthood for these transforms: the reason is that
indexing a <a class="reference internal" href="generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose" title="torchrl.envs.transforms.Compose"><code class="xref py py-class docutils literal notranslate"><span class="pre">Compose</span></code></a> transform results in another <a class="reference internal" href="generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose" title="torchrl.envs.transforms.Compose"><code class="xref py py-class docutils literal notranslate"><span class="pre">Compose</span></code></a> transform
that does not have a parent environment. Hence, we have to clone the sub-transforms
to be able to create this other composition:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span><span class="n">base_env</span><span class="p">,</span> <span class="n">Compose</span><span class="p">(</span><span class="n">transform1</span><span class="p">,</span> <span class="n">transform2</span><span class="p">,</span> <span class="n">transform3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">last_two</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">transform</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">last_two</span><span class="p">,</span> <span class="n">Compose</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">last_two</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="kc">None</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">last_two</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">transform2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">last_two</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">type</span><span class="p">(</span><span class="n">transform2</span><span class="p">))</span>  <span class="c1"># and the buffers will match</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">last_two</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">transform3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">last_two</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">type</span><span class="p">(</span><span class="n">transform3</span><span class="p">))</span>  <span class="c1"># and the buffers will match</span>
</pre></div>
</div>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.Transform.html#torchrl.envs.transforms.Transform" title="torchrl.envs.transforms.Transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Transform</span></code></a>([in_keys, out_keys, in_keys_inv, ...])</p></td>
<td><p>Base class for environment transforms, which modify or create new data in a tensordict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv" title="torchrl.envs.transforms.TransformedEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TransformedEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>A transformed environment.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.ActionDiscretizer.html#torchrl.envs.transforms.ActionDiscretizer" title="torchrl.envs.transforms.ActionDiscretizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ActionDiscretizer</span></code></a>(num_intervals[, ...])</p></td>
<td><p>A transform to discretize a continuous action space.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.ActionMask.html#torchrl.envs.transforms.ActionMask" title="torchrl.envs.transforms.ActionMask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ActionMask</span></code></a>([action_key, mask_key])</p></td>
<td><p>An adaptive action masker.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.AutoResetEnv.html#torchrl.envs.transforms.AutoResetEnv" title="torchrl.envs.transforms.AutoResetEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AutoResetEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>A subclass for auto-resetting envs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.AutoResetTransform.html#torchrl.envs.transforms.AutoResetTransform" title="torchrl.envs.transforms.AutoResetTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AutoResetTransform</span></code></a>(*[, replace, fill_float, ...])</p></td>
<td><p>A transform for auto-resetting environments.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.BatchSizeTransform.html#torchrl.envs.transforms.BatchSizeTransform" title="torchrl.envs.transforms.BatchSizeTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BatchSizeTransform</span></code></a>(*[, batch_size, ...])</p></td>
<td><p>A transform to modify the batch-size of an environment.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.BinarizeReward.html#torchrl.envs.transforms.BinarizeReward" title="torchrl.envs.transforms.BinarizeReward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BinarizeReward</span></code></a>([in_keys, out_keys])</p></td>
<td><p>Maps the reward to a binary value (0 or 1) if the reward is null or non-null, respectively.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.BurnInTransform.html#torchrl.envs.transforms.BurnInTransform" title="torchrl.envs.transforms.BurnInTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BurnInTransform</span></code></a>(modules, burn_in[, out_keys])</p></td>
<td><p>Transform to partially burn-in data sequences.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.CatFrames.html#torchrl.envs.transforms.CatFrames" title="torchrl.envs.transforms.CatFrames"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CatFrames</span></code></a>(N, dim[, in_keys, out_keys, ...])</p></td>
<td><p>Concatenates successive observation frames into a single tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.CatTensors.html#torchrl.envs.transforms.CatTensors" title="torchrl.envs.transforms.CatTensors"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CatTensors</span></code></a>([in_keys, out_key, dim, ...])</p></td>
<td><p>Concatenates several keys in a single tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.CenterCrop.html#torchrl.envs.transforms.CenterCrop" title="torchrl.envs.transforms.CenterCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CenterCrop</span></code></a>(w[, h, in_keys, out_keys])</p></td>
<td><p>Crops the center of an image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.ClipTransform.html#torchrl.envs.transforms.ClipTransform" title="torchrl.envs.transforms.ClipTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ClipTransform</span></code></a>([in_keys, out_keys, ...])</p></td>
<td><p>A transform to clip input (state, action) or output (observation, reward) values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose" title="torchrl.envs.transforms.Compose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Compose</span></code></a>(transforms)</p></td>
<td><p>Composes a chain of transforms.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.ConditionalPolicySwitch.html#torchrl.envs.transforms.ConditionalPolicySwitch" title="torchrl.envs.transforms.ConditionalPolicySwitch"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ConditionalPolicySwitch</span></code></a>(policy, condition)</p></td>
<td><p>A transform that conditionally switches between policies based on a specified condition.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.ConditionalSkip.html#torchrl.envs.transforms.ConditionalSkip" title="torchrl.envs.transforms.ConditionalSkip"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ConditionalSkip</span></code></a>(cond)</p></td>
<td><p>A transform that skips steps in the env if certain conditions are met.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.Crop.html#torchrl.envs.transforms.Crop" title="torchrl.envs.transforms.Crop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Crop</span></code></a>(w[, h, top, left, in_keys, out_keys])</p></td>
<td><p>Crops the input image at the specified location and output size.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.DTypeCastTransform.html#torchrl.envs.transforms.DTypeCastTransform" title="torchrl.envs.transforms.DTypeCastTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DTypeCastTransform</span></code></a>(dtype_in, dtype_out[, ...])</p></td>
<td><p>Casts one dtype to another for selected keys.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.DeviceCastTransform.html#torchrl.envs.transforms.DeviceCastTransform" title="torchrl.envs.transforms.DeviceCastTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DeviceCastTransform</span></code></a>(device[, orig_device, ...])</p></td>
<td><p>Moves data from one device to another.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.DiscreteActionProjection.html#torchrl.envs.transforms.DiscreteActionProjection" title="torchrl.envs.transforms.DiscreteActionProjection"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DiscreteActionProjection</span></code></a>(...[, action_key, ...])</p></td>
<td><p>Projects discrete actions from a high dimensional space to a low dimensional space.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.DoubleToFloat.html#torchrl.envs.transforms.DoubleToFloat" title="torchrl.envs.transforms.DoubleToFloat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DoubleToFloat</span></code></a>([in_keys, out_keys, ...])</p></td>
<td><p>Casts one dtype to another for selected keys.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.EndOfLifeTransform.html#torchrl.envs.transforms.EndOfLifeTransform" title="torchrl.envs.transforms.EndOfLifeTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EndOfLifeTransform</span></code></a>([eol_key, lives_key, ...])</p></td>
<td><p>Registers the end-of-life signal from a Gym env with a <cite>lives</cite> method.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.ExcludeTransform.html#torchrl.envs.transforms.ExcludeTransform" title="torchrl.envs.transforms.ExcludeTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ExcludeTransform</span></code></a>(*excluded_keys[, inverse])</p></td>
<td><p>Excludes keys from the data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.FiniteTensorDictCheck.html#torchrl.envs.transforms.FiniteTensorDictCheck" title="torchrl.envs.transforms.FiniteTensorDictCheck"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FiniteTensorDictCheck</span></code></a>()</p></td>
<td><p>This transform will check that all the items of the tensordict are finite, and raise an exception if they are not.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.FlattenObservation.html#torchrl.envs.transforms.FlattenObservation" title="torchrl.envs.transforms.FlattenObservation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FlattenObservation</span></code></a>(first_dim, last_dim[, ...])</p></td>
<td><p>Flatten adjacent dimensions of a tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.FrameSkipTransform.html#torchrl.envs.transforms.FrameSkipTransform" title="torchrl.envs.transforms.FrameSkipTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FrameSkipTransform</span></code></a>([frame_skip])</p></td>
<td><p>A frame-skip transform.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.GrayScale.html#torchrl.envs.transforms.GrayScale" title="torchrl.envs.transforms.GrayScale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GrayScale</span></code></a>([in_keys, out_keys])</p></td>
<td><p>Turns a pixel observation to grayscale.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.Hash.html#torchrl.envs.transforms.Hash" title="torchrl.envs.transforms.Hash"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Hash</span></code></a>(in_keys, out_keys[, in_keys_inv, ...])</p></td>
<td><p>Adds a hash value to a tensordict.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.InitTracker.html#torchrl.envs.transforms.InitTracker" title="torchrl.envs.transforms.InitTracker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">InitTracker</span></code></a>([init_key])</p></td>
<td><p>Reset tracker.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.KLRewardTransform.html#torchrl.envs.transforms.KLRewardTransform" title="torchrl.envs.transforms.KLRewardTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KLRewardTransform</span></code></a>(actor[, coef, in_keys, ...])</p></td>
<td><p>A transform to add a KL[pi_current||pi_0] correction term to the reward.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.LineariseRewards.html#torchrl.envs.transforms.LineariseRewards" title="torchrl.envs.transforms.LineariseRewards"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LineariseRewards</span></code></a>(in_keys[, out_keys, weights])</p></td>
<td><p>Transforms a multi-objective reward signal to a single-objective one via a weighted sum.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.ModuleTransform.html#torchrl.envs.transforms.ModuleTransform" title="torchrl.envs.transforms.ModuleTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ModuleTransform</span></code></a>(*args[, use_ray_service])</p></td>
<td><p>A transform that wraps a module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.MultiAction.html#torchrl.envs.transforms.MultiAction" title="torchrl.envs.transforms.MultiAction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiAction</span></code></a>(*[, dim, stack_rewards, ...])</p></td>
<td><p>A transform to execute multiple actions in the parent environment.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.NoopResetEnv.html#torchrl.envs.transforms.NoopResetEnv" title="torchrl.envs.transforms.NoopResetEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NoopResetEnv</span></code></a>([noops, random])</p></td>
<td><p>Runs a series of random actions when an environment is reset.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.ObservationNorm.html#torchrl.envs.transforms.ObservationNorm" title="torchrl.envs.transforms.ObservationNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ObservationNorm</span></code></a>([loc, scale, in_keys, ...])</p></td>
<td><p>Observation affine transformation layer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.ObservationTransform.html#torchrl.envs.transforms.ObservationTransform" title="torchrl.envs.transforms.ObservationTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ObservationTransform</span></code></a>([in_keys, out_keys, ...])</p></td>
<td><p>Abstract class for transformations of the observations.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.PermuteTransform.html#torchrl.envs.transforms.PermuteTransform" title="torchrl.envs.transforms.PermuteTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PermuteTransform</span></code></a>(dims[, in_keys, out_keys, ...])</p></td>
<td><p>Permutation transform.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.PinMemoryTransform.html#torchrl.envs.transforms.PinMemoryTransform" title="torchrl.envs.transforms.PinMemoryTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PinMemoryTransform</span></code></a>()</p></td>
<td><p>Calls pin_memory on the tensordict to facilitate writing on CUDA devices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.R3MTransform.html#torchrl.envs.transforms.R3MTransform" title="torchrl.envs.transforms.R3MTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">R3MTransform</span></code></a>(*args, **kwargs)</p></td>
<td><p>R3M Transform class.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.RandomCropTensorDict.html#torchrl.envs.transforms.RandomCropTensorDict" title="torchrl.envs.transforms.RandomCropTensorDict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomCropTensorDict</span></code></a>(sub_seq_len[, ...])</p></td>
<td><p>A trajectory sub-sampler for ReplayBuffer and modules.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.RemoveEmptySpecs.html#torchrl.envs.transforms.RemoveEmptySpecs" title="torchrl.envs.transforms.RemoveEmptySpecs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RemoveEmptySpecs</span></code></a>([in_keys, out_keys, ...])</p></td>
<td><p>Removes empty specs and content from an environment.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.RenameTransform.html#torchrl.envs.transforms.RenameTransform" title="torchrl.envs.transforms.RenameTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RenameTransform</span></code></a>(in_keys, out_keys[, ...])</p></td>
<td><p>A transform to rename entries in the output tensordict (or input tensordict via the inverse keys).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.Resize.html#torchrl.envs.transforms.Resize" title="torchrl.envs.transforms.Resize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Resize</span></code></a>(w[, h, interpolation, in_keys, out_keys])</p></td>
<td><p>Resizes a pixel observation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.Reward2GoTransform.html#torchrl.envs.transforms.Reward2GoTransform" title="torchrl.envs.transforms.Reward2GoTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Reward2GoTransform</span></code></a>([gamma, in_keys, ...])</p></td>
<td><p>Calculates the reward to go based on the episode reward and a discount factor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.RewardClipping.html#torchrl.envs.transforms.RewardClipping" title="torchrl.envs.transforms.RewardClipping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RewardClipping</span></code></a>([clamp_min, clamp_max, ...])</p></td>
<td><p>Clips the reward between <cite>clamp_min</cite> and <cite>clamp_max</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.RewardScaling.html#torchrl.envs.transforms.RewardScaling" title="torchrl.envs.transforms.RewardScaling"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RewardScaling</span></code></a>(loc, scale[, in_keys, ...])</p></td>
<td><p>Affine transform of the reward.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.RewardSum.html#torchrl.envs.transforms.RewardSum" title="torchrl.envs.transforms.RewardSum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RewardSum</span></code></a>([in_keys, out_keys, reset_keys, ...])</p></td>
<td><p>Tracks episode cumulative rewards.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.SelectTransform.html#torchrl.envs.transforms.SelectTransform" title="torchrl.envs.transforms.SelectTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SelectTransform</span></code></a>(*selected_keys[, ...])</p></td>
<td><p>Select keys from the input tensordict.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.SignTransform.html#torchrl.envs.transforms.SignTransform" title="torchrl.envs.transforms.SignTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SignTransform</span></code></a>([in_keys, out_keys, ...])</p></td>
<td><p>A transform to compute the signs of TensorDict values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.SqueezeTransform.html#torchrl.envs.transforms.SqueezeTransform" title="torchrl.envs.transforms.SqueezeTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SqueezeTransform</span></code></a>(*args, **kwargs)</p></td>
<td><p>Removes a dimension of size one at the specified position.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.Stack.html#torchrl.envs.transforms.Stack" title="torchrl.envs.transforms.Stack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Stack</span></code></a>(in_keys, out_key[, in_key_inv, ...])</p></td>
<td><p>Stacks tensors and tensordicts.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.StepCounter.html#torchrl.envs.transforms.StepCounter" title="torchrl.envs.transforms.StepCounter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StepCounter</span></code></a>([max_steps, truncated_key, ...])</p></td>
<td><p>Counts the steps from a reset and optionally sets the truncated state to <code class="docutils literal notranslate"><span class="pre">True</span></code> after a certain number of steps.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.TargetReturn.html#torchrl.envs.transforms.TargetReturn" title="torchrl.envs.transforms.TargetReturn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TargetReturn</span></code></a>(target_return[, mode, in_keys, ...])</p></td>
<td><p>Sets a target return for the agent to achieve in the environment.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.TensorDictPrimer.html#torchrl.envs.transforms.TensorDictPrimer" title="torchrl.envs.transforms.TensorDictPrimer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorDictPrimer</span></code></a>([primers, random, ...])</p></td>
<td><p>A primer for TensorDict initialization at reset time.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.TimeMaxPool.html#torchrl.envs.transforms.TimeMaxPool" title="torchrl.envs.transforms.TimeMaxPool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TimeMaxPool</span></code></a>([in_keys, out_keys, T, reset_key])</p></td>
<td><p>Take the maximum value in each position over the last T observations.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.Timer.html#torchrl.envs.transforms.Timer" title="torchrl.envs.transforms.Timer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Timer</span></code></a>([out_keys, time_key])</p></td>
<td><p>A transform that measures the time intervals between <cite>inv</cite> and <cite>call</cite> operations in an environment.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.Tokenizer.html#torchrl.envs.transforms.Tokenizer" title="torchrl.envs.transforms.Tokenizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tokenizer</span></code></a>([in_keys, out_keys, in_keys_inv, ...])</p></td>
<td><p>Applies a tokenization operation on the specified inputs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.ToTensorImage.html#torchrl.envs.transforms.ToTensorImage" title="torchrl.envs.transforms.ToTensorImage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ToTensorImage</span></code></a>([from_int, unsqueeze, dtype, ...])</p></td>
<td><p>Transforms a numpy-like image (W x H x C) to a pytorch image (C x W x H).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.TrajCounter.html#torchrl.envs.transforms.TrajCounter" title="torchrl.envs.transforms.TrajCounter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TrajCounter</span></code></a>([out_key, repeats])</p></td>
<td><p>Global trajectory counter transform.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.UnaryTransform.html#torchrl.envs.transforms.UnaryTransform" title="torchrl.envs.transforms.UnaryTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">UnaryTransform</span></code></a>(in_keys, out_keys[, ...])</p></td>
<td><p>Applies a unary operation on the specified inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.UnsqueezeTransform.html#torchrl.envs.transforms.UnsqueezeTransform" title="torchrl.envs.transforms.UnsqueezeTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">UnsqueezeTransform</span></code></a>(*args, **kwargs)</p></td>
<td><p>Inserts a dimension of size one at the specified position.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.VC1Transform.html#torchrl.envs.transforms.VC1Transform" title="torchrl.envs.transforms.VC1Transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VC1Transform</span></code></a>(in_keys, out_keys, model_name)</p></td>
<td><p>VC1 Transform class.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.VIPRewardTransform.html#torchrl.envs.transforms.VIPRewardTransform" title="torchrl.envs.transforms.VIPRewardTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VIPRewardTransform</span></code></a>(*args, **kwargs)</p></td>
<td><p>A VIP transform to compute rewards based on embedded similarity.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.VIPTransform.html#torchrl.envs.transforms.VIPTransform" title="torchrl.envs.transforms.VIPTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VIPTransform</span></code></a>(*args, **kwargs)</p></td>
<td><p>VIP Transform class.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.VecGymEnvTransform.html#torchrl.envs.transforms.VecGymEnvTransform" title="torchrl.envs.transforms.VecGymEnvTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VecGymEnvTransform</span></code></a>([final_name, ...])</p></td>
<td><p>A transform for GymWrapper subclasses that handles the auto-reset in a consistent way.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.VecNorm.html#torchrl.envs.transforms.VecNorm" title="torchrl.envs.transforms.VecNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VecNorm</span></code></a>(*args, **kwargs)</p></td>
<td><p>Moving average normalization layer for torchrl environments.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.VecNormV2.html#torchrl.envs.transforms.VecNormV2" title="torchrl.envs.transforms.VecNormV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VecNormV2</span></code></a>(in_keys[, out_keys, lock, ...])</p></td>
<td><p>A class for normalizing vectorized observations and rewards in reinforcement learning environments.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.transforms.gSDENoise.html#torchrl.envs.transforms.gSDENoise" title="torchrl.envs.transforms.gSDENoise"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gSDENoise</span></code></a>([state_dim, action_dim, shape])</p></td>
<td><p>A gSDE noise initializer.</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="environments-with-masked-actions">
<h2>Environments with masked actions<a class="headerlink" href="#environments-with-masked-actions" title="Permalink to this heading">¶</a></h2>
<p>In some environments with discrete actions, the actions available to the agent might change throughout execution.
In such cases the environments will output an action mask (under the <code class="docutils literal notranslate"><span class="pre">&quot;action_mask&quot;</span></code> key by default).
This mask needs to be used to filter out unavailable actions for that step.</p>
<p>If you are using a custom policy you can pass this mask to your probability distribution like so:</p>
<div class="literal-block-wrapper docutils container" id="id13">
<div class="code-block-caption"><span class="caption-text">Categorical policy with action mask</span><a class="headerlink" href="#id13" title="Permalink to this code">¶</a></div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorDictModule</span><span class="p">,</span> <span class="n">ProbabilisticTensorDictModule</span><span class="p">,</span> <span class="n">TensorDictSequential</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.modules</span><span class="w"> </span><span class="kn">import</span> <span class="n">MaskedCategorical</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">module</span> <span class="o">=</span> <span class="n">TensorDictModule</span><span class="p">(</span>
     <span class="o">&gt;&gt;&gt;</span>     <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_feats</span><span class="p">,</span> <span class="n">out_feats</span><span class="p">),</span>
     <span class="o">&gt;&gt;&gt;</span>     <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">],</span>
     <span class="o">&gt;&gt;&gt;</span>     <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">],</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="p">)</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">dist</span> <span class="o">=</span> <span class="n">ProbabilisticTensorDictModule</span><span class="p">(</span>
     <span class="o">&gt;&gt;&gt;</span>     <span class="n">in_keys</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;logits&quot;</span><span class="p">:</span> <span class="s2">&quot;logits&quot;</span><span class="p">,</span> <span class="s2">&quot;mask&quot;</span><span class="p">:</span> <span class="s2">&quot;action_mask&quot;</span><span class="p">},</span>
     <span class="o">&gt;&gt;&gt;</span>     <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">],</span>
     <span class="o">&gt;&gt;&gt;</span>     <span class="n">distribution_class</span><span class="o">=</span><span class="n">MaskedCategorical</span><span class="p">,</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="p">)</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">actor</span> <span class="o">=</span> <span class="n">TensorDictSequential</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">dist</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>If you want to use a default policy, you will need to wrap your environment in the <a class="reference internal" href="generated/torchrl.envs.transforms.ActionMask.html#torchrl.envs.transforms.ActionMask" title="torchrl.envs.transforms.ActionMask"><code class="xref py py-class docutils literal notranslate"><span class="pre">ActionMask</span></code></a>
transform. This transform can take care of updating the action mask in the action spec in order for the default policy
to always know what the latest available actions are. You can do this like so:</p>
<div class="literal-block-wrapper docutils container" id="id14">
<div class="code-block-caption"><span class="caption-text">How to use the action mask transform</span><a class="headerlink" href="#id14" title="Permalink to this code">¶</a></div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorDictModule</span><span class="p">,</span> <span class="n">ProbabilisticTensorDictModule</span><span class="p">,</span> <span class="n">TensorDictSequential</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="n">TransformedEnv</span><span class="p">,</span> <span class="n">ActionMask</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="n">env</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span>
     <span class="o">&gt;&gt;&gt;</span>     <span class="n">your_base_env</span>
     <span class="o">&gt;&gt;&gt;</span>     <span class="n">ActionMask</span><span class="p">(</span><span class="n">action_key</span><span class="o">=</span><span class="s2">&quot;action&quot;</span><span class="p">,</span> <span class="n">mask_key</span><span class="o">=</span><span class="s2">&quot;action_mask&quot;</span><span class="p">),</span>
     <span class="o">&gt;&gt;&gt;</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In case you are using a parallel environment it is important to add the transform to the parallel environment itself
and not to its sub-environments.</p>
</div>
</section>
<section id="recorders">
<h2>Recorders<a class="headerlink" href="#recorders" title="Permalink to this heading">¶</a></h2>
<p id="environment-recorders">Recording data during environment rollout execution is crucial to keep an eye on the algorithm performance as well as
reporting results after training.</p>
<p>TorchRL offers several tools to interact with the environment output: first and foremost, a <code class="docutils literal notranslate"><span class="pre">callback</span></code> callable
can be passed to the <a class="reference internal" href="generated/torchrl.envs.EnvBase.html#id2" title="torchrl.envs.EnvBase.rollout"><code class="xref py py-meth docutils literal notranslate"><span class="pre">rollout()</span></code></a> method. This function will be called upon the collected
tensordict at each iteration of the rollout (if some iterations have to be skipped, an internal variable should be added
to keep track of the call count within <code class="docutils literal notranslate"><span class="pre">callback</span></code>).</p>
<p>To save collected tensordicts on disk, the <a class="reference internal" href="generated/torchrl.record.TensorDictRecorder.html#torchrl.record.TensorDictRecorder" title="torchrl.record.TensorDictRecorder"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorDictRecorder</span></code></a> can be used.</p>
<section id="recording-videos">
<h3>Recording videos<a class="headerlink" href="#recording-videos" title="Permalink to this heading">¶</a></h3>
<p>Several backends offer the possibility of recording rendered images from the environment.
If the pixels are already part of the environment output (e.g. Atari or other game simulators), a
<a class="reference internal" href="generated/torchrl.record.VideoRecorder.html#torchrl.record.VideoRecorder" title="torchrl.record.VideoRecorder"><code class="xref py py-class docutils literal notranslate"><span class="pre">VideoRecorder</span></code></a> can be appended to the environment. This environment transform takes as input
a logger capable of recording videos (e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">CSVLogger</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">WandbLogger</span></code>
or <code class="xref py py-class docutils literal notranslate"><span class="pre">TensorBoardLogger</span></code>) as well as a tag indicating where the video should be saved.
For instance, to save mp4 videos on disk, one can use <code class="xref py py-class docutils literal notranslate"><span class="pre">CSVLogger</span></code> with a <cite>video_format=”mp4”</cite>
argument.</p>
<p>The <a class="reference internal" href="generated/torchrl.record.VideoRecorder.html#torchrl.record.VideoRecorder" title="torchrl.record.VideoRecorder"><code class="xref py py-class docutils literal notranslate"><span class="pre">VideoRecorder</span></code></a> transform can handle batched images and automatically detects numpy or PyTorch
formatted images (WHC or CWH).</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">logger</span> <span class="o">=</span> <span class="n">CSVLogger</span><span class="p">(</span><span class="s2">&quot;dummy-exp&quot;</span><span class="p">,</span> <span class="n">video_format</span><span class="o">=</span><span class="s2">&quot;mp4&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;ALE/Pong-v5&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">append_transform</span><span class="p">(</span><span class="n">VideoRecorder</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;rendered&quot;</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pixels&quot;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">env</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">dump</span><span class="p">()</span>  <span class="c1"># Save the video and clear cache</span>
</pre></div>
</div>
<p>Note that the cache of the transform will keep on growing until dump is called. It is the user responsibility to
take care of calling <cite>dump</cite> when needed to avoid OOM issues.</p>
<p>In some cases, creating a testing environment where images can be collected is tedious or expensive, or simply impossible
(some libraries only allow one environment instance per workspace).
In these cases, assuming that a <cite>render</cite> method is available in the environment, the <a class="reference internal" href="generated/torchrl.record.PixelRenderTransform.html#torchrl.record.PixelRenderTransform" title="torchrl.record.PixelRenderTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">PixelRenderTransform</span></code></a>
can be used to call <cite>render</cite> on the parent environment and save the images in the rollout data stream.
This class works over single and batched environments alike:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs</span><span class="w"> </span><span class="kn">import</span> <span class="n">GymEnv</span><span class="p">,</span> <span class="n">check_env_specs</span><span class="p">,</span> <span class="n">ParallelEnv</span><span class="p">,</span> <span class="n">EnvCreator</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.record.loggers</span><span class="w"> </span><span class="kn">import</span> <span class="n">CSVLogger</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.record.recorder</span><span class="w"> </span><span class="kn">import</span> <span class="n">PixelRenderTransform</span><span class="p">,</span> <span class="n">VideoRecorder</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">make_env</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">env</span> <span class="o">=</span> <span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># Uncomment this line to execute per-env</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># env = env.append_transform(PixelRenderTransform())</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">return</span> <span class="n">env</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">logger</span> <span class="o">=</span> <span class="n">CSVLogger</span><span class="p">(</span><span class="s2">&quot;dummy&quot;</span><span class="p">,</span> <span class="n">video_format</span><span class="o">=</span><span class="s2">&quot;mp4&quot;</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="n">env</span> <span class="o">=</span> <span class="n">ParallelEnv</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">EnvCreator</span><span class="p">(</span><span class="n">make_env</span><span class="p">))</span>
<span class="gp">... </span>    <span class="n">env</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="gp">... </span>    <span class="c1"># Comment this line to execute per-env</span>
<span class="gp">... </span>    <span class="n">env</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">append_transform</span><span class="p">(</span><span class="n">PixelRenderTransform</span><span class="p">())</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="n">env</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">append_transform</span><span class="p">(</span><span class="n">VideoRecorder</span><span class="p">(</span><span class="n">logger</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;pixels_record&quot;</span><span class="p">))</span>
<span class="gp">... </span>    <span class="n">env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="n">check_env_specs</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="n">r</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">env</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">dump</span><span class="p">()</span>
<span class="gp">... </span>    <span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>Recorders are transforms that register data as they come in, for logging purposes.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.record.TensorDictRecorder.html#torchrl.record.TensorDictRecorder" title="torchrl.record.TensorDictRecorder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorDictRecorder</span></code></a>(out_file_base[, ...])</p></td>
<td><p>TensorDict recorder.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.record.VideoRecorder.html#torchrl.record.VideoRecorder" title="torchrl.record.VideoRecorder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VideoRecorder</span></code></a>(logger, tag[, in_keys, skip, ...])</p></td>
<td><p>Video Recorder transform.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.record.PixelRenderTransform.html#torchrl.record.PixelRenderTransform" title="torchrl.record.PixelRenderTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PixelRenderTransform</span></code></a>([out_keys, preproc, ...])</p></td>
<td><p>A transform to call render on the parent environment and register the pixel observation in the tensordict.</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="helpers">
<h2>Helpers<a class="headerlink" href="#helpers" title="Permalink to this heading">¶</a></h2>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.RandomPolicy.html#torchrl.envs.RandomPolicy" title="torchrl.envs.RandomPolicy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomPolicy</span></code></a>(action_spec[, action_key])</p></td>
<td><p>A random policy for data collectors.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.check_env_specs.html#torchrl.envs.check_env_specs" title="torchrl.envs.check_env_specs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">check_env_specs</span></code></a>(env[, return_contiguous, ...])</p></td>
<td><p>Tests an environment specs against the results of short rollout.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.exploration_type.html#torchrl.envs.exploration_type" title="torchrl.envs.exploration_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">exploration_type</span></code></a>()</p></td>
<td><p>Returns the current sampling type.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.get_available_libraries.html#torchrl.envs.get_available_libraries" title="torchrl.envs.get_available_libraries"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_available_libraries</span></code></a>()</p></td>
<td><p>Returns all the supported libraries.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.make_composite_from_td.html#torchrl.envs.make_composite_from_td" title="torchrl.envs.make_composite_from_td"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_composite_from_td</span></code></a>(data, *[, ...])</p></td>
<td><p>Creates a Composite instance from a tensordict, assuming all values are unbounded.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.set_exploration_type.html#torchrl.envs.set_exploration_type" title="torchrl.envs.set_exploration_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_exploration_type</span></code></a></p></td>
<td><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">set_interaction_type</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.step_mdp.html#torchrl.envs.step_mdp" title="torchrl.envs.step_mdp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">step_mdp</span></code></a>(tensordict[, next_tensordict, ...])</p></td>
<td><p>Creates a new tensordict that reflects a step in time of the input tensordict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.terminated_or_truncated.html#torchrl.envs.terminated_or_truncated" title="torchrl.envs.terminated_or_truncated"><code class="xref py py-obj docutils literal notranslate"><span class="pre">terminated_or_truncated</span></code></a>(data[, ...])</p></td>
<td><p>Reads the done / terminated / truncated keys within a tensordict, and writes a new tensor where the values of both signals are aggregated.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="domain-specific">
<h2>Domain-specific<a class="headerlink" href="#domain-specific" title="Permalink to this heading">¶</a></h2>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.ModelBasedEnvBase.html#torchrl.envs.ModelBasedEnvBase" title="torchrl.envs.ModelBasedEnvBase"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ModelBasedEnvBase</span></code></a>(*args, **kwargs)</p></td>
<td><p>Basic environment for Model Based RL sota-implementations.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.model_based.dreamer.DreamerEnv.html#torchrl.envs.model_based.dreamer.DreamerEnv" title="torchrl.envs.model_based.dreamer.DreamerEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">model_based.dreamer.DreamerEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>Dreamer simulation environment.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.model_based.dreamer.DreamerDecoder.html#torchrl.envs.model_based.dreamer.DreamerDecoder" title="torchrl.envs.model_based.dreamer.DreamerDecoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">model_based.dreamer.DreamerDecoder</span></code></a>([...])</p></td>
<td><p>A transform to record the decoded observations in Dreamer.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="libraries">
<h2>Libraries<a class="headerlink" href="#libraries" title="Permalink to this heading">¶</a></h2>
<p>TorchRL’s mission is to make the training of control and decision algorithm as
easy as it gets, irrespective of the simulator being used (if any).
Multiple wrappers are available for DMControl, Habitat, Jumanji and, naturally,
for Gym.</p>
<p>This last library has a special status in the RL community as being the mostly
used framework for coding simulators. Its successful API has been foundational
and inspired many other frameworks, among which TorchRL.
However, Gym has gone through multiple design changes and it is sometimes hard
to accommodate these as an external adoption library: users usually have their
“preferred” version of the library. Moreover, gym is now being maintained
by another group under the “gymnasium” name, which does not facilitate code
compatibility. In practice, we must consider that users may have a version of
gym <em>and</em> gymnasium installed in the same virtual environment, and we must
allow both to work concomittantly.
Fortunately, TorchRL provides a solution for this problem: a special decorator
<code class="xref py py-class docutils literal notranslate"><span class="pre">set_gym_backend</span></code> allows to control which library will be used
in the relevant functions:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.libs.gym</span><span class="w"> </span><span class="kn">import</span> <span class="n">GymEnv</span><span class="p">,</span> <span class="n">set_gym_backend</span><span class="p">,</span> <span class="n">gym_backend</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">gymnasium</span><span class="o">,</span><span class="w"> </span><span class="nn">gym</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">set_gym_backend</span><span class="p">(</span><span class="n">gymnasium</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">gym_backend</span><span class="p">())</span>
<span class="gp">... </span>    <span class="n">env1</span> <span class="o">=</span> <span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">)</span>
<span class="go">&lt;module &#39;gymnasium&#39; from &#39;/path/to/venv/python3.10/site-packages/gymnasium/__init__.py&#39;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">set_gym_backend</span><span class="p">(</span><span class="n">gym</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">gym_backend</span><span class="p">())</span>
<span class="gp">... </span>    <span class="n">env2</span> <span class="o">=</span> <span class="n">GymEnv</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">)</span>
<span class="go">&lt;module &#39;gym&#39; from &#39;/path/to/venv/python3.10/site-packages/gym/__init__.py&#39;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">env1</span><span class="o">.</span><span class="n">_env</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">env</span><span class="p">)</span>
<span class="go">&lt;gymnasium.envs.classic_control.pendulum.PendulumEnv at 0x15147e190&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">env2</span><span class="o">.</span><span class="n">_env</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">env</span><span class="p">)</span>
<span class="go">&lt;gym.envs.classic_control.pendulum.PendulumEnv at 0x1629916a0&gt;</span>
</pre></div>
</div>
<p>We can see that the two libraries modify the value returned by <code class="xref py py-func docutils literal notranslate"><span class="pre">gym_backend()</span></code>
which can be further used to indicate which library needs to be used for
the current computation. <code class="xref py py-class docutils literal notranslate"><span class="pre">set_gym_backend</span></code> is also a decorator:
we can use it to tell to a specific function what gym backend needs to be used
during its execution.
The <code class="xref py py-func docutils literal notranslate"><span class="pre">torchrl.envs.libs.gym.gym_backend()</span></code> function allows you to gather
the current gym backend or any of its modules:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">mo_gymnasium</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">set_gym_backend</span><span class="p">(</span><span class="s2">&quot;gym&quot;</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">wrappers</span> <span class="o">=</span> <span class="n">gym_backend</span><span class="p">(</span><span class="s1">&#39;wrappers&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">wrappers</span><span class="p">)</span>
<span class="go">&lt;module &#39;gym.wrappers&#39; from &#39;/path/to/venv/python3.10/site-packages/gym/wrappers/__init__.py&#39;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">set_gym_backend</span><span class="p">(</span><span class="s2">&quot;gymnasium&quot;</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">wrappers</span> <span class="o">=</span> <span class="n">gym_backend</span><span class="p">(</span><span class="s1">&#39;wrappers&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">wrappers</span><span class="p">)</span>
<span class="go">&lt;module &#39;gymnasium.wrappers&#39; from &#39;/path/to/venv/python3.10/site-packages/gymnasium/wrappers/__init__.py&#39;&gt;</span>
</pre></div>
</div>
<p>Another tool that comes in handy with gym and other external dependencies is
the <code class="xref py py-class docutils literal notranslate"><span class="pre">torchrl._utils.implement_for</span></code> class. Decorating a function
with <code class="docutils literal notranslate"><span class="pre">&#64;implement_for</span></code> will tell torchrl that, depending on the version
indicated, a specific behavior is to be expected. This allows us to easily
support multiple versions of gym without requiring any effort from the user side.
For example, considering that our virtual environment has the v0.26.2 installed,
the following function will return <code class="docutils literal notranslate"><span class="pre">1</span></code> when queried:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">torchrl._utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">implement_for</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nd">@implement_for</span><span class="p">(</span><span class="s2">&quot;gym&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;0.26.0&quot;</span><span class="p">)</span>
<span class="gp">... </span><span class="k">def</span><span class="w"> </span><span class="nf">fun</span><span class="p">():</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="mi">0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nd">@implement_for</span><span class="p">(</span><span class="s2">&quot;gym&quot;</span><span class="p">,</span> <span class="s2">&quot;0.26.0&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="gp">... </span><span class="k">def</span><span class="w"> </span><span class="nf">fun</span><span class="p">():</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fun</span><span class="p">()</span>
<span class="go">1</span>
</pre></div>
</div>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.BraxEnv.html#torchrl.envs.BraxEnv" title="torchrl.envs.BraxEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BraxEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>Google Brax environment wrapper built with the environment name.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.BraxWrapper.html#torchrl.envs.BraxWrapper" title="torchrl.envs.BraxWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BraxWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>Google Brax environment wrapper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.DMControlEnv.html#torchrl.envs.DMControlEnv" title="torchrl.envs.DMControlEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DMControlEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>DeepMind Control lab environment wrapper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.DMControlWrapper.html#torchrl.envs.DMControlWrapper" title="torchrl.envs.DMControlWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DMControlWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>DeepMind Control lab environment wrapper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.GymEnv.html#torchrl.envs.GymEnv" title="torchrl.envs.GymEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GymEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>OpenAI Gym environment wrapper constructed by environment ID directly.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.GymWrapper.html#torchrl.envs.GymWrapper" title="torchrl.envs.GymWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GymWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>OpenAI Gym environment wrapper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.HabitatEnv.html#torchrl.envs.HabitatEnv" title="torchrl.envs.HabitatEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HabitatEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>A wrapper for habitat envs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.IsaacGymEnv.html#torchrl.envs.IsaacGymEnv" title="torchrl.envs.IsaacGymEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">IsaacGymEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>A TorchRL Env interface for IsaacGym environments.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.IsaacGymWrapper.html#torchrl.envs.IsaacGymWrapper" title="torchrl.envs.IsaacGymWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">IsaacGymWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>Wrapper for IsaacGymEnvs environments.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.IsaacLabWrapper.html#torchrl.envs.IsaacLabWrapper" title="torchrl.envs.IsaacLabWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">IsaacLabWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>A wrapper for IsaacLab environments.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.JumanjiEnv.html#torchrl.envs.JumanjiEnv" title="torchrl.envs.JumanjiEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">JumanjiEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>Jumanji environment wrapper built with the environment name.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.JumanjiWrapper.html#torchrl.envs.JumanjiWrapper" title="torchrl.envs.JumanjiWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">JumanjiWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>Jumanji's environment wrapper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.MeltingpotEnv.html#torchrl.envs.MeltingpotEnv" title="torchrl.envs.MeltingpotEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MeltingpotEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>Meltingpot environment wrapper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.MeltingpotWrapper.html#torchrl.envs.MeltingpotWrapper" title="torchrl.envs.MeltingpotWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MeltingpotWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>Meltingpot environment wrapper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.MOGymEnv.html#torchrl.envs.MOGymEnv" title="torchrl.envs.MOGymEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MOGymEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>FARAMA MO-Gymnasium environment wrapper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.MOGymWrapper.html#torchrl.envs.MOGymWrapper" title="torchrl.envs.MOGymWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MOGymWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>FARAMA MO-Gymnasium environment wrapper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.MultiThreadedEnv.html#torchrl.envs.MultiThreadedEnv" title="torchrl.envs.MultiThreadedEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiThreadedEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>Multithreaded execution of environments based on EnvPool.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.MultiThreadedEnvWrapper.html#torchrl.envs.MultiThreadedEnvWrapper" title="torchrl.envs.MultiThreadedEnvWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiThreadedEnvWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>Wrapper for envpool-based multithreaded environments.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.OpenMLEnv.html#torchrl.envs.OpenMLEnv" title="torchrl.envs.OpenMLEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenMLEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>An environment interface to OpenML data to be used in bandits contexts.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.OpenSpielWrapper.html#torchrl.envs.OpenSpielWrapper" title="torchrl.envs.OpenSpielWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenSpielWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>Google DeepMind OpenSpiel environment wrapper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.OpenSpielEnv.html#torchrl.envs.OpenSpielEnv" title="torchrl.envs.OpenSpielEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenSpielEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>Google DeepMind OpenSpiel environment wrapper built with the game string.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.PettingZooEnv.html#torchrl.envs.PettingZooEnv" title="torchrl.envs.PettingZooEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PettingZooEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>PettingZoo Environment.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.PettingZooWrapper.html#torchrl.envs.PettingZooWrapper" title="torchrl.envs.PettingZooWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PettingZooWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>PettingZoo environment wrapper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.RoboHiveEnv.html#torchrl.envs.RoboHiveEnv" title="torchrl.envs.RoboHiveEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RoboHiveEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>A wrapper for RoboHive gym environments.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.SMACv2Env.html#torchrl.envs.SMACv2Env" title="torchrl.envs.SMACv2Env"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SMACv2Env</span></code></a>(*args, **kwargs)</p></td>
<td><p>SMACv2 (StarCraft Multi-Agent Challenge v2) environment wrapper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.SMACv2Wrapper.html#torchrl.envs.SMACv2Wrapper" title="torchrl.envs.SMACv2Wrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SMACv2Wrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>SMACv2 (StarCraft Multi-Agent Challenge v2) environment wrapper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.UnityMLAgentsEnv.html#torchrl.envs.UnityMLAgentsEnv" title="torchrl.envs.UnityMLAgentsEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">UnityMLAgentsEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>Unity ML-Agents environment wrapper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.UnityMLAgentsWrapper.html#torchrl.envs.UnityMLAgentsWrapper" title="torchrl.envs.UnityMLAgentsWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">UnityMLAgentsWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>Unity ML-Agents environment wrapper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.VmasEnv.html#torchrl.envs.VmasEnv" title="torchrl.envs.VmasEnv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VmasEnv</span></code></a>(*args, **kwargs)</p></td>
<td><p>Vmas environment wrapper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.VmasWrapper.html#torchrl.envs.VmasWrapper" title="torchrl.envs.VmasWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VmasWrapper</span></code></a>(*args, **kwargs)</p></td>
<td><p>Vmas environment wrapper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.gym_backend.html#torchrl.envs.gym_backend" title="torchrl.envs.gym_backend"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gym_backend</span></code></a>([submodule])</p></td>
<td><p>Returns the gym backend, or a sumbodule of it.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchrl.envs.set_gym_backend.html#torchrl.envs.set_gym_backend" title="torchrl.envs.set_gym_backend"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_gym_backend</span></code></a>(backend)</p></td>
<td><p>Sets the gym-backend to a certain value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchrl.envs.register_gym_spec_conversion.html#torchrl.envs.register_gym_spec_conversion" title="torchrl.envs.register_gym_spec_conversion"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_gym_spec_conversion</span></code></a>(spec_type)</p></td>
<td><p>Decorator to register a conversion function for a specific spec type.</p></td>
</tr>
</tbody>
</table>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="generated/torchrl.envs.EnvBase.html" class="btn btn-neutral float-right" title="EnvBase" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="generated/torchrl.envs.transforms.rb_transforms.MultiStepTransform.html" class="btn btn-neutral" title="MultiStepTransform" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">torchrl.envs package</a><ul>
<li><a class="reference internal" href="#env-specs-locks-and-batch-size">Env specs: locks and batch size</a></li>
<li><a class="reference internal" href="#env-methods">Env methods</a></li>
<li><a class="reference internal" href="#partial-steps-and-partial-resets">Partial steps and partial resets</a><ul>
<li><a class="reference internal" href="#batching-environments-and-locking-the-batch">Batching environments and locking the batch</a></li>
<li><a class="reference internal" href="#partial-steps">Partial Steps</a></li>
<li><a class="reference internal" href="#partial-resets">Partial Resets</a></li>
</ul>
</li>
<li><a class="reference internal" href="#vectorized-envs">Vectorized envs</a></li>
<li><a class="reference internal" href="#async-environments">Async environments</a><ul>
<li><a class="reference internal" href="#classes">Classes</a></li>
<li><a class="reference internal" href="#example">Example</a></li>
</ul>
</li>
<li><a class="reference internal" href="#custom-native-torchrl-environments">Custom native TorchRL environments</a></li>
<li><a class="reference internal" href="#multi-agent-environments">Multi-agent environments</a></li>
<li><a class="reference internal" href="#auto-resetting-envs">Auto-resetting Envs</a></li>
<li><a class="reference internal" href="#dynamic-specs">Dynamic Specs</a></li>
<li><a class="reference internal" href="#transforms">Transforms</a><ul>
<li><a class="reference internal" href="#forward-and-inverse-transforms">Forward and inverse transforms</a><ul>
<li><a class="reference internal" href="#understanding-transform-keys">Understanding Transform Keys</a></li>
<li><a class="reference internal" href="#transforming-tensors-and-specs">Transforming Tensors and Specs</a></li>
<li><a class="reference internal" href="#exposing-specs-to-the-outside-world">Exposing Specs to the Outside World</a></li>
</ul>
</li>
<li><a class="reference internal" href="#designing-your-own-transform">Designing your own Transform</a><ul>
<li><a class="reference internal" href="#tips-for-subclassing-transform">Tips for subclassing <cite>Transform</cite></a></li>
<li><a class="reference internal" href="#inverse-transforms">Inverse Transforms</a></li>
<li><a class="reference internal" href="#using-a-transform-with-a-replay-buffer">Using a Transform with a Replay Buffer</a></li>
</ul>
</li>
<li><a class="reference internal" href="#cloning-transforms">Cloning transforms</a></li>
</ul>
</li>
<li><a class="reference internal" href="#environments-with-masked-actions">Environments with masked actions</a></li>
<li><a class="reference internal" href="#recorders">Recorders</a><ul>
<li><a class="reference internal" href="#recording-videos">Recording videos</a></li>
</ul>
</li>
<li><a class="reference internal" href="#helpers">Helpers</a></li>
<li><a class="reference internal" href="#domain-specific">Domain-specific</a></li>
<li><a class="reference internal" href="#libraries">Libraries</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrl = $("#tutorial-type").text();
	      var githubLink = "https://github.com/pytorch/rl/blob/main/tutorials/sphinx-"  + tutorialUrl + ".py",
		  notebookLink = $(".sphx-glr-download-jupyter").find(".download.reference")[0].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/rl/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }

          var overwrite = function(_) {
              if ($(this).length > 0) {
                  $(this)[0].href = "https://github.com/pytorch/rl"
              }
          }
          // PC
          $(".main-menu a:contains('GitHub')").each(overwrite);
          // Mobile
          $(".main-menu a:contains('Github')").each(overwrite);
      });

      
       $(window).ready(function() {
           var original = window.sideMenus.bind;
           var startup = true;
           window.sideMenus.bind = function() {
               original();
               if (startup) {
                   $("#pytorch-right-menu a.reference.internal").each(function(i) {
                       if (this.classList.contains("not-expanded")) {
                           this.nextElementSibling.style.display = "block";
                           this.classList.remove("not-expanded");
                           this.classList.add("expanded");
                       }
                   });
                   startup = false;
               }
           };
       });
    </script>

    


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch Documentation</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">Newsletter</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">Cloud Credit Program</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">Technical Advisory Council</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">Staff</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">Contact Us</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>
Search.setIndex({"docnames": ["index", "reference/collectors", "reference/collectors_basics", "reference/collectors_distributed", "reference/collectors_replay", "reference/collectors_single", "reference/collectors_weightsync", "reference/config", "reference/cudnn_persistent_rnn", "reference/cudnn_rnn_determinism", "reference/data", "reference/data_datasets", "reference/data_replaybuffers", "reference/data_samplers", "reference/data_specs", "reference/data_storage", "reference/envs", "reference/envs_api", "reference/envs_libraries", "reference/envs_multiagent", "reference/envs_recorders", "reference/envs_transforms", "reference/envs_vectorized", "reference/generated/knowledge_base/DEBUGGING_RL", "reference/generated/knowledge_base/GYM", "reference/generated/knowledge_base/HABITAT", "reference/generated/knowledge_base/MUJOCO_INSTALLATION", "reference/generated/knowledge_base/PRO-TIPS", "reference/generated/knowledge_base/RESOURCES", "reference/generated/knowledge_base/VERSIONING_ISSUES", "reference/generated/knowledge_base/VIDEO_CUSTOMISATION", "reference/generated/torchrl.auto_unwrap_transformed_env", "reference/generated/torchrl.collectors.AsyncCollector", "reference/generated/torchrl.collectors.BaseCollector", "reference/generated/torchrl.collectors.Collector", "reference/generated/torchrl.collectors.MultiAsyncCollector", "reference/generated/torchrl.collectors.MultiCollector", "reference/generated/torchrl.collectors.MultiProcessedWeightUpdater", "reference/generated/torchrl.collectors.MultiSyncCollector", "reference/generated/torchrl.collectors.RayWeightUpdater", "reference/generated/torchrl.collectors.VanillaWeightUpdater", "reference/generated/torchrl.collectors.WeightUpdaterBase", "reference/generated/torchrl.collectors.distributed.DistributedCollector", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedSyncCollector", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedWeightUpdater", "reference/generated/torchrl.collectors.distributed.RPCCollector", "reference/generated/torchrl.collectors.distributed.RPCDataCollector", "reference/generated/torchrl.collectors.distributed.RPCWeightUpdater", "reference/generated/torchrl.collectors.distributed.RayCollector", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher", "reference/generated/torchrl.collectors.llm.LLMCollector", "reference/generated/torchrl.collectors.llm.RayLLMCollector", "reference/generated/torchrl.collectors.llm.vLLMUpdater", "reference/generated/torchrl.collectors.llm.vLLMUpdaterV2", "reference/generated/torchrl.collectors.utils.split_trajectories", "reference/generated/torchrl.data.Binary", "reference/generated/torchrl.data.Bounded", "reference/generated/torchrl.data.Categorical", "reference/generated/torchrl.data.Composite", "reference/generated/torchrl.data.MultiCategorical", "reference/generated/torchrl.data.MultiOneHot", "reference/generated/torchrl.data.NonTensor", "reference/generated/torchrl.data.OneHot", "reference/generated/torchrl.data.PrioritizedReplayBuffer", "reference/generated/torchrl.data.RayReplayBuffer", "reference/generated/torchrl.data.RemoteTensorDictReplayBuffer", "reference/generated/torchrl.data.ReplayBuffer", "reference/generated/torchrl.data.ReplayBufferEnsemble", "reference/generated/torchrl.data.Stacked", "reference/generated/torchrl.data.StackedComposite", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer", "reference/generated/torchrl.data.TensorDictReplayBuffer", "reference/generated/torchrl.data.TensorSpec", "reference/generated/torchrl.data.Unbounded", "reference/generated/torchrl.data.UnboundedContinuous", "reference/generated/torchrl.data.UnboundedDiscrete", "reference/generated/torchrl.data.datasets.AtariDQNExperienceReplay", "reference/generated/torchrl.data.datasets.D4RLExperienceReplay", "reference/generated/torchrl.data.datasets.GenDGRLExperienceReplay", "reference/generated/torchrl.data.datasets.MinariExperienceReplay", "reference/generated/torchrl.data.datasets.OpenMLExperienceReplay", "reference/generated/torchrl.data.datasets.OpenXExperienceReplay", "reference/generated/torchrl.data.datasets.RobosetExperienceReplay", "reference/generated/torchrl.data.datasets.VD4RLExperienceReplay", "reference/generated/torchrl.data.llm.ContentBase", "reference/generated/torchrl.data.llm.History", "reference/generated/torchrl.data.llm.TopKRewardSelector", "reference/generated/torchrl.data.llm.add_chat_template", "reference/generated/torchrl.data.replay_buffers.CompressedListStorage", "reference/generated/torchrl.data.replay_buffers.CompressedListStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.FlatStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.H5StorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.ImmutableDatasetWriter", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage", "reference/generated/torchrl.data.replay_buffers.LazyStackStorage", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage", "reference/generated/torchrl.data.replay_buffers.ListStorage", "reference/generated/torchrl.data.replay_buffers.ListStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.NestedStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler", "reference/generated/torchrl.data.replay_buffers.PrioritizedSliceSampler", "reference/generated/torchrl.data.replay_buffers.RandomSampler", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.Sampler", "reference/generated/torchrl.data.replay_buffers.SamplerEnsemble", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.SliceSampler", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.Storage", "reference/generated/torchrl.data.replay_buffers.StorageCheckpointerBase", "reference/generated/torchrl.data.replay_buffers.StorageEnsemble", "reference/generated/torchrl.data.replay_buffers.StorageEnsembleCheckpointer", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.TensorStorage", "reference/generated/torchrl.data.replay_buffers.TensorStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.Writer", "reference/generated/torchrl.data.replay_buffers.WriterEnsemble", "reference/generated/torchrl.envs.AsyncEnvPool", "reference/generated/torchrl.envs.BraxEnv", "reference/generated/torchrl.envs.BraxWrapper", "reference/generated/torchrl.envs.ChessEnv", "reference/generated/torchrl.envs.DMControlEnv", "reference/generated/torchrl.envs.DMControlWrapper", "reference/generated/torchrl.envs.EnvBase", "reference/generated/torchrl.envs.EnvCreator", "reference/generated/torchrl.envs.EnvMetaData", "reference/generated/torchrl.envs.GymEnv", "reference/generated/torchrl.envs.GymLikeEnv", "reference/generated/torchrl.envs.GymWrapper", "reference/generated/torchrl.envs.HabitatEnv", "reference/generated/torchrl.envs.IsaacGymEnv", "reference/generated/torchrl.envs.IsaacGymWrapper", "reference/generated/torchrl.envs.IsaacLabWrapper", "reference/generated/torchrl.envs.JumanjiEnv", "reference/generated/torchrl.envs.JumanjiWrapper", "reference/generated/torchrl.envs.LLMHashingEnv", "reference/generated/torchrl.envs.MOGymEnv", "reference/generated/torchrl.envs.MOGymWrapper", "reference/generated/torchrl.envs.MarlGroupMapType", "reference/generated/torchrl.envs.MeltingpotEnv", "reference/generated/torchrl.envs.MeltingpotWrapper", "reference/generated/torchrl.envs.ModelBasedEnvBase", "reference/generated/torchrl.envs.MultiThreadedEnv", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper", "reference/generated/torchrl.envs.OpenMLEnv", "reference/generated/torchrl.envs.OpenSpielEnv", "reference/generated/torchrl.envs.OpenSpielWrapper", "reference/generated/torchrl.envs.ParallelEnv", "reference/generated/torchrl.envs.PendulumEnv", "reference/generated/torchrl.envs.PettingZooEnv", "reference/generated/torchrl.envs.PettingZooWrapper", "reference/generated/torchrl.envs.ProcessorAsyncEnvPool", "reference/generated/torchrl.envs.RoboHiveEnv", "reference/generated/torchrl.envs.SMACv2Env", "reference/generated/torchrl.envs.SMACv2Wrapper", "reference/generated/torchrl.envs.SerialEnv", "reference/generated/torchrl.envs.ThreadingAsyncEnvPool", "reference/generated/torchrl.envs.TicTacToeEnv", "reference/generated/torchrl.envs.UnityMLAgentsEnv", "reference/generated/torchrl.envs.UnityMLAgentsWrapper", "reference/generated/torchrl.envs.VmasEnv", "reference/generated/torchrl.envs.VmasWrapper", "reference/generated/torchrl.envs.check_env_specs", "reference/generated/torchrl.envs.check_marl_grouping", "reference/generated/torchrl.envs.exploration_type", "reference/generated/torchrl.envs.get_available_libraries", "reference/generated/torchrl.envs.gym_backend", "reference/generated/torchrl.envs.llm.ChatEnv", "reference/generated/torchrl.envs.llm.DatasetChatEnv", "reference/generated/torchrl.envs.llm.GSM8KEnv", "reference/generated/torchrl.envs.llm.GSM8KPrepareQuestion", "reference/generated/torchrl.envs.llm.GSM8KRewardParser", "reference/generated/torchrl.envs.llm.IFEvalEnv", "reference/generated/torchrl.envs.llm.IFEvalScoreData", "reference/generated/torchrl.envs.llm.IfEvalScorer", "reference/generated/torchrl.envs.llm.LLMEnv", "reference/generated/torchrl.envs.llm.LLMHashingEnv", "reference/generated/torchrl.envs.llm.MLGymWrapper", "reference/generated/torchrl.envs.llm.make_gsm8k_env", "reference/generated/torchrl.envs.llm.make_mlgym", "reference/generated/torchrl.envs.llm.transforms.AddThinkingPrompt", "reference/generated/torchrl.envs.llm.transforms.BrowserTransform", "reference/generated/torchrl.envs.llm.transforms.DataLoadingPrimer", "reference/generated/torchrl.envs.llm.transforms.ExecuteToolsInOrder", "reference/generated/torchrl.envs.llm.transforms.JSONCallParser", "reference/generated/torchrl.envs.llm.transforms.KLComputation", "reference/generated/torchrl.envs.llm.transforms.KLRewardTransform", "reference/generated/torchrl.envs.llm.transforms.MCPToolTransform", "reference/generated/torchrl.envs.llm.transforms.PolicyVersion", "reference/generated/torchrl.envs.llm.transforms.PythonExecutorService", "reference/generated/torchrl.envs.llm.transforms.PythonInterpreter", "reference/generated/torchrl.envs.llm.transforms.RayDataLoadingPrimer", "reference/generated/torchrl.envs.llm.transforms.RetrieveKL", "reference/generated/torchrl.envs.llm.transforms.RetrieveLogProb", "reference/generated/torchrl.envs.llm.transforms.SimpleToolTransform", "reference/generated/torchrl.envs.llm.transforms.TemplateTransform", "reference/generated/torchrl.envs.llm.transforms.Tokenizer", "reference/generated/torchrl.envs.llm.transforms.ToolCall", "reference/generated/torchrl.envs.llm.transforms.ToolRegistry", "reference/generated/torchrl.envs.llm.transforms.ToolService", "reference/generated/torchrl.envs.llm.transforms.XMLBlockParser", "reference/generated/torchrl.envs.llm.transforms.as_nested_tensor", "reference/generated/torchrl.envs.llm.transforms.as_padded_tensor", "reference/generated/torchrl.envs.make_composite_from_td", "reference/generated/torchrl.envs.model_based.dreamer.DreamerDecoder", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv", "reference/generated/torchrl.envs.register_gym_spec_conversion", "reference/generated/torchrl.envs.set_exploration_type", "reference/generated/torchrl.envs.set_gym_backend", "reference/generated/torchrl.envs.step_mdp", "reference/generated/torchrl.envs.terminated_or_truncated", "reference/generated/torchrl.envs.transforms.ActionDiscretizer", "reference/generated/torchrl.envs.transforms.ActionMask", "reference/generated/torchrl.envs.transforms.AutoResetEnv", "reference/generated/torchrl.envs.transforms.AutoResetTransform", "reference/generated/torchrl.envs.transforms.BatchSizeTransform", "reference/generated/torchrl.envs.transforms.BinarizeReward", "reference/generated/torchrl.envs.transforms.BurnInTransform", "reference/generated/torchrl.envs.transforms.CatFrames", "reference/generated/torchrl.envs.transforms.CatTensors", "reference/generated/torchrl.envs.transforms.CenterCrop", "reference/generated/torchrl.envs.transforms.ClipTransform", "reference/generated/torchrl.envs.transforms.Compose", "reference/generated/torchrl.envs.transforms.ConditionalPolicySwitch", "reference/generated/torchrl.envs.transforms.ConditionalSkip", "reference/generated/torchrl.envs.transforms.Crop", "reference/generated/torchrl.envs.transforms.DTypeCastTransform", "reference/generated/torchrl.envs.transforms.DeviceCastTransform", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection", "reference/generated/torchrl.envs.transforms.DoubleToFloat", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform", "reference/generated/torchrl.envs.transforms.ExcludeTransform", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck", "reference/generated/torchrl.envs.transforms.FlattenObservation", "reference/generated/torchrl.envs.transforms.FrameSkipTransform", "reference/generated/torchrl.envs.transforms.GrayScale", "reference/generated/torchrl.envs.transforms.Hash", "reference/generated/torchrl.envs.transforms.InitTracker", "reference/generated/torchrl.envs.transforms.KLRewardTransform", "reference/generated/torchrl.envs.transforms.LineariseRewards", "reference/generated/torchrl.envs.transforms.ModuleTransform", "reference/generated/torchrl.envs.transforms.MultiAction", "reference/generated/torchrl.envs.transforms.NoopResetEnv", "reference/generated/torchrl.envs.transforms.ObservationNorm", "reference/generated/torchrl.envs.transforms.ObservationTransform", "reference/generated/torchrl.envs.transforms.PermuteTransform", "reference/generated/torchrl.envs.transforms.PinMemoryTransform", "reference/generated/torchrl.envs.transforms.R3MTransform", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict", "reference/generated/torchrl.envs.transforms.RemoveEmptySpecs", "reference/generated/torchrl.envs.transforms.RenameTransform", "reference/generated/torchrl.envs.transforms.Resize", "reference/generated/torchrl.envs.transforms.Reward2GoTransform", "reference/generated/torchrl.envs.transforms.RewardClipping", "reference/generated/torchrl.envs.transforms.RewardScaling", "reference/generated/torchrl.envs.transforms.RewardSum", "reference/generated/torchrl.envs.transforms.SelectTransform", "reference/generated/torchrl.envs.transforms.SignTransform", "reference/generated/torchrl.envs.transforms.SqueezeTransform", "reference/generated/torchrl.envs.transforms.Stack", "reference/generated/torchrl.envs.transforms.StepCounter", "reference/generated/torchrl.envs.transforms.TargetReturn", "reference/generated/torchrl.envs.transforms.TensorDictPrimer", "reference/generated/torchrl.envs.transforms.TimeMaxPool", "reference/generated/torchrl.envs.transforms.Timer", "reference/generated/torchrl.envs.transforms.ToTensorImage", "reference/generated/torchrl.envs.transforms.Tokenizer", "reference/generated/torchrl.envs.transforms.TrajCounter", "reference/generated/torchrl.envs.transforms.Transform", "reference/generated/torchrl.envs.transforms.TransformedEnv", "reference/generated/torchrl.envs.transforms.UnaryTransform", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform", "reference/generated/torchrl.envs.transforms.VC1Transform", "reference/generated/torchrl.envs.transforms.VIPRewardTransform", "reference/generated/torchrl.envs.transforms.VIPTransform", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform", "reference/generated/torchrl.envs.transforms.VecNorm", "reference/generated/torchrl.envs.transforms.VecNormV2", "reference/generated/torchrl.envs.transforms.gSDENoise", "reference/generated/torchrl.implement_for", "reference/generated/torchrl.modules.ActorCriticOperator", "reference/generated/torchrl.modules.ActorCriticWrapper", "reference/generated/torchrl.modules.ActorValueOperator", "reference/generated/torchrl.modules.AdditiveGaussianModule", "reference/generated/torchrl.modules.ConsistentDropoutModule", "reference/generated/torchrl.modules.ConvNet", "reference/generated/torchrl.modules.DTActor", "reference/generated/torchrl.modules.DdpgCnnActor", "reference/generated/torchrl.modules.DdpgCnnQNet", "reference/generated/torchrl.modules.DdpgMlpActor", "reference/generated/torchrl.modules.DdpgMlpQNet", "reference/generated/torchrl.modules.DecisionTransformer", "reference/generated/torchrl.modules.Delta", "reference/generated/torchrl.modules.DistributionalDQNnet", "reference/generated/torchrl.modules.DistributionalQValueActor", "reference/generated/torchrl.modules.DistributionalQValueModule", "reference/generated/torchrl.modules.DreamerActor", "reference/generated/torchrl.modules.DuelingCnnDQNet", "reference/generated/torchrl.modules.EGreedyModule", "reference/generated/torchrl.modules.GRUModule", "reference/generated/torchrl.modules.IndependentNormal", "reference/generated/torchrl.modules.LSTMModule", "reference/generated/torchrl.modules.MLP", "reference/generated/torchrl.modules.MaskedCategorical", "reference/generated/torchrl.modules.NormalParamExtractor", "reference/generated/torchrl.modules.ObsDecoder", "reference/generated/torchrl.modules.ObsEncoder", "reference/generated/torchrl.modules.OneHotCategorical", "reference/generated/torchrl.modules.OnlineDTActor", "reference/generated/torchrl.modules.OrnsteinUhlenbeckProcessModule", "reference/generated/torchrl.modules.QValueActor", "reference/generated/torchrl.modules.QValueModule", "reference/generated/torchrl.modules.RSSMPosterior", "reference/generated/torchrl.modules.RSSMPrior", "reference/generated/torchrl.modules.RSSMRollout", "reference/generated/torchrl.modules.ReparamGradientStrategy", "reference/generated/torchrl.modules.TanhDelta", "reference/generated/torchrl.modules.TanhNormal", "reference/generated/torchrl.modules.TruncatedNormal", "reference/generated/torchrl.modules.ValueOperator", "reference/generated/torchrl.modules.WorldModelWrapper", "reference/generated/torchrl.modules.llm.AsyncVLLM", "reference/generated/torchrl.modules.llm.ChatHistory", "reference/generated/torchrl.modules.llm.LLMWrapperBase", "reference/generated/torchrl.modules.llm.LogProbs", "reference/generated/torchrl.modules.llm.Masks", "reference/generated/torchrl.modules.llm.RemoteTransformersWrapper", "reference/generated/torchrl.modules.llm.Text", "reference/generated/torchrl.modules.llm.Tokens", "reference/generated/torchrl.modules.llm.TransformersWrapper", "reference/generated/torchrl.modules.llm.make_async_vllm_engine", "reference/generated/torchrl.modules.llm.make_vllm_worker", "reference/generated/torchrl.modules.llm.stateless_init_process_group", "reference/generated/torchrl.modules.llm.stateless_init_process_group_async", "reference/generated/torchrl.modules.llm.vLLMWrapper", "reference/generated/torchrl.modules.models.utils.SquashDims", "reference/generated/torchrl.modules.set_exploration_modules_spec_from_env", "reference/generated/torchrl.modules.tensordict_module.Actor", "reference/generated/torchrl.modules.tensordict_module.MultiStepActorWrapper", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor", "reference/generated/torchrl.modules.tensordict_module.RandomPolicy", "reference/generated/torchrl.modules.tensordict_module.SafeModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential", "reference/generated/torchrl.modules.tensordict_module.SafeSequential", "reference/generated/torchrl.modules.tensordict_module.TanhModule", "reference/generated/torchrl.objectives.A2CLoss", "reference/generated/torchrl.objectives.CQLLoss", "reference/generated/torchrl.objectives.ClipPPOLoss", "reference/generated/torchrl.objectives.CrossQLoss", "reference/generated/torchrl.objectives.DDPGLoss", "reference/generated/torchrl.objectives.DQNLoss", "reference/generated/torchrl.objectives.DTLoss", "reference/generated/torchrl.objectives.DiscreteCQLLoss", "reference/generated/torchrl.objectives.DiscreteIQLLoss", "reference/generated/torchrl.objectives.DiscreteSACLoss", "reference/generated/torchrl.objectives.DistributionalDQNLoss", "reference/generated/torchrl.objectives.DreamerActorLoss", "reference/generated/torchrl.objectives.DreamerModelLoss", "reference/generated/torchrl.objectives.DreamerValueLoss", "reference/generated/torchrl.objectives.GAILLoss", "reference/generated/torchrl.objectives.IQLLoss", "reference/generated/torchrl.objectives.KLPENPPOLoss", "reference/generated/torchrl.objectives.LossModule", "reference/generated/torchrl.objectives.OnlineDTLoss", "reference/generated/torchrl.objectives.PPOLoss", "reference/generated/torchrl.objectives.REDQLoss", "reference/generated/torchrl.objectives.ReinforceLoss", "reference/generated/torchrl.objectives.SACLoss", "reference/generated/torchrl.objectives.TD3BCLoss", "reference/generated/torchrl.objectives.TD3Loss", "reference/generated/torchrl.objectives.ValueEstimators", "reference/generated/torchrl.objectives.add_random_module", "reference/generated/torchrl.objectives.llm.CISPOLoss", "reference/generated/torchrl.objectives.llm.CISPOLossOutput", "reference/generated/torchrl.objectives.llm.DAPO", "reference/generated/torchrl.objectives.llm.DAPOLossOutput", "reference/generated/torchrl.objectives.llm.GRPOLoss", "reference/generated/torchrl.objectives.llm.GRPOLossOutput", "reference/generated/torchrl.objectives.llm.LLMLossOutput", "reference/generated/torchrl.objectives.llm.MCAdvantage", "reference/generated/torchrl.objectives.llm.SFTLoss", "reference/generated/torchrl.objectives.llm.SFTLossOutput", "reference/generated/torchrl.objectives.value.GAE", "reference/generated/torchrl.objectives.value.TD0Estimator", "reference/generated/torchrl.objectives.value.TD1Estimator", "reference/generated/torchrl.objectives.value.TDLambdaEstimator", "reference/generated/torchrl.objectives.value.ValueEstimatorBase", "reference/generated/torchrl.record.PixelRenderTransform", "reference/generated/torchrl.record.TensorDictRecorder", "reference/generated/torchrl.record.VideoRecorder", "reference/generated/torchrl.record.loggers.Logger", "reference/generated/torchrl.record.loggers.csv.CSVLogger", "reference/generated/torchrl.record.loggers.generate_exp_name", "reference/generated/torchrl.record.loggers.get_logger", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger", "reference/generated/torchrl.record.loggers.trackio.TrackioLogger", "reference/generated/torchrl.record.loggers.wandb.WandbLogger", "reference/generated/torchrl.services.RayService", "reference/generated/torchrl.services.ServiceBase", "reference/generated/torchrl.services.get_services", "reference/generated/torchrl.set_auto_unwrap_transformed_env", "reference/generated/torchrl.trainers.BatchSubSampler", "reference/generated/torchrl.trainers.ClearCudaCache", "reference/generated/torchrl.trainers.CountFramesLog", "reference/generated/torchrl.trainers.LogScalar", "reference/generated/torchrl.trainers.LogValidationReward", "reference/generated/torchrl.trainers.OptimizerHook", "reference/generated/torchrl.trainers.ReplayBufferTrainer", "reference/generated/torchrl.trainers.RewardNormalizer", "reference/generated/torchrl.trainers.SelectKeys", "reference/generated/torchrl.trainers.TargetNetUpdaterHook", "reference/generated/torchrl.trainers.Trainer", "reference/generated/torchrl.trainers.TrainerHookBase", "reference/generated/torchrl.trainers.UTDRHook", "reference/generated/torchrl.trainers.UpdateWeights", "reference/generated/torchrl.trainers.algorithms.PPOTrainer", "reference/generated/torchrl.trainers.algorithms.SACTrainer", "reference/generated/torchrl.trainers.algorithms.configs.collectors.AsyncDataCollectorConfig", "reference/generated/torchrl.trainers.algorithms.configs.collectors.SyncDataCollectorConfig", "reference/generated/torchrl.trainers.algorithms.configs.common.ConfigBase", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyMemmapStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyStackStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyTensorStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.ListStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.PrioritizedSamplerConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.RandomSamplerConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.ReplayBufferConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.RoundRobinWriterConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.SamplerWithoutReplacementConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerWithoutReplacementConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleWriterConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorDictReplayBufferConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs.BatchedEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs.EnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs.TransformedEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.BraxEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.DMControlEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.EnvLibsConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.GymEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.HabitatEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.IsaacGymEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.JumanjiEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MOGymEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MeltingpotEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MultiThreadedEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenMLEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenSpielEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.PettingZooEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.RoboHiveEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.SMACv2EnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.UnityMLAgentsEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.VmasEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.CSVLoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.LoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.TensorboardLoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.WandbLoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.ConvNetConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.MLPConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.ModelConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.NetworkConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.TanhNormalModelConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.TensorDictModuleConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.ValueModelConfig", "reference/generated/torchrl.trainers.algorithms.configs.objectives.LossConfig", "reference/generated/torchrl.trainers.algorithms.configs.objectives.PPOLossConfig", "reference/generated/torchrl.trainers.algorithms.configs.trainers.PPOTrainerConfig", "reference/generated/torchrl.trainers.algorithms.configs.trainers.TrainerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionDiscretizerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionMaskConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.AutoResetTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BatchSizeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BinarizeRewardConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BurnInTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatFramesConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatTensorsConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CenterCropConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ClipTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ComposeConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalPolicySwitchConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalSkipConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CropConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DTypeCastTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DeviceCastTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DiscreteActionProjectionConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DoubleToFloatConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.EndOfLifeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ExcludeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FiniteTensorDictCheckConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FlattenObservationConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FrameSkipTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.GrayScaleConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.HashConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.InitTrackerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.KLRewardTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.LineariseRewardsConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiActionConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiStepTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.NoopResetEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ObservationNormConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PermuteTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PinMemoryTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.R3MTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RandomCropTensorDictConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RemoveEmptySpecsConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RenameTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ResizeConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.Reward2GoTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardClippingConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardScalingConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardSumConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SelectTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SignTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SqueezeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StackConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StepCounterConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TargetReturnConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TensorDictPrimerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimeMaxPoolConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ToTensorImageConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TokenizerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TrajCounterConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnaryTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnsqueezeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VC1TransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPRewardTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecGymEnvTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormV2Config", "reference/generated/torchrl.trainers.algorithms.configs.utils.ASGDConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdadeltaConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdagradConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamWConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamaxConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.LBFGSConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.LionConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.NAdamConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.RAdamConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.RMSpropConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.RpropConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.SGDConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.SparseAdamConfig", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy", "reference/generated/torchrl.trainers.helpers.make_dqn_loss", "reference/generated/torchrl.trainers.helpers.make_replay_buffer", "reference/generated/torchrl.trainers.helpers.make_target_updater", "reference/generated/torchrl.trainers.helpers.make_trainer", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor", "reference/generated/torchrl.trainers.helpers.sync_async_collector", "reference/generated/torchrl.trainers.helpers.sync_sync_collector", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor", "reference/generated/torchrl.weight_update.DistributedTransport", "reference/generated/torchrl.weight_update.DistributedWeightSyncScheme", "reference/generated/torchrl.weight_update.MPTransport", "reference/generated/torchrl.weight_update.MultiProcessWeightSyncScheme", "reference/generated/torchrl.weight_update.NoWeightSyncScheme", "reference/generated/torchrl.weight_update.RPCTransport", "reference/generated/torchrl.weight_update.RPCWeightSyncScheme", "reference/generated/torchrl.weight_update.RayModuleTransformScheme", "reference/generated/torchrl.weight_update.RayTransport", "reference/generated/torchrl.weight_update.RayWeightSyncScheme", "reference/generated/torchrl.weight_update.SharedMemTransport", "reference/generated/torchrl.weight_update.SharedMemWeightSyncScheme", "reference/generated/torchrl.weight_update.TransportBackend", "reference/generated/torchrl.weight_update.WeightStrategy", "reference/generated/torchrl.weight_update.WeightSyncScheme", "reference/generated/torchrl.weight_update.llm.VLLMCollectiveTransport", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferTransport", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightSender", "reference/generated/torchrl.weight_update.llm.VLLMWeightReceiver", "reference/generated/torchrl.weight_update.llm.VLLMWeightSender", "reference/generated/torchrl.weight_update.llm.VLLMWeightSyncScheme", "reference/generated/torchrl.weight_update.llm.get_model_metadata", "reference/generated/tutorials/README", "reference/index", "reference/knowledge_base", "reference/llms", "reference/llms_collectors", "reference/llms_data", "reference/llms_envs", "reference/llms_modules", "reference/llms_objectives", "reference/llms_transforms", "reference/modules", "reference/modules_actors", "reference/modules_critics", "reference/modules_distributions", "reference/modules_exploration", "reference/modules_models", "reference/modules_utils", "reference/objectives", "reference/objectives_actorcritic", "reference/objectives_common", "reference/objectives_offline", "reference/objectives_other", "reference/objectives_policy", "reference/objectives_value", "reference/services", "reference/trainers", "reference/trainers_basics", "reference/trainers_hooks", "reference/trainers_loggers", "reference/utils", "sg_execution_times", "tutorials/coding_ddpg", "tutorials/coding_dqn", "tutorials/coding_ppo", "tutorials/dqn_with_rnn", "tutorials/export", "tutorials/getting-started-0", "tutorials/getting-started-1", "tutorials/getting-started-2", "tutorials/getting-started-3", "tutorials/getting-started-4", "tutorials/getting-started-5", "tutorials/index", "tutorials/llm_browser", "tutorials/llm_wrappers", "tutorials/multi_task", "tutorials/multiagent_competitive_ddpg", "tutorials/multiagent_ppo", "tutorials/pendulum", "tutorials/pretrained_models", "tutorials/rb_tutorial", "tutorials/sg_execution_times", "tutorials/torchrl_demo", "tutorials/torchrl_envs"], "filenames": ["index.rst", "reference/collectors.rst", "reference/collectors_basics.rst", "reference/collectors_distributed.rst", "reference/collectors_replay.rst", "reference/collectors_single.rst", "reference/collectors_weightsync.rst", "reference/config.rst", "reference/cudnn_persistent_rnn.rst", "reference/cudnn_rnn_determinism.rst", "reference/data.rst", "reference/data_datasets.rst", "reference/data_replaybuffers.rst", "reference/data_samplers.rst", "reference/data_specs.rst", "reference/data_storage.rst", "reference/envs.rst", "reference/envs_api.rst", "reference/envs_libraries.rst", "reference/envs_multiagent.rst", "reference/envs_recorders.rst", "reference/envs_transforms.rst", "reference/envs_vectorized.rst", "reference/generated/knowledge_base/DEBUGGING_RL.rst", "reference/generated/knowledge_base/GYM.rst", "reference/generated/knowledge_base/HABITAT.rst", "reference/generated/knowledge_base/MUJOCO_INSTALLATION.rst", "reference/generated/knowledge_base/PRO-TIPS.rst", "reference/generated/knowledge_base/RESOURCES.rst", "reference/generated/knowledge_base/VERSIONING_ISSUES.rst", "reference/generated/knowledge_base/VIDEO_CUSTOMISATION.rst", "reference/generated/torchrl.auto_unwrap_transformed_env.rst", "reference/generated/torchrl.collectors.AsyncCollector.rst", "reference/generated/torchrl.collectors.BaseCollector.rst", "reference/generated/torchrl.collectors.Collector.rst", "reference/generated/torchrl.collectors.MultiAsyncCollector.rst", "reference/generated/torchrl.collectors.MultiCollector.rst", "reference/generated/torchrl.collectors.MultiProcessedWeightUpdater.rst", "reference/generated/torchrl.collectors.MultiSyncCollector.rst", "reference/generated/torchrl.collectors.RayWeightUpdater.rst", "reference/generated/torchrl.collectors.VanillaWeightUpdater.rst", "reference/generated/torchrl.collectors.WeightUpdaterBase.rst", "reference/generated/torchrl.collectors.distributed.DistributedCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedSyncCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedWeightUpdater.rst", "reference/generated/torchrl.collectors.distributed.RPCCollector.rst", "reference/generated/torchrl.collectors.distributed.RPCDataCollector.rst", "reference/generated/torchrl.collectors.distributed.RPCWeightUpdater.rst", "reference/generated/torchrl.collectors.distributed.RayCollector.rst", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher.rst", "reference/generated/torchrl.collectors.llm.LLMCollector.rst", "reference/generated/torchrl.collectors.llm.RayLLMCollector.rst", "reference/generated/torchrl.collectors.llm.vLLMUpdater.rst", "reference/generated/torchrl.collectors.llm.vLLMUpdaterV2.rst", "reference/generated/torchrl.collectors.utils.split_trajectories.rst", "reference/generated/torchrl.data.Binary.rst", "reference/generated/torchrl.data.Bounded.rst", "reference/generated/torchrl.data.Categorical.rst", "reference/generated/torchrl.data.Composite.rst", "reference/generated/torchrl.data.MultiCategorical.rst", "reference/generated/torchrl.data.MultiOneHot.rst", "reference/generated/torchrl.data.NonTensor.rst", "reference/generated/torchrl.data.OneHot.rst", "reference/generated/torchrl.data.PrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.RayReplayBuffer.rst", "reference/generated/torchrl.data.RemoteTensorDictReplayBuffer.rst", "reference/generated/torchrl.data.ReplayBuffer.rst", "reference/generated/torchrl.data.ReplayBufferEnsemble.rst", "reference/generated/torchrl.data.Stacked.rst", "reference/generated/torchrl.data.StackedComposite.rst", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.TensorDictReplayBuffer.rst", "reference/generated/torchrl.data.TensorSpec.rst", "reference/generated/torchrl.data.Unbounded.rst", "reference/generated/torchrl.data.UnboundedContinuous.rst", "reference/generated/torchrl.data.UnboundedDiscrete.rst", "reference/generated/torchrl.data.datasets.AtariDQNExperienceReplay.rst", "reference/generated/torchrl.data.datasets.D4RLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.GenDGRLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.MinariExperienceReplay.rst", "reference/generated/torchrl.data.datasets.OpenMLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.OpenXExperienceReplay.rst", "reference/generated/torchrl.data.datasets.RobosetExperienceReplay.rst", "reference/generated/torchrl.data.datasets.VD4RLExperienceReplay.rst", "reference/generated/torchrl.data.llm.ContentBase.rst", "reference/generated/torchrl.data.llm.History.rst", "reference/generated/torchrl.data.llm.TopKRewardSelector.rst", "reference/generated/torchrl.data.llm.add_chat_template.rst", "reference/generated/torchrl.data.replay_buffers.CompressedListStorage.rst", "reference/generated/torchrl.data.replay_buffers.CompressedListStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.FlatStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.H5StorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.ImmutableDatasetWriter.rst", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage.rst", "reference/generated/torchrl.data.replay_buffers.LazyStackStorage.rst", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.ListStorage.rst", "reference/generated/torchrl.data.replay_buffers.ListStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.NestedStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler.rst", "reference/generated/torchrl.data.replay_buffers.PrioritizedSliceSampler.rst", "reference/generated/torchrl.data.replay_buffers.RandomSampler.rst", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.Sampler.rst", "reference/generated/torchrl.data.replay_buffers.SamplerEnsemble.rst", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.SliceSampler.rst", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.Storage.rst", "reference/generated/torchrl.data.replay_buffers.StorageCheckpointerBase.rst", "reference/generated/torchrl.data.replay_buffers.StorageEnsemble.rst", "reference/generated/torchrl.data.replay_buffers.StorageEnsembleCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.TensorStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.Writer.rst", "reference/generated/torchrl.data.replay_buffers.WriterEnsemble.rst", "reference/generated/torchrl.envs.AsyncEnvPool.rst", "reference/generated/torchrl.envs.BraxEnv.rst", "reference/generated/torchrl.envs.BraxWrapper.rst", "reference/generated/torchrl.envs.ChessEnv.rst", "reference/generated/torchrl.envs.DMControlEnv.rst", "reference/generated/torchrl.envs.DMControlWrapper.rst", "reference/generated/torchrl.envs.EnvBase.rst", "reference/generated/torchrl.envs.EnvCreator.rst", "reference/generated/torchrl.envs.EnvMetaData.rst", "reference/generated/torchrl.envs.GymEnv.rst", "reference/generated/torchrl.envs.GymLikeEnv.rst", "reference/generated/torchrl.envs.GymWrapper.rst", "reference/generated/torchrl.envs.HabitatEnv.rst", "reference/generated/torchrl.envs.IsaacGymEnv.rst", "reference/generated/torchrl.envs.IsaacGymWrapper.rst", "reference/generated/torchrl.envs.IsaacLabWrapper.rst", "reference/generated/torchrl.envs.JumanjiEnv.rst", "reference/generated/torchrl.envs.JumanjiWrapper.rst", "reference/generated/torchrl.envs.LLMHashingEnv.rst", "reference/generated/torchrl.envs.MOGymEnv.rst", "reference/generated/torchrl.envs.MOGymWrapper.rst", "reference/generated/torchrl.envs.MarlGroupMapType.rst", "reference/generated/torchrl.envs.MeltingpotEnv.rst", "reference/generated/torchrl.envs.MeltingpotWrapper.rst", "reference/generated/torchrl.envs.ModelBasedEnvBase.rst", "reference/generated/torchrl.envs.MultiThreadedEnv.rst", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper.rst", "reference/generated/torchrl.envs.OpenMLEnv.rst", "reference/generated/torchrl.envs.OpenSpielEnv.rst", "reference/generated/torchrl.envs.OpenSpielWrapper.rst", "reference/generated/torchrl.envs.ParallelEnv.rst", "reference/generated/torchrl.envs.PendulumEnv.rst", "reference/generated/torchrl.envs.PettingZooEnv.rst", "reference/generated/torchrl.envs.PettingZooWrapper.rst", "reference/generated/torchrl.envs.ProcessorAsyncEnvPool.rst", "reference/generated/torchrl.envs.RoboHiveEnv.rst", "reference/generated/torchrl.envs.SMACv2Env.rst", "reference/generated/torchrl.envs.SMACv2Wrapper.rst", "reference/generated/torchrl.envs.SerialEnv.rst", "reference/generated/torchrl.envs.ThreadingAsyncEnvPool.rst", "reference/generated/torchrl.envs.TicTacToeEnv.rst", "reference/generated/torchrl.envs.UnityMLAgentsEnv.rst", "reference/generated/torchrl.envs.UnityMLAgentsWrapper.rst", "reference/generated/torchrl.envs.VmasEnv.rst", "reference/generated/torchrl.envs.VmasWrapper.rst", "reference/generated/torchrl.envs.check_env_specs.rst", "reference/generated/torchrl.envs.check_marl_grouping.rst", "reference/generated/torchrl.envs.exploration_type.rst", "reference/generated/torchrl.envs.get_available_libraries.rst", "reference/generated/torchrl.envs.gym_backend.rst", "reference/generated/torchrl.envs.llm.ChatEnv.rst", "reference/generated/torchrl.envs.llm.DatasetChatEnv.rst", "reference/generated/torchrl.envs.llm.GSM8KEnv.rst", "reference/generated/torchrl.envs.llm.GSM8KPrepareQuestion.rst", "reference/generated/torchrl.envs.llm.GSM8KRewardParser.rst", "reference/generated/torchrl.envs.llm.IFEvalEnv.rst", "reference/generated/torchrl.envs.llm.IFEvalScoreData.rst", "reference/generated/torchrl.envs.llm.IfEvalScorer.rst", "reference/generated/torchrl.envs.llm.LLMEnv.rst", "reference/generated/torchrl.envs.llm.LLMHashingEnv.rst", "reference/generated/torchrl.envs.llm.MLGymWrapper.rst", "reference/generated/torchrl.envs.llm.make_gsm8k_env.rst", "reference/generated/torchrl.envs.llm.make_mlgym.rst", "reference/generated/torchrl.envs.llm.transforms.AddThinkingPrompt.rst", "reference/generated/torchrl.envs.llm.transforms.BrowserTransform.rst", "reference/generated/torchrl.envs.llm.transforms.DataLoadingPrimer.rst", "reference/generated/torchrl.envs.llm.transforms.ExecuteToolsInOrder.rst", "reference/generated/torchrl.envs.llm.transforms.JSONCallParser.rst", "reference/generated/torchrl.envs.llm.transforms.KLComputation.rst", "reference/generated/torchrl.envs.llm.transforms.KLRewardTransform.rst", "reference/generated/torchrl.envs.llm.transforms.MCPToolTransform.rst", "reference/generated/torchrl.envs.llm.transforms.PolicyVersion.rst", "reference/generated/torchrl.envs.llm.transforms.PythonExecutorService.rst", "reference/generated/torchrl.envs.llm.transforms.PythonInterpreter.rst", "reference/generated/torchrl.envs.llm.transforms.RayDataLoadingPrimer.rst", "reference/generated/torchrl.envs.llm.transforms.RetrieveKL.rst", "reference/generated/torchrl.envs.llm.transforms.RetrieveLogProb.rst", "reference/generated/torchrl.envs.llm.transforms.SimpleToolTransform.rst", "reference/generated/torchrl.envs.llm.transforms.TemplateTransform.rst", "reference/generated/torchrl.envs.llm.transforms.Tokenizer.rst", "reference/generated/torchrl.envs.llm.transforms.ToolCall.rst", "reference/generated/torchrl.envs.llm.transforms.ToolRegistry.rst", "reference/generated/torchrl.envs.llm.transforms.ToolService.rst", "reference/generated/torchrl.envs.llm.transforms.XMLBlockParser.rst", "reference/generated/torchrl.envs.llm.transforms.as_nested_tensor.rst", "reference/generated/torchrl.envs.llm.transforms.as_padded_tensor.rst", "reference/generated/torchrl.envs.make_composite_from_td.rst", "reference/generated/torchrl.envs.model_based.dreamer.DreamerDecoder.rst", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv.rst", "reference/generated/torchrl.envs.register_gym_spec_conversion.rst", "reference/generated/torchrl.envs.set_exploration_type.rst", "reference/generated/torchrl.envs.set_gym_backend.rst", "reference/generated/torchrl.envs.step_mdp.rst", "reference/generated/torchrl.envs.terminated_or_truncated.rst", "reference/generated/torchrl.envs.transforms.ActionDiscretizer.rst", "reference/generated/torchrl.envs.transforms.ActionMask.rst", "reference/generated/torchrl.envs.transforms.AutoResetEnv.rst", "reference/generated/torchrl.envs.transforms.AutoResetTransform.rst", "reference/generated/torchrl.envs.transforms.BatchSizeTransform.rst", "reference/generated/torchrl.envs.transforms.BinarizeReward.rst", "reference/generated/torchrl.envs.transforms.BurnInTransform.rst", "reference/generated/torchrl.envs.transforms.CatFrames.rst", "reference/generated/torchrl.envs.transforms.CatTensors.rst", "reference/generated/torchrl.envs.transforms.CenterCrop.rst", "reference/generated/torchrl.envs.transforms.ClipTransform.rst", "reference/generated/torchrl.envs.transforms.Compose.rst", "reference/generated/torchrl.envs.transforms.ConditionalPolicySwitch.rst", "reference/generated/torchrl.envs.transforms.ConditionalSkip.rst", "reference/generated/torchrl.envs.transforms.Crop.rst", "reference/generated/torchrl.envs.transforms.DTypeCastTransform.rst", "reference/generated/torchrl.envs.transforms.DeviceCastTransform.rst", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection.rst", "reference/generated/torchrl.envs.transforms.DoubleToFloat.rst", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform.rst", "reference/generated/torchrl.envs.transforms.ExcludeTransform.rst", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck.rst", "reference/generated/torchrl.envs.transforms.FlattenObservation.rst", "reference/generated/torchrl.envs.transforms.FrameSkipTransform.rst", "reference/generated/torchrl.envs.transforms.GrayScale.rst", "reference/generated/torchrl.envs.transforms.Hash.rst", "reference/generated/torchrl.envs.transforms.InitTracker.rst", "reference/generated/torchrl.envs.transforms.KLRewardTransform.rst", "reference/generated/torchrl.envs.transforms.LineariseRewards.rst", "reference/generated/torchrl.envs.transforms.ModuleTransform.rst", "reference/generated/torchrl.envs.transforms.MultiAction.rst", "reference/generated/torchrl.envs.transforms.NoopResetEnv.rst", "reference/generated/torchrl.envs.transforms.ObservationNorm.rst", "reference/generated/torchrl.envs.transforms.ObservationTransform.rst", "reference/generated/torchrl.envs.transforms.PermuteTransform.rst", "reference/generated/torchrl.envs.transforms.PinMemoryTransform.rst", "reference/generated/torchrl.envs.transforms.R3MTransform.rst", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict.rst", "reference/generated/torchrl.envs.transforms.RemoveEmptySpecs.rst", "reference/generated/torchrl.envs.transforms.RenameTransform.rst", "reference/generated/torchrl.envs.transforms.Resize.rst", "reference/generated/torchrl.envs.transforms.Reward2GoTransform.rst", "reference/generated/torchrl.envs.transforms.RewardClipping.rst", "reference/generated/torchrl.envs.transforms.RewardScaling.rst", "reference/generated/torchrl.envs.transforms.RewardSum.rst", "reference/generated/torchrl.envs.transforms.SelectTransform.rst", "reference/generated/torchrl.envs.transforms.SignTransform.rst", "reference/generated/torchrl.envs.transforms.SqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.Stack.rst", "reference/generated/torchrl.envs.transforms.StepCounter.rst", "reference/generated/torchrl.envs.transforms.TargetReturn.rst", "reference/generated/torchrl.envs.transforms.TensorDictPrimer.rst", "reference/generated/torchrl.envs.transforms.TimeMaxPool.rst", "reference/generated/torchrl.envs.transforms.Timer.rst", "reference/generated/torchrl.envs.transforms.ToTensorImage.rst", "reference/generated/torchrl.envs.transforms.Tokenizer.rst", "reference/generated/torchrl.envs.transforms.TrajCounter.rst", "reference/generated/torchrl.envs.transforms.Transform.rst", "reference/generated/torchrl.envs.transforms.TransformedEnv.rst", "reference/generated/torchrl.envs.transforms.UnaryTransform.rst", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.VC1Transform.rst", "reference/generated/torchrl.envs.transforms.VIPRewardTransform.rst", "reference/generated/torchrl.envs.transforms.VIPTransform.rst", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform.rst", "reference/generated/torchrl.envs.transforms.VecNorm.rst", "reference/generated/torchrl.envs.transforms.VecNormV2.rst", "reference/generated/torchrl.envs.transforms.gSDENoise.rst", "reference/generated/torchrl.implement_for.rst", "reference/generated/torchrl.modules.ActorCriticOperator.rst", "reference/generated/torchrl.modules.ActorCriticWrapper.rst", "reference/generated/torchrl.modules.ActorValueOperator.rst", "reference/generated/torchrl.modules.AdditiveGaussianModule.rst", "reference/generated/torchrl.modules.ConsistentDropoutModule.rst", "reference/generated/torchrl.modules.ConvNet.rst", "reference/generated/torchrl.modules.DTActor.rst", "reference/generated/torchrl.modules.DdpgCnnActor.rst", "reference/generated/torchrl.modules.DdpgCnnQNet.rst", "reference/generated/torchrl.modules.DdpgMlpActor.rst", "reference/generated/torchrl.modules.DdpgMlpQNet.rst", "reference/generated/torchrl.modules.DecisionTransformer.rst", "reference/generated/torchrl.modules.Delta.rst", "reference/generated/torchrl.modules.DistributionalDQNnet.rst", "reference/generated/torchrl.modules.DistributionalQValueActor.rst", "reference/generated/torchrl.modules.DistributionalQValueModule.rst", "reference/generated/torchrl.modules.DreamerActor.rst", "reference/generated/torchrl.modules.DuelingCnnDQNet.rst", "reference/generated/torchrl.modules.EGreedyModule.rst", "reference/generated/torchrl.modules.GRUModule.rst", "reference/generated/torchrl.modules.IndependentNormal.rst", "reference/generated/torchrl.modules.LSTMModule.rst", "reference/generated/torchrl.modules.MLP.rst", "reference/generated/torchrl.modules.MaskedCategorical.rst", "reference/generated/torchrl.modules.NormalParamExtractor.rst", "reference/generated/torchrl.modules.ObsDecoder.rst", "reference/generated/torchrl.modules.ObsEncoder.rst", "reference/generated/torchrl.modules.OneHotCategorical.rst", "reference/generated/torchrl.modules.OnlineDTActor.rst", "reference/generated/torchrl.modules.OrnsteinUhlenbeckProcessModule.rst", "reference/generated/torchrl.modules.QValueActor.rst", "reference/generated/torchrl.modules.QValueModule.rst", "reference/generated/torchrl.modules.RSSMPosterior.rst", "reference/generated/torchrl.modules.RSSMPrior.rst", "reference/generated/torchrl.modules.RSSMRollout.rst", "reference/generated/torchrl.modules.ReparamGradientStrategy.rst", "reference/generated/torchrl.modules.TanhDelta.rst", "reference/generated/torchrl.modules.TanhNormal.rst", "reference/generated/torchrl.modules.TruncatedNormal.rst", "reference/generated/torchrl.modules.ValueOperator.rst", "reference/generated/torchrl.modules.WorldModelWrapper.rst", "reference/generated/torchrl.modules.llm.AsyncVLLM.rst", "reference/generated/torchrl.modules.llm.ChatHistory.rst", "reference/generated/torchrl.modules.llm.LLMWrapperBase.rst", "reference/generated/torchrl.modules.llm.LogProbs.rst", "reference/generated/torchrl.modules.llm.Masks.rst", "reference/generated/torchrl.modules.llm.RemoteTransformersWrapper.rst", "reference/generated/torchrl.modules.llm.Text.rst", "reference/generated/torchrl.modules.llm.Tokens.rst", "reference/generated/torchrl.modules.llm.TransformersWrapper.rst", "reference/generated/torchrl.modules.llm.make_async_vllm_engine.rst", "reference/generated/torchrl.modules.llm.make_vllm_worker.rst", "reference/generated/torchrl.modules.llm.stateless_init_process_group.rst", "reference/generated/torchrl.modules.llm.stateless_init_process_group_async.rst", "reference/generated/torchrl.modules.llm.vLLMWrapper.rst", "reference/generated/torchrl.modules.models.utils.SquashDims.rst", "reference/generated/torchrl.modules.set_exploration_modules_spec_from_env.rst", "reference/generated/torchrl.modules.tensordict_module.Actor.rst", "reference/generated/torchrl.modules.tensordict_module.MultiStepActorWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor.rst", "reference/generated/torchrl.modules.tensordict_module.RandomPolicy.rst", "reference/generated/torchrl.modules.tensordict_module.SafeModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential.rst", "reference/generated/torchrl.modules.tensordict_module.SafeSequential.rst", "reference/generated/torchrl.modules.tensordict_module.TanhModule.rst", "reference/generated/torchrl.objectives.A2CLoss.rst", "reference/generated/torchrl.objectives.CQLLoss.rst", "reference/generated/torchrl.objectives.ClipPPOLoss.rst", "reference/generated/torchrl.objectives.CrossQLoss.rst", "reference/generated/torchrl.objectives.DDPGLoss.rst", "reference/generated/torchrl.objectives.DQNLoss.rst", "reference/generated/torchrl.objectives.DTLoss.rst", "reference/generated/torchrl.objectives.DiscreteCQLLoss.rst", "reference/generated/torchrl.objectives.DiscreteIQLLoss.rst", "reference/generated/torchrl.objectives.DiscreteSACLoss.rst", "reference/generated/torchrl.objectives.DistributionalDQNLoss.rst", "reference/generated/torchrl.objectives.DreamerActorLoss.rst", "reference/generated/torchrl.objectives.DreamerModelLoss.rst", "reference/generated/torchrl.objectives.DreamerValueLoss.rst", "reference/generated/torchrl.objectives.GAILLoss.rst", "reference/generated/torchrl.objectives.IQLLoss.rst", "reference/generated/torchrl.objectives.KLPENPPOLoss.rst", "reference/generated/torchrl.objectives.LossModule.rst", "reference/generated/torchrl.objectives.OnlineDTLoss.rst", "reference/generated/torchrl.objectives.PPOLoss.rst", "reference/generated/torchrl.objectives.REDQLoss.rst", "reference/generated/torchrl.objectives.ReinforceLoss.rst", "reference/generated/torchrl.objectives.SACLoss.rst", "reference/generated/torchrl.objectives.TD3BCLoss.rst", "reference/generated/torchrl.objectives.TD3Loss.rst", "reference/generated/torchrl.objectives.ValueEstimators.rst", "reference/generated/torchrl.objectives.add_random_module.rst", "reference/generated/torchrl.objectives.llm.CISPOLoss.rst", "reference/generated/torchrl.objectives.llm.CISPOLossOutput.rst", "reference/generated/torchrl.objectives.llm.DAPO.rst", "reference/generated/torchrl.objectives.llm.DAPOLossOutput.rst", "reference/generated/torchrl.objectives.llm.GRPOLoss.rst", "reference/generated/torchrl.objectives.llm.GRPOLossOutput.rst", "reference/generated/torchrl.objectives.llm.LLMLossOutput.rst", "reference/generated/torchrl.objectives.llm.MCAdvantage.rst", "reference/generated/torchrl.objectives.llm.SFTLoss.rst", "reference/generated/torchrl.objectives.llm.SFTLossOutput.rst", "reference/generated/torchrl.objectives.value.GAE.rst", "reference/generated/torchrl.objectives.value.TD0Estimator.rst", "reference/generated/torchrl.objectives.value.TD1Estimator.rst", "reference/generated/torchrl.objectives.value.TDLambdaEstimator.rst", "reference/generated/torchrl.objectives.value.ValueEstimatorBase.rst", "reference/generated/torchrl.record.PixelRenderTransform.rst", "reference/generated/torchrl.record.TensorDictRecorder.rst", "reference/generated/torchrl.record.VideoRecorder.rst", "reference/generated/torchrl.record.loggers.Logger.rst", "reference/generated/torchrl.record.loggers.csv.CSVLogger.rst", "reference/generated/torchrl.record.loggers.generate_exp_name.rst", "reference/generated/torchrl.record.loggers.get_logger.rst", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger.rst", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger.rst", "reference/generated/torchrl.record.loggers.trackio.TrackioLogger.rst", "reference/generated/torchrl.record.loggers.wandb.WandbLogger.rst", "reference/generated/torchrl.services.RayService.rst", "reference/generated/torchrl.services.ServiceBase.rst", "reference/generated/torchrl.services.get_services.rst", "reference/generated/torchrl.set_auto_unwrap_transformed_env.rst", "reference/generated/torchrl.trainers.BatchSubSampler.rst", "reference/generated/torchrl.trainers.ClearCudaCache.rst", "reference/generated/torchrl.trainers.CountFramesLog.rst", "reference/generated/torchrl.trainers.LogScalar.rst", "reference/generated/torchrl.trainers.LogValidationReward.rst", "reference/generated/torchrl.trainers.OptimizerHook.rst", "reference/generated/torchrl.trainers.ReplayBufferTrainer.rst", "reference/generated/torchrl.trainers.RewardNormalizer.rst", "reference/generated/torchrl.trainers.SelectKeys.rst", "reference/generated/torchrl.trainers.TargetNetUpdaterHook.rst", "reference/generated/torchrl.trainers.Trainer.rst", "reference/generated/torchrl.trainers.TrainerHookBase.rst", "reference/generated/torchrl.trainers.UTDRHook.rst", "reference/generated/torchrl.trainers.UpdateWeights.rst", "reference/generated/torchrl.trainers.algorithms.PPOTrainer.rst", "reference/generated/torchrl.trainers.algorithms.SACTrainer.rst", "reference/generated/torchrl.trainers.algorithms.configs.collectors.AsyncDataCollectorConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.collectors.SyncDataCollectorConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.common.ConfigBase.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyMemmapStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyStackStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyTensorStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.ListStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.PrioritizedSamplerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.RandomSamplerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.ReplayBufferConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.RoundRobinWriterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.SamplerWithoutReplacementConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerWithoutReplacementConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleWriterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorDictReplayBufferConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs.BatchedEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs.EnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs.TransformedEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.BraxEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.DMControlEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.EnvLibsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.GymEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.HabitatEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.IsaacGymEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.JumanjiEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MOGymEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MeltingpotEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MultiThreadedEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenMLEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenSpielEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.PettingZooEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.RoboHiveEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.SMACv2EnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.UnityMLAgentsEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.VmasEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.CSVLoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.LoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.TensorboardLoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.WandbLoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.ConvNetConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.MLPConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.ModelConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.NetworkConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.TanhNormalModelConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.TensorDictModuleConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.ValueModelConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.objectives.LossConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.objectives.PPOLossConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.trainers.PPOTrainerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.trainers.TrainerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionDiscretizerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionMaskConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.AutoResetTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BatchSizeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BinarizeRewardConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BurnInTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatFramesConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatTensorsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CenterCropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ClipTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ComposeConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalPolicySwitchConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalSkipConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DTypeCastTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DeviceCastTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DiscreteActionProjectionConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DoubleToFloatConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.EndOfLifeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ExcludeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FiniteTensorDictCheckConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FlattenObservationConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FrameSkipTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.GrayScaleConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.HashConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.InitTrackerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.KLRewardTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.LineariseRewardsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiActionConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiStepTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.NoopResetEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ObservationNormConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PermuteTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PinMemoryTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.R3MTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RandomCropTensorDictConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RemoveEmptySpecsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RenameTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ResizeConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.Reward2GoTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardClippingConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardScalingConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardSumConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SelectTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SignTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SqueezeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StackConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StepCounterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TargetReturnConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TensorDictPrimerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimeMaxPoolConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ToTensorImageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TokenizerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TrajCounterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnaryTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnsqueezeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VC1TransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPRewardTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecGymEnvTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormV2Config.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.ASGDConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdadeltaConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdagradConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamWConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamaxConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.LBFGSConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.LionConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.NAdamConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.RAdamConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.RMSpropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.RpropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.SGDConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.SparseAdamConfig.rst", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip.rst", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout.rst", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_dqn_loss.rst", "reference/generated/torchrl.trainers.helpers.make_replay_buffer.rst", "reference/generated/torchrl.trainers.helpers.make_target_updater.rst", "reference/generated/torchrl.trainers.helpers.make_trainer.rst", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor.rst", "reference/generated/torchrl.trainers.helpers.sync_async_collector.rst", "reference/generated/torchrl.trainers.helpers.sync_sync_collector.rst", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor.rst", "reference/generated/torchrl.weight_update.DistributedTransport.rst", "reference/generated/torchrl.weight_update.DistributedWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.MPTransport.rst", "reference/generated/torchrl.weight_update.MultiProcessWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.NoWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.RPCTransport.rst", "reference/generated/torchrl.weight_update.RPCWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.RayModuleTransformScheme.rst", "reference/generated/torchrl.weight_update.RayTransport.rst", "reference/generated/torchrl.weight_update.RayWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.SharedMemTransport.rst", "reference/generated/torchrl.weight_update.SharedMemWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.TransportBackend.rst", "reference/generated/torchrl.weight_update.WeightStrategy.rst", "reference/generated/torchrl.weight_update.WeightSyncScheme.rst", "reference/generated/torchrl.weight_update.llm.VLLMCollectiveTransport.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferTransport.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightSender.rst", "reference/generated/torchrl.weight_update.llm.VLLMWeightReceiver.rst", "reference/generated/torchrl.weight_update.llm.VLLMWeightSender.rst", "reference/generated/torchrl.weight_update.llm.VLLMWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.llm.get_model_metadata.rst", "reference/generated/tutorials/README.rst", "reference/index.rst", "reference/knowledge_base.rst", "reference/llms.rst", "reference/llms_collectors.rst", "reference/llms_data.rst", "reference/llms_envs.rst", "reference/llms_modules.rst", "reference/llms_objectives.rst", "reference/llms_transforms.rst", "reference/modules.rst", "reference/modules_actors.rst", "reference/modules_critics.rst", "reference/modules_distributions.rst", "reference/modules_exploration.rst", "reference/modules_models.rst", "reference/modules_utils.rst", "reference/objectives.rst", "reference/objectives_actorcritic.rst", "reference/objectives_common.rst", "reference/objectives_offline.rst", "reference/objectives_other.rst", "reference/objectives_policy.rst", "reference/objectives_value.rst", "reference/services.rst", "reference/trainers.rst", "reference/trainers_basics.rst", "reference/trainers_hooks.rst", "reference/trainers_loggers.rst", "reference/utils.rst", "sg_execution_times.rst", "tutorials/coding_ddpg.rst", "tutorials/coding_dqn.rst", "tutorials/coding_ppo.rst", "tutorials/dqn_with_rnn.rst", "tutorials/export.rst", "tutorials/getting-started-0.rst", "tutorials/getting-started-1.rst", "tutorials/getting-started-2.rst", "tutorials/getting-started-3.rst", "tutorials/getting-started-4.rst", "tutorials/getting-started-5.rst", "tutorials/index.rst", "tutorials/llm_browser.rst", "tutorials/llm_wrappers.rst", "tutorials/multi_task.rst", "tutorials/multiagent_competitive_ddpg.rst", "tutorials/multiagent_ppo.rst", "tutorials/pendulum.rst", "tutorials/pretrained_models.rst", "tutorials/rb_tutorial.rst", "tutorials/sg_execution_times.rst", "tutorials/torchrl_demo.rst", "tutorials/torchrl_envs.rst"], "titles": ["TorchRL", "torchrl.collectors package", "Collector Basics", "Distributed Collectors", "Collectors and Replay Buffers", "Single Node Collectors", "Weight Synchronization", "TorchRL Configuration System", "&lt;no title&gt;", "&lt;no title&gt;", "torchrl.data package", "Datasets", "Replay Buffers", "Sampling Strategies", "TensorSpec System", "Storage Backends", "torchrl.envs package", "Environment API", "Library Wrappers", "Multi-agent Environments", "Recorders", "Transforms", "Vectorized and Parallel Environments", "Things to consider when debugging RL", "Working with gym", "Working with <code class=\"docutils literal notranslate\"><span class=\"pre\">habitat-lab</span></code>", "Working with MuJoCo-based environments", "Common PyTorch errors and solutions", "Useful resources", "Versioning Issues", "Customising Video Renders", "auto_unwrap_transformed_env", "AsyncCollector", "BaseCollector", "Collector", "MultiAsyncCollector", "MultiCollector", "MultiProcessedWeightUpdater", "MultiSyncCollector", "RayWeightUpdater", "VanillaWeightUpdater", "WeightUpdaterBase", "DistributedCollector", "DistributedDataCollector", "DistributedSyncCollector", "DistributedSyncDataCollector", "DistributedWeightUpdater", "RPCCollector", "RPCDataCollector", "RPCWeightUpdater", "RayCollector", "submitit_delayed_launcher", "LLMCollector", "RayLLMCollector", "vLLMUpdater", "vLLMUpdaterV2", "split_trajectories", "Binary", "Bounded", "Categorical", "Composite", "MultiCategorical", "MultiOneHot", "NonTensor", "OneHot", "PrioritizedReplayBuffer", "RayReplayBuffer", "RemoteTensorDictReplayBuffer", "ReplayBuffer", "ReplayBufferEnsemble", "Stacked", "StackedComposite", "TensorDictPrioritizedReplayBuffer", "TensorDictReplayBuffer", "TensorSpec", "Unbounded", "UnboundedContinuous", "UnboundedDiscrete", "AtariDQNExperienceReplay", "D4RLExperienceReplay", "GenDGRLExperienceReplay", "MinariExperienceReplay", "OpenMLExperienceReplay", "OpenXExperienceReplay", "RobosetExperienceReplay", "VD4RLExperienceReplay", "ContentBase", "History", "TopKRewardSelector", "add_chat_template", "CompressedListStorage", "CompressedListStorageCheckpointer", "FlatStorageCheckpointer", "H5StorageCheckpointer", "ImmutableDatasetWriter", "LazyMemmapStorage", "LazyStackStorage", "LazyTensorStorage", "ListStorage", "ListStorageCheckpointer", "NestedStorageCheckpointer", "PrioritizedSampler", "PrioritizedSliceSampler", "RandomSampler", "RoundRobinWriter", "Sampler", "SamplerEnsemble", "SamplerWithoutReplacement", "SliceSampler", "SliceSamplerWithoutReplacement", "Storage", "StorageCheckpointerBase", "StorageEnsemble", "StorageEnsembleCheckpointer", "TensorDictMaxValueWriter", "TensorDictRoundRobinWriter", "TensorStorage", "TensorStorageCheckpointer", "Writer", "WriterEnsemble", "AsyncEnvPool", "BraxEnv", "BraxWrapper", "ChessEnv", "DMControlEnv", "DMControlWrapper", "EnvBase", "EnvCreator", "EnvMetaData", "GymEnv", "GymLikeEnv", "GymWrapper", "HabitatEnv", "IsaacGymEnv", "IsaacGymWrapper", "IsaacLabWrapper", "JumanjiEnv", "JumanjiWrapper", "LLMHashingEnv", "MOGymEnv", "MOGymWrapper", "MarlGroupMapType", "MeltingpotEnv", "MeltingpotWrapper", "ModelBasedEnvBase", "MultiThreadedEnv", "MultiThreadedEnvWrapper", "OpenMLEnv", "OpenSpielEnv", "OpenSpielWrapper", "ParallelEnv", "PendulumEnv", "PettingZooEnv", "PettingZooWrapper", "ProcessorAsyncEnvPool", "RoboHiveEnv", "SMACv2Env", "SMACv2Wrapper", "SerialEnv", "ThreadingAsyncEnvPool", "TicTacToeEnv", "UnityMLAgentsEnv", "UnityMLAgentsWrapper", "VmasEnv", "VmasWrapper", "check_env_specs", "check_marl_grouping", "exploration_type", "get_available_libraries", "gym_backend", "ChatEnv", "DatasetChatEnv", "GSM8KEnv", "GSM8KPrepareQuestion", "GSM8KRewardParser", "IFEvalEnv", "IFEvalScoreData", "IfEvalScorer", "LLMEnv", "LLMHashingEnv", "MLGymWrapper", "make_gsm8k_env", "make_mlgym", "AddThinkingPrompt", "BrowserTransform", "DataLoadingPrimer", "ExecuteToolsInOrder", "JSONCallParser", "KLComputation", "KLRewardTransform", "MCPToolTransform", "PolicyVersion", "PythonExecutorService", "PythonInterpreter", "RayDataLoadingPrimer", "RetrieveKL", "RetrieveLogProb", "SimpleToolTransform", "TemplateTransform", "Tokenizer", "ToolCall", "ToolRegistry", "ToolService", "XMLBlockParser", "as_nested_tensor", "as_padded_tensor", "make_composite_from_td", "DreamerDecoder", "DreamerEnv", "register_gym_spec_conversion", "set_exploration_type", "set_gym_backend", "step_mdp", "terminated_or_truncated", "ActionDiscretizer", "ActionMask", "AutoResetEnv", "AutoResetTransform", "BatchSizeTransform", "BinarizeReward", "BurnInTransform", "CatFrames", "CatTensors", "CenterCrop", "ClipTransform", "Compose", "ConditionalPolicySwitch", "ConditionalSkip", "Crop", "DTypeCastTransform", "DeviceCastTransform", "DiscreteActionProjection", "DoubleToFloat", "EndOfLifeTransform", "ExcludeTransform", "FiniteTensorDictCheck", "FlattenObservation", "FrameSkipTransform", "GrayScale", "Hash", "InitTracker", "KLRewardTransform", "LineariseRewards", "ModuleTransform", "MultiAction", "NoopResetEnv", "ObservationNorm", "ObservationTransform", "PermuteTransform", "PinMemoryTransform", "R3MTransform", "RandomCropTensorDict", "RemoveEmptySpecs", "RenameTransform", "Resize", "Reward2GoTransform", "RewardClipping", "RewardScaling", "RewardSum", "SelectTransform", "SignTransform", "SqueezeTransform", "Stack", "StepCounter", "TargetReturn", "TensorDictPrimer", "TimeMaxPool", "Timer", "ToTensorImage", "Tokenizer", "TrajCounter", "Transform", "TransformedEnv", "UnaryTransform", "UnsqueezeTransform", "VC1Transform", "VIPRewardTransform", "VIPTransform", "VecGymEnvTransform", "VecNorm", "VecNormV2", "gSDENoise", "implement_for", "ActorCriticOperator", "ActorCriticWrapper", "ActorValueOperator", "AdditiveGaussianModule", "ConsistentDropoutModule", "ConvNet", "DTActor", "DdpgCnnActor", "DdpgCnnQNet", "DdpgMlpActor", "DdpgMlpQNet", "DecisionTransformer", "Delta", "DistributionalDQNnet", "DistributionalQValueActor", "DistributionalQValueModule", "DreamerActor", "DuelingCnnDQNet", "EGreedyModule", "GRUModule", "IndependentNormal", "LSTMModule", "MLP", "MaskedCategorical", "NormalParamExtractor", "ObsDecoder", "ObsEncoder", "OneHotCategorical", "OnlineDTActor", "OrnsteinUhlenbeckProcessModule", "QValueActor", "QValueModule", "RSSMPosterior", "RSSMPrior", "RSSMRollout", "ReparamGradientStrategy", "TanhDelta", "TanhNormal", "TruncatedNormal", "ValueOperator", "WorldModelWrapper", "AsyncVLLM", "ChatHistory", "LLMWrapperBase", "LogProbs", "Masks", "RemoteTransformersWrapper", "Text", "Tokens", "TransformersWrapper", "make_async_vllm_engine", "make_vllm_worker", "stateless_init_process_group", "stateless_init_process_group_async", "vLLMWrapper", "SquashDims", "set_exploration_modules_spec_from_env", "Actor", "MultiStepActorWrapper", "ProbabilisticActor", "RandomPolicy", "SafeModule", "SafeProbabilisticModule", "SafeProbabilisticTensorDictSequential", "SafeSequential", "TanhModule", "A2CLoss", "CQLLoss", "ClipPPOLoss", "CrossQLoss", "DDPGLoss", "DQNLoss", "DTLoss", "DiscreteCQLLoss", "DiscreteIQLLoss", "DiscreteSACLoss", "DistributionalDQNLoss", "DreamerActorLoss", "DreamerModelLoss", "DreamerValueLoss", "GAILLoss", "IQLLoss", "KLPENPPOLoss", "LossModule", "OnlineDTLoss", "PPOLoss", "REDQLoss", "ReinforceLoss", "SACLoss", "TD3BCLoss", "TD3Loss", "ValueEstimators", "add_random_module", "CISPOLoss", "CISPOLossOutput", "DAPO", "DAPOLossOutput", "GRPOLoss", "GRPOLossOutput", "LLMLossOutput", "MCAdvantage", "SFTLoss", "SFTLossOutput", "GAE", "TD0Estimator", "TD1Estimator", "TDLambdaEstimator", "ValueEstimatorBase", "PixelRenderTransform", "TensorDictRecorder", "VideoRecorder", "Logger", "CSVLogger", "generate_exp_name", "get_logger", "MLFlowLogger", "TensorboardLogger", "TrackioLogger", "WandbLogger", "RayService", "ServiceBase", "get_services", "set_auto_unwrap_transformed_env", "BatchSubSampler", "ClearCudaCache", "CountFramesLog", "LogScalar", "LogValidationReward", "OptimizerHook", "ReplayBufferTrainer", "RewardNormalizer", "SelectKeys", "TargetNetUpdaterHook", "Trainer", "TrainerHookBase", "UTDRHook", "UpdateWeights", "PPOTrainer", "SACTrainer", "torchrl.trainers.algorithms.configs.collectors.AsyncDataCollectorConfig", "torchrl.trainers.algorithms.configs.collectors.SyncDataCollectorConfig", "torchrl.trainers.algorithms.configs.common.ConfigBase", "torchrl.trainers.algorithms.configs.data.LazyMemmapStorageConfig", "torchrl.trainers.algorithms.configs.data.LazyStackStorageConfig", "torchrl.trainers.algorithms.configs.data.LazyTensorStorageConfig", "torchrl.trainers.algorithms.configs.data.ListStorageConfig", "torchrl.trainers.algorithms.configs.data.PrioritizedSamplerConfig", "torchrl.trainers.algorithms.configs.data.RandomSamplerConfig", "torchrl.trainers.algorithms.configs.data.ReplayBufferConfig", "torchrl.trainers.algorithms.configs.data.RoundRobinWriterConfig", "torchrl.trainers.algorithms.configs.data.SamplerWithoutReplacementConfig", "torchrl.trainers.algorithms.configs.data.SliceSamplerConfig", "torchrl.trainers.algorithms.configs.data.SliceSamplerWithoutReplacementConfig", "torchrl.trainers.algorithms.configs.data.StorageEnsembleConfig", "torchrl.trainers.algorithms.configs.data.StorageEnsembleWriterConfig", "torchrl.trainers.algorithms.configs.data.TensorDictReplayBufferConfig", "torchrl.trainers.algorithms.configs.data.TensorStorageConfig", "torchrl.trainers.algorithms.configs.envs.BatchedEnvConfig", "torchrl.trainers.algorithms.configs.envs.EnvConfig", "torchrl.trainers.algorithms.configs.envs.TransformedEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.BraxEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.DMControlEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.EnvLibsConfig", "torchrl.trainers.algorithms.configs.envs_libs.GymEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.HabitatEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.IsaacGymEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.JumanjiEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.MOGymEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.MeltingpotEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.MultiThreadedEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.OpenMLEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.OpenSpielEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.PettingZooEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.RoboHiveEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.SMACv2EnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.UnityMLAgentsEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.VmasEnvConfig", "torchrl.trainers.algorithms.configs.logging.CSVLoggerConfig", "torchrl.trainers.algorithms.configs.logging.LoggerConfig", "torchrl.trainers.algorithms.configs.logging.TensorboardLoggerConfig", "torchrl.trainers.algorithms.configs.logging.WandbLoggerConfig", "torchrl.trainers.algorithms.configs.modules.ConvNetConfig", "torchrl.trainers.algorithms.configs.modules.MLPConfig", "torchrl.trainers.algorithms.configs.modules.ModelConfig", "torchrl.trainers.algorithms.configs.modules.NetworkConfig", "torchrl.trainers.algorithms.configs.modules.TanhNormalModelConfig", "torchrl.trainers.algorithms.configs.modules.TensorDictModuleConfig", "torchrl.trainers.algorithms.configs.modules.ValueModelConfig", "torchrl.trainers.algorithms.configs.objectives.LossConfig", "torchrl.trainers.algorithms.configs.objectives.PPOLossConfig", "torchrl.trainers.algorithms.configs.trainers.PPOTrainerConfig", "torchrl.trainers.algorithms.configs.trainers.TrainerConfig", "torchrl.trainers.algorithms.configs.transforms.ActionDiscretizerConfig", "torchrl.trainers.algorithms.configs.transforms.ActionMaskConfig", "torchrl.trainers.algorithms.configs.transforms.AutoResetTransformConfig", "torchrl.trainers.algorithms.configs.transforms.BatchSizeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.BinarizeRewardConfig", "torchrl.trainers.algorithms.configs.transforms.BurnInTransformConfig", "torchrl.trainers.algorithms.configs.transforms.CatFramesConfig", "torchrl.trainers.algorithms.configs.transforms.CatTensorsConfig", "torchrl.trainers.algorithms.configs.transforms.CenterCropConfig", "torchrl.trainers.algorithms.configs.transforms.ClipTransformConfig", "torchrl.trainers.algorithms.configs.transforms.ComposeConfig", "torchrl.trainers.algorithms.configs.transforms.ConditionalPolicySwitchConfig", "torchrl.trainers.algorithms.configs.transforms.ConditionalSkipConfig", "torchrl.trainers.algorithms.configs.transforms.CropConfig", "torchrl.trainers.algorithms.configs.transforms.DTypeCastTransformConfig", "torchrl.trainers.algorithms.configs.transforms.DeviceCastTransformConfig", "torchrl.trainers.algorithms.configs.transforms.DiscreteActionProjectionConfig", "torchrl.trainers.algorithms.configs.transforms.DoubleToFloatConfig", "torchrl.trainers.algorithms.configs.transforms.EndOfLifeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.ExcludeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.FiniteTensorDictCheckConfig", "torchrl.trainers.algorithms.configs.transforms.FlattenObservationConfig", "torchrl.trainers.algorithms.configs.transforms.FrameSkipTransformConfig", "torchrl.trainers.algorithms.configs.transforms.GrayScaleConfig", "torchrl.trainers.algorithms.configs.transforms.HashConfig", "torchrl.trainers.algorithms.configs.transforms.InitTrackerConfig", "torchrl.trainers.algorithms.configs.transforms.KLRewardTransformConfig", "torchrl.trainers.algorithms.configs.transforms.LineariseRewardsConfig", "torchrl.trainers.algorithms.configs.transforms.MultiActionConfig", "torchrl.trainers.algorithms.configs.transforms.MultiStepTransformConfig", "torchrl.trainers.algorithms.configs.transforms.NoopResetEnvConfig", "torchrl.trainers.algorithms.configs.transforms.ObservationNormConfig", "torchrl.trainers.algorithms.configs.transforms.PermuteTransformConfig", "torchrl.trainers.algorithms.configs.transforms.PinMemoryTransformConfig", "torchrl.trainers.algorithms.configs.transforms.R3MTransformConfig", "torchrl.trainers.algorithms.configs.transforms.RandomCropTensorDictConfig", "torchrl.trainers.algorithms.configs.transforms.RemoveEmptySpecsConfig", "torchrl.trainers.algorithms.configs.transforms.RenameTransformConfig", "torchrl.trainers.algorithms.configs.transforms.ResizeConfig", "torchrl.trainers.algorithms.configs.transforms.Reward2GoTransformConfig", "torchrl.trainers.algorithms.configs.transforms.RewardClippingConfig", "torchrl.trainers.algorithms.configs.transforms.RewardScalingConfig", "torchrl.trainers.algorithms.configs.transforms.RewardSumConfig", "torchrl.trainers.algorithms.configs.transforms.SelectTransformConfig", "torchrl.trainers.algorithms.configs.transforms.SignTransformConfig", "torchrl.trainers.algorithms.configs.transforms.SqueezeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.StackConfig", "torchrl.trainers.algorithms.configs.transforms.StepCounterConfig", "torchrl.trainers.algorithms.configs.transforms.TargetReturnConfig", "torchrl.trainers.algorithms.configs.transforms.TensorDictPrimerConfig", "torchrl.trainers.algorithms.configs.transforms.TimeMaxPoolConfig", "torchrl.trainers.algorithms.configs.transforms.TimerConfig", "torchrl.trainers.algorithms.configs.transforms.ToTensorImageConfig", "torchrl.trainers.algorithms.configs.transforms.TokenizerConfig", "torchrl.trainers.algorithms.configs.transforms.TrajCounterConfig", "torchrl.trainers.algorithms.configs.transforms.TransformConfig", "torchrl.trainers.algorithms.configs.transforms.UnaryTransformConfig", "torchrl.trainers.algorithms.configs.transforms.UnsqueezeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VC1TransformConfig", "torchrl.trainers.algorithms.configs.transforms.VIPRewardTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VIPTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VecGymEnvTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VecNormConfig", "torchrl.trainers.algorithms.configs.transforms.VecNormV2Config", "torchrl.trainers.algorithms.configs.utils.ASGDConfig", "torchrl.trainers.algorithms.configs.utils.AdadeltaConfig", "torchrl.trainers.algorithms.configs.utils.AdagradConfig", "torchrl.trainers.algorithms.configs.utils.AdamConfig", "torchrl.trainers.algorithms.configs.utils.AdamWConfig", "torchrl.trainers.algorithms.configs.utils.AdamaxConfig", "torchrl.trainers.algorithms.configs.utils.LBFGSConfig", "torchrl.trainers.algorithms.configs.utils.LionConfig", "torchrl.trainers.algorithms.configs.utils.NAdamConfig", "torchrl.trainers.algorithms.configs.utils.RAdamConfig", "torchrl.trainers.algorithms.configs.utils.RMSpropConfig", "torchrl.trainers.algorithms.configs.utils.RpropConfig", "torchrl.trainers.algorithms.configs.utils.SGDConfig", "torchrl.trainers.algorithms.configs.utils.SparseAdamConfig", "correct_for_frame_skip", "get_stats_random_rollout", "make_collector_offpolicy", "make_collector_onpolicy", "make_dqn_loss", "make_replay_buffer", "make_target_updater", "make_trainer", "parallel_env_constructor", "sync_async_collector", "sync_sync_collector", "transformed_env_constructor", "DistributedTransport", "DistributedWeightSyncScheme", "MPTransport", "MultiProcessWeightSyncScheme", "NoWeightSyncScheme", "RPCTransport", "RPCWeightSyncScheme", "RayModuleTransformScheme", "RayTransport", "RayWeightSyncScheme", "SharedMemTransport", "SharedMemWeightSyncScheme", "TransportBackend", "WeightStrategy", "WeightSyncScheme", "VLLMCollectiveTransport", "VLLMDoubleBufferSyncScheme", "VLLMDoubleBufferTransport", "VLLMDoubleBufferWeightReceiver", "VLLMDoubleBufferWeightSender", "VLLMWeightReceiver", "VLLMWeightSender", "VLLMWeightSyncScheme", "get_model_metadata", "README Tutos", "API Reference", "Knowledge Base", "LLM Interface", "LLM Collectors", "Data Structures", "LLM Environments", "LLM Wrappers", "LLM Objectives", "LLM Transforms", "torchrl.modules package", "Actor Modules", "Value Networks and Critics", "Distribution Classes", "Exploration Strategies", "World Models and Model-Based RL", "Utilities and Helpers", "torchrl.objectives package", "Actor-Critic Methods", "Common Components", "Offline RL Methods", "Other Loss Modules", "Policy Gradient Methods", "Value-Based Methods", "Service Registry", "torchrl.trainers package", "Trainer Basics", "Training Hooks", "Loggers", "torchrl._utils package", "Computation times", "TorchRL objectives: Coding a DDPG loss", "TorchRL trainer: A DQN example", "Reinforcement Learning (PPO) with TorchRL Tutorial", "Recurrent DQN: Training recurrent policies", "Exporting TorchRL modules", "Get started with Environments, TED and transforms", "Get started with TorchRL\u2019s modules", "Getting started with model optimization", "Get started with data collection and storage", "Get started with logging", "Get started with your own first training loop", "README Tutos", "TorchRL LLM: Building Tool-Enabled Environments", "LLM Wrappers in TorchRL", "Task-specific policy in multi-task environments", "Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial", "Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial", "Pendulum: Writing your environment and transforms with TorchRL", "Using pretrained models", "Using Replay Buffers", "Computation times", "Introduction to TorchRL", "TorchRL envs"], "terms": {"an": [0, 2, 6, 12, 16, 17, 18, 19, 20, 21, 22, 24, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 94, 95, 96, 97, 98, 102, 104, 106, 108, 109, 110, 112, 114, 115, 116, 118, 119, 120, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 137, 138, 144, 145, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 165, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 214, 215, 217, 218, 220, 221, 223, 229, 231, 232, 235, 239, 243, 245, 246, 250, 251, 252, 253, 255, 264, 265, 266, 267, 268, 270, 271, 272, 275, 278, 279, 280, 283, 284, 285, 288, 290, 291, 292, 293, 295, 297, 298, 301, 302, 304, 305, 312, 313, 320, 323, 324, 325, 326, 327, 328, 330, 331, 332, 333, 335, 336, 337, 338, 341, 342, 345, 346, 349, 350, 351, 352, 354, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 396, 401, 404, 410, 411, 416, 417, 420, 421, 554, 561, 562, 563, 564, 568, 576, 591, 592, 620, 621, 624, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636, 638, 639, 641, 642], "open": [0, 24, 26, 83, 86, 87, 95, 176, 282, 325, 327, 328, 330, 331, 335, 336, 377, 379, 381, 382, 385, 621, 632, 635, 636, 641], "sourc": [0, 2, 4, 23, 26, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "reinforc": [0, 7, 15, 22, 28, 80, 142, 143, 170, 171, 221, 280, 290, 291, 292, 293, 298, 312, 349, 350, 352, 355, 356, 357, 359, 364, 370, 371, 372, 420, 592, 604, 606, 609, 619, 621, 625, 626, 631, 633, 637, 640, 641], "learn": [0, 7, 15, 19, 22, 26, 27, 28, 42, 80, 81, 82, 84, 85, 86, 87, 101, 102, 126, 142, 143, 147, 150, 158, 170, 171, 176, 177, 221, 280, 290, 291, 292, 293, 298, 312, 325, 327, 328, 330, 331, 349, 350, 351, 352, 355, 356, 357, 359, 363, 364, 368, 369, 370, 371, 372, 377, 379, 380, 381, 382, 385, 420, 421, 592, 604, 606, 609, 619, 620, 621, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 637, 639, 640, 641, 642], "rl": [0, 2, 6, 10, 11, 12, 16, 18, 22, 24, 27, 29, 32, 34, 35, 38, 78, 135, 144, 170, 221, 264, 322, 332, 337, 340, 342, 349, 351, 365, 366, 368, 370, 380, 406, 589, 590, 591, 599, 600, 602, 605, 606, 612, 620, 621, 622, 628, 631, 635, 636, 638, 639, 642], "librari": [0, 2, 3, 6, 10, 16, 17, 20, 22, 24, 25, 26, 27, 28, 29, 30, 35, 36, 38, 42, 44, 47, 123, 124, 125, 134, 145, 168, 177, 190, 324, 404, 590, 591, 618, 620, 621, 622, 624, 625, 626, 628, 635, 636, 637, 642], "pytorch": [0, 2, 3, 6, 19, 20, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 81, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 175, 178, 179, 180, 221, 267, 268, 317, 416, 578, 580, 589, 591, 602, 620, 622, 623, 627, 631, 635, 636, 637, 641, 642], "you": [0, 2, 5, 6, 7, 12, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 54, 80, 87, 88, 89, 120, 123, 126, 130, 134, 138, 141, 142, 143, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 221, 242, 271, 279, 280, 326, 332, 337, 345, 368, 376, 378, 380, 383, 384, 401, 405, 587, 591, 592, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "can": [0, 2, 3, 4, 6, 7, 8, 12, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 101, 102, 107, 108, 109, 114, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 134, 136, 137, 138, 141, 142, 143, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 202, 209, 211, 213, 214, 215, 217, 218, 220, 221, 224, 225, 227, 229, 231, 232, 233, 236, 239, 244, 245, 246, 250, 251, 255, 258, 262, 263, 264, 265, 269, 270, 271, 272, 273, 275, 277, 279, 280, 282, 286, 287, 288, 290, 297, 298, 301, 302, 303, 304, 306, 307, 312, 313, 314, 320, 321, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 337, 339, 340, 341, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 401, 402, 403, 405, 409, 410, 420, 466, 562, 563, 564, 566, 568, 569, 571, 572, 574, 575, 576, 577, 578, 579, 581, 586, 587, 591, 592, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "directli": [0, 6, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 69, 78, 81, 88, 120, 121, 122, 123, 126, 129, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 246, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 273, 275, 276, 278, 279, 280, 324, 329, 345, 366, 372, 376, 378, 380, 383, 384, 564, 566, 568, 571, 572, 574, 575, 579, 581, 587, 592, 621, 622, 623, 624, 625, 635, 636, 637, 639], "from": [0, 1, 2, 4, 5, 6, 7, 10, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 96, 97, 98, 101, 102, 106, 107, 108, 109, 110, 112, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 206, 208, 211, 212, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 239, 240, 241, 242, 246, 248, 250, 251, 252, 253, 254, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 277, 278, 279, 280, 282, 283, 284, 285, 287, 290, 291, 292, 293, 294, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 315, 316, 317, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 393, 402, 406, 409, 412, 416, 418, 419, 420, 421, 429, 430, 434, 473, 553, 554, 558, 560, 561, 564, 565, 566, 567, 568, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 591, 592, 599, 606, 613, 614, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642], "pypi": [0, 641], "see": [0, 1, 3, 17, 18, 19, 21, 22, 25, 26, 27, 28, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 96, 102, 108, 109, 120, 123, 126, 130, 133, 135, 137, 138, 142, 143, 145, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 225, 227, 244, 250, 265, 268, 270, 271, 272, 275, 277, 279, 280, 281, 283, 285, 287, 288, 302, 303, 304, 305, 307, 317, 321, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 344, 345, 351, 352, 363, 365, 366, 368, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 401, 402, 412, 420, 566, 568, 571, 572, 574, 575, 576, 579, 581, 587, 590, 592, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 632, 635, 636, 637, 639, 641, 642], "more": [0, 2, 6, 9, 17, 21, 22, 23, 25, 27, 28, 32, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 49, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 101, 102, 114, 120, 123, 126, 129, 130, 131, 133, 134, 137, 138, 142, 143, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 268, 271, 275, 280, 281, 282, 286, 287, 297, 298, 305, 307, 317, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 344, 345, 349, 359, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 401, 402, 411, 587, 590, 591, 592, 606, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 632, 633, 634, 635, 636, 637, 638, 641, 642], "about": [0, 21, 24, 26, 28, 42, 44, 47, 49, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 81, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 183, 195, 326, 332, 337, 620, 621, 622, 624, 625, 626, 627, 628, 629, 630, 635, 636, 637, 639, 641, 642], "instruct": [0, 6, 25, 26, 29, 51, 79, 87, 135, 172, 177, 231, 233, 565, 568, 576, 592, 620, 621, 622, 623, 632, 635, 636, 639], "dedic": [0, 3, 6, 19, 42, 44, 47, 50, 68, 69, 72, 73, 150, 158, 283, 284, 285, 324, 575, 592, 620, 625, 627, 628, 630, 634, 636], "section": [0, 7, 17, 23, 126, 590, 621, 624, 625, 630, 635, 636], "below": [0, 1, 6, 17, 22, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 68, 72, 73, 75, 86, 87, 88, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 227, 244, 250, 265, 270, 271, 272, 275, 277, 288, 303, 305, 317, 321, 325, 326, 327, 328, 330, 331, 332, 337, 342, 344, 351, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 412, 620, 621, 622, 623, 624, 625, 635, 637], "pip": [0, 29, 82, 190, 624, 625, 626, 627, 628, 629, 630, 632, 636, 641, 642], "provid": [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 15, 16, 17, 18, 19, 21, 22, 24, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 98, 101, 102, 103, 106, 108, 109, 117, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 218, 220, 221, 222, 223, 224, 228, 229, 232, 236, 239, 243, 245, 246, 248, 250, 251, 254, 255, 258, 259, 264, 265, 266, 269, 270, 272, 274, 275, 277, 278, 279, 280, 282, 288, 294, 295, 298, 301, 302, 304, 305, 306, 313, 314, 315, 316, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 337, 340, 341, 342, 345, 348, 349, 350, 351, 352, 353, 354, 356, 358, 359, 360, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 397, 402, 403, 406, 412, 418, 419, 424, 554, 560, 566, 568, 586, 591, 592, 594, 596, 606, 613, 614, 620, 621, 622, 623, 624, 625, 626, 628, 629, 633, 634, 635, 636, 637, 638, 639, 641, 642], "python": [0, 5, 7, 22, 24, 25, 26, 29, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 146, 161, 162, 170, 190, 192, 193, 208, 211, 302, 304, 306, 590, 592, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "first": [0, 1, 2, 5, 6, 9, 17, 18, 19, 20, 22, 23, 24, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 95, 97, 102, 108, 109, 114, 116, 120, 123, 126, 129, 130, 131, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 186, 217, 218, 221, 222, 226, 227, 236, 244, 246, 250, 251, 267, 268, 272, 275, 280, 282, 288, 295, 297, 298, 302, 304, 305, 306, 309, 313, 324, 331, 340, 342, 344, 345, 351, 361, 365, 366, 368, 376, 378, 380, 384, 392, 393, 414, 574, 619, 620, 621, 622, 623, 624, 625, 628, 629, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642], "low": [0, 6, 18, 58, 60, 74, 75, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 183, 206, 214, 224, 231, 239, 242, 265, 273, 298, 319, 320, 321, 342, 345, 348, 368, 484, 620, 621, 622, 624, 635, 636, 637, 641], "high": [0, 1, 18, 22, 28, 58, 60, 72, 75, 86, 87, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 183, 206, 214, 224, 231, 239, 242, 245, 265, 273, 298, 319, 320, 321, 325, 327, 328, 330, 331, 342, 345, 348, 368, 377, 379, 381, 382, 385, 386, 484, 586, 614, 620, 621, 622, 633, 635, 636, 637, 639, 641], "level": [0, 6, 19, 21, 22, 23, 35, 36, 38, 51, 60, 65, 66, 68, 69, 71, 86, 87, 90, 129, 131, 176, 188, 196, 221, 263, 271, 302, 304, 325, 327, 328, 330, 331, 358, 365, 371, 377, 379, 381, 382, 385, 614, 620, 621, 624, 628, 641], "abstract": [0, 19, 27, 41, 74, 78, 82, 118, 126, 247, 390, 403, 407, 417, 424, 577, 579, 622, 624, 637, 641], "ar": [0, 1, 2, 3, 5, 6, 7, 9, 10, 12, 17, 18, 19, 20, 21, 22, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 96, 97, 98, 100, 101, 102, 106, 107, 108, 109, 110, 112, 114, 116, 120, 123, 126, 127, 129, 130, 131, 137, 138, 141, 142, 143, 144, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 208, 212, 213, 214, 216, 217, 218, 220, 221, 224, 225, 227, 229, 230, 231, 232, 233, 235, 236, 239, 241, 242, 244, 245, 248, 250, 255, 258, 262, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 278, 279, 280, 286, 293, 295, 297, 301, 302, 304, 306, 307, 310, 313, 316, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 337, 341, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 401, 402, 403, 404, 405, 412, 416, 418, 419, 420, 421, 560, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 579, 581, 585, 587, 592, 599, 606, 613, 618, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "intend": [0, 6, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 220, 231, 366, 641], "effici": [0, 1, 3, 6, 9, 10, 12, 23, 27, 39, 91, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 192, 332, 352, 418, 568, 573, 592, 594, 606, 613, 620, 621, 622, 623, 624, 627, 628, 630, 634, 635, 636, 638, 639, 641], "modular": [0, 7, 78, 189, 347, 599, 614, 624, 639, 641], "document": [0, 6, 24, 26, 30, 32, 35, 36, 38, 42, 44, 47, 50, 83, 88, 120, 123, 126, 130, 135, 138, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 326, 332, 337, 376, 378, 380, 383, 384, 589, 590, 613, 621, 623, 624, 625, 628, 631, 641], "properli": [0, 4, 5, 21, 22, 52, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 195, 196, 212, 227, 302, 304, 386, 592, 622, 623, 629, 635, 636, 637, 641], "test": [0, 7, 20, 22, 24, 52, 120, 121, 122, 123, 126, 130, 136, 137, 138, 142, 143, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 183, 185, 270, 275, 315, 316, 410, 560, 581, 582, 585, 586, 592, 613, 622, 623, 624, 638, 641], "The": [0, 1, 2, 3, 5, 6, 7, 9, 10, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 93, 101, 102, 106, 108, 109, 110, 114, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 136, 137, 138, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 205, 208, 209, 212, 213, 214, 217, 218, 220, 221, 225, 226, 227, 229, 232, 233, 234, 239, 242, 243, 244, 246, 248, 250, 255, 257, 258, 259, 262, 263, 264, 265, 267, 270, 271, 272, 275, 277, 278, 279, 280, 283, 286, 290, 291, 292, 293, 294, 297, 298, 302, 304, 306, 307, 312, 313, 314, 315, 316, 317, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 342, 344, 345, 347, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 395, 398, 399, 400, 401, 402, 403, 405, 406, 411, 418, 419, 420, 421, 461, 471, 473, 560, 562, 563, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 584, 585, 587, 592, 594, 595, 596, 613, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 635, 636, 637, 638, 639, 641, 642], "code": [0, 6, 17, 18, 22, 24, 26, 27, 35, 38, 60, 71, 83, 120, 123, 126, 130, 135, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 189, 190, 192, 193, 250, 272, 275, 326, 342, 345, 347, 592, 613, 619, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 638, 639, 640, 641, 642], "aim": [0, 21, 26, 70, 71, 250, 275, 277, 305, 553, 591, 620, 621, 641], "support": [0, 2, 3, 4, 7, 10, 16, 18, 19, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 82, 85, 86, 87, 89, 95, 97, 110, 112, 116, 117, 119, 120, 121, 122, 123, 129, 131, 136, 145, 147, 150, 152, 155, 168, 176, 178, 184, 189, 199, 218, 221, 233, 239, 246, 265, 266, 269, 272, 273, 280, 297, 298, 320, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 342, 344, 347, 359, 366, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 398, 404, 566, 568, 571, 572, 574, 576, 577, 578, 579, 581, 587, 592, 594, 599, 606, 613, 614, 622, 623, 625, 626, 632, 633, 636, 637, 639, 641], "research": [0, 26, 28, 142, 143, 633, 641], "most": [0, 4, 6, 12, 17, 21, 26, 27, 35, 36, 38, 63, 101, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 231, 278, 613, 620, 622, 624, 625, 626, 627, 628, 629, 630, 637, 641, 642], "written": [0, 4, 13, 17, 22, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 93, 95, 102, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 183, 212, 213, 214, 221, 233, 236, 241, 242, 258, 263, 266, 267, 272, 278, 282, 287, 312, 322, 325, 327, 328, 330, 331, 340, 342, 344, 345, 349, 351, 365, 368, 370, 377, 379, 380, 381, 382, 385, 391, 392, 393, 418, 592, 620, 623, 624, 626, 634, 637, 641], "highli": [0, 15, 332, 351, 368, 625, 641, 642], "wai": [0, 1, 2, 4, 5, 19, 21, 22, 23, 50, 60, 69, 71, 78, 81, 114, 134, 171, 172, 175, 195, 221, 225, 250, 253, 270, 271, 277, 278, 302, 304, 368, 386, 387, 388, 389, 421, 592, 613, 620, 621, 622, 624, 625, 627, 628, 634, 635, 636, 637, 638, 639, 641, 642], "easili": [0, 2, 7, 17, 18, 22, 26, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 613, 620, 621, 622, 625, 626, 627, 630, 635, 636, 641, 642], "swap": [0, 2, 16, 17, 129, 278, 622, 624, 638, 641], "compon": [0, 2, 6, 7, 10, 12, 19, 21, 22, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 95, 96, 97, 98, 110, 112, 116, 171, 297, 298, 314, 324, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 411, 416, 590, 606, 620, 621, 622, 623, 624, 626, 627, 630, 632, 634, 635, 636, 637, 638, 641], "transform": [0, 3, 4, 6, 10, 12, 16, 17, 18, 20, 22, 23, 27, 32, 34, 35, 36, 38, 40, 41, 42, 44, 47, 50, 52, 53, 54, 55, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 93, 100, 112, 117, 120, 123, 126, 127, 130, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 207, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 287, 289, 290, 294, 299, 302, 304, 311, 317, 320, 325, 327, 328, 329, 330, 331, 332, 337, 341, 348, 355, 367, 377, 379, 381, 382, 383, 384, 385, 391, 393, 412, 419, 420, 431, 436, 437, 438, 442, 473, 564, 572, 573, 574, 590, 594, 613, 619, 621, 623, 624, 626, 628, 629, 630, 631, 632, 638, 640], "them": [0, 6, 12, 19, 26, 28, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 114, 119, 120, 123, 126, 127, 130, 134, 138, 141, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 199, 229, 232, 239, 242, 265, 269, 272, 273, 279, 280, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 338, 341, 348, 350, 352, 358, 364, 365, 369, 371, 372, 373, 387, 388, 389, 393, 565, 568, 575, 577, 582, 583, 584, 613, 620, 621, 623, 624, 625, 626, 628, 629, 633, 634, 635, 636, 637, 638, 639, 641, 642], "write": [0, 17, 27, 32, 34, 35, 36, 38, 52, 56, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 112, 119, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 213, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 248, 249, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 274, 275, 276, 278, 279, 322, 325, 327, 328, 330, 331, 340, 344, 345, 347, 352, 353, 354, 356, 357, 358, 364, 369, 371, 372, 373, 377, 379, 381, 382, 383, 385, 390, 393, 581, 582, 584, 592, 613, 614, 619, 620, 621, 622, 623, 624, 625, 626, 628, 629, 630, 631, 632, 634, 635, 636, 638, 639, 640, 641, 642], "new": [0, 2, 6, 7, 18, 21, 23, 27, 32, 34, 35, 36, 38, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 101, 102, 107, 120, 123, 126, 130, 138, 145, 150, 151, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 212, 213, 218, 243, 258, 262, 271, 272, 279, 280, 295, 302, 304, 312, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 344, 345, 349, 350, 351, 354, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 401, 419, 566, 568, 571, 572, 574, 575, 576, 579, 581, 583, 587, 592, 620, 622, 625, 627, 633, 635, 636, 637, 641, 642], "ones": [0, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 86, 87, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 222, 225, 226, 229, 230, 232, 246, 250, 255, 262, 265, 271, 272, 275, 277, 280, 306, 325, 326, 327, 328, 330, 331, 332, 337, 343, 344, 349, 350, 351, 352, 353, 364, 365, 368, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 592, 620, 622, 624, 633, 635, 636, 637, 639, 641, 642], "littl": [0, 4, 5, 17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272, 349, 351, 365, 368, 370, 622, 623, 624, 628, 639, 641, 642], "effort": [0, 16, 17, 18, 324, 637, 639, 641], "thi": [0, 2, 3, 4, 5, 6, 7, 8, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 100, 101, 102, 106, 107, 108, 109, 110, 112, 114, 116, 117, 119, 120, 121, 122, 123, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 147, 150, 151, 152, 153, 154, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 208, 209, 211, 212, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 243, 244, 246, 249, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 320, 321, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 401, 402, 403, 404, 405, 406, 408, 409, 410, 412, 416, 418, 419, 420, 421, 424, 473, 553, 554, 560, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 591, 592, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "repo": [0, 25, 79, 221, 266, 275, 591, 636, 641], "attempt": [0, 32, 34, 35, 36, 38, 42, 44, 47, 50, 86, 87, 88, 95, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 325, 326, 327, 328, 330, 331, 332, 337, 345, 354, 357, 364, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 627, 641], "align": [0, 641], "exist": [0, 19, 23, 32, 34, 35, 36, 38, 42, 50, 52, 53, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 222, 230, 243, 270, 271, 272, 282, 295, 325, 326, 327, 328, 330, 331, 332, 337, 345, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 403, 404, 554, 564, 573, 613, 635, 636, 641, 642], "ecosystem": [0, 624, 628, 641], "ha": [0, 2, 4, 6, 7, 18, 21, 22, 23, 24, 26, 27, 29, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 97, 101, 102, 106, 108, 114, 116, 120, 123, 126, 127, 130, 134, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 218, 221, 243, 244, 263, 264, 265, 266, 267, 269, 270, 271, 272, 286, 298, 302, 304, 320, 325, 326, 327, 328, 330, 331, 332, 337, 341, 345, 349, 352, 365, 366, 368, 370, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 393, 420, 473, 565, 573, 592, 620, 621, 622, 623, 624, 625, 628, 629, 632, 634, 635, 636, 637, 638, 639, 641, 642], "dataset": [0, 10, 65, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 94, 102, 106, 108, 109, 147, 170, 171, 172, 175, 176, 177, 178, 181, 185, 194, 279, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 393, 590, 592, 620, 621, 625, 638, 639, 641, 642], "pillar": [0, 641], "environ": [0, 1, 2, 3, 4, 6, 16, 20, 24, 27, 29, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 66, 70, 71, 74, 75, 76, 77, 88, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 208, 214, 215, 217, 218, 220, 221, 222, 226, 227, 229, 230, 231, 232, 237, 244, 245, 246, 250, 251, 252, 255, 258, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 278, 279, 280, 286, 287, 302, 304, 317, 332, 337, 339, 341, 356, 360, 383, 386, 387, 388, 389, 390, 391, 393, 405, 406, 408, 410, 420, 421, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 473, 553, 554, 555, 556, 560, 561, 562, 563, 564, 590, 591, 598, 613, 619, 624, 626, 627, 628, 629, 631, 638, 639, 640], "model": [0, 2, 3, 6, 17, 19, 27, 28, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 55, 86, 87, 88, 89, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 229, 250, 265, 275, 277, 281, 283, 284, 285, 288, 289, 294, 296, 305, 311, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 344, 349, 350, 351, 352, 354, 355, 356, 357, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 403, 416, 466, 468, 470, 555, 556, 557, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 584, 586, 587, 588, 590, 591, 592, 594, 599, 619, 622, 625, 628, 631, 633, 635, 636, 637, 639, 640, 642], "data": [0, 1, 2, 3, 4, 6, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 27, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 135, 136, 137, 138, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 165, 170, 171, 172, 175, 176, 177, 178, 179, 180, 182, 185, 188, 189, 190, 191, 194, 195, 196, 199, 202, 206, 213, 215, 218, 220, 221, 226, 229, 230, 232, 234, 236, 239, 241, 246, 252, 255, 262, 263, 265, 269, 271, 272, 273, 278, 280, 297, 301, 302, 304, 312, 313, 322, 325, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336, 337, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 377, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 391, 393, 401, 406, 409, 412, 416, 418, 419, 420, 421, 473, 555, 560, 562, 563, 564, 567, 573, 580, 585, 590, 592, 595, 599, 613, 614, 619, 623, 624, 625, 626, 627, 631, 632, 633, 637, 638, 639, 640, 642], "util": [0, 11, 17, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 56, 68, 86, 87, 88, 108, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 143, 150, 151, 152, 153, 154, 158, 159, 160, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 265, 277, 287, 288, 294, 302, 304, 325, 326, 327, 328, 330, 331, 332, 337, 338, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 557, 560, 590, 598, 599, 608, 614, 618, 620, 622, 624, 626, 627, 636, 637, 639, 641, 642], "e": [0, 2, 6, 7, 17, 19, 20, 21, 22, 26, 27, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 89, 90, 95, 97, 101, 102, 114, 116, 120, 123, 126, 127, 130, 131, 138, 150, 151, 154, 158, 159, 160, 163, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 220, 222, 225, 226, 227, 228, 236, 239, 242, 244, 246, 250, 258, 265, 267, 270, 271, 272, 275, 277, 282, 298, 302, 303, 304, 307, 314, 320, 321, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 341, 342, 344, 345, 349, 351, 352, 353, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 403, 406, 416, 420, 473, 553, 563, 566, 567, 568, 569, 571, 572, 573, 574, 576, 579, 580, 581, 584, 587, 592, 613, 621, 622, 624, 626, 627, 629, 633, 635, 636, 638, 639, 641, 642], "g": [0, 2, 6, 7, 17, 19, 20, 21, 22, 26, 27, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 89, 114, 120, 123, 126, 127, 130, 131, 138, 150, 151, 154, 158, 159, 160, 163, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 220, 222, 225, 226, 236, 239, 242, 246, 250, 258, 265, 267, 270, 271, 272, 275, 277, 282, 302, 303, 304, 320, 321, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 342, 344, 345, 352, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 403, 416, 420, 473, 563, 566, 567, 568, 569, 571, 572, 574, 576, 579, 580, 581, 584, 587, 592, 613, 621, 622, 624, 626, 629, 635, 636, 637, 638, 639, 641, 642], "collector": [0, 7, 17, 18, 22, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 255, 263, 271, 302, 304, 312, 326, 329, 332, 337, 339, 343, 351, 365, 368, 380, 383, 412, 416, 419, 420, 421, 473, 555, 556, 560, 562, 563, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 576, 579, 581, 587, 590, 592, 606, 613, 614, 624, 639, 642], "contain": [0, 17, 21, 22, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 94, 102, 104, 106, 108, 109, 110, 115, 118, 119, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 221, 225, 229, 232, 239, 250, 262, 265, 270, 271, 272, 275, 277, 278, 279, 280, 288, 297, 298, 305, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 342, 344, 345, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 397, 406, 553, 560, 561, 562, 563, 564, 575, 582, 583, 592, 606, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 635, 636, 637, 638, 639, 641, 642], "etc": [0, 6, 7, 12, 17, 21, 22, 26, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 262, 272, 282, 305, 320, 326, 332, 337, 376, 378, 380, 383, 384, 402, 566, 567, 568, 569, 571, 572, 574, 576, 579, 581, 587, 599, 621, 622, 628, 639, 641, 642], "have": [0, 2, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 32, 35, 36, 38, 42, 46, 47, 50, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 107, 110, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 209, 213, 214, 217, 221, 226, 229, 232, 233, 241, 245, 246, 262, 263, 265, 269, 270, 271, 272, 279, 280, 286, 288, 305, 306, 312, 317, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 346, 347, 349, 351, 365, 368, 370, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 393, 402, 406, 416, 418, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587, 592, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 634, 635, 636, 637, 638, 639, 641, 642], "few": [0, 12, 27, 86, 87, 109, 130, 176, 180, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 393, 406, 592, 613, 622, 623, 626, 635, 636, 639, 641, 642], "depend": [0, 2, 3, 5, 6, 18, 21, 22, 23, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 58, 75, 120, 123, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 175, 177, 178, 179, 180, 190, 229, 232, 286, 322, 332, 337, 339, 345, 368, 395, 613, 620, 622, 623, 632, 635, 636, 637, 641, 642], "possibl": [0, 19, 20, 22, 23, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 80, 83, 85, 86, 87, 88, 96, 102, 108, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 225, 250, 265, 270, 271, 272, 275, 277, 288, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 410, 416, 592, 620, 622, 623, 624, 626, 628, 629, 635, 636, 637, 639, 641, 642], "standard": [0, 19, 21, 63, 123, 246, 257, 279, 280, 286, 299, 311, 315, 316, 324, 326, 332, 337, 351, 365, 368, 372, 373, 386, 387, 388, 389, 409, 620, 621, 625, 626, 636, 639, 641], "numpi": [0, 20, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 239, 268, 273, 282, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 416, 624, 637, 639, 641, 642], "common": [0, 22, 23, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 74, 88, 120, 130, 136, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 233, 271, 283, 284, 285, 326, 349, 350, 351, 352, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 380, 383, 402, 403, 420, 560, 590, 591, 592, 606, 613, 620, 622, 626, 629, 634, 635, 636, 637, 638, 641, 642], "openai": [0, 26, 129, 131, 138, 155, 179, 622, 637, 641, 642], "gym": [0, 3, 7, 16, 17, 18, 22, 23, 27, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 88, 120, 123, 126, 127, 129, 130, 131, 132, 134, 135, 138, 142, 143, 145, 146, 150, 151, 154, 155, 158, 159, 160, 163, 164, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 209, 211, 217, 221, 224, 233, 240, 241, 246, 248, 253, 255, 258, 265, 271, 278, 279, 282, 383, 450, 560, 591, 620, 621, 622, 623, 625, 629, 630, 637, 638, 639], "onli": [0, 2, 6, 7, 17, 19, 20, 22, 23, 26, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 95, 97, 101, 102, 108, 109, 116, 120, 123, 124, 125, 126, 129, 130, 131, 132, 134, 137, 138, 145, 146, 150, 151, 152, 153, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 217, 221, 222, 224, 225, 226, 227, 229, 231, 232, 236, 239, 244, 246, 250, 251, 255, 262, 263, 264, 265, 266, 270, 271, 272, 275, 277, 279, 280, 282, 297, 304, 306, 313, 317, 326, 329, 332, 337, 340, 342, 344, 345, 346, 347, 349, 351, 352, 353, 357, 358, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 393, 401, 402, 404, 416, 418, 554, 567, 576, 580, 587, 613, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 632, 634, 635, 636, 637, 639, 641, 642], "option": [0, 3, 6, 10, 18, 22, 23, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 101, 102, 103, 104, 106, 107, 108, 109, 112, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 205, 206, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 228, 229, 231, 232, 233, 234, 236, 237, 239, 240, 241, 242, 243, 244, 245, 246, 250, 251, 253, 254, 257, 258, 259, 262, 263, 264, 265, 266, 268, 269, 270, 272, 273, 274, 275, 277, 278, 279, 280, 282, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 340, 341, 342, 344, 345, 346, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 395, 398, 400, 401, 402, 403, 404, 406, 408, 409, 410, 411, 412, 413, 416, 419, 420, 421, 473, 554, 560, 562, 563, 564, 566, 568, 569, 571, 572, 573, 574, 576, 579, 580, 581, 584, 586, 587, 590, 592, 623, 625, 628, 635, 636, 639, 641], "On": [0, 5, 19, 21, 26, 42, 44, 47, 50, 60, 80, 568, 576, 581, 592, 621, 635, 636], "end": [0, 6, 17, 32, 35, 36, 38, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 93, 102, 107, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 233, 239, 248, 263, 264, 270, 272, 288, 326, 332, 337, 341, 352, 371, 376, 378, 380, 383, 384, 434, 435, 493, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "come": [0, 1, 2, 4, 5, 6, 18, 20, 21, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 114, 120, 123, 126, 130, 137, 138, 141, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 229, 232, 283, 284, 285, 322, 340, 342, 349, 351, 365, 368, 370, 393, 567, 575, 620, 621, 622, 623, 627, 628, 629, 630, 635, 636, 639, 641, 642], "set": [0, 2, 3, 6, 7, 15, 17, 18, 21, 22, 26, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 98, 107, 110, 116, 120, 123, 126, 128, 130, 131, 137, 138, 142, 143, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 211, 213, 215, 217, 218, 221, 222, 225, 229, 232, 239, 240, 241, 242, 250, 255, 263, 264, 265, 266, 270, 271, 272, 275, 277, 279, 280, 282, 286, 302, 304, 306, 312, 317, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 339, 344, 345, 351, 352, 358, 363, 365, 366, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 390, 393, 405, 406, 410, 412, 421, 556, 564, 566, 568, 569, 571, 572, 573, 574, 576, 579, 581, 587, 591, 592, 618, 620, 621, 622, 623, 624, 626, 627, 628, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "re": [0, 21, 27, 33, 42, 43, 44, 45, 47, 48, 50, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 107, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 236, 304, 306, 326, 332, 337, 342, 345, 376, 378, 380, 383, 384, 401, 614, 620, 622, 623, 625, 627, 632, 634, 635, 637, 641, 642], "usabl": [0, 95, 614, 623, 641], "function": [0, 1, 7, 12, 17, 18, 19, 20, 21, 22, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 126, 127, 130, 131, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 211, 212, 213, 217, 218, 229, 232, 239, 241, 243, 269, 270, 272, 273, 279, 280, 282, 283, 284, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 304, 306, 307, 308, 309, 310, 311, 312, 314, 317, 321, 322, 325, 326, 327, 328, 330, 331, 332, 337, 338, 339, 341, 342, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 402, 404, 416, 420, 421, 472, 473, 560, 568, 579, 588, 594, 597, 605, 620, 623, 624, 625, 626, 629, 632, 634, 637, 639, 642], "cost": [0, 15, 59, 83, 96, 98, 349, 351, 365, 368, 370, 620, 621, 624, 635, 636, 637, 639], "return": [0, 1, 5, 6, 10, 16, 17, 18, 19, 20, 21, 22, 26, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 94, 95, 96, 102, 104, 106, 108, 109, 112, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 204, 205, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 288, 289, 290, 291, 292, 293, 295, 302, 303, 304, 305, 306, 307, 310, 311, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 335, 336, 337, 340, 341, 342, 344, 345, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 397, 402, 403, 404, 405, 416, 418, 419, 553, 555, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 585, 587, 588, 592, 606, 613, 620, 621, 622, 624, 626, 627, 629, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "process": [0, 1, 2, 3, 5, 6, 7, 12, 18, 21, 22, 23, 24, 27, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 65, 68, 72, 73, 78, 80, 84, 85, 86, 87, 88, 90, 95, 97, 101, 102, 104, 108, 116, 120, 123, 126, 127, 130, 134, 138, 141, 145, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 220, 221, 229, 232, 239, 265, 268, 270, 271, 279, 280, 298, 302, 304, 312, 314, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 351, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 566, 567, 568, 569, 571, 572, 573, 574, 576, 579, 580, 581, 587, 592, 613, 620, 621, 623, 624, 625, 632, 633, 635, 636, 637, 638, 639, 641, 642], "good": [0, 2, 23, 28, 101, 102, 150, 191, 592, 613, 620, 622, 623, 624, 626, 636, 641, 642], "runtim": [0, 22, 56, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 613, 637], "perform": [0, 5, 6, 7, 10, 18, 20, 22, 23, 27, 32, 33, 35, 36, 38, 42, 43, 44, 45, 47, 48, 54, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 95, 120, 123, 124, 125, 126, 129, 130, 131, 132, 137, 138, 150, 151, 154, 155, 158, 159, 160, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 239, 245, 267, 270, 272, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 317, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 338, 341, 348, 351, 352, 361, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 410, 416, 418, 565, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587, 590, 592, 620, 621, 622, 623, 624, 625, 628, 630, 633, 634, 635, 636, 637, 642], "To": [0, 7, 18, 19, 20, 21, 23, 25, 26, 27, 28, 41, 42, 44, 47, 65, 66, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 93, 102, 108, 109, 112, 119, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 141, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 227, 263, 265, 279, 283, 284, 285, 287, 302, 304, 312, 326, 332, 337, 345, 352, 358, 363, 366, 372, 376, 378, 380, 383, 384, 393, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 585, 586, 592, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 635, 636, 637, 638, 639, 641, 642], "read": [0, 6, 17, 26, 56, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 110, 112, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 233, 234, 235, 236, 237, 240, 241, 243, 248, 249, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 269, 270, 271, 274, 275, 276, 278, 279, 283, 284, 285, 287, 297, 310, 322, 323, 325, 327, 328, 330, 331, 340, 341, 342, 344, 345, 347, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 393, 410, 416, 568, 575, 581, 582, 583, 620, 621, 622, 624, 625, 626, 634, 635, 636, 637, 638, 641, 642], "philosophi": [0, 28], "capabl": [0, 3, 18, 20, 26, 28, 30, 39, 50, 56, 170, 184, 420, 582, 592, 620, 625, 628, 632, 634, 638, 642], "beyond": [0, 6, 7, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 613, 624], "api": [0, 6, 16, 18, 22, 24, 46, 56, 60, 71, 74, 86, 87, 123, 126, 152, 153, 155, 176, 180, 182, 190, 250, 277, 279, 280, 324, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 384, 385, 420, 421, 581, 583, 585, 587, 592, 594, 596, 624, 625, 626, 627, 628, 629, 633, 635, 636, 637, 639, 641, 642], "check": [0, 17, 22, 23, 24, 25, 26, 28, 32, 34, 35, 36, 38, 42, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 86, 87, 88, 92, 93, 100, 108, 120, 123, 126, 127, 129, 130, 131, 138, 144, 150, 151, 154, 158, 159, 160, 165, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 221, 222, 227, 235, 241, 251, 265, 268, 272, 282, 295, 297, 298, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 344, 345, 352, 363, 368, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 402, 404, 565, 566, 568, 571, 572, 574, 576, 579, 580, 581, 582, 587, 589, 613, 621, 622, 623, 624, 625, 626, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 639, 641, 642], "paper": [0, 80, 83, 121, 122, 124, 125, 132, 136, 137, 142, 143, 145, 146, 155, 163, 164, 250, 275, 277, 288, 356, 372, 376, 378, 380, 620, 622, 635, 636], "releas": [0, 6, 23, 26, 29, 54, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384, 569, 571, 572, 574, 579, 581, 587, 592, 613], "sync": [0, 1, 2, 5, 7, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 120, 191, 324, 419, 560, 565, 566, 568, 576, 620], "so": [0, 5, 21, 22, 23, 25, 26, 29, 30, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 265, 270, 279, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 346, 347, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 393, 568, 576, 592, 620, 622, 623, 627, 630, 635, 636, 637, 642], "make": [0, 1, 5, 6, 7, 16, 17, 18, 19, 21, 23, 26, 30, 60, 65, 66, 68, 69, 74, 78, 79, 82, 84, 85, 86, 87, 88, 106, 110, 112, 119, 120, 123, 126, 130, 131, 134, 135, 137, 138, 140, 146, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 227, 234, 242, 246, 250, 251, 255, 259, 263, 267, 271, 275, 287, 297, 302, 304, 324, 325, 326, 327, 328, 330, 331, 332, 337, 345, 349, 351, 365, 368, 370, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 402, 412, 556, 564, 599, 620, 621, 622, 623, 624, 625, 626, 627, 629, 630, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "sure": [0, 5, 19, 23, 26, 50, 82, 88, 110, 123, 130, 134, 173, 174, 175, 177, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 255, 271, 297, 383, 564, 620, 622, 623, 624, 627, 635, 636, 637, 639, 641, 642], "alwai": [0, 19, 21, 22, 35, 36, 38, 47, 52, 58, 74, 75, 78, 88, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 241, 245, 267, 279, 280, 326, 332, 337, 359, 366, 376, 378, 380, 383, 384, 466, 566, 568, 569, 571, 572, 574, 576, 579, 581, 582, 587, 613, 621, 622, 623, 624, 635, 636, 637, 639], "enjoi": [0, 22, 83, 628], "latest": [0, 21, 29, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 145, 148, 149, 152, 153, 190, 412, 622, 635, 636, 637, 641], "featur": [0, 5, 6, 18, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 54, 56, 63, 64, 74, 81, 86, 87, 102, 108, 109, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 197, 218, 221, 236, 239, 241, 248, 265, 266, 274, 279, 288, 299, 300, 302, 304, 305, 325, 326, 327, 328, 330, 331, 332, 337, 345, 349, 351, 365, 368, 370, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 402, 420, 421, 564, 590, 594, 620, 621, 622, 623, 624, 626, 627, 628, 630, 633, 637, 639, 641, 642], "recent": [0, 26, 189, 278, 280, 282, 642], "version": [0, 2, 5, 6, 7, 18, 25, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 48, 49, 52, 53, 54, 55, 76, 77, 80, 85, 86, 87, 88, 108, 120, 123, 126, 129, 130, 131, 132, 138, 145, 146, 150, 151, 152, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 221, 269, 278, 279, 280, 282, 285, 302, 304, 325, 326, 327, 328, 329, 330, 331, 332, 336, 337, 349, 351, 365, 366, 368, 370, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 389, 420, 421, 590, 591, 594, 620, 622, 623, 624, 625, 627, 630, 635, 636, 637, 638, 642], "although": [0, 2, 5, 21, 27, 50, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 338, 341, 348, 620, 621, 628, 639], "core": [0, 7, 10, 19, 27, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 170, 613, 614, 615, 623, 626, 641], "guarante": [0, 12, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 345, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 628], "backward": [0, 1, 3, 5, 7, 8, 9, 27, 35, 36, 38, 54, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 279, 280, 308, 309, 316, 325, 326, 327, 328, 330, 331, 332, 337, 345, 349, 350, 352, 353, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 419, 620, 622, 623, 624, 627, 628, 630, 635, 636, 637], "compat": [0, 1, 3, 5, 6, 7, 17, 18, 26, 34, 35, 36, 38, 50, 54, 56, 60, 69, 71, 79, 86, 87, 88, 96, 98, 106, 108, 109, 110, 114, 120, 123, 126, 130, 132, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 263, 272, 275, 279, 280, 282, 302, 304, 308, 309, 313, 316, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 352, 353, 354, 356, 357, 358, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 419, 573, 581, 583, 587, 592, 620, 623, 632, 639], "2": [0, 2, 4, 7, 8, 10, 18, 19, 21, 22, 27, 28, 29, 33, 34, 35, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 95, 97, 101, 102, 108, 109, 114, 116, 120, 121, 122, 123, 126, 127, 130, 136, 137, 138, 141, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 206, 213, 217, 218, 220, 222, 225, 226, 227, 229, 230, 231, 232, 241, 242, 246, 248, 250, 252, 255, 258, 262, 263, 264, 265, 270, 271, 272, 275, 277, 279, 280, 282, 287, 288, 289, 290, 291, 292, 293, 294, 297, 298, 300, 301, 302, 304, 305, 306, 307, 311, 312, 320, 322, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 337, 338, 341, 344, 348, 349, 350, 351, 352, 353, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 393, 402, 406, 464, 465, 468, 469, 470, 550, 566, 567, 568, 570, 571, 572, 573, 574, 576, 579, 581, 587, 592, 599, 613, 619, 620, 621, 622, 623, 624, 626, 627, 634, 635, 636, 637, 639, 640, 641, 642], "0": [0, 2, 6, 7, 9, 10, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 101, 102, 108, 109, 116, 120, 121, 122, 123, 126, 129, 130, 132, 133, 136, 137, 138, 144, 145, 146, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 203, 205, 214, 215, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 230, 231, 233, 234, 235, 237, 240, 241, 242, 243, 244, 245, 246, 249, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 275, 276, 277, 278, 279, 280, 282, 286, 287, 288, 290, 291, 292, 293, 294, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 310, 312, 314, 315, 316, 319, 320, 321, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 340, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 402, 406, 413, 419, 420, 426, 446, 450, 464, 468, 472, 473, 488, 504, 506, 514, 516, 520, 521, 523, 532, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 560, 564, 566, 567, 572, 573, 574, 575, 580, 583, 585, 586, 587, 592, 606, 613, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642], "nightli": [0, 25], "via": [0, 3, 6, 17, 18, 22, 23, 26, 27, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 79, 81, 82, 83, 84, 85, 87, 89, 95, 96, 130, 150, 158, 178, 180, 186, 190, 242, 250, 253, 277, 286, 326, 332, 337, 352, 355, 366, 376, 378, 380, 384, 420, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 579, 580, 581, 585, 587, 606, 620, 621, 622, 623, 626, 628, 639, 641, 642], "tensordict": [0, 1, 2, 6, 10, 16, 17, 18, 19, 20, 21, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 96, 97, 98, 100, 101, 102, 106, 108, 109, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 206, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 283, 284, 285, 286, 287, 296, 297, 298, 301, 302, 304, 307, 312, 313, 314, 317, 322, 325, 326, 327, 328, 329, 330, 331, 332, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 406, 410, 411, 412, 414, 416, 419, 438, 469, 565, 566, 568, 569, 571, 572, 573, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 587, 592, 599, 606, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636, 637, 638, 642], "git": [0, 25, 26, 29], "clone": [0, 23, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 95, 172, 184, 193, 194, 241, 252, 270, 271, 280, 283, 284, 285, 326, 332, 337, 344, 357, 364, 372, 620, 635, 637, 641], "willing": 0, "contribut": [0, 306, 420], "cd": [0, 26], "path": [0, 18, 25, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 93, 95, 111, 117, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 250, 277, 325, 326, 327, 328, 329, 330, 331, 332, 337, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 395, 401, 402, 416, 419, 420, 421, 473, 581, 582, 621, 624, 630, 635], "root": [0, 19, 21, 22, 60, 65, 66, 68, 69, 71, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 221, 244, 266, 267, 302, 303, 304, 320, 321, 386, 623, 625, 635, 636, 637, 639, 642], "http": [0, 24, 25, 26, 29, 35, 38, 42, 44, 47, 65, 78, 80, 81, 82, 83, 84, 85, 101, 102, 121, 122, 124, 125, 132, 134, 136, 137, 142, 143, 145, 146, 147, 148, 149, 152, 153, 155, 161, 162, 163, 164, 177, 186, 190, 221, 250, 275, 289, 290, 291, 292, 293, 294, 298, 299, 300, 306, 308, 309, 312, 315, 316, 317, 349, 350, 352, 354, 355, 356, 357, 359, 360, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 386, 589, 631, 632, 638, 641], "github": [0, 24, 25, 26, 29, 42, 44, 47, 78, 80, 81, 83, 121, 122, 124, 125, 129, 132, 136, 137, 142, 143, 145, 146, 148, 149, 152, 153, 155, 161, 162, 163, 164, 218, 221, 275, 626, 630, 632, 635, 636, 641], "com": [0, 24, 25, 26, 29, 42, 44, 47, 80, 83, 84, 121, 122, 124, 125, 132, 134, 136, 137, 142, 143, 145, 146, 148, 149, 152, 153, 155, 161, 162, 163, 164, 221, 632, 641], "setup": [0, 1, 6, 26, 42, 47, 50, 121, 122, 134, 136, 137, 161, 195, 196, 384, 420, 581, 586, 587], "py": [0, 6, 7, 18, 22, 129, 131, 211, 221, 295, 613, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642], "develop": [0, 6, 22, 23, 26, 134, 332, 337, 592, 620, 633, 641], "If": [0, 2, 3, 4, 5, 6, 9, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 102, 104, 106, 107, 108, 109, 114, 116, 120, 123, 124, 125, 126, 127, 129, 130, 131, 132, 134, 137, 138, 142, 143, 144, 145, 146, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 209, 212, 213, 214, 217, 218, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 236, 239, 241, 242, 243, 244, 245, 246, 250, 251, 254, 255, 258, 259, 264, 265, 266, 267, 268, 269, 270, 272, 273, 275, 277, 279, 280, 282, 287, 288, 297, 298, 301, 302, 304, 305, 306, 308, 309, 312, 313, 314, 315, 316, 317, 322, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 340, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 358, 359, 360, 361, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 397, 401, 402, 403, 404, 405, 409, 411, 412, 416, 419, 420, 421, 473, 554, 560, 564, 565, 566, 568, 570, 571, 572, 573, 574, 575, 576, 579, 581, 582, 584, 586, 587, 591, 620, 621, 622, 623, 624, 625, 627, 629, 630, 632, 634, 635, 636, 637, 639, 641, 642], "us": [0, 1, 2, 3, 4, 7, 8, 9, 12, 15, 16, 17, 18, 19, 20, 22, 24, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 98, 100, 101, 102, 103, 108, 109, 114, 116, 120, 121, 122, 123, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 208, 210, 211, 212, 213, 214, 215, 217, 218, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 244, 246, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 282, 286, 287, 288, 289, 290, 291, 294, 296, 297, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 342, 344, 345, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 396, 397, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 461, 471, 473, 554, 555, 556, 558, 560, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 579, 580, 581, 582, 583, 584, 585, 586, 587, 591, 592, 593, 606, 613, 614, 618, 619, 620, 621, 622, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 640, 642], "uv": 0, "specif": [0, 1, 2, 7, 16, 18, 22, 24, 27, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 72, 73, 74, 75, 76, 77, 120, 123, 126, 130, 138, 148, 149, 150, 151, 154, 158, 159, 160, 163, 170, 171, 172, 175, 178, 179, 180, 185, 190, 209, 244, 265, 280, 294, 302, 304, 324, 326, 332, 333, 334, 337, 349, 351, 366, 368, 370, 376, 378, 380, 384, 393, 402, 403, 404, 416, 420, 565, 566, 568, 569, 570, 571, 572, 573, 574, 579, 581, 587, 590, 599, 613, 614, 619, 622, 623, 625, 626, 627, 628, 629, 630, 631, 632, 635, 636, 639, 640, 641], "build": [0, 3, 7, 21, 26, 56, 60, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 121, 122, 123, 126, 130, 131, 132, 136, 137, 138, 142, 143, 145, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 255, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 416, 557, 558, 559, 594, 599, 605, 619, 622, 623, 624, 626, 627, 628, 629, 631, 635, 636, 637, 638, 640, 641, 642], "beforehand": 0, "wheel": [0, 622], "dep": 0, "edit": [0, 21, 183, 271, 628], "prevent": [0, 23, 57, 59, 60, 61, 62, 64, 66, 71, 93, 101, 102, 121, 122, 279, 280, 303, 320, 321, 324, 332, 337, 349, 351, 365, 368, 370, 380, 413, 592, 629, 639], "resolut": [0, 326, 332, 337, 348, 566, 569, 571, 572, 574, 579, 581, 587], "potenti": [0, 2, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 637, 639], "downgrad": 0, "A": [0, 2, 6, 21, 22, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 107, 108, 110, 114, 115, 116, 117, 118, 120, 123, 126, 128, 130, 132, 133, 135, 138, 150, 151, 154, 155, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 203, 204, 205, 207, 212, 214, 216, 217, 218, 220, 221, 224, 225, 226, 227, 231, 237, 241, 243, 244, 250, 251, 253, 260, 265, 267, 270, 271, 272, 275, 276, 278, 279, 280, 281, 282, 286, 287, 288, 297, 298, 301, 302, 304, 305, 306, 307, 313, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 338, 341, 342, 343, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 394, 395, 398, 401, 403, 404, 405, 408, 415, 416, 419, 421, 460, 461, 462, 463, 464, 465, 466, 468, 469, 470, 471, 472, 560, 568, 576, 579, 581, 587, 588, 613, 619, 620, 622, 624, 626, 627, 628, 631, 632, 637, 640, 642], "seri": [0, 12, 17, 26, 27, 64, 94, 104, 114, 115, 118, 119, 158, 245, 271, 393, 620, 621, 622, 629, 630, 635, 636, 639, 642], "quick": [0, 78, 590, 624], "ramp": 0, "up": [0, 1, 2, 5, 6, 7, 8, 21, 22, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 85, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 201, 217, 220, 239, 242, 266, 271, 324, 329, 368, 383, 403, 421, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587, 591, 613, 620, 621, 622, 623, 626, 630, 632, 633, 635, 636, 637, 639, 641, 642], "hurri": [0, 625], "last": [0, 2, 17, 18, 23, 32, 34, 35, 36, 38, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 107, 108, 109, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 183, 195, 206, 214, 217, 220, 225, 226, 236, 244, 246, 251, 264, 266, 268, 278, 282, 286, 288, 301, 302, 304, 305, 306, 308, 320, 326, 332, 337, 338, 341, 345, 352, 386, 388, 389, 592, 621, 622, 623, 624, 625, 626, 632, 635, 636, 637, 638, 639, 641, 642], "item": [0, 21, 27, 34, 38, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 96, 102, 107, 114, 214, 235, 271, 280, 306, 353, 354, 356, 384, 406, 606, 620, 622, 623, 627, 628, 632, 635, 636, 637, 639], "navig": [0, 184, 632, 636], "previou": [0, 22, 23, 29, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 236, 265, 316, 317, 622, 623, 624, 625, 626, 630, 637, 642], "whenev": [0, 2, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 83, 88, 101, 102, 108, 109, 124, 125, 129, 131, 132, 142, 143, 155, 163, 164, 171, 172, 173, 174, 175, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 236, 240, 271, 272, 278, 326, 332, 337, 366, 376, 378, 380, 383, 384, 386, 387, 388, 389, 391, 419, 629, 632, 639], "want": [0, 5, 6, 21, 22, 25, 26, 27, 34, 50, 52, 109, 171, 172, 175, 185, 221, 246, 326, 332, 337, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 613, 620, 621, 622, 623, 624, 625, 627, 628, 629, 635, 636, 637, 638, 639, 641, 642], "ted": [0, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 100, 619, 631, 640], "s": [0, 1, 2, 3, 5, 6, 7, 17, 18, 19, 21, 22, 25, 26, 27, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 60, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 108, 109, 114, 120, 121, 122, 123, 126, 130, 134, 136, 137, 138, 142, 143, 145, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 225, 226, 239, 244, 250, 263, 265, 268, 269, 270, 271, 272, 275, 277, 279, 280, 283, 285, 286, 288, 295, 298, 301, 302, 304, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 342, 344, 345, 348, 350, 351, 352, 357, 363, 364, 365, 366, 368, 371, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 402, 418, 419, 420, 565, 566, 567, 568, 569, 571, 572, 573, 574, 576, 579, 580, 581, 582, 583, 587, 592, 613, 619, 620, 621, 622, 623, 624, 625, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642], "modul": [0, 6, 7, 17, 18, 21, 22, 23, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 65, 68, 69, 72, 73, 86, 87, 88, 114, 120, 121, 122, 123, 126, 130, 138, 144, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 214, 220, 221, 225, 231, 233, 239, 241, 243, 250, 251, 255, 264, 265, 270, 271, 272, 275, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 415, 416, 418, 420, 421, 473, 557, 560, 566, 568, 569, 571, 572, 573, 574, 578, 579, 581, 587, 590, 592, 603, 604, 605, 606, 607, 608, 609, 611, 612, 619, 621, 622, 625, 627, 628, 629, 631, 633, 634, 635, 636, 637, 638, 639, 640], "optim": [0, 1, 2, 15, 27, 55, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 350, 352, 366, 367, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 410, 411, 416, 418, 420, 421, 473, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 560, 590, 613, 614, 619, 622, 623, 624, 625, 626, 628, 631, 633, 635, 636, 637, 640], "collect": [0, 1, 2, 3, 4, 5, 6, 12, 20, 22, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 60, 61, 65, 66, 67, 68, 69, 71, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 107, 120, 123, 126, 130, 138, 150, 151, 154, 155, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 218, 219, 220, 221, 222, 223, 225, 228, 229, 232, 236, 238, 242, 246, 247, 250, 252, 254, 255, 256, 257, 258, 262, 264, 265, 266, 268, 271, 272, 273, 277, 279, 280, 282, 288, 295, 303, 305, 306, 310, 312, 320, 325, 326, 327, 328, 330, 331, 332, 337, 341, 350, 353, 356, 358, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 406, 409, 411, 412, 416, 418, 419, 420, 421, 473, 553, 554, 560, 562, 563, 565, 568, 573, 577, 580, 585, 586, 587, 590, 592, 599, 606, 614, 619, 620, 623, 624, 625, 626, 627, 630, 631, 635, 636, 637, 638, 639, 640, 641, 642], "storag": [0, 2, 4, 10, 13, 27, 32, 34, 35, 36, 38, 50, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 107, 108, 109, 111, 112, 113, 114, 116, 117, 120, 123, 126, 128, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 220, 221, 229, 232, 255, 325, 326, 327, 328, 330, 331, 332, 337, 351, 365, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 403, 421, 425, 426, 427, 428, 431, 432, 436, 437, 438, 439, 581, 582, 583, 584, 590, 619, 621, 622, 623, 624, 625, 627, 630, 631, 635, 636, 638, 640], "log": [0, 20, 23, 27, 30, 188, 189, 195, 196, 295, 296, 297, 298, 306, 310, 320, 321, 324, 326, 329, 332, 333, 337, 342, 345, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 401, 408, 409, 410, 416, 418, 420, 421, 473, 560, 567, 580, 582, 590, 619, 620, 621, 622, 625, 626, 630, 631, 635, 636, 637, 640, 641], "your": [0, 1, 5, 7, 16, 22, 26, 27, 29, 30, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 52, 88, 120, 123, 126, 130, 134, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 345, 351, 368, 376, 378, 380, 383, 384, 405, 564, 591, 592, 613, 619, 621, 622, 623, 625, 626, 627, 628, 629, 631, 633, 635, 636, 639, 640, 641], "own": [0, 2, 5, 7, 16, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 55, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 393, 566, 571, 574, 575, 613, 619, 621, 622, 625, 631, 635, 636, 637, 640], "train": [0, 1, 2, 5, 6, 9, 18, 20, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 59, 78, 80, 86, 87, 88, 101, 102, 120, 123, 126, 130, 135, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 229, 237, 250, 264, 269, 272, 275, 277, 286, 290, 292, 301, 312, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 403, 409, 416, 418, 419, 420, 421, 473, 560, 572, 584, 590, 592, 596, 597, 603, 613, 614, 619, 621, 625, 628, 629, 631, 638, 639, 640, 641, 642], "loop": [0, 1, 5, 6, 7, 27, 34, 42, 47, 50, 52, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 286, 301, 312, 317, 325, 327, 328, 330, 331, 350, 352, 358, 364, 368, 369, 371, 372, 373, 377, 379, 381, 382, 385, 386, 387, 388, 389, 412, 416, 565, 566, 567, 568, 571, 572, 574, 576, 579, 581, 584, 587, 614, 616, 619, 620, 621, 625, 627, 628, 629, 631, 634, 639, 640, 641], "ppo": [0, 1, 5, 7, 23, 27, 35, 36, 38, 342, 345, 351, 365, 368, 376, 420, 472, 473, 614, 619, 620, 621, 624, 626, 627, 631, 635, 640], "pendulum": [0, 1, 7, 16, 18, 21, 22, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 88, 114, 120, 123, 124, 125, 126, 127, 129, 130, 131, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 221, 224, 225, 227, 234, 240, 241, 246, 253, 255, 259, 260, 263, 265, 266, 267, 270, 271, 272, 273, 279, 280, 287, 302, 304, 339, 383, 560, 599, 619, 621, 622, 625, 626, 627, 631, 640, 641, 642], "introduct": [0, 619, 625, 631, 635, 636, 640, 642], "multi": [0, 1, 4, 5, 16, 17, 26, 28, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 68, 70, 71, 72, 73, 88, 92, 93, 100, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 242, 272, 302, 304, 305, 324, 326, 332, 337, 341, 345, 376, 378, 380, 383, 384, 386, 387, 388, 389, 465, 590, 592, 594, 613, 619, 620, 621, 622, 623, 625, 626, 631, 637, 640, 641], "agent": [0, 16, 21, 22, 28, 67, 70, 71, 135, 141, 142, 143, 148, 149, 152, 153, 156, 157, 161, 162, 163, 164, 166, 184, 242, 262, 263, 264, 306, 351, 365, 368, 420, 590, 619, 625, 631, 637, 640], "env": [0, 1, 2, 4, 5, 6, 7, 18, 19, 20, 21, 22, 24, 25, 26, 27, 30, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 53, 60, 65, 66, 69, 72, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 114, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 287, 302, 304, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 344, 366, 376, 378, 380, 383, 384, 391, 392, 393, 405, 421, 443, 444, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 531, 532, 533, 534, 535, 536, 537, 538, 554, 555, 556, 560, 562, 563, 564, 572, 590, 592, 599, 613, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 636, 638, 639, 640], "pretrain": [0, 324, 619, 631, 640], "recurr": [0, 220, 302, 304, 316, 386, 619, 621, 626, 631, 639, 640], "dqn": [0, 1, 5, 7, 78, 214, 233, 288, 297, 298, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 557, 619, 624, 626, 627, 630, 631, 640], "polici": [0, 1, 3, 4, 5, 6, 7, 10, 12, 17, 21, 22, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 66, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 226, 231, 241, 244, 264, 267, 271, 283, 284, 285, 286, 287, 297, 298, 301, 302, 304, 312, 313, 314, 326, 329, 332, 337, 339, 340, 341, 342, 343, 344, 345, 348, 349, 350, 351, 352, 353, 357, 358, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 410, 418, 419, 420, 421, 473, 486, 555, 556, 560, 562, 563, 566, 567, 568, 569, 571, 572, 574, 579, 581, 587, 590, 599, 600, 606, 619, 621, 625, 627, 628, 631, 633, 638, 639, 640, 641, 642], "replai": [0, 1, 5, 10, 13, 15, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 101, 102, 103, 104, 105, 107, 109, 110, 112, 114, 115, 119, 220, 221, 231, 251, 255, 265, 271, 352, 353, 354, 356, 357, 358, 364, 369, 371, 372, 373, 383, 403, 412, 416, 418, 420, 421, 428, 429, 430, 431, 434, 438, 439, 473, 558, 560, 590, 592, 613, 614, 619, 624, 631, 637, 638, 640], "buffer": [0, 1, 3, 5, 6, 10, 13, 15, 18, 22, 23, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 114, 115, 116, 119, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 220, 221, 225, 230, 231, 239, 250, 251, 255, 265, 270, 271, 272, 275, 277, 286, 312, 325, 326, 327, 328, 330, 331, 332, 337, 344, 347, 351, 352, 353, 354, 356, 357, 358, 364, 365, 368, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 402, 403, 412, 416, 418, 420, 421, 428, 429, 430, 431, 434, 438, 439, 473, 558, 560, 565, 567, 568, 570, 573, 575, 576, 577, 581, 582, 583, 584, 590, 592, 613, 614, 619, 624, 629, 631, 637, 638, 640, 642], "export": [0, 25, 26, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 619, 631, 640], "llm": [0, 6, 52, 53, 54, 55, 86, 87, 88, 89, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 501, 580, 581, 582, 583, 584, 585, 586, 587, 588, 590, 594, 613, 619, 631, 640], "tool": [0, 3, 18, 20, 24, 87, 170, 184, 186, 187, 190, 193, 197, 200, 201, 202, 203, 592, 594, 595, 598, 619, 623, 625, 631, 635, 637, 639, 640, 642], "enabl": [0, 7, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 79, 89, 95, 97, 107, 116, 150, 158, 170, 184, 218, 302, 304, 312, 324, 326, 329, 332, 333, 334, 337, 339, 341, 380, 391, 393, 410, 418, 420, 421, 572, 592, 603, 613, 619, 622, 625, 631, 635, 636, 637, 639, 640], "competit": [0, 22, 142, 143, 619, 631, 636, 640], "ddpg": [0, 290, 291, 292, 293, 353, 421, 619, 621, 627, 631, 636, 640], "task": [0, 7, 19, 22, 28, 70, 71, 80, 83, 120, 123, 124, 125, 126, 130, 133, 138, 142, 143, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 175, 177, 178, 179, 180, 182, 250, 263, 272, 275, 277, 357, 364, 421, 590, 619, 620, 621, 622, 623, 625, 626, 631, 632, 635, 636, 637, 640, 642], "object": [0, 6, 17, 21, 23, 25, 26, 32, 34, 35, 36, 38, 39, 42, 44, 47, 50, 52, 53, 60, 63, 69, 74, 86, 87, 88, 89, 90, 95, 96, 97, 98, 106, 110, 112, 116, 119, 120, 123, 126, 130, 136, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 229, 232, 233, 239, 242, 246, 250, 270, 271, 272, 275, 279, 280, 283, 302, 304, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 343, 344, 345, 346, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 393, 421, 554, 555, 556, 557, 559, 560, 564, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587, 590, 619, 621, 622, 623, 624, 628, 630, 631, 633, 635, 636, 637, 639, 640, 642], "loss": [0, 6, 7, 19, 21, 27, 233, 306, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 376, 378, 380, 384, 386, 411, 415, 416, 420, 421, 471, 472, 473, 557, 560, 590, 592, 597, 606, 607, 608, 609, 611, 612, 614, 619, 624, 625, 627, 628, 629, 631, 637, 639, 640], "trainer": [0, 6, 7, 324, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 417, 418, 419, 420, 421, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 572, 580, 581, 585, 586, 587, 590, 619, 620, 631, 640], "exampl": [0, 2, 3, 5, 18, 19, 21, 23, 28, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 101, 102, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 203, 206, 207, 211, 212, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 246, 248, 249, 250, 251, 252, 253, 254, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 320, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 393, 402, 404, 405, 406, 407, 408, 409, 411, 412, 413, 414, 415, 419, 420, 421, 464, 465, 468, 469, 470, 473, 560, 568, 572, 576, 581, 583, 584, 587, 590, 619, 620, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 636, 637, 638, 640, 641, 642], "packag": [0, 18, 25, 26, 29, 190, 211, 590, 591, 632, 642], "multicollector": [0, 2, 6, 35, 38, 590], "kei": [0, 2, 6, 7, 17, 18, 19, 22, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 86, 87, 88, 92, 101, 102, 106, 108, 109, 114, 120, 123, 126, 130, 136, 137, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 243, 246, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 286, 287, 296, 297, 298, 301, 302, 304, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 340, 341, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 409, 410, 411, 413, 414, 416, 419, 420, 554, 582, 583, 588, 590, 620, 622, 623, 624, 625, 627, 632, 633, 634, 635, 636, 637, 639, 641, 642], "legaci": [0, 5, 26, 35, 36, 38, 56, 86, 87, 176, 188, 189, 195, 196, 325, 326, 327, 328, 330, 331, 332, 337, 377, 379, 381, 382, 385, 419, 572, 574, 590], "name": [0, 5, 6, 7, 17, 18, 21, 25, 26, 32, 34, 35, 36, 38, 54, 55, 60, 71, 78, 80, 82, 85, 86, 87, 88, 89, 120, 121, 123, 124, 126, 130, 136, 138, 142, 143, 145, 148, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 209, 213, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 231, 233, 234, 235, 237, 239, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 282, 297, 302, 304, 313, 318, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 389, 390, 391, 395, 397, 398, 399, 400, 401, 402, 403, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 417, 418, 419, 572, 573, 574, 580, 585, 586, 588, 590, 606, 613, 620, 621, 622, 623, 624, 627, 628, 629, 632, 635, 636, 637, 638, 642], "interfac": [0, 1, 16, 22, 55, 120, 133, 147, 305, 324, 326, 329, 332, 337, 403, 424, 573, 577, 583, 587, 590, 596, 620, 622, 624, 629, 632, 633, 637, 639], "servic": [0, 50, 186, 189, 192, 193, 195, 201, 202, 243, 324, 333, 402, 403, 404, 590, 592], "registri": [0, 129, 161, 186, 193, 201, 402, 403, 404, 590, 592], "overview": [0, 590, 622, 624, 627, 635, 636, 641], "usag": [0, 1, 12, 18, 24, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 79, 85, 91, 93, 114, 171, 189, 191, 192, 218, 221, 233, 302, 304, 324, 326, 332, 337, 351, 352, 357, 364, 365, 368, 371, 374, 376, 378, 380, 384, 402, 404, 419, 420, 568, 576, 590, 592, 620, 622, 623, 626, 627, 629, 635, 636, 639], "executor": [0, 22, 42, 44, 47, 159, 193, 590], "best": [0, 5, 24, 28, 134, 302, 304, 324, 368, 590, 635, 636, 639, 641], "practic": [0, 3, 4, 18, 21, 22, 23, 24, 27, 52, 63, 78, 271, 303, 320, 321, 590, 591, 620, 621, 622, 623, 624, 627, 632, 635, 636, 638, 642], "also": [0, 2, 5, 6, 7, 12, 17, 18, 19, 21, 22, 27, 28, 30, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 57, 59, 61, 62, 64, 68, 69, 72, 73, 74, 78, 80, 81, 83, 84, 85, 86, 87, 88, 95, 96, 97, 102, 108, 109, 114, 116, 120, 123, 126, 130, 137, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 211, 212, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 231, 233, 234, 235, 237, 239, 240, 241, 243, 246, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 282, 288, 305, 316, 325, 326, 327, 328, 330, 331, 332, 337, 341, 342, 346, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 363, 364, 368, 371, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 391, 393, 409, 590, 592, 620, 621, 622, 623, 624, 625, 626, 627, 628, 632, 634, 635, 636, 637, 639, 641, 642], "_util": [0, 18, 150, 590, 624, 630], "implement_for": [0, 18, 590], "set_auto_unwrap_transformed_env": [0, 31, 272, 590], "auto_unwrap_transformed_env": [0, 405, 590], "configur": [0, 2, 4, 27, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 55, 123, 171, 190, 241, 289, 294, 311, 324, 326, 333, 351, 366, 368, 376, 378, 380, 384, 402, 403, 420, 421, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 568, 571, 572, 574, 579, 590, 599, 614, 620, 621, 622, 627, 633, 635, 636, 637], "system": [0, 10, 16, 23, 24, 87, 93, 170, 171, 172, 175, 177, 191, 193, 195, 196, 339, 380, 384, 424, 590, 592, 613, 614, 622, 633, 635, 636, 637], "simpl": [0, 19, 21, 28, 40, 41, 64, 74, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 290, 324, 326, 332, 337, 341, 345, 354, 356, 366, 368, 370, 376, 378, 380, 383, 384, 386, 409, 590, 592, 613, 620, 621, 622, 625, 626, 627, 633, 635, 636, 639, 642], "categori": [0, 60, 80, 590], "group": [0, 6, 18, 19, 22, 54, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 86, 87, 88, 120, 123, 126, 130, 138, 141, 142, 143, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 166, 170, 171, 172, 175, 176, 178, 179, 180, 185, 242, 262, 324, 325, 327, 328, 330, 331, 332, 333, 335, 336, 377, 379, 381, 382, 385, 573, 574, 580, 581, 585, 586, 590, 592, 621, 626, 628, 636, 639], "complex": [0, 6, 12, 22, 37, 39, 40, 41, 46, 49, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384, 402, 587, 590, 592, 613, 620, 621, 625, 626], "parallel": [0, 1, 2, 3, 4, 5, 16, 18, 19, 21, 27, 35, 36, 38, 54, 55, 120, 123, 126, 129, 130, 131, 138, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 272, 278, 302, 304, 324, 333, 334, 349, 440, 561, 562, 563, 564, 587, 590, 613, 621, 622, 635, 636, 641], "avail": [0, 2, 3, 5, 16, 20, 23, 25, 32, 35, 36, 38, 50, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 102, 107, 108, 109, 121, 122, 124, 125, 134, 136, 137, 142, 143, 148, 149, 150, 152, 153, 155, 161, 162, 163, 164, 182, 186, 192, 194, 195, 201, 214, 217, 220, 239, 241, 333, 342, 345, 366, 376, 378, 380, 384, 393, 562, 563, 566, 567, 568, 569, 571, 572, 574, 575, 576, 577, 579, 581, 587, 590, 592, 613, 620, 621, 622, 623, 624, 625, 626, 633, 635, 636, 637, 639, 642], "complet": [0, 1, 5, 6, 26, 28, 35, 36, 38, 46, 52, 53, 102, 107, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 184, 221, 263, 324, 383, 420, 570, 573, 580, 587, 590, 591, 592, 613, 620, 622, 625, 632, 633, 634], "run": [0, 1, 2, 6, 16, 18, 19, 22, 23, 24, 25, 26, 27, 29, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 66, 78, 80, 88, 102, 108, 109, 120, 121, 122, 123, 124, 125, 126, 129, 130, 136, 137, 138, 144, 145, 146, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 225, 239, 245, 246, 262, 270, 271, 272, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 317, 324, 326, 332, 337, 338, 341, 345, 346, 347, 348, 352, 358, 371, 376, 378, 380, 383, 384, 393, 401, 410, 421, 562, 563, 564, 572, 590, 591, 613, 614, 620, 621, 622, 623, 626, 627, 628, 629, 630, 632, 635, 636, 637, 641], "experi": [0, 1, 16, 17, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 395, 396, 397, 398, 399, 400, 401, 402, 421, 590, 591, 617, 621, 622, 624, 628, 629, 635, 636, 639], "store": [0, 2, 6, 12, 17, 27, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 60, 63, 65, 66, 68, 69, 72, 73, 80, 81, 83, 84, 86, 87, 88, 90, 93, 95, 96, 97, 98, 101, 102, 108, 114, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 267, 278, 279, 280, 286, 312, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 401, 420, 421, 473, 565, 566, 568, 572, 573, 574, 576, 590, 620, 622, 623, 626, 628, 630, 635, 636, 638, 642], "implement": [0, 1, 6, 9, 10, 12, 17, 21, 22, 28, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 70, 71, 74, 75, 76, 77, 88, 99, 101, 110, 111, 120, 123, 126, 130, 138, 144, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 237, 241, 244, 252, 253, 259, 263, 269, 271, 272, 273, 279, 280, 282, 302, 303, 304, 319, 320, 321, 324, 326, 332, 334, 337, 349, 350, 352, 355, 356, 357, 363, 364, 366, 367, 368, 370, 371, 372, 376, 378, 380, 383, 384, 391, 406, 420, 421, 555, 585, 586, 587, 590, 592, 613, 614, 620, 621, 622, 623, 624, 635, 636, 637, 641], "detail": [0, 6, 21, 24, 25, 26, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 268, 272, 298, 307, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 351, 359, 365, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 566, 590, 591, 592, 621, 624, 628, 634, 639], "class": [0, 1, 2, 4, 5, 6, 10, 14, 16, 18, 19, 20, 21, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 126, 127, 128, 129, 130, 131, 132, 137, 138, 141, 144, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 211, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 393, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 590, 592, 593, 599, 608, 613, 615, 617, 620, 621, 622, 623, 625, 626, 627, 628, 629, 632, 635, 636, 639, 642], "creat": [0, 1, 4, 6, 10, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 29, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 98, 114, 120, 123, 126, 127, 130, 134, 138, 150, 151, 152, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 218, 221, 226, 239, 243, 250, 270, 271, 272, 275, 278, 279, 280, 288, 290, 291, 292, 293, 294, 295, 299, 300, 302, 303, 304, 305, 308, 309, 315, 316, 317, 320, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 344, 345, 352, 354, 359, 368, 369, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 402, 403, 404, 412, 420, 421, 473, 554, 555, 556, 560, 562, 563, 565, 566, 568, 569, 570, 571, 572, 573, 574, 575, 576, 579, 581, 587, 590, 592, 599, 606, 613, 614, 620, 621, 622, 623, 624, 626, 629, 632, 633, 635, 636, 637, 638, 639, 641, 642], "custom": [0, 6, 10, 16, 21, 22, 24, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 81, 86, 87, 88, 89, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 275, 303, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 359, 368, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 404, 420, 473, 564, 569, 571, 572, 574, 579, 581, 585, 586, 587, 590, 602, 614, 616, 620, 621, 622, 623, 626, 627, 629, 632, 635, 636], "futur": [0, 23, 34, 41, 54, 56, 86, 87, 88, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 250, 270, 272, 277, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 420, 421, 573, 590, 591, 592, 613], "extens": [0, 65, 68, 72, 73, 109, 590, 639], "thing": [0, 5, 19, 21, 22, 26, 27, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 271, 325, 327, 328, 330, 331, 358, 371, 377, 379, 381, 382, 385, 591, 622, 623, 624, 625, 626, 627, 628, 629, 635, 636, 639, 642], "consid": [0, 2, 18, 21, 27, 34, 35, 36, 37, 38, 39, 42, 46, 47, 49, 50, 52, 54, 60, 65, 68, 71, 72, 73, 88, 95, 97, 108, 109, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 231, 279, 295, 306, 319, 326, 332, 337, 350, 352, 364, 369, 371, 372, 373, 376, 378, 380, 383, 384, 386, 388, 389, 591, 592, 613, 620, 625, 626, 627, 637, 639], "when": [0, 1, 2, 3, 6, 7, 8, 17, 18, 20, 21, 22, 24, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 96, 97, 98, 100, 101, 102, 103, 107, 108, 109, 110, 112, 116, 120, 121, 122, 123, 126, 127, 129, 130, 131, 137, 138, 141, 142, 143, 145, 147, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 212, 215, 217, 220, 221, 225, 226, 229, 231, 232, 241, 242, 245, 246, 250, 251, 258, 265, 267, 270, 271, 272, 275, 277, 278, 279, 280, 282, 295, 302, 304, 305, 306, 317, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 342, 344, 345, 347, 350, 351, 352, 354, 358, 359, 364, 365, 366, 368, 369, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 393, 395, 398, 400, 401, 402, 412, 418, 419, 564, 565, 566, 568, 571, 572, 574, 575, 576, 579, 580, 581, 587, 591, 592, 613, 620, 621, 622, 623, 624, 626, 628, 629, 635, 636, 637, 638, 639, 641, 642], "debug": [0, 6, 25, 27, 78, 79, 80, 81, 82, 83, 84, 85, 191, 267, 326, 332, 337, 567, 591, 642], "work": [0, 4, 6, 18, 20, 21, 22, 23, 27, 46, 49, 54, 55, 60, 68, 71, 78, 79, 80, 81, 82, 83, 84, 85, 88, 95, 101, 102, 106, 108, 109, 112, 119, 120, 123, 126, 129, 130, 131, 134, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 212, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 280, 282, 288, 298, 305, 314, 324, 326, 332, 337, 348, 351, 365, 368, 376, 378, 380, 383, 384, 402, 403, 416, 573, 587, 590, 591, 592, 599, 620, 621, 622, 623, 625, 628, 633, 634, 635, 636, 637, 638, 639, 641, 642], "habitat": [0, 18, 132, 447, 591, 638], "lab": [0, 17, 124, 125, 132, 135, 591], "mujoco": [0, 25, 27, 155, 591, 620, 622, 623], "error": [0, 2, 22, 26, 29, 32, 34, 35, 36, 38, 52, 57, 59, 61, 62, 64, 70, 86, 87, 88, 95, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 165, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 251, 270, 282, 324, 325, 326, 327, 328, 330, 331, 332, 337, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 591, 592, 613, 620, 622, 635, 636, 642], "solut": [0, 12, 18, 25, 26, 28, 50, 108, 591, 624, 641], "resourc": [0, 3, 33, 42, 43, 44, 45, 47, 48, 50, 132, 171, 172, 175, 184, 185, 192, 194, 195, 324, 329, 337, 402, 403, 569, 571, 572, 574, 579, 581, 587, 591, 592, 613, 620, 622, 624, 635, 636], "issu": [0, 6, 20, 22, 23, 24, 27, 66, 78, 81, 93, 95, 97, 101, 102, 108, 116, 120, 123, 126, 129, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 194, 195, 212, 221, 251, 266, 297, 298, 313, 314, 324, 340, 342, 344, 345, 351, 368, 420, 591, 592, 633, 641], "customis": [0, 591, 621, 629], "video": [0, 16, 23, 28, 86, 393, 395, 398, 400, 401, 410, 564, 591, 630, 635, 636], "render": [0, 20, 27, 137, 163, 391, 393, 410, 591, 620, 621, 622, 624, 625, 629], "index": [0, 21, 26, 27, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 94, 95, 96, 97, 101, 102, 104, 106, 108, 112, 114, 115, 116, 118, 119, 120, 123, 126, 130, 138, 142, 143, 148, 149, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 195, 212, 216, 221, 225, 231, 272, 306, 324, 325, 327, 328, 330, 331, 341, 377, 379, 381, 382, 385, 566, 567, 568, 569, 571, 572, 573, 574, 575, 576, 577, 579, 581, 587, 625, 632, 634, 635, 636, 639, 641], "search": [0, 60, 71, 147, 186, 187, 203, 213, 326, 332, 337, 621], "page": [0, 26, 184, 401, 627, 632], "bridg": [1, 421], "between": [1, 2, 6, 19, 21, 23, 24, 32, 34, 35, 36, 38, 39, 46, 50, 52, 53, 54, 65, 66, 68, 69, 72, 73, 83, 86, 87, 88, 90, 97, 101, 102, 104, 107, 108, 109, 116, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 231, 245, 256, 267, 270, 272, 279, 280, 288, 296, 298, 302, 304, 305, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 342, 345, 349, 351, 352, 353, 356, 357, 358, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 410, 416, 421, 568, 572, 588, 594, 613, 620, 621, 623, 624, 628, 632, 633, 635, 636, 637, 639, 642], "manag": [1, 2, 6, 10, 11, 22, 27, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 190, 192, 201, 302, 304, 324, 337, 368, 386, 387, 388, 389, 403, 404, 405, 410, 421, 579, 592, 594, 613, 623, 624, 627, 632, 641], "gather": [1, 2, 17, 18, 42, 47, 50, 95, 97, 102, 108, 116, 195, 244, 251, 310, 326, 332, 337, 366, 376, 378, 380, 384, 420, 421, 473, 554, 591, 621, 622, 623, 628, 635, 636, 637, 639, 641, 642], "thei": [1, 2, 3, 6, 7, 17, 20, 21, 22, 23, 27, 28, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 120, 123, 126, 129, 130, 131, 138, 141, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 220, 235, 241, 250, 259, 267, 271, 272, 277, 304, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 412, 416, 566, 568, 571, 572, 574, 576, 579, 581, 587, 600, 613, 620, 621, 622, 623, 624, 627, 634, 635, 636, 637, 638, 639, 641, 642], "handl": [1, 5, 6, 7, 16, 17, 18, 20, 22, 35, 36, 37, 38, 39, 40, 41, 42, 46, 47, 49, 50, 54, 55, 63, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 278, 279, 280, 304, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 403, 409, 416, 421, 562, 563, 565, 566, 567, 569, 570, 571, 572, 573, 574, 578, 579, 580, 581, 587, 592, 594, 613, 620, 621, 622, 623, 625, 627, 632, 636, 639], "reset": [1, 2, 7, 16, 17, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 109, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 216, 217, 218, 221, 233, 236, 240, 245, 250, 258, 263, 264, 265, 266, 267, 270, 271, 272, 275, 278, 279, 282, 287, 302, 304, 312, 326, 332, 337, 341, 366, 376, 378, 380, 383, 384, 392, 402, 403, 592, 613, 620, 621, 622, 623, 625, 628, 632, 634, 635, 636, 641], "execut": [1, 2, 3, 5, 17, 18, 20, 21, 22, 25, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 95, 96, 98, 108, 109, 120, 121, 122, 123, 126, 127, 130, 131, 132, 134, 136, 137, 138, 144, 145, 150, 151, 154, 155, 158, 159, 160, 161, 170, 171, 172, 175, 176, 178, 179, 180, 186, 190, 192, 193, 197, 201, 215, 226, 227, 244, 267, 272, 301, 302, 304, 324, 325, 327, 328, 329, 330, 331, 334, 341, 346, 347, 366, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 554, 564, 592, 595, 613, 619, 621, 622, 623, 624, 625, 626, 627, 628, 629, 635, 636, 639, 640, 641, 642], "aggreg": [1, 2, 22, 78, 102, 114, 152, 153, 177, 213, 242, 280, 288, 290, 291, 347, 380, 403, 592, 636], "easi": [1, 7, 16, 17, 18, 21, 24, 30, 78, 82, 120, 123, 124, 125, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 301, 312, 599, 620, 621, 622, 633, 636, 638, 639, 641, 642], "qualiti": [1, 30, 177, 285, 368], "sever": [1, 2, 5, 6, 7, 12, 20, 27, 55, 61, 80, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 222, 224, 225, 242, 272, 325, 326, 327, 328, 330, 331, 332, 337, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 466, 592, 620, 622, 624, 629, 630, 639, 642], "differ": [1, 2, 5, 6, 7, 15, 16, 17, 19, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 83, 86, 87, 88, 101, 106, 120, 121, 122, 123, 126, 127, 130, 136, 137, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 221, 226, 230, 231, 242, 246, 253, 262, 270, 272, 274, 282, 305, 317, 324, 325, 326, 327, 328, 330, 331, 332, 337, 345, 364, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 402, 410, 416, 419, 562, 563, 568, 572, 574, 577, 581, 585, 586, 592, 596, 613, 614, 620, 621, 622, 624, 625, 627, 629, 633, 634, 635, 636, 637, 638, 639, 641, 642], "scenario": [1, 4, 6, 40, 46, 49, 142, 143, 150, 163, 164, 226, 270, 380, 391, 613, 620, 626, 635, 636, 637], "singl": [1, 2, 3, 4, 7, 16, 17, 18, 19, 20, 21, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 96, 109, 114, 120, 123, 126, 129, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 214, 221, 222, 242, 250, 255, 265, 270, 272, 277, 288, 302, 304, 305, 314, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 347, 350, 351, 352, 354, 356, 358, 359, 364, 365, 368, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 564, 565, 566, 568, 570, 571, 572, 573, 574, 579, 581, 587, 590, 592, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 632, 634, 635, 636, 637, 638, 639, 641], "worker": [1, 2, 4, 5, 6, 7, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 65, 68, 69, 72, 73, 74, 80, 85, 86, 87, 88, 127, 145, 150, 158, 173, 174, 176, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 271, 279, 280, 324, 325, 327, 328, 330, 331, 334, 335, 336, 377, 379, 381, 382, 383, 385, 402, 403, 404, 416, 562, 563, 564, 565, 566, 567, 568, 569, 571, 572, 573, 574, 575, 576, 577, 579, 580, 581, 583, 584, 585, 586, 587, 590, 620, 621, 622, 641, 642], "across": [1, 2, 3, 16, 19, 27, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 87, 102, 108, 109, 121, 122, 124, 125, 129, 131, 132, 134, 136, 137, 145, 146, 150, 155, 160, 171, 172, 175, 185, 194, 195, 270, 279, 280, 302, 304, 312, 324, 326, 366, 368, 376, 378, 380, 383, 384, 403, 404, 419, 432, 566, 571, 574, 579, 592, 596, 613, 620, 625, 629, 635, 636, 637], "multipl": [1, 2, 3, 6, 7, 17, 18, 21, 22, 24, 27, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 62, 68, 69, 72, 73, 87, 90, 97, 104, 116, 120, 121, 122, 136, 137, 150, 158, 160, 171, 172, 175, 177, 178, 185, 192, 194, 195, 222, 224, 231, 240, 244, 245, 255, 258, 262, 263, 270, 279, 297, 304, 313, 324, 337, 340, 342, 344, 345, 348, 351, 358, 365, 368, 403, 420, 432, 564, 565, 568, 569, 570, 571, 572, 573, 574, 579, 581, 587, 590, 592, 594, 620, 621, 622, 625, 627, 628, 633, 635, 636, 637, 639, 641], "distribut": [1, 6, 10, 15, 21, 22, 23, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 123, 152, 153, 191, 241, 246, 280, 286, 295, 296, 297, 298, 299, 303, 306, 307, 310, 311, 315, 316, 317, 319, 320, 321, 324, 326, 329, 332, 335, 336, 337, 342, 345, 346, 349, 350, 351, 352, 357, 358, 359, 364, 365, 368, 369, 370, 371, 372, 373, 380, 402, 403, 404, 432, 565, 566, 567, 570, 571, 572, 573, 574, 575, 580, 581, 585, 586, 590, 599, 613, 621, 622, 624, 626, 628, 635, 636, 637, 641, 642], "For": [1, 2, 5, 6, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69, 72, 73, 74, 75, 76, 77, 79, 83, 85, 86, 87, 88, 89, 95, 97, 102, 108, 116, 120, 123, 126, 129, 130, 131, 135, 137, 138, 150, 151, 152, 153, 154, 158, 159, 160, 161, 163, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 229, 232, 236, 246, 264, 271, 272, 278, 283, 285, 298, 302, 303, 304, 306, 313, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 357, 359, 364, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 404, 410, 566, 568, 571, 572, 574, 575, 576, 579, 580, 581, 582, 585, 587, 592, 613, 620, 621, 622, 623, 625, 626, 628, 629, 632, 635, 636, 637, 638, 639, 642], "node": [1, 3, 7, 15, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 60, 71, 85, 86, 87, 138, 176, 179, 270, 324, 325, 327, 328, 330, 331, 335, 336, 377, 379, 381, 382, 385, 580, 581, 587, 590, 613, 628, 641], "rai": [1, 3, 6, 10, 32, 34, 35, 36, 38, 39, 50, 52, 53, 54, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 171, 172, 175, 185, 189, 192, 193, 194, 195, 243, 324, 329, 334, 337, 402, 403, 404, 572, 573, 574, 580, 585, 586, 587, 613], "rpc": [1, 3, 6, 32, 34, 35, 36, 38, 47, 49, 51, 52, 53, 67, 324, 570, 571, 580, 583, 585, 586], "backend": [1, 3, 6, 7, 8, 10, 16, 17, 18, 20, 22, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 175, 178, 179, 180, 192, 193, 211, 282, 317, 326, 332, 333, 334, 337, 403, 404, 446, 450, 566, 572, 573, 574, 579, 585, 586, 590, 596, 613, 620, 622, 623, 624, 625, 628, 629, 633, 637], "distributedcollector": [1, 3, 43], "rpccollector": [1, 3, 48], "unifi": [1, 16, 324, 337, 578, 592, 596, 633, 642], "paramet": [1, 2, 5, 6, 7, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 96, 97, 98, 101, 102, 103, 104, 106, 107, 110, 112, 114, 116, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 204, 205, 206, 210, 211, 212, 213, 214, 215, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 395, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 461, 471, 473, 553, 554, 555, 556, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 606, 613, 620, 623, 624, 626, 630, 635, 636, 637, 638, 641], "choos": [1, 2, 3, 6, 22, 30, 63, 120, 123, 141, 302, 304, 368, 620, 621, 622, 624, 635, 636, 639, 641], "synchron": [1, 3, 5, 22, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 86, 87, 145, 176, 190, 208, 324, 325, 327, 328, 330, 331, 337, 377, 379, 381, 382, 385, 402, 562, 563, 566, 567, 568, 569, 571, 572, 573, 574, 576, 577, 579, 580, 581, 587, 590, 592, 621, 622, 635], "asynchron": [1, 2, 3, 22, 28, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 349, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 416, 418, 562, 570, 620, 621, 622], "import": [1, 5, 6, 7, 10, 16, 18, 19, 20, 21, 22, 23, 25, 29, 30, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 101, 102, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 140, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 206, 211, 212, 213, 214, 215, 217, 218, 220, 221, 224, 226, 227, 233, 234, 239, 240, 241, 242, 246, 248, 250, 252, 253, 254, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 270, 271, 273, 277, 279, 280, 282, 283, 284, 285, 287, 290, 291, 292, 293, 296, 297, 298, 300, 301, 302, 303, 304, 305, 307, 312, 313, 314, 320, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 393, 408, 410, 420, 421, 560, 587, 592, 599, 606, 613, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 634, 635, 636, 637, 638, 639, 641, 642], "all": [1, 2, 3, 5, 6, 7, 17, 18, 19, 21, 22, 23, 27, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 120, 123, 124, 125, 126, 127, 129, 130, 131, 132, 137, 138, 142, 143, 144, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 166, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 206, 210, 212, 214, 220, 221, 224, 225, 229, 230, 232, 235, 241, 245, 246, 250, 258, 260, 262, 265, 266, 271, 272, 275, 277, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 341, 344, 345, 347, 348, 349, 350, 351, 352, 361, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 402, 403, 404, 411, 416, 420, 424, 473, 553, 562, 563, 564, 565, 566, 567, 568, 571, 572, 573, 574, 576, 579, 580, 581, 583, 585, 587, 591, 608, 613, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 634, 635, 636, 637, 639, 641, 642], "befor": [1, 2, 4, 5, 6, 17, 21, 22, 23, 25, 26, 29, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 59, 61, 82, 88, 107, 109, 114, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 278, 279, 280, 286, 302, 304, 305, 324, 326, 332, 337, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 387, 388, 389, 412, 566, 568, 571, 572, 573, 574, 577, 579, 580, 581, 585, 587, 592, 613, 620, 622, 623, 624, 628, 629, 635, 636, 637, 639, 642], "deliv": [1, 2, 5, 18, 34, 35, 36, 38, 83, 185, 620, 621, 625, 628, 641], "batch": [1, 4, 5, 6, 7, 9, 16, 18, 19, 20, 32, 34, 35, 36, 38, 39, 42, 44, 47, 50, 52, 53, 55, 56, 60, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 98, 102, 103, 107, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 144, 145, 147, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 218, 221, 225, 227, 236, 244, 246, 248, 251, 255, 262, 265, 267, 271, 272, 274, 278, 279, 280, 295, 302, 304, 306, 310, 312, 319, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 341, 344, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 406, 409, 412, 413, 414, 416, 418, 419, 420, 421, 440, 473, 562, 563, 564, 592, 594, 606, 621, 622, 623, 624, 625, 628, 630, 632, 634, 635, 636, 638, 641, 642], "create_env_fn": [1, 5, 6, 7, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 127, 150, 158, 440, 473, 568, 620, 641], "make_env": [1, 4, 5, 16, 20, 22, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 150, 158, 164, 270, 279, 280, 391, 555, 556, 592, 620, 621, 641, 642], "4": [1, 4, 5, 6, 7, 10, 16, 17, 22, 26, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 60, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 101, 102, 108, 109, 116, 120, 121, 122, 123, 124, 125, 126, 130, 136, 137, 138, 139, 140, 141, 144, 146, 150, 151, 154, 156, 157, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 194, 214, 215, 217, 218, 221, 226, 227, 233, 255, 262, 263, 264, 270, 279, 280, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 297, 298, 299, 300, 301, 303, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 320, 322, 325, 327, 328, 330, 331, 338, 340, 341, 342, 344, 347, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 391, 392, 402, 420, 421, 473, 481, 491, 497, 566, 568, 571, 572, 574, 579, 581, 587, 592, 613, 619, 620, 621, 622, 623, 629, 635, 636, 637, 639, 640, 641, 642], "my_polici": [1, 5, 35, 36, 38], "frames_per_batch": [1, 2, 4, 5, 6, 7, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 66, 218, 221, 255, 302, 304, 421, 553, 568, 620, 621, 622, 623, 624, 628, 630, 635, 636, 639, 641], "200": [1, 7, 16, 34, 35, 38, 50, 66, 78, 88, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 255, 290, 291, 299, 315, 316, 326, 332, 337, 376, 378, 380, 383, 384, 391, 393, 620, 623, 624, 628, 630, 639], "total_fram": [1, 4, 5, 6, 7, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 66, 218, 221, 255, 416, 420, 421, 473, 553, 560, 568, 614, 620, 621, 622, 623, 624, 628, 630, 635, 636, 639, 641], "10000": [1, 6, 32, 35, 36, 38, 50, 150, 416, 420, 421, 473, 623], "true": [1, 2, 5, 6, 7, 9, 18, 21, 22, 23, 27, 30, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 95, 96, 97, 98, 101, 102, 104, 106, 107, 108, 109, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 213, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 231, 234, 236, 239, 240, 241, 242, 244, 245, 246, 250, 251, 253, 254, 257, 258, 259, 262, 263, 265, 268, 269, 270, 271, 272, 273, 274, 275, 277, 279, 280, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 297, 298, 300, 302, 304, 305, 306, 312, 313, 314, 317, 319, 320, 321, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 340, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 393, 401, 402, 405, 408, 409, 410, 412, 416, 418, 420, 421, 433, 434, 435, 442, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 464, 465, 468, 472, 473, 475, 503, 505, 522, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 564, 565, 566, 568, 569, 571, 572, 574, 576, 578, 579, 581, 582, 583, 585, 587, 592, 613, 620, 621, 622, 623, 624, 626, 629, 630, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "deliveri": [1, 5, 17, 35, 36, 38], "serv": [1, 2, 5, 16, 22, 35, 36, 38, 42, 47, 50, 86, 87, 132, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 424, 592, 639, 641, 642], "fals": [1, 2, 3, 5, 18, 22, 30, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 106, 107, 108, 109, 110, 115, 116, 118, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 208, 212, 213, 214, 215, 217, 218, 221, 222, 225, 227, 229, 232, 233, 234, 236, 239, 240, 241, 243, 244, 245, 246, 248, 250, 251, 252, 253, 255, 257, 258, 259, 262, 263, 265, 268, 269, 270, 271, 272, 273, 274, 275, 277, 279, 280, 282, 283, 284, 285, 286, 287, 288, 290, 296, 297, 298, 301, 302, 303, 304, 305, 306, 312, 313, 314, 317, 320, 321, 322, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 337, 340, 341, 342, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 393, 401, 405, 408, 409, 410, 412, 413, 416, 420, 421, 425, 426, 427, 428, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 477, 478, 503, 506, 516, 527, 539, 540, 541, 542, 543, 549, 550, 551, 564, 566, 568, 576, 583, 585, 613, 620, 621, 622, 623, 624, 629, 630, 632, 633, 634, 635, 636, 637, 638, 641, 642], "async": [1, 7, 16, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 66, 120, 154, 159, 190, 278, 324, 333, 336, 337, 418, 420, 473], "faster": [1, 3, 23, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 84, 85, 101, 145, 306, 386, 387, 388, 389, 623, 624, 635, 636], "mai": [1, 2, 3, 5, 6, 17, 18, 19, 21, 22, 23, 24, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 54, 56, 60, 70, 71, 74, 79, 85, 86, 87, 88, 93, 96, 101, 102, 108, 120, 123, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 246, 259, 270, 272, 274, 279, 280, 302, 304, 305, 317, 325, 326, 327, 328, 330, 331, 332, 337, 339, 345, 351, 358, 365, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 420, 421, 566, 568, 571, 572, 574, 576, 577, 579, 581, 587, 592, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 635, 636, 637, 638, 639, 642], "lag": [1, 2, 620, 621, 622], "vs": [1, 6, 280, 282, 326, 332, 337, 402], "algorithm": [1, 5, 7, 10, 12, 18, 20, 27, 28, 33, 35, 36, 38, 42, 43, 44, 45, 47, 48, 144, 214, 262, 349, 368, 369, 371, 418, 420, 421, 606, 607, 610, 611, 612, 614, 620, 621, 622, 623, 624, 626, 627, 628, 629, 635, 636, 638, 639, 641], "a2c": [1, 5, 349], "where": [1, 2, 4, 6, 7, 17, 18, 19, 20, 21, 22, 23, 26, 27, 32, 34, 35, 36, 37, 38, 39, 40, 42, 44, 46, 47, 49, 50, 52, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 95, 97, 102, 108, 109, 114, 116, 117, 120, 123, 126, 130, 138, 141, 144, 147, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 212, 213, 214, 215, 218, 221, 226, 233, 241, 250, 255, 258, 263, 264, 265, 266, 267, 271, 272, 274, 277, 278, 286, 301, 302, 304, 306, 312, 317, 325, 326, 327, 328, 330, 331, 332, 337, 339, 342, 344, 345, 349, 350, 351, 352, 357, 358, 359, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 395, 401, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 421, 581, 582, 614, 620, 621, 622, 624, 625, 632, 634, 635, 636, 637, 639, 642], "must": [1, 4, 6, 18, 21, 22, 26, 30, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 95, 96, 97, 98, 102, 108, 109, 110, 111, 112, 114, 116, 120, 121, 123, 126, 127, 130, 136, 138, 148, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 163, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 214, 217, 218, 221, 224, 226, 227, 233, 237, 239, 241, 243, 244, 246, 248, 259, 262, 264, 265, 266, 269, 270, 272, 273, 274, 279, 286, 288, 297, 298, 302, 304, 305, 306, 313, 314, 322, 324, 326, 329, 332, 337, 340, 341, 342, 344, 345, 348, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 395, 401, 402, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 421, 580, 581, 587, 588, 592, 620, 621, 622, 623, 626, 632, 634, 637, 639], "match": [1, 10, 19, 21, 22, 25, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 112, 120, 123, 124, 125, 126, 127, 129, 130, 131, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 238, 240, 241, 242, 243, 244, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 288, 295, 297, 302, 304, 305, 313, 319, 322, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 344, 345, 348, 350, 351, 352, 358, 365, 367, 368, 369, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 412, 419, 575, 620, 622, 624, 634, 636, 637, 639, 642], "current": [1, 4, 18, 22, 31, 32, 34, 35, 36, 37, 38, 39, 46, 49, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 99, 102, 109, 120, 123, 126, 130, 132, 138, 145, 148, 149, 150, 151, 154, 158, 159, 160, 167, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 217, 218, 221, 239, 251, 264, 265, 266, 270, 271, 272, 280, 299, 312, 316, 317, 320, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 341, 349, 351, 352, 359, 365, 368, 370, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 396, 402, 403, 404, 566, 568, 569, 571, 572, 574, 575, 576, 579, 581, 584, 585, 586, 587, 613, 620, 621, 622, 623, 627, 635, 636, 637, 639, 642], "off": [1, 2, 5, 10, 12, 23, 35, 36, 38, 297, 303, 321, 371, 391, 410, 418, 421, 555, 620, 621, 622, 626, 627, 635, 636, 638, 641, 642], "sac": [1, 5, 7, 35, 36, 38, 358, 369, 371, 421, 614], "slight": [1, 150, 158, 621], "accept": [1, 2, 6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 68, 75, 80, 81, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 216, 221, 225, 236, 239, 250, 258, 262, 265, 270, 271, 272, 273, 274, 275, 277, 305, 325, 326, 327, 328, 330, 331, 332, 337, 344, 345, 346, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 613, 622, 625, 629, 639, 641, 642], "flexibl": [1, 6, 10, 16, 22, 28, 145, 170, 374, 592, 613, 620, 624, 633, 639, 642], "devic": [1, 2, 3, 6, 12, 17, 18, 19, 21, 22, 26, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 108, 109, 116, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 209, 212, 214, 218, 225, 229, 230, 232, 233, 234, 239, 241, 242, 243, 248, 249, 250, 252, 253, 255, 259, 262, 263, 265, 268, 271, 272, 273, 275, 277, 279, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 308, 309, 311, 312, 313, 314, 315, 316, 320, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 340, 341, 342, 344, 345, 347, 349, 350, 351, 352, 353, 354, 356, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 412, 419, 425, 427, 439, 440, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 464, 465, 472, 490, 509, 533, 534, 535, 558, 568, 579, 580, 587, 620, 621, 622, 623, 624, 635, 636, 637, 638, 641], "control": [1, 2, 7, 13, 17, 18, 22, 24, 27, 34, 56, 60, 68, 69, 71, 72, 73, 101, 102, 108, 120, 123, 124, 125, 126, 130, 137, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 194, 195, 196, 208, 212, 231, 290, 291, 292, 293, 302, 304, 312, 316, 324, 344, 345, 346, 349, 351, 352, 365, 366, 368, 376, 378, 380, 384, 386, 391, 405, 421, 592, 613, 620, 621, 622, 623, 624, 625, 626, 627, 635, 636, 637, 639, 641], "weight": [1, 2, 23, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 65, 69, 86, 87, 88, 101, 102, 106, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 239, 242, 250, 265, 270, 271, 272, 275, 277, 302, 304, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 349, 350, 351, 352, 358, 361, 368, 371, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 419, 421, 502, 559, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 590, 620, 621, 622, 634, 637, 639, 641], "keep": [1, 2, 7, 20, 21, 22, 23, 26, 27, 35, 65, 68, 69, 72, 73, 86, 87, 88, 107, 114, 123, 150, 158, 176, 189, 191, 195, 212, 246, 250, 277, 279, 280, 312, 325, 327, 328, 330, 331, 341, 351, 368, 377, 379, 380, 381, 382, 383, 385, 393, 408, 416, 620, 621, 622, 623, 628, 629, 630, 636, 637, 639, 642], "infer": [1, 2, 6, 21, 34, 35, 36, 37, 38, 39, 41, 42, 46, 47, 49, 50, 52, 53, 54, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 194, 195, 196, 221, 279, 306, 324, 334, 337, 342, 345, 356, 380, 384, 391, 403, 581, 587, 592, 596, 620, 622, 624, 628, 630, 633, 639, 641], "date": [1, 37, 39, 123, 220, 396], "integr": [1, 6, 7, 16, 54, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 293, 302, 304, 324, 326, 332, 337, 344, 376, 378, 380, 383, 384, 625, 626, 628, 632, 635, 636, 637, 638], "seamless": [1, 305, 324, 592, 633], "strategi": [1, 2, 5, 6, 7, 10, 12, 22, 34, 83, 86, 87, 106, 141, 176, 188, 214, 301, 310, 324, 325, 327, 328, 330, 331, 337, 377, 379, 380, 381, 382, 385, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 587, 590, 592, 599, 613, 620, 621, 624, 626, 635, 636, 639, 641], "organ": [1, 2, 7, 16, 632, 637, 639], "gymenv": [1, 5, 6, 16, 18, 20, 21, 22, 24, 30, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 88, 114, 120, 123, 126, 127, 130, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 217, 218, 221, 224, 225, 226, 227, 233, 239, 240, 241, 246, 248, 253, 254, 255, 258, 260, 264, 265, 266, 267, 270, 271, 272, 273, 279, 280, 287, 302, 304, 339, 341, 383, 391, 393, 446, 560, 568, 599, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 638, 639, 641, 642], "parallelenv": [1, 3, 4, 16, 18, 20, 22, 32, 34, 35, 36, 38, 47, 52, 53, 88, 114, 120, 123, 126, 130, 138, 145, 151, 152, 153, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 271, 280, 302, 304, 383, 391, 561, 620, 621, 622, 625, 634, 641, 642], "def": [1, 5, 6, 7, 16, 18, 20, 21, 22, 35, 36, 38, 51, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 120, 123, 126, 127, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 209, 211, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 280, 282, 322, 325, 326, 327, 328, 330, 331, 332, 337, 341, 342, 350, 352, 353, 358, 364, 366, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 405, 585, 586, 592, 613, 620, 621, 624, 632, 634, 635, 636, 637, 639, 641, 642], "v1": [1, 5, 6, 7, 16, 18, 20, 21, 22, 30, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 79, 81, 86, 87, 88, 114, 120, 123, 126, 127, 129, 130, 131, 136, 137, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 217, 218, 221, 224, 226, 227, 234, 240, 241, 246, 253, 255, 258, 259, 260, 263, 264, 265, 266, 267, 270, 271, 273, 279, 280, 287, 302, 304, 325, 327, 328, 330, 331, 339, 341, 377, 379, 381, 382, 383, 385, 391, 568, 599, 621, 623, 625, 626, 627, 628, 629, 630, 637, 639, 641, 642], "shape": [1, 4, 6, 14, 17, 18, 19, 22, 33, 34, 35, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 95, 96, 97, 101, 108, 114, 116, 120, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 175, 176, 177, 178, 179, 180, 183, 185, 188, 195, 196, 206, 212, 214, 218, 220, 222, 229, 232, 233, 234, 239, 241, 242, 246, 248, 252, 253, 255, 259, 262, 263, 265, 268, 273, 279, 281, 283, 284, 285, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 319, 320, 322, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 341, 342, 344, 345, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 391, 393, 406, 412, 416, 464, 465, 468, 469, 470, 560, 580, 585, 586, 588, 592, 620, 621, 622, 623, 624, 626, 627, 630, 632, 633, 634, 635, 636, 638, 639, 641, 642], "50": [1, 34, 35, 38, 50, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 85, 88, 108, 109, 142, 143, 183, 324, 329, 332, 337, 550, 613, 623, 633, 639], "step": [1, 2, 3, 4, 6, 7, 16, 17, 18, 19, 21, 23, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 78, 86, 87, 88, 92, 93, 100, 102, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 212, 213, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 236, 237, 240, 241, 243, 244, 246, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 286, 299, 301, 302, 304, 312, 317, 325, 327, 328, 330, 331, 341, 342, 345, 349, 360, 368, 377, 379, 381, 382, 383, 385, 386, 387, 388, 389, 392, 395, 406, 410, 416, 418, 420, 421, 473, 592, 614, 621, 623, 624, 626, 627, 629, 630, 633, 634, 637, 638, 641], "each": [1, 2, 3, 5, 6, 7, 12, 15, 17, 19, 20, 21, 22, 23, 26, 27, 32, 34, 35, 36, 37, 38, 39, 42, 44, 46, 47, 49, 50, 52, 53, 55, 56, 60, 61, 62, 68, 69, 71, 72, 78, 79, 80, 83, 86, 87, 88, 101, 102, 106, 108, 109, 111, 114, 120, 123, 126, 127, 130, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 240, 242, 244, 250, 255, 258, 263, 264, 265, 266, 270, 271, 277, 279, 280, 282, 286, 297, 298, 301, 302, 304, 308, 314, 317, 324, 325, 326, 327, 328, 330, 331, 332, 337, 345, 347, 351, 365, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 393, 402, 410, 412, 562, 563, 566, 568, 569, 571, 572, 574, 575, 576, 577, 579, 580, 581, 587, 592, 613, 620, 621, 622, 623, 626, 627, 628, 630, 635, 636, 637, 638, 639, 641, 642], "updat": [1, 17, 18, 21, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 144, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 215, 217, 218, 229, 231, 232, 239, 252, 263, 264, 270, 272, 276, 279, 280, 286, 301, 312, 313, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 344, 345, 349, 350, 351, 352, 353, 354, 356, 358, 359, 360, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 410, 415, 416, 418, 419, 421, 555, 556, 559, 560, 565, 566, 567, 568, 570, 571, 572, 573, 574, 575, 576, 579, 581, 583, 585, 587, 590, 621, 622, 623, 624, 627, 630, 635, 636, 637, 639, 642], "period": [1, 191, 580], "should_upd": 1, "update_policy_weights_": [1, 2, 6, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 191, 566, 568, 571, 572, 574, 576, 579, 581, 587, 620, 636, 641], "shutdown": [1, 5, 6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 154, 159, 190, 218, 324, 402, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587, 613, 620, 621, 639, 641], "follow": [1, 2, 3, 4, 5, 6, 9, 17, 18, 19, 21, 22, 25, 26, 27, 30, 41, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 109, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 144, 147, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 217, 221, 241, 250, 275, 279, 280, 288, 298, 302, 304, 305, 313, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 349, 350, 351, 352, 353, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 416, 565, 566, 567, 568, 570, 571, 573, 574, 580, 592, 606, 620, 621, 622, 623, 624, 627, 628, 634, 635, 636, 637, 639, 641, 642], "kept": [1, 3, 19, 22, 46, 49, 56, 107, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 212, 231, 259, 303, 320, 321, 581, 583, 585, 587, 627, 635], "syncdatacollector": [1, 4, 5, 18, 620, 621, 622, 623, 624, 628, 630, 635, 636, 639], "multisyncdatacollector": [1, 2, 4, 5, 622, 628, 641], "multiasyncdatacollector": [1, 2, 5, 53, 620, 621, 622, 628, 641], "datacollectorbas": [1, 5], "basecollector": [1, 5, 32, 35, 36, 37, 38, 39, 40, 41, 44, 46, 49, 54, 55, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 271, 342, 345, 383, 419, 420, 421, 555, 556, 560], "basic": [1, 6, 21, 40, 89, 144, 170, 402, 404, 420, 568, 576, 590, 592, 614, 622, 627, 628, 630, 635, 641, 642], "size": [1, 16, 18, 19, 22, 34, 35, 38, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 103, 107, 108, 109, 110, 116, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 214, 218, 220, 221, 222, 225, 228, 229, 232, 233, 234, 236, 239, 242, 244, 248, 250, 252, 253, 255, 259, 261, 262, 263, 265, 267, 268, 271, 272, 273, 274, 277, 279, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 315, 316, 319, 320, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 341, 342, 344, 347, 349, 350, 351, 352, 353, 354, 356, 357, 358, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 393, 402, 406, 412, 418, 420, 421, 580, 585, 586, 592, 621, 622, 623, 624, 625, 626, 628, 632, 635, 636, 637, 642], "copi": [1, 6, 18, 35, 36, 37, 38, 39, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 74, 75, 76, 77, 83, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 217, 221, 239, 253, 264, 270, 271, 272, 279, 280, 282, 302, 304, 325, 326, 327, 328, 330, 331, 332, 337, 352, 366, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 391, 566, 568, 571, 572, 574, 575, 576, 579, 581, 587, 592, 620, 621, 623, 625, 635, 639, 641], "distributedsynccollector": [1, 3, 45], "distributeddatacollector": [1, 3, 42, 46, 51, 570], "rpcdatacollector": [1, 3, 34, 35, 36, 38, 47, 49, 51], "distributedsyncdatacollector": [1, 3], "submitit_delayed_launch": 1, "raycollector": [1, 39, 66], "lifecycl": [1, 22, 324], "scheme": [1, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 565, 566, 567, 568, 569, 571, 572, 573, 574, 576, 579, 581, 583, 584, 585, 586, 587, 592, 642], "behavior": [1, 2, 18, 21, 22, 23, 35, 36, 38, 50, 74, 83, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 222, 229, 232, 246, 251, 264, 272, 280, 302, 303, 304, 321, 324, 325, 326, 327, 328, 330, 331, 332, 337, 351, 357, 364, 368, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 405, 410, 579, 613, 621, 623, 635, 636, 637, 639], "transport": [1, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 579, 580, 581, 582, 583, 587], "interoper": [1, 35, 36, 38], "helper": [1, 16, 339, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 590, 599, 614, 620, 621, 623, 635, 637], "somewhat": [2, 185, 626, 642], "equival": [2, 7, 17, 50, 53, 54, 57, 59, 60, 61, 62, 64, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 230, 233, 265, 267, 272, 297, 298, 305, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 412, 628, 641, 642], "dataload": [2, 6, 52, 107, 109, 170, 171, 172, 175, 178, 185, 194, 621, 628, 639], "except": [2, 17, 21, 32, 34, 35, 36, 38, 42, 44, 47, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 235, 255, 264, 265, 266, 270, 272, 286, 301, 302, 304, 310, 312, 325, 326, 327, 328, 330, 331, 332, 337, 349, 352, 366, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 592, 620, 621, 625, 633, 635, 639, 641, 642], "1": [2, 4, 7, 8, 10, 18, 19, 21, 22, 23, 27, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 95, 96, 97, 101, 102, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 206, 212, 214, 215, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 237, 239, 241, 242, 244, 246, 248, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 270, 271, 272, 273, 275, 277, 279, 280, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 298, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 361, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 393, 402, 404, 406, 410, 412, 413, 421, 425, 427, 440, 446, 464, 465, 468, 470, 472, 473, 477, 482, 503, 506, 516, 525, 540, 545, 550, 560, 564, 566, 567, 568, 570, 571, 572, 573, 574, 576, 579, 580, 581, 582, 585, 586, 587, 591, 592, 613, 619, 620, 621, 622, 623, 624, 626, 627, 628, 630, 634, 635, 636, 637, 638, 639, 640, 641, 642], "over": [2, 5, 7, 18, 20, 21, 22, 23, 27, 35, 36, 38, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 101, 102, 107, 108, 109, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 231, 246, 258, 266, 280, 306, 310, 317, 320, 326, 332, 337, 347, 359, 361, 366, 376, 378, 380, 383, 384, 386, 391, 412, 553, 620, 621, 622, 624, 625, 626, 627, 628, 635, 636, 637, 642], "non": [2, 6, 12, 17, 22, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 53, 55, 57, 58, 60, 63, 65, 70, 71, 74, 75, 76, 77, 83, 86, 87, 88, 96, 98, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 218, 219, 221, 225, 236, 250, 262, 265, 271, 272, 273, 274, 275, 277, 280, 287, 302, 304, 307, 325, 326, 327, 328, 330, 331, 332, 337, 344, 345, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 566, 568, 570, 571, 572, 574, 576, 579, 581, 587, 620, 623, 624, 635, 636, 637, 639, 642], "static": [2, 60, 71, 102, 108, 109, 132, 151, 174, 180, 279, 282, 326, 332, 337, 364, 376, 378, 380, 384, 625, 637, 639], "like": [2, 4, 6, 7, 17, 19, 21, 22, 23, 26, 30, 34, 35, 36, 38, 46, 50, 60, 63, 65, 68, 69, 71, 72, 73, 86, 87, 88, 90, 98, 109, 120, 123, 126, 127, 130, 132, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 233, 265, 268, 303, 320, 325, 326, 327, 328, 329, 330, 331, 332, 337, 339, 345, 349, 351, 365, 368, 369, 370, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 403, 567, 613, 620, 622, 623, 624, 625, 626, 627, 628, 629, 630, 635, 636, 637, 638, 639, 641, 642], "being": [2, 3, 17, 18, 21, 22, 26, 27, 32, 34, 35, 36, 38, 41, 42, 44, 47, 49, 50, 70, 86, 87, 88, 96, 98, 101, 102, 114, 117, 120, 123, 126, 129, 130, 131, 132, 137, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 220, 229, 231, 232, 239, 245, 253, 265, 270, 271, 272, 301, 302, 304, 312, 325, 326, 327, 328, 330, 331, 332, 337, 351, 352, 365, 366, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 412, 419, 562, 563, 564, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587, 613, 620, 621, 622, 623, 628, 635, 636, 637, 639], "torchrl": [2, 3, 5, 6, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 592, 613, 619, 623, 625, 627, 628, 629, 630, 631, 634, 638, 639, 640], "two": [2, 6, 7, 18, 22, 23, 27, 29, 61, 62, 65, 68, 69, 72, 73, 83, 86, 87, 88, 107, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 226, 246, 250, 270, 277, 293, 302, 304, 317, 320, 325, 326, 327, 328, 330, 331, 332, 337, 345, 365, 368, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 410, 416, 568, 592, 620, 621, 622, 623, 624, 625, 626, 628, 629, 633, 634, 635, 636, 637, 639, 641, 642], "main": [2, 6, 7, 19, 24, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 56, 66, 85, 127, 150, 158, 170, 193, 221, 226, 324, 345, 416, 565, 566, 567, 568, 569, 571, 572, 574, 576, 579, 581, 587, 592, 620, 621, 632, 633, 634, 641, 642], "argument": [2, 3, 6, 18, 19, 20, 21, 22, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 95, 96, 97, 98, 101, 102, 106, 107, 108, 109, 112, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 152, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 206, 212, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 244, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 286, 287, 288, 297, 298, 301, 302, 304, 305, 306, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 340, 341, 342, 344, 345, 346, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 398, 400, 401, 402, 403, 404, 408, 416, 420, 421, 553, 560, 561, 564, 578, 613, 620, 621, 622, 623, 624, 625, 626, 628, 635, 636, 637, 639, 641, 642], "list": [2, 21, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 96, 98, 106, 107, 108, 109, 110, 112, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 212, 219, 220, 224, 225, 229, 230, 232, 241, 242, 246, 248, 250, 258, 260, 268, 269, 270, 271, 272, 274, 275, 277, 279, 287, 288, 290, 296, 298, 300, 302, 304, 305, 306, 308, 313, 314, 322, 324, 325, 326, 327, 328, 330, 331, 332, 334, 337, 341, 345, 347, 348, 350, 352, 364, 366, 369, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 389, 391, 392, 402, 403, 404, 410, 412, 428, 436, 437, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 476, 478, 479, 480, 481, 482, 483, 484, 485, 488, 489, 490, 491, 492, 494, 495, 496, 497, 498, 499, 501, 502, 504, 506, 507, 508, 509, 510, 513, 514, 515, 516, 517, 518, 519, 520, 521, 523, 524, 525, 526, 527, 528, 531, 532, 533, 534, 535, 536, 537, 538, 562, 563, 566, 568, 569, 571, 572, 574, 575, 576, 579, 581, 587, 613, 620, 622, 625, 626, 627, 628, 632, 633, 634, 635, 637, 638, 639, 641, 642], "constructor": [2, 17, 21, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 66, 68, 72, 73, 83, 86, 87, 101, 114, 120, 123, 126, 130, 138, 145, 150, 151, 154, 158, 159, 160, 163, 170, 171, 172, 175, 176, 177, 178, 179, 180, 195, 196, 217, 221, 270, 288, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 402, 403, 420, 561, 564, 578, 592, 613, 620, 621, 622, 625, 628, 635, 636, 639, 641], "iter": [2, 5, 18, 20, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 98, 107, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 234, 246, 259, 282, 287, 288, 297, 305, 313, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 344, 346, 347, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 410, 412, 414, 416, 620, 622, 623, 628, 630, 635, 636, 637], "queri": [2, 18, 38, 86, 87, 88, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 203, 250, 275, 279, 325, 326, 327, 328, 330, 331, 332, 337, 347, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 620, 627, 632, 637, 641], "defin": [2, 7, 14, 21, 32, 34, 35, 36, 38, 41, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 251, 264, 282, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 348, 354, 356, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 415, 473, 561, 613, 620, 621, 623, 627, 630, 637, 639, 642], "number": [2, 16, 17, 18, 19, 27, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 106, 108, 109, 116, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 144, 145, 146, 147, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 231, 233, 234, 235, 237, 240, 241, 243, 245, 246, 249, 251, 252, 253, 255, 257, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 286, 288, 295, 299, 300, 301, 302, 303, 304, 305, 307, 308, 309, 312, 315, 316, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341, 342, 344, 345, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 398, 400, 401, 402, 406, 408, 410, 416, 418, 419, 420, 421, 473, 553, 554, 562, 563, 564, 580, 581, 582, 587, 592, 620, 621, 622, 623, 625, 626, 628, 630, 635, 636, 637, 638, 639, 642], "stack": [2, 4, 10, 17, 18, 19, 22, 26, 27, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 74, 75, 76, 77, 86, 87, 96, 101, 120, 123, 126, 129, 130, 131, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 186, 195, 196, 204, 205, 221, 226, 244, 279, 302, 304, 317, 325, 327, 328, 330, 331, 341, 346, 347, 350, 352, 364, 369, 371, 372, 373, 377, 379, 381, 382, 385, 386, 392, 406, 426, 521, 592, 621, 624, 625, 632, 633, 634, 635, 637, 641], "user": [2, 6, 12, 18, 20, 21, 22, 24, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 56, 78, 79, 83, 85, 87, 88, 89, 95, 102, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 222, 239, 264, 270, 272, 294, 326, 332, 337, 352, 368, 371, 372, 376, 378, 380, 383, 384, 393, 561, 592, 620, 621, 625, 627, 628, 633, 637, 641, 642], "reach": [2, 18, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 107, 120, 123, 126, 130, 137, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 244, 263, 286, 301, 312, 620, 622, 630, 632, 635, 636, 641, 642], "done": [2, 17, 18, 19, 21, 22, 23, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 92, 93, 95, 100, 102, 108, 109, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 212, 213, 214, 215, 217, 218, 221, 229, 230, 232, 233, 234, 239, 243, 244, 245, 246, 248, 252, 253, 255, 257, 259, 262, 263, 265, 266, 269, 270, 271, 272, 273, 279, 302, 304, 320, 329, 341, 349, 350, 351, 352, 353, 354, 356, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 380, 383, 384, 386, 387, 388, 389, 390, 409, 493, 592, 613, 620, 622, 623, 624, 625, 627, 628, 630, 633, 634, 635, 636, 637, 639, 641, 642], "state": [2, 6, 17, 18, 21, 22, 23, 32, 34, 35, 36, 38, 40, 41, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 100, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 144, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 217, 220, 221, 222, 224, 225, 227, 230, 233, 236, 239, 243, 244, 246, 253, 263, 264, 269, 270, 271, 272, 273, 274, 279, 280, 283, 289, 294, 299, 302, 304, 305, 308, 311, 315, 316, 317, 323, 325, 326, 327, 328, 329, 330, 331, 332, 337, 341, 344, 349, 351, 352, 356, 358, 365, 366, 368, 369, 370, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 402, 409, 416, 418, 420, 421, 473, 564, 573, 578, 592, 601, 606, 614, 620, 621, 622, 623, 624, 625, 626, 627, 628, 632, 633, 635, 636, 637, 642], "after": [2, 4, 6, 19, 20, 22, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 66, 69, 78, 86, 87, 88, 95, 97, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 135, 136, 137, 138, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 286, 297, 301, 302, 304, 313, 325, 326, 327, 328, 330, 331, 332, 337, 352, 361, 371, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 402, 403, 565, 566, 567, 568, 569, 571, 572, 573, 574, 576, 577, 579, 581, 587, 592, 613, 621, 622, 623, 624, 625, 626, 628, 630, 632, 635, 636, 637, 638, 639, 642], "predefin": [2, 7, 183, 393, 621, 623, 628, 639, 641], "becaus": [2, 18, 21, 22, 23, 26, 53, 60, 71, 78, 86, 87, 88, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 233, 241, 263, 278, 293, 297, 298, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 342, 344, 345, 349, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 620, 621, 623, 624, 626, 627, 628, 632, 634, 635, 636, 637, 639, 642], "comput": [2, 6, 17, 18, 21, 22, 23, 27, 33, 34, 38, 39, 42, 43, 44, 45, 47, 48, 50, 52, 53, 59, 86, 87, 88, 101, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 243, 246, 260, 272, 276, 280, 283, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 317, 320, 321, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 341, 342, 345, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 409, 420, 421, 473, 554, 568, 574, 592, 595, 606, 613, 620, 622, 623, 624, 625, 626, 632, 633, 634, 635, 636, 638, 639], "heavi": [2, 6, 27, 78, 613, 639], "crucial": [2, 20, 86, 87, 176, 286, 301, 312, 325, 327, 328, 330, 331, 357, 364, 366, 377, 379, 380, 381, 382, 385, 421, 592, 620, 621, 622, 623, 625, 627, 629, 635, 636, 637, 641, 642], "hyperparamet": [2, 106, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 590, 620, 629, 637, 639], "appropri": [2, 6, 7, 17, 23, 26, 87, 94, 104, 114, 115, 118, 119, 138, 150, 158, 179, 180, 233, 561, 564, 592, 613, 620, 629, 639], "take": [2, 17, 20, 21, 22, 27, 41, 56, 80, 86, 87, 90, 111, 117, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 183, 224, 226, 263, 266, 267, 271, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 303, 304, 307, 308, 309, 311, 312, 314, 315, 316, 320, 325, 327, 328, 330, 331, 338, 341, 342, 345, 348, 368, 377, 379, 381, 382, 385, 393, 406, 419, 592, 620, 621, 622, 624, 625, 626, 627, 635, 636, 637, 639, 642], "consider": [2, 21, 22, 27, 129, 131, 271, 324, 590, 592, 621, 635, 636, 639], "whether": [2, 18, 22, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 97, 104, 116, 120, 123, 126, 130, 137, 138, 142, 143, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 217, 226, 227, 229, 232, 243, 264, 270, 272, 279, 280, 288, 302, 304, 305, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 341, 345, 349, 350, 351, 352, 353, 354, 356, 358, 359, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 405, 416, 420, 421, 473, 564, 566, 568, 569, 571, 572, 574, 576, 578, 579, 581, 583, 585, 587, 613, 620, 621, 622, 624, 625, 635, 636, 637, 641, 642], "should": [2, 5, 6, 7, 17, 18, 20, 21, 22, 23, 24, 26, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 95, 98, 102, 108, 109, 110, 114, 117, 120, 123, 124, 125, 126, 129, 130, 131, 132, 137, 138, 141, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 217, 218, 221, 224, 225, 226, 229, 230, 233, 234, 236, 241, 242, 244, 246, 251, 252, 253, 255, 258, 259, 263, 264, 266, 269, 271, 272, 273, 278, 279, 280, 282, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 339, 341, 342, 344, 345, 348, 349, 351, 352, 358, 365, 366, 368, 369, 370, 371, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 393, 395, 405, 410, 411, 412, 416, 560, 562, 563, 564, 567, 569, 571, 572, 574, 579, 580, 581, 587, 613, 620, 621, 622, 623, 624, 626, 628, 629, 632, 634, 635, 636, 637, 638, 639, 641, 642], "occur": [2, 6, 27, 35, 70, 71, 78, 120, 123, 126, 130, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 222, 234, 246, 251, 278, 297, 298, 313, 314, 326, 332, 337, 340, 342, 344, 345, 361, 376, 378, 380, 384, 592, 624, 639, 642], "serial": [2, 6, 15, 18, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 279, 280, 326, 332, 337, 376, 378, 380, 383, 384], "multisynccollector": [2, 3, 5, 33, 34, 35, 36, 42, 43, 44, 45, 47, 48, 50, 52, 53, 563, 568], "split": [2, 6, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 71, 78, 79, 80, 81, 82, 83, 84, 85, 102, 108, 109, 141, 152, 153, 171, 307, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 622, 626, 639, 641], "workload": [2, 324], "result": [2, 3, 7, 17, 18, 20, 21, 22, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 56, 58, 65, 66, 67, 68, 69, 72, 73, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 95, 102, 107, 108, 109, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 212, 213, 214, 217, 218, 219, 221, 222, 223, 224, 225, 227, 228, 229, 230, 231, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 286, 298, 301, 302, 304, 305, 314, 320, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 337, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 392, 402, 418, 419, 592, 613, 621, 623, 625, 626, 629, 630, 633, 637, 638, 641, 642], "final": [2, 7, 21, 22, 23, 50, 86, 87, 172, 175, 176, 177, 183, 265, 278, 286, 301, 302, 304, 312, 324, 325, 327, 328, 330, 331, 333, 334, 346, 377, 379, 381, 382, 385, 386, 410, 620, 621, 622, 624, 629, 630, 632, 635, 636, 637, 642], "multiasynccollector": [2, 5, 32, 36, 38, 42, 44, 47, 50, 562], "continu": [2, 21, 28, 58, 60, 75, 76, 87, 109, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 206, 214, 239, 265, 273, 290, 291, 292, 293, 312, 326, 347, 350, 386, 421, 567, 620, 622, 623, 626, 635, 636, 639], "concomitantli": [2, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180], "network": [2, 6, 23, 27, 81, 88, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 283, 284, 285, 288, 290, 291, 292, 293, 296, 299, 300, 305, 308, 309, 315, 316, 317, 326, 332, 337, 344, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 415, 421, 464, 466, 467, 468, 470, 473, 559, 560, 590, 599, 605, 624, 627, 630, 634, 637, 642], "impli": [2, 642], "slightli": [2, 56, 78, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 623, 624, 635, 637, 638, 639, 642], "therefor": [2, 19, 21, 22, 26, 65, 68, 72, 73, 84, 85, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 183, 255, 325, 327, 328, 330, 331, 368, 377, 379, 381, 382, 383, 385, 624, 627, 635, 642], "fastest": 2, "price": 2, "suitabl": [2, 6, 221, 380], "curriculum": [2, 23], "remot": [2, 6, 10, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 150, 158, 176, 189, 194, 195, 280, 325, 327, 328, 329, 330, 331, 337, 377, 379, 381, 382, 385, 402, 403, 570, 571, 572, 573, 574, 580, 585, 586, 587, 613, 642], "rollout": [2, 16, 17, 18, 20, 22, 30, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 114, 120, 121, 122, 123, 126, 130, 132, 133, 136, 137, 138, 142, 143, 144, 145, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 165, 170, 171, 172, 175, 178, 179, 180, 185, 208, 214, 215, 217, 218, 221, 224, 226, 227, 229, 232, 233, 234, 239, 241, 242, 248, 252, 253, 258, 259, 260, 263, 264, 266, 267, 270, 273, 279, 280, 287, 302, 304, 312, 317, 341, 349, 391, 393, 554, 606, 620, 622, 623, 626, 627, 628, 629, 630, 638, 639, 641], "necessari": [2, 6, 23, 25, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 78, 80, 81, 83, 84, 85, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 259, 369, 386, 387, 388, 389, 390, 620, 622, 626, 627, 628, 632, 633], "synchronis": [2, 127, 635, 636], "either": [2, 5, 24, 51, 55, 57, 65, 66, 68, 69, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 243, 244, 263, 264, 280, 323, 326, 332, 334, 337, 366, 372, 373, 376, 378, 380, 383, 384, 397, 592, 600, 620, 621, 623, 635, 638, 639, 641, 642], "update_at_each_batch": [2, 32, 35, 36, 38], "second": [2, 6, 22, 27, 32, 34, 35, 36, 38, 52, 56, 61, 62, 78, 80, 114, 150, 184, 190, 192, 197, 218, 267, 298, 302, 304, 324, 351, 365, 368, 371, 393, 395, 398, 400, 401, 414, 565, 566, 567, 568, 570, 571, 572, 573, 574, 576, 577, 579, 581, 587, 613, 620, 622, 628, 635, 636, 637, 639, 641, 642], "oper": [2, 3, 6, 17, 21, 22, 23, 26, 27, 32, 34, 35, 36, 38, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 96, 97, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 236, 241, 267, 269, 273, 280, 283, 284, 285, 296, 297, 298, 323, 325, 326, 327, 328, 329, 330, 331, 332, 337, 344, 349, 351, 353, 354, 359, 365, 368, 370, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 402, 403, 416, 566, 568, 573, 580, 581, 582, 585, 592, 594, 606, 620, 621, 622, 623, 624, 625, 626, 634, 635, 636, 637, 642], "instanc": [2, 6, 7, 17, 20, 21, 22, 23, 26, 27, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 58, 60, 65, 66, 67, 68, 69, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 95, 96, 97, 100, 102, 108, 109, 116, 120, 123, 125, 126, 127, 129, 130, 131, 135, 138, 144, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 213, 246, 265, 272, 279, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 313, 314, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 341, 342, 344, 345, 346, 347, 348, 350, 352, 354, 357, 358, 364, 366, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 393, 397, 404, 405, 410, 418, 419, 466, 554, 555, 556, 560, 562, 563, 576, 579, 581, 587, 592, 613, 620, 622, 623, 624, 625, 626, 632, 637, 639, 642], "cpu": [2, 3, 6, 18, 22, 27, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 101, 108, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 214, 218, 225, 229, 230, 232, 233, 234, 239, 242, 243, 248, 250, 252, 253, 255, 259, 262, 263, 265, 271, 272, 273, 275, 277, 283, 284, 285, 287, 296, 297, 298, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 329, 330, 331, 332, 337, 340, 341, 342, 344, 347, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 402, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 490, 509, 533, 534, 535, 575, 613, 620, 621, 622, 623, 635, 636, 637, 638, 641], "slower": [2, 3, 8, 9, 568, 635], "than": [2, 3, 6, 22, 23, 27, 32, 34, 35, 36, 38, 42, 44, 46, 47, 50, 52, 53, 57, 65, 68, 69, 72, 73, 78, 79, 83, 86, 87, 88, 102, 108, 109, 112, 114, 120, 123, 126, 130, 134, 138, 148, 149, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 189, 195, 226, 242, 244, 253, 280, 286, 293, 297, 302, 304, 305, 307, 322, 325, 327, 328, 330, 331, 332, 340, 344, 345, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 417, 419, 568, 581, 591, 592, 613, 620, 621, 622, 623, 624, 625, 627, 635, 636, 637, 639, 641, 642], "one": [2, 3, 6, 7, 17, 18, 20, 21, 22, 23, 24, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 83, 86, 87, 88, 92, 93, 94, 95, 100, 101, 102, 104, 108, 109, 110, 112, 114, 115, 118, 119, 120, 121, 122, 123, 126, 127, 129, 130, 131, 132, 134, 135, 136, 137, 138, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 221, 224, 226, 227, 229, 230, 231, 232, 239, 242, 243, 245, 246, 250, 255, 258, 261, 262, 264, 265, 266, 271, 272, 274, 277, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 310, 311, 312, 313, 314, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 341, 342, 344, 345, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 393, 395, 404, 408, 410, 411, 416, 554, 564, 566, 576, 587, 591, 592, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 634, 635, 636, 637, 638, 639, 642], "cuda": [2, 3, 21, 22, 26, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 121, 122, 123, 126, 130, 132, 133, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 225, 241, 249, 250, 265, 271, 272, 275, 277, 326, 332, 333, 337, 344, 376, 378, 380, 383, 384, 407, 575, 580, 620, 621, 622, 623, 635, 636, 638, 642], "dispatch": [2, 5, 22, 42, 44, 47, 50, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 326, 332, 337, 341, 376, 378, 380, 383, 384, 393, 566, 568, 571, 572, 574, 576, 579, 581, 587, 620, 642], "speed": [2, 5, 22, 23, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 613, 620, 621, 622, 623, 635, 636, 637, 639, 641], "avoid": [2, 7, 17, 20, 81, 88, 95, 97, 108, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 211, 221, 239, 270, 272, 279, 280, 303, 320, 322, 326, 332, 337, 340, 344, 351, 352, 365, 368, 371, 376, 378, 380, 383, 384, 553, 565, 568, 570, 572, 574, 575, 592, 613, 622, 624, 633, 636], "oom": [2, 20, 86, 87, 95, 97, 116, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "choic": [2, 15, 63, 79, 85, 86, 87, 150, 176, 185, 307, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 420, 620, 621, 627, 635, 636], "pass": [2, 4, 5, 6, 9, 12, 17, 18, 19, 20, 21, 22, 23, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 57, 60, 63, 65, 66, 68, 69, 71, 72, 73, 74, 78, 80, 81, 83, 84, 85, 86, 87, 88, 93, 95, 97, 102, 108, 109, 114, 116, 120, 123, 126, 127, 128, 130, 131, 138, 141, 145, 150, 151, 152, 153, 154, 158, 159, 160, 163, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 215, 217, 218, 221, 225, 227, 229, 232, 242, 244, 252, 253, 270, 271, 274, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 313, 314, 315, 316, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 340, 341, 342, 344, 345, 347, 348, 350, 351, 352, 364, 365, 366, 368, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 402, 403, 404, 412, 416, 420, 421, 562, 563, 564, 572, 575, 576, 592, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 634, 635, 636, 637, 639, 641, 642], "ie": [2, 17, 42, 47, 51, 57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 72, 74, 75, 76, 77, 83, 101, 109, 120, 123, 126, 130, 134, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 214, 221, 236, 262, 265, 274, 279, 302, 304, 326, 332, 337, 344, 376, 378, 380, 384, 621, 636], "while": [2, 6, 7, 17, 21, 22, 26, 27, 32, 34, 35, 36, 38, 52, 56, 66, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 255, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 341, 348, 351, 357, 364, 365, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 573, 592, 613, 620, 622, 623, 626, 628, 629, 635, 636, 637, 638, 639, 641], "wait": [2, 6, 32, 33, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 66, 95, 97, 161, 183, 324, 565, 566, 567, 568, 570, 571, 572, 573, 574, 576, 577, 579, 580, 581, 587, 623, 637], "impact": [2, 18, 33, 42, 43, 44, 45, 47, 48, 83, 137, 229, 232, 332, 349, 351, 365, 368, 370, 380, 621, 623, 635, 636], "memori": [2, 3, 4, 6, 9, 10, 12, 18, 21, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 59, 66, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 90, 91, 93, 95, 96, 100, 120, 121, 122, 123, 126, 127, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 221, 225, 250, 265, 271, 272, 275, 277, 279, 280, 295, 325, 326, 327, 328, 330, 331, 332, 337, 344, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 425, 564, 566, 567, 568, 571, 572, 574, 575, 576, 579, 581, 582, 587, 592, 613, 620, 621, 623, 635, 639, 641], "which": [2, 3, 5, 6, 7, 10, 17, 18, 19, 21, 22, 23, 26, 27, 32, 34, 35, 36, 37, 38, 41, 42, 44, 47, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 92, 96, 106, 107, 114, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 205, 221, 222, 226, 229, 232, 237, 239, 241, 242, 245, 246, 250, 251, 253, 263, 265, 266, 269, 270, 271, 272, 273, 275, 279, 282, 283, 284, 285, 286, 296, 302, 303, 304, 306, 317, 321, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 342, 344, 345, 346, 347, 349, 350, 351, 352, 354, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 393, 402, 406, 411, 420, 566, 567, 568, 571, 572, 574, 576, 579, 581, 587, 592, 594, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 632, 634, 635, 636, 637, 638, 639, 642], "storing_devic": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 621, 623, 636], "dure": [2, 6, 10, 18, 20, 21, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 93, 95, 97, 98, 101, 102, 106, 108, 120, 123, 126, 127, 130, 137, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 182, 185, 191, 198, 199, 217, 218, 221, 224, 229, 232, 234, 236, 237, 239, 244, 248, 260, 262, 265, 267, 269, 270, 272, 273, 274, 279, 280, 287, 302, 304, 324, 332, 341, 351, 368, 380, 384, 386, 388, 389, 410, 416, 418, 421, 565, 567, 568, 574, 576, 584, 585, 588, 592, 603, 620, 621, 622, 623, 626, 627, 628, 630, 635, 636, 637, 639, 642], "heurist": [2, 23, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 176, 286, 325, 327, 328, 330, 331, 341, 345, 377, 379, 381, 382, 385, 620, 624, 628, 642], "usual": [2, 17, 18, 21, 23, 25, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 79, 106, 114, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 270, 368, 372, 380, 384, 386, 387, 388, 389, 390, 392, 591, 592, 594, 620, 621, 622, 623, 626, 628, 629, 636, 639, 642], "same": [2, 4, 5, 6, 7, 18, 19, 21, 22, 23, 34, 41, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 83, 86, 87, 88, 107, 108, 109, 112, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 141, 145, 146, 150, 151, 152, 153, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 221, 229, 231, 232, 237, 239, 242, 244, 245, 246, 262, 270, 271, 272, 279, 282, 288, 305, 306, 312, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 350, 352, 364, 366, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 420, 565, 566, 568, 570, 571, 573, 574, 581, 582, 587, 588, 592, 613, 620, 621, 622, 625, 626, 628, 632, 633, 634, 635, 636, 638, 639, 642], "default": [2, 3, 6, 7, 17, 19, 21, 22, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 95, 96, 97, 98, 101, 102, 104, 106, 107, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 205, 206, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 245, 246, 248, 249, 250, 251, 252, 253, 255, 257, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341, 342, 344, 345, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 395, 398, 399, 400, 401, 402, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 464, 473, 560, 564, 566, 567, 568, 569, 571, 572, 573, 574, 576, 578, 579, 581, 583, 585, 587, 620, 621, 622, 623, 626, 635, 638, 639, 641, 642], "besid": 2, "those": [2, 22, 24, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 199, 221, 226, 229, 232, 239, 246, 265, 266, 269, 273, 304, 342, 345, 346, 347, 419, 562, 563, 566, 568, 571, 572, 574, 579, 581, 587, 620, 621, 625, 626, 636, 637, 642], "max_frames_per_traj": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 553, 620, 622, 641], "frame": [2, 30, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 78, 90, 221, 237, 286, 301, 312, 341, 392, 393, 395, 398, 400, 401, 408, 410, 416, 420, 421, 473, 553, 554, 620, 621, 622, 623, 626, 635, 636, 639, 641, 642], "call": [2, 6, 7, 8, 17, 18, 20, 21, 22, 26, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 102, 103, 107, 108, 110, 112, 116, 117, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 135, 136, 137, 138, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 203, 210, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 230, 231, 233, 234, 235, 236, 237, 239, 240, 241, 243, 244, 246, 248, 249, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 316, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 341, 344, 345, 347, 348, 350, 351, 352, 358, 364, 365, 366, 368, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 395, 402, 403, 410, 412, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 576, 577, 579, 580, 581, 585, 586, 587, 592, 594, 613, 621, 622, 623, 624, 625, 626, 628, 629, 635, 636, 637, 639, 641, 642], "init_random_fram": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 553, 620, 621, 624, 630], "random": [2, 7, 19, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 85, 103, 114, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 185, 214, 231, 245, 246, 265, 272, 287, 301, 302, 324, 326, 332, 337, 342, 343, 344, 345, 350, 366, 369, 375, 376, 378, 380, 384, 410, 420, 421, 430, 468, 473, 505, 554, 606, 620, 621, 622, 624, 625, 626, 628, 637, 638, 639, 641, 642], "rand_step": [2, 19, 22, 120, 123, 124, 125, 126, 127, 129, 130, 131, 138, 139, 140, 144, 145, 146, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 240, 265, 279, 637, 641, 642], "reset_at_each_it": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 620], "split_traj": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 79, 81, 83, 84, 85, 620, 621, 622], "trajectori": [2, 4, 17, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 56, 72, 78, 79, 80, 81, 83, 84, 85, 101, 102, 108, 109, 114, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 251, 263, 270, 304, 312, 368, 383, 386, 389, 406, 434, 435, 620, 621, 622, 623, 625, 628, 630, 637, 641, 642], "pad": [2, 22, 56, 79, 81, 83, 84, 85, 87, 185, 188, 189, 195, 196, 199, 205, 221, 269, 288, 290, 291, 304, 306, 326, 327, 328, 329, 330, 331, 332, 337, 380, 412, 464, 592, 633], "along": [2, 18, 22, 35, 36, 38, 56, 57, 58, 59, 60, 61, 62, 63, 64, 69, 70, 71, 74, 75, 76, 77, 79, 81, 83, 84, 85, 86, 87, 88, 97, 102, 108, 109, 114, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 205, 206, 220, 221, 222, 244, 246, 248, 251, 258, 262, 268, 297, 304, 305, 306, 315, 316, 325, 326, 327, 328, 330, 331, 332, 337, 342, 344, 345, 352, 366, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 620, 621, 623, 625, 627, 635, 636, 637, 639, 641], "mask": [2, 16, 18, 22, 23, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 87, 89, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 195, 196, 215, 251, 287, 297, 298, 301, 306, 313, 314, 326, 329, 332, 337, 358, 371, 376, 380, 384, 409, 412, 592, 594, 621, 623, 624, 633, 642], "point": [2, 19, 22, 51, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 70, 71, 74, 75, 76, 77, 82, 88, 94, 101, 102, 104, 114, 115, 118, 119, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 275, 276, 277, 278, 279, 324, 326, 332, 337, 344, 359, 376, 378, 380, 383, 384, 416, 591, 614, 616, 621, 622, 634, 635, 636, 637, 639, 641, 642], "boolean": [2, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 108, 109, 130, 180, 213, 217, 226, 251, 263, 306, 312, 592, 623], "repres": [2, 17, 19, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 60, 63, 71, 72, 81, 86, 87, 96, 120, 123, 124, 125, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 237, 251, 267, 279, 297, 298, 306, 313, 314, 320, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 386, 412, 600, 620, 622, 623, 624, 625, 626, 627, 635, 636], "valid": [2, 7, 19, 56, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 166, 170, 171, 172, 175, 178, 179, 180, 217, 251, 270, 272, 286, 288, 305, 306, 312, 326, 329, 351, 358, 365, 368, 371, 378, 380, 386, 387, 388, 389, 412, 624, 642], "valu": [2, 7, 17, 18, 19, 21, 22, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 101, 102, 108, 109, 114, 120, 123, 126, 130, 131, 138, 141, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 203, 206, 211, 212, 213, 214, 217, 219, 221, 222, 224, 227, 229, 230, 231, 232, 233, 239, 245, 246, 250, 251, 254, 255, 256, 258, 260, 262, 265, 266, 270, 271, 272, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 290, 291, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 310, 312, 313, 314, 318, 319, 320, 321, 322, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 342, 344, 345, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 393, 405, 406, 408, 409, 410, 411, 412, 416, 420, 470, 473, 560, 590, 599, 606, 621, 624, 627, 628, 629, 634, 635, 636, 637, 639, 641, 642], "exploration_typ": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 410, 468, 620, 621], "explor": [2, 7, 281, 286, 297, 298, 301, 312, 313, 314, 339, 340, 342, 344, 345, 349, 366, 368, 410, 421, 555, 556, 560, 590, 599, 622, 623, 624, 625, 627, 628, 630, 635, 636, 637], "reset_when_don": [2, 32, 34, 35, 36, 38], "its": [2, 6, 17, 18, 19, 21, 22, 23, 24, 26, 28, 30, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 72, 74, 75, 76, 77, 86, 87, 88, 95, 97, 101, 102, 108, 109, 120, 123, 126, 130, 137, 138, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 220, 221, 227, 233, 241, 263, 264, 265, 270, 272, 278, 279, 280, 282, 286, 288, 297, 302, 304, 306, 307, 313, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 348, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 416, 420, 421, 560, 566, 571, 574, 575, 587, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 635, 636, 637, 638, 639, 641, 642], "within": [2, 20, 21, 22, 32, 35, 36, 38, 41, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 96, 101, 102, 109, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 280, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 345, 348, 354, 359, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 391, 393, 402, 416, 613, 621, 624, 625, 626, 627, 628, 629, 630, 635, 637, 641], "how": [2, 5, 6, 13, 17, 19, 21, 30, 41, 42, 44, 47, 65, 72, 83, 86, 87, 88, 101, 102, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 242, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 349, 351, 365, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 395, 416, 418, 579, 583, 590, 591, 620, 621, 622, 623, 624, 625, 626, 628, 629, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "tabl": [2, 380, 621, 626], "summar": [2, 17, 187, 637], "what": [2, 7, 18, 19, 21, 22, 27, 30, 35, 36, 38, 65, 74, 78, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 195, 196, 212, 233, 265, 270, 313, 352, 363, 366, 372, 376, 378, 380, 384, 591, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 632, 633, 635, 636, 637, 638, 639, 641, 642], "expect": [2, 5, 6, 8, 17, 18, 21, 22, 23, 26, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 81, 86, 87, 88, 102, 107, 108, 120, 123, 126, 130, 138, 144, 147, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 214, 218, 219, 220, 221, 222, 223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 238, 240, 241, 242, 243, 244, 246, 248, 250, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 298, 302, 304, 312, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 347, 349, 350, 351, 352, 353, 354, 356, 357, 358, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 554, 591, 613, 620, 622, 623, 625, 626, 627, 628, 632, 633, 635, 636, 637, 639, 642], "n": [2, 4, 6, 17, 19, 25, 26, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 101, 102, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 231, 236, 274, 312, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 345, 349, 350, 358, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 412, 481, 592, 621, 623, 624, 633, 639, 641, 642], "b": [2, 22, 26, 27, 52, 56, 60, 68, 71, 72, 73, 86, 87, 95, 96, 114, 123, 176, 197, 201, 239, 273, 325, 326, 327, 328, 330, 331, 332, 337, 348, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 393, 621, 632, 639], "cat_result": [2, 4, 35, 36, 38], "na": [2, 172, 175, 193], "t": [2, 4, 12, 21, 22, 23, 25, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 92, 101, 102, 107, 108, 109, 114, 120, 123, 126, 127, 129, 130, 138, 145, 146, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 239, 240, 241, 243, 249, 250, 251, 252, 253, 254, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 277, 278, 279, 282, 297, 302, 304, 306, 312, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 344, 349, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 393, 401, 416, 419, 564, 581, 591, 592, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 634, 635, 636, 637, 638, 639, 641, 642], "p": [2, 23, 69, 101, 102, 106, 127, 156, 157, 287, 317], "In": [2, 3, 4, 6, 7, 8, 12, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 51, 52, 78, 79, 81, 83, 84, 85, 86, 87, 88, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 229, 230, 232, 240, 250, 255, 259, 264, 265, 268, 270, 271, 272, 275, 277, 278, 280, 282, 303, 305, 316, 320, 321, 325, 326, 327, 328, 330, 331, 332, 337, 344, 345, 347, 349, 350, 352, 353, 354, 356, 357, 358, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 419, 562, 563, 564, 586, 587, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 635, 636, 637, 638, 639, 642], "case": [2, 4, 6, 7, 15, 18, 19, 20, 21, 22, 23, 24, 26, 27, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 92, 93, 100, 114, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 195, 197, 229, 230, 232, 240, 246, 265, 268, 272, 273, 282, 286, 304, 305, 325, 327, 328, 330, 331, 342, 344, 345, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 393, 403, 406, 419, 562, 563, 564, 592, 593, 620, 621, 622, 623, 624, 625, 626, 628, 629, 633, 635, 636, 637, 639, 641, 642], "dimens": [2, 4, 17, 18, 19, 22, 34, 35, 36, 38, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 79, 81, 83, 84, 85, 86, 87, 95, 96, 97, 102, 108, 109, 114, 116, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 177, 178, 179, 180, 185, 205, 206, 214, 220, 221, 222, 236, 244, 246, 248, 251, 258, 261, 262, 265, 268, 274, 279, 280, 288, 289, 294, 295, 297, 302, 304, 305, 306, 308, 311, 315, 316, 319, 320, 325, 327, 328, 330, 331, 332, 337, 338, 341, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 564, 592, 620, 621, 622, 623, 625, 632, 635, 636, 637, 639], "time": [2, 4, 5, 7, 17, 22, 23, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 56, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 92, 95, 114, 120, 121, 122, 123, 126, 127, 130, 136, 137, 138, 141, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 212, 220, 221, 222, 244, 251, 258, 265, 266, 267, 270, 272, 279, 287, 299, 304, 312, 317, 325, 326, 327, 328, 330, 331, 332, 337, 341, 345, 350, 351, 352, 358, 361, 364, 365, 366, 368, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 416, 420, 473, 526, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 576, 577, 579, 581, 587, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 635, 636, 637, 639, 641, 642], "adapt": [2, 4, 215, 244, 263, 279, 324, 358, 365, 371, 592, 620, 624, 637], "equal": [2, 32, 35, 36, 38, 78, 88, 102, 108, 109, 123, 145, 148, 149, 150, 158, 178, 245, 246, 288, 302, 304, 305, 306, 351, 368, 380, 406, 562, 563, 620, 622, 638], "i": [2, 5, 6, 17, 19, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 60, 65, 68, 71, 73, 86, 87, 88, 90, 91, 95, 97, 101, 102, 108, 109, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 228, 244, 250, 255, 258, 270, 272, 277, 298, 302, 304, 307, 314, 325, 326, 327, 328, 330, 331, 332, 337, 341, 342, 344, 345, 349, 351, 352, 353, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 406, 553, 573, 592, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 635, 636, 637, 639, 641, 642], "introduc": [2, 101, 102, 150, 158, 302, 304, 312, 620, 635], "some": [2, 6, 8, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 51, 57, 58, 59, 60, 61, 62, 63, 64, 66, 68, 69, 70, 71, 74, 75, 76, 77, 79, 85, 86, 87, 88, 90, 95, 97, 114, 116, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 203, 217, 250, 265, 272, 275, 290, 302, 325, 326, 327, 328, 330, 331, 332, 337, 345, 346, 347, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 406, 553, 566, 568, 571, 572, 574, 576, 577, 579, 581, 587, 592, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 635, 636, 637, 639, 641, 642], "confus": [2, 57, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 326, 332, 337, 376, 378, 380, 383, 384], "other": [2, 3, 5, 6, 7, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 30, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 74, 75, 76, 77, 78, 79, 81, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 106, 107, 108, 109, 110, 112, 116, 120, 123, 126, 129, 130, 131, 135, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 224, 226, 230, 231, 252, 259, 265, 268, 275, 279, 280, 298, 301, 302, 304, 307, 314, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 345, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 391, 402, 404, 409, 412, 562, 563, 567, 575, 586, 587, 590, 592, 606, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 635, 636, 637, 638, 641, 642], "better": [2, 6, 19, 22, 27, 28, 34, 35, 36, 38, 54, 55, 56, 137, 170, 171, 172, 175, 177, 189, 302, 304, 324, 333, 337, 592, 622, 625, 637, 641], "consist": [2, 5, 16, 17, 18, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 80, 83, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 278, 288, 305, 326, 332, 337, 376, 378, 380, 383, 384, 585, 588, 596, 613, 620, 621, 622, 633, 637, 638, 642], "interact": [2, 20, 21, 23, 24, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 83, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 181, 184, 272, 342, 345, 421, 592, 620, 622, 624, 625, 626, 628, 635, 636, 637, 642], "separ": [2, 4, 6, 7, 23, 27, 32, 34, 35, 36, 38, 42, 47, 50, 52, 56, 60, 68, 71, 72, 73, 78, 80, 86, 87, 176, 183, 221, 250, 277, 324, 325, 327, 328, 330, 331, 350, 353, 356, 358, 369, 371, 372, 373, 377, 379, 381, 382, 385, 386, 402, 580, 592, 613, 620, 621, 626, 627, 635, 636, 639, 642], "interchang": [2, 622, 625, 629, 633, 638, 639], "wherea": [2, 51, 52, 63, 83, 88, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 231, 270, 272, 326, 332, 337, 352, 366, 371, 376, 378, 380, 383, 384, 629], "correspond": [2, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 72, 74, 75, 76, 77, 80, 83, 85, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 250, 265, 270, 272, 277, 279, 280, 301, 302, 304, 306, 312, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 352, 354, 357, 358, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 403, 565, 620, 621, 622, 624, 625, 627, 628, 629, 635, 636, 637, 638], "sub": [2, 3, 6, 21, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 71, 78, 83, 88, 108, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 251, 270, 271, 280, 326, 332, 337, 346, 347, 376, 378, 380, 383, 384, 406, 416, 566, 568, 571, 572, 574, 576, 579, 581, 587, 620, 621, 622, 628, 634, 641, 642], "doesn": [2, 23, 32, 35, 36, 38, 88, 114, 120, 123, 126, 130, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 282, 326, 329, 332, 337, 376, 378, 380, 383, 384, 581, 624, 625], "understood": [2, 620], "basi": [2, 114, 639, 641], "we": [2, 6, 12, 17, 18, 19, 21, 22, 24, 26, 28, 30, 53, 54, 56, 60, 65, 68, 72, 73, 78, 79, 83, 85, 88, 95, 107, 109, 114, 120, 121, 122, 123, 126, 127, 130, 134, 136, 137, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 226, 241, 250, 253, 259, 270, 275, 278, 279, 280, 282, 304, 306, 324, 326, 332, 337, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 393, 420, 565, 568, 576, 591, 592, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 634, 635, 636, 637, 638, 639, 641, 642], "anoth": [2, 18, 21, 22, 27, 37, 39, 40, 41, 46, 49, 54, 74, 83, 87, 96, 102, 108, 120, 123, 126, 129, 130, 131, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 196, 218, 227, 229, 230, 232, 265, 271, 305, 342, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 403, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 417, 419, 620, 622, 623, 624, 626, 627, 634, 635, 636, 637, 642], "wise": [2, 244, 380], "requir": [2, 4, 6, 17, 18, 22, 23, 26, 27, 32, 34, 35, 36, 37, 38, 39, 40, 42, 44, 46, 47, 49, 50, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 81, 83, 86, 87, 88, 96, 101, 102, 108, 109, 120, 123, 126, 130, 134, 138, 145, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 225, 226, 239, 250, 262, 265, 270, 271, 272, 275, 277, 280, 302, 304, 305, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 344, 345, 346, 347, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 391, 393, 395, 404, 419, 420, 473, 581, 586, 587, 592, 620, 621, 622, 623, 625, 626, 627, 629, 632, 633, 635, 636, 637, 639, 641, 642], "method": [2, 6, 16, 20, 21, 22, 23, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 108, 109, 110, 111, 112, 114, 116, 120, 123, 126, 129, 130, 131, 132, 137, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 209, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 233, 234, 235, 236, 237, 240, 241, 243, 244, 246, 249, 250, 251, 252, 253, 254, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 295, 297, 298, 301, 302, 304, 313, 314, 317, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 343, 344, 345, 346, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 363, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 391, 392, 402, 403, 409, 421, 561, 565, 566, 567, 568, 569, 571, 572, 573, 574, 575, 576, 579, 580, 581, 583, 585, 587, 590, 606, 613, 618, 621, 622, 623, 624, 625, 626, 627, 628, 629, 632, 635, 637, 639, 642], "op": [2, 6, 7, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 57, 58, 59, 61, 62, 63, 64, 74, 75, 76, 77, 186, 245, 278, 286, 301, 393, 419, 565, 567, 569, 570, 575, 577, 585], "sinc": [2, 3, 6, 19, 21, 23, 24, 26, 30, 32, 34, 35, 36, 38, 41, 52, 53, 54, 56, 65, 68, 72, 73, 78, 85, 86, 87, 88, 101, 102, 109, 114, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 155, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 208, 212, 227, 286, 287, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 348, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 393, 566, 568, 571, 572, 573, 574, 576, 579, 581, 587, 592, 620, 621, 622, 623, 625, 626, 627, 632, 635, 637, 638, 639, 641, 642], "goal": [2, 17, 23, 78, 79, 80, 81, 82, 83, 84, 85, 138, 179, 264, 620, 621, 622, 623, 632, 636, 637], "policy_devic": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 621], "explicitli": [2, 22, 23, 59, 69, 89, 92, 93, 100, 217, 342, 405, 613, 621, 623, 628, 635, 636, 639], "do": [2, 5, 6, 17, 21, 22, 23, 26, 63, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 177, 178, 179, 180, 193, 195, 196, 212, 214, 226, 251, 265, 270, 278, 279, 284, 302, 304, 345, 366, 376, 378, 380, 384, 386, 393, 586, 587, 592, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 634, 635, 636, 637, 639, 641, 642], "deepcopi": [2, 366, 376, 378, 380, 384, 635], "structur": [2, 6, 7, 12, 16, 17, 22, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 63, 65, 68, 72, 73, 74, 86, 87, 96, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 185, 195, 196, 202, 213, 229, 232, 265, 312, 325, 326, 327, 328, 330, 331, 332, 337, 349, 358, 368, 371, 377, 379, 381, 382, 385, 386, 387, 388, 389, 390, 424, 592, 599, 606, 613, 620, 622, 623, 625, 628, 635, 636, 637, 638], "place": [2, 7, 21, 22, 40, 60, 69, 71, 86, 87, 88, 95, 97, 106, 108, 116, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 217, 225, 233, 250, 265, 271, 272, 275, 277, 278, 279, 325, 326, 327, 328, 329, 330, 331, 332, 337, 341, 344, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 412, 419, 553, 566, 568, 569, 571, 572, 574, 575, 576, 578, 579, 581, 583, 585, 587, 592, 621, 622, 626, 629, 635, 636, 637, 639], "instanti": [2, 6, 7, 17, 22, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 101, 102, 134, 137, 150, 158, 176, 180, 217, 225, 239, 265, 325, 327, 328, 330, 331, 339, 377, 379, 381, 382, 385, 386, 387, 388, 389, 390, 391, 402, 403, 420, 464, 465, 468, 469, 470, 613, 620, 621, 626, 627, 629, 635, 636, 637, 639, 642], "graph": [2, 21, 23, 27, 86, 87, 121, 122, 136, 137, 176, 189, 303, 320, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 384, 385, 620, 624, 637], "reli": [2, 6, 17, 30, 56, 265, 302, 304, 335, 336, 349, 368, 386, 418, 620, 622, 624, 626, 628, 637, 642], "third": [2, 246, 267, 298, 635, 636], "parti": 2, "try": [2, 23, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 60, 71, 86, 87, 176, 325, 326, 327, 328, 330, 331, 332, 337, 377, 379, 381, 382, 385, 592, 620, 621, 622, 624, 627, 628, 633, 635, 636, 637, 641, 642], "limit": [2, 5, 7, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 189, 195, 196, 221, 241, 349, 351, 365, 366, 368, 370, 376, 378, 380, 384, 592, 613, 620, 621, 623, 635, 636, 637], "chart": 2, "show": [2, 7, 30, 35, 36, 38, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 324, 326, 332, 337, 376, 378, 380, 383, 384, 393, 420, 421, 473, 620, 622, 623, 624, 632, 635, 636, 637, 639, 641], "decis": [2, 18, 19, 289, 294, 311, 355, 367, 623, 625, 626, 635, 636, 639, 642], "tree": [2, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 221, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 635, 639], "These": [3, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 80, 85, 117, 163, 250, 277, 280, 376, 378, 380, 384, 592, 599, 606, 613, 620, 622, 635, 636, 637, 639, 642], "gloo": [3, 42, 44, 47, 51, 566, 572, 573, 574], "nccl": [3, 42, 44, 47, 324, 335, 336, 566, 572, 573, 574, 580, 581, 585, 586, 587], "mpi": [3, 42, 44, 47], "launcher": [3, 42, 44, 47, 51], "submitit": [3, 42, 44, 47, 51], "torch": [3, 6, 10, 17, 18, 19, 21, 22, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 104, 107, 108, 109, 114, 115, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 213, 214, 215, 217, 218, 219, 220, 222, 225, 226, 227, 229, 230, 231, 232, 233, 234, 239, 241, 242, 243, 246, 248, 250, 252, 253, 255, 257, 258, 259, 260, 262, 263, 264, 265, 266, 268, 271, 272, 273, 275, 277, 279, 280, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 324, 325, 326, 327, 328, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 395, 406, 413, 414, 421, 464, 465, 468, 469, 470, 489, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 560, 565, 566, 570, 571, 572, 573, 574, 579, 580, 585, 586, 587, 592, 599, 614, 620, 621, 622, 623, 624, 626, 627, 628, 630, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "multiprocess": [3, 5, 6, 22, 35, 36, 37, 38, 42, 44, 47, 50, 68, 69, 72, 73, 78, 85, 95, 96, 97, 98, 120, 127, 128, 150, 154, 158, 279, 280, 565, 566, 567, 568, 571, 573, 574, 575, 613, 620, 621, 622, 623, 628, 635, 636, 637, 638, 642], "mode": [3, 21, 25, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 123, 126, 130, 135, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 264, 272, 279, 280, 295, 302, 303, 304, 310, 317, 319, 320, 321, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 351, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 405, 410, 523, 592, 606, 613, 620, 621, 635, 636, 641, 642], "find": [3, 23, 25, 26, 42, 44, 47, 65, 108, 109, 183, 286, 312, 403, 409, 413, 585, 620, 621, 624, 626, 627, 632, 635, 636], "folder": [3, 86, 87, 163, 176, 221, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 621], "variou": [3, 10, 15, 19, 21, 22, 37, 123, 271, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 374, 376, 378, 380, 384, 393, 562, 563, 594, 616, 620, 621, 622, 624, 625, 626, 627, 629, 635, 636, 639, 642], "machin": [3, 26, 42, 44, 47, 82, 134, 581, 635, 636, 641], "One": [3, 4, 6, 22, 23, 27, 57, 59, 60, 62, 64, 71, 114, 120, 121, 122, 150, 154, 158, 159, 221, 255, 275, 286, 310, 344, 348, 397, 613, 620, 621, 639, 642], "wonder": 3, "why": [3, 22, 212, 635, 637, 642], "instead": [3, 21, 22, 23, 26, 27, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 52, 53, 54, 57, 59, 66, 83, 86, 87, 88, 101, 102, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 236, 282, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 316, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 344, 348, 349, 351, 352, 354, 357, 358, 359, 364, 365, 368, 369, 370, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 390, 564, 623, 624, 625, 626, 630, 637, 639, 642], "gener": [3, 5, 6, 16, 17, 21, 22, 26, 27, 28, 32, 34, 35, 36, 38, 42, 44, 47, 50, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 105, 107, 120, 123, 126, 127, 130, 138, 142, 143, 144, 147, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 213, 215, 218, 225, 227, 229, 230, 234, 239, 241, 244, 246, 252, 253, 258, 259, 263, 265, 269, 271, 273, 278, 280, 287, 295, 302, 304, 306, 310, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 337, 340, 342, 345, 363, 369, 377, 379, 380, 381, 382, 383, 384, 385, 386, 396, 409, 416, 431, 592, 594, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "lower": [3, 15, 22, 50, 58, 101, 102, 224, 279, 280, 315, 316, 348, 368, 622, 635, 637], "io": [3, 30, 78, 83, 136, 137, 145, 148, 149, 161, 162, 202, 624], "footprint": [3, 639], "need": [3, 4, 6, 7, 17, 18, 19, 20, 21, 22, 23, 26, 27, 29, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 65, 68, 69, 72, 73, 74, 86, 87, 88, 95, 110, 114, 120, 123, 126, 130, 134, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 224, 226, 227, 236, 242, 250, 253, 266, 270, 271, 272, 277, 279, 280, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 313, 314, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 341, 342, 344, 348, 358, 370, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 393, 402, 416, 564, 573, 575, 587, 592, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 635, 636, 637, 639, 641, 642], "commun": [3, 18, 22, 46, 49, 86, 87, 138, 150, 154, 158, 176, 179, 324, 325, 327, 328, 330, 331, 335, 336, 377, 379, 381, 382, 385, 565, 568, 570, 573, 575, 577, 579, 580, 585, 586, 587, 591, 613, 622, 642], "yet": [3, 6, 121, 122, 136, 330, 331, 383, 638], "spec": [3, 16, 19, 22, 34, 35, 36, 38, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 87, 88, 120, 121, 122, 123, 126, 128, 129, 130, 131, 132, 135, 136, 137, 138, 144, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 209, 212, 213, 214, 215, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 232, 233, 234, 236, 238, 240, 241, 242, 243, 244, 246, 248, 250, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 286, 297, 298, 301, 302, 304, 312, 313, 314, 316, 325, 327, 328, 330, 331, 339, 340, 342, 343, 344, 345, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 383, 592, 599, 620, 621, 622, 623, 624, 625, 626, 630, 632, 634, 635, 636, 641], "plai": [3, 19, 152, 153, 160, 170, 221, 621, 622, 627, 639, 642], "role": [3, 19, 87, 89, 143, 170, 172, 175, 183, 190, 195, 196, 197, 332, 337, 384, 621, 627, 633, 642], "opposit": [3, 635], "direct": [3, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 366, 376, 378, 380, 383, 384, 621, 627, 633], "vector": [3, 16, 21, 27, 57, 64, 121, 122, 131, 136, 137, 141, 152, 153, 155, 163, 164, 231, 278, 280, 290, 292, 305, 386, 389, 590, 620, 621, 623, 634, 635, 636, 637, 638, 642], "share": [3, 6, 7, 15, 19, 21, 25, 27, 32, 34, 35, 36, 38, 50, 52, 56, 68, 69, 72, 73, 74, 86, 87, 90, 93, 95, 96, 97, 98, 102, 104, 108, 110, 112, 116, 127, 150, 158, 171, 172, 175, 176, 185, 192, 193, 194, 195, 262, 270, 279, 280, 283, 284, 285, 302, 304, 325, 327, 328, 330, 331, 349, 350, 351, 352, 353, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 377, 379, 381, 382, 385, 403, 431, 466, 468, 469, 470, 564, 566, 567, 568, 569, 571, 572, 573, 574, 575, 576, 579, 581, 582, 583, 584, 587, 592, 613, 622, 624, 630, 632, 633, 634, 635, 636, 641, 642], "among": [3, 18, 63, 152, 153, 270, 358, 371, 635, 636], "achiev": [3, 4, 21, 23, 88, 120, 123, 126, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 264, 287, 326, 332, 337, 342, 376, 378, 380, 383, 384, 412, 620, 621, 622, 623, 624, 632, 635, 636, 637, 639, 641, 642], "prohibit": [3, 21, 114], "slow": [3, 22, 23, 30, 86, 87, 96, 108, 109, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "compar": [3, 21, 22, 83, 114, 350, 352, 364, 369, 371, 372, 373, 410, 613, 620, 622, 624, 626, 627, 635, 636, 639, 642], "gpu": [3, 26, 27, 53, 55, 88, 95, 97, 116, 120, 123, 126, 130, 131, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 243, 324, 326, 329, 332, 333, 334, 337, 376, 378, 380, 383, 384, 402, 580, 586, 587, 620, 622, 623, 635, 636, 642], "nativ": [3, 6, 16, 26, 28, 81, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 324, 337, 393, 623, 639], "driver": [3, 26], "mean": [3, 5, 6, 7, 17, 19, 21, 22, 23, 26, 32, 34, 35, 36, 38, 39, 42, 44, 47, 50, 52, 72, 74, 78, 86, 87, 96, 101, 102, 108, 109, 114, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 183, 217, 246, 270, 279, 280, 286, 295, 299, 302, 304, 311, 319, 320, 325, 327, 328, 330, 331, 342, 345, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 377, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 409, 420, 566, 567, 568, 571, 572, 574, 576, 577, 579, 581, 587, 620, 621, 622, 624, 626, 635, 636, 637, 639, 642], "keyword": [3, 6, 21, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 93, 95, 96, 97, 98, 101, 102, 106, 108, 109, 112, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 206, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 244, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 286, 287, 297, 301, 302, 304, 306, 312, 313, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 340, 341, 342, 344, 345, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 398, 400, 401, 403, 416, 420, 421, 561, 620, 621, 622, 624, 626, 629, 635, 636, 639, 641, 642], "given": [3, 4, 12, 22, 35, 36, 38, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 109, 120, 123, 126, 130, 138, 144, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 225, 231, 239, 246, 250, 265, 269, 271, 272, 273, 275, 277, 279, 280, 286, 287, 297, 298, 299, 301, 302, 304, 314, 317, 318, 322, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 344, 345, 346, 347, 353, 354, 356, 366, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 403, 407, 410, 560, 620, 621, 622, 625, 626, 627, 628, 629, 636, 637, 642], "mani": [3, 7, 16, 18, 19, 22, 23, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 68, 86, 87, 121, 122, 124, 125, 126, 129, 131, 132, 136, 137, 145, 146, 155, 176, 178, 183, 185, 265, 325, 327, 328, 330, 331, 349, 351, 358, 365, 368, 377, 379, 380, 381, 382, 385, 418, 568, 613, 620, 621, 622, 624, 625, 626, 628, 630, 635, 636, 637, 639, 641, 642], "eg": [3, 17, 22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 124, 125, 126, 129, 130, 131, 132, 134, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 231, 263, 272, 282, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 393], "gymnasium": [3, 17, 18, 22, 24, 32, 34, 35, 36, 38, 52, 120, 123, 126, 129, 130, 131, 135, 138, 139, 140, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 175, 178, 179, 180, 211, 234, 259, 263, 278, 282, 446, 621, 622, 624, 637, 641], "warn": [3, 22, 35, 36, 38, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 272, 279, 286, 301, 312, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 405, 621, 632, 633], "quickli": [3, 22, 621, 635, 636, 642], "becom": [3, 22, 23, 50, 402, 403, 613, 635, 636, 642], "quit": [3, 22, 30, 78, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 620, 621, 622, 624, 626, 635, 636, 642], "annoi": [3, 22], "By": [3, 17, 21, 22, 34, 37, 39, 40, 41, 46, 49, 60, 64, 71, 88, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 142, 143, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 244, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 345, 366, 376, 378, 380, 383, 384, 405, 410, 564, 592, 620, 623, 635, 638, 639, 642], "filter": [3, 21, 22, 23, 102, 108, 109, 349, 350, 352, 353, 357, 358, 364, 368, 369, 371, 380, 402, 625], "out": [3, 17, 19, 21, 22, 23, 24, 28, 37, 39, 40, 41, 46, 49, 50, 54, 55, 79, 83, 86, 87, 88, 93, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 262, 265, 286, 297, 298, 306, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 344, 345, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 620, 621, 622, 623, 624, 625, 626, 628, 635, 636, 637, 639, 641, 642], "still": [3, 17, 22, 28, 75, 83, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 270, 272, 312, 326, 332, 337, 365, 366, 376, 378, 380, 384, 592, 620, 621, 623, 634, 637, 639, 642], "wish": [3, 22, 30, 32, 35, 36, 38, 83, 211, 627, 639], "displai": [3, 22, 26, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 416, 620, 621, 632, 636, 637], "filter_warnings_subprocess": [3, 22], "simplest": [4, 114, 326, 332, 337, 348, 376, 378, 380, 384, 620, 622, 626, 635, 636, 639, 642], "transit": [4, 35, 36, 38, 79, 83, 88, 102, 109, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 317, 323, 326, 332, 337, 376, 378, 380, 383, 384, 620, 623, 625, 626, 628, 635, 637, 639], "sampl": [4, 5, 7, 10, 15, 23, 27, 28, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 95, 96, 97, 101, 102, 103, 106, 107, 108, 109, 112, 114, 116, 120, 123, 126, 130, 138, 144, 147, 150, 151, 154, 158, 159, 160, 167, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 210, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 280, 286, 295, 297, 298, 301, 303, 306, 310, 311, 312, 313, 314, 315, 316, 317, 320, 321, 326, 329, 332, 337, 340, 342, 344, 345, 349, 350, 351, 352, 353, 354, 356, 365, 367, 368, 372, 373, 376, 380, 383, 406, 412, 416, 418, 421, 429, 430, 433, 434, 435, 475, 553, 590, 620, 621, 622, 623, 624, 625, 626, 628, 630, 635, 636, 638, 641, 642], "attent": [4, 27, 178, 221, 326, 332, 337, 380, 620, 623, 633, 642], "built": [4, 7, 10, 16, 17, 21, 24, 26, 69, 86, 87, 121, 122, 129, 136, 137, 147, 148, 176, 317, 325, 327, 328, 330, 331, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 384, 385, 558, 560, 561, 564, 592, 599, 613, 620, 621, 622, 623, 624, 627, 629, 632, 637, 639, 642], "flatten": [4, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 114, 176, 218, 236, 325, 327, 328, 330, 331, 338, 377, 379, 381, 382, 383, 385, 386, 412, 582, 583, 592, 636], "suffici": [4, 18, 23, 620], "preprocess": [4, 10, 16, 78, 79, 80, 81, 82, 83, 84, 85, 271, 621, 624], "popul": [4, 17, 34, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 178, 240, 265, 295, 366, 376, 378, 380, 384, 620, 622, 623, 626, 628, 637, 639], "replaybuff": [4, 10, 12, 21, 32, 34, 35, 36, 38, 50, 52, 53, 65, 66, 67, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 95, 96, 101, 102, 103, 108, 109, 118, 221, 251, 255, 354, 359, 402, 420, 421, 431, 558, 560, 622, 624, 628, 630, 635, 636, 638, 639, 641], "lazytensorstorag": [4, 10, 12, 32, 34, 35, 36, 38, 52, 65, 68, 72, 73, 101, 108, 109, 114, 255, 421, 427, 622, 624, 630, 635, 636, 639], "lambda": [4, 6, 32, 34, 35, 36, 38, 50, 51, 52, 53, 68, 114, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 183, 211, 218, 226, 227, 239, 241, 265, 273, 280, 282, 287, 297, 313, 326, 332, 337, 341, 342, 360, 362, 363, 372, 376, 378, 380, 384, 386, 389, 391, 419, 420, 560, 568, 585, 592, 620, 621, 623, 624, 635, 636, 638, 639, 641, 642], "reshap": [4, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 108, 114, 218, 302, 304, 305, 391, 592, 622, 635, 636], "extend": [4, 7, 10, 27, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 94, 95, 98, 101, 102, 104, 108, 109, 112, 114, 115, 118, 119, 170, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 220, 255, 271, 366, 376, 378, 380, 383, 384, 412, 420, 585, 586, 592, 594, 602, 620, 621, 622, 624, 628, 630, 635, 636, 638, 639, 641], "slice": [4, 10, 17, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 83, 102, 108, 109, 214, 220, 221, 325, 434, 435, 623, 639], "recommend": [4, 5, 23, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 68, 72, 73, 86, 87, 108, 114, 134, 150, 158, 170, 171, 172, 175, 176, 189, 221, 324, 325, 327, 328, 330, 331, 332, 335, 336, 337, 351, 368, 377, 378, 379, 380, 381, 382, 385, 592, 613, 628, 633, 635, 636], "multidimension": [4, 72, 101, 102, 639], "slicesampl": [4, 10, 78, 102, 109, 221, 434, 623, 639], "sampler": [4, 7, 10, 13, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 95, 96, 97, 98, 101, 102, 103, 106, 107, 108, 109, 110, 112, 114, 116, 221, 251, 354, 359, 431, 438, 620, 622, 623, 635, 636, 639], "ensur": [4, 7, 17, 21, 33, 42, 43, 44, 45, 46, 47, 48, 49, 65, 72, 88, 101, 102, 107, 120, 123, 126, 130, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 221, 250, 263, 272, 275, 279, 280, 297, 302, 304, 324, 326, 332, 337, 351, 365, 368, 376, 378, 380, 383, 384, 402, 566, 568, 569, 571, 572, 574, 579, 580, 581, 585, 587, 588, 592, 596, 613, 621, 622, 623, 637, 639], "clearli": 4, "dimension": [4, 65, 68, 72, 73, 178, 231, 302, 304, 386, 636], "num_slic": [4, 78, 83, 102, 108, 109, 434, 435, 639], "trajectory_kei": [4, 56, 108, 109], "traj_id": [4, 17, 34, 35, 38, 52, 56, 218, 255, 628, 639], "dim": [4, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 108, 176, 190, 205, 221, 222, 244, 248, 261, 262, 265, 274, 279, 325, 327, 328, 330, 331, 341, 377, 379, 381, 382, 385, 481, 482, 503, 507, 520, 521, 525, 532, 564, 592, 621, 622, 624, 635, 637, 639], "ndim": [4, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 95, 97, 101, 102, 114, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 244, 341, 425, 427, 439], "regular": [4, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 86, 87, 88, 101, 106, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 296, 298, 302, 304, 313, 314, 325, 327, 328, 329, 330, 331, 344, 345, 359, 368, 377, 379, 381, 382, 383, 384, 385, 419, 420, 421, 620, 621, 624, 625, 626, 630, 632, 639, 642], "behav": [4, 22, 132, 144, 310, 357, 364, 366, 376, 378, 380, 384, 624, 638], "accordingli": [4, 22, 86, 87, 102, 174, 176, 227, 244, 263, 264, 313, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 623], "3": [4, 18, 19, 20, 22, 25, 26, 29, 30, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 97, 101, 102, 108, 109, 114, 116, 120, 123, 124, 125, 126, 129, 130, 131, 132, 133, 138, 141, 142, 143, 145, 147, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 206, 215, 217, 218, 221, 225, 226, 227, 231, 233, 234, 239, 241, 246, 248, 250, 252, 253, 255, 258, 259, 262, 263, 264, 265, 268, 270, 271, 272, 273, 275, 277, 280, 282, 283, 284, 285, 287, 288, 290, 291, 292, 294, 297, 298, 300, 302, 303, 304, 305, 306, 307, 310, 314, 320, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 339, 340, 342, 343, 344, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 393, 402, 414, 464, 481, 504, 566, 567, 568, 570, 571, 572, 573, 574, 576, 579, 581, 587, 599, 613, 619, 620, 621, 622, 623, 625, 626, 628, 629, 635, 636, 637, 639, 640, 641, 642], "isn": [4, 22, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 83, 86, 87, 101, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 217, 233, 239, 297, 325, 327, 328, 330, 331, 344, 377, 379, 381, 382, 385, 386, 626, 627, 629, 635, 636], "fulli": [4, 6, 27, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 621, 624, 627, 637, 639], "ani": [4, 6, 7, 12, 17, 18, 19, 21, 22, 24, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 94, 95, 96, 97, 98, 104, 107, 109, 110, 112, 114, 115, 116, 118, 119, 120, 123, 126, 127, 130, 131, 138, 145, 150, 151, 152, 153, 154, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 213, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 236, 237, 239, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 280, 282, 287, 288, 294, 295, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 345, 346, 347, 349, 350, 351, 352, 353, 354, 356, 357, 358, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 389, 391, 393, 398, 402, 403, 409, 416, 418, 419, 420, 425, 427, 431, 434, 435, 436, 437, 438, 439, 440, 442, 446, 450, 464, 465, 466, 468, 469, 470, 472, 473, 478, 485, 486, 487, 524, 531, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 584, 585, 586, 587, 591, 613, 620, 621, 622, 623, 624, 626, 627, 632, 635, 636, 637, 639, 641, 642], "consecut": [4, 17, 78, 107, 134, 304, 312, 393, 623, 625, 628, 636, 639, 642], "won": [4, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 83, 86, 87, 88, 120, 123, 126, 127, 129, 130, 138, 145, 146, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 277, 325, 326, 327, 328, 330, 331, 332, 337, 349, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 416, 564, 621, 622, 625, 626], "therebi": [4, 391, 620, 621], "interrupt": [4, 130, 180, 341, 402, 403], "asyncdatacollector": 5, "asynccollector": 5, "_multidatacollector": 5, "It": [5, 7, 17, 20, 21, 22, 23, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 106, 114, 119, 120, 123, 126, 130, 132, 138, 144, 145, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 208, 212, 215, 218, 220, 221, 233, 239, 241, 246, 251, 264, 270, 272, 278, 280, 286, 290, 292, 298, 299, 301, 312, 314, 315, 316, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 345, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 391, 401, 402, 409, 410, 420, 466, 568, 569, 571, 572, 574, 579, 581, 587, 590, 591, 592, 594, 620, 621, 623, 624, 625, 635, 636, 637, 638, 639, 641, 642], "cartpol": [5, 6, 7, 18, 20, 22, 30, 35, 36, 38, 120, 123, 124, 125, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 218, 221, 226, 258, 264, 279, 341, 391, 568, 621, 623, 626, 628, 629, 630, 639, 642], "sync_collector": [5, 35, 36, 38], "1000": [5, 23, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 68, 90, 95, 96, 101, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 279, 286, 301, 312, 342, 345, 421, 528, 568, 620, 621, 622, 623, 624, 626, 628, 630, 633, 637, 638, 639], "100000": [5, 7, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 421, 621], "async_collector": [5, 35, 36, 38], "comparison": [5, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 326, 332, 337, 366, 376, 378, 380, 383, 384, 620, 621], "older": [5, 26, 282], "throughput": [5, 28, 137, 324, 333, 337, 620], "slowest": 5, "higher": [5, 22, 23, 101, 102, 177, 188, 196, 224, 324, 326, 332, 337, 348, 378, 380, 384, 620, 621, 622, 635, 639, 642], "allow": [5, 6, 7, 12, 16, 17, 18, 20, 21, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 63, 64, 68, 69, 70, 71, 72, 73, 78, 83, 86, 87, 88, 89, 96, 102, 106, 108, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 212, 217, 218, 253, 280, 305, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 568, 592, 613, 620, 622, 623, 624, 625, 626, 627, 633, 635, 636, 637, 639, 641, 642], "start": [5, 6, 20, 21, 22, 23, 24, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 66, 74, 78, 85, 101, 102, 108, 109, 120, 123, 126, 127, 130, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 214, 228, 318, 374, 411, 566, 568, 569, 570, 571, 572, 573, 574, 576, 577, 579, 580, 581, 585, 587, 590, 619, 620, 621, 623, 624, 631, 636, 637, 639, 640, 642], "get": [5, 6, 18, 19, 21, 22, 23, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 60, 65, 68, 71, 78, 79, 83, 86, 87, 88, 95, 97, 102, 108, 109, 110, 112, 114, 116, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 188, 190, 194, 195, 196, 201, 215, 220, 222, 226, 229, 231, 232, 241, 246, 251, 264, 265, 268, 272, 279, 280, 301, 313, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 340, 342, 345, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 393, 397, 402, 403, 404, 566, 568, 569, 571, 572, 574, 575, 576, 579, 581, 585, 587, 590, 592, 606, 619, 620, 621, 622, 623, 624, 631, 633, 635, 636, 637, 639, 640, 641, 642], "rid": [5, 326, 332, 337, 376, 378, 380, 384], "natur": [5, 18, 33, 42, 43, 44, 45, 47, 48, 170, 186, 620, 626, 627, 628, 639], "background": [5, 32, 33, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 53, 190, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587, 639], "simpli": [5, 6, 7, 20, 22, 25, 86, 87, 112, 114, 119, 176, 182, 234, 259, 278, 325, 327, 328, 330, 331, 366, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 620, 622, 627, 632, 635, 636, 642], "replay_buff": [5, 7, 27, 32, 34, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 221, 412, 419, 420, 421, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 473, 560, 620, 621, 622, 623, 628, 635, 636, 639], "rb": [5, 32, 34, 35, 36, 38, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 96, 101, 102, 108, 109, 114, 221, 255, 621, 623, 624, 628, 630, 636, 638, 639, 641], "paus": [5, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "sleep": [5, 32, 34, 35, 36, 38, 52, 66, 127, 642], "10": [5, 6, 18, 20, 26, 51, 56, 57, 59, 61, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 101, 108, 109, 114, 116, 120, 121, 122, 123, 126, 127, 130, 136, 137, 138, 144, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 183, 185, 188, 190, 192, 193, 197, 214, 215, 218, 220, 221, 226, 227, 264, 266, 267, 268, 279, 280, 287, 289, 290, 292, 294, 296, 301, 302, 304, 306, 311, 312, 325, 327, 328, 330, 331, 342, 345, 348, 350, 354, 356, 363, 368, 369, 370, 373, 377, 378, 379, 380, 381, 382, 385, 386, 387, 388, 389, 393, 402, 406, 465, 468, 469, 470, 475, 480, 523, 541, 567, 613, 614, 620, 621, 622, 623, 624, 625, 626, 630, 635, 637, 639, 641, 642], "rang": [5, 6, 17, 19, 23, 27, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 97, 114, 120, 123, 126, 127, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 185, 255, 268, 279, 282, 325, 327, 328, 330, 331, 365, 372, 373, 377, 379, 381, 382, 385, 620, 622, 623, 624, 627, 628, 630, 635, 636, 637, 639, 641], "optim_step": [5, 624, 630], "rest": [5, 7, 32, 35, 36, 38, 622, 623, 635, 637, 641], "multithread": [5, 22, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 145, 146, 628, 639], "mind": [5, 21, 22, 78, 83, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 635, 636], "gil": 5, "relat": [5, 19, 22, 23, 29, 60, 65, 150, 175, 236, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 621, 630, 637], "restrict": [5, 22, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 621, 632, 638, 639, 642], "hand": [5, 19, 26, 50, 60, 635, 636, 637], "let": [5, 6, 7, 19, 25, 26, 30, 56, 65, 68, 72, 73, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 297, 326, 332, 337, 376, 378, 380, 383, 384, 410, 592, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "child": [5, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 621], "fill": [5, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 130, 180, 217, 265, 278, 304, 386, 623, 637, 638], "truli": [5, 278, 402, 641], "decoupl": [5, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 52, 620, 627, 641], "been": [5, 18, 24, 26, 27, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 107, 120, 123, 126, 130, 134, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 241, 243, 263, 264, 271, 272, 302, 304, 341, 349, 366, 368, 370, 376, 378, 380, 384, 402, 565, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587, 620, 621, 622, 623, 634, 635, 636, 637, 639, 641, 642], "shut": [5, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 154, 159, 402], "down": [5, 23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 154, 159, 402, 623, 625], "async_shutdown": [5, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 66], "drastic": [5, 6, 137, 150, 639], "hardwar": [5, 17, 624], "load": [5, 6, 25, 26, 32, 34, 35, 36, 38, 52, 53, 54, 55, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 95, 96, 97, 98, 110, 111, 112, 116, 117, 120, 123, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 279, 280, 324, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 416, 418, 420, 421, 564, 583, 592, 595, 620, 622, 624, 632, 633, 639], "factor": [5, 27, 30, 255, 286, 301, 303, 312, 320, 321, 350, 356, 359, 360, 362, 420, 620, 621, 624, 626, 630, 635, 636, 639, 642], "signific": [5, 21, 24, 27, 613, 622, 641, 642], "understand": [5, 6, 19, 27, 33, 42, 43, 44, 45, 47, 48, 613, 620, 621, 624, 625, 626, 632, 635, 636], "affect": [5, 22, 27, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 272, 280, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 402, 635], "legitim": [5, 642], "unless": [5, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 86, 87, 88, 92, 107, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 280, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 352, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 622], "benchmark": [5, 18, 22, 28, 121, 122, 130, 136, 137, 180], "pipelin": [6, 19, 26, 130, 180, 333, 376, 592, 596, 622], "typic": [6, 17, 22, 23, 27, 33, 34, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 81, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 233, 264, 326, 332, 337, 342, 350, 352, 366, 368, 371, 376, 378, 380, 383, 384, 420, 573, 580, 587, 592, 622, 624, 625, 627, 628, 633, 635, 636, 637], "big": [6, 622, 628, 639, 642], "bucket": [6, 171], "send": [6, 22, 27, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 86, 87, 154, 159, 176, 324, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 401, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 579, 581, 584, 586, 587, 641], "occasion": 6, "tradit": [6, 627, 635], "neural": [6, 7, 141, 152, 153, 288, 344, 386, 599, 621, 622, 623, 626, 635, 636, 637, 642], "both": [6, 7, 18, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 54, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 127, 129, 130, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 161, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 214, 221, 239, 253, 269, 270, 272, 283, 284, 285, 288, 298, 302, 304, 305, 314, 324, 326, 332, 334, 337, 349, 351, 352, 353, 357, 358, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 402, 403, 409, 410, 419, 473, 570, 573, 575, 578, 579, 585, 586, 587, 592, 613, 620, 622, 624, 625, 627, 632, 633, 635, 636, 637, 638, 639, 642], "anyth": [6, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50], "happen": [6, 7, 18, 21, 22, 33, 34, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 282, 312, 418, 567, 573, 621, 624, 627, 628, 629, 638, 642], "held": 6, "datacollector": [6, 32, 34, 35, 36, 38, 50, 52, 53, 368, 622, 628, 639], "receiv": [6, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 271, 272, 280, 305, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 585, 587, 620, 622, 627, 634, 637], "postprocess": [6, 34], "hook": [6, 37, 39, 40, 41, 46, 49, 54, 55, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 117, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 348, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 473, 590, 614], "itself": [6, 21, 34, 42, 47, 50, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 325, 326, 327, 328, 330, 331, 332, 337, 366, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 622, 625], "transfer": [6, 55, 86, 87, 176, 303, 320, 325, 327, 328, 330, 331, 345, 377, 379, 381, 382, 385, 570, 573, 580, 581, 585, 586], "think": [6, 21, 87, 170, 172, 174, 175, 177, 183, 591, 592, 622, 635, 636, 642], "world": [6, 19, 24, 144, 323, 324, 333, 361, 402, 590, 599, 613, 624, 629, 635, 636, 637, 642], "engin": [6, 26, 54, 55, 155, 324, 333, 334, 337, 383, 580, 581, 583, 585, 586, 587, 592, 632, 637], "veri": [6, 12, 15, 18, 19, 22, 86, 87, 136, 137, 175, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 621, 625, 628, 632, 635, 637, 639, 641, 642], "kernel": [6, 288], "forward": [6, 16, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 240, 241, 243, 246, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 317, 322, 324, 326, 332, 337, 338, 341, 342, 344, 345, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 623, 637, 641], "format": [6, 20, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 62, 64, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 92, 93, 100, 106, 114, 120, 123, 126, 130, 138, 150, 151, 152, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 203, 221, 225, 250, 265, 271, 272, 275, 277, 326, 330, 332, 337, 344, 376, 378, 380, 383, 384, 393, 578, 588, 592, 594, 595, 596, 606, 620, 621, 624, 625, 627, 629, 632, 641, 642], "quantiz": 6, "much": [6, 22, 27, 32, 35, 36, 38, 65, 72, 83, 86, 87, 101, 102, 150, 158, 176, 325, 327, 328, 330, 331, 365, 368, 377, 379, 381, 382, 385, 622, 624, 625, 629, 635, 636, 637, 639, 642], "cannot": [6, 18, 22, 23, 26, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 60, 62, 64, 68, 72, 73, 90, 97, 98, 102, 104, 108, 109, 116, 120, 123, 126, 129, 130, 131, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 229, 232, 251, 258, 270, 313, 349, 352, 368, 621, 622, 623, 624, 635, 636, 637], "dump": [6, 20, 30, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 93, 95, 96, 97, 98, 110, 112, 116, 176, 190, 194, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 391, 392, 393, 629, 630, 635], "dict": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 102, 108, 109, 120, 123, 126, 127, 128, 129, 130, 131, 138, 142, 143, 145, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 239, 241, 265, 270, 272, 278, 279, 280, 282, 288, 289, 290, 291, 292, 293, 294, 300, 305, 311, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 352, 371, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 397, 398, 402, 403, 404, 410, 416, 418, 419, 420, 421, 440, 464, 465, 473, 512, 555, 556, 562, 563, 564, 566, 568, 569, 571, 572, 574, 575, 576, 578, 579, 580, 581, 582, 585, 586, 587, 588, 613, 620, 621, 622, 639, 641, 642], "who": 6, "activ": [6, 25, 26, 28, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 288, 294, 299, 305, 351, 365, 368, 637, 641], "ask": [6, 22, 27, 78, 83, 102, 108, 109, 332, 393, 622, 623, 625, 626, 635, 636, 638, 642], "push": [6, 55, 384, 585], "intermedi": [6, 23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 220, 287, 298, 302, 304, 317, 326, 332, 337, 376, 378, 380, 384, 620, 624, 638], "approach": [6, 21, 34, 65, 68, 72, 73, 86, 87, 176, 189, 221, 246, 325, 327, 328, 330, 331, 335, 336, 337, 372, 377, 379, 381, 382, 385, 421, 567, 568, 581, 592, 620, 622, 627, 628, 635, 642], "intermediari": 6, "server": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 190], "fetch": [6, 40, 86, 87, 121, 122, 124, 125, 176, 241, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 585, 626, 638, 639], "tri": [6, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 324, 326, 332, 337, 344, 376, 378, 380, 383, 384, 629], "account": [6, 95, 97, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 227, 306, 621, 623, 639, 642], "problem": [6, 18, 26, 27, 28, 34, 175, 380, 621, 622, 623, 628, 635, 636, 637, 639, 642], "manner": [6, 130, 180, 250, 275, 620, 621, 622, 628, 634, 637, 639], "identifi": [6, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 195, 196, 402, 403, 566, 568, 569, 571, 572, 573, 574, 576, 579, 581, 582, 587, 594, 613, 632], "three": [6, 57, 59, 61, 62, 64, 170, 352, 592, 622, 624, 625, 626, 635, 636, 637, 639, 642], "orchestr": [6, 592, 595, 621, 627, 629], "entir": [6, 23, 34, 35, 36, 38, 50, 60, 83, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 280, 569, 592, 622, 625, 637, 639], "includ": [6, 7, 12, 16, 19, 21, 23, 26, 28, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 63, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 95, 96, 97, 98, 100, 110, 112, 116, 120, 123, 126, 130, 138, 144, 148, 149, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 236, 239, 264, 270, 272, 279, 280, 302, 304, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 349, 352, 366, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 403, 409, 420, 473, 553, 592, 594, 598, 604, 620, 621, 622, 623, 624, 632, 633, 635, 636, 637, 639, 642], "coordin": [6, 35, 36, 38, 50, 95, 97, 228, 565, 566, 573, 580, 581, 583, 585, 586, 613], "actual": [6, 17, 18, 21, 23, 26, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 278, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 553, 567, 568, 570, 573, 585, 588, 592, 620, 622, 624, 635, 636, 637], "through": [6, 12, 17, 18, 21, 22, 23, 24, 27, 32, 34, 35, 36, 38, 41, 42, 47, 50, 52, 53, 55, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 120, 121, 122, 123, 126, 129, 130, 131, 134, 136, 137, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 184, 185, 190, 217, 227, 229, 232, 251, 282, 287, 305, 315, 316, 324, 325, 327, 328, 330, 331, 337, 341, 342, 345, 346, 347, 366, 377, 379, 381, 382, 385, 386, 387, 388, 389, 405, 567, 568, 575, 580, 613, 620, 621, 622, 623, 625, 627, 634, 635, 636, 637, 638, 639, 642], "queue": [6, 52, 154, 279, 326, 332, 337, 383, 567, 568, 575, 613, 639, 641], "determin": [6, 22, 35, 36, 38, 39, 65, 72, 79, 86, 87, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 174, 175, 176, 178, 179, 180, 183, 186, 250, 277, 312, 325, 326, 327, 328, 330, 331, 332, 337, 352, 377, 379, 380, 381, 382, 385, 579, 621, 626, 635, 636], "state_dict": [6, 32, 34, 35, 36, 38, 50, 52, 53, 54, 55, 86, 87, 88, 90, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 418, 564, 568, 569, 571, 572, 574, 578, 579, 581, 587, 588, 620, 621, 642], "extract": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 60, 71, 80, 102, 150, 158, 170, 184, 186, 190, 193, 197, 199, 217, 239, 269, 273, 339, 566, 567, 568, 569, 571, 572, 574, 576, 578, 579, 581, 584, 586, 587, 588, 592, 620, 622, 641], "appli": [6, 7, 10, 21, 22, 23, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 231, 233, 234, 235, 236, 237, 240, 241, 242, 243, 245, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 297, 320, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 391, 409, 411, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 581, 583, 585, 587, 592, 620, 621, 622, 628, 632, 635, 637, 641, 642], "automat": [6, 7, 18, 19, 20, 22, 24, 31, 35, 36, 38, 41, 55, 58, 69, 74, 75, 85, 86, 87, 89, 95, 97, 109, 116, 120, 121, 122, 123, 126, 129, 130, 131, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 174, 175, 176, 178, 179, 180, 191, 217, 229, 232, 246, 265, 278, 280, 302, 304, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 339, 340, 341, 342, 345, 377, 379, 381, 382, 385, 391, 405, 409, 416, 420, 473, 566, 568, 571, 572, 574, 575, 576, 578, 579, 581, 585, 587, 594, 599, 613, 620, 622, 623, 625, 626, 635, 636, 637, 639, 641], "weight_sync_schem": [6, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 419, 420, 473, 565, 566, 568, 569, 570, 571, 572, 573, 574, 576, 577, 579, 581, 587, 592], "intern": [6, 20, 22, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 280, 324, 326, 332, 337, 402, 568, 569, 576, 579, 580, 585, 618], "propag": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 71, 349, 351, 352, 353, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 386, 387, 388, 389, 622, 623, 635, 636], "convent": [6, 22, 78, 79, 80, 81, 82, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 326, 606, 620, 623, 635, 636, 637], "regist": [6, 7, 20, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 209, 212, 229, 232, 233, 258, 270, 272, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 348, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 393, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 566, 568, 571, 572, 574, 576, 579, 581, 584, 586, 587, 592, 613, 614, 620, 622, 625, 639], "posit": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 102, 120, 123, 124, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 226, 236, 237, 239, 261, 262, 263, 266, 270, 272, 274, 307, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384, 402, 403, 622, 635, 636, 637, 639], "policy_modul": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 622, 635, 636], "weights_tensordict": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "clariti": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 272], "actor_modul": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 641], "weights_td": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "model_id": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 566, 567, 568, 569, 571, 572, 573, 574, 576, 579, 580, 581, 582, 587], "actor": [6, 21, 23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 66, 171, 172, 175, 185, 189, 192, 193, 194, 195, 241, 243, 283, 284, 285, 289, 290, 292, 297, 298, 299, 301, 311, 312, 313, 314, 324, 329, 334, 337, 339, 341, 342, 343, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 376, 378, 380, 384, 402, 403, 404, 421, 472, 473, 572, 573, 574, 586, 587, 590, 599, 606, 613, 621, 623, 625, 627, 630, 635, 638, 641], "atom": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "weights_dict": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "actor_td": 6, "critic": [6, 23, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 177, 283, 349, 351, 352, 353, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 380, 421, 472, 473, 570, 590, 599, 606, 613, 620, 627], "critic_td": 6, "primarili": [6, 74, 251, 626], "special": [6, 7, 18, 60, 71, 76, 77, 86, 87, 176, 180, 325, 326, 327, 328, 330, 331, 332, 337, 377, 379, 381, 382, 385, 592, 593, 597, 610, 613, 620, 623, 624, 642], "outsid": [6, 22, 34, 230, 270, 629, 635, 636, 637], "pattern": [6, 89, 190, 197, 565, 566, 568, 570, 571, 573, 574, 575, 580, 590, 592], "clear": [6, 20, 30, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 80, 88, 120, 121, 122, 123, 126, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 402, 407, 613, 625, 628, 633], "local": [6, 23, 26, 29, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 67, 81, 86, 88, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 280, 326, 332, 334, 337, 376, 378, 380, 383, 384, 398, 401, 581, 582, 613, 624, 629, 630, 635, 636], "inter": [6, 22, 150, 154], "base": [6, 10, 12, 16, 19, 21, 22, 23, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 83, 86, 87, 101, 102, 105, 111, 114, 115, 117, 118, 120, 121, 122, 123, 126, 130, 134, 136, 137, 138, 144, 145, 146, 150, 151, 154, 158, 159, 160, 163, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 185, 188, 189, 191, 194, 195, 199, 204, 205, 212, 218, 225, 226, 230, 255, 269, 271, 272, 273, 275, 276, 280, 283, 286, 302, 304, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 352, 353, 354, 356, 357, 358, 360, 364, 368, 369, 370, 371, 372, 373, 377, 379, 381, 382, 385, 386, 387, 388, 389, 390, 401, 402, 403, 416, 420, 424, 428, 438, 439, 441, 445, 474, 530, 565, 566, 567, 568, 569, 571, 572, 574, 575, 576, 578, 579, 581, 582, 583, 585, 587, 590, 599, 606, 608, 613, 620, 621, 623, 625, 626, 627, 629, 632, 633, 635, 636, 637, 639, 642], "tcpstore": [6, 565, 566], "small": [6, 101, 102, 109, 275, 280, 620, 622, 624, 635, 636, 642], "logic": [6, 21, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 89, 569, 571, 572, 574, 579, 581, 587, 635], "sender": [6, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 579, 580, 581, 582, 584, 587, 592], "trigger": [6, 26, 178, 280, 326, 332, 337, 376, 378, 380, 384, 566, 568, 571, 572, 574, 576, 579, 581, 587, 623], "_receive_weights_schem": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "side": [6, 18, 23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 188, 189, 195, 196, 202, 306, 326, 566, 568, 569, 571, 572, 573, 574, 576, 577, 579, 580, 581, 587, 642], "init_on_send": [6, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587], "context": [6, 17, 19, 21, 24, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 109, 120, 123, 126, 127, 130, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 265, 274, 302, 304, 326, 332, 337, 376, 378, 380, 383, 384, 386, 387, 388, 389, 393, 405, 410, 566, 567, 568, 569, 571, 572, 574, 575, 576, 579, 581, 587, 592, 613, 620, 621, 622, 623, 624, 635, 636, 637, 638, 639, 641], "NO": 6, "pickl": [6, 32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 68, 69, 72, 73, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 376, 378, 380, 383, 384], "init": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 66, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 271, 279, 324, 326, 329, 332, 337, 376, 378, 380, 383, 384, 386, 400, 401, 402, 404, 580, 585, 587, 613, 621, 622], "block": [6, 53, 55, 89, 94, 119, 135, 175, 177, 186, 193, 203, 324, 565, 566, 567, 568, 570, 571, 572, 573, 574, 576, 577, 579, 581, 587, 592, 620, 623, 624, 627, 628, 635, 639], "readi": [6, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 170, 324, 566, 568, 569, 571, 572, 574, 576, 579, 581, 582, 585, 587, 591, 621, 622, 624, 626, 629, 639, 641], "init_on_receiv": [6, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587], "resolv": [6, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 419], "handler": 6, "prepar": [6, 25, 80, 170, 173, 195, 196, 384, 566, 568, 569, 571, 572, 574, 576, 579, 581, 586, 587, 592, 622], "without": [6, 17, 18, 19, 22, 26, 28, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 83, 86, 87, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 217, 229, 232, 268, 271, 284, 285, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 339, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 402, 433, 435, 560, 565, 567, 568, 573, 575, 576, 591, 613, 620, 621, 622, 624, 625, 626, 627, 628, 632, 633, 635, 636, 637, 639, 642], "attribut": [6, 17, 19, 21, 22, 23, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 129, 130, 131, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 233, 244, 250, 272, 275, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 345, 349, 350, 352, 353, 354, 356, 358, 359, 360, 363, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 581, 620, 623, 637], "refer": [6, 7, 17, 18, 21, 26, 27, 28, 30, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 123, 126, 129, 130, 131, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 270, 271, 272, 279, 285, 298, 299, 306, 308, 309, 315, 316, 317, 325, 326, 327, 328, 330, 331, 332, 337, 349, 352, 359, 360, 361, 362, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 566, 567, 568, 569, 571, 572, 574, 575, 579, 580, 581, 587, 619, 620, 622, 624, 626, 627, 628, 629, 635, 636, 639], "indic": [6, 12, 17, 18, 20, 22, 27, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 94, 101, 102, 104, 106, 107, 108, 109, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 213, 214, 221, 222, 226, 263, 264, 265, 266, 272, 280, 282, 288, 305, 306, 312, 313, 314, 325, 327, 328, 330, 331, 341, 349, 350, 351, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 554, 564, 591, 613, 622, 623, 624, 628, 629, 630, 637, 639, 642], "primit": [6, 21, 23, 83, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 566, 570], "NOT": [6, 22, 35, 36, 38, 92, 93, 100, 109, 251, 587], "sent": [6, 35, 36, 38, 65, 68, 69, 72, 73, 86, 87, 90, 95, 97, 116, 176, 279, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 566, 567, 568, 570, 571, 572, 574, 575, 576, 577, 579, 581, 587], "explicit": [6, 23, 34, 35, 36, 38, 171, 172, 175, 185, 194, 195, 282, 303, 315, 316, 320, 329, 402, 575, 576, 613, 639], "param": [6, 27, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 273, 280, 295, 319, 325, 326, 327, 328, 330, 331, 332, 337, 342, 344, 347, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 580, 585, 586, 620, 624, 630, 635, 636, 637, 638, 641], "num_work": [6, 7, 35, 36, 38, 46, 49, 78, 79, 80, 81, 82, 83, 84, 85, 145, 150, 158, 194, 440, 579, 620, 621], "inner_collector": 6, "worker_idx": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 579, 581, 587], "simultan": [6, 22, 47, 137, 145, 146, 150, 158, 568, 580, 587, 613, 637], "order": [6, 21, 30, 34, 41, 52, 53, 64, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 107, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 222, 229, 232, 239, 248, 262, 270, 272, 297, 322, 324, 326, 332, 337, 340, 344, 346, 347, 349, 350, 352, 353, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 570, 621, 635, 636], "driven": 6, "exchang": 6, "notabl": [6, 22], "until": [6, 20, 26, 50, 52, 88, 137, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 266, 271, 383, 405, 565, 568, 570, 573, 576, 622, 623, 630, 635, 636], "exact": [6, 22, 56, 150, 613], "sharedmem": 6, "put": [6, 65, 66, 68, 69, 130, 142, 143, 160, 163, 164, 279, 401, 564, 621, 622, 623, 625, 632, 635, 637], "recv": [6, 565, 566, 570, 573], "send_async": [6, 568, 576], "train_step": 6, "new_weight": [6, 191], "zero": [6, 18, 22, 23, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 97, 101, 102, 108, 109, 114, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 218, 220, 222, 226, 229, 231, 232, 246, 252, 255, 262, 280, 291, 292, 293, 300, 301, 302, 303, 304, 306, 312, 314, 320, 325, 326, 327, 328, 330, 331, 332, 337, 345, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 575, 623, 624, 633, 639, 641, 642], "instantan": 6, "none": [6, 18, 21, 22, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 95, 96, 97, 98, 100, 101, 102, 106, 108, 109, 110, 112, 114, 116, 120, 123, 126, 127, 129, 130, 138, 142, 143, 144, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 206, 207, 209, 210, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 228, 229, 230, 232, 236, 238, 239, 241, 242, 243, 246, 247, 248, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 320, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 342, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 397, 398, 399, 402, 403, 409, 410, 411, 412, 413, 414, 416, 418, 419, 420, 421, 425, 426, 427, 428, 429, 431, 434, 435, 438, 439, 440, 442, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 463, 464, 465, 466, 468, 469, 470, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 494, 495, 496, 497, 498, 499, 500, 501, 502, 504, 506, 507, 508, 509, 510, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 543, 545, 547, 549, 550, 551, 554, 555, 556, 557, 559, 560, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 613, 620, 621, 623, 624, 633, 637, 639, 641], "mp": [6, 42, 44, 47, 78, 79, 80, 81, 82, 83, 84, 85, 127, 279, 280, 567, 575], "signal": [6, 17, 32, 34, 35, 36, 38, 56, 78, 79, 81, 83, 84, 85, 102, 108, 109, 114, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 177, 178, 179, 180, 213, 221, 227, 233, 242, 263, 266, 565, 570, 573, 585, 586, 620, 622, 635, 636, 639, 642], "alreadi": [6, 20, 21, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 243, 265, 282, 325, 326, 327, 328, 329, 330, 331, 332, 337, 345, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 402, 403, 565, 575, 613, 620, 622, 629, 635, 636], "part": [6, 7, 12, 20, 21, 22, 23, 27, 78, 80, 81, 83, 84, 85, 88, 102, 120, 121, 123, 126, 130, 136, 138, 148, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 220, 246, 255, 258, 322, 326, 332, 337, 376, 378, 380, 383, 384, 406, 564, 613, 620, 622, 623, 624, 630, 635, 637, 642], "irecv": 6, "return_prematur": 6, "rank": [6, 46, 86, 87, 114, 176, 324, 325, 327, 328, 330, 331, 335, 336, 377, 379, 381, 382, 385, 565, 571, 572, 573, 574, 580, 585, 586, 587], "flag": [6, 7, 17, 19, 27, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 174, 175, 177, 178, 179, 180, 183, 240, 312, 635, 636, 637, 638], "poll": [6, 583, 585], "ref": [6, 324], "connectioninfo": 6, "init_process_group": [6, 573], "isend": [6, 570, 573], "insid": [6, 7, 21, 86, 87, 150, 176, 230, 325, 327, 328, 330, 331, 339, 377, 379, 381, 382, 385, 572, 613, 642], "raymoduletransform": [6, 572], "join": [6, 127, 185, 573, 621, 622, 624, 635], "uniqu": [6, 64, 108, 109, 138, 142, 143, 177, 179, 221, 233, 264, 265, 266, 270, 341, 401, 402, 403, 572, 574, 575, 592, 613, 628, 639], "even": [6, 17, 21, 23, 27, 30, 35, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 90, 95, 96, 97, 98, 102, 108, 110, 112, 116, 120, 123, 126, 127, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 217, 620, 622, 625, 632, 635, 636, 637, 642], "invok": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 67, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 326, 332, 337, 376, 378, 380, 383, 384], "mechan": [6, 23, 32, 34, 35, 36, 37, 38, 39, 40, 46, 49, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 324, 326, 332, 337, 376, 378, 380, 383, 384, 577, 585, 586, 592, 613, 621, 627, 637], "benefit": [6, 101, 102, 591, 625, 633, 635, 636, 639], "cascad": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 566, 568, 571, 572, 574, 576, 579, 581, 587], "grace": [6, 324], "runnabl": 6, "repositori": [6, 26, 80, 81, 82, 85, 163, 164, 635, 636], "weight_sync_standalon": 6, "weight_sync_collector": 6, "seamlessli": [6, 19, 170, 191, 592, 599, 633, 637], "nn": [6, 17, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 66, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 167, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 226, 231, 233, 241, 250, 265, 271, 272, 275, 277, 283, 284, 285, 287, 288, 290, 291, 292, 293, 297, 299, 300, 301, 302, 304, 305, 307, 312, 313, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 342, 344, 345, 346, 347, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 469, 560, 566, 568, 569, 571, 572, 573, 574, 578, 579, 581, 587, 599, 620, 621, 622, 623, 624, 626, 627, 630, 634, 635, 636, 637, 638, 641], "tensordictmodul": [6, 17, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 66, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 220, 226, 241, 283, 284, 285, 287, 297, 302, 304, 313, 314, 317, 323, 326, 332, 337, 341, 342, 344, 346, 347, 348, 350, 352, 353, 357, 358, 360, 361, 362, 363, 364, 366, 369, 371, 372, 373, 376, 378, 380, 384, 386, 387, 388, 389, 410, 469, 560, 599, 620, 622, 623, 627, 630, 634, 635, 636, 637, 638, 642], "weight_upd": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 592], "linear": [6, 21, 32, 34, 35, 36, 38, 50, 52, 53, 66, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 241, 250, 265, 271, 272, 275, 277, 283, 284, 285, 287, 288, 290, 291, 292, 293, 300, 301, 305, 307, 312, 313, 315, 316, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 342, 344, 347, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 560, 599, 621, 634, 638, 641], "observation_spec": [6, 17, 18, 19, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 193, 194, 195, 196, 197, 198, 199, 215, 218, 221, 222, 223, 224, 225, 228, 229, 230, 232, 233, 236, 238, 239, 240, 241, 243, 246, 248, 250, 252, 254, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 278, 279, 280, 302, 304, 383, 554, 560, 620, 622, 627, 634, 635, 636, 637, 642], "observ": [6, 7, 10, 16, 17, 18, 19, 21, 22, 27, 32, 34, 35, 36, 38, 50, 52, 53, 66, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 92, 93, 100, 102, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 193, 194, 195, 196, 197, 198, 199, 207, 212, 214, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 233, 234, 236, 238, 239, 240, 241, 243, 244, 246, 247, 248, 252, 253, 254, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 278, 279, 280, 283, 284, 285, 287, 289, 290, 291, 292, 293, 294, 297, 301, 302, 304, 308, 309, 311, 312, 313, 315, 317, 322, 323, 339, 340, 341, 342, 349, 350, 351, 352, 353, 354, 356, 357, 358, 361, 364, 365, 368, 369, 370, 371, 372, 373, 383, 386, 387, 388, 389, 390, 391, 393, 420, 421, 469, 560, 592, 599, 600, 621, 622, 623, 624, 625, 626, 627, 629, 630, 634, 635, 636, 637, 639, 641, 642], "action_spec": [6, 17, 18, 19, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 88, 120, 121, 122, 123, 126, 130, 136, 137, 138, 144, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 218, 221, 225, 229, 230, 232, 241, 243, 246, 252, 255, 271, 272, 273, 274, 297, 313, 316, 339, 340, 342, 343, 350, 352, 354, 356, 369, 371, 372, 373, 383, 560, 599, 620, 621, 622, 623, 624, 626, 627, 628, 630, 634, 635, 636, 637, 638, 639, 641, 642], "in_kei": [6, 7, 20, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 66, 69, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 207, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 283, 284, 285, 287, 296, 297, 302, 304, 313, 322, 326, 329, 332, 337, 339, 340, 341, 342, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 363, 364, 365, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 392, 393, 466, 468, 469, 470, 476, 479, 480, 481, 482, 483, 484, 488, 489, 490, 491, 492, 495, 496, 497, 498, 499, 501, 502, 504, 506, 507, 508, 509, 510, 513, 514, 515, 516, 517, 519, 520, 521, 523, 524, 525, 527, 528, 531, 532, 533, 534, 535, 536, 537, 538, 560, 599, 620, 621, 622, 623, 624, 626, 627, 630, 633, 634, 635, 636, 637, 638, 639, 641, 642], "out_kei": [6, 7, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 66, 69, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 207, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 277, 278, 279, 280, 283, 284, 285, 287, 296, 298, 302, 304, 313, 314, 322, 326, 329, 332, 337, 339, 340, 341, 342, 344, 345, 347, 348, 349, 350, 351, 352, 357, 358, 363, 364, 365, 368, 369, 370, 371, 372, 376, 378, 380, 383, 384, 386, 387, 388, 389, 391, 393, 410, 466, 468, 469, 470, 476, 479, 480, 481, 482, 483, 484, 488, 489, 490, 491, 492, 495, 496, 497, 498, 499, 501, 502, 504, 506, 507, 508, 509, 510, 513, 514, 515, 516, 517, 519, 520, 521, 523, 524, 525, 526, 527, 528, 529, 531, 532, 533, 534, 535, 536, 537, 538, 560, 599, 620, 621, 622, 623, 624, 626, 630, 633, 634, 635, 636, 637, 638, 639, 641, 642], "action": [6, 7, 10, 16, 17, 18, 19, 22, 27, 28, 32, 34, 35, 36, 38, 50, 52, 53, 64, 66, 78, 79, 80, 81, 82, 83, 84, 85, 88, 101, 102, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 214, 215, 218, 224, 225, 226, 229, 230, 231, 232, 233, 234, 236, 237, 239, 241, 243, 244, 245, 246, 248, 252, 253, 255, 259, 263, 265, 269, 271, 272, 273, 274, 278, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 301, 302, 304, 305, 306, 311, 312, 313, 314, 316, 317, 319, 320, 322, 326, 332, 337, 339, 340, 341, 342, 343, 345, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 409, 420, 421, 469, 475, 560, 564, 592, 599, 600, 601, 603, 620, 621, 622, 624, 625, 626, 627, 632, 633, 634, 635, 636, 638, 641, 642], "192": [6, 142, 143], "enumer": [6, 34, 35, 38, 50, 52, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 73, 74, 75, 76, 77, 88, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 374, 376, 378, 380, 383, 384, 620, 621, 622, 623, 630, 635, 639, 641], "worker_fn": 6, "overwritten": [6, 42, 44, 47, 50, 78, 80, 81, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 236], "now": [6, 18, 21, 26, 65, 68, 69, 72, 73, 89, 148, 149, 150, 185, 189, 221, 259, 324, 339, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 632, 634, 635, 636, 638, 639, 642], "from_modul": [6, 35, 36, 38, 86, 87, 176, 325, 326, 327, 328, 330, 331, 332, 337, 344, 347, 377, 379, 381, 382, 385, 419, 641], "spawn": [6, 22, 23, 42, 51, 134, 145, 150, 158, 270, 621, 635, 636], "target": [6, 7, 23, 27, 50, 88, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 264, 324, 326, 332, 337, 344, 345, 349, 350, 351, 352, 353, 354, 356, 358, 359, 362, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 415, 421, 553, 559, 560, 623, 624, 630, 635, 637], "arg": [6, 17, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 58, 60, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 102, 108, 109, 110, 112, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 208, 214, 215, 216, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 244, 249, 250, 251, 252, 253, 255, 258, 259, 261, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 274, 275, 276, 277, 278, 279, 283, 284, 285, 286, 287, 288, 295, 296, 297, 298, 301, 302, 304, 305, 312, 313, 314, 317, 322, 323, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 400, 401, 402, 403, 408, 412, 416, 420, 421, 564, 566, 568, 569, 571, 572, 574, 575, 576, 577, 581, 587, 613, 621, 624, 632], "w": [6, 23, 69, 123, 148, 149, 190, 221, 223, 228, 254, 268, 312, 368, 393, 513, 621, 639], "epoch": [6, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 416, 420, 473, 622, 635, 636], "stop": [6, 17, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 85, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 186, 326, 332, 337, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587, 622, 628, 635, 636, 641, 642], "With": [6, 17, 86, 87, 136, 137, 141, 176, 264, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 402, 404, 587, 621, 632, 634, 635, 636, 639, 642], "dictionari": [6, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 60, 86, 87, 88, 89, 102, 106, 108, 109, 120, 123, 126, 129, 130, 131, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 239, 265, 270, 272, 280, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 352, 371, 372, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 410, 418, 562, 563, 564, 578, 621, 622, 625, 627, 635, 637, 642], "map": [6, 17, 21, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 93, 95, 100, 101, 102, 120, 123, 126, 130, 138, 141, 142, 143, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 214, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 232, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 278, 279, 280, 283, 284, 285, 297, 307, 313, 322, 323, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 344, 345, 347, 348, 351, 352, 365, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 410, 419, 420, 425, 473, 568, 580, 581, 582, 585, 586, 588, 600, 620, 621, 622, 623, 626, 627, 638], "transportbackend": [6, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587], "protocol": [6, 190, 197, 202], "stateless": [6, 17, 22, 53, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 218, 227, 280, 335, 336, 366, 376, 378, 380, 384, 391, 620, 625, 637, 642], "design": [6, 7, 10, 16, 17, 18, 22, 37, 46, 49, 63, 64, 86, 87, 88, 106, 112, 119, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 221, 239, 251, 270, 272, 280, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 599, 606, 613, 620, 621, 622, 625, 626, 627, 632, 633, 634, 635, 636, 637, 639, 641, 642], "rather": [6, 23, 65, 68, 69, 72, 73, 112, 148, 149, 178, 185, 253, 280, 620, 621, 622, 623, 625, 627, 635, 636, 639], "kwarg": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 58, 60, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 95, 96, 97, 98, 100, 101, 102, 108, 109, 110, 112, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 202, 208, 209, 215, 216, 218, 225, 243, 250, 252, 261, 265, 270, 271, 272, 274, 276, 277, 279, 281, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 296, 297, 298, 300, 301, 302, 303, 304, 305, 310, 312, 313, 314, 317, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 340, 341, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 397, 398, 400, 401, 402, 403, 408, 416, 420, 421, 555, 556, 561, 562, 563, 566, 568, 569, 571, 572, 574, 576, 577, 579, 581, 587, 613, 622, 624, 636], "receive_weight": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 565, 567, 570, 573, 575, 577, 580, 582], "pre": [6, 26, 51, 55, 83, 88, 97, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 269, 275, 277, 315, 316, 326, 332, 337, 376, 378, 380, 383, 384, 565, 568, 570, 573, 577, 642], "alloc": [6, 86, 87, 97, 176, 194, 295, 306, 324, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 565, 570, 573, 577, 592, 613, 620], "weightstrategi": [6, 565, 566, 568, 569, 570, 571, 572, 573, 574, 576, 577, 579, 581, 587, 588], "applic": [6, 86, 87, 150, 158, 170, 176, 325, 327, 328, 330, 331, 371, 377, 379, 381, 382, 385, 578, 580, 613, 625, 626, 637], "setup_connection_and_weights_on_receiv": [6, 565, 567, 570, 573, 575, 577], "recept": [6, 38], "note": [6, 18, 19, 20, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 213, 229, 232, 270, 279, 280, 302, 304, 312, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 351, 359, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 566, 568, 571, 572, 574, 576, 579, 581, 585, 587, 613, 621, 624, 626, 632, 634, 635, 636, 642], "mptransport": [6, 568], "ye": 6, "rpctransport": [6, 571], "raytransport": [6, 572, 574], "distributedtransport": 6, "sharedmemtransport": [6, 567, 577], "instant": [6, 575, 582], "arriv": [6, 568, 576], "specifi": [6, 7, 15, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 228, 229, 230, 232, 258, 261, 264, 269, 273, 274, 282, 307, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 344, 345, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 401, 404, 566, 568, 571, 572, 574, 576, 577, 578, 579, 581, 587, 613, 620, 622, 623, 624, 628, 632, 635], "expir": [6, 565, 570, 573], "weightupdat": 6, "deprec": [6, 34, 35, 36, 38, 41, 43, 45, 46, 48, 50, 56, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 279, 325, 326, 327, 328, 330, 331, 332, 337, 349, 351, 352, 354, 357, 358, 359, 364, 365, 368, 369, 370, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 590, 642], "11": [6, 29, 56, 64, 95, 96, 97, 101, 109, 116, 127, 214, 226, 268, 592], "prefer": [6, 18, 22, 32, 35, 36, 38, 47, 56, 65, 68, 72, 73, 108, 109, 120, 154, 159, 181, 251, 259, 368, 372, 412, 622, 635, 636, 639, 641], "power": [7, 16, 30, 621], "top": [7, 21, 23, 88, 114, 121, 122, 136, 137, 228, 271, 326, 332, 337, 488, 599, 626], "hydra": [7, 420, 614], "dataclass": [7, 74, 86, 87, 176, 325, 327, 328, 330, 331, 366, 377, 379, 381, 382, 385], "compos": [7, 10, 21, 65, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 103, 104, 105, 114, 115, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 226, 227, 239, 254, 270, 271, 272, 279, 326, 332, 337, 341, 352, 361, 371, 376, 378, 380, 383, 384, 393, 485, 599, 620, 621, 622, 623, 624, 628, 632, 634, 636, 638, 639, 641, 642], "overridden": [7, 22, 37, 39, 40, 41, 46, 49, 78, 80, 81, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 208, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 338, 341, 348, 386, 388, 389, 623, 635], "advantag": [7, 21, 22, 27, 178, 185, 300, 349, 351, 365, 368, 370, 376, 378, 380, 383, 386, 387, 388, 389, 390, 620, 621, 622, 623, 636, 637, 642], "glimps": 7, "go": [7, 19, 21, 26, 96, 141, 150, 227, 251, 255, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "sota": [7, 35, 38, 144, 237, 370, 406, 555, 620, 621, 641], "ppo_train": 7, "help": [7, 17, 23, 74, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 233, 326, 332, 333, 334, 337, 349, 351, 365, 368, 370, 376, 378, 380, 383, 384, 420, 591, 620, 621, 622, 623, 632, 633, 635, 636], "overrid": [7, 22, 37, 39, 40, 41, 46, 49, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 78, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 295, 326, 332, 337, 376, 378, 380, 383, 384, 393, 564, 569, 571, 572, 574, 579, 581, 586, 587, 632], "reproduc": [7, 17, 21, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 221, 239, 420, 421, 473, 620, 622, 624, 636], "command": [7, 25, 26, 29, 154, 159, 160, 190, 622, 632, 635, 636, 637, 642], "here": [7, 18, 19, 21, 23, 26, 27, 28, 29, 35, 38, 50, 84, 85, 114, 120, 123, 124, 125, 126, 130, 134, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 193, 221, 270, 401, 592, 620, 621, 622, 623, 624, 625, 626, 628, 630, 635, 636, 637, 639, 641, 642], "minim": [7, 16, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 395, 568, 592, 639], "config": [7, 25, 26, 190, 250, 277, 286, 289, 294, 311, 339, 420, 554, 555, 556, 558, 561, 613], "yaml": 7, "training_env": 7, "env_nam": [7, 25, 120, 121, 123, 124, 126, 127, 129, 130, 132, 136, 138, 139, 145, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 620, 622, 642], "tell": [7, 18, 23, 26, 120, 152, 153, 270, 576, 583, 620, 623, 628, 635, 636], "proper": [7, 22, 23, 25, 26, 189, 324, 386, 387, 388, 389, 592, 621, 622, 632, 635, 636, 637, 639], "select": [7, 23, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 123, 142, 143, 152, 153, 163, 164, 170, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 236, 237, 240, 241, 243, 244, 245, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 297, 313, 324, 326, 332, 337, 343, 376, 378, 380, 383, 384, 414, 620, 624, 625, 633, 635, 639], "syntax": [7, 613, 620], "dmcontrol": [7, 16, 18, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "brax": [7, 16, 27, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 253, 443, 625, 642], "well": [7, 15, 16, 17, 20, 21, 22, 27, 50, 56, 65, 68, 72, 73, 74, 88, 102, 106, 110, 117, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 271, 272, 290, 315, 316, 326, 332, 337, 345, 366, 368, 372, 376, 378, 380, 383, 384, 386, 390, 620, 621, 623, 624, 625, 626, 627, 629, 638, 639, 641, 642], "reward": [7, 10, 17, 18, 19, 22, 34, 35, 38, 78, 79, 80, 81, 82, 83, 84, 85, 88, 101, 102, 114, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 214, 215, 218, 219, 224, 225, 229, 230, 232, 233, 234, 239, 241, 242, 243, 244, 248, 252, 253, 255, 256, 257, 258, 259, 260, 262, 263, 264, 269, 271, 272, 273, 274, 276, 277, 279, 280, 302, 323, 341, 349, 350, 352, 353, 354, 356, 357, 358, 361, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 408, 409, 410, 413, 420, 421, 564, 595, 614, 620, 621, 622, 623, 624, 625, 629, 632, 633, 635, 636, 637, 641, 642], "mlp": [7, 144, 283, 288, 290, 291, 292, 293, 297, 300, 302, 304, 354, 356, 465, 599, 621, 624, 626, 627, 630, 634, 638, 641], "convnet": [7, 290, 291, 300, 464, 599, 623, 624, 626, 641], "writer": [7, 10, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 94, 97, 102, 104, 108, 114, 115, 116, 119, 431, 432, 437, 438, 622, 639], "logger": [7, 20, 30, 391, 393, 395, 396, 397, 398, 399, 400, 401, 409, 416, 420, 421, 460, 461, 462, 463, 473, 560, 564, 590, 614, 621, 635], "assign": [7, 17, 23, 32, 35, 36, 38, 54, 58, 75, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 352, 353, 354, 356, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 587, 613, 622, 626, 632, 635, 636, 639], "locat": [7, 15, 26, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 209, 228, 233, 246, 257, 280, 303, 320, 321, 324, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 417, 419, 613, 620, 621, 622, 629, 635, 636, 639], "batched_env": 7, "transformed_env": [7, 225, 272, 625], "base_env": [7, 21, 22, 120, 122, 123, 126, 130, 131, 137, 138, 149, 150, 151, 154, 158, 159, 160, 162, 170, 171, 172, 175, 178, 179, 180, 194, 214, 215, 218, 224, 226, 227, 229, 231, 232, 241, 248, 252, 254, 260, 263, 265, 266, 270, 272, 393, 405, 442, 572, 592, 620, 621, 622, 624, 635, 638, 641, 642], "transform0": 7, "noop_reset": 7, "transform1": [7, 21], "step_count": [7, 34, 35, 38, 120, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 227, 263, 522, 622, 623, 624, 625, 630], "noop": [7, 245, 505], "30": [7, 18, 20, 68, 81, 88, 108, 109, 184, 217, 245, 315, 316, 391, 395, 398, 400, 401, 460, 505, 613, 628, 633, 636, 637, 639], "max_step": [7, 16, 17, 30, 114, 120, 123, 126, 130, 138, 142, 143, 144, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 183, 263, 270, 391, 522, 625, 626, 627, 629, 630, 635, 636, 641, 642], "step_count_kei": [7, 226, 227, 263, 522], "_partial_": [7, 425, 426, 427, 428, 431, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 464, 465, 466, 467, 468, 469, 470, 471, 472, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552], "individu": [7, 23, 34, 42, 44, 47, 50, 69, 88, 102, 114, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 280, 317, 326, 332, 337, 351, 365, 368, 376, 378, 380, 383, 384, 620, 623, 636], "construct": [7, 18, 24, 56, 65, 68, 69, 72, 73, 74, 78, 88, 120, 123, 126, 127, 129, 130, 138, 150, 151, 152, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 280, 302, 304, 316, 326, 332, 337, 345, 376, 378, 380, 383, 384, 416, 599, 614, 621, 622, 623, 626, 635, 637, 639, 642], "repeat": [7, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 181, 185, 194, 270, 295, 324, 326, 332, 337, 529, 622, 635, 636, 637], "layer": [7, 246, 279, 288, 290, 291, 296, 299, 302, 304, 305, 308, 309, 324, 333, 334, 338, 348, 465, 580, 585, 586, 592, 594, 595, 599, 621, 622, 623, 624, 626, 635, 638], "episod": [7, 18, 78, 79, 80, 81, 82, 83, 84, 85, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 217, 255, 258, 264, 386, 420, 621, 625, 630, 635, 636, 639], "track": [7, 20, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 73, 86, 87, 101, 102, 107, 123, 176, 178, 191, 258, 267, 279, 280, 312, 325, 327, 328, 330, 331, 341, 377, 379, 381, 382, 383, 385, 398, 408, 418, 420, 473, 590, 617, 621, 623, 625, 628, 636, 637, 639], "count": [7, 18, 20, 22, 32, 34, 35, 36, 38, 52, 126, 127, 226, 263, 270, 280, 312, 324, 410, 416, 553, 592, 620, 621, 622, 623, 639, 642], "composit": [7, 10, 17, 18, 19, 21, 57, 58, 59, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 87, 88, 106, 112, 119, 120, 123, 126, 128, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 206, 213, 215, 218, 229, 230, 231, 232, 234, 239, 241, 244, 252, 253, 259, 263, 265, 269, 270, 271, 273, 280, 286, 340, 342, 345, 347, 348, 349, 368, 383, 592, 620, 622, 626, 632, 637, 642], "combin": [7, 23, 102, 188, 195, 196, 324, 372, 621, 624, 629, 639, 641], "maximum": [7, 17, 23, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 47, 48, 50, 57, 75, 90, 95, 96, 97, 98, 101, 102, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 231, 256, 263, 264, 266, 319, 320, 321, 326, 329, 332, 337, 348, 350, 352, 357, 358, 364, 366, 367, 371, 376, 378, 380, 384, 393, 412, 420, 421, 473, 565, 566, 567, 568, 570, 571, 572, 573, 574, 576, 577, 579, 581, 587, 592, 613, 620, 621, 622, 623, 626, 635, 636, 639], "length": [7, 35, 36, 38, 47, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 83, 87, 102, 108, 109, 112, 120, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 196, 214, 221, 242, 251, 279, 288, 290, 292, 294, 305, 322, 325, 326, 332, 337, 340, 344, 383, 384, 406, 412, 592, 620, 622, 623, 628, 630, 632, 637, 639, 642], "concept": [7, 21, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 592, 621, 632, 639], "nest": [7, 16, 17, 19, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 60, 68, 69, 71, 86, 87, 88, 95, 96, 97, 100, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 213, 221, 263, 266, 270, 271, 325, 326, 327, 328, 330, 331, 332, 337, 341, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 405, 409, 614, 621, 622, 624, 636, 637, 639, 641], "deep": [7, 22, 28, 221, 242, 290, 291, 292, 293, 296, 312, 349, 352, 371, 620, 635], "factori": [7, 28, 32, 34, 35, 36, 38, 42, 44, 47, 50, 66, 68, 72, 73, 74, 194, 243, 403, 440, 464, 465, 620], "onc": [7, 22, 26, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 54, 69, 83, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 244, 255, 265, 272, 286, 312, 325, 326, 327, 328, 330, 331, 332, 337, 341, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 413, 566, 568, 569, 571, 572, 574, 576, 577, 579, 581, 587, 613, 621, 622, 623, 626, 629, 637, 639, 642], "per": [7, 19, 20, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 53, 80, 88, 101, 102, 108, 114, 134, 136, 137, 150, 152, 153, 196, 224, 244, 258, 288, 299, 301, 324, 333, 341, 368, 380, 393, 395, 398, 400, 401, 416, 418, 420, 421, 473, 562, 563, 575, 587, 592, 620, 621, 622, 623, 624, 626, 627, 630, 635, 636, 639, 641], "variabl": [7, 18, 20, 22, 23, 26, 27, 41, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 80, 81, 84, 85, 87, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 142, 143, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 175, 178, 179, 180, 185, 196, 200, 202, 225, 267, 271, 280, 283, 284, 285, 302, 304, 326, 332, 337, 366, 369, 405, 592, 621, 633], "interpol": [7, 69, 254, 513, 621, 624], "script": [7, 26, 80, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 405, 560, 564, 614, 620, 621, 624, 629, 635, 636, 637, 639], "discov": [7, 23], "print": [7, 18, 22, 25, 26, 34, 35, 38, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 101, 102, 108, 109, 114, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 136, 137, 138, 139, 140, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 203, 206, 211, 212, 213, 214, 217, 218, 221, 222, 226, 227, 229, 230, 231, 232, 240, 246, 252, 253, 255, 258, 263, 265, 266, 267, 268, 279, 280, 283, 284, 285, 288, 290, 291, 292, 293, 294, 297, 300, 301, 302, 304, 305, 306, 307, 310, 312, 313, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 340, 341, 342, 344, 345, 347, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 402, 560, 583, 592, 613, 621, 622, 623, 624, 625, 626, 627, 628, 629, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "someth": [7, 88, 120, 123, 126, 130, 138, 141, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 591, 621, 622, 637, 642], "policy_model": [7, 584], "tanh_norm": 7, "value_model": [7, 360, 362], "policy_network": 7, "value_network": [7, 353, 354, 356, 357, 359, 364, 371, 386, 387, 388, 389, 606, 620, 622, 624, 627, 630, 635], "tensor": [7, 10, 12, 14, 17, 18, 19, 22, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 106, 108, 109, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 206, 208, 212, 213, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 231, 232, 233, 234, 236, 239, 240, 242, 246, 248, 250, 251, 252, 253, 255, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 270, 271, 272, 273, 274, 275, 277, 279, 280, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 340, 341, 342, 344, 345, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 361, 362, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 409, 427, 439, 575, 592, 594, 620, 621, 622, 623, 624, 625, 626, 635, 636, 637, 641, 642], "without_replac": 7, "round_robin": 7, "adam": [7, 172, 320, 421, 542, 620, 621, 622, 623, 624, 627, 630, 635, 636, 637], "wandb": [7, 393, 397, 401, 416, 420, 463, 473, 629, 641], "out_featur": [7, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 283, 288, 290, 291, 292, 293, 297, 299, 300, 302, 304, 305, 326, 332, 337, 344, 354, 356, 376, 378, 380, 383, 384, 465, 468, 469, 470, 620, 623, 624, 626, 627, 630, 641], "in_featur": [7, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 283, 288, 290, 291, 292, 293, 300, 305, 326, 332, 337, 344, 354, 356, 376, 378, 380, 383, 384, 464, 465, 468, 469, 470, 624, 626, 627], "num_cel": [7, 283, 288, 290, 291, 292, 293, 299, 300, 302, 304, 305, 464, 465, 468, 469, 470, 621, 622, 623, 624, 626, 627, 630, 635, 636, 641], "128": [7, 78, 79, 83, 109, 121, 122, 136, 137, 193, 291, 294, 613, 621, 623, 624, 630, 635, 638, 639], "num_cal": 7, "state_valu": [7, 284, 285, 322, 351, 357, 364, 365, 368, 369, 371, 386, 387, 388, 389, 620, 636], "loss_modul": [7, 351, 365, 366, 368, 376, 378, 380, 384, 415, 416, 419, 420, 421, 473, 559, 560, 606, 614, 620, 621, 622, 635, 636, 639], "1024": [7, 50, 66, 294, 402, 639], "lr": [7, 421, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 620, 621, 622, 623, 630, 635, 636, 637], "001": [7, 542, 543, 548, 551, 552, 620, 637], "actor_network": [7, 349, 350, 351, 352, 353, 355, 357, 358, 364, 365, 367, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 415, 419, 420, 421, 472, 473, 606, 620, 622, 627, 635, 636], "critic_network": [7, 349, 351, 365, 368, 370, 419, 420, 472, 473, 622, 636], "exp_nam": [7, 30, 393, 394, 395, 398, 399, 400, 401, 460, 462, 463, 560, 621, 629, 630], "my_experi": [7, 404], "0001": [7, 280, 299, 307, 468, 539, 542, 546], "chang": [7, 18, 21, 24, 26, 30, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 86, 87, 88, 90, 95, 96, 97, 98, 102, 107, 108, 110, 112, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 232, 234, 241, 244, 252, 253, 259, 263, 269, 271, 272, 273, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 420, 421, 568, 576, 592, 613, 620, 623, 633, 635, 636, 637, 638, 639, 642], "rate": [7, 23, 30, 78, 279, 280, 420, 621, 622, 635, 636], "multirun": 7, "01": [7, 217, 246, 280, 312, 349, 351, 365, 368, 380, 539, 541, 543, 549, 550], "8": [7, 25, 26, 60, 68, 71, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 108, 109, 120, 121, 122, 123, 124, 125, 126, 130, 138, 148, 149, 150, 151, 154, 158, 159, 160, 161, 170, 171, 172, 175, 178, 179, 180, 214, 217, 226, 227, 264, 267, 273, 280, 283, 284, 285, 288, 290, 291, 300, 305, 342, 344, 347, 364, 620, 621, 637, 639, 641], "my_custom_config": 7, "under": [7, 17, 18, 21, 23, 50, 60, 71, 78, 79, 80, 81, 83, 84, 85, 88, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 242, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 297, 298, 313, 314, 326, 332, 337, 340, 342, 344, 345, 366, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 393, 416, 592, 620, 621, 626, 635, 637, 642], "hood": [7, 17, 50, 78, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 637], "configstor": 7, "type": [7, 10, 21, 22, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 85, 86, 87, 88, 95, 120, 123, 126, 130, 138, 141, 144, 147, 150, 151, 152, 153, 154, 158, 159, 160, 167, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 204, 205, 209, 210, 212, 214, 218, 221, 225, 229, 230, 233, 234, 239, 241, 244, 250, 252, 253, 259, 263, 265, 269, 270, 271, 272, 273, 275, 277, 279, 280, 286, 288, 297, 305, 318, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 335, 336, 337, 342, 344, 345, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 402, 403, 404, 440, 464, 465, 471, 562, 575, 578, 613, 620, 621, 622, 624, 628, 632, 635, 636, 637, 639, 642], "safeti": [7, 32, 35, 36, 38, 144, 150, 158, 280, 613, 632], "id": [7, 26, 32, 34, 35, 36, 37, 38, 39, 40, 41, 46, 49, 52, 53, 55, 56, 69, 102, 108, 109, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 175, 177, 178, 179, 180, 200, 312, 324, 332, 352, 369, 396, 401, 463, 566, 568, 569, 571, 572, 574, 576, 579, 580, 581, 587, 628, 639], "registr": [7, 41, 402, 590, 621], "config_stor": 7, "cs": 7, "gymenvconfig": 7, "batchedenvconfig": 7, "tanhnormalmodelconfig": [7, 466], "inherit": [7, 21, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 193, 366, 376, 622, 635, 636], "envs_lib": 7, "envlibsconfig": 7, "mycustomenvconfig": 7, "_target_": [7, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 462, 463, 464, 465, 468, 469, 470, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552], "str": [7, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 95, 96, 97, 98, 101, 102, 114, 116, 120, 121, 123, 124, 125, 126, 128, 129, 130, 131, 132, 136, 138, 142, 143, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 210, 213, 217, 221, 233, 239, 240, 241, 243, 250, 254, 263, 264, 267, 269, 270, 272, 273, 275, 277, 278, 279, 282, 288, 289, 290, 291, 292, 293, 296, 297, 298, 300, 302, 304, 305, 306, 307, 311, 313, 314, 317, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 340, 342, 344, 345, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 462, 463, 464, 465, 468, 469, 470, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 554, 564, 566, 567, 568, 569, 571, 572, 573, 574, 575, 576, 578, 579, 580, 581, 582, 585, 586, 587, 613, 621, 622, 624, 632], "my_modul": [7, 572], "mycustomenv": 7, "myenv": [7, 150, 218, 229, 232], "custom_param": 7, "float": [7, 18, 21, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 58, 60, 64, 65, 69, 72, 75, 83, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 214, 217, 221, 225, 229, 232, 241, 242, 246, 250, 255, 256, 257, 264, 265, 268, 271, 272, 275, 277, 280, 286, 287, 295, 299, 303, 305, 306, 315, 316, 319, 320, 321, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 348, 349, 350, 351, 352, 356, 357, 358, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 413, 420, 421, 429, 465, 468, 472, 473, 484, 502, 504, 506, 514, 515, 516, 523, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 579, 580, 581, 582, 583, 585, 587, 592, 620, 621, 639, 642], "__post_init__": 7, "self": [7, 18, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 71, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 277, 278, 279, 282, 286, 301, 302, 304, 322, 325, 326, 327, 328, 330, 331, 332, 337, 342, 344, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 585, 586, 592, 613, 620, 632, 637, 641], "super": [7, 18, 21, 88, 144, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 322, 350, 352, 353, 358, 364, 369, 371, 372, 373, 383, 569, 571, 572, 574, 579, 581, 586, 587, 620, 637, 641], "my_custom": 7, "begin": [7, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 102, 108, 217, 405, 624, 625, 626, 627, 628, 629, 630, 632], "gradual": 7, "add": [7, 10, 16, 21, 23, 25, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 94, 96, 101, 104, 114, 115, 118, 119, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 221, 239, 241, 269, 272, 302, 304, 326, 332, 337, 349, 375, 376, 378, 380, 383, 384, 411, 420, 473, 569, 571, 572, 574, 579, 581, 587, 592, 603, 613, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 635, 636, 637, 639, 641], "leverag": [7, 39, 50, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 324, 592, 620, 636, 642], "sparingli": 7, "correctli": [7, 22, 26, 88, 90, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 592], "duplic": [7, 88, 107, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 350, 352, 354, 359, 364, 366, 369, 371, 372, 373, 376, 378, 380, 383, 384], "As": [7, 19, 22, 23, 68, 69, 72, 73, 74, 78, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 255, 295, 345, 386, 620, 621, 622, 623, 624, 625, 627, 628, 635, 636, 637, 638, 639, 641, 642], "td3": [7, 372, 373], "expand": [7, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 95, 108, 109, 176, 218, 265, 295, 325, 327, 328, 330, 331, 344, 347, 350, 352, 364, 366, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 635, 636, 637, 639, 641], "sactrainerconfig": 7, "td3trainerconfig": 7, "addit": [7, 16, 19, 22, 23, 37, 39, 46, 49, 63, 79, 86, 87, 88, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 163, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 225, 250, 265, 269, 271, 272, 275, 277, 286, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 337, 341, 344, 351, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 391, 393, 571, 572, 574, 587, 610, 613, 620, 621, 624, 625, 635, 636, 639], "maintain": [7, 18, 24, 28, 35, 36, 38, 63, 189, 192, 201, 221, 280, 358, 371, 575, 579, 592, 613, 637], "circumst": 8, "cudnn": [8, 302, 304, 623, 624], "7": [8, 10, 25, 29, 64, 65, 68, 72, 101, 102, 109, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 214, 217, 226, 227, 264, 267, 280, 287, 288, 291, 305, 324, 332, 337, 587, 620, 639, 641], "5x": 8, "batch_first": [8, 623], "input": [8, 9, 16, 17, 18, 20, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 96, 98, 111, 117, 120, 123, 126, 130, 138, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 243, 244, 248, 249, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 287, 288, 290, 291, 292, 293, 296, 297, 298, 301, 302, 303, 304, 305, 307, 308, 309, 312, 313, 314, 315, 316, 320, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 340, 341, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 409, 413, 553, 560, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587, 592, 596, 606, 620, 621, 622, 623, 624, 625, 632, 635, 636, 637, 641, 642], "fix": [8, 27, 150, 208, 265, 350, 352, 367, 371, 613, 621, 630, 637, 642], "5": [8, 10, 18, 19, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 72, 73, 78, 87, 88, 90, 108, 109, 114, 120, 123, 126, 127, 130, 136, 137, 138, 142, 143, 145, 150, 151, 154, 156, 157, 158, 159, 160, 163, 164, 170, 172, 175, 177, 178, 179, 180, 183, 193, 214, 217, 218, 220, 226, 227, 242, 255, 262, 263, 264, 270, 280, 287, 288, 290, 291, 296, 297, 299, 300, 303, 305, 308, 313, 320, 321, 324, 333, 334, 337, 341, 348, 365, 368, 370, 372, 373, 380, 391, 464, 465, 468, 470, 550, 592, 613, 619, 620, 621, 624, 626, 630, 635, 636, 637, 639, 640, 641, 642], "condit": [9, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 178, 183, 226, 227, 264, 279, 297, 298, 313, 314, 316, 341, 486, 575, 590, 592, 620, 635, 637, 639], "met": [9, 226, 227, 635, 637], "packedsequ": 9, "dropout": [9, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 287, 302, 304, 305, 326, 332, 337, 376, 378, 380, 383, 384, 465, 623], "comprehens": [10, 16, 420, 421, 592, 594, 599, 606, 613], "around": [10, 24, 26, 32, 72, 73, 89, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 341, 343, 345, 386, 592, 620, 621, 632, 636, 642], "central": [10, 12, 37, 41, 46, 49, 50, 324, 403, 613, 620, 621, 625, 635, 636, 639], "offer": [10, 16, 17, 20, 22, 26, 120, 121, 122, 123, 126, 130, 136, 137, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 270, 391, 599, 620, 621, 624, 625, 627, 628, 635, 637, 639, 642], "memmap": [10, 86, 87, 95, 97, 150, 158, 176, 279, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 393, 395, 412, 581, 582, 584], "compress": [10, 90, 91], "advanc": [10, 22, 50, 65, 68, 72, 73, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 324, 402, 590, 625, 628, 639], "priorit": [10, 27, 65, 72, 101, 102, 352, 353, 354, 356, 357, 358, 364, 369, 371, 372, 373, 429, 620, 621, 628, 641], "mix": [10, 251, 613, 620, 635, 636], "arbitrari": [10, 16, 17, 22, 57, 64, 68, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 620, 621, 637, 639], "lazymemmapstorag": [10, 12, 15, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 102, 108, 109, 220, 221, 425, 620, 621, 623, 628, 635, 638, 639], "prioritizedsampl": [10, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 102, 354, 359, 429, 620, 639], "max_siz": [10, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 95, 96, 97, 98, 108, 109, 110, 114, 116, 425, 426, 427, 428, 439, 622, 628], "1000000": [10, 78, 79, 80, 81, 82, 83, 84, 85, 402, 421, 539, 614], "max_capac": [10, 101, 102, 429, 620, 639], "alpha": [10, 65, 72, 101, 102, 288, 290, 291, 292, 293, 300, 350, 352, 358, 367, 369, 371, 372, 429, 539, 549, 620, 639, 641], "beta": [10, 23, 65, 72, 101, 102, 357, 364, 365, 384, 429, 542, 543, 544, 546, 547, 548, 552, 620, 621, 639, 641], "batch_siz": [10, 17, 18, 19, 22, 27, 34, 35, 38, 52, 55, 56, 60, 63, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 101, 102, 103, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 133, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 212, 213, 214, 218, 220, 221, 225, 229, 232, 233, 234, 239, 248, 252, 253, 255, 259, 262, 263, 265, 271, 272, 273, 283, 284, 285, 287, 294, 295, 296, 297, 298, 301, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 342, 344, 345, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 402, 406, 412, 418, 420, 421, 431, 438, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 478, 592, 613, 620, 621, 622, 623, 628, 632, 633, 635, 636, 637, 639, 641, 642], "256": [10, 34, 52, 142, 143, 239, 294, 592, 621, 622, 624, 635, 636], "randn": [10, 22, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 95, 96, 97, 102, 108, 109, 116, 120, 176, 188, 206, 220, 246, 283, 284, 285, 287, 289, 290, 294, 296, 297, 306, 307, 310, 311, 313, 322, 325, 327, 328, 330, 331, 338, 340, 342, 344, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 364, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 414, 464, 465, 468, 469, 470, 624, 639, 641, 642], "32": [10, 51, 60, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 109, 130, 137, 156, 157, 163, 164, 180, 185, 192, 193, 194, 221, 239, 288, 289, 290, 291, 293, 294, 300, 305, 308, 309, 311, 391, 402, 463, 464, 465, 468, 469, 470, 613, 621, 623, 624, 626, 627, 637, 638, 639, 641, 642], "compressedliststorag": [10, 91], "compressedliststoragecheckpoint": 10, "flatstoragecheckpoint": 10, "h5storagecheckpoint": 10, "immutabledatasetwrit": [10, 78, 79, 80, 81, 82, 83, 84, 85], "liststorag": [10, 12, 65, 66, 68, 69, 72, 73, 96, 428, 639], "lazystackstorag": [10, 88, 426], "liststoragecheckpoint": 10, "nestedstoragecheckpoint": 10, "storagecheckpointerbas": [10, 68, 110], "storageensembl": [10, 69, 106, 436], "storageensemblecheckpoint": 10, "tensorstorag": [10, 12, 68, 78, 79, 80, 81, 82, 83, 84, 85, 95, 101, 102, 114, 117, 439, 628, 639], "tensorstoragecheckpoint": [10, 95], "prioritizedslicesampl": [10, 639], "randomsampl": [10, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 430, 620, 635], "samplerensembl": [10, 69], "samplerwithoutreplac": [10, 88, 114, 433, 622, 636, 639], "slicesamplerwithoutreplac": [10, 108, 435, 639], "ataridqnexperiencereplai": 10, "d4rlexperiencereplai": 10, "gendgrlexperiencereplai": 10, "minariexperiencereplai": [10, 78, 79, 80, 82, 83, 84, 85], "openmlexperiencereplai": 10, "openxexperiencereplai": [10, 393], "robosetexperiencereplai": [10, 108, 109], "vd4rlexperiencereplai": 10, "tensorspec": [10, 17, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 75, 76, 77, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 213, 214, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 238, 240, 241, 242, 243, 244, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 286, 297, 298, 301, 312, 313, 314, 316, 340, 342, 343, 344, 345, 346, 348, 350, 352, 354, 357, 358, 369, 371, 372, 373, 383, 590, 637], "binari": [10, 18, 26, 64, 161, 215, 219, 297, 298, 313, 314, 354, 357, 358, 632], "bound": [10, 18, 23, 50, 60, 75, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 224, 245, 279, 286, 297, 298, 301, 312, 313, 314, 315, 316, 326, 332, 337, 340, 342, 343, 344, 345, 348, 349, 350, 352, 353, 364, 368, 369, 371, 372, 373, 376, 378, 380, 383, 384, 620, 621, 622, 624, 635, 637, 641, 642], "categor": [10, 19, 21, 57, 58, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 175, 178, 179, 180, 213, 214, 215, 233, 252, 297, 298, 310, 313, 314, 326, 342, 354, 357, 358, 475, 623], "multicategor": [10, 62], "multionehot": [10, 61, 354, 357, 358], "nontensor": [10, 17, 87, 175, 180, 239, 273], "onehot": [10, 57, 58, 59, 60, 61, 62, 63, 70, 71, 74, 75, 76, 77, 121, 122, 129, 131, 132, 135, 136, 137, 145, 146, 148, 149, 155, 161, 162, 297, 313, 354, 356, 357, 358], "stackedcomposit": 10, "unbound": [10, 18, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 76, 77, 86, 87, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 206, 215, 218, 229, 232, 252, 265, 322, 325, 327, 328, 330, 331, 340, 344, 347, 370, 377, 379, 381, 382, 385, 592, 632, 637, 639], "unboundedcontinu": [10, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 252, 265, 347], "unboundeddiscret": [10, 75, 151, 239], "offlin": [11, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 78, 80, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 350, 356, 357, 364, 372, 383, 401, 463, 590, 606, 625, 638, 639], "wide": [12, 22, 24, 641], "give": [12, 22, 26, 60, 71, 72, 80, 87, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 351, 365, 368, 591, 613, 620, 621, 624, 635, 636, 637, 638, 641], "abil": [12, 15, 366, 637, 639], "panel": [12, 622], "almost": [12, 280, 306, 623], "physic": [12, 25, 26, 93, 150, 151, 155, 620, 635, 636, 637], "theori": 12, "crude": 12, "made": [12, 18, 22, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 78, 88, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 265, 271, 312, 326, 332, 337, 354, 366, 376, 378, 380, 383, 384, 466, 620, 621, 623, 635, 636, 638, 639, 641], "ineffici": [12, 23], "contigu": [12, 18, 27, 58, 60, 75, 80, 83, 84, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 239, 242, 265, 273, 637, 639, 641], "collate_fn": [12, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 170, 171, 172, 175, 639, 641], "__init__": [12, 18, 21, 26, 88, 126, 144, 161, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 211, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 295, 322, 334, 350, 352, 353, 358, 364, 369, 371, 372, 373, 383, 613, 637, 642], "retriev": [13, 17, 22, 32, 35, 36, 37, 38, 39, 41, 46, 49, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 106, 108, 109, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 188, 189, 195, 196, 201, 212, 222, 230, 233, 246, 325, 327, 328, 330, 331, 337, 341, 342, 345, 348, 349, 350, 351, 352, 354, 365, 368, 369, 371, 372, 373, 377, 379, 380, 381, 382, 385, 386, 387, 388, 389, 402, 403, 404, 564, 573, 621, 622, 626, 637, 642], "dtype": [14, 18, 19, 22, 34, 35, 38, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 101, 102, 108, 109, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 209, 212, 213, 214, 215, 218, 219, 225, 226, 229, 230, 231, 232, 233, 234, 239, 241, 242, 246, 248, 250, 252, 253, 255, 259, 262, 263, 265, 267, 268, 271, 272, 273, 275, 277, 283, 284, 285, 287, 296, 297, 298, 302, 304, 312, 313, 314, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 342, 344, 345, 347, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 489, 527, 580, 585, 586, 588, 592, 624, 632, 633, 634, 637, 639, 641, 642], "domain": [14, 16, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 184, 206, 231, 239, 265, 273, 297, 298, 313, 314, 340, 342, 344, 345, 346, 347, 622, 627, 632, 635, 636, 637, 641, 642], "influenti": 15, "latenc": [15, 22, 613], "especi": [15, 17, 26, 27, 222, 326, 332, 337, 568], "larger": [15, 23, 42, 47, 50, 302, 304, 357, 364, 641], "volum": 15, "advis": [15, 30, 80, 629, 642], "due": [15, 22, 24, 33, 42, 43, 44, 45, 47, 48, 56, 351, 368, 421, 587, 627, 638, 639, 642], "memorymappedtensor": [15, 78, 79, 80, 81, 82, 83, 84, 85, 95, 395, 628], "file": [15, 25, 26, 27, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 78, 79, 80, 81, 83, 84, 85, 86, 87, 93, 95, 163, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 392, 393, 395, 416, 420, 421, 473, 581, 582, 583, 590, 613, 619, 621, 635, 639, 640], "improv": [15, 23, 30, 54, 177, 192, 237, 349, 420, 624, 635, 636, 639], "failur": [15, 23, 177, 324, 351, 368, 380, 592], "recoveri": 15, "wrapper": [16, 17, 21, 32, 55, 72, 73, 86, 87, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 169, 170, 171, 172, 175, 176, 178, 179, 180, 185, 189, 278, 282, 287, 323, 325, 326, 327, 328, 329, 330, 331, 332, 334, 337, 341, 343, 345, 377, 379, 381, 382, 385, 386, 398, 399, 400, 401, 564, 588, 590, 599, 619, 622, 623, 625, 631, 632, 635, 636, 638, 640, 641, 642], "popular": [16, 22, 623, 627, 636], "framework": [16, 18, 23, 28, 51, 120, 121, 122, 123, 126, 130, 136, 137, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 592, 613, 632, 633, 641, 642], "jumanji": [16, 18, 120, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 449], "envbas": [16, 17, 18, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 88, 120, 123, 127, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 215, 218, 229, 232, 245, 252, 253, 271, 272, 279, 302, 304, 339, 341, 383, 410, 554, 555, 556, 560, 562, 563, 564, 625], "foundat": [16, 18, 24, 152, 153, 424, 594, 622, 636], "output": [16, 17, 18, 19, 20, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 65, 68, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 137, 138, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 213, 218, 219, 221, 224, 225, 227, 228, 229, 230, 232, 234, 236, 239, 241, 244, 246, 250, 252, 253, 258, 259, 262, 263, 266, 267, 269, 271, 272, 273, 275, 277, 278, 280, 283, 286, 288, 289, 290, 291, 294, 296, 297, 298, 299, 302, 304, 305, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 340, 341, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 406, 592, 594, 596, 599, 606, 620, 621, 622, 623, 624, 625, 626, 629, 632, 633, 634, 635, 636, 637, 638, 641, 642], "infrastructur": [16, 19, 197, 635, 636], "transformedenv": [16, 21, 22, 30, 31, 88, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 218, 221, 224, 225, 227, 229, 232, 233, 234, 240, 241, 242, 245, 246, 248, 252, 253, 254, 255, 258, 259, 260, 263, 264, 265, 266, 270, 271, 279, 302, 304, 341, 383, 393, 405, 442, 572, 592, 620, 621, 622, 623, 624, 625, 629, 630, 634, 635, 636, 637, 638, 639, 641, 642], "rewardsum": [16, 21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 212, 271, 383, 517, 635, 636], "stepcount": [16, 88, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 226, 227, 270, 271, 272, 287, 383, 522, 592, 620, 621, 622, 623, 624, 625, 630, 635, 636, 641], "parallel_env": [16, 153, 620, 641, 642], "100": [16, 32, 34, 35, 36, 38, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 95, 97, 108, 109, 114, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 224, 226, 233, 246, 255, 260, 263, 298, 306, 324, 326, 332, 337, 341, 376, 378, 380, 383, 384, 393, 407, 421, 545, 560, 568, 613, 621, 622, 624, 625, 627, 630, 634, 635, 636, 637, 639, 641, 642], "lock": [16, 60, 71, 86, 87, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 218, 227, 265, 279, 280, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 637], "partial": [16, 17, 32, 34, 35, 36, 38, 52, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 220, 221, 264, 265, 266, 303, 320, 342, 416, 623], "invers": [16, 23, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 221, 229, 232, 234, 239, 243, 246, 253, 255, 267, 269, 271, 273, 351, 357, 364, 368, 380, 383, 637], "marlgroupmaptyp": [16, 142, 143, 148, 149, 152, 153, 161, 162, 163, 164, 166, 635], "check_marl_group": 16, "auto": [16, 54, 89, 97, 116, 126, 131, 216, 217, 272, 278, 312, 350, 352, 358, 367, 369, 371, 372, 373, 402, 404, 587, 635, 636], "dynam": [16, 26, 34, 35, 36, 38, 80, 83, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 206, 357, 364, 402, 594, 599, 604, 622, 625, 637], "record": [16, 30, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 207, 214, 241, 326, 332, 337, 368, 376, 378, 380, 383, 384, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 410, 421, 460, 462, 463, 560, 590, 614, 621, 622, 626, 630, 635], "dm": [17, 620, 642], "abl": [17, 21, 22, 120, 141, 152, 153, 154, 159, 302, 304, 620, 622, 623, 626, 634, 635, 636, 637, 639], "simul": [17, 18, 19, 20, 24, 26, 27, 74, 121, 122, 123, 132, 136, 137, 155, 163, 164, 170, 208, 317, 592, 620, 622, 624, 625, 629, 633, 635, 636], "box": [17, 19, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 129, 131, 366, 376, 378, 380, 384, 632], "lib": [17, 18, 19, 24, 25, 26, 28, 29, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 88, 120, 123, 126, 127, 130, 135, 138, 142, 143, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 221, 224, 233, 240, 241, 246, 248, 253, 255, 258, 265, 271, 278, 279, 383, 391, 443, 444, 445, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 560, 620, 621, 622, 623, 634, 636, 638, 639, 641, 642], "hope": [17, 30], "imit": [17, 363], "parent": [17, 20, 21, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 63, 69, 74, 88, 112, 119, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 221, 222, 225, 226, 227, 230, 233, 236, 237, 244, 246, 250, 258, 263, 264, 265, 266, 270, 271, 274, 275, 283, 302, 304, 326, 332, 337, 366, 368, 376, 378, 380, 383, 384, 390, 391, 393, 466, 467, 568, 572, 620, 628, 637, 641, 642], "subclass": [17, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 58, 60, 69, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 216, 217, 271, 278, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 337, 338, 341, 344, 345, 346, 348, 366, 368, 569, 571, 572, 574, 579, 581, 586, 587, 613, 621, 623, 628, 637, 639], "organis": [17, 84, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272, 621], "togeth": [17, 21, 30, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 70, 71, 96, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 251, 262, 271, 283, 284, 285, 302, 304, 323, 587, 592, 621, 623, 625, 635], "live": [17, 22, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 233, 326, 332, 337, 376, 378, 380, 383, 384, 493], "doe": [17, 18, 21, 22, 40, 42, 65, 72, 78, 79, 83, 86, 87, 88, 92, 93, 100, 102, 108, 110, 112, 119, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 280, 294, 295, 302, 304, 325, 326, 327, 328, 330, 331, 332, 337, 346, 347, 349, 351, 359, 365, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 416, 569, 620, 621, 622, 623, 625, 628, 635, 637, 639, 642], "respons": [17, 20, 22, 27, 34, 35, 36, 38, 41, 42, 47, 50, 52, 53, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 174, 175, 177, 178, 179, 180, 183, 186, 187, 190, 193, 203, 325, 327, 329, 330, 331, 332, 337, 380, 384, 416, 565, 592, 594, 627, 628, 632, 633, 642], "just": [17, 22, 23, 86, 87, 112, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 135, 136, 137, 138, 141, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 175, 176, 178, 179, 180, 213, 217, 224, 265, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 406, 592, 613, 620, 621, 622, 623, 624, 625, 626, 628, 632, 635, 636, 637, 639, 641, 642], "care": [17, 20, 21, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 338, 341, 348, 393, 620, 622, 624, 635, 636, 637, 639], "desir": [17, 18, 30, 32, 34, 35, 36, 38, 52, 59, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 216, 218, 225, 227, 246, 248, 250, 251, 265, 271, 272, 275, 277, 288, 295, 297, 298, 305, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 344, 345, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 620, 624, 632, 635, 636, 637, 639], "parametr": [17, 307, 345, 350, 352, 357, 364, 371, 620, 622], "pair": [17, 22, 55, 79, 86, 87, 120, 123, 124, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 255, 265, 270, 283, 302, 325, 327, 328, 330, 331, 342, 345, 366, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 579, 601, 620, 621, 622, 626, 627, 634, 637, 642], "state_spec": [17, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 225, 230, 243, 246, 271, 273, 274, 383, 637, 642], "empti": [17, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 98, 120, 123, 126, 130, 137, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 206, 229, 232, 250, 252, 266, 272, 275, 277, 280, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 397, 403, 613, 620, 637], "reward_spec": [17, 18, 19, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 218, 219, 224, 225, 229, 230, 232, 242, 243, 252, 256, 257, 258, 260, 262, 269, 271, 273, 274, 280, 383, 592, 622, 632, 635, 636, 637, 642], "done_spec": [17, 18, 19, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 229, 230, 232, 233, 243, 252, 262, 269, 271, 273, 383, 635, 636, 637, 642], "termin": [17, 18, 19, 22, 26, 32, 34, 35, 36, 38, 52, 66, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 100, 108, 120, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 142, 143, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 178, 179, 180, 185, 208, 213, 214, 217, 218, 233, 239, 252, 265, 273, 302, 304, 341, 346, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 386, 387, 388, 389, 390, 402, 403, 592, 613, 620, 621, 622, 632, 635, 636, 637, 641, 642], "input_spec": [17, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 225, 229, 230, 231, 244, 248, 252, 253, 258, 259, 262, 263, 264, 265, 269, 271, 272, 273, 276, 383, 622, 637], "full_action_spec": [17, 120, 123, 126, 130, 138, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 175, 178, 179, 180, 214, 230, 635, 636], "full_state_spec": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 214, 230], "output_spec": [17, 19, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 272, 273, 280, 383, 637], "full_observation_spec": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180], "full_reward_spec": [17, 18, 19, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 218, 230, 252, 635, 636], "full_done_spec": [17, 18, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 218, 230, 252, 635, 636], "carri": [17, 19, 50, 62, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 265, 280, 366, 376, 378, 380, 384, 621, 623, 635, 636, 637, 639], "spec_lock": [17, 126], "modif": [17, 19, 22, 24, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 236, 239, 326, 332, 337, 366, 376, 378, 380, 383, 384, 592, 622, 637], "children": [17, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "unlock": [17, 22, 60, 71, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "set_spec_lock_": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "reason": [17, 21, 22, 23, 27, 83, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 275, 304, 326, 332, 337, 376, 378, 380, 383, 384, 592, 620, 621, 622, 627, 628, 635, 637, 639], "cach": [17, 20, 32, 35, 36, 38, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 102, 108, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 194, 212, 217, 229, 232, 250, 271, 272, 277, 324, 407, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587, 592], "modifi": [17, 18, 22, 26, 27, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 225, 227, 236, 239, 241, 243, 250, 265, 271, 272, 275, 277, 280, 312, 325, 326, 327, 328, 330, 331, 332, 337, 344, 345, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 553, 592, 620, 621, 622, 624, 625, 635, 636, 637], "often": [17, 22, 27, 351, 366, 368, 376, 378, 380, 384, 416, 620, 621, 625, 627, 637, 639, 642], "principl": [17, 592], "new_spec": 17, "eras": [17, 21, 22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272], "relock": 17, "wa": [17, 22, 24, 26, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 91, 95, 102, 107, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 185, 213, 221, 239, 272, 325, 326, 327, 328, 330, 331, 332, 337, 349, 351, 365, 368, 370, 377, 379, 380, 381, 382, 385, 403, 566, 568, 571, 572, 573, 574, 576, 579, 581, 587, 621, 622, 625, 626, 634, 635, 639, 641], "previous": [17, 23, 81, 403, 622, 642], "importantli": [17, 342, 345], "action_s": 17, "prealloc": [17, 22, 150, 158, 637], "necessarili": [17, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 642], "present": [17, 18, 19, 22, 52, 65, 66, 68, 69, 74, 78, 79, 83, 86, 87, 88, 101, 102, 107, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 234, 255, 259, 265, 270, 272, 288, 289, 290, 291, 292, 293, 300, 302, 304, 311, 312, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 345, 346, 347, 349, 350, 351, 352, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 564, 620, 630, 634, 635, 636, 639, 641], "0s": [17, 78, 83, 265, 623], "step_and_maybe_reset": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 592, 625, 632], "next": [17, 18, 19, 23, 27, 34, 35, 38, 53, 56, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 92, 93, 100, 102, 108, 109, 114, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 136, 137, 138, 142, 143, 144, 148, 149, 150, 151, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 178, 179, 180, 183, 185, 188, 190, 192, 193, 195, 206, 212, 214, 217, 218, 220, 221, 226, 227, 229, 232, 233, 234, 239, 240, 241, 242, 244, 248, 252, 253, 255, 258, 259, 263, 265, 267, 270, 273, 278, 279, 280, 302, 304, 316, 317, 323, 341, 349, 350, 352, 353, 354, 356, 357, 358, 359, 364, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 390, 393, 409, 410, 413, 434, 435, 592, 613, 621, 623, 624, 626, 630, 632, 637, 638, 641, 642], "step_mdp": [17, 60, 71, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 302, 304, 623, 625, 637, 641, 642], "done_kei": [17, 18, 19, 56, 88, 92, 93, 100, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 217, 221, 233, 255, 263, 383, 493, 635, 636], "_reset": [17, 18, 22, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 215, 217, 218, 221, 229, 232, 240, 252, 267, 635], "data_": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "append": [17, 19, 20, 21, 27, 30, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 182, 185, 195, 217, 224, 225, 244, 255, 265, 272, 278, 297, 302, 304, 313, 592, 594, 620, 621, 622, 623, 624, 632, 635, 636, 637, 638, 639, 641], "set_se": [17, 18, 32, 34, 35, 36, 38, 50, 52, 53, 120, 121, 122, 123, 126, 130, 136, 137, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 226, 227, 246, 253, 258, 264, 266, 272, 592, 624, 628, 630, 637, 641, 642], "seed": [17, 18, 32, 34, 35, 36, 38, 50, 52, 53, 68, 69, 72, 73, 84, 120, 123, 126, 130, 138, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 175, 178, 179, 180, 181, 215, 218, 229, 232, 239, 252, 272, 391, 416, 420, 421, 473, 635], "determinist": [17, 32, 34, 35, 36, 38, 42, 44, 47, 50, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 210, 225, 250, 265, 271, 272, 275, 277, 289, 299, 308, 315, 316, 317, 326, 332, 337, 340, 342, 344, 345, 348, 350, 351, 366, 368, 376, 378, 380, 383, 384, 410, 600, 620, 621, 622, 623, 624, 626, 627, 630, 635, 637, 641, 642], "preced": [17, 123, 221, 419, 623], "risk": [17, 251], "overlap": [17, 72, 114], "mark": [17, 34, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 267, 302, 304, 386, 388, 389, 628, 639], "trail": [17, 63, 177, 279, 632], "treat": [17, 21, 626, 627], "figur": [17, 21, 620, 622, 623, 636, 637, 642], "brief": [17, 622, 625, 627, 639], "entri": [17, 19, 21, 22, 32, 35, 36, 38, 56, 60, 71, 79, 80, 81, 82, 84, 85, 86, 87, 88, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 142, 143, 150, 151, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 217, 221, 223, 224, 227, 228, 229, 230, 232, 233, 236, 240, 242, 244, 246, 248, 250, 253, 255, 258, 260, 262, 263, 264, 265, 267, 270, 272, 274, 277, 279, 297, 302, 306, 313, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 350, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 620, 622, 623, 625, 626, 627, 629, 635, 636, 637, 638, 639, 641, 642], "metaclass": [17, 126, 131], "everi": [17, 27, 32, 34, 35, 36, 38, 39, 52, 53, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 110, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 263, 264, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 326, 332, 337, 338, 341, 348, 351, 365, 366, 368, 376, 378, 380, 383, 384, 416, 620, 621, 622, 623, 625, 626, 635, 636, 637], "flank": [17, 623], "dual": 17, "strictli": [17, 27, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 242, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384, 620, 622], "union": [17, 34, 47, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 275, 277, 288, 289, 290, 291, 292, 293, 300, 305, 311, 324, 326, 332, 337, 344, 356, 358, 369, 376, 378, 380, 383, 384, 412, 561, 564], "interpret": [17, 65, 66, 68, 69, 192, 193, 592, 613, 621], "truncat": [17, 18, 19, 22, 32, 34, 35, 36, 38, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 93, 100, 102, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 178, 179, 180, 185, 213, 214, 233, 234, 239, 245, 252, 255, 259, 263, 265, 272, 273, 302, 304, 321, 330, 341, 386, 434, 435, 522, 620, 622, 625, 635, 642], "look": [17, 19, 22, 24, 26, 27, 86, 87, 88, 102, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 226, 239, 250, 251, 275, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 346, 347, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 622, 623, 624, 625, 626, 627, 628, 629, 630, 635, 636, 637, 638, 639, 641, 642], "assess": [17, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 71, 142, 143, 166, 175, 620], "split_trajectori": [17, 32, 34, 35, 36, 38, 42, 44, 47, 50, 78, 83, 102, 108, 109], "adjac": [17, 56, 236, 341], "junction": 17, "miss": [17, 22, 23, 25, 26, 60, 88, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 239, 270, 272, 278, 282, 326, 332, 337, 346, 347, 349, 352, 368, 371, 376, 378, 380, 383, 384, 591, 613, 620, 623, 633], "inittrack": [17, 302, 304, 341, 500, 620, 623], "our": [17, 18, 21, 26, 27, 30, 42, 68, 221, 226, 393, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 634, 635, 636, 638, 639, 641], "tutori": [17, 21, 151, 184, 589, 619, 620, 621, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 637, 638, 639, 640, 642], "inform": [17, 18, 19, 21, 23, 32, 34, 35, 36, 38, 42, 44, 47, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 86, 87, 88, 101, 102, 120, 123, 126, 127, 130, 133, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 287, 288, 305, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 416, 420, 473, 620, 621, 622, 623, 624, 625, 632, 635, 636, 637, 639, 641], "scratch": [17, 27, 621, 637], "mission": 18, "irrespect": [18, 344, 345], "statu": [18, 46, 126, 189, 190], "mostli": [18, 22, 32, 393, 629, 639, 642], "Its": [18, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 279, 326, 332, 337, 344, 376, 378, 380, 383, 384, 390], "success": [18, 78, 79, 80, 81, 82, 83, 84, 85, 172, 174, 177, 178, 185, 190, 192, 221, 267, 301, 352, 372, 592, 621, 628, 630, 633, 637, 639, 641], "inspir": [18, 624, 637], "howev": [18, 24, 26, 54, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 326, 332, 337, 349, 351, 352, 365, 368, 370, 371, 376, 378, 380, 383, 384, 592, 620, 621, 623, 624, 627, 637, 639, 642], "gone": [18, 23, 24, 341], "sometim": [18, 74, 623, 642], "hard": [18, 26, 35, 36, 38, 114, 124, 125, 150, 621, 642], "accommod": [18, 19, 613, 625, 626], "extern": [18, 229, 232, 280, 324, 335, 336, 613, 632, 635, 642], "adopt": [18, 24, 620, 642], "moreov": 18, "facilit": [18, 26, 249, 250, 265, 275, 277, 283, 284, 285, 620, 623, 626, 637], "instal": [18, 24, 29, 42, 44, 47, 79, 82, 120, 123, 126, 130, 135, 138, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 190, 395, 404, 416, 591, 620, 622, 623, 624, 625, 626, 627, 628, 629, 630, 635, 636, 642], "virtual": [18, 129], "concomittantli": 18, "fortun": [18, 21, 623, 624, 625, 626, 629], "decor": [18, 27, 209, 211, 282, 302, 304, 366, 386, 387, 388, 389, 405, 592, 623, 641], "set_gym_backend": [18, 32, 34, 35, 36, 38, 52, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 175, 178, 179, 180, 217, 625, 641], "relev": [18, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 386, 387, 388, 389, 390, 401, 624, 637], "gym_backend": [18, 211], "env1": [18, 287, 634], "venv": 18, "python3": [18, 25, 26, 29], "site": [18, 25, 26, 84, 123, 211], "env2": [18, 634], "_env": [18, 25, 129, 642], "classic_control": 18, "pendulumenv": [18, 637], "0x15147e190": 18, "0x1629916a0": 18, "further": [18, 22, 24, 384, 620, 622, 624, 625], "mo_gymnasium": [18, 140, 169, 242], "handi": [18, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 629], "v0": [18, 35, 36, 38, 60, 71, 86, 87, 120, 123, 126, 130, 132, 135, 136, 137, 138, 139, 140, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 225, 242, 272, 279, 280, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 405, 560], "26": [18, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 195, 196, 226], "fun": [18, 211, 282, 622, 635, 636], "effect": [18, 22, 34, 52, 53, 60, 65, 66, 68, 69, 72, 73, 78, 83, 86, 87, 88, 101, 102, 106, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 217, 221, 227, 272, 325, 326, 327, 328, 330, 331, 332, 337, 351, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 416, 421, 592, 620, 626, 635, 639, 642], "autoresettransform": [18, 477], "skip": [18, 20, 22, 33, 34, 39, 42, 43, 44, 45, 47, 48, 50, 52, 53, 78, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 237, 239, 244, 270, 272, 326, 331, 332, 337, 342, 345, 352, 366, 371, 376, 378, 380, 383, 384, 386, 387, 388, 389, 392, 393, 408, 410, 420, 421, 473, 620, 621, 633, 637], "fine": [18, 68, 69, 72, 73, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 218, 241, 384, 592, 624, 628, 638], "grain": [18, 68, 69, 72, 73, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 218], "invalid": [18, 88, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 166, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 306, 326, 332, 333, 337, 376, 378, 380, 383, 384, 633], "nan": [18, 217, 278, 477], "auto_reset": [18, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 217, 637], "auto_reset_replac": [18, 217], "replac": [18, 21, 25, 26, 78, 83, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 217, 231, 233, 240, 279, 280, 301, 324, 326, 332, 337, 350, 352, 358, 364, 369, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 433, 435, 477, 635, 639, 641], "placehold": [18, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 131, 132, 175, 233, 272, 278], "manual_se": [18, 57, 61, 65, 68, 72, 73, 80, 84, 85, 86, 87, 96, 108, 109, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 215, 217, 226, 227, 231, 246, 255, 258, 264, 266, 280, 298, 301, 306, 310, 312, 325, 327, 328, 330, 331, 340, 345, 348, 349, 350, 352, 353, 357, 364, 371, 377, 379, 381, 382, 385, 624, 628, 630, 635, 636, 637, 641, 642], "autoresettinggymenv": [18, 217], "_step": [18, 21, 22, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 236, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 383], "td_reset": [18, 217], "exclud": [18, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 84, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 195, 196, 212, 217, 221, 234, 329, 337, 351, 365, 368, 380, 635, 636, 639], "r": [18, 20, 23, 86, 87, 89, 123, 172, 175, 176, 190, 193, 197, 214, 215, 217, 224, 226, 227, 246, 260, 267, 270, 279, 280, 287, 325, 327, 328, 330, 331, 345, 368, 377, 379, 381, 382, 385, 391, 592, 621, 637, 642], "break_when_any_don": [18, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 217, 270, 287, 341, 636], "squeez": [18, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 217, 218, 221, 226, 261, 264, 288, 620, 624, 637, 639], "creation": [18, 19, 150, 158, 196, 332, 380, 473, 568, 587, 642], "imposs": [18, 20, 68, 72, 73, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 349, 351, 365, 368, 370], "forecast": 18, "awar": [18, 26, 60, 71, 88, 90, 95, 96, 97, 98, 110, 112, 116, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 271, 302, 304, 324, 383, 621, 623], "detect": [18, 20, 85, 87, 89, 174, 178, 366, 375, 376, 378, 380, 384, 402, 578, 592, 594], "return_contigu": [18, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 634], "tensordictbas": [18, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 114, 120, 123, 126, 128, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 212, 213, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 233, 234, 235, 236, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 280, 286, 298, 301, 302, 304, 312, 314, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 345, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 416, 565, 566, 568, 569, 571, 572, 574, 575, 576, 578, 579, 581, 587, 620, 635, 637], "envwithdynamicspec": 18, "max_count": 18, "bool": [18, 19, 22, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 94, 95, 96, 97, 98, 101, 102, 104, 106, 107, 108, 109, 110, 115, 116, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 213, 214, 215, 217, 218, 221, 222, 226, 227, 229, 231, 232, 233, 234, 236, 239, 241, 243, 244, 245, 246, 248, 250, 252, 253, 255, 257, 258, 259, 262, 263, 265, 268, 269, 270, 272, 273, 274, 275, 277, 279, 280, 282, 286, 287, 288, 290, 291, 297, 298, 302, 303, 304, 305, 306, 313, 314, 317, 319, 320, 321, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 340, 341, 342, 344, 345, 346, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 393, 401, 402, 405, 408, 409, 410, 412, 413, 416, 420, 421, 425, 426, 427, 428, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 475, 477, 478, 503, 505, 506, 516, 522, 527, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 564, 565, 566, 568, 569, 571, 572, 574, 576, 578, 579, 580, 581, 582, 583, 585, 587, 592, 621, 622, 624, 632, 633, 637, 641, 642], "full": [18, 19, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 188, 190, 195, 196, 197, 298, 302, 304, 325, 327, 328, 330, 331, 332, 337, 345, 368, 376, 377, 378, 379, 380, 381, 382, 385, 406, 592, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "_set_se": [18, 215, 218, 229, 232, 252, 637], "int": [18, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 94, 95, 96, 97, 98, 101, 102, 103, 104, 106, 108, 109, 110, 114, 115, 116, 118, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 142, 143, 144, 145, 146, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 205, 206, 214, 216, 217, 218, 220, 221, 222, 223, 225, 228, 231, 236, 237, 239, 243, 244, 245, 246, 248, 250, 251, 254, 261, 262, 263, 266, 269, 270, 272, 274, 275, 277, 286, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 301, 303, 305, 306, 308, 309, 311, 312, 314, 315, 316, 319, 320, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 341, 342, 344, 345, 349, 350, 351, 358, 360, 361, 365, 366, 367, 368, 369, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 389, 392, 393, 395, 398, 400, 401, 402, 406, 407, 408, 410, 412, 416, 419, 420, 421, 425, 426, 427, 428, 429, 431, 434, 435, 438, 439, 440, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 463, 464, 465, 472, 473, 475, 477, 478, 480, 481, 482, 483, 488, 491, 497, 503, 504, 505, 507, 510, 513, 520, 521, 522, 525, 528, 529, 532, 545, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 579, 580, 581, 582, 587, 624, 637, 639], "lazystackedtensordict": [18, 52, 71, 78, 86, 87, 96, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 634], "field": [18, 19, 22, 32, 34, 35, 36, 38, 52, 53, 56, 60, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 101, 108, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 218, 229, 232, 233, 234, 239, 248, 252, 253, 255, 259, 262, 263, 265, 270, 272, 273, 283, 284, 285, 287, 296, 297, 298, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 342, 344, 347, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 473, 554, 591, 592, 621, 633, 637], "float32": [18, 21, 34, 35, 38, 58, 60, 65, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 95, 96, 97, 101, 102, 108, 116, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 144, 147, 148, 149, 150, 151, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 206, 212, 214, 218, 229, 232, 233, 234, 239, 242, 246, 248, 252, 253, 255, 259, 262, 263, 265, 268, 273, 283, 284, 285, 287, 296, 297, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 342, 344, 347, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 489, 632, 637], "is_shar": [18, 22, 34, 35, 38, 52, 56, 60, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 95, 96, 97, 101, 108, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 185, 212, 214, 218, 229, 232, 233, 234, 239, 248, 252, 253, 255, 259, 262, 263, 265, 273, 279, 283, 284, 285, 287, 296, 297, 298, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 342, 344, 347, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 637], "exclusive_field": [18, 52, 78, 86, 87, 96, 120, 172, 175, 176, 185, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "stack_dim": [18, 52, 78, 86, 87, 96, 120, 172, 175, 176, 185, 205, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 426], "absenc": [18, 22], "dramat": 18, "carefulli": [18, 183, 635, 636, 642], "against": [18, 24, 26, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 297, 298, 313, 314, 326, 332, 337, 340, 342, 344, 345, 350, 352, 364, 369, 371, 372, 373, 376, 378, 380, 383, 384, 622, 635, 636], "plain": [18, 27, 350, 352, 358, 364, 369, 371, 372, 373, 387, 388, 389, 625], "deseri": 18, "larg": [18, 23, 59, 86, 87, 101, 102, 108, 109, 176, 229, 232, 275, 324, 325, 327, 328, 330, 331, 332, 349, 351, 365, 368, 370, 377, 379, 380, 381, 382, 385, 568, 621, 622, 633, 635, 636, 639], "expens": [18, 20, 53, 102, 108, 109, 391, 639], "check_env_spec": [18, 20, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 214, 239, 252, 273, 391, 622, 635, 636, 637], "vari": [18, 19, 129, 131, 132, 152, 153, 155, 163, 251, 624, 636], "absent": [18, 60, 71, 79, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 259, 272], "view": [19, 27, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 83, 84, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 305, 326, 332, 337, 376, 378, 380, 383, 384, 592, 625, 637, 639, 641, 642], "act": [19, 22, 23, 108, 109, 152, 153, 272, 296, 350, 352, 353, 364, 369, 371, 372, 373, 623, 624, 635, 636, 639, 641], "paradigm": [19, 32, 636], "decpodp": 19, "markov": [19, 625, 642], "game": [19, 20, 23, 24, 78, 123, 142, 143, 148, 149, 226, 288, 393, 624, 629], "thank": [19, 170, 195, 196, 384, 620, 624, 625, 641], "carrier": [19, 622, 623, 625, 639], "particular": [19, 79, 80, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 272, 326, 332, 337, 376, 378, 380, 383, 384, 621, 623, 625, 634, 636, 639], "thu": [19, 365, 636], "vma": [19, 163, 164, 391, 459, 635, 636], "robot": [19, 24, 26, 83, 250, 275, 277, 368, 624, 636], "vmasenv": [19, 391, 459, 635, 636], "balanc": [19, 101, 102, 124, 125, 324, 620, 621], "num_env": [19, 32, 35, 36, 38, 50, 120, 129, 133, 146, 163, 164, 171, 172, 175, 181, 391, 446, 450, 613, 635, 636], "n_agent": [19, 163, 164, 391, 635, 636], "td": [19, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 101, 102, 114, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 139, 140, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 175, 176, 178, 179, 180, 183, 185, 186, 190, 212, 215, 218, 220, 222, 226, 227, 229, 230, 231, 232, 240, 241, 242, 244, 246, 255, 258, 262, 265, 268, 272, 279, 283, 284, 285, 287, 296, 297, 301, 312, 313, 322, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 343, 344, 347, 376, 377, 378, 379, 380, 381, 382, 384, 385, 387, 388, 389, 392, 406, 414, 592, 606, 620, 621, 623, 636, 637, 638, 641], "info": [19, 35, 38, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 106, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 142, 143, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 175, 178, 179, 180, 190, 239, 273, 275, 278, 281, 401, 571, 572, 573, 574, 625, 630, 632, 635, 636, 639, 641], "ground_rew": 19, "pos_rew": 19, "16": [19, 20, 32, 35, 36, 38, 52, 84, 88, 102, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 324, 326, 329, 332, 337, 376, 378, 380, 383, 384, 613, 623, 639], "style": [19, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 187, 197, 203, 376, 421], "info_spec": [19, 150], "agent_i_action_spec": 19, "agent_i_reward_spec": 19, "agent_i_observation_spec": 19, "prefix": [19, 56, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 267, 270, 272, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 352, 366, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 392, 402, 416, 420, 473, 623, 627, 632, 642], "exactli": [19, 88, 120, 123, 126, 130, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 310, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384, 620, 623, 628, 635, 636], "action_kei": [19, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 214, 215, 231, 241, 244, 286, 301, 312, 341, 343, 475, 635, 636], "reward_kei": [19, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 409, 413, 635, 636], "right": [19, 22, 25, 26, 56, 102, 108, 180, 226, 332, 337, 621, 622, 624, 636, 637, 642], "set_kei": [19, 233, 349, 351, 352, 354, 357, 358, 359, 364, 365, 366, 368, 369, 370, 371, 376, 378, 380, 384, 390, 620, 635, 636], "awai": [19, 622, 625, 635, 636, 641], "eas": [19, 635, 636], "access": [19, 21, 26, 27, 30, 32, 34, 35, 36, 38, 52, 53, 65, 80, 81, 82, 88, 95, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 221, 250, 271, 275, 324, 326, 332, 337, 376, 378, 380, 383, 384, 402, 403, 404, 564, 575, 590, 591, 606, 620, 625, 635, 636, 637, 639, 641], "leaf": [19, 21, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 240, 263, 265, 271, 345], "abov": [19, 21, 22, 26, 54, 75, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 271, 303, 320, 321, 326, 332, 337, 376, 378, 380, 383, 384, 592, 620, 622, 624, 625, 626, 635, 636, 637, 642], "would": [19, 21, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 302, 304, 305, 326, 332, 337, 345, 376, 378, 380, 383, 384, 621, 622, 623, 625, 627, 628, 637, 639, 641, 642], "ey": 20, "report": [20, 121, 122, 136, 137, 420, 629], "foremost": 20, "callback": [20, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 636], "callabl": [20, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 120, 123, 126, 127, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 211, 216, 218, 225, 226, 227, 233, 239, 243, 265, 272, 273, 282, 288, 303, 305, 320, 326, 332, 337, 345, 366, 376, 378, 380, 383, 384, 391, 419, 420, 421, 555, 556, 562, 563, 564, 579, 621, 639], "upon": [20, 27, 41, 635, 637], "ad": [20, 23, 32, 34, 35, 36, 38, 52, 56, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 258, 270, 272, 312, 325, 326, 327, 328, 330, 331, 332, 337, 349, 351, 352, 354, 359, 365, 368, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 592, 621, 623, 624, 626, 632, 635, 639, 641, 642], "save": [20, 27, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 98, 100, 110, 111, 112, 116, 117, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 278, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 392, 393, 395, 401, 416, 420, 421, 473, 613, 614, 624, 628, 629, 630, 635, 636], "disk": [20, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 91, 95, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 416, 620, 621, 623, 624, 628, 629, 635, 639], "tensordictrecord": 20, "imag": [20, 23, 26, 30, 83, 86, 90, 221, 223, 226, 228, 250, 268, 277, 305, 391, 393, 620, 621, 624, 625, 629, 636, 638, 642], "pixel": [20, 21, 22, 26, 60, 69, 85, 123, 124, 125, 129, 131, 132, 155, 221, 223, 228, 233, 236, 238, 246, 248, 250, 254, 268, 275, 277, 290, 308, 309, 391, 393, 620, 621, 623, 624, 629, 635, 638, 639, 641, 642], "atari": [20, 22, 23, 78, 79, 80, 81, 83, 84, 85, 90, 221, 288, 393, 624, 629, 642], "videorecord": [20, 30, 391, 622, 629, 630, 635], "csvlogger": [20, 30, 391, 393, 460, 614, 621, 629, 630, 635], "wandblogg": [20, 463, 614, 629], "tensorboardlogg": [20, 462, 560, 614, 629], "tag": [20, 26, 30, 174, 175, 177, 187, 200, 203, 391, 393, 395, 398, 564, 592, 629, 630, 632, 635], "mp4": [20, 391, 393, 395, 630, 635], "video_format": [20, 391, 393, 395, 460, 630, 635], "whc": 20, "cwh": 20, "dummi": [20, 160, 185, 391, 620, 624, 628, 642], "exp": [20, 307], "al": [20, 32, 34, 35, 36, 38, 52, 129, 131, 233, 248, 493, 624, 642], "pong": [20, 32, 34, 35, 36, 38, 52, 78, 146, 248, 624, 642], "v5": [20, 32, 34, 35, 36, 38, 52, 129, 131, 146, 233, 248, 624, 642], "append_transform": [20, 21, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 207, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 280, 287, 302, 304, 383, 391, 592, 613, 620, 623, 632, 635, 637, 639, 641, 642], "grow": [20, 96], "tediou": [20, 625], "workspac": [20, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 239], "assum": [20, 22, 25, 34, 35, 36, 37, 38, 39, 46, 49, 50, 54, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 72, 73, 74, 75, 76, 77, 79, 81, 83, 84, 85, 92, 93, 100, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 206, 220, 223, 228, 236, 250, 251, 258, 265, 272, 275, 277, 287, 302, 304, 348, 354, 358, 359, 371, 383, 393, 565, 620, 622, 634, 637], "pixelrendertransform": [20, 635], "stream": [20, 83, 90], "alik": [20, 391], "envcreat": [20, 34, 50, 51, 150, 158, 270, 280, 391, 560, 561, 564, 620, 621, 641, 642], "render_mod": [20, 391, 446, 450, 637], "rgb_arrai": [20, 391, 635, 636, 637], "uncom": [20, 629], "line": [20, 26, 78, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 621, 629, 635, 636], "__name__": [20, 32, 34, 35, 36, 38, 51, 52, 66, 127, 280, 391, 621, 641], "__main__": [20, 32, 34, 35, 36, 38, 51, 52, 66, 127, 280, 391, 641], "comment": [20, 621, 641], "pixels_record": [20, 391], "close": [20, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 52, 66, 88, 120, 130, 145, 173, 174, 177, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 241, 271, 280, 339, 349, 351, 365, 368, 380, 383, 391, 567, 620, 621, 625, 632, 634, 635, 637, 641], "purpos": [20, 21, 22, 26, 30, 35, 36, 38, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 197, 221, 325, 327, 328, 330, 331, 349, 351, 363, 365, 368, 370, 377, 379, 380, 381, 382, 385, 560, 613, 620, 622, 623, 624, 627, 629, 635, 636, 638, 642], "raw": [21, 23, 90, 199, 239, 269, 273, 303, 320, 321, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587, 621, 624, 628, 637], "torchvis": [21, 30, 250, 277, 395, 635, 641, 642], "from_pixel": [21, 22, 30, 121, 122, 124, 125, 129, 131, 132, 136, 137, 155, 221, 254, 391, 393, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 620, 621, 623, 625, 629, 630, 638, 639, 641, 642], "totensorimag": [21, 69, 85, 221, 254, 527, 621, 623, 624, 639, 641, 642], "resiz": [21, 69, 85, 221, 513, 621, 623, 624, 625, 639, 642], "64": [21, 69, 78, 83, 86, 87, 176, 221, 254, 290, 291, 300, 302, 304, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 464, 599, 613, 620, 621, 622, 623, 624, 626, 630, 634, 637, 639, 641, 642], "appar": [21, 408], "bring": [21, 622, 625, 642], "speedup": [21, 22, 27, 635, 642], "kind": [21, 68, 74, 627, 635, 639], "great": [21, 22, 26, 27, 624, 633, 635, 641], "consult": 21, "interest": [21, 22, 342, 345, 621, 622, 625, 636, 637, 642], "resize_par": 21, "inv": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 224, 231, 234, 239, 248, 255, 260, 262, 267, 271, 274, 383, 637], "revers": 21, "chain": [21, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 138, 170, 176, 178, 179, 194, 195, 225, 231, 288, 317, 325, 327, 328, 330, 331, 347, 377, 379, 381, 382, 385, 592, 642], "taken": [21, 53, 57, 59, 61, 62, 64, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 214, 254, 306, 620, 622, 623, 626, 635, 636, 637], "in_keys_inv": [21, 194, 199, 207, 224, 229, 230, 232, 239, 246, 247, 248, 252, 253, 255, 260, 269, 271, 273, 274, 484, 489, 490, 492, 620, 634, 637, 642], "doubletofloat": [21, 492, 620, 622, 634], "float64": [21, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 124, 125, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 225, 229, 232, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "paragraph": [21, 22], "in_": 21, "out_": 21, "perspect": [21, 183, 298, 359, 622, 624], "inner": [21, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 231, 272, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587, 614, 621, 622, 636, 642], "outer": [21, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272, 614, 620, 621, 642], "ob": [21, 23, 27, 56, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 101, 108, 109, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 212, 215, 217, 226, 229, 230, 232, 246, 260, 262, 268, 290, 291, 292, 293, 313, 322, 350, 352, 353, 358, 364, 369, 371, 372, 373, 386, 387, 388, 389, 621, 624, 634, 635, 637, 639, 641, 642], "obs_standard": 21, "similarli": [21, 50, 88, 107, 112, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 244, 326, 332, 337, 346, 347, 357, 364, 376, 378, 380, 383, 384, 386, 592, 642], "seen": [21, 42, 44, 47, 50, 60, 71, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 230, 620, 621, 623, 627, 635, 636, 639], "out_keys_inv": [21, 194, 199, 207, 224, 229, 230, 232, 239, 246, 247, 248, 252, 253, 260, 262, 269, 271, 273, 274, 484, 489, 490, 492, 637], "produc": [21, 34, 60, 71, 108, 214, 217, 218, 283, 285, 288, 305, 310, 345, 386, 393, 622, 623, 624, 625, 626, 628, 639, 642], "illustr": [21, 620, 621, 626, 639], "renametransform": [21, 69, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 512], "renam": [21, 60, 69, 71, 86, 87, 171, 176, 212, 253, 255, 272, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 620], "schemat": 21, "outermost": 21, "innermost": 21, "similar": [21, 63, 68, 83, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 276, 277, 279, 280, 283, 285, 324, 325, 326, 327, 328, 330, 331, 332, 337, 342, 344, 345, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 567, 583, 620, 621, 622, 623, 624, 626, 627, 628, 629, 637, 639, 641, 642], "transform_action_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 230, 243, 246, 271, 273, 274, 383], "pseudocod": 21, "could": [21, 22, 23, 25, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 345, 376, 378, 380, 383, 384, 613, 621, 622, 629, 635, 636, 638, 642], "spec_from_random_valu": 21, "_apply_transform": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 383, 637, 642], "rand": [21, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 96, 121, 122, 136, 137, 144, 148, 149, 161, 162, 215, 218, 229, 232, 252, 262, 342, 343, 349, 350, 352, 353, 354, 356, 357, 358, 364, 366, 368, 369, 371, 372, 373, 376, 378, 380, 384, 637, 641, 642], "did": [21, 68, 278, 621, 622, 628, 639, 642], "_inv_apply_transform": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 271, 383, 637, 642], "actiondiscret": [21, 475], "rand_act": [21, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 218, 272, 625], "action_discret": 21, "counterpart": [21, 221], "obtain": [21, 26, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 196, 220, 250, 264, 277, 287, 412, 620, 622, 625, 626, 627, 635, 636], "addonetoob": 21, "There": [21, 29, 69, 86, 87, 172, 176, 271, 302, 304, 325, 327, 328, 330, 331, 349, 368, 377, 379, 381, 382, 385, 622, 623, 624, 626, 628, 635, 636, 637, 639, 641, 642], "Is": [21, 271], "ident": [21, 34, 35, 38, 68, 69, 72, 73, 86, 87, 95, 108, 120, 123, 126, 129, 130, 131, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 233, 262, 271, 280, 325, 327, 328, 330, 331, 350, 352, 364, 369, 371, 372, 373, 377, 379, 381, 382, 385, 386, 387, 388, 389, 562, 563, 621, 625, 635, 636], "rewrit": [21, 271], "otherwis": [21, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 109, 120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 222, 226, 227, 231, 239, 246, 264, 265, 266, 270, 271, 272, 279, 282, 297, 303, 313, 320, 321, 325, 326, 327, 328, 330, 331, 332, 337, 345, 348, 350, 352, 361, 366, 367, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 389, 410, 412, 566, 567, 568, 569, 571, 572, 573, 574, 576, 579, 581, 583, 587, 620, 621, 622, 623, 632, 637, 642], "_call": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 231, 233, 234, 235, 236, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 383, 632, 637], "_inv_cal": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 271, 383], "overwrit": [21, 271], "till": [21, 271, 278], "encapsul": [21, 271, 625, 626, 627], "don": [21, 22, 23, 25, 26, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 170, 197, 221, 271, 306, 324, 613, 621, 622, 624, 628, 639, 641, 642], "forget": [21, 271], "transform_output_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 273, 280, 383], "transform_input_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 225, 229, 230, 231, 244, 248, 252, 253, 258, 262, 263, 264, 265, 269, 271, 273, 276, 383], "transform_observation_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 222, 223, 224, 225, 228, 229, 230, 233, 234, 236, 238, 240, 241, 243, 244, 246, 248, 252, 253, 254, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 278, 279, 280, 383, 637], "transform_state_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 230, 243, 246, 271, 273, 274, 383], "transform_reward_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 219, 224, 225, 229, 230, 234, 241, 242, 243, 244, 252, 253, 256, 257, 258, 259, 260, 262, 263, 269, 271, 273, 274, 280, 383, 592, 632], "undo": [21, 183], "addonetoact": 21, "subtract": [21, 188, 264], "properti": [21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 270, 271, 272, 279, 280, 286, 295, 303, 306, 310, 319, 320, 321, 325, 326, 327, 328, 329, 330, 331, 332, 337, 341, 349, 352, 366, 368, 370, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 566, 568, 569, 571, 572, 574, 575, 576, 579, 581, 587, 626, 628, 637, 639], "manipul": [21, 23, 27, 124, 125, 250, 271, 275], "third_transform": 21, "assert": [21, 22, 25, 34, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 114, 120, 123, 126, 130, 133, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 183, 206, 211, 214, 218, 221, 224, 229, 232, 241, 253, 260, 272, 279, 287, 307, 325, 327, 328, 330, 331, 339, 377, 379, 381, 382, 384, 385, 386, 387, 388, 389, 405, 406, 414, 464, 465, 468, 469, 470, 613, 628, 634, 639, 642], "lead": [21, 23, 27, 29, 52, 56, 60, 65, 68, 71, 79, 101, 107, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 265, 282, 303, 320, 321, 620, 623, 624, 635, 636, 637, 639, 641], "unexpect": [21, 34, 35, 36, 38, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 642], "behviour": 21, "rais": [21, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 81, 83, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 165, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 221, 235, 245, 255, 264, 265, 266, 270, 272, 279, 286, 301, 312, 325, 326, 327, 328, 330, 331, 332, 333, 337, 352, 366, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 403, 404, 405, 566, 568, 571, 572, 573, 574, 575, 576, 577, 579, 581, 587, 613, 620, 622, 635, 636, 639], "catfram": [21, 341, 481, 621], "hold": [21, 22, 271, 383, 568, 637, 639], "notic": [21, 114, 221, 622, 630, 637], "parenthood": 21, "henc": [21, 53, 65, 213, 251, 620, 622, 635, 636, 637], "transform2": 21, "transform3": 21, "last_two": 21, "isinst": [21, 150, 158, 272, 391, 405, 469, 637], "discret": [21, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 129, 130, 131, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 214, 231, 239, 310, 356, 357, 358, 359, 621, 626, 636], "might": [21, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 397, 591, 620, 625, 642], "throughout": [21, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 622, 635, 642], "action_mask": [21, 123, 136, 137, 152, 153, 156, 157, 215, 476, 633], "unavail": [21, 152, 153], "probabl": [21, 23, 27, 69, 101, 102, 106, 188, 189, 195, 196, 287, 295, 301, 302, 304, 305, 306, 310, 317, 320, 321, 326, 329, 332, 337, 342, 345, 352, 358, 368, 371, 376, 378, 380, 384, 621, 624, 626, 641], "probabilistictensordictmodul": [21, 241, 345, 346, 641], "tensordictsequenti": [21, 285, 287, 297, 301, 302, 304, 312, 326, 332, 337, 339, 341, 346, 347, 376, 378, 380, 384, 620, 621, 623, 624, 626, 630, 634, 635, 638, 641], "maskedcategor": [21, 599], "in_feat": 21, "out_feat": 21, "logit": [21, 296, 298, 306, 310, 326, 329, 332, 337, 342, 357, 358, 592], "dist": [21, 29, 303, 306, 310, 320, 345, 626], "distribution_class": [21, 241, 283, 284, 285, 342, 345, 347, 349, 350, 352, 357, 358, 364, 368, 369, 370, 371, 599, 620, 622, 626, 635, 636, 641], "wrap": [21, 24, 32, 34, 35, 36, 38, 42, 44, 47, 50, 81, 88, 120, 121, 122, 123, 126, 130, 131, 135, 136, 137, 138, 143, 146, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 162, 164, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 227, 243, 270, 272, 282, 283, 284, 285, 302, 304, 313, 323, 326, 329, 332, 337, 341, 345, 366, 376, 378, 380, 383, 384, 592, 620, 621, 622, 623, 627, 630, 632, 635, 636, 642], "actionmask": [21, 123, 476], "know": [21, 22, 23, 28, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 68, 72, 73, 129, 131, 286, 366, 369, 376, 378, 380, 384, 410, 620, 621, 622, 623, 624, 625, 626, 627, 628, 635, 636, 639], "your_base_env": 21, "mask_kei": [21, 56, 215, 251, 326, 332, 337, 476], "intens": [22, 27], "gym3": 22, "envpool": [22, 145, 146, 452], "scale": [22, 23, 79, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 177, 178, 179, 180, 221, 241, 246, 257, 264, 268, 279, 280, 283, 284, 285, 299, 303, 307, 315, 316, 320, 321, 342, 345, 347, 349, 350, 352, 364, 368, 369, 370, 371, 413, 506, 516, 554, 564, 599, 620, 621, 622, 623, 626, 636, 641], "varieti": [22, 30], "serialenv": [22, 120, 123, 126, 130, 138, 150, 151, 154, 159, 160, 170, 171, 172, 175, 178, 179, 180, 265, 280, 287, 341, 641, 642], "Of": [22, 26, 591, 637, 642], "cours": [22, 23, 591, 637, 642], "saniti": [22, 26, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 622], "9": [22, 26, 56, 65, 68, 72, 84, 85, 86, 87, 102, 109, 114, 124, 125, 141, 152, 153, 160, 176, 214, 217, 226, 227, 264, 267, 272, 279, 280, 306, 325, 327, 328, 330, 331, 332, 337, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 384, 385, 405, 420, 540, 542, 543, 544, 546, 547, 548, 552, 620, 621, 635, 636], "81": [22, 86, 87, 108, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "c": [22, 25, 26, 32, 34, 35, 36, 38, 52, 60, 68, 72, 73, 82, 86, 87, 95, 96, 176, 246, 268, 273, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 384, 385, 621, 639], "d": [22, 60, 65, 68, 71, 72, 73, 80, 82, 84, 85, 101, 102, 326, 332, 337, 342, 345, 376, 378, 380, 384, 641], "forc": [22, 25, 26, 32, 35, 36, 38, 42, 44, 47, 50, 78, 80, 81, 83, 84, 85, 151, 332, 621, 635, 636, 637], "launch": [22, 32, 35, 36, 38, 42, 44, 47, 51, 78, 80, 150, 158, 190, 324, 333], "bottleneck": [22, 27, 102, 108, 109], "precis": [22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 212, 229, 232, 620, 622], "misspecifi": 22, "caus": [22, 26, 27, 34, 35, 36, 38, 95, 97, 101, 102, 116, 120, 123, 126, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 251, 380, 642], "breakag": 22, "mismatch": [22, 351, 368, 380, 621], "subprocess": [22, 32, 35, 36, 38, 127, 150, 158], "multithreadedenv": [22, 452], "underneath": 22, "cover": [22, 129, 131, 591, 622, 625, 628, 629, 637, 641], "classic": [22, 135, 144, 153, 621], "benchmark_batched_env": 22, "distinguish": [22, 68, 72, 73, 142, 143, 163, 164], "mere": [22, 32, 624], "element": [22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 56, 57, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 95, 96, 97, 98, 101, 102, 108, 109, 114, 116, 120, 123, 126, 130, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 185, 214, 221, 226, 227, 251, 260, 264, 265, 280, 286, 288, 297, 322, 325, 327, 328, 330, 331, 340, 341, 344, 345, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 406, 620, 622, 626, 628, 632, 639, 642], "batch_lock": [22, 120, 123, 126, 128, 130, 138, 150, 154, 158, 159, 170, 171, 172, 175, 178, 179, 180, 218, 265, 272, 637], "contrast": [22, 639], "braxenv": [22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 253, 443, 625], "jumanjienv": [22, 449], "straightforward": [22, 40, 620, 621, 625, 626, 627, 628, 639], "merg": [22, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 637], "deal": [22, 65, 66, 68, 69, 366, 376, 378, 380, 384, 620, 622, 636, 639], "silent": [22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 326, 338, 341, 348], "temporari": [22, 95, 97, 613, 620], "arm": 22, "unbatch": 22, "captur": [22, 190, 197, 286, 301, 312, 543, 592, 624], "content": [22, 27, 34, 60, 65, 68, 71, 72, 73, 86, 87, 89, 95, 107, 108, 109, 120, 123, 126, 129, 130, 131, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 174, 175, 176, 178, 179, 180, 184, 190, 195, 196, 252, 288, 305, 325, 327, 328, 330, 331, 332, 337, 342, 366, 376, 377, 378, 379, 380, 381, 382, 384, 385, 592, 622, 632, 633, 637, 641], "found": [22, 25, 26, 29, 32, 34, 35, 36, 38, 50, 56, 60, 71, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 213, 215, 221, 242, 255, 258, 266, 279, 280, 301, 325, 326, 327, 328, 330, 331, 332, 337, 342, 345, 365, 366, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 403, 594, 613, 620, 621, 623, 624, 625, 627, 629, 632, 637, 639, 641], "essenti": [22, 33, 42, 43, 44, 45, 47, 48, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 592, 621, 625, 635, 637, 639], "break_when_all_don": [22, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "conditionalskip": [22, 487], "programmat": 22, "pretti": [22, 620, 625, 629, 639], "likewis": 22, "te": 22, "dive": 22, "privat": [22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 278, 637, 642], "distinct": [22, 65, 66, 68, 69, 86, 87, 176, 218, 221, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 627, 634], "total": [22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 109, 114, 172, 176, 183, 226, 325, 327, 328, 330, 331, 335, 336, 351, 365, 368, 377, 379, 380, 381, 382, 385, 406, 408, 410, 416, 418, 420, 421, 473, 553, 554, 580, 606, 619, 620, 621, 622, 623, 627, 635, 636, 638, 639, 640, 641], "accord": [22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 69, 71, 86, 87, 106, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 175, 176, 178, 179, 180, 246, 257, 303, 315, 317, 320, 321, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 626, 627, 635, 637, 639], "nevertheless": [22, 622, 625, 639], "wherev": 22, "expos": [22, 155, 229, 232, 346, 351, 368, 621], "lost": [22, 27, 278], "face": [22, 24, 27, 28, 329, 332, 625, 633, 642], "word": [22, 30, 78, 79, 81, 83, 84, 85, 366, 376, 378, 380, 384, 620, 628, 637, 642], "preliminari": 22, "warranti": 22, "long": [22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 95, 102, 148, 149, 231, 270, 324, 357, 380, 623, 624, 628, 639], "assumpt": [22, 74, 637, 639], "preclud": 22, "presenc": [22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 326, 332, 337, 376, 378, 380, 384, 627], "annihil": 22, "known": [22, 24, 26, 27, 130, 180, 265, 620, 621, 625], "supersed": [22, 56], "pettingzoowrapp": 22, "associ": [22, 60, 66, 71, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 271, 315, 325, 326, 327, 328, 329, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 403, 564, 566, 572, 574, 620, 639], "__not__": [22, 342, 350, 352, 364, 369, 371, 372, 373], "constrain": [22, 241, 302, 304, 368, 642], "li": 22, "fact": [22, 26, 27, 592, 620, 622, 625, 635, 636, 637, 638, 639, 642], "predict": [22, 296, 299, 323, 349, 351, 356, 359, 361, 362, 365, 368, 370, 380, 620, 621, 627], "meaning": [22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 177, 418], "perfectli": [22, 620, 624, 637], "meaningless": 22, "discard": [22, 33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 79, 81, 130, 212, 275, 392, 639, 642], "val": [22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 171, 280, 303, 320, 405, 627, 641], "agent0": [22, 368, 624], "agent1": [22, 368], "elimin": [22, 625], "500": [22, 620, 621], "uint8": [22, 60, 78, 83, 86, 87, 124, 125, 142, 143, 176, 233, 239, 248, 268, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 621, 639], "significantli": [22, 33, 42, 43, 44, 45, 47, 48, 90, 108, 109, 221, 351, 368, 380, 568, 620, 621, 627, 636], "asyncenvpool": [22, 52, 154, 159], "thread": [22, 32, 34, 35, 36, 38, 50, 52, 53, 86, 87, 120, 121, 122, 136, 137, 150, 158, 159, 176, 190, 280, 324, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 566, 568, 569, 571, 572, 574, 576, 579, 581, 582, 587], "pool": [22, 78, 79, 80, 81, 82, 83, 84, 85, 120, 154, 159, 192, 266, 613], "concurr": [22, 120, 324, 329, 418, 613, 635, 636], "contrari": 22, "permit": [22, 224, 236, 262, 274, 349, 351, 365, 368, 370], "job": [22, 26, 42, 44, 47, 51, 68, 69, 72, 73, 639, 641], "famili": [22, 87, 89, 594], "particularli": [22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 68, 69, 72, 73, 86, 87, 90, 176, 191, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 418, 421, 613, 624, 641, 642], "pleas": [22, 41, 81, 88, 120, 123, 126, 129, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 239, 266, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384, 420, 591, 592], "processorasyncenvpool": 22, "threadingasyncenvpool": 22, "functool": [22, 32, 34, 35, 36, 38, 52, 120, 150, 158, 303, 320], "lazi": [22, 70, 71, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 250, 275, 325, 327, 328, 330, 331, 346, 347, 377, 379, 381, 382, 385, 425, 426, 427, 620, 621, 626, 628, 634, 639, 642], "s0": [22, 120], "clamp": [22, 120, 345, 348, 361, 416, 635, 637], "env_index": [22, 120], "async_step_send": [22, 120, 154, 159], "s0_result": [22, 120], "async_step_recv": [22, 120, 154, 159], "reveal": 23, "bug": 23, "curv": 23, "exploit": [23, 626], "cv": 23, "flip": [23, 137], "correspondingli": 23, "prescript": 23, "tune": [23, 241, 384, 592, 635, 636, 638], "coeffici": [23, 188, 195, 241, 351, 358, 365, 368, 371, 380, 384, 636], "bonu": [23, 177, 349, 351, 365, 368, 380, 592], "altern": [23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 59, 86, 87, 145, 170, 176, 197, 226, 270, 294, 306, 324, 325, 327, 328, 330, 331, 352, 377, 379, 381, 382, 385, 391, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587, 613, 620, 622, 624, 635, 636], "reduc": [23, 25, 59, 101, 102, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 192, 212, 221, 227, 264, 280, 320, 384, 523, 568, 621, 635], "downstream": [23, 380, 620], "formul": [23, 635, 636], "gradient": [23, 65, 68, 69, 72, 73, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 243, 272, 303, 310, 320, 321, 326, 332, 337, 345, 349, 351, 352, 353, 357, 358, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 416, 420, 421, 473, 590, 606, 620, 622, 635, 636, 637], "norm": [23, 27, 86, 87, 121, 122, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 409, 416, 420, 421, 473, 620, 621, 622, 635, 636, 637], "easier": [23, 620, 641], "optima": 23, "sens": [23, 86, 87, 176, 185, 221, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 628, 637], "product": [23, 28, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 562, 563, 613, 633], "sum": [23, 35, 36, 38, 50, 62, 64, 86, 87, 114, 121, 122, 124, 125, 129, 131, 132, 136, 137, 145, 146, 155, 176, 177, 220, 242, 258, 306, 320, 325, 327, 328, 330, 331, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 377, 379, 380, 381, 382, 384, 385, 409, 592, 606, 620, 621, 622, 624, 627, 630, 635, 636, 637, 642], "stat": [23, 246, 279, 280, 554, 564, 621, 622], "yield": [23, 34, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 324, 326, 332, 337, 366, 376, 378, 380, 383, 384, 620, 623, 627], "insight": [23, 171, 418, 613, 624], "auxiliari": [23, 627], "credit": 23, "past": [23, 221, 341, 621, 639], "difficult": [23, 150, 629], "spars": [23, 592, 623], "instrument": 23, "greatli": 23, "soccer": 23, "kick": 23, "ball": [23, 172], "likelihood": [23, 620], "score": [23, 177, 332, 368, 592], "undesir": [23, 150, 158], "though": [23, 30, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 305, 332, 613, 622, 635, 636], "unintention": 23, "valuabl": 23, "idiosyncrat": 23, "subtask": 23, "hierarch": 23, "fall": [23, 37, 39, 41, 46, 49, 54, 55, 79, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "curios": 23, "magnitudin": 23, "domin": 23, "smaller": [23, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 357, 364, 622, 636], "addition": [23, 295], "timestep": [23, 79, 255, 635, 636], "realli": 23, "huge": [23, 623], "std": [23, 246, 279, 286, 307, 311, 420, 620, 642], "initi": [23, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 59, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 97, 114, 120, 123, 126, 130, 138, 148, 149, 150, 151, 154, 158, 159, 160, 161, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 220, 239, 246, 250, 265, 272, 275, 280, 281, 282, 286, 301, 312, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 339, 341, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 404, 564, 565, 566, 567, 568, 569, 571, 572, 573, 574, 575, 576, 577, 579, 580, 581, 585, 586, 587, 592, 613, 620, 621, 623, 625, 626, 628, 632, 635, 637, 642], "estim": [23, 78, 102, 108, 109, 170, 171, 172, 175, 178, 185, 233, 241, 283, 284, 285, 290, 320, 349, 350, 351, 352, 353, 354, 356, 358, 359, 360, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 376, 378, 380, 384, 386, 387, 388, 389, 390, 601, 606, 621, 622, 626, 627, 635, 636], "encount": [23, 83, 244, 341, 591, 621, 626, 637], "unseen": 23, "extrins": 23, "wrong": [23, 102, 108, 183], "goe": [23, 152, 153, 620, 622, 635, 636, 642], "bonus": 23, "denser": 23, "prior": [23, 315, 316, 317, 361, 636], "freshli": 23, "drop": [23, 107, 109, 212, 280, 324, 351, 368, 380], "meant": [23, 144, 178], "encourag": [23, 150, 183, 368, 421, 620, 621, 639], "measur": [23, 88, 95, 97, 101, 116, 121, 122, 136, 137, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 351, 368, 380, 383, 418, 421, 622, 628], "novelti": 23, "revisit": 23, "diminish": 23, "decreas": [23, 626], "ideal": [23, 170, 226, 246, 380, 633, 637], "distil": 23, "nois": [23, 281, 312, 315, 316, 369, 372, 373, 410, 564, 603, 620, 635], "exploratori": [23, 349, 351, 365, 368, 380], "misalign": 23, "trade": [23, 626], "unavoid": 23, "prioriti": [23, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 95, 96, 97, 98, 101, 102, 110, 112, 116, 352, 353, 354, 356, 357, 358, 359, 364, 369, 371, 372, 373, 620, 621, 639], "schedul": [23, 26, 324, 410, 622, 637], "divers": [23, 150, 158, 332], "bootstrap": [23, 359, 386, 387, 620, 623], "noisi": 23, "unstabl": [23, 101, 102, 303, 320, 321], "inher": [23, 349, 368], "stochast": [23, 241, 299, 308, 316, 350, 352, 355, 357, 358, 363, 364, 367, 369, 371, 421, 599, 600, 622, 626, 636], "enemi": 23, "pomdp": [23, 639], "loos": [23, 345, 585, 621, 622], "nonexist": 23, "architectur": [23, 189, 294, 324, 332, 599, 613, 627, 635, 636, 641], "sequenc": [23, 32, 34, 35, 36, 38, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 74, 75, 76, 77, 83, 86, 87, 94, 104, 106, 112, 115, 118, 119, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 199, 201, 207, 219, 220, 221, 222, 223, 228, 229, 231, 232, 236, 238, 239, 242, 246, 247, 251, 252, 253, 254, 255, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 273, 279, 280, 288, 295, 305, 306, 310, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 346, 347, 355, 376, 377, 378, 379, 380, 381, 382, 384, 385, 392, 393, 410, 411, 412, 414, 416, 592, 620, 622, 623, 624, 634, 635, 636, 642], "lstm": [23, 265, 304, 307, 624], "rel": [23, 69, 265, 295, 319, 620, 621, 635, 636, 639], "tend": 23, "stabl": [23, 28, 29, 101, 102, 147], "compens": 23, "descent": 23, "minimum": [23, 75, 120, 150, 158, 256, 299, 307, 319, 320, 321, 326, 332, 337, 348, 350, 352, 358, 366, 367, 371, 376, 378, 380, 384, 406, 620, 622, 630, 635, 636], "manual": [23, 30, 42, 47, 50, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 95, 130, 131, 180, 191, 420, 620, 623, 639], "deviat": [23, 246, 279, 280, 286, 299, 311, 368, 372, 373, 384, 409, 620, 626, 636], "radic": 23, "stabil": [23, 101, 102, 237, 324, 333, 334, 349, 351, 365, 368, 370, 380], "stage": [23, 620, 637], "never": [23, 32, 35, 36, 38, 52, 58, 75, 101, 102, 208, 267, 628, 641], "solv": [23, 26, 28, 29, 65, 66, 68, 69, 183, 591, 620, 621, 622, 628, 630, 635, 636, 637, 639], "submit": [23, 129, 218, 591, 641], "adequ": [23, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 622, 635, 636], "infeas": 23, "allevi": 23, "prune": [23, 138, 179], "fire": [23, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "certain": [23, 42, 44, 47, 50, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 226, 227, 237, 263, 272, 301, 326, 332, 333, 334, 337, 365, 376, 378, 380, 383, 384, 620, 621, 622, 624, 630, 635, 636, 642], "illeg": 23, "move": [23, 74, 85, 88, 96, 98, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 225, 230, 250, 265, 271, 272, 275, 277, 279, 280, 305, 326, 332, 337, 344, 376, 378, 380, 383, 384, 413, 620, 621, 623, 625, 642], "chess": [23, 123, 148, 149], "grasp": 23, "wherein": 23, "cumul": [23, 258, 264, 622], "q": [23, 28, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 285, 290, 291, 292, 293, 296, 298, 300, 313, 314, 317, 350, 352, 353, 354, 356, 357, 358, 359, 364, 369, 371, 372, 373, 599, 620, 627, 632], "flow": [23, 208, 386, 567, 568, 575, 620, 622, 635, 636, 637, 639], "reparameter": [23, 295, 310], "soft": [23, 371, 421, 635], "clip": [23, 183, 224, 256, 349, 351, 365, 368, 370, 372, 373, 376, 378, 380, 416, 420, 421, 472, 473, 622, 636, 637], "oppos": 23, "incorrect": [23, 108, 183, 368], "thought": [23, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 592], "region": [23, 102, 380], "squash": [23, 338, 623, 641], "tanh": [23, 288, 303, 305, 319, 320, 321, 348, 622, 626, 635, 636, 637, 638], "correct": [23, 86, 87, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 182, 183, 188, 221, 241, 325, 327, 328, 330, 331, 377, 379, 380, 381, 382, 385, 553, 613, 622, 623, 632], "prob": [23, 188, 189, 195, 196, 306, 310, 324, 326, 329, 332, 337, 622, 633, 636], "rememb": [23, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 635], "remap": 23, "origin": [23, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 90, 134, 170, 176, 230, 231, 241, 250, 272, 277, 325, 326, 327, 328, 330, 331, 332, 337, 342, 344, 345, 350, 352, 364, 366, 368, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 592, 620, 624, 632, 634, 637, 642], "real": [24, 35, 36, 38, 83, 326, 332, 337, 345, 573, 623, 624, 637, 638], "histor": 24, "ceas": 24, "fork": [24, 78, 79, 80, 81, 82, 83, 84, 85, 620, 621, 622, 623, 635, 636, 638, 641], "farama": [24, 81, 139, 140, 152, 153, 622, 637], "bc": [24, 372], "break": [24, 32, 34, 35, 36, 38, 50, 52, 54, 66, 68, 73, 78, 80, 81, 83, 84, 85, 88, 102, 108, 109, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 255, 279, 280, 302, 303, 304, 320, 326, 332, 337, 376, 378, 380, 383, 384, 393, 621, 624, 628, 630, 639, 641], "13": [24, 108, 109, 155, 226, 278, 280, 282], "gymwrapp": [24, 120, 123, 126, 130, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 234, 259, 263, 278, 622, 641], "feel": [24, 591, 630, 641], "free": [24, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 176, 212, 229, 232, 325, 327, 328, 330, 331, 349, 361, 368, 377, 379, 381, 382, 385, 613, 622, 630, 636, 641], "gladli": 24, "conda": [25, 26, 591], "cmake": 25, "14": [25, 78, 79, 80, 81, 82, 83, 84, 85, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 226, 246, 282, 368], "sim": 25, "bullet": 25, "headless": [25, 26, 135, 184, 632], "cluster": [25, 26, 27, 42, 50, 80, 402, 403, 404, 591], "withbullet": 25, "forg": [25, 26], "aihabitat": [25, 132], "y": [25, 26, 68, 86, 87, 147, 176, 300, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 384, 385, 464, 465, 468, 470, 620, 636, 639], "facebookresearch": [25, 80, 132], "subdirectori": 25, "verbos": [25, 52, 53, 88, 177, 324, 333, 383, 630, 632], "magnum_log": 25, "quiet": 25, "habitat_sim_log": 25, "remov": [25, 34, 35, 36, 38, 41, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 252, 261, 272, 325, 326, 327, 328, 330, 331, 332, 337, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 403, 592, 635, 636, 641, 642], "readm": [25, 26, 163, 641], "md": [25, 26], "habitatenv": [25, 447], "_has_habitat": 25, "available_env": [25, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 139, 142, 143, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 175, 178, 179, 180, 642], "startswith": [25, 287, 606, 620, 627], "oserror": 25, "libllvmlit": 25, "ionstal": 25, "pointer": [25, 127, 366, 620], "llvmlite": 25, "var": [25, 26, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 280, 326, 332, 337, 352, 366, 371, 376, 378, 380, 383, 384], "ld_preload": [25, 26], "bind": 25, "deactiv": [25, 26, 121, 122, 297, 350, 352, 358, 364, 366, 369, 371, 372, 373, 387, 388, 389], "importerror": [25, 26, 29, 404, 633], "usr": [25, 26, 29], "x86_64": [25, 26], "linux": [25, 26], "gnu": [25, 26], "libopengl": [25, 26], "undefin": [25, 26, 29, 59, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 352, 366, 371, 376, 378, 380, 383, 384, 624, 639], "symbol": [25, 26, 29], "_glapi_tls_curr": [25, 26], "link": [25, 26, 126, 621, 630], "mujoco_env": [25, 26], "libglvnd": [25, 26], "glx": [25, 26], "cos7": [25, 26], "reinstal": [25, 26], "xvfbwrapper": [25, 26], "sysroot": [25, 26], "lib64": [25, 26], "libgldispatch": [25, 26], "offici": [26, 79, 190, 624], "stand": [26, 124, 125, 150, 158, 634, 637], "joint": [26, 621], "contact": [26, 635], "biomechan": 26, "graphic": 26, "anim": [26, 636], "area": 26, "demand": [26, 568, 629, 642], "fast": [26, 28, 96, 121, 122, 212, 253, 369, 613, 620, 621, 622, 641], "accur": [26, 79, 85, 592, 621, 637, 639], "articul": 26, "acquir": [26, 622], "deepmind": [26, 27, 28, 83, 120, 123, 124, 125, 126, 130, 138, 142, 143, 148, 149, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 233, 622, 625], "whomev": 26, "licenc": 26, "were": [26, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 67, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 150, 158, 239, 339, 351, 368, 568, 583, 592, 594, 622, 635, 639], "incorpor": [26, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 301, 312, 372, 421, 623, 626, 637], "relianc": 26, "obsolet": 26, "pro": [26, 591], "tip": [26, 591], "glfw": [26, 620], "osmesa": 26, "egl": 26, "advic": [26, 83, 642], "sudo": [26, 591], "apt": [26, 636], "libglfw3": 26, "libglew2": 26, "libgl1": 26, "mesa": 26, "libosmesa6": 26, "workflow": [26, 283, 284, 285, 286, 324, 592, 633], "glew": 26, "mesalib": 26, "anaconda": 26, "libgl": 26, "cos6": 26, "menpo": 26, "glfw3": 26, "mujoco_gl": 26, "pyopengl_platform": 26, "mkdir": 26, "earlier": [26, 620, 622, 623, 635, 636, 639], "roboti": 26, "download": [26, 29, 78, 79, 80, 81, 83, 84, 85, 134, 250, 277, 393, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "html": [26, 35, 38, 145, 147, 148, 149, 632], "wget": 26, "mujoco210": 26, "tar": [26, 80], "gz": 26, "xf": 26, "charg": [26, 32, 35, 36, 38, 150, 158], "mjkei": 26, "txt": [26, 384], "mjlib_path": 26, "home": 26, "bin": [26, 190, 298], "libmujoco210": 26, "ld_library_path": 26, "mujoco_py_mujoco_path": 26, "too": [26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 245, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 303, 320, 321, 326, 332, 337, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 386, 387, 388, 389, 621, 626, 629, 637, 639, 642], "mujoco_py_mjkey_path": 26, "reload": 26, "later": [26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 101, 102, 293, 339, 342, 345, 403, 567, 620, 622, 624, 639], "nvidia": [26, 134, 624], "hack": [26, 620], "adatp": 26, "unnot": [26, 251], "mujoco_pi": 26, "cymj": 26, "linuxgpuextensionbuild": 26, "filenam": [26, 86, 87, 93, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 621, 639], "troubleshoot": [26, 351, 365, 368], "gl": 26, "h": [26, 69, 221, 223, 228, 254, 268, 302, 304, 393, 513, 621, 639], "eglshim": 26, "fatal": 26, "No": [26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 54, 57, 59, 62, 64, 177, 402, 565, 567, 569, 570, 575], "directori": [26, 78, 79, 80, 81, 83, 84, 85, 86, 87, 91, 95, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 398, 401, 581, 582, 583, 584, 620, 626, 629, 635], "devel": 26, "ubuntu": [26, 134], "libglew": 26, "dev": 26, "cento": 26, "yum": 26, "glu": 26, "38": 26, "disappear": [26, 621, 623, 634], "libstdc": 26, "6": [26, 32, 34, 35, 36, 38, 52, 53, 56, 60, 68, 71, 78, 84, 85, 101, 102, 109, 124, 125, 130, 150, 156, 157, 172, 180, 214, 217, 226, 227, 246, 248, 264, 270, 280, 287, 288, 290, 291, 292, 295, 300, 305, 308, 319, 322, 341, 342, 621, 624, 641], "glibcxx_3": 26, "29": [26, 108, 109], "compil": [26, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 68, 72, 73, 86, 87, 88, 90, 94, 95, 96, 97, 98, 102, 104, 108, 109, 110, 115, 116, 118, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 282, 303, 317, 320, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 425, 426, 427, 428, 432, 434, 435, 439], "libosmesa": 26, "libgcc": 26, "Then": [26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 175, 183, 278, 585, 586, 622, 634], "filenotfounderror": [26, 81], "errno": 26, "patchelf": 26, "fatalerror": 26, "gladloadgl": 26, "mj_env": 26, "912": 26, "glfwerror": 26, "65537": 26, "myscript": 26, "runtimeerror": [26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 59, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 245, 270, 272, 326, 332, 333, 337, 352, 371, 376, 378, 380, 383, 384, 573, 642], "slurm": 26, "mjrendercontext": 26, "pyx": 26, "46": [26, 108, 121, 122], "114": 26, "_setup_opengl_context": 26, "opengl_context": 26, "130": 26, "offscreenopenglcontext": 26, "fail": [26, 32, 34, 35, 36, 38, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 195, 215, 326, 332, 337], "opengl": [26, 635, 636], "global": [26, 68, 69, 72, 73, 88, 89, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 270, 326, 332, 335, 336, 337, 342, 345, 376, 378, 380, 383, 384, 402, 403, 620, 635, 636], "cuda_visible_devic": [26, 587], "slurm_step_gpu": 26, "black": [26, 123, 635], "onscreen": 26, "101": 26, "lgl": 26, "libegl": 26, "x11": [26, 636], "xlib": 26, "libx11": 26, "xorg": 26, "attributeerror": [26, 32, 35, 36, 38, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "nonetyp": 26, "glgeterror": 26, "this_dir": 26, "pwd": 26, "ln": 26, "libglut": 26, "12": [26, 29, 35, 36, 38, 84, 86, 87, 95, 97, 109, 116, 136, 137, 150, 156, 157, 158, 172, 176, 190, 226, 272, 280, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 393, 639], "sketch": 27, "_": [27, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 96, 123, 127, 134, 163, 164, 176, 185, 222, 229, 231, 232, 241, 246, 253, 268, 279, 322, 325, 327, 328, 330, 331, 340, 344, 345, 349, 350, 352, 353, 357, 358, 364, 368, 369, 371, 372, 373, 377, 379, 381, 382, 385, 386, 387, 388, 389, 395, 620, 621, 622, 623, 624, 630, 635, 636, 637, 639, 641], "n_training_step": 27, "datapoint": [27, 639], "onlin": [27, 32, 38, 221, 294, 311, 349, 355, 367, 368, 406, 564, 622, 623, 636, 639], "n_data_per_train": 27, "no_grad": [27, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 243, 326, 332, 337, 376, 378, 380, 383, 384, 386, 387, 388, 389, 622, 623, 624, 636], "loss_fn": [27, 623, 627, 628, 641], "zero_grad": [27, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 620, 622, 623, 624, 627, 630, 635, 636, 637], "backpropag": [27, 121, 122, 136, 137, 150, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 627, 636, 637], "differenti": [27, 121, 122, 241, 352, 372, 386, 387, 388, 389, 539, 540, 541, 543, 549, 550, 551, 623, 626, 627, 635, 636, 637], "pai": [27, 221, 620, 623], "denomin": 27, "artifact": 27, "numer": [27, 68, 101, 102, 130, 180, 279, 297, 298, 303, 313, 314, 320, 321, 324, 333, 334, 340, 342, 344, 345, 413, 622, 639, 642], "misconcept": 27, "freed": 27, "appear": [27, 30, 58, 64, 75, 78, 83, 102, 108, 109, 126, 178, 185, 186, 637, 639], "compuat": 27, "twice": [27, 109], "retain_graph": [27, 121, 122], "discuss": [27, 28, 628, 635, 636], "inplac": [27, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 329, 330, 331, 332, 337, 344, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 566, 568, 569, 571, 572, 574, 576, 578, 579, 581, 583, 585, 587, 620], "accumul": [27, 317], "onto": [27, 64, 86, 87, 176, 189, 195, 206, 230, 286, 297, 298, 307, 312, 313, 314, 325, 327, 328, 330, 331, 340, 342, 344, 345, 377, 379, 381, 382, 385, 386, 623, 637], "submodul": [27, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 265, 302, 304, 326, 332, 337, 366, 376, 378, 380, 383, 384], "grad": [27, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 330, 331, 332, 337, 345, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 620, 622], "whose": [27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "neg": [27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 72, 74, 101, 102, 182, 221, 236, 251, 262, 274, 326, 351, 360, 365, 368, 386, 388, 389, 622, 635, 636, 637], "fit": [27, 246, 265, 282, 324, 620], "jax": [27, 121, 122, 136, 137, 282], "improperli": 27, "underli": [27, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 326, 332, 366, 613, 623, 625, 627, 629, 637], "tedeiou": 27, "amount": [27, 150, 312, 386, 621, 639], "costli": [27, 637], "concaten": [27, 35, 36, 38, 50, 61, 62, 83, 86, 87, 176, 178, 221, 222, 246, 262, 305, 325, 327, 328, 330, 331, 347, 377, 379, 381, 382, 385, 620, 621, 626, 635, 636, 637, 639, 642], "constitut": [27, 621, 636, 637], "profil": [27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "frequent": [27, 613, 639], "techniqu": [27, 150, 158, 621, 624, 628, 639], "program": [27, 357, 364, 624, 642], "functorch": [27, 29], "incl": 27, "suit": [27, 125, 613, 622, 625, 641, 642], "mujoco_instal": 27, "valueerror": [27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 330, 331, 332, 333, 337, 376, 378, 380, 383, 384, 402, 403, 404, 566, 568, 571, 572, 574, 575, 576, 577, 579, 581, 587, 633], "bad": 27, "fds_to_keep": 27, "new_shap": 27, "permut": [27, 107, 248, 268, 624, 641, 642], "idea": [28, 101, 102, 369, 614, 623, 626, 635, 636], "introductori": 28, "intro": [28, 622, 623], "dai": [28, 641], "2022": [28, 29, 641], "spin": [28, 124, 125], "hug": [28, 329, 332, 633], "syllabu": 28, "lectur": 28, "awesom": 28, "curat": 28, "succinct": [28, 626], "summari": [28, 246, 279, 280, 620, 621, 622, 623], "reddit": 28, "reagent": 28, "orient": [28, 85, 642], "baselines3": 28, "tf": 28, "bandit": [28, 147], "tensorflow": [28, 306], "kera": 28, "acm": 28, "dopamin": 28, "prototyp": [28, 420, 421, 624, 630], "salina": 28, "sequenti": [28, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 220, 241, 283, 284, 285, 326, 332, 337, 342, 346, 347, 349, 350, 352, 358, 364, 368, 369, 370, 371, 372, 376, 378, 380, 383, 384, 568, 599, 622, 623, 626, 636, 637, 638, 641, 642], "tianshou": 28, "eleg": 28, "rlpyt": 28, "rllib": 28, "industri": [28, 641], "grade": 28, "cherri": 28, "jaxrl": 28, "space": [28, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 87, 92, 93, 100, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 209, 214, 224, 231, 239, 242, 265, 273, 286, 288, 294, 297, 298, 309, 312, 313, 314, 317, 322, 337, 340, 342, 344, 345, 347, 348, 349, 354, 356, 357, 358, 368, 372, 373, 621, 622, 623, 624, 625, 626, 627, 635, 636, 637, 642], "mbrl": [28, 144], "rlmeta": 28, "light": 28, "elegantrl": 28, "cloud": 28, "mtrl": 28, "baselin": 28, "689": 29, "_torchrl": 29, "_zn8pybind116detail11type_casterin2at6tensoreve4loadens_6handleeb": 29, "colab": [29, 622, 623, 635, 636], "notebook": [29, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "24": [29, 84, 109, 129, 145, 146, 172, 183, 338, 341, 393, 635], "pip3": [29, 620, 622, 623, 635, 636], "extra": [29, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 221, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 400, 401, 622, 623, 639], "url": [29, 86, 132, 186, 632], "org": [29, 35, 38, 65, 80, 81, 83, 85, 101, 102, 121, 122, 124, 125, 132, 136, 137, 142, 143, 145, 146, 147, 155, 163, 164, 221, 250, 275, 289, 290, 291, 292, 293, 294, 298, 299, 300, 306, 308, 309, 312, 315, 316, 317, 349, 350, 354, 355, 356, 357, 359, 360, 361, 362, 363, 364, 367, 368, 370, 371, 372, 386, 589, 631, 638], "whl": 29, "u": [29, 82, 637], "upgrad": 29, "lib_version_her": 29, "heavili": 30, "pyav": 30, "conveni": [30, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 221, 324, 402, 622, 635, 636, 637, 639], "knob": 30, "dispos": 30, "guid": [30, 152, 153, 156, 157, 264, 324, 591, 620, 636, 641], "clarifi": 30, "behind": [30, 259], "adjust": [30, 265, 620, 635, 636, 637], "ultim": [30, 303, 320, 321], "ffmpeg": 30, "whatev": [30, 326, 332, 337, 620], "fed": [30, 636, 639], "feed": [30, 250, 277, 366, 376, 378, 380, 384, 620, 635, 636, 639], "suppos": [30, 150, 410, 642], "snippet": [30, 250, 275, 620], "gave": 30, "extrem": [30, 150, 158, 349, 351, 365, 368, 370, 380], "blurri": [30, 624], "stitch": 30, "my_exp": [30, 629], "pixels_onli": [30, 124, 125, 129, 131, 132, 155, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 620, 621, 629, 630, 641, 642], "my_video": [30, 629], "record_env": [30, 629, 630], "codec": 30, "h264": 30, "constant": [30, 101, 102, 221, 246, 264, 620, 622, 623, 642], "crf": 30, "17": [30, 84, 108, 109, 130, 150, 180, 214, 226], "preset": 30, "allow_non": 31, "unwrap": [31, 233, 272, 405, 493], "seealso": 31, "randompolici": [32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 221, 255, 628, 639], "tensordictmodulebas": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 220, 243, 297, 313, 326, 332, 337, 341, 376, 378, 380, 384, 466, 623], "signatur": [32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 66, 68, 69, 88, 89, 112, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 218, 225, 239, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384, 620, 624, 625, 637], "undergon": [32, 34, 35, 36, 38, 42, 44, 47, 50], "env_obs_kei": [32, 34, 35, 36, 38, 42, 44, 47, 50], "mustn": [32, 34, 35, 36, 38, 42, 44, 47, 50], "policy_factori": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53], "exclus": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 63, 68, 72, 73, 78, 83, 86, 87, 102, 108, 109, 176, 182, 218, 234, 236, 243, 297, 298, 302, 304, 306, 313, 314, 325, 327, 328, 330, 331, 334, 372, 373, 377, 379, 381, 382, 385, 386, 387, 388, 389, 390, 401, 564], "lifespan": [32, 34, 35, 36, 38, 42, 44, 47, 52, 53, 621], "divis": [32, 34, 35, 36, 38, 42, 44, 47, 78, 83, 102, 108, 109, 280, 636], "endless": [32, 34, 35, 36, 38, 42, 44, 47, 185, 592], "env_devic": [32, 34, 35, 36, 38, 42, 44, 47, 50, 621], "sit": [32, 34, 35, 36, 38, 42, 44, 47, 50, 419, 621], "cast": [32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 277, 278, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 344, 351, 365, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 635, 642], "create_env_kwarg": [32, 34, 35, 36, 38, 50, 120, 127, 145, 150, 158, 270, 440, 620, 642], "span": [32, 34, 35, 36, 38, 42, 44, 47, 50, 83, 102, 108, 109, 434, 435], "n_step": [32, 34, 35, 36, 38, 42, 44, 47, 50, 341, 504, 621, 622, 635, 636], "independ": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 80, 150, 158, 186, 236, 244, 265, 274, 324, 349, 368, 402, 585, 613, 620, 621, 623, 636, 639, 641], "ignor": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 93, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 231, 234, 259, 268, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 306, 307, 308, 309, 311, 312, 314, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 348, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 567, 575, 580, 582, 632, 633, 639], "mainli": [32, 34, 35, 36, 38, 42, 44, 47, 50, 170, 171, 172, 175, 401, 635, 636, 637], "round": [32, 34, 35, 36, 38, 42, 44, 47, 50, 78, 123, 192, 324, 432, 613], "closest": [32, 34, 35, 36, 38, 42, 44, 47, 50], "postproc": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 255, 621, 639], "post": [32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 81, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 592], "multistep": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 621], "explorationtyp": [32, 34, 35, 36, 38, 42, 44, 47, 50, 342, 366, 410, 620, 621, 622, 623, 626, 635, 641], "boolm": [32, 35, 36, 38], "preemptive_threshold": [32, 35, 36, 38], "ratio": [32, 35, 36, 38, 351, 368, 416, 418, 620, 622], "finish": [32, 34, 35, 36, 38, 50, 52, 130, 180, 255, 573, 642], "earli": [32, 35, 36, 38, 101, 102, 130, 180, 263, 326, 332, 337, 641], "num_thread": [32, 35, 36, 38, 86, 87, 130, 150, 158, 176, 180, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 581, 582], "num_sub_thread": [32, 35, 36, 38, 150, 158], "plu": [32, 35, 36, 38, 150, 158, 592, 637], "harm": [32, 35, 36, 38, 150, 158], "set_trunc": [32, 34, 35, 36, 38, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "add_truncated_kei": [32, 34, 35, 36, 38, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272], "track_policy_vers": [32, 34, 35, 36, 38, 52, 53, 191, 592], "policyvers": [32, 34, 35, 36, 38, 52, 53, 592], "mediat": [32, 34, 35, 36, 38, 52], "timeout": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 150, 184, 190, 192, 193, 197, 324, 326, 332, 337, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 579, 580, 581, 582, 583, 585, 587, 613], "close_env": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 52], "cascade_execut": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "attr_path": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "caller": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 324, 326, 332, 337, 376, 378, 380, 383, 384, 580], "_receiver_schem": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "_set_dist_connection_info": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "connection_info_ref": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "enable_profil": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "get_cached_weight": [32, 35, 36, 38], "get_model": [32, 34, 35, 36, 38, 52, 53, 566, 568, 571, 572, 574, 579, 581, 587], "value_net": [32, 34, 35, 36, 38, 52, 53, 354, 356, 370, 386, 387, 388, 389, 622, 624, 626, 627, 630], "recogn": [32, 34, 35, 36, 38, 52, 53, 402], "get_policy_vers": [32, 34, 35, 36, 38, 52, 53], "uuid": [32, 34, 35, 36, 38, 52, 53, 191, 396, 621, 642], "disabl": [32, 34, 35, 36, 38, 52, 53, 57, 59, 61, 62, 64, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 303, 321, 326, 332, 337, 376, 378, 380, 383, 384, 391, 420, 569, 620, 635, 636], "getattr_env": [32, 34, 35, 36, 38, 52, 53], "attr": [32, 34, 35, 36, 38, 52, 53], "getattr_polici": [32, 34, 35, 36, 38, 52, 53], "getattr_rb": [32, 34, 35, 36, 38, 52, 53], "increment_vers": [32, 34, 35, 36, 37, 38, 39, 40, 41, 46, 49, 52, 53, 54, 55, 191], "increment": [32, 34, 35, 36, 37, 38, 39, 40, 41, 46, 49, 52, 53, 54, 55, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180, 191, 246, 365, 592], "init_updat": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "load_state_dict": [32, 34, 35, 36, 38, 50, 52, 53, 86, 87, 88, 90, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 418, 620], "ordereddict": [32, 34, 35, 36, 38, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 279, 280, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384], "form": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 302, 304, 317, 326, 332, 337, 345, 349, 351, 365, 368, 376, 378, 380, 383, 384, 416, 421, 626], "worker0": [32, 35, 36, 38], "state_dict0": [32, 35, 36, 38], "worker1": [32, 35, 36, 38, 613], "state_dict1": [32, 35, 36, 38], "policy_vers": [32, 34, 35, 36, 38, 52, 53, 191, 592], "profile_config": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "_base": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "profileconfig": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "policy_or_weight": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54], "deleg": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 176, 194, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 637], "trained_polici": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "mirror": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "conflict": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 171, 326, 332, 337], "register_scheme_receiv": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "weight_recv_schem": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "weightsyncschem": [32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53], "synchronize_weight": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 567, 568, 574], "hierarchi": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 324], "immedi": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 402, 403, 404, 566, 568, 571, 572, 574, 576, 579, 581, 587, 613, 635, 636], "reset_idx": [32, 35, 36, 38], "abc": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 60, 61, 65, 67, 68, 69, 71, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 219, 220, 221, 222, 223, 225, 228, 229, 232, 236, 238, 242, 246, 247, 252, 254, 255, 256, 257, 258, 262, 264, 265, 266, 268, 271, 272, 273, 279, 280, 282, 288, 295, 303, 305, 306, 310, 320, 326, 332, 337, 376, 378, 380, 383, 384, 411, 412, 419, 562, 563], "static_se": [32, 34, 35, 36, 38, 50, 52, 53, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272], "integ": [32, 34, 35, 36, 38, 52, 53, 56, 61, 62, 64, 102, 108, 109, 110, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180, 191, 214, 217, 233, 237, 246, 263, 280, 288, 305, 352, 357, 364, 371, 624, 639], "env_fn": [32, 34, 35, 36, 38, 52, 53, 127, 562, 563], "env_fn_parallel": [32, 34, 35, 36, 38, 52, 53], "300": [32, 34, 35, 36, 38, 52, 53, 108, 109, 292, 293], "out_se": [32, 34, 35, 36, 38, 52, 53, 642], "raise_on_error": [32, 34, 35, 36, 38, 52, 402], "irrevers": [32, 35, 36, 38], "pipe": [32, 34, 35, 36, 38, 52, 150], "tqdm": [32, 34, 35, 36, 38, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 416, 620, 622, 623, 635, 636, 637], "ale_pi": [32, 34, 35, 36, 38, 52, 624], "progress": [32, 34, 35, 36, 38, 52, 53, 324, 408, 409, 410, 416, 418, 420, 421, 473, 621, 623, 642], "bar": [32, 34, 35, 36, 38, 52, 95, 97, 116, 324, 408, 409, 410, 416, 420, 421, 473, 621], "pbar": [32, 34, 35, 36, 38, 52, 78, 79, 80, 81, 82, 83, 84, 85, 620, 622, 623, 635, 636, 637], "100_000": [32, 34, 35, 36, 38, 52, 624, 630], "prec_wc": [32, 34, 35, 36, 38, 52], "wc": [32, 34, 35, 36, 38, 52], "write_count": [32, 34, 35, 36, 38, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 418], "set_descript": [32, 34, 35, 36, 38, 52, 620, 622, 623, 635, 636, 637], "f": [32, 34, 35, 36, 38, 52, 84, 88, 121, 122, 130, 136, 137, 180, 188, 190, 193, 195, 196, 267, 282, 384, 386, 387, 388, 389, 390, 613, 620, 621, 622, 623, 630, 633, 635, 636, 637, 639, 642], "worker_id": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587], "actor_weight": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "critic_weight": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "Will": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 86, 87, 102, 108, 145, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 393, 613], "_get_server_weight": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54], "typeerror": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "weight_updat": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 621], "weightupdaterbas": [32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55], "localweightsupdaterbas": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "remoteweightsupdaterbas": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "num_rollout": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "warmup_rollout": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "save_path": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "pathlib": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 95, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 416, 420, 421, 624], "record_shap": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "profile_memori": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "with_stack": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "with_flop": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "on_trace_readi": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "warmup": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "jit": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 137], "trace": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 624], "collector_profile_": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "json": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 187, 190, 632], "flop": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "chrome": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "worker_": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "overhead": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 208, 212, 325, 327, 328, 330, 331, 345, 377, 379, 381, 382, 385], "viewer": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "tensorboard": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53, 393, 397, 399, 416, 420, 462, 473, 629, 641], "plugin": [33, 34, 42, 43, 44, 45, 47, 48, 50, 52, 53], "implic": [33, 42, 43, 44, 45, 47, 48], "notimplementederror": [33, 42, 43, 44, 45, 47, 48, 620], "env_creat": [34, 127, 620], "interactiontyp": [34, 42, 44, 47, 50, 167, 210, 342, 345, 410], "return_same_td": 34, "interruptor": 34, "use_buff": [34, 35, 36, 38, 150, 158], "extend_buff": [34, 35, 36, 38], "local_init_rb": [34, 35, 36, 38], "trust_polici": [34, 35, 36, 38, 50, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "compile_polici": [34, 35, 36, 38], "cudagraph_polici": [34, 35, 36, 38], "no_cuda_sync": [34, 35, 36, 38, 50], "cautious": [34, 368], "whole": [34, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 342, 352, 371, 376, 378, 380, 383, 384, 406, 620, 622], "_interruptor": 34, "start_collect": 34, "stop_collect": 34, "preeptiv": 34, "trust": [34, 35, 36, 38, 50, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 227, 304, 380], "cudagraphmodul": [34, 35, 36, 38, 50, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "behaviour": [34, 35, 36, 38, 326, 332, 337, 376, 378, 380, 384, 623, 624, 641], "bypass": [34, 35, 36, 38, 81, 626], "isaaclab": [34, 35, 36, 38, 131, 135], "maniskil": [34, 35, 36, 38], "crash": [34, 35, 36, 38, 255], "Not": [34, 54, 61, 68, 121, 122, 136, 270, 302, 304, 332, 581, 583, 587], "env_mak": [34, 35, 38, 50, 66, 120, 560, 642], "2000": [34, 35, 38, 133, 393, 639], "int64": [34, 35, 38, 52, 56, 57, 59, 61, 62, 64, 72, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 101, 108, 120, 123, 126, 130, 138, 141, 142, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 214, 218, 226, 233, 248, 255, 263, 297, 298, 312, 313, 314, 325, 327, 328, 330, 331, 342, 377, 379, 381, 382, 385, 637], "del": [34, 35, 38, 52, 620, 621, 622, 634, 635, 639, 641, 642], "chunk": [34, 52, 53, 88, 626], "policy_state_dict": [34, 52, 53], "env_state_dict": [34, 52, 53], "safe": [35, 38, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 102, 108, 176, 286, 297, 298, 312, 313, 314, 319, 320, 325, 327, 328, 330, 331, 340, 342, 344, 345, 347, 377, 379, 381, 382, 385, 569, 571, 572, 574, 579, 581, 587, 599, 641], "guard": [35, 38], "doc": [35, 38, 132, 135, 136, 137, 147, 155, 186, 401, 621, 635, 636, 639], "depopul": [35, 36, 38], "mutual": [35, 36, 38], "collector_class": [35, 36, 38, 42, 44, 47, 49, 50, 570, 571], "deriv": [35, 36, 38, 42, 44, 47, 50, 86, 87, 176, 295, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 416], "fake": [35, 36, 38, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 620, 621, 624], "multiprocessedweightupdat": [35, 36, 38], "multiprocessweightsyncschem": [35, 36, 38, 567], "get_server_weight": 37, "policy_weight": [37, 39, 40, 46, 49], "all_worker_id": [37, 39, 40, 41, 46, 49, 54, 55], "scope": [37, 39, 40, 41, 46, 49, 54, 55, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 624, 642], "classmethod": [37, 39, 40, 41, 46, 49, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 239, 275, 282, 288, 289, 311, 324, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_polici": [37, 39, 40, 41, 46, 49, 54, 55], "back": [37, 39, 41, 46, 49, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 74, 75, 76, 77, 79, 86, 87, 89, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 199, 269, 278, 297, 298, 313, 314, 325, 327, 328, 330, 331, 340, 342, 344, 345, 377, 379, 381, 382, 385, 582, 622, 624, 635, 636, 637, 639], "post_hook": [37, 39, 40, 41, 46, 49, 54, 55], "push_weight": [37, 39, 40, 41, 46, 49, 54, 55], "noth": [37, 39, 40, 41, 46, 49, 54, 138, 179, 569, 620, 622], "register_collector": [37, 39, 40, 41, 46, 49, 54, 55, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 326, 332, 337], "register_post_hook": [37, 39, 40, 41, 46, 49, 54, 55], "remote_collector": [39, 50, 572, 574], "max_interv": 39, "_maybe_map_weight": [39, 41, 46, 49, 54], "_sync_weights_with_work": [39, 41, 46, 49, 54], "_skip_upd": 39, "interv": [39, 214, 267, 392, 393, 407, 419, 420, 421, 473, 621, 637], "weight_gett": 40, "vanillaweightsend": 40, "update_weight": [40, 46, 49, 324, 419, 565, 584, 586, 587, 592], "piec": [41, 94, 104, 115, 118, 119, 620, 621, 622, 629, 635, 636, 637, 639], "_push_weight": 41, "unchang": [41, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 231, 243, 250, 265, 271, 272, 275, 277, 301, 326, 332, 337, 344, 376, 378, 380, 383, 384, 393, 412, 585, 586, 620, 639], "__call__": [41, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 326, 332, 337, 345, 376, 378, 380, 383, 384], "proxi": [41, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 176, 310, 325, 327, 328, 330, 331, 342, 377, 379, 381, 382, 385], "weakref": 41, "exporationtyp": [42, 44, 47], "_singl": [42, 44, 47, 50, 563], "collector_kwarg": [42, 44, 47, 50], "num_workers_per_collector": [42, 44, 47, 50], "slurm_kwarg": [42, 44, 47], "update_after_each_batch": [42, 44, 47, 50], "max_weight_update_interv": [42, 44, 47, 50], "update_interv": [42, 44], "tcp_port": [42, 44, 47, 51], "string": [42, 44, 47, 63, 88, 89, 96, 120, 123, 126, 130, 138, 142, 148, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 239, 250, 263, 269, 277, 297, 302, 304, 313, 324, 325, 326, 329, 332, 337, 341, 342, 376, 378, 380, 383, 384, 392, 409, 414, 592, 620, 622, 623, 632, 639], "respect": [42, 44, 47, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 219, 225, 229, 232, 244, 250, 251, 260, 265, 271, 272, 275, 277, 316, 322, 326, 332, 337, 344, 349, 351, 365, 368, 370, 376, 378, 380, 383, 384, 386, 388, 389, 411, 622, 623, 635, 636], "subnod": [42, 44, 47, 50], "fashion": [42, 47, 50, 86, 87, 109, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "distributed_back": [42, 44], "ucc": [42, 44, 47], "turn": [42, 44, 47, 50, 53, 60, 71, 86, 87, 88, 123, 137, 150, 160, 170, 176, 226, 238, 271, 274, 278, 297, 325, 327, 328, 330, 331, 377, 379, 380, 381, 382, 385, 386, 391, 410, 592, 620, 621, 623, 626, 637, 638], "submitit_delai": [42, 51], "former": [42, 44, 47, 56, 65, 68, 72, 73, 79, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 338, 341, 348, 620], "whilst": [42, 44, 47, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "latter": [42, 44, 47, 79, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 326, 332, 337, 338, 341, 348, 368, 376, 378, 380, 383, 384, 562, 563], "homonym": [42, 44, 47, 637], "visit": [42, 44, 47, 175], "facebookincub": [42, 44, 47], "tcp": [42, 44, 47, 51], "port": [42, 44, 47, 51, 54, 161, 324, 335, 336, 580, 587], "10003": [42, 44, 47, 51], "distributedweightupdat": 42, "distributedweightsyncschem": [42, 46], "liter": [44, 86, 120, 165, 170, 171, 172, 174, 175, 178, 182, 183, 185, 191, 324, 325, 327, 328, 330, 331, 332, 337, 380, 384, 569, 571, 572, 574, 578, 579, 581, 587], "frequenc": [44, 337, 421, 620], "favor": [46, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 326, 332, 337, 376, 378, 380, 383, 384, 592, 622], "restart": 46, "less": [46, 86, 87, 101, 102, 145, 176, 325, 327, 328, 330, 331, 332, 377, 379, 381, 382, 385, 562, 563, 622, 623, 639, 641], "visible_devic": 47, "tensorpipe_opt": 47, "experiment": [47, 54, 56, 64, 78, 342, 345, 420, 421], "tensorpiperpcbackendopt": 47, "rpcweightupdat": 47, "rpcweightsyncschem": 47, "collector_info": [49, 570, 571], "collector_rref": [49, 570, 571], "_td": [50, 88, 127, 360, 368], "ray_init_config": [50, 53, 66, 402, 404], "remote_config": [50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "num_collector": [50, 562, 563, 620, 621], "use_env_cr": [50, 564], "autodetect": 50, "num_cpu": [50, 53, 66, 192, 193, 194, 243, 329, 402, 403, 404, 613], "num_gpu": [50, 53, 66, 194, 243, 329, 402, 403, 613], "equat": [50, 83, 130, 180, 279, 280, 312, 351, 622, 625, 637], "exce": [50, 639], "indefinit": 50, "rayreplaybuff": [50, 65, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "enfoc": 50, "rayweightupdat": 50, "rayweightsyncschem": 50, "lazili": [50, 86, 87, 96, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 637], "defer": [50, 337], "distributed_collector": [50, 66], "add_collector": 50, "shutdown_rai": [50, 66], "kill": [50, 402], "local_polici": 50, "stop_remote_collector": 50, "num_job": 51, "tcpport": 51, "submitit_main_conf": 51, "slurm_cpus_per_task": 51, "slurm_gpus_per_nod": 51, "slurm_partit": 51, "timeout_min": 51, "submitit_collection_conf": 51, "delai": [51, 286, 339, 372, 627], "jump": [51, 625], "host": [51, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "satellit": 51, "rendezv": 51, "hang": 51, "forev": 51, "default_config": [51, 289, 294, 311], "default_slurm_conf_main": 51, "default_slurm_conf": 51, "randompolicyfrom": 51, "boundedcontinu": [51, 58, 60, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 239, 242, 273], "dialog_turns_per_batch": [52, 53, 592], "yield_only_last_step": [52, 53], "yield_completed_trajectori": [52, 53], "total_dialog_turn": [52, 53, 88], "async_env": [52, 53], "flatten_data": [52, 53], "simplifi": [52, 55, 65, 209, 329, 626, 637, 639], "vllm": [52, 54, 55, 178, 324, 333, 334, 335, 336, 337, 580, 581, 582, 583, 584, 585, 586, 587, 592, 632], "vllmwrapper": [52, 170, 178, 326, 332, 592, 633], "mocking_class": [52, 270], "dummystrdataload": 52, "llmenv": [52, 173, 181, 185], "llm_model": 52, "gpt2": [52, 138, 179, 289, 294, 311, 329, 332, 337, 613], "token": [52, 87, 88, 89, 138, 170, 171, 172, 174, 175, 177, 178, 179, 181, 182, 183, 184, 188, 189, 193, 195, 196, 198, 324, 325, 326, 329, 330, 332, 337, 376, 378, 380, 384, 402, 403, 404, 528, 592, 594, 613, 632, 633], "get_token": 52, "pad_token": [52, 195, 196, 384], "eos_token": [52, 174, 195, 196, 384], "from_dataload": [52, 170, 171, 172, 175, 178, 185], "from_text": [52, 87, 89, 178, 185, 384], "group_repeat": [52, 170, 171, 172, 175, 178, 181, 185], "attention_mask": [52, 178, 332, 337], "22": [52, 83, 90, 108, 109, 278], "text": [52, 81, 86, 87, 88, 89, 138, 170, 171, 172, 174, 175, 177, 178, 179, 187, 189, 190, 193, 195, 196, 203, 312, 324, 325, 326, 329, 331, 332, 333, 337, 383, 384, 592, 594, 622, 632], "nontensorstack": [52, 63, 87, 96, 120, 123, 138, 172, 175, 179, 185, 199, 239, 269, 273], "plsgqejeyd": 52, "text_respons": [52, 172, 175, 177, 178, 180, 183, 193, 384, 592, 632], "ec": 52, "tjbjz3perwhz": 52, "tokens_respons": [52, 178], "as_remot": [52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "cl": [52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 621], "quantiti": [52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "reserv": [52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "alia": [52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 349, 350, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 373, 376, 378, 380, 383, 384, 390, 422, 423, 572, 574], "get_policy_model": [52, 53], "rayllmcollector": [52, 592], "is_initi": [52, 53, 329, 613], "sync_it": 53, "lightweight": [53, 197, 624, 629], "dialog": [53, 88], "yeild": 53, "idl": [53, 150], "somehwat": 53, "serializ": [53, 150, 158, 329], "v2": [54, 55, 86, 87, 136, 137, 156, 157, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 623], "master_address": [54, 324, 335, 336, 580, 587], "master": [54, 324, 335, 336, 580, 587, 635, 636], "address": [54, 324, 335, 336, 402, 404, 580, 587, 592, 639], "localhost": [54, 161, 335, 336, 587], "master_port": [54, 324, 335, 336, 580, 587, 592], "model_metadata": [54, 55, 580, 585, 586], "tupl": [54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 98, 102, 108, 112, 114, 120, 123, 124, 125, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 241, 246, 287, 290, 296, 297, 298, 302, 304, 305, 307, 311, 313, 314, 315, 316, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 350, 351, 352, 353, 357, 358, 360, 364, 365, 366, 368, 369, 370, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 409, 410, 413, 472, 542, 543, 544, 546, 547, 548, 550, 552, 557, 580, 585, 586, 588, 632, 639, 641], "metadata": [54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 79, 86, 87, 91, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 324, 325, 327, 328, 330, 331, 352, 372, 377, 379, 381, 382, 385, 585, 587, 588, 592, 622, 625, 627, 628, 635, 636, 642], "vllm_tp_size": 54, "vllmupdaterv2": [54, 592], "asyncvllm": [54, 333, 337, 580, 583, 592], "vllm_engin": [54, 55, 580, 581, 583, 585, 586, 587, 592], "reliabl": [54, 592], "get_model_metadata": [54, 55, 324, 592], "transformerswrapp": [54, 55, 170, 195, 196, 326, 329, 337, 384, 584, 592, 633], "rlvllmengin": [55, 334, 587], "vllmupdat": [55, 592], "get_tp_siz": [55, 324], "push_weights_from_transform": 55, "transformers_model": [55, 633], "pretrainedmodel": 55, "push_weights_from_transformers_optim": 55, "rollout_tensordict": 56, "_nestedkei": [56, 70, 71, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 178, 179, 180, 212, 219, 220, 221, 222, 223, 228, 229, 232, 236, 238, 241, 242, 246, 247, 251, 252, 254, 255, 256, 257, 258, 262, 264, 265, 266, 268, 271, 273, 280, 326, 332, 337], "nestedkei": [56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 188, 195, 196, 199, 207, 212, 213, 214, 215, 219, 220, 221, 222, 223, 224, 228, 229, 230, 231, 232, 233, 234, 236, 238, 239, 240, 241, 242, 246, 247, 248, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 279, 280, 286, 287, 301, 312, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 345, 351, 354, 365, 368, 377, 379, 381, 382, 383, 385, 391, 393, 409], "as_nest": 56, "x": [56, 68, 83, 86, 87, 109, 138, 176, 179, 239, 241, 268, 273, 282, 287, 288, 297, 300, 302, 304, 305, 313, 325, 326, 327, 328, 330, 331, 332, 337, 338, 342, 376, 377, 378, 379, 380, 381, 382, 384, 385, 391, 393, 416, 592, 620, 624, 635, 637, 639, 641], "max": [56, 64, 72, 101, 102, 114, 137, 177, 231, 266, 312, 350, 351, 352, 358, 367, 369, 371, 380, 409, 420, 592, 620, 622, 623, 624, 630], "durat": [56, 636], "meta": [56, 74, 79, 86, 87, 89, 128, 132, 176, 190, 325, 327, 328, 330, 331, 349, 351, 365, 368, 370, 377, 379, 381, 382, 385, 622, 635, 636, 639], "aren": [56, 264, 623], "eventu": [56, 623, 637], "recov": [56, 79, 81, 83, 84, 85, 86, 87, 108, 109, 176, 325, 327, 328, 330, 331, 346, 357, 364, 377, 379, 381, 382, 385, 634], "layout": [56, 326, 329, 332, 337], "to_padded_tensor": 56, "nested_tensor": [56, 129, 131], "stride": [56, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 290, 291, 300, 326, 332, 337, 376, 378, 380, 383, 384, 464, 621, 635, 641], "jag": 56, "focu": [56, 620, 621, 622, 624, 626, 627, 628, 635], "team": [56, 635, 636, 641], "cat": [56, 86, 87, 176, 185, 322, 325, 327, 328, 330, 331, 350, 352, 353, 364, 369, 371, 372, 373, 377, 379, 381, 382, 385, 635, 639, 641], "arang": [56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 108, 109, 214, 297, 306, 406, 639], "obs_": 56, "15": [56, 78, 79, 80, 81, 82, 83, 84, 85, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 190, 226, 312, 360, 639], "trajectory_id": 56, "int32": [56, 58, 73, 75, 78, 83, 108, 136, 137, 148, 149, 160, 206, 341], "data_split": 56, "got": [56, 628], "int8": [57, 126, 141, 152, 153, 219], "encod": [57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 74, 75, 76, 77, 86, 87, 121, 122, 126, 129, 130, 131, 132, 135, 136, 137, 145, 146, 148, 149, 155, 161, 162, 176, 180, 214, 231, 309, 310, 315, 317, 325, 326, 327, 328, 330, 331, 332, 337, 377, 379, 381, 382, 385, 402, 613, 621, 622, 623, 626, 637, 639], "unlik": [57, 68, 72, 73, 107, 130, 142, 143, 163, 164, 180, 341, 359, 368, 393, 568, 621, 624, 626, 628, 641], "null": [57, 58, 60, 63, 65, 70, 71, 72, 74, 75, 76, 77, 170, 178, 219, 239], "denot": [57, 636], "assert_is_in": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "belong": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 83, 278, 279, 345, 620, 628, 636], "cardin": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 297, 298, 314, 622], "outcom": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 295, 306, 319, 366, 376, 378, 380, 384, 635], "cartesian": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "clear_device_": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "is_in": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 642], "ndarrai": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 130, 176, 180, 312, 325, 327, 328, 330, 331, 348, 377, 379, 381, 382, 385, 391, 624, 635], "ignore_devic": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "arrai": [57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 74, 75, 76, 77, 86, 87, 90, 101, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 233, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 620, 635], "np": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 90, 130, 176, 180, 278, 325, 327, 328, 330, 331, 348, 377, 379, 381, 382, 385, 391, 624, 635, 637], "use_mask": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 152, 153], "erase_memoize_cach": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "memoiz": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 130, 180], "memoize_encod": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "broadcast": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 295, 324, 358, 371, 580, 585, 586, 587, 588, 592], "least": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 224, 243, 629, 642], "compliant": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "singleton": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 177, 288, 305, 632], "start_dim": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "end_dim": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "implements_for_spec": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "torch_funct": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "tensor_to_index": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "represent": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 250, 275, 277, 325, 326, 327, 328, 330, 331, 332, 337, 349, 368, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 594, 620, 637, 638, 642], "exanpl": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "one_hot": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "categ": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 342], "to_categorical_spec": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "idx_one_hot": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "idx_categ": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "to_categor": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "make_neg_dim": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "convert": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 90, 120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 229, 232, 250, 265, 271, 272, 275, 277, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 344, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587, 594, 620, 621, 622, 637, 639], "shortcut": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 637, 642], "len": [57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 95, 97, 116, 185, 248, 288, 305, 384, 620, 623, 624, 628, 630, 635, 637, 638, 639, 641], "ndimens": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 620], "violat": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "primari": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 138, 179, 613, 628], "project": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 231, 286, 297, 298, 312, 313, 314, 340, 342, 344, 345, 400, 401, 463, 599, 641, 642], "uniformli": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 101, 102, 103, 366, 376, 378, 380, 384, 642], "normal": [57, 58, 59, 60, 61, 62, 63, 64, 67, 70, 71, 74, 75, 76, 77, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 246, 279, 280, 286, 288, 303, 305, 306, 315, 316, 320, 321, 342, 345, 351, 352, 365, 368, 383, 384, 410, 413, 564, 587, 623, 626, 636, 642], "drawn": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 265, 301, 342, 345, 622, 635, 636], "set_provisional_n": [57, 59, 61], "temporarili": [57, 59, 61, 93, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 628, 639], "dest": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 250, 275, 277, 344], "to_numpi": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "transformed_in": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 319, 564], "check_spec_encod": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "to_one_hot": [57, 59, 61, 62, 64], "hot": [57, 59, 61, 62, 64, 121, 122, 129, 131, 132, 135, 136, 137, 142, 143, 145, 146, 148, 149, 152, 153, 155, 161, 162, 163, 164, 214, 231, 297, 298, 310, 313, 314, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 623], "categ_sampl": [57, 59, 62, 64], "onehot_sampl": [57, 59, 62], "to_one_hot_spec": [57, 59, 61, 62, 64], "categoricalbox": [57, 59, 62, 64, 151], "type_check": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "unflatten": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 176, 218, 325, 327, 328, 330, 331, 341, 377, 379, 381, 382, 385], "unsqueez": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 190, 206, 215, 218, 221, 222, 268, 274, 527, 592, 620, 624, 635, 636, 637], "update_mask": [57, 59, 61, 62, 64], "leav": [57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 213, 259, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 620, 628, 639], "unmask": [57, 59, 61, 62, 64, 306], "ts": [57, 59, 61, 62, 64], "boundeddiscret": [58, 60], "upper": [58, 106, 245], "continuousbox": [58, 60, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 239, 242, 265, 273], "provision": [59, 337], "descript": [60, 135, 163, 217, 380, 613, 621, 622], "akin": 60, "unnam": [60, 71], "constraint": [60, 144, 320, 599, 622, 635, 636], "data_cl": 60, "tensorclass": [60, 86, 87, 95, 97, 116, 176, 325, 326, 327, 328, 330, 331, 337, 377, 379, 381, 382, 385, 594], "enforc": [60, 88, 107, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 334, 337, 346, 351, 352, 368, 371, 376, 378, 380, 383, 384, 637], "step_mdp_stat": 60, "pixels_spec": 60, "observation_vector_spec": 60, "33": [60, 69, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 305, 326, 332, 337, 376, 378, 380, 383, 384], "composite_spec": 60, "observation_vector": [60, 222, 620], "_nodefault": [60, 71], "is_empti": [60, 71, 637], "recurs": [60, 71, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 330, 331, 332, 337, 366, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 624], "include_nest": [60, 71], "leaves_onli": [60, 71], "is_leaf": [60, 71], "step_mdp_static_onli": [60, 71], "_compositespecitemsview": [60, 71], "_compositespeckeysview": [60, 71], "reflect": [60, 71, 131, 152, 153, 212, 239, 278, 366, 376, 378, 380, 384, 553, 621, 622, 623, 636], "lock_": [60, 71], "succeed": [60, 71, 239, 273], "ones_upd": [60, 71], "pop": [60, 71, 195, 225], "keyerror": [60, 71, 171, 172, 175, 201, 272, 368, 402, 403, 613], "rand_upd": [60, 71], "refine_nam": [60, 71], "refin": [60, 71, 83, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 592], "lift": [60, 71, 83], "coexist": [60, 71], "nice": [60, 71, 622, 625, 628], "ellipsi": [60, 71], "greedili": [60, 71, 626], "spec_refin": [60, 71], "selected_kei": [60, 71, 259, 620], "unlock_": [60, 71], "_compositespecvaluesview": [60, 71], "zeros_upd": [60, 71], "nvec": [61, 62], "remove_singleton": 61, "ax": [61, 635], "m": [61, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 231, 287, 326, 332, 337, 345, 376, 378, 380, 383, 384, 621, 637], "tensor_spec": [61, 64, 74, 213, 215, 265, 343, 357, 358, 368, 370], "neither": [61, 62, 83, 161, 637], "use_regist": [62, 64], "mone_hot": 62, "boxlist": 62, "example_data": [63, 87, 175, 178, 185], "feature_dim": 63, "conform": 63, "nontensordata": [63, 78, 83, 86, 87, 123, 148, 149, 176, 185, 199, 239, 269, 273, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 391], "left": [63, 78, 79, 83, 88, 102, 108, 173, 174, 177, 178, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 218, 225, 226, 228, 229, 230, 234, 241, 244, 250, 252, 253, 259, 263, 266, 269, 271, 273, 275, 277, 280, 301, 306, 326, 332, 337, 383, 488, 621, 622, 624, 628, 629], "device_typ": [63, 558], "templat": [63, 87, 89, 170, 171, 172, 175, 195, 196, 198, 325, 330, 331, 332, 337, 394, 592, 594], "randomli": [63, 83, 107, 160, 183, 215, 245, 246, 265, 301, 342, 345, 626, 635, 636, 637, 639], "unidimension": 64, "action_valu": [64, 296, 297, 298, 313, 314, 352, 358, 366, 376, 378, 380, 384, 623, 624, 626, 630], "keepdim": [64, 592], "chosen_action_valu": [64, 313, 314, 623, 626], "priori": 64, "definit": [64, 110, 632], "one_hot_sampl": 64, "ep": [65, 72, 101, 102, 246, 279, 280, 312, 351, 380, 413, 429, 506, 516, 537, 538, 540, 541, 542, 543, 544, 547, 548, 549, 552, 620, 621, 623, 624, 627, 630], "1e": [65, 72, 101, 102, 246, 279, 280, 295, 299, 307, 319, 506, 516, 537, 538, 540, 541, 543, 544, 545, 547, 548, 549, 550, 552, 620, 621, 622, 636], "08": [65, 72, 101, 102, 506, 516, 537, 538, 543, 544, 547, 548, 549, 552], "pin_memori": [65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 249, 620, 641], "prefetch": [65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 620, 621, 623, 639], "dim_extend": [65, 68, 72, 73], "delayed_init": [65, 66, 68, 69, 72, 73], "schaul": [65, 101, 102], "quan": [65, 101, 102], "j": [65, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384, 623, 627], "antonogl": [65, 101, 102], "silver": [65, 101, 102], "2015": [65, 101, 102, 226], "arxiv": [65, 80, 83, 85, 101, 102, 121, 122, 124, 125, 136, 137, 142, 143, 145, 146, 155, 163, 164, 221, 250, 275, 289, 290, 291, 292, 293, 294, 298, 299, 300, 308, 309, 312, 315, 316, 317, 349, 350, 354, 355, 356, 357, 359, 360, 361, 362, 363, 364, 367, 368, 371, 372, 386, 638], "ab": [65, 80, 83, 85, 101, 102, 121, 122, 124, 125, 136, 137, 142, 143, 145, 146, 155, 163, 164, 220, 250, 275, 279, 289, 294, 299, 300, 308, 309, 315, 316, 317, 349, 350, 354, 355, 356, 357, 360, 361, 362, 364, 367, 368, 371, 638], "1511": [65, 101, 102, 300], "05952": [65, 101, 102], "expon": [65, 72, 101, 102], "\u03b1": [65, 72], "uniform": [65, 72, 101, 102, 326, 332, 337, 635], "delta": [65, 72, 319, 342, 345, 599, 635], "1_000": [65, 68, 72, 73, 635, 639], "mini": [65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 636], "decid": [65, 68, 72, 73, 613, 635, 641], "incompat": [65, 68, 72, 73, 370, 639], "drop_last": [65, 68, 72, 73, 107, 109, 433], "notion": [65, 68, 72, 73], "capac": [65, 68, 72, 73, 95, 97, 101, 102, 108, 116, 622, 628], "caution": [65, 68, 72, 73, 107, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 402, 642], "codebas": [65, 68, 72, 73, 637], "unbind": [65, 68, 72, 73, 86, 87, 176, 244, 325, 327, 328, 330, 331, 341, 377, 379, 381, 382, 384, 385, 592], "transform_factori": [65, 66, 68, 69, 72, 73], "return_info": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 639], "tensordictprioritizedreplaybuff": [65, 641], "priority_weight": [65, 72, 101, 102], "update_prior": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 412, 621, 639, 641], "36278465": 65, "invert": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 622], "default_remote_class_config": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "overriden": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "tempfil": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 95, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 560, 620, 621, 623, 624, 628, 635, 638, 639], "tensordictreplaybuff": [65, 66, 67, 68, 69, 72, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 108, 109, 114, 220, 221, 412, 438, 560, 620, 621, 623, 639], "1_000_000": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 108, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 620, 623, 635], "td_error": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 352, 353, 354, 356, 357, 358, 359, 364, 366, 369, 371, 372, 373, 376, 378, 380, 384, 620, 639, 641], "update_tensordict_prior": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 620, 639, 641], "temporarydirectori": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 620, 621, 623, 624, 628, 635, 638, 639], "tmpdir": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 620, 621, 624, 635], "rb_load": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "empty_write_count": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "cursor": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "ambigu": [65, 66, 68, 69], "pytre": [65, 66, 68, 69, 72, 73, 86, 87, 98, 117, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "cut": [65, 66, 68, 69], "insert_transform": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 171, 172, 175, 216, 272], "insert": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 94, 104, 114, 115, 118, 119, 171, 172, 175, 195, 216, 221, 225, 262, 272, 274, 592], "__iter__": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 185], "register_load_hook": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "register_save_hook": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "set_sampl": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "set_storag": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "set_writ": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "far": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 175, 303, 320, 321, 380, 592, 630, 637, 642], "replay_buffer_cl": 66, "optiona": 66, "asyncio": [66, 120], "ray_buff": 66, "object_store_memori": 66, "600": 66, "await": 66, "invoc": 67, "friendli": [67, 317, 620], "public": [67, 82, 111, 250, 277], "include_info": [67, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "checkpoint": [68, 91, 93, 95, 99, 110, 111, 113, 117, 402, 418, 614, 639], "roundrobinwrit": [68, 78, 79, 80, 81, 82, 83, 84, 85, 432], "depth": [68, 74, 120, 123, 126, 130, 138, 144, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 288, 290, 291, 292, 293, 297, 299, 300, 305, 308, 309, 464, 465, 468, 469, 470, 621, 625, 627, 628, 634, 635, 636, 639], "_pytre": [68, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 639], "tree_map": [68, 86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 639], "assert0": [68, 639], "writerensembl": [69, 112], "sample_from_al": [69, 78, 106], "num_buffer_sampl": [69, 106], "_c": [69, 72], "ensembl": [69, 106, 112, 113, 119, 344, 369, 436, 437], "forbidden": 69, "collat": [69, 171, 172, 175], "rb0": 69, "rb1": 69, "another_kei": 69, "pixels33": 69, "0x13a2ef430": 69, "0x13a2f9310": 69, "interpolationmod": 69, "bilinear": [69, 254, 513], "0x13a2f9220": 69, "0x13a2f9f70": 69, "tensordictroundrobinwrit": [69, 73], "0x13a2d9b50": 69, "0x13a2f95b0": 69, "0x128648260": 69, "data0": [69, 96], "randint": [69, 86, 87, 176, 185, 268, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 639], "255": [69, 268, 639], "244": [69, 250, 277], "data1": [69, 96, 641], "thrown": [70, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 639], "heterogen": [70, 71, 96, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 620, 621], "semant": [70, 71, 129, 131, 638], "priority_kei": [72, 73, 101, 352, 354, 357, 358, 359, 364, 366, 369, 371, 372, 373, 376, 378, 380, 384, 639, 641], "reduct": [72, 101, 102, 114, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 380, 384, 409, 429, 472], "prioritizedreplaybuff": [72, 641], "min": [72, 101, 102, 114, 312, 350, 351, 352, 358, 367, 369, 371, 376, 380, 409, 621, 622], "median": [72, 101, 102, 114, 130, 136, 137, 180, 214, 342, 345], "_encode_memo_dict": 74, "possess": [74, 79], "describ": [74, 86, 87, 176, 202, 222, 319, 320, 325, 327, 328, 330, 331, 343, 354, 377, 379, 381, 382, 385, 396, 620, 622, 635, 636, 637, 642], "make_composite_from_td": [74, 637], "educ": 74, "guess": 74, "knowledg": [74, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 627, 629], "dataset_id": [78, 79, 80, 81, 83, 84, 85], "num_proc": 78, "slice_len": [78, 83, 102, 108, 109, 393, 434, 435, 623], "strict_len": 78, "mp_start_method": [78, 79, 80, 81, 82, 83, 84, 85, 150, 158, 270, 621, 641], "arari": 78, "2600": 78, "million": 78, "consequ": [78, 93, 628], "50x10": 78, "available_dataset": [78, 79, 80, 81, 82, 83, 84, 85, 108, 109], "ataridqn": 78, "greater": [78, 102, 108, 109, 226, 242, 244, 302, 304, 352, 620, 621], "strict_length": [78, 83, 102, 108, 109, 393, 434, 435, 623], "shorter": [78, 83, 102, 108, 109], "Be": [78, 83, 102, 108, 109], "game_nam": 78, "krull": 78, "1d": [78, 101, 102, 108, 109, 114], "1m": [78, 83, 553, 620, 622, 623], "cheapli": 78, "invalid_rang": 78, "999998": 78, "999999": 78, "add_count": 78, "84": [78, 90, 108, 254, 483, 488, 513, 623, 624], "valueestim": [78, 349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 620, 635, 636], "convolut": [78, 288, 290, 291, 464, 624, 626], "2657628": 78, "2657629": 78, "2657630": 78, "2657631": 78, "2657632": 78, "2657633": 78, "2657634": 78, "2657635": 78, "2657636": 78, "2657637": 78, "2657638": 78, "2657639": 78, "2657640": 78, "2657641": 78, "2657642": 78, "2657643": 78, "2657644": 78, "2657645": 78, "2657646": 78, "2657647": 78, "2657648": 78, "2657649": 78, "2657650": 78, "2657651": 78, "2657652": 78, "2657653": 78, "2657654": 78, "2657655": 78, "2657656": 78, "2657657": 78, "2657658": 78, "2657659": 78, "2657660": 78, "2657661": 78, "2657662": 78, "2657663": 78, "2657664": 78, "2657665": 78, "2657666": 78, "2657667": 78, "2657668": 78, "2657669": 78, "2657670": 78, "2657671": 78, "2657672": 78, "2657673": 78, "2657674": 78, "2657675": 78, "2657676": 78, "2657677": 78, "2657678": 78, "2657679": 78, "2657680": 78, "2657681": 78, "2657682": 78, "2657683": 78, "2657684": 78, "2657685": 78, "2657686": 78, "2657687": 78, "2657688": 78, "2657689": 78, "2657690": 78, "2657691": 78, "1995687": 78, "1995688": 78, "1995689": 78, "1995690": 78, "1995691": 78, "1995692": 78, "1995693": 78, "1995694": 78, "1995695": 78, "1995696": 78, "1995697": 78, "1995698": 78, "1995699": 78, "1995700": 78, "1995701": 78, "1995702": 78, "1995703": 78, "1995704": 78, "1995705": 78, "1995706": 78, "1995707": 78, "1995708": 78, "1995709": 78, "1995710": 78, "1995711": 78, "1995712": 78, "1995713": 78, "1995714": 78, "1995715": 78, "1995716": 78, "1995717": 78, "1995718": 78, "1995719": 78, "1995720": 78, "1995721": 78, "1995722": 78, "1995723": 78, "1995724": 78, "1995725": 78, "1995726": 78, "1995727": 78, "1995728": 78, "1995729": 78, "1995730": 78, "1995731": 78, "1995732": 78, "1995733": 78, "1995734": 78, "1995735": 78, "1995736": 78, "1995737": 78, "1995738": 78, "1995739": 78, "1995740": 78, "1995741": 78, "1995742": 78, "1995743": 78, "1995744": 78, "1995745": 78, "1995746": 78, "1995747": 78, "1995748": 78, "1995749": 78, "1995750": 78, "replaybufferensembl": [78, 106, 112, 119], "untouch": [78, 83, 86, 87, 88, 173, 174, 176, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 273, 280, 325, 327, 328, 330, 331, 377, 379, 381, 382, 383, 385], "_max_run": 78, "dataset_asterix": 78, "asterix": 78, "dataset_pong": 78, "buffer_id": [78, 106, 112], "hidden": [78, 150, 158, 220, 283, 284, 285, 290, 299, 302, 304, 308, 309, 315, 316, 344, 347, 351, 365, 368, 623, 634, 641], "data_path": [78, 79, 80, 81, 82, 83, 84, 85], "data_path_root": [78, 79, 80, 81, 82, 83, 84, 85], "delet": [78, 79, 80, 81, 82, 83, 84, 85, 97, 222, 262, 401], "fn": [78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 273, 307, 326, 332, 337, 376, 378, 380, 383, 384, 531, 562, 563], "chunksiz": [78, 79, 80, 81, 82, 83, 84, 85], "num_chunk": [78, 79, 80, 81, 82, 83, 84, 85], "max_tasks_per_child": [78, 79, 80, 81, 82, 83, 84, 85], "worker_thread": [78, 79, 80, 81, 82, 83, 84, 85], "index_with_gener": [78, 79, 80, 81, 82, 83, 84, 85], "num_fram": [78, 79, 80, 81, 82, 83, 84, 85], "unitari": [78, 79, 80, 81, 82, 83, 84, 85, 637], "subsequ": [78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 326, 332, 337, 376, 378, 380, 383, 384, 567, 575, 623, 635], "distance_from_origin": [78, 79, 80, 81, 82, 83, 84, 85], "forward_reward": [78, 79, 80, 81, 82, 83, 84, 85], "qpo": [78, 79, 80, 81, 82, 83, 84, 85], "qvel": [78, 79, 80, 81, 82, 83, 84, 85], "reward_ctrl": [78, 79, 80, 81, 82, 83, 84, 85, 130, 150, 180], "reward_forward": [78, 79, 80, 81, 82, 83, 84, 85], "reward_surv": [78, 79, 80, 81, 82, 83, 84, 85], "x_posit": [78, 79, 80, 81, 82, 83, 84, 85, 130, 150, 180], "x_veloc": [78, 79, 80, 81, 82, 83, 84, 85, 130, 150, 180], "y_posit": [78, 79, 80, 81, 82, 83, 84, 85], "y_veloc": [78, 79, 80, 81, 82, 83, 84, 85], "achieved_go": [78, 79, 80, 81, 82, 83, 84, 85], "desired_go": [78, 79, 80, 81, 82, 83, 84, 85], "27": [78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 108, 109, 121, 122, 150, 158, 176, 226, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "_collate_id": [78, 79, 80, 81, 82, 83, 84, 85], "0x120e21dc0": [78, 79, 80, 81, 82, 83, 84, 85], "cattensor": [78, 79, 80, 81, 82, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 482, 620, 634, 637, 642], "cat_tensor": [78, 79, 80, 81, 82, 83, 84, 85], "cat_next_tensor": [78, 79, 80, 81, 82, 83, 84, 85], "func": [78, 79, 80, 81, 82, 83, 84, 85, 281], "new_storag": [78, 79, 80, 81, 82, 83, 84, 85], "31": [78, 79, 80, 81, 82, 83, 84, 85, 108, 136, 137], "full_storag": [78, 79, 80, 81, 82, 83, 84, 85], "0x168406fc0": [78, 79, 80, 81, 82, 83, 84, 85], "from_env": 79, "use_truncated_as_don": 79, "direct_download": 79, "terminate_on_end": 79, "env_kwarg": [79, 84, 85, 218, 478, 562, 563, 620], "d4rl": [79, 85], "reconstruct": [79, 108, 109, 361, 620, 642], "regard": [79, 85, 298, 349, 359, 368, 620, 622, 637], "get_dataset": 79, "qlearning_dataset": 79, "fewer": [79, 102, 108], "unexpectedli": 79, "traj_split": 79, "observationnorm": [79, 279, 280, 506, 564, 620, 621, 622, 623, 641], "maze2d": 79, "umaz": 79, "loc": [79, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180, 241, 246, 257, 279, 280, 283, 284, 285, 303, 307, 320, 321, 342, 345, 347, 349, 350, 352, 364, 368, 369, 370, 371, 506, 516, 554, 564, 599, 620, 621, 622, 623, 626, 636, 641], "gen": 80, "dgrl": 80, "accompani": [80, 218, 263], "gap": 80, "2312": 80, "05742": 80, "gen_dgrl": 80, "procgen": 80, "bigfish": 80, "bossfight": 80, "1m_e": 80, "1m_": 80, "comma": [80, 624], "npy": 80, "mmap": [80, 84, 85], "minut": 80, "huggingfac": [80, 85, 177, 332], "internet": [80, 85], "connect": [80, 85, 161, 190, 565, 566, 568, 569, 571, 572, 573, 574, 576, 579, 581, 587], "load_from_local_minari": 81, "minari": 81, "websit": [81, 83, 632], "currenrtli": 81, "minari_data": 81, "door": 81, "human": [81, 171, 637], "torchrl_logg": [81, 630, 632], "28": [81, 108, 109, 378, 380], "39": [81, 136, 137], "door_body_po": 81, "openml": [82, 147, 453], "dua": 82, "graff": 82, "2017": 82, "uci": [82, 123], "archiv": 82, "ic": 82, "edu": 82, "ml": [82, 161, 162, 324], "scikit": [82, 147], "sklearn": [82, 147], "panda": 82, "adult_num": [82, 147], "adult_onehot": [82, 147], "mushroom_num": [82, 147], "mushroom_onehot": [82, 147], "covertyp": [82, 147], "shuttl": [82, 147], "magic": [82, 147, 624, 625], "shuffl": [83, 107, 109, 171, 172, 175, 433, 636], "embodi": [83, 638], "collabor": 83, "21": [83, 84, 108, 109, 150, 152, 153, 158, 226, 619, 640], "institut": 83, "demonstr": [83, 592, 622, 624, 628, 632, 633, 635, 636, 637, 639, 642], "527": 83, "skill": 83, "160266": 83, "googl": [83, 84, 121, 122, 142, 143, 148, 149, 175, 177, 622, 623, 632, 635, 636], "open_x_embodi": 83, "2310": [83, 155], "08864": 83, "language_instruct": 83, "get_non_tensor": 83, "nor": [83, 161], "insuffici": 83, "chosen": [83, 163, 164, 264, 265, 314, 393, 613, 629], "openx": 83, "__will": 83, "change__": 83, "crop": [83, 223, 251, 393, 488], "compli": 83, "modal": [83, 326, 332, 337, 620], "cmu_stretch": [83, 393], "discount": [83, 127, 255, 350, 356, 359, 360, 362, 386, 387, 388, 389, 420, 621, 622, 635, 636], "is_init": [83, 85, 220, 240, 302, 304, 312, 341, 386, 623, 624], "language_embed": 83, "512": [83, 300], "green": [83, 635], "garbag": [83, 568], "lid": 83, "roboset": 84, "h5": [84, 85, 86, 87, 93, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "roboh": [84, 155, 456], "excludetransform": [84, 259, 494, 639], "fk1": 84, "v4": [84, 130, 150, 180, 214, 254, 620, 622, 638, 641], "expert": 84, "fk1_microopenrandom_v2d": 84, "concis": [84, 627], "20": [84, 108, 109, 114, 120, 123, 126, 130, 134, 138, 148, 149, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 264, 300, 378, 380, 402, 406, 545, 633, 639, 642], "18": [84, 108, 109, 156, 157, 163, 164, 270], "23": [84, 109, 226, 282], "19": [84, 108, 109, 114, 226], "75": [84, 108, 539], "totensor": 85, "image_s": 85, "v": [85, 279, 283, 357, 364, 371, 606, 620, 621], "npz": 85, "2206": [85, 145, 146], "04779": [85, 350, 356], "vd4rl": 85, "squar": [85, 223, 228, 303, 320, 321, 351, 368, 380, 393, 592], "rectangular": [85, 288], "walker_walk": 85, "64px": 85, "height": [85, 223, 228, 254, 483, 488], "veloc": [85, 120, 123, 124, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 635, 636, 637, 642], "audio": 86, "function_cal": 86, "_wrap_td_method": 86, "wrapped_func": 86, "0x7ff8813eafc0": 86, "mime_typ": 86, "function_nam": 86, "function_arg": 86, "copy_exist": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "return_earli": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "share_non_tensor": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "robust_kei": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_ani": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "auto_batch_s": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "batch_dim": [86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 564], "incur": [86, 87, 121, 122, 136, 137, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "involv": [86, 87, 129, 131, 132, 142, 143, 155, 176, 218, 221, 270, 302, 304, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 625, 627], "opinion": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "term": [86, 87, 96, 176, 188, 195, 241, 325, 327, 328, 330, 331, 349, 358, 368, 377, 379, 381, 382, 385, 419, 621, 622, 625, 626, 636], "obj": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_dataclass": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "namedtupl": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 325, 326, 327, 328, 330, 331, 332, 337, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385], "from_namedtupl": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_dict": [86, 87, 176, 185, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_tupl": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_struct_arrai": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "hdf5": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_h5": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "dest_cl": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "as_tensorclass": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "convers": [86, 87, 121, 122, 136, 137, 170, 172, 175, 176, 186, 195, 196, 209, 325, 327, 328, 330, 331, 377, 379, 380, 381, 382, 385, 566, 569, 571, 572, 574, 579, 581, 587, 592, 594, 632, 633], "persistenttensordict": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "key1": [86, 87, 176, 222, 262, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 406, 414, 641], "key2": [86, 87, 176, 222, 262, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 406, 414, 641], "as_modul": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "use_state_dict": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "lazy_stack": [86, 87, 88, 89, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 384, 385, 592, 634], "expand_ident": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "ensebml": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "vmap": [86, 87, 176, 325, 327, 328, 330, 331, 344, 347, 350, 352, 358, 364, 366, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 606], "tensordictparam": [86, 87, 176, 325, 327, 328, 330, 331, 345, 377, 379, 381, 382, 385], "densli": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "dens": [86, 87, 120, 176, 306, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 592], "reinstanti": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "tempt": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "orign": [86, 87, 176, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 384, 385], "longer": [86, 87, 95, 176, 189, 282, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 592, 621, 623, 630, 635, 636, 639], "empty_modul": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "n_model": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "bia": [86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 239, 250, 265, 270, 271, 272, 275, 277, 288, 290, 291, 292, 293, 299, 300, 301, 302, 304, 305, 307, 312, 325, 326, 327, 328, 330, 331, 332, 337, 344, 352, 366, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 620, 621, 622, 623, 636], "exec_modul": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "to_modul": [86, 87, 176, 325, 327, 328, 330, 331, 344, 347, 377, 379, 381, 382, 385, 620, 641], "backprop": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "named_tupl": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "a_tensor": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "a_str": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "nt": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "to_namedtupl": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "genericdict": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_pytre": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "biject": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "castabl": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "surject": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "weird": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "weirdlookingclass": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "weird_kei": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "pytree_recon": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "to_pytre": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_remote_init": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "processgroup": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "init_remot": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "src": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "struct_arrai": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "rex": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "fido": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "u10": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "ag": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "i4": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "f4": [86, 87, 123, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "x_recon": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "to_struct_arrai": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "from_tensordict": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "non_tensordict": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "my_tupl": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "fromkei": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "getattr": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "load_memmap": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "load_": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "load_memmap_": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "non_block": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 325, 326, 327, 328, 330, 331, 332, 337, 344, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385], "robust": [86, 87, 176, 251, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 592], "decod": [86, 87, 138, 176, 179, 207, 308, 324, 325, 326, 327, 328, 330, 331, 332, 337, 377, 379, 381, 382, 385, 592], "emit": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "saved_td": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "td_load": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "_subclass": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "faketensormod": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "faketensor": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "strict": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 325, 326, 327, 328, 330, 331, 332, 337, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 613, 624], "from_flatten": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "attemptedli": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "destin": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 220, 229, 230, 232, 239, 270, 272, 275, 279, 325, 326, 327, 328, 330, 331, 332, 337, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 393, 419, 420, 473, 578], "maybe_dense_stack": [86, 87, 176, 185, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "existsok": [86, 87, 95, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "mimic": [86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "non_tensor": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "charact": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 622, 624], "throw": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 330, 331, 332, 337, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 642], "cross": [86, 87, 176, 325, 326, 327, 328, 330, 331, 332, 337, 377, 379, 381, 382, 385, 590], "anymor": [86, 87, 176, 272, 325, 327, 328, 330, 331, 344, 377, 379, 381, 382, 385], "tensordictfutur": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "serialis": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "deepli": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "memmap_": [86, 87, 176, 279, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "memmap_lik": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "contentless": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "memmap_refresh_": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "refresh": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385, 630, 635, 636], "saved_path": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "setattr": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "tent": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "keep_var": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 325, 326, 327, 328, 330, 331, 332, 337, 352, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385], "to_tensordict": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "retain_non": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "discrard": [86, 87, 176, 325, 327, 328, 330, 331, 377, 379, 381, 382, 385], "contentbas": 87, "is_complet": 87, "tool_cal": 87, "tool_respons": [87, 193, 592], "apply_chat_templ": [87, 89, 170, 193, 384, 592, 632], "autotoken": [87, 89, 170, 171, 172, 174, 175, 182, 183, 189, 193, 195, 196, 325, 330, 331, 332, 337, 384, 592, 632, 633], "autoprocessor": 87, "add_generation_prompt": [87, 89, 195, 196, 325, 384], "chat_templ": [87, 198, 325, 332, 337, 384], "chat_template_nam": [87, 89, 325, 330, 331, 332, 337, 384], "continue_final_messag": 87, "return_tensor": [87, 195, 330], "return_dict": [87, 89, 196], "return_assistant_tokens_mask": [87, 89, 195, 196], "chat": [87, 89, 170, 171, 172, 175, 184, 193, 195, 196, 198, 325, 330, 331, 332, 337, 384, 592, 594, 633], "pretrainedtoken": [87, 170, 181, 332, 337], "prompt": [87, 88, 170, 171, 172, 173, 175, 177, 178, 183, 185, 190, 193, 324, 325, 327, 329, 330, 331, 332, 337, 380, 383, 592, 633], "im_start": [87, 172, 175, 193, 592], "assist": [87, 89, 170, 172, 175, 183, 189, 190, 193, 195, 196, 332, 337, 380, 384, 592, 594, 623, 632, 633], "preval": 87, "messag": [87, 89, 170, 183, 187, 566, 567, 568, 569, 571, 572, 574, 575, 576, 579, 581, 587, 592, 633], "pt": [87, 195, 330, 395, 460], "assistant_mask": 87, "qwen": [87, 172, 175, 183, 193, 324, 332, 333, 334, 337, 384, 592, 632, 633], "dialogpt": 87, "falcon": 87, "deepseek": 87, "chatml_format": [87, 332, 337, 384], "default_spec": [87, 325, 327, 328, 330, 331], "set_list_to_stack": [87, 175, 190, 193, 195, 196, 197, 592, 632], "foo": [87, 95, 97, 116, 639, 642], "from_chat": [87, 89, 170, 195, 196, 332, 337, 384, 633], "from_pretrain": [87, 89, 138, 172, 175, 179, 183, 193, 195, 196, 324, 329, 332, 337, 384, 592, 632, 633], "qwen2": [87, 172, 175, 183, 193, 324, 333, 334, 337, 592, 632, 633], "7b": [87, 89, 324, 592, 632], "nyou": [87, 175], "im_end": [87, 172, 183, 193, 592, 632], "nwrite": 87, "capit": [87, 632, 633], "franc": [87, 632, 633], "germani": 87, "pari": [87, 175, 632], "berlin": 87, "answer": [87, 172, 174, 175, 177, 183, 592, 632], "topk_siz": 88, "prompt_kei": [88, 177, 383], "rewards_kei": [88, 383], "k": [88, 287, 326, 332, 337, 606], "topk": 88, "selector": [88, 632], "25": [88, 226, 472, 613, 620], "wrote": 88, "top3": 88, "r3": 88, "as_padded_tensor": [88, 178, 185, 196, 326, 332, 337], "add_modul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "init_weight": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "fill_": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 621, 623], "net": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 291, 293, 296, 300, 326, 332, 337, 349, 350, 352, 358, 364, 368, 369, 370, 371, 376, 378, 380, 383, 384, 464, 465, 468, 470, 560, 621, 637, 638, 641], "requires_grad": [88, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 270, 272, 326, 332, 337, 345, 352, 371, 376, 378, 380, 383, 384, 443], "bfloat16": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "datatyp": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 639], "member": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 366, 376, 378, 380, 383, 384, 393], "xdoctest": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 239, 250, 265, 270, 271, 272, 275, 277, 326, 332, 337, 344, 352, 366, 371, 376, 378, 380, 383, 384], "buf": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "20l": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 366, 376, 378, 380, 383, 384], "1l": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 366, 376, 378, 380, 383, 384], "5l": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 366, 376, 378, 380, 383, 384], "doubl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 229, 230, 232, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 354, 359, 369, 376, 378, 380, 383, 384, 581, 582, 583, 584, 620, 621, 622, 623, 642], "eval": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 279, 326, 332, 337, 351, 368, 376, 378, 380, 383, 384, 620, 621, 622], "evalu": [88, 120, 123, 126, 130, 131, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 272, 295, 306, 310, 321, 326, 332, 337, 369, 376, 378, 380, 383, 384, 555, 556, 613, 621, 622, 630], "batchnorm": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 326, 332, 337, 376, 378, 380, 383, 384], "extra_repr": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "transformthatmeasuresbyt": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 383], "byte": [88, 90, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 383], "bytes_in_td": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 383], "get_buff": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "docstr": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 625, 626], "get_submodul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "explan": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "qualifi": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "referenc": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "get_extra_st": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 376, 378, 380, 383, 384], "set_extra_st": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 376, 378, 380, 383, 384], "picklabl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 376, 378, 380, 383, 384], "get_paramet": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "sai": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 635, 638, 642], "net_b": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "net_c": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "conv": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 326, 332, 337, 376, 378, 380, 383, 384, 621], "conv2d": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 290, 291, 300, 326, 332, 337, 376, 378, 380, 383, 384], "kernel_s": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 290, 291, 300, 308, 326, 332, 337, 376, 378, 380, 383, 384, 464, 621, 641], "diagram": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "degre": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 326, 332, 337, 376, 378, 380, 383, 384], "named_modul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "o": [88, 91, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "half": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384, 620], "ipu": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "descend": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384], "get_swap_module_params_on_convers": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384], "persist": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 212, 239, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384, 402, 613], "preserv": [88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 344, 352, 371, 376, 378, 380, 383, 384], "missing_kei": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384], "unexpected_kei": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384], "l": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 622, 637], "idx": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "mtia": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "named_buff": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "remove_dupl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 366, 376, 378, 380, 383, 384], "prepend": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 366, 376, 378, 380, 383, 384, 624], "running_var": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "named_children": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "conv4": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "conv5": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "memo": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "named_paramet": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 326, 332, 337, 366, 376, 378, 380, 383, 384], "register_backward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "removablehandl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_full_backward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_buff": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "running_mean": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "alongsid": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 592, 613, 629], "num_featur": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_forward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "with_kwarg": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "always_cal": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_module_forward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "regardless": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 351, 365, 368, 376, 378, 380, 383, 384], "register_forward_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "And": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 627], "forward_pr": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_module_forward_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "rule": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 326, 332, 337, 345, 376, 378, 380, 383, 384, 622], "ordinarili": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "grad_input": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "grad_output": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "technic": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 621, 623, 624, 626], "register_module_full_backward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_full_backward_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "backward_pr": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_module_full_backward_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_load_state_dict_post_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "incompatible_kei": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_load_state_dict_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "local_metadata": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "error_msg": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "noqa": [88, 120, 123, 126, 130, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 624], "b950": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_modul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_paramet": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_state_dict_post_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "register_state_dict_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "requires_grad_": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 624], "autograd": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384], "freez": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 376, 378, 380, 383, 384], "finetun": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "gan": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "set_submodul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "share_memori": [88, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 620], "share_memory_": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384, 641], "averag": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 279, 280, 312, 326, 332, 337, 352, 360, 361, 371, 376, 378, 380, 383, 384, 413, 592, 620, 622], "shallow": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 352, 371, 376, 378, 380, 383, 384, 623], "detach": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 352, 363, 366, 371, 372, 376, 378, 380, 383, 384, 386, 387, 388, 389, 620], "memory_format": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "channels_last": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "pin": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "4d": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "ignore_w": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "1913": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "3420": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "5113": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "2325": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "torch_doctest_cuda1": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "gpu1": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "1914": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "5112": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "2324": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "float16": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "cdoubl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "3741": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "2382": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "5593": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "4443": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "complex128": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "6122": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "1150": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 344, 376, 378, 380, 383, 384], "to_empti": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "transform_done_spec": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 230, 243, 262, 269, 271, 273, 383], "transform_env_batch_s": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 271, 383], "transform_env_devic": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 230, 271, 383], "transform_full_done_spec": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 273, 280, 383], "dst_type": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "xpu": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "set_to_non": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 376, 378, 380, 383, 384], "template_nam": 89, "inverse_pars": 89, "model_family_keyword": 89, "llama": 89, "mistral": 89, "histori": [89, 170, 171, 172, 174, 175, 178, 183, 184, 186, 189, 190, 193, 195, 196, 197, 325, 326, 329, 330, 331, 332, 337, 384, 592, 632], "jinja2": 89, "pars": [89, 174, 186, 198, 200, 203, 330, 331, 592, 594, 632, 639], "parser": [89, 135, 174, 186, 187, 197, 203, 561, 564, 592], "llama_templ": 89, "inst": 89, "elif": [89, 592, 620, 621, 632], "endgener": 89, "endif": 89, "endfor": 89, "parse_llama_text": 89, "findal": 89, "dotal": 89, "user_cont": 89, "assistant_cont": 89, "strip": [89, 621], "hf": 89, "hello": [89, 170, 195, 196, 324, 332, 333, 337, 384, 402, 613], "hi": [89, 332, 337], "Or": [89, 156, 157], "compression_fn": 90, "decompression_fn": 90, "compression_level": 90, "decompress": 90, "sensori": 90, "zstd": 90, "verifi": [90, 171, 368], "attach": [90, 95, 96, 97, 98, 110, 112, 116, 621], "entiti": [90, 95, 96, 97, 98, 110, 112, 116], "to_bytestream": 90, "data_to_bytestream": 90, "compact": [92, 93, 100], "shift": [92, 93, 100, 386, 387, 388, 389, 622], "checkpoint_fil": 93, "h5_kwarg": 93, "iff": 93, "suffix": [93, 410], "h5py": 93, "create_dataset": 93, "increas": [93, 221, 266, 312, 351, 368, 380, 384, 635, 636], "immut": [94, 120, 123, 126, 130, 138, 150, 154, 158, 159, 170, 171, 172, 175, 178, 179, 180, 253, 272], "scratch_dir": [95, 620, 621, 623, 628, 635, 638, 639], "shared_init": [95, 97, 425, 427], "auto_cleanup": 95, "mistak": [95, 97, 116], "overewritten": 95, "cleanup": [95, 192, 324, 337, 569, 571, 572, 574, 579, 581, 587, 590], "exit": 95, "ctrl": 95, "sigterm": 95, "temp": [95, 613], "main_ckpt_dir": 95, "rb_memmap": 95, "10_000_000": 95, "myclass": [95, 97, 116], "clean": [95, 184, 324, 329, 403, 566, 568, 569, 571, 572, 574, 576, 579, 581, 587, 592, 613], "lazystacktensordict": 96, "heterougen": 96, "linearli": 96, "densifi": 96, "unlimit": [96, 98], "st": 96, "consolid": 97, "cleanup_memmap": 97, "expans": [97, 366, 376, 378, 380, 384], "ram": [97, 129, 131, 629, 639], "zero_": [97, 116, 206], "liststoag": 99, "max_priority_within_buff": [101, 102], "proport": [101, 639], "magnitud": [101, 102, 620, 635], "tempor": [101, 302, 304, 387, 388], "focus": [101, 102, 613, 620, 627], "p_i": [101, 102], "delta_i": [101, 102], "epsilon": [101, 102, 246, 286, 301, 312, 413, 621, 622, 623, 626], "frac": [101, 102, 622], "sum_j": [101, 102], "p_j": [101, 102], "w_i": [101, 102], "cdot": [101, 102, 384], "aggress": [101, 102, 384], "bias": [101, 102, 620], "toward": [101, 102, 277], "unbias": [101, 102], "anneal": [101, 102, 312, 621, 626, 635], "guidelin": [101, 102], "math": [101, 102, 190], "data_0": 101, "data_1": 101, "smoothen": 101, "tdrb": 101, "pack": [101, 332, 622, 625, 642], "nd": [101, 102], "sum_tre": [101, 102], "min_tre": [101, 102], "end_kei": [102, 108, 109, 434, 435, 623], "traj_kei": [102, 108, 109, 434, 435, 639], "cache_valu": [102, 108, 109, 434, 435, 623], "truncated_kei": [102, 108, 109, 255, 263, 434, 435, 522], "closer": [102, 641], "commonli": [102, 108, 109, 642], "readili": [102, 108, 109, 345], "conjunct": [102, 108, 109, 621], "buffer0": [102, 108], "immutablewrit": [102, 108], "buffer1": [102, 108], "other_sampl": [102, 108], "short": [102, 108, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 332, 621, 622, 625, 626, 636, 639], "tolist": [102, 592], "120110917137936e": 102, "06": [102, 295, 319, 540, 550], "roundrobin": [104, 115], "consum": [107, 109, 341, 621, 622, 628, 636, 639], "incomplet": [107, 109, 183], "fresh": [107, 185, 568, 576], "haven": [107, 638], "remain": [107, 183, 191, 220, 230, 231, 241, 243, 264, 592, 613, 627], "draw": [107, 301], "use_gpu": [108, 109, 434, 435], "acceler": [108, 109, 130, 180, 635, 636], "ep_1": [108, 109], "ep_2": [108, 109], "73": 108, "74": 108, "76": 108, "77": 108, "41": 108, "42": [108, 305, 349, 350, 352, 353, 357, 364, 371], "43": 108, "44": 108, "45": 108, "67": [108, 634], "68": 108, "69": 108, "70": 108, "71": 108, "80": [108, 121, 122], "82": 108, "83": 108, "78": 108, "79": 108, "320": [108, 109, 124, 125], "550": [108, 109], "700": [108, 109], "dataid": [108, 109], "counter": [109, 191, 226, 270, 341, 408, 624], "request": [109, 201, 218, 251, 324, 330, 565, 613], "51": 109, "__len__": 110, "rank_kei": 114, "flat": [114, 386], "get_insert_index": 114, "themselv": [120, 621], "maybe_dens": 120, "maker": [120, 564, 621], "min_get": [120, 154, 159], "sort": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 222, 312], "another_act": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "discretebox": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "mutabl": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "action_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 622, 636], "had": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 626, 628], "all_act": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "any_don": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "_callabletransform": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180], "auto_specs_": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "observation_kei": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "action_spac": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 233, 297, 298, 313, 314, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 623, 624, 626, 630], "discrep": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 349, 351, 353, 354, 365, 368, 370], "broken": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180], "check_dtyp": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180], "rng": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 637], "revert": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 326, 332, 337, 376, 378, 380, 384, 626, 639], "accomplish": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 625, 632], "done_keys_group": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "another_don": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "done_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "empty_cach": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 194, 272], "env_batch_s": [120, 154, 159], "fake_tensordict": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 621, 624], "recip": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 338, 341, 348, 568], "afterward": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 338, 341, 348, 635, 642], "envnam": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "full_action_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 635, 636], "full_done_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "full_observation_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "full_reward_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "pipeline_st": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "full_state_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "input_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "is_spec_lock": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "maybe_reset": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "speak": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 227, 345, 620], "observation_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "output_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "register_gym": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 625], "entry_point": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "info_kei": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "reward_threshold": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "nondeterminist": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "max_episode_step": [120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "order_enforc": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "autoreset": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "disable_env_check": [120, 123, 126, 129, 130, 138, 145, 146, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 446, 450], "apply_api_compat": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "nasium": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 209], "dmcontrolenv": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 393, 444, 620, 625, 634, 642], "dmc": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "cheetah": [120, 123, 124, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 393, 620], "removeemptyspec": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 511], "threshold": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 301, 350, 351, 378, 380, 592, 622], "learnt": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 560], "checker": [120, 123, 126, 129, 130, 138, 145, 146, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "stepapicompat": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "deem": [120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180], "task_nam": [120, 123, 124, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 444], "envgym": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0855": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0215": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0881": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0412": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "1101": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0080": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0254": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0424": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "9609e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "02": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 280, 621, 630], "9776e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "04": [120, 123, 126, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 267, 280], "6347e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "03": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 246, 267], "3842e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5338e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "3064e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0381e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "6656e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "05": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 267, 368, 637], "0204e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0833": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0275": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0612": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0770": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "1256": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0082": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0186": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0476": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "2221": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "2256": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5930": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "6937": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5865": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5479": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0187": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "6825": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5224": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0018": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "1005": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0335": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 227], "0268": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0133": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0627": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0074": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0488": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0353": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0075": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0069": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0098": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0058": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0033": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0157": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0004": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 267], "0381": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0452": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "11355747": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "04257728": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "00408397": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "04155852": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0389733": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "01409826": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0978704": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "08808327": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "03970837": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "00535434": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "02353762": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "05116226": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "02788907": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "06848346": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "05154399": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0371798": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "05128025": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "selecttransform": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 518], "dydact": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "ant": [120, 121, 122, 123, 126, 130, 133, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 638], "gym_env": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 641], "reset_kei": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 258, 264, 265, 266, 523, 635], "multitask": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "multiag": [120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 351, 365, 368], "another_reward": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "reward_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "auto_cast_to_devic": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 636], "soon": [120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "__sort": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "as__": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "categorical_action_encod": [120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 209, 226, 443, 446, 450, 624], "argmaxmodul": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "argmax": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 298, 314, 624, 626], "n_ob": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 241, 341, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 627], "n_act": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 241, 349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 627], "ourselv": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 622, 642], "emul": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "input_td": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "rollout_td": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "state_kei": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "state_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "prevail": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 222, 258, 326], "newli": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "next_tensordict": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 218, 222, 234, 235, 236, 249, 252, 253, 259, 262, 275, 279, 592], "precomput": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "_stepmdp": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212], "exclude_act": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212], "retain": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "next_data": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "reset_data": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 190, 592, 642], "2106": [121, 122, 355, 372], "13281": [121, 122], "cache_clear_frequ": [121, 122, 443], "leak": [121, 122, 324], "frame_skip": [121, 122, 124, 125, 129, 130, 131, 132, 136, 137, 139, 140, 145, 146, 155, 180, 237, 408, 410, 420, 421, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 473, 497, 553, 620, 621, 622, 641], "allow_done_after_reset": [121, 122, 124, 125, 126, 129, 131, 132, 135, 136, 137, 145, 146, 148, 149, 155, 161, 162, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459], "toler": [121, 122, 124, 125, 129, 131, 132, 135, 136, 137, 145, 146, 148, 149, 155, 161, 162, 194, 295, 319, 324], "is_avail": [121, 122, 620, 621, 622, 623, 635, 636, 638], "els": [121, 122, 185, 218, 308, 613, 620, 621, 622, 623, 632, 633, 635, 636, 637, 638], "87": [121, 122], "acrobot": [121, 122, 124, 125, 642], "advant": [121, 122, 136, 137], "timer": [121, 122, 130, 136, 137, 180, 526], "timeit": [121, 122, 136, 137, 624], "310": [121, 122], "00": [121, 122, 217, 619, 640], "ms": [121, 122, 136, 137], "268": [121, 122], "433": [121, 122], "213": [121, 122], "8605": [121, 122], "pipelineenv": 122, "get_environ": 122, "san": 123, "fen": [123, 148, 149], "pgn": 123, "legal": [123, 215], "board": [123, 160], "include_san": 123, "algebra": [123, 637], "notat": 123, "include_fen": 123, "forsyth": 123, "edward": 123, "include_pgn": 123, "portabl": [123, 613, 629], "include_legal_mov": 123, "include_hash": 123, "hash": [123, 138, 179, 499], "mask_act": 123, "subset": [123, 637, 638], "29275": 123, "rnbqkbnr": [123, 148, 149], "pppppppp": [123, 148, 149], "kqkq": [123, 148, 149], "legal_mov": 123, "219": 123, "5p2": 123, "ppppp1pp": 123, "event": [123, 306, 310, 317, 639], "white": 123, "96": 123, "kq": 123, "5n2": 123, "rnbqkb1r": 123, "nf3": 123, "na6": 123, "c4": 123, "f6": 123, "h4": 123, "rb8": 123, "na3": 123, "ra": 123, "get_legal_mov": 123, "dm_control": [124, 125, 444, 620, 634, 642], "2006": [124, 125, 226, 350, 356], "12983": [124, 125], "240": [124, 125, 641], "swingup": [124, 125, 642], "swingup_spars": [124, 125], "ball_in_cup": [124, 125], "catch": [124, 125, 624], "balance_spars": [124, 125], "three_pol": [124, 125], "two_pol": [124, 125], "finger": [124, 125], "turn_easi": [124, 125], "turn_hard": [124, 125], "fish": [124, 125], "upright": [124, 125, 621], "swim": [124, 125], "hopper": [124, 125], "hop": [124, 125], "humanoid": [124, 125, 150, 158, 634], "walk": [124, 125, 150, 158, 621, 634], "run_pure_st": [124, 125], "bring_bal": [124, 125], "bring_peg": [124, 125], "insert_bal": [124, 125], "insert_peg": [124, 125], "point_mass": [124, 125], "reacher": [124, 125], "swimmer": [124, 125], "swimmer6": [124, 125], "swimmer15": [124, 125], "walker": [124, 125], "dog": [124, 125], "trot": [124, 125], "humanoid_cmu": [124, 125], "lqr": [124, 125], "lqr_2_1": [124, 125], "lqr_6_2": [124, 125], "quadrup": [124, 125], "escap": [124, 125], "stacker": [124, 125], "stack_2": [124, 125], "stack_4": [124, 125], "deviceless": 126, "run_type_check": [126, 144], "hint": 126, "counterenv": 126, "creator": [127, 555, 556, 562, 563, 564], "substitut": [127, 264, 279, 626], "vecnorm": [127, 280, 537, 538, 564], "test_env1": 127, "observation_count": [127, 642], "test_env2": 127, "ps": 127, "p1": 127, "p2": 127, "9934": 127, "make_vari": [127, 270], "variant": [127, 270], "trajcount": [127, 529], "env_creator_pendulum": 127, "env_creator_cartpol": 127, "env_str": 128, "device_map": 128, "asyncvectorenv": 129, "pixel_observ": [129, 131, 132, 155], "pixelobservationwrapp": [129, 131, 132, 155], "adventur": [129, 131], "airraid": [129, 131, 642], "alien": [129, 131], "time_limit": 129, "timelimit": [129, 142, 143, 163, 164], "default_info_dict_read": [129, 130, 131, 150, 180], "reader": [129, 130, 131, 150, 180, 621], "set_info_dict_read": [129, 130, 131, 150, 180, 625], "info_dict": [129, 130, 131, 150, 180], "gymlikeenv": [129, 131, 180], "auto_register_info_dict": [129, 130, 131, 150, 180], "multibinari": [129, 131], "multidiscret": [129, 131], "rag": [129, 131], "gym_conversion_exampl": [129, 131], "info_dict_read": [130, 150, 180], "ignore_priv": [130, 180], "baseinfodictread": [130, 180], "tensordictprim": [130, 150, 180, 287, 302, 304, 524, 623], "succe": [130, 150, 180, 587], "underscor": [130, 180], "primer": [130, 170, 171, 172, 175, 178, 180, 185, 194, 265, 287, 302, 304, 317, 623], "halfcheetah": [130, 150, 180, 214, 254, 620, 641], "reward_run": [130, 150, 180], "raise_if_clos": [130, 180], "fast_encod": [130, 180], "memoize_cach": [130, 180], "adaptive_autorang": [130, 180], "4f": [130, 180, 384, 622, 623, 637], "fp": [130, 180, 393, 398, 400, 401], "10141": [130, 180], "5742fp": [130, 180], "10576": [130, 180], "8388fp": [130, 180], "read_act": [130, 180], "read_don": [130, 180], "nonsens": [130, 180], "fallback": [130, 180, 324], "read_ob": [130, 180], "dictat": [130, 180, 242, 342, 345, 368, 620, 637], "read_reward": [130, 180], "gym_lik": [130, 180], "hoc": [130, 150, 180, 626], "dict_read": [130, 180], "my_info_kei": [130, 180], "some_env": [130, 180], "vecenv": 131, "vectorenv": 131, "convert_actions_to_numpi": [131, 446, 450], "missing_obs_valu": [131, 278, 446, 450], "vecgymenvtransform": [131, 536], "secur": [132, 632], "habitat3": 132, "ai": [132, 638], "habitatrenderpick": 132, "isaacgym": [133, 134, 448], "isaacgymwrapp": 133, "isaacgymenv": [134, 448], "webpag": 134, "isaac": [134, 135], "essenc": [134, 625], "scripts_isaaclab": 135, "managerbasedrlenv": 135, "app": 135, "applaunch": 135, "argpars": [135, 561, 564], "argumentpars": 135, "add_app_launcher_arg": 135, "args_cli": 135, "hydra_arg": 135, "parse_known_arg": 135, "app_launch": 135, "isaaclab_task": 135, "f401": 135, "manager_bas": 135, "ant_env_cfg": 135, "antenvcfg": 135, "isaac_lab": 135, "cfg": [135, 464, 465, 468, 469, 470, 553, 554, 555, 556, 557, 558, 559, 560, 561, 564], "instadeepai": [136, 137], "2306": [136, 137, 280], "09884": [136, 137], "snake": [136, 137, 172], "grid": [136, 137, 393], "bodi": [136, 137], "body_st": [136, 137], "fruit_posit": [136, 137], "col": [136, 137], "row": [136, 137, 242], "head_posit": [136, 137], "tail": [136, 137], "game2048": [136, 137], "maze": [136, 137], "cleaner": [136, 137, 592, 633], "cvrp": [136, 137], "multicvrp": [136, 137], "minesweep": [136, 137], "rubikscub": [136, 137], "knapsack": [136, 137], "sudoku": [136, 137], "tsp": [136, 137], "connector": [136, 137], "mmst": [136, 137], "graphcolor": [136, 137], "partli": [136, 137], "scrambl": [136, 137], "robotwarehous": [136, 137], "tetri": [136, 137], "binpack": [136, 137], "jobshop": [136, 137], "0x1fca91910": 136, "122": [136, 137, 642], "40": [136, 137], "0x1ff9baee0": 136, "134": [136, 137], "0x1ff9ba7c0": 136, "172": [136, 137], "eager": [137, 334], "tdreset": [137, 634], "whichev": 137, "mctsforest": [138, 179], "vocab_s": [138, 178, 179, 528, 613], "vocabulari": [138, 178, 179, 199, 269], "omit": [138, 179, 185, 286, 301, 312, 411, 622, 627, 637, 639], "hashing_modul": [138, 179], "siphash": [138, 179], "text_output": [138, 179], "batch_decod": [138, 179], "text_kei": [138, 179, 326, 329, 332, 337], "gpt2token": [138, 179], "input_id": [138, 178, 179], "make_tensordict": [138, 179], "mo": [139, 140], "minecart": [139, 140], "mo_gym": [140, 242], "marl": [141, 166, 221, 262, 266, 358, 371, 625, 635, 636], "group_map": [141, 142, 143, 148, 149, 152, 153, 161, 162, 163, 164, 166, 635], "constructiuon": [141, 152, 153], "premad": [141, 142, 143, 152, 153, 163, 164], "all_in_one_group": [141, 148, 149, 166], "agent_0": [141, 152, 153, 161, 166, 262], "agent_1": [141, 152, 153, 161, 166, 262], "agent_2": [141, 152, 153, 161, 166], "agent_3": [141, 161], "one_group_per_ag": [141, 152, 153], "meltingpot": [142, 143, 451], "2211": [142, 143], "13746": [142, 143], "melt": [142, 143], "pot": [142, 143], "novel": [142, 143, 627], "social": [142, 143], "situat": [142, 143, 178, 185], "familiar": [142, 143, 621, 632, 636, 642], "unfamiliar": [142, 143], "broad": [142, 143], "cooper": [142, 143, 635, 636], "decept": [142, 143], "reciproc": [142, 143], "stubborn": [142, 143], "substrat": [142, 143], "ml_collect": 142, "config_dict": 142, "configdict": 142, "horizon": [142, 143, 163, 164, 208, 622], "infinit": [142, 143, 163, 164, 171, 172, 175, 185, 280, 628, 639], "categorical_act": [142, 143, 148, 149, 152, 153, 156, 157, 161, 162, 163, 164], "agent_nam": [142, 143, 163, 164, 166], "agent_names_to_indices_map": [142, 143, 163, 164], "env_torchrl": [142, 143], "commons_harvest__open": [142, 143], "rgb": [142, 143], "144": [142, 143, 190], "collective_reward": [142, 143], "ready_to_shoot": [142, 143], "88": [142, 143, 156, 157], "substrate_config": 143, "get_config": 143, "mp_env": 143, "build_from_config": 143, "default_player_rol": 143, "mymbenv": 144, "world_model": [144, 361], "hidden_observ": 144, "worldmodelwrapp": [144, 599], "activation_class": [144, 288, 290, 291, 292, 293, 299, 300, 305, 464, 465, 621, 626, 635, 636, 641], "relu": [144, 294, 307, 326, 332, 337, 599], "activate_last_lay": [144, 293, 305, 465], "sail": [145, 146], "sg": [145, 146], "10558": [145, 146], "readthedoc": [145, 148, 149], "en": [145, 148, 149], "python_interfac": 145, "envpoolmixin": 146, "env_bas": 146, "task_id": 146, "env_typ": 146, "gym_reset_return_info": 146, "envpool_env": 146, "www": [147, 306], "fetch_openml": 147, "dataset_nam": 147, "106": 147, "openspiel": [148, 149, 454], "open_spiel": [148, 149], "game_str": 148, "return_st": [148, 149, 152, 153], "4672": [148, 149], "current_play": [148, 149], "674": 148, "2048": [148, 149], "add_nois": [148, 149], "amazon": [148, 149], "backgammon": [148, 149], "restor": [148, 149, 592, 614], "td_restor": [148, 149], "pyspiel": 149, "load_gam": 149, "new_initial_st": 149, "3009": 149, "my_env_fun": [150, 158], "custom_attribute_list": [150, 158], "custom_attribut": [150, 158], "custom_method_list": [150, 158], "custom_method": [150, 158], "deploi": [150, 158, 218, 624], "share_individual_td": [150, 158], "shared_memori": [150, 158], "policy_proof": [150, 158], "ll": [150, 158, 226, 620, 621, 622, 623, 625, 626, 627, 628, 630, 632, 636, 642], "serial_for_singl": [150, 158, 621], "circular": [150, 158, 620], "daemon": [150, 158], "auto_wrap_env": [150, 158], "list_of_kwarg": [150, 158], "sharabl": [150, 158], "com_veloc": [150, 158], "head_height": [150, 158], "joint_angl": [150, 158], "torso_vert": [150, 158], "batched_pipe_timeout": 150, "stringent": [150, 622, 635, 636], "penv": [150, 270], "env_fix": 150, "influenc": 150, "thumb": [150, 622], "update_kwarg": [150, 158], "th": [151, 236, 274, 637], "thdot": [151, 637], "max_spe": [151, 637], "max_torqu": [151, 637], "dt": [151, 312, 637], "gen_param": [151, 637], "gravit": [151, 637], "torqu": [151, 637], "pettingzoo": [152, 153, 455, 635, 636], "pet": [152, 153], "zoo": [152, 153], "__": [152, 153], "aecenv": [152, 153], "dead": [152, 153], "done_on_ani": [152, 153, 635], "compulsori": [152, 153], "adversary_0": [152, 153], "adversari": [152, 153, 363, 635], "sisl": 152, "multiwalker_v9": 152, "aec": [152, 153], "n_piston": [152, 153], "pistonball_v6": [152, 153], "piston": [152, 153], "piston_0": [152, 153], "piston_1": [152, 153], "piston_20": [152, 153], "tictactoe_v3": [152, 153], "player": [152, 153, 160], "player_1": [152, 153], "player_2": [152, 153], "butterfli": 153, "_setup": [154, 159], "async_reset_send": [154, 159], "async_reset_recv": [154, 159], "vikashplu": 155, "wiki": 155, "06828": 155, "from_depth": 155, "smacv2": [156, 157, 457], "starcraft": [156, 157], "challeng": [156, 157, 625, 637, 638], "10gen_terran": [156, 157], "10gen_zerg": [156, 157], "10gen_protoss": [156, 157], "3m": [156, 157], "8m": [156, 157], "25m": [156, 157], "5m_vs_6m": [156, 157], "8m_vs_9m": [156, 157], "10m_vs_11m": [156, 157], "27m_vs_30m": [156, 157], "mmm": [156, 157], "mmm2": [156, 157], "2s3z": [156, 157], "3s5z": [156, 157], "3s5z_vs_3s6z": [156, 157], "3s_vs_3z": [156, 157], "3s_vs_4z": [156, 157], "3s_vs_5z": [156, 157], "1c3s5z": [156, 157], "2m_vs_1z": [156, 157], "corridor": [156, 157], "6h_vs_8z": [156, 157], "2s_vs_1sc": [156, 157], "so_many_banel": [156, 157], "bane_vs_ban": [156, 157], "2c_vs_64zg": [156, 157], "old": [156, 157, 272, 280, 365, 642], "smac": [156, 157], "map_nam": [156, 157], "176": [156, 157], "battle_won": [156, 157], "dead_al": [156, 157], "dead_enemi": [156, 157], "episode_limit": [156, 157], "322": [156, 157, 183], "procedur": [156, 157, 324], "distribution_config": [156, 157], "n_unit": [156, 157], "n_enemi": [156, 157], "team_gen": [156, 157], "dist_typ": [156, 157], "weighted_team": [156, 157], "unit_typ": [156, 157], "marin": [156, 157], "maraud": [156, 157], "medivac": [156, 157], "exception_unit_typ": [156, 157], "start_posit": [156, 157], "surrounded_and_reflect": [156, 157], "map_x": [156, 157], "map_i": [156, 157], "capability_config": [156, 157], "131": [156, 157], "starcraft2env": 157, "tic": 160, "tac": 160, "toe": 160, "single_play": 160, "player1": 160, "desired_batch_s": 160, "player0": 160, "uniti": [161, 162], "technolog": [161, 162], "llapi": [161, 162], "mlagents_env": [161, 162], "unityenviron": [161, 162], "file_nam": 161, "registered_nam": 161, "3dball": 161, "group_0": 161, "vectorsensor_size8": 161, "continuous_act": [161, 163, 164, 391, 635, 636], "agent_10": 161, "agent_11": 161, "agent_4": 161, "agent_5": 161, "agent_6": 161, "agent_7": 161, "agent_8": 161, "agent_9": 161, "group_reward": 161, "proroklab": [163, 164], "vectorizedmultiagentsimul": [163, 164], "2207": [163, 164], "03530": [163, 164], "basescenario": 163, "defaultt": 163, "sparsiti": 163, "unbatched_action_spec": [163, 164], "unbatched_observation_spec": [163, 164], "unbatched_reward_spec": [163, 164], "het_spec": [163, 164], "het_specs_map": [163, 164], "flock": [163, 164, 391], "agent_collision_rew": [163, 164], "agent_distance_rew": [163, 164], "ca": 166, "environment4": 166, "get_group_map": 166, "probabilist": [167, 241, 342, 349, 368, 599, 622, 641], "sumbodul": 169, "blank": [170, 592], "canva": [170, 592], "fundament": [170, 592, 628], "intention": [170, 592], "data_kei": [170, 171, 172, 175, 178, 194], "dialogu": 170, "klrewardtransform": [170, 188, 195, 196, 501, 592], "kl": [170, 188, 189, 195, 196, 241, 361, 365, 376, 380, 384, 592], "diverg": [170, 188, 189, 195, 196, 241, 342, 345, 361, 365, 380, 384, 592], "pythoninterpret": [170, 192, 592, 613], "dataloadingprim": [170, 171, 178, 194, 265, 592], "addthinkingprompt": [170, 592], "input_mod": [170, 171, 172, 174, 175, 195, 196, 326, 329, 332, 337, 592, 633], "system_prompt": [170, 171, 172, 175, 193, 592, 613, 632], "template_kwarg": [170, 171, 172, 175], "system_rol": [170, 592], "user_rol": [170, 592], "policy_rol": 170, "response_kei": 170, "datasetchatenv": 170, "gsm8kenv": [170, 171, 174, 181, 183, 592], "ifevalenv": [170, 171, 592], "response_data": 170, "next_ob": [170, 246, 386, 387, 388, 389, 641], "mont": [170, 171, 172, 175, 178, 185, 349, 351, 365, 368, 380, 383, 620], "carlo": [170, 171, 172, 175, 178, 185, 349, 351, 365, 368, 380, 383, 620], "pull": [171, 639], "rlhf": [171, 241, 380], "feedback": [171, 420, 592, 630, 641], "rlvr": 171, "batch_size_dl": [171, 172, 175, 181], "apply_templ": [171, 172, 175, 193, 632], "ray_backend": [171, 172, 175], "dataloader_actor_nam": [171, 172, 175], "thin": [171, 180], "chatenv": [171, 172, 175, 180, 186, 190, 193, 197, 590, 613, 632], "reset_dataload": [171, 172, 175, 185, 194], "set_missing_toler": [171, 172, 175, 194, 272], "gsm8k": [172, 173, 181, 592], "compute_reward": [172, 175], "gsm8k_dataload": 172, "3b": [172, 175, 183, 193, 324, 333, 334, 337], "question": [172, 175, 632, 639, 641], "bought": 172, "sandwich": 172, "he": 172, "paid": 172, "calcul": [172, 190, 197, 255, 349, 351, 356, 365, 368, 370, 372, 380, 386, 418], "breed": 172, "36": 172, "mari": 172, "saw": [172, 629, 637, 639], "reward_answ": [172, 174, 592], "reward_contain": [172, 174, 592], "reward_right": [172, 174, 592], "reward_think": [172, 174, 592], "snak": 172, "set_done_if_answ": [174, 177, 592], "make_gsm8k_env": 174, "sentenc": 174, "extract_tag": [174, 592], "xml": [174, 197, 203, 592], "ifev": [175, 177, 592], "ifeval_dataload": 175, "pprint": [175, 592], "instruction_id_list": [175, 177], "detectable_cont": 175, "number_placehold": 175, "num_highlight": 175, "num_": 175, "respond": 175, "plan": [175, 613], "week": 175, "europ": 175, "trip": 175, "london": 175, "rome": 175, "cap": [175, 622, 639], "restaur": 175, "prompt_level_strict_acc": [176, 177], "inst_level_strict_acc": [176, 177], "prompt_level_loose_acc": [176, 177], "inst_level_loose_acc": [176, 177], "instruction_ids_kei": 177, "keyword_args_kei": 177, "id_kei": 177, "response_column": 177, "score_kei": 177, "ifeval_scor": 177, "aggregate_reward": 177, "_scorer": 177, "ifevalscoredata": [177, 592], "format_weight": 177, "scorer": 177, "IF": 177, "co": [177, 233, 324, 637], "column": 177, "builder": [177, 181, 614, 621, 642], "think_block": 177, "answer_block": [177, 592], "langdetect": 177, "nltk": 177, "immutabledict": 177, "default_reward_aggreg": [177, 592], "tier": 177, "eo": [177, 337], "metric": [177, 351, 368, 380, 403, 409, 416, 418, 420, 421, 473, 620], "multipli": [177, 178, 185, 349, 350, 351, 352, 358, 365, 367, 368, 369, 371, 380, 413, 620, 635], "penalti": [177, 182, 188, 326, 332, 337, 363, 365, 376], "formula": [177, 241, 303, 320, 321, 349, 351, 365, 368, 380, 622], "format_scor": [177, 592], "quality_bonu": 177, "structure_multipli": 177, "complexity_scal": 177, "everyth": [177, 621, 622, 623, 629, 630], "incent": 177, "languag": [178, 592, 633], "tailor": [178, 641], "cot": [178, 592], "token_kei": 178, "str_kei": 178, "attention_kei": 178, "assign_reward": 178, "has_attent": 178, "assign_don": 178, "batchless": 178, "eos_token_id": [178, 332], "pretrainedtokenizerbas": [178, 199, 269], "stack_method": [178, 185, 194], "as_nested_tensor": [178, 185, 326, 332, 337], "bert": [178, 199, 269], "uncas": [178, 199, 269], "tokens_in": 178, "tokens_out": 178, "grpo": [178, 185, 376, 378, 380], "mlgym": [180, 182, 592], "get_library_nam": 180, "prisonersdilemma": 182, "reward_wrong_format": 182, "mlgymenv": [182, 592], "wrongli": 182, "cond": [183, 226, 227, 487], "random_prompt": 183, "edit_last_turn": 183, "zero_reward": 183, "undo_don": 183, "egocentr": 183, "reconsid": 183, "But": [183, 613, 634], "me": [183, 187, 190, 632], "wrong_answ": 183, "natalia": 183, "sold": 183, "48": 183, "friend": 183, "april": 183, "she": [183, 639], "72": 183, "altogeth": [183, 227], "undon": 183, "correct_answ": 183, "allowed_domain": [184, 632], "tool_nam": [184, 190, 193, 197, 203], "web": [184, 624, 632], "brows": [184, 632], "browser": [184, 190, 632], "click": [184, 632], "llm_tool": 184, "use_ray_servic": [185, 189, 195, 243], "mappabl": 185, "dataloader_factori": [185, 194], "unrel": 185, "dl": 185, "raydataloadingprim": 185, "endless_dataload": [185, 194], "set_capture_non_tensor_stack": 185, "dummydataload": 185, "generate_random_str": 185, "ascii_lowercas": 185, "__next__": 185, "zxwvupirska": 185, "stringa": 185, "zxwvupirsk": 185, "roll": 185, "init_st": 185, "nngcmflsana": 185, "vrrbnhzpmga": 185, "nngcmflsan": 185, "vrrb": 185, "dummytensordataload": 185, "max_length": [185, 199, 269, 624, 630], "generate_random_tensor": 185, "pad_tensor": 185, "padding_length": 185, "data_spec": 185, "toolregistri": 186, "llmtoolpars": [186, 197], "stop_on_error": 186, "pass_state_to_tool": 186, "pluggabl": 186, "xmlblockpars": [186, 197], "websearch": 186, "schema_in": [186, 201, 202], "schema_out": [186, 201, 202], "titl": [186, 622, 623, 624, 636, 637], "gen_log_probs_full_kei": [188, 195], "log_prob": [188, 195, 295, 306, 310, 321, 326, 329, 332, 337, 345, 352, 358, 371, 376, 378, 380, 384, 633], "ref_log_probs_full_kei": [188, 195], "ref_log_prob": [188, 195, 196, 376, 378, 380, 384], "kl_kei": [188, 195], "kl_penalti": [188, 195], "add_to_reward": [188, 195], "coeff": [188, 195, 351, 365, 368], "padding_sid": [188, 189, 195, 196, 306, 326, 332, 337], "retrievelogprob": [188, 189, 195, 384], "retrievekl": [188, 189, 196], "pad_output": [188, 195, 196, 326, 329, 332, 337, 633], "gen_log_prob": [188, 195], "pad_sequ": [188, 189, 195, 196], "next_td": [188, 195], "kl_transform": 188, "gen_log_probs_kei": 188, "ref_log_probs_kei": 188, "coef": [188, 241], "chathistori": [189, 195, 196, 330, 331, 332, 337], "ref_model": [189, 195, 196], "llmwrapperbas": [189, 195, 196, 332, 337, 380], "ref_model_factori": [189, 195], "assistant_onli": [189, 195, 196, 384], "upcom": [189, 195, 366, 376, 378, 380, 384, 620], "actor_nam": [189, 194, 195, 243, 329], "gen_model": [189, 195], "klcomput": [189, 195, 196], "tool_call_pattern": [190, 197], "mcp": 190, "npx": 190, "uvx": 190, "browsermcp": 190, "regex": [190, 197, 592], "tool_name_with_serv": 190, "args_json": [190, 197], "os": [190, 621, 633], "deno": 190, "deno_path": 190, "expandus": 190, "stdio": 190, "sqrt": [190, 312], "pi": [190, 624, 635, 636, 637], "run_python_cod": 190, "python_cod": 190, "linkedlist": 190, "successfulli": [190, 193, 583, 592, 632, 633], "textcont": 190, "nresult": 190, "141592653589793": 190, "return_valu": 190, "n15": 190, "annot": [190, 632], "curl": 190, "fssl": 190, "land": 190, "sh": 190, "version_typ": 191, "llmcollector": [191, 195, 326, 332, 337, 592], "tracker": [191, 240], "current_vers": 191, "uuid4": 191, "pool_siz": [192, 193, 613], "get_servic": [192, 193, 613], "python_executor": [192, 193, 613], "max_concurr": [192, 193, 329, 402, 613], "robin": [192, 324, 432, 613], "stdout": 192, "stderr": 192, "returncod": 192, "service_nam": [193, 404, 613], "namespac": [193, 402, 404, 561, 564, 590], "tooltransformbas": 193, "boilerpl": 193, "inject": 193, "nprint": 193, "pythonexecutorservic": [193, 592, 613], "reus": [194, 290, 401, 592], "create_dataload": 194, "primer1": 194, "primer2": 194, "travers": 194, "missing_toler": [194, 199, 269], "reset_par": [194, 271], "set_contain": [194, 271], "ahead": [195, 642], "from_collector": 195, "get_new_vers": [195, 326, 329, 332, 337], "gen_model_factori": 195, "consciou": [195, 196], "identif": [195, 196], "history_kei": [195, 332, 337], "tokenizer_kwarg": [195, 196, 326, 332, 337, 384], "assit": [195, 196, 384], "rayretrievekl": 195, "optconfig": [195, 196, 384], "optforcausallm": [195, 196, 384], "weather": [195, 196, 384], "facebook": [195, 196, 384], "opt": [195, 196, 384], "125m": [195, 196, 384], "return_log_prob": [195, 196, 241, 283, 284, 285, 332, 337, 342, 345, 347, 370, 384, 468, 622, 626, 633, 635, 636, 641], "log_probs_kei": [195, 196, 326, 329, 332, 337], "chat_histori": [195, 196, 332, 337], "log_probs_full_kei": 196, "batchabl": 196, "tool_schema": 197, "mcptooltransform": [197, 592], "schema": [197, 202], "unknown": [197, 620], "use_raw_nontensor": [199, 239, 269, 273], "additional_token": [199, 269], "skip_special_token": [199, 269, 326, 331, 332, 337], "add_special_token": [199, 269], "return_attention_mask": [199, 269], "call_before_reset": [199, 269], "test_input_spec": [199, 273], "visibl": [200, 402, 403, 404, 590, 636], "label": [200, 620, 635, 639], "correl": [200, 312], "toolservic": 201, "addservic": 201, "optional_tag": 203, "nsome": 203, "list_of_tensordict": [204, 205], "unsqueeze_null_shap": 206, "dynamic_shap": 206, "model_bas": [207, 208], "dreamer": [207, 208, 299, 360, 361, 362], "model_based_env": [207, 360], "dreamerenv": [207, 360], "model_based_env_ev": 207, "imagin": [208, 323], "spec_typ": 209, "convert_specnam": 209, "remap_state_to_observ": 209, "spectyp": 209, "unus": 209, "probabilistictdmodul": [210, 305, 342, 345, 410], "keep_oth": [212, 637], "exclude_reward": 212, "exclude_don": 212, "next_": 212, "mdp": [212, 625, 637], "write_full_fals": 213, "_terminated_or_trunc": 213, "num_interv": [214, 475], "out_action_kei": [214, 475], "samplingstrategi": 214, "optino": 214, "intenum": 214, "action_disc": 214, "qualnam": [214, 318, 374], "boundari": [214, 318, 348, 374, 622, 624, 635, 636], "masker": 215, "finit": [215, 235, 626, 639], "maskedenv": 215, "ones_lik": [215, 303, 306, 320], "scatter": 215, "fill_float": [217, 477], "fill_int": [217, 477], "fill_bool": [217, 477], "someenvclass": 217, "autoresetenv": 217, "fooenv": 217, "sign": [217, 260, 386, 635], "envtyp": 217, "3633e": 217, "4877e": 217, "2849e": 217, "7584e": 217, "6609e": 217, "6166e": 217, "8366e": 217, "2761e": 217, "5685e": 217, "4102e": 217, "8111e": 217, "9959e": 217, "0865e": 217, "5644e": 217, "2119e": 217, "2542e": 217, "9952e": 217, "4059e": 217, "2094e": 217, "9009e": 217, "5140e": 217, "3554e": 217, "2920e": 217, "7893e": 217, "6429e": 217, "3057e": 217, "2867e": 217, "6963e": 217, "3818e": 217, "2576e": 217, "2679e": 217, "1640e": 217, "6972e": 217, "0212e": 217, "5959e": 217, "4637e": 217, "3121e": 217, "2168e": 217, "5232e": 217, "7704e": 217, "7457e": 217, "4127e": 217, "1064e": 217, "0854e": 217, "5712e": 217, "2189e": 217, "5235e": 217, "8289e": 217, "0009e": 217, "0257e": 217, "8893e": 217, "5872e": 217, "9405e": 217, "7766e": 217, "0403e": 217, "0626e": 217, "2959e": 217, "7263e": 217, "2775e": 217, "9564e": 217, "0411e": 217, "6769e": 217, "6354e": 217, "8698e": 217, "1765e": 217, "6292e": 217, "5375e": 217, "1820e": 217, "7023e": 217, "5836e": 217, "9016e": 217, "4826e": 217, "6191e": 217, "6387e": 217, "8667e": 217, "2056e": 217, "1147e": 217, "5991e": 217, "0278e": 217, "5219e": 217, "3067e": 217, "6617e": 217, "3322e": 217, "2629e": 217, "4599e": 217, "7298e": 217, "5848e": 217, "0148e": 217, "5745e": 217, "6982e": 217, "7877e": 217, "3527e": 217, "7285e": 217, "6668e": 217, "0583e": 217, "6956e": 217, "3962e": 217, "9845e": 217, "5015e": 217, "5903e": 217, "9993e": 217, "9418e": 217, "0196e": 217, "6557e": 217, "2109e": 217, "8997e": 217, "1507e": 217, "7363e": 217, "0310e": 217, "9574e": 217, "8980e": 217, "0090e": 217, "reshape_fn": [218, 478, 624], "reset_func": [218, 478], "tensordict_batch_s": 218, "tensordict_reset": [218, 637], "biner": 219, "burn_in": [220, 480], "burn": 220, "burnt": 220, "grumodul": [220, 265, 599, 623], "gru_modul": [220, 302], "input_s": [220, 265, 302, 304, 623, 624], "hidden_s": [220, 265, 302, 304, 623, 624], "default_recurrent_mod": [220, 302, 304], "burn_in_transform": 220, "gru": [220, 265, 302, 624], "num_lay": [220, 302, 304, 308, 309, 624], "86": 220, "3008": 220, "37": 220, "0344": 220, "padding_valu": [221, 306, 326, 332, 337], "as_invers": 221, "movement": [221, 368], "propos": [221, 233, 623, 639], "pdf": [221, 289, 290, 291, 292, 293, 298, 312, 352, 359, 363, 369, 372, 386], "1312": 221, "5602": 221, "unsqueezetransform": [221, 532, 637, 639], "consumpt": 221, "pictur": 221, "pixels_trsf": [221, 639], "grayscal": [221, 498, 621, 623, 624, 639, 642], "data_exclud": [221, 639], "mitig": 221, "make_rb_transform_and_sampl": 221, "sampler_kwarg": 221, "redund": [221, 592, 623], "fly": [221, 279, 365, 592, 622, 637, 639, 642], "del_kei": [222, 262, 275, 634, 637], "unsqueeze_if_oor": 222, "observation_posit": 222, "observation_veloc": 222, "center": [223, 393, 549], "width": [223, 228, 254, 483, 488], "scalar": [224, 256, 286, 291, 293, 301, 312, 349, 350, 351, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 373, 376, 378, 380, 384, 386, 387, 388, 389, 409, 621, 627, 637], "rewardsc": [225, 272, 516, 620, 621, 623], "rewardclip": [225, 515], "transform_list": 225, "condition": 226, "switch": [226, 272, 280, 303, 321, 391, 613, 633], "unalt": 226, "criteria": [226, 332], "mod": [226, 241, 287, 302, 304, 326, 332, 337, 341, 345, 348, 376, 378, 380, 384, 623, 624, 630], "policy_switch": 226, "step_count_tot": 226, "step_count_main": 226, "0322": 226, "1540": 226, "0111": 226, "3190": 226, "0299": 226, "1544": 226, "0181": 226, "3280": 226, "0276": 226, "1550": 226, "0255": 226, "3414": 226, "0253": 226, "1558": 226, "0334": 226, "3596": 226, "0230": 226, "1569": 226, "0422": 226, "3828": 226, "0206": 226, "1582": 226, "0519": 226, "4117": 226, "1598": 226, "0629": 226, "4469": 226, "0156": 226, "1617": 226, "0753": 226, "4891": 226, "0130": 226, "1639": 226, "0895": 226, "5394": 226, "0104": 226, "1665": 226, "1058": 226, "5987": 226, "0076": 226, "1696": 226, "1246": 226, "6685": 226, "0047": 226, "1732": 226, "1463": 226, "7504": 226, "0016": 226, "1774": 226, "1715": 226, "8459": 226, "0020": 226, "0150": 226, "1884": 226, "6117": 226, "0017": 226, "2071": 226, "3838": 226, "0105": 226, "2115": 226, "5110": 226, "exectu": 227, "palliat": [227, 626], "inner_count": 227, "middle_env": 227, "middle_count": 227, "auto_unwrap": [227, 272, 405, 442], "9670": 227, "2546": 227, "9669": 227, "9802": 227, "1981": 227, "1601": 227, "9926": 227, "1214": 227, "5556": 227, "9994": 227, "7622": 227, "9984": 227, "0561": 227, "7933": 227, "9895": 227, "1445": 227, "7779": 227, "dtype_in": 229, "dtype_out": 229, "scan": [229, 232, 317, 346, 347], "resp": [229, 232], "anticip": [229, 232], "not_transform": [229, 232], "orig_devic": 230, "unspecifi": 230, "num_actions_effect": 231, "max_act": 231, "include_forward": 231, "num_act": [231, 288, 358, 491, 624, 626], "action_out": 231, "inde": [231, 622, 624, 637], "eol_kei": [233, 493], "life": [233, 493, 638], "lives_kei": [233, 493], "eol_attribut": [233, 493], "breakout": 233, "210": [233, 248], "160": [233, 248], "eol_transform": 233, "eol": 233, "dqnloss": [233, 349, 350, 352, 353, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 374, 376, 378, 380, 384, 557, 606, 621, 623, 624, 630], "register_kei": 233, "loss_or_advantag": 233, "lossmodul": [233, 416, 420, 421, 559, 560, 606], "valueestimatorbas": [233, 366, 376, 378, 380, 384], "excluded_kei": 234, "first_dim": 236, "last_dim": 236, "allow_positive_dim": [236, 262, 274], "frameskip": 236, "repeatedli": [237, 622, 636], "hash_fn": 239, "repertoir": 239, "reproducible_hash": 239, "unarytransform": [239, 531], "observation_str": 239, "tobyt": [239, 273], "observation_hash": 239, "x08": 239, "x8b": 239, "xbexav": 239, "xbf": 239, "x00": 239, "xee": 239, "xb5": 239, "x17": 239, "x8f": 239, "xbe": [239, 273], "x88": 239, "xccu": 239, "xc0vr": 239, "get_input_from_hash": 239, "hash_tensor": 239, "bit": [239, 622, 623, 625, 635, 636, 639], "init_kei": [240, 341, 500], "log_prob_kei": [241, 329, 345], "sample_log_prob": [241, 283, 284, 285, 342, 345, 347, 368, 376, 378, 380], "pi_curr": 241, "pi_0": 241, "overfit": 241, "get_dist": [241, 326, 329, 332, 337, 345, 346], "frozen": [241, 279, 280], "normalparamextractor": [241, 283, 284, 285, 342, 347, 349, 350, 352, 358, 364, 368, 369, 370, 371, 372, 373, 599, 622, 626, 636, 641], "probabilisticactor": [241, 283, 284, 285, 349, 350, 352, 357, 358, 364, 368, 369, 370, 371, 372, 373, 599, 620, 622, 626, 635, 636], "tanhnorm": [241, 283, 284, 285, 342, 347, 349, 350, 352, 364, 368, 369, 370, 371, 372, 373, 468, 599, 622, 636, 641], "reward_kl": 241, "apply_": 241, "copy_": [241, 620], "mogymwrapp": 242, "mo_env": 242, "sea": 242, "treasur": 242, "so_env": 242, "module_factori": 243, "At": [243, 267, 301, 317, 621, 622, 623, 628, 634, 637, 638], "observation_spec_transform": 243, "done_spec_transform": 243, "reward_spec_transform": 243, "state_spec_transform": 243, "action_spec_transform": 243, "stack_reward": [244, 503], "stack_observ": [244, 503], "auto_batch_size_": 244, "macro": [244, 341], "trial": 245, "standard_norm": [246, 257, 279, 280, 506, 516, 620, 621, 623], "affin": [246, 257, 279, 280], "recover": 246, "set_default_tensor_typ": 246, "doubletensor": 246, "isclos": 246, "rubric": [246, 326, 332, 337, 347, 376, 378, 380, 384], "init_stat": [246, 620, 621, 622, 623], "3752e": 246, "5087e": 246, "9294e": 246, "9636": 246, "5608": 246, "6408": 246, "num_it": [246, 621, 622], "reduce_dim": [246, 620, 621, 622, 623], "cat_dim": [246, 620, 621, 622, 623], "keep_dim": [246, 341, 621, 623], "statist": [246, 279, 280, 324, 333, 370, 420, 421, 564, 620, 621, 622, 642], "gaussian": [246, 265, 286, 311, 622, 624, 635], "empir": [246, 342, 345, 620, 622, 636], "3d": 246, "reorder": 248, "in_keys_in": [248, 274], "channel": [248, 268, 308, 309, 621], "r3m": [250, 509, 638], "resnet": [250, 275, 277], "visual": [250, 275, 277, 393, 617, 622, 635, 637], "embed": [250, 275, 276, 277, 283, 284, 285, 290, 315, 322, 340, 344, 345, 638], "ego4d": [250, 275, 277], "univers": [250, 275, 277, 332, 625], "suraj": [250, 275], "nair": [250, 275], "aravind": [250, 275], "rajeswaran": [250, 275], "vikash": [250, 275, 277], "kumar": [250, 275, 277], "chelsea": [250, 275], "finn": [250, 275], "abhinav": [250, 275], "gupta": [250, 275], "2203": [250, 275, 638], "12601": [250, 275, 638], "_init": [250, 275, 620], "resnet50": [250, 277, 638], "model_nam": [250, 275, 277, 324, 333, 334, 396, 509, 613], "resnet34": 250, "resnet18": [250, 509], "r3m_vec": [250, 638], "stack_imag": [250, 277], "tread": [250, 277], "hub": [250, 277, 625], "resnet50_weight": [250, 277], "imagenet1k_v1": [250, 277], "download_path": [250, 277], "tensor_pixels_kei": [250, 277], "sub_seq_len": 251, "sample_dim": [251, 620], "hesit": 251, "improp": 251, "dummyenv": 252, "another_oth": 252, "other_reward": 252, "create_copi": 253, "stuff": [253, 628], "newnam": 253, "gamma": [255, 349, 350, 352, 353, 354, 356, 358, 359, 360, 362, 364, 366, 368, 369, 370, 371, 372, 373, 374, 376, 378, 380, 384, 386, 387, 388, 389, 420, 472, 504, 514, 560, 606, 620, 621, 622, 635, 636, 641], "r2g": 255, "99": [255, 279, 362, 420, 504, 514, 537, 538, 546, 549, 560, 606, 620, 621, 622, 624, 627, 630, 635, 636, 641], "reward_to_go": 255, "bernoulli_": 255, "9010": 255, "9404": 255, "9701": 255, "9900": 255, "0000": [255, 266, 267, 301, 348], "clamp_min": [256, 515], "clamp_max": [256, 515], "clip_min": 256, "clip_max": 256, "episode_": 258, "reward1": 258, "reward2": 258, "episode_reward": [258, 635, 636], "keep_reward": 259, "keep_don": 259, "logical_or": 260, "in_key_inv": 262, "unstack": 262, "update_don": [263, 522], "disjunct": 263, "recognis": 263, "target_return": [264, 523], "default_valu": 265, "expand_spec": 265, "single_default_valu": 265, "call_before_env_reset": 265, "unit": [265, 299, 308, 309, 315, 316, 622], "scala": 265, "mykei": 265, "__unless": 265, "exists__": 265, "get_primers_from_modul": [265, 287, 302, 304], "recurrent_st": [265, 302, 304, 623], "10th": 266, "0216": 266, "1149": 266, "1990": 266, "2749": 266, "3281": 266, "9290": 266, "3702": 266, "8978": 266, "time_kei": [267, 526], "elaps": [267, 629], "monitor": [267, 324, 326, 332, 337, 351, 368, 418, 420, 566, 625], "expend": 267, "_polici": 267, "time_reset": 267, "time_polici": 267, "time_step": [267, 341], "0882": 267, "0002": 267, "5797e": 267, "6289e": 267, "7990e": 267, "0824e": 267, "0837e": 267, "6056e": 267, "2016e": 267, "1062e": 267, "7009e": 267, "from_int": [268, 527], "shape_toler": [268, 527], "ri": 268, "traj_count": [270, 529], "traj": 270, "countingenv": 270, "make_env_c0": 270, "make_env_c1": 270, "smoothli": 272, "add_1": 272, "cache_spec": [272, 442], "shown": [272, 592, 624, 632, 634, 635, 636, 639], "inv_fn": 273, "unari": 273, "durin": 273, "ommit": 273, "observation_trsf": 273, "xbc": 273, "x7f": 273, "x859": 273, "x81": 273, "x9a": 273, "xbd": 273, "xb8t8": 273, "test_output_spec": 273, "danger": 274, "vc1": [275, 533], "vc1_vec": 275, "untrain": 275, "make_noload_model": 275, "naiv": [275, 625], "vip": [276, 277, 534, 535, 638], "implicit": [277, 357, 364, 586, 639], "jason": 277, "ma": 277, "shagun": 277, "sodhani": 277, "dinesh": 277, "jayaraman": 277, "osbert": 277, "bastani": 277, "ami": 277, "zhang": 277, "vip_vec": 277, "final_nam": 278, "sb3": 278, "terminal_obs_read": 278, "vecnormv2": [279, 538], "new_api": [279, 280], "to_observation_norm": [279, 280], "frozen_copi": [279, 280], "shared_td": 279, "race": [279, 575], "decai": [279, 280, 286, 301, 413, 537, 538, 620, 621, 623, 642], "underflow": [279, 413], "build_td_for_shared_vecnorm": 279, "memmori": 279, "td_share": 279, "unfreez": [279, 280], "train_env": 279, "eval_env": 279, "9999": 280, "shared_data": 280, "reduce_batch_dim": 280, "varianc": [280, 303, 307, 320, 321, 368, 620, 622, 636], "weigh": 280, "_cast_int_to_float": 280, "env_trsf": 280, "observation_norm": 280, "reward_norm": [280, 413], "unnorm": [280, 306, 310], "7967": 280, "1238": 280, "5911": 280, "5275": 280, "8585": 280, "5028": 280, "2505": 280, "3169": [280, 348], "1332": 280, "1235": 280, "6596e": 280, "3072e": 280, "9170e": 280, "9255e": 280, "9131e": 280, "4671e": 280, "3760e": 280, "2058e": 280, "3484e": 280, "6185e": 280, "1456": 280, "1862": 280, "2053": 280, "2605": 280, "4046": 280, "5185": 280, "8023": 280, "1364": 280, "6183": 280, "5406": 280, "0920": 280, "1492": 280, "2702": 280, "3917": 280, "5001": 280, "7947": 280, "0160": 280, "3347": 280, "9082": 280, "9679": 280, "2199": 280, "2918": 280, "1668": 280, "2083": 280, "4981": 280, "5046": 280, "7950": 280, "9791": 280, "1484": 280, "4182": 280, "2201": 280, "0403": 280, "5206": 280, "7791": 280, "8282": 280, "2279": 280, "2907": 280, "4929": 280, "7793": 280, "8626": 280, "1832": 280, "local_env": 280, "testifi": 280, "4307": 280, "9613": 280, "state_dim": [281, 289, 294, 308, 311, 315, 316], "action_dim": [281, 289, 290, 292, 294, 311, 316, 620, 634], "gsde": [281, 369, 564], "gsdemodul": 281, "module_nam": [282, 366, 376, 378, 380, 384], "from_vers": 282, "to_vers": 282, "class_method": 282, "intersect": 282, "import_modul": 282, "get_class_that_defined_method": 282, "module_set": 282, "setters_dict": 282, "pyver": 282, "setter": [282, 286], "setter_dict": 282, "actorvalueoper": [283, 351, 365, 368, 599, 626], "get_policy_oper": [283, 284, 285, 351, 365, 368], "standalon": [283, 284, 285, 624, 626], "tdmodul": [283, 284, 285, 560], "get_critic_oper": 283, "common_oper": [283, 285], "policy_oper": [283, 284, 285], "value_oper": [283, 284, 285], "valueoper": [283, 284, 285, 349, 350, 351, 352, 353, 358, 364, 365, 368, 369, 370, 371, 372, 373, 470, 560, 599, 606, 620, 622, 627], "module_hidden": [283, 285], "td_module_hidden": [283, 285], "safemodul": [283, 285, 345, 349, 350, 352, 357, 358, 364, 368, 369, 370, 371, 372, 373, 555, 556, 560, 599, 641], "module_act": [283, 285], "td_module_act": [283, 284, 285], "module_valu": [283, 284, 285], "td_module_valu": [283, 284, 285], "state_action_valu": [283, 322, 350, 352, 357, 364, 371, 560, 620, 635, 641], "td_modul": [283, 284, 285, 322, 340, 342, 344, 345, 347, 626, 641], "td_clone": [283, 284, 285], "tensordictmodulewrapp": [283, 555, 556, 560], "get_policy_head": [283, 284, 285], "head": [283, 285, 345, 351, 365, 368], "get_value_head": [283, 284, 285], "get_value_oper": [283, 284, 285, 351, 365, 368], "action_modul": 284, "actorcriticoper": [285, 599, 626], "actorcriticwrapp": [285, 599, 620], "po": 286, "sigma_init": [286, 635], "sigma_end": [286, 635], "annealing_num_step": [286, 301, 312, 620, 621, 623, 624, 626, 630, 635], "sigma": [286, 303, 312, 320, 321, 384, 622, 635], "omiss": [286, 301, 312], "consistentdropout": 287, "input_shap": 287, "batcht": 287, "make_tensordict_prim": [287, 302, 304, 623], "input_dtyp": 287, "get_default_dtyp": [287, 413], "mask_6127171760": 287, "seq": [287, 302, 304, 326, 332, 337, 341, 376, 378, 380, 384, 623, 624, 630, 634], "env0": [287, 642], "elu": [288, 290, 291, 292, 293, 299, 300, 621, 641], "activation_kwarg": [288, 305, 464, 465], "norm_class": [288, 290, 291, 305, 464, 465], "norm_kwarg": [288, 305, 464, 465], "bias_last_lay": [288, 290, 291, 292, 293, 300, 305, 464, 465], "aggregator_class": [288, 290, 291, 464, 621, 623, 641], "squashdim": [288, 290, 300, 599, 641], "aggregator_kwarg": [288, 290, 291, 464, 621, 623], "squeeze_output": [288, 290, 291, 464, 621, 623], "lazyconv2d": [288, 290, 291, 300, 309], "cell": [288, 302, 304, 305, 622, 624, 625, 626, 627, 628, 629, 630], "cnet": 288, "34": [288, 305, 368], "35": [288, 305, 633], "default_atari_dqn": [288, 624], "semin": 288, "transformer_config": [289, 311], "decision_transform": [289, 311], "decisiontransform": [289, 311, 599], "dtconfig": [289, 294, 311], "2202": [289, 294, 367], "05607": [289, 294, 367], "return_to_go": [289, 294, 311], "conv_net_kwarg": [290, 291], "mlp_net_kwarg": [290, 291, 292], "use_avg_pool": [290, 291], "WITH": [290, 291, 292, 293, 312], "1509": [290, 291, 292, 293, 312, 354], "02971": [290, 291, 292, 293, 312], "maximis": [290, 292, 621, 622, 636], "ndims_in": [290, 338], "avgpool": [290, 291], "lazylinear": [290, 291, 292, 293, 300, 305, 308, 316, 622, 626, 637, 638], "2304": 290, "adaptiveavgpool2d": [291, 621, 623], "output_s": [291, 621, 623], "squeeze2dlay": 291, "400": [292, 293, 636], "mlp_net_kwargs_net1": 293, "mlp_net_kwargs_net2": 293, "mlp1": 293, "mlp2": 293, "desdescrib": 294, "n_embd": 294, "n_layer": 294, "n_head": 294, "n_inner": 294, "n_posit": 294, "resid_pdrop": 294, "attn_pdrop": 294, "gpt2config": 294, "atol": [295, 319], "rtol": [295, 319], "batch_shap": [295, 310, 319], "event_shap": [295, 319], "absolut": [295, 319, 620], "_instanc": 295, "densiti": [295, 306, 310, 321], "mass": [295, 306, 310, 321, 637], "rsampl": [295, 310, 345], "sample_shap": [295, 306, 310], "softmax": [296, 297, 298, 310], "qvaluemodul": [297, 313, 623, 624, 626, 630], "distributionaldqnnet": [297, 599], "make_log_softmax": 297, "character": [297, 313, 340, 342, 344, 639], "overflow": [297, 298, 313, 314, 320, 340, 342, 344, 345], "var_num": [297, 298, 314], "mult": [297, 298, 313, 314], "action_value_kei": [297, 298, 313, 314, 352, 366, 376, 378, 380, 384], "action_mask_kei": [297, 298, 301, 313, 314], "nbin": 297, "log_softmax": 297, "qvalue_actor": [297, 313], "greedi": [298, 301, 314, 326, 332, 337, 599, 621, 623, 624, 626], "1707": [298, 359, 368], "06887": [298, 359], "my_action_valu": [298, 314], "chanc": 298, "std_bia": 299, "std_min_val": 299, "belief": [299, 308, 315, 316, 317], "1912": [299, 360, 361, 362], "01603": [299, 360, 361, 362], "softplu": [299, 307], "out_features_valu": 300, "cnn_kwarg": [300, 621], "mlp_kwarg": [300, 621], "duel": [300, 599], "cnn": [300, 621, 624, 626, 641], "06581": 300, "eps_init": [301, 312, 621, 623, 624, 626, 630], "eps_end": [301, 312, 621], "explorative_polici": [301, 312], "9055": 301, "9277": 301, "6295": 301, "2532": 301, "grad_fn": [301, 340, 345], "addbackward0": 301, "embedd": [302, 304], "grucel": [302, 344], "python_bas": [302, 304], "custom_kei": [302, 304], "hasn": [302, 304], "set_recurrent_mod": [302, 304, 623], "recurrent_mod": [302, 304], "rnn": [302, 304, 315, 358, 371, 386, 623, 624, 626], "rs": [302, 620], "gru_module_train": 302, "policy_train": [302, 384], "traj_td": 302, "make_cudnn_bas": [302, 304], "make_python_bas": [302, 304, 624], "supplementari": [302, 304, 622, 642], "That": [302, 304, 622, 635], "dealt": [302, 304], "poorli": [302, 304], "meth": [302, 304, 366, 637], "lstmmodul": [302, 599, 623, 624], "data_collector": [302, 304, 621], "upscal": [303, 320, 321], "tanh_loc": [303, 320, 321], "event_dim": [303, 319, 320], "poor": [303, 320, 321], "explos": [303, 320, 321], "full_lik": [303, 320], "fill_valu": [303, 320], "lstmcell": [304, 624], "b_ih": 304, "b_hh": 304, "recurrent_state_h": 304, "recurrent_state_c": 304, "triplet": [304, 313, 314], "lstm_modul": 304, "rs_h": 304, "rs_c": 304, "single_bias_last_lay": [305, 465], "layer_class": [305, 465], "layer_kwarg": [305, 465], "perceptron": [305, 465, 626], "noisylinear": [305, 621], "noisylazylinear": 305, "neg_inf": 306, "inf": 306, "use_cross_entropi": 306, "api_doc": 306, "tf_agent": 306, "sparse_mask": 306, "cross_entropi": 306, "1203": 306, "0928": 306, "0831": 306, "1972": 306, "entropi": [306, 310, 349, 350, 351, 352, 357, 358, 364, 365, 367, 368, 369, 371, 372, 373, 376, 377, 379, 380, 381, 382, 420, 421, 636], "scale_map": [307, 468], "biased_softplus_1": [307, 468], "scale_lb": [307, 315, 316, 468], "normal_param": 307, "latent_dim": 308, "1803": [308, 309], "10122": [308, 309], "rnn_hidden_dim": [308, 315, 316], "rnn_hidden": 308, "in_channel": 309, "latent": [309, 317], "grad_method": 310, "reparamgradientstrategi": [310, 599], "passthrough": 310, "relaxedonehot": 310, "inres": 311, "mu": [311, 312, 622], "ornstein": [312, 599, 620, 624], "uhlenbeck": [312, 599, 620, 624], "ou": [312, 620], "noise_t": 312, "noise_": 312, "theta": [312, 622, 637], "sigma_t": 312, "sigma_": 312, "ou_prev_nois": 312, "ou_step": 312, "x0": 312, "sigma_min": 312, "n_steps_ann": 312, "is_init_kei": 312, "_ou_prev_nois": 312, "_ou_step": 312, "tensordict_modul": [313, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 357, 358, 364, 368, 369, 370, 371, 372, 373], "chose": 314, "hidden_dim": [315, 316], "obs_embed_dim": 315, "posterior": [315, 317, 361], "rssm": [315, 316, 317, 361], "1811": [315, 316, 317], "04551": [315, 316, 317], "obs_embed": 315, "posterior_mean": 315, "posterior_std": 315, "dream": 316, "prior_mean": 316, "prior_std": 316, "rssm_prior": 317, "rssm_posterior": 317, "use_scan": 317, "_higher_order_op": 317, "characterist": [317, 592, 620, 637], "compile_step": 317, "compile_backend": 317, "inductor": 317, "compile_mod": 317, "s_": [317, 592, 632], "s_t": 317, "a_t": 317, "b_t": 317, "a_": 317, "evid": 317, "o_t": 317, "b_": 317, "o_": 317, "amend": 317, "safe_tanh": 320, "tanhtransform": 320, "get_mod": [320, 345], "custommodul": 322, "imaginari": 323, "transition_model": 323, "reward_model": 323, "get_reward_oper": 323, "get_transition_model_oper": 323, "engine_arg": 324, "asyncenginearg": [324, 333], "num_replica": [324, 333, 337, 580, 587, 592], "actor_class": 324, "enable_prefix_cach": 324, "replica": [324, 333, 337, 587], "placement": 324, "samplingparam": 324, "num_devic": [324, 333, 334], "max_model_len": 324, "4096": 324, "sampling_param": [324, 333], "temperatur": [324, 326, 332, 337, 350, 357, 364], "max_token": [324, 326, 332, 337], "tensor_parallel_s": [324, 333], "actor_index": 324, "fault": 324, "resili": 324, "collective_rpc": [324, 583], "create_load_balanc": 324, "kv": 324, "loadbalanc": 324, "rout": 324, "smart": 324, "lb": 324, "selected_actor_index": 324, "select_actor": 324, "prefix_length": 324, "overload_threshold": 324, "enable_fp32_output": [324, 333, 334], "fp32": [324, 333, 334], "prompt_token_id": 324, "use_tqdm": 324, "lora_request": 324, "prompt_adapter_request": 324, "guided_options_request": 324, "timeout_second": 324, "requestoutput": 324, "tokensprompt": 324, "lora": 324, "get_cache_usag": 324, "fraction": [324, 349, 351, 368], "get_master_address": 324, "get_master_port": 324, "get_num_unfinished_request": 324, "unfinish": 324, "get_random_actor_index": 324, "init_weight_update_group": 324, "asyncvllmengineservic": 324, "asyncllmengin": 324, "parameter_nam": 324, "to_text": [325, 331], "to_token": [325, 330], "logprob": [326, 332, 337, 633], "input_kei": [326, 332, 337, 633], "attention_mask_kei": [326, 332, 337], "generate_kwarg": [326, 329, 332, 337, 633], "max_new_token": [326, 329, 332, 337, 633], "num_return_sequ": [326, 332, 337], "top_p": [326, 332, 337], "nucleu": [326, 332, 337], "top_k": [326, 332, 337], "repetition_penalti": [326, 332, 337], "do_sampl": [326, 332, 337], "num_beam": [326, 332, 337], "beam": [326, 332, 337], "length_penalti": [326, 332, 337], "early_stop": [326, 332, 337], "stop_sequ": [326, 332, 337], "win": 326, "pad_model_input": [326, 332, 337], "num_sampl": [326, 329, 332, 337], "tokens_kei": [326, 329, 332, 337], "masks_kei": [326, 329, 332, 337], "ref_batch": [326, 332, 337], "min_batch_s": [326, 332, 337], "max_batch_s": [326, 332, 337], "batching_timeout": [326, 332, 337], "ref_transformers_wrapp": [326, 337], "ref_vllm_wrapp": [326, 332], "cleanup_batch": [326, 329, 332, 337], "flush": [326, 332, 337], "cancel": [326, 332, 337], "pend": [326, 332, 337, 573], "_batch_queu": [326, 332, 337], "tensordict_out": [326, 332, 337, 642], "logits_onli": [326, 332, 337], "get_batching_st": [326, 329, 332, 337], "logits_kei": [326, 332, 337], "llmmaskedcategor": 326, "alter": [326, 329, 332, 337, 341, 366], "is_tdmodule_compat": [326, 332, 337, 376, 378, 380, 384], "weak": [326, 332, 337], "reset_out_kei": [326, 332, 337, 376, 378, 380, 384], "select_out_kei": [326, 332, 337, 349, 350, 352, 353, 357, 358, 364, 368, 369, 371, 372, 373, 376, 378, 380, 384, 624], "reset_parameters_recurs": [326, 332, 337, 366, 376, 378, 380, 384], "old_param": [326, 332, 337], "bork": [326, 332, 337], "dork": [326, 332, 337], "reset_paramet": [326, 332, 337], "complic": [326, 332, 337, 376, 378, 380, 384, 637, 639, 642], "out_keys_sourc": [326, 332, 337, 376, 378, 380, 384], "z": [326, 332, 337, 376, 378, 380, 384], "all_attention_mask": [328, 332, 337, 633], "all_assistant_mask": [328, 332, 337, 633], "validate_model": 329, "automodelforcausallm": [329, 332, 633], "remote_wrapp": 329, "tensordict_input": 329, "dist_params_kei": 329, "dist_sample_kei": 329, "get_dist_with_prompt_mask": [329, 337], "to_histori": [330, 331], "wast": 332, "simpler": [332, 581, 621, 625, 633], "unsur": 332, "overlong": 332, "tokenization_util": [332, 337], "output_scor": 332, "discourag": [332, 337, 622, 637], "pad_token_id": 332, "bad_words_id": 332, "force_words_id": 332, "no_repeat_ngram_s": 332, "gram": 332, "encoder_repetition_penalti": 332, "repetit": [332, 622, 625, 628], "num_beam_group": 332, "diversity_penalti": 332, "return_dict_in_gener": 332, "ref_categorical_sequenti": [332, 337], "repeat_interleave_caus": 332, "sequence_length": 332, "_create_block_diagonal_attention_mask": 332, "causal": 332, "data_parallel_s": 333, "pipeline_parallel_s": 333, "_model": [333, 334], "make_ray_work": 334, "enforce_eag": 334, "rayllmwork": 334, "localllmwrapp": 334, "world_siz": [335, 336, 580, 587], "statelessprocessgroup": [335, 336], "plane": [335, 336], "pyncclcommun": [335, 336], "async_engin": 337, "presence_penalti": 337, "frequency_penalti": 337, "ignore_eo": 337, "prompt_logprob": 337, "detoken": 337, "include_stop_str_in_output": 337, "spaces_between_special_token": 337, "sampling_typ": 337, "temperature_last": 337, "top_p_last": 337, "top_k_last": 337, "assistant_mask_kei": 337, "set_token": 337, "additivegaussianmodul": [339, 599, 626, 635], "_spec": 339, "translat": [340, 342], "3635": 340, "0340": 340, "1476": 340, "3911": 340, "1664": 340, "5455": 340, "2247": 340, "4583": 340, "2916": 340, "2160": 340, "5337": 340, "5193": 340, "addmmbackward0": 340, "lookahead": 341, "window": [341, 635, 639, 641], "n_action": [341, 350, 352, 354, 356, 367, 369, 371], "reshape_cat": 341, "actor_bas": 341, "obs_cat": 341, "obs_cat_reshap": 341, "action_orig": 341, "multistepenvwrapp": 341, "ego": 341, "default_interaction_typ": [342, 345, 626], "interaction_typ": [342, 345], "set_interaction_typ": [342, 345], "compositedistribut": [342, 345, 349, 368, 626], "distribution_map": [342, 345], "name_map": [342, 345], "distribution_kwarg": [342, 345, 622, 635, 636], "cache_dist": [342, 345], "n_empirical_estim": [342, 345], "compound": [342, 626], "cube": 343, "functionalmodul": 344, "functionalmodulewithbuff": 344, "td_fmodul": 344, "td_function": 344, "td_state": 344, "params_repeat": 344, "td_vmap": [344, 347], "random_sampl": [344, 345], "suppli": 345, "paliat": 345, "get_median": 345, "get_mean": 345, "sample_key_nam": 345, "_log_prob": 345, "composite_lp_aggreg": 345, "induc": 345, "clampbackward0": 345, "anihil": 345, "probabilistictensordictsequenti": [346, 349, 350, 351, 352, 355, 357, 358, 364, 365, 367, 368, 370, 371, 555, 556, 641], "partial_toler": [346, 347, 634], "AND": [346, 347, 352], "tensordictsequ": 347, "safeprobabilisticmodul": 347, "spec1": 347, "net1": 347, "module1": 347, "td_module1": 347, "spec2": 347, "module2": 347, "td_module2": 347, "9944": 348, "9991": 348, "3020": 348, "2299": 348, "5418": 348, "2989": 348, "6849": 348, "2690": 348, "9649": 348, "5686": 348, "8602": 348, "0315": 348, "8455": 348, "6027": 348, "4746": 348, "7843": 348, "7782": 348, "2111": 348, "5115": 348, "4687": 348, "5760": 348, "1602": 349, "01783v2": 349, "entropy_bonu": [349, 351, 365, 368, 380, 472, 622], "favour": [349, 351, 365, 368, 380], "samples_mc_entropi": [349, 351, 365, 367, 368, 380, 472], "entropy_coeff": [349, 351, 365, 368, 380, 472], "critic_coeff": [349, 351, 365, 368, 472], "loss_critic_typ": [349, 351, 365, 368, 370, 472, 622], "l1": [349, 351, 353, 354, 358, 365, 368, 369, 370, 372, 373, 620], "l2": [349, 351, 353, 354, 355, 356, 358, 361, 362, 365, 368, 369, 370, 372, 373, 620, 635], "smooth_l1": [349, 350, 351, 352, 353, 354, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 472, 622], "separate_loss": [349, 351, 352, 353, 357, 358, 364, 365, 368, 369, 370, 371, 372, 373, 472], "advantage_kei": [349, 351, 365, 368, 370, 380, 383, 386, 387, 388, 389, 472], "value_target_kei": [349, 351, 365, 368, 370, 386, 387, 388, 389, 472], "value_target": [349, 351, 365, 368, 370, 386, 387, 388, 389, 622, 636], "ddp": [349, 351, 365, 368, 370], "fsdp": [349, 351, 365, 368, 370], "divid": [349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 380, 553, 620, 635, 636, 637], "clip_valu": [349, 351, 365, 368, 370, 380, 472], "loss_crit": [349, 368, 622, 636], "loss_entropi": [349, 368, 377, 379, 381, 382, 622, 636], "loss_object": [349, 368, 377, 379, 381, 382, 622, 636], "recur": [349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 386, 387, 388, 389, 390, 626], "next_reward": [349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 386, 387, 388, 389], "next_don": [349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 386, 387, 388, 389], "next_termin": [349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 386, 387, 388, 389], "loss_obj": 349, "next_observ": [349, 350, 352, 353, 354, 356, 357, 358, 364, 368, 369, 370, 371, 372, 373, 634], "sacloss": [349, 415, 421, 606], "default_kei": [349, 350, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 373, 384, 390], "_acceptedkei": [349, 350, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 390], "make_value_estim": [349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 374, 376, 378, 380, 384, 620, 621, 635, 636, 641], "value_typ": [349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 620], "hyperparam": [349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 620], "enum": [349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 620], "default_value_estim": [349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 620, 641], "default_value_kwarg": [349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 620], "dqn_loss": [349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 374, 376, 378, 380, 384], "td1": [349, 350, 352, 353, 354, 356, 358, 359, 360, 364, 366, 368, 369, 370, 371, 372, 373, 376, 378, 380, 384, 620], "cql": [350, 356], "conserv": [350, 356], "qvalue_network": [350, 352, 357, 358, 364, 369, 371, 372, 373, 415, 421], "unti": [350, 352, 364, 369, 371, 372, 373], "loss_funct": [350, 352, 353, 354, 355, 356, 357, 358, 364, 369, 371, 372, 373, 384, 620, 635], "alpha_init": [350, 352, 358, 367, 369, 371], "min_alpha": [350, 352, 358, 367, 369, 371], "max_alpha": [350, 352, 358, 367, 369, 371], "fixed_alpha": [350, 352, 358, 367, 369, 371], "target_entropi": [350, 352, 358, 367, 369, 371], "prod": [350, 352, 367, 369, 371], "delay_actor": [350, 353, 371, 372, 373], "delay_qvalu": [350, 358, 369, 371, 372, 373], "min_q_weight": 350, "max_q_backup": 350, "backup": 350, "deterministic_backup": 350, "num_random": 350, "with_lagrang": 350, "lagrang": 350, "lagrange_thresh": 350, "deactivate_vmap": [350, 352, 358, 364, 369, 371, 372, 373, 386, 387, 388, 389], "valueclass": [350, 352, 353, 358, 369, 371, 372, 373], "qvalu": [350, 352, 357, 358, 364, 369, 371, 372, 373], "loss_actor": [350, 352, 353, 357, 358, 364, 369, 370, 371, 372, 373, 411, 620, 635], "loss_actor_bc": 350, "loss_alpha": [350, 352, 358, 369, 371], "loss_cql": [350, 356], "loss_qvalu": [350, 352, 356, 357, 358, 364, 369, 371, 372, 373], "loss_alpha_prim": 350, "ess": [351, 368, 376, 377, 379, 380, 381, 382], "coupl": [351, 368, 585, 623, 626, 627, 637, 639], "clip_epsilon": [351, 380, 622, 636], "head_nam": [351, 365, 368], "ppo_entropy_coeffici": [351, 365, 368], "normalize_advantag": [351, 365, 368, 472, 636], "normalize_advantage_exclude_dim": [351, 365, 368, 472], "multiobject": [351, 365, 368], "value_kei": [351, 365, 368, 386, 387, 388, 389, 472, 620], "somemodul": [351, 365, 368], "actor_head": [351, 365, 368], "someactor": [351, 365, 368], "value_head": [351, 365, 368], "somevalu": [351, 365, 368], "crossq": 352, "IN": 352, "FOR": 352, "simplic": [352, 621, 622, 628, 638, 639, 641], "openreview": [352, 369], "pczqttstix": 352, "qvalue_loss": [352, 372], "actor_loss": [352, 372], "alpha_loss": [352, 358, 371], "num_qvalue_net": [352, 357, 358, 364, 369, 371, 372, 373], "maybe_init_target_entropi": 352, "fault_toler": 352, "target_entropy_buff": 352, "delay_valu": [353, 354, 356, 359, 370, 371, 621, 623, 624, 630, 635], "loss_valu": [353, 357, 364, 370, 371, 620, 622, 635, 636], "pred_valu": [353, 356, 372, 373, 620], "pred_value_max": [353, 620], "target_valu": [353, 356, 369, 372, 373, 620], "target_value_max": [353, 620], "qvalueactor": [354, 356, 621, 623], "double_dqn": 354, "06461": 354, "mult_one_hot": [354, 357, 358], "loss_val": [354, 356, 384, 606, 620, 622, 623, 624, 627, 628, 630, 635, 636, 639], "01345": 355, "distanc": [356, 365, 386, 636], "dcql_loss": 356, "iql": [357, 364, 620, 635, 636], "2110": [357, 364], "06169": [357, 364], "expectil": [357, 364], "tau": [357, 364, 620, 621, 635], "antmaz": [357, 364], "sticht": [357, 364], "onehotcategor": [357, 358, 599], "target_entropy_weight": 358, "skip_done_st": [358, 371], "disctount": 359, "distributionalqvalueactor": 359, "input_tensordict": [359, 620], "actor_model": 360, "imagination_horizon": 360, "unrol": 360, "discount_loss": [360, 362], "lambda_kl": 361, "lambda_reco": 361, "lambda_reward": 361, "reco_loss": 361, "reward_loss": 361, "free_nat": 361, "nat": 361, "delayed_clamp": 361, "global_averag": 361, "value_loss": 362, "fake_data": 362, "gail": 363, "1606": 363, "03476": 363, "discriminator_network": 363, "use_grad_penalti": 363, "gp_lambda": 363, "discrimin": 363, "qvalueclass": 364, "loss_value_diff": 364, "diff": 364, "old_polici": 365, "new_polici": 365, "apart": [365, 636], "dtarg": 365, "samples_mc_kl": 365, "analyt": 365, "decrement": 365, "loss_": [366, 411, 606, 620, 627], "equip": [366, 623, 624, 626], "gh": 366, "_forward_value_estimator_kei": 366, "value_estim": [366, 376, 378, 380, 384, 386, 387, 388, 389, 390, 620, 636], "myloss": 366, "action2": 366, "augment": [366, 592, 628, 630, 639], "set_exploration_typ": [366, 410, 622, 623, 624, 626, 635, 641], "deterministic_sampling_mod": 366, "convert_to_funct": [366, 376, 378, 380, 384, 620], "expand_dim": [366, 376, 378, 380, 384], "create_target_param": [366, 376, 378, 380, 384, 620], "compare_against": [366, 376, 378, 380, 384, 620], "isol": [366, 376, 378, 380, 384, 402, 404, 587, 590, 624], "_param": [366, 376, 378, 380, 384], "resampl": [366, 376, 378, 380, 384], "_target_param": [366, 376, 378, 380, 384], "from_stateful_net": [366, 376, 378, 380, 384], "network_nam": [366, 376, 378, 380, 384], "stateful_net": [366, 376, 378, 380, 384], "get_stateful_net": [366, 376, 378, 380, 384], "Such": [366, 376, 378, 380, 384], "blend": [366, 376, 378, 380, 384], "vmap_random": [366, 375, 376, 378, 380, 384], "add_random_modul": [366, 376, 378, 380, 384, 606], "proxim": [368, 420, 473, 622, 636], "flavor": [368, 620, 635, 636, 641], "clipppoloss": [368, 606, 622, 636], "klpenppoloss": [368, 606], "06347": 368, "log_explained_vari": [368, 472], "explain": [368, 624, 638], "explained_vari": 368, "wors": 368, "gae": [368, 420, 473, 606, 620, 622, 636], "ppo_loss": 368, "tdlambda": [368, 620], "base_lay": 368, "action_log_prob": 368, "randn_lik": 368, "kl_approx": [368, 377, 379, 381, 382], "samplelogprob": 368, "gripper": 368, "composite_entropi": 368, "0234": 368, "set_composite_lp_aggreg": [368, 636], "redq": 369, "ay8zfzm0tdd": 369, "sub_sample_len": 369, "subsampl": [369, 406], "action_log_prob_actor": 369, "state_action_value_actor": [369, 372, 373], "connectionist": 370, "william": 370, "1992": 370, "doi": 370, "1007": 370, "bf00992696": 370, "actor_net": [370, 620, 622], "1801": 371, "01290": 371, "1812": 371, "05905": 371, "minimalist": 372, "06860": 372, "policy_nois": [372, 373], "noise_clip": [372, 373], "td3_bc": 372, "bc_loss": 372, "lmbd": 372, "next_state_valu": [372, 373], "td0": [374, 620, 635], "cispo": 376, "eps_low": [376, 380], "eps_high": [376, 380], "minimax": 376, "m1": 376, "llmoutputtyp": [376, 378, 380], "output_typ": [376, 378, 380], "cispolossoutput": [376, 590], "tensor_kei": [376, 378, 380, 386, 387, 388, 389, 390], "grpoloss": [376, 378, 590, 592], "my_advantage_kei": [376, 378, 380], "clip_fract": [377, 379, 381, 382], "loss_kl_to_ref": [377, 379, 381, 382, 384, 385], "kl_to_ref": [377, 379, 381, 382, 385], "loss_kl_to_infer": [377, 379, 381, 382], "kl_to_infer": [377, 379, 381, 382], "asymmetr": [378, 380], "eq": [378, 380], "dapolossoutput": [378, 590], "instabl": 380, "diagnost": 380, "masking_strategi": 380, "sft": [380, 384], "surrog": 380, "symmetr": 380, "dapo": [380, 590], "kl_mask_threshold": 380, "pi_theta": 380, "pi_ref": 380, "drift": 380, "token_mean": 380, "prompt_mean": 380, "kl_to_ref_coeff": [380, 384], "kl_to_inference_coeff": 380, "grpolossoutput": [380, 383, 590], "grpo_siz": 383, "hit": 383, "supervis": [384, 627, 628, 639, 642], "normalize_by_seq_length": 384, "minor_sft": 384, "minorsft": 384, "shime": 384, "xie": 384, "hong": 384, "chen": 384, "fred": 384, "yu": 384, "zey": 384, "sun": 384, "xiuyu": 384, "wu": 384, "2024": 384, "minor": [384, 635], "_chat_templ": 384, "policy_ref": 384, "txt_start": 384, "zip": [384, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "loss_sft": [384, 385], "1506": 386, "02438": 386, "exponenti": [386, 387, 388, 389, 413], "lmbda": [386, 389, 420, 620, 622, 636], "average_ga": [386, 622], "skip_exist": [386, 387, 388, 389], "get_default_devic": [386, 387, 388, 389, 390], "time_dim": [386, 388, 389], "auto_reset_env": 386, "next_valu": [386, 387, 388, 389, 390], "gradient_mod": 386, "value_error": [386, 387, 388, 389, 390], "marker": [386, 620], "trajecotri": 386, "fair": 386, "target_param": [386, 387, 388, 389, 390, 620, 636], "98": [386, 387, 388, 389], "94": [386, 389], "unpack": [386, 387, 388, 389], "aka": [387, 621, 635], "average_reward": [387, 388, 389], "tdestim": [387, 388, 390], "infti": 388, "valuefunctionbas": 390, "preproc": [391, 624, 635], "as_non_tensor": [391, 635], "render_method": 391, "pass_tensordict": 391, "syntact": 391, "sugar": 391, "relax": 391, "out_file_bas": 392, "skip_reset": 392, "center_crop": 393, "make_grid": 393, "log_video": 393, "csv": [393, 395, 397, 460, 621, 629, 630], "log_dir": [393, 394, 395, 397, 399, 401, 460, 462, 463, 621, 630], "cheetah_video": 393, "run_video": 393, "sec": [393, 637], "video_fp": [393, 395, 398, 460, 463], "run_video_0": 393, "cur_dir": 395, "csv_log": 395, "add_video": 395, "video_": 395, "experiment_nam": [396, 397], "logger_typ": 397, "logger_nam": 397, "mlflow": [397, 398], "wandb_kwarg": 397, "mlflow_kwarg": 397, "trackio_kwarg": 397, "tracking_uri": 398, "uri": 398, "datastor": 398, "tb_log": [399, 462], "tensoarboard": 399, "td_log": 399, "trackio": 400, "save_dir": [401, 463], "resum": 401, "uncategor": 401, "torchrl_servic": [402, 404], "discoveri": 402, "instantli": 402, "tokenizerclass": [402, 404], "modelclass": 402, "tok": 402, "service_factori": [402, 403, 613], "max_restart": 402, "register_with_opt": [402, 613], "actor_opt": [402, 613], "constructor_kwarg": 402, "readabl": 402, "concern": [402, 580, 592, 627], "model_path": 402, "ongo": [402, 403], "destruct": [402, 403], "init_kwarg": 404, "servicebas": [404, 613], "unsupport": [404, 575], "my_funct": 405, "sub_traj_len": 406, "min_sub_traj_len": 406, "register_op": [406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 417, 419, 621], "process_optim_batch": [406, 412, 413], "td_out": [406, 414], "_process_optim_batch_hook": 406, "batch_subsampl": 406, "clear_cuda": 407, "pre_optim_step": 407, "log_pbar": [408, 409, 410, 413, 621], "count_fram": 408, "pre_steps_log": [408, 409], "count_frames_log": 408, "lognam": 409, "include_std": 409, "log_reward": [409, 420, 421, 621], "r_train": 409, "log_action_norm": 409, "action_norm": 409, "percentag": 409, "log_don": 409, "done_percentag": 409, "record_interv": [410, 620, 621], "record_fram": [410, 553, 620, 621], "policy_explor": [410, 560, 620, 621, 624, 626, 630], "log_kei": [410, 621], "underestim": 410, "r_evalu": [410, 620], "loss_compon": 411, "appl": 411, "optimizer_hook": 411, "flatten_tensordict": [412, 621], "max_dim": 412, "rb_trainer": 412, "batch_process": [412, 413, 414], "post_loss": 412, "999": [413, 542, 543, 544, 547, 548, 552, 621], "jitter": 413, "finfo": 413, "default_dtyp": 413, "update_reward_stat": 413, "normalize_reward": 413, "make_train": 414, "_process_batch_hook": 414, "select_kei": 414, "target_params_updat": 415, "targetnetupdat": [415, 421, 557, 559, 560], "target_net_updat": [415, 421, 560, 620, 621], "softupd": [415, 620, 621, 623, 624, 627, 630, 635], "target_net_updater_hook": 415, "post_optim": [415, 621], "versatil": [416, 625], "optim_steps_per_batch": [416, 420, 421, 473, 621], "clip_grad_norm": [416, 420, 421, 473], "clip_norm": [416, 420, 421, 473], "progress_bar": [416, 420, 421, 473], "save_trainer_interv": [416, 420, 421, 473], "log_interv": [416, 420, 421, 473, 621], "save_trainer_fil": [416, 420, 421, 473], "async_collect": [416, 418, 420, 473], "utd": [416, 418, 620, 623], "utd_ratio": 416, "log_tim": [416, 420, 473], "logtim": [416, 420], "updateweight": [416, 420, 473, 614, 621], "load_from_fil": [416, 420, 421], "update_count": 418, "utdr_hook": 418, "update_weights_interv": [419, 621], "policy_weights_gett": 419, "weight_update_map": [419, 420, 473], "post_step": [419, 621], "num_epoch": [420, 473, 622, 636], "enable_log": [420, 421], "log_act": [420, 421], "log_observ": [420, 421], "add_ga": [420, 473], "ppotrainerconfig": 420, "welcom": [420, 592, 625], "elsewher": 421, "3e": [421, 622, 623, 635, 636], "asynccollectorconfig": 422, "collectorconfig": 423, "storageensemblewrit": 437, "batched_env_typ": 440, "make_batched_env": 440, "make_gym_env": 446, "mogymenv": 450, "meltingpotenv": 451, "openmlenv": 453, "openspielenv": 454, "pettingzooenv": [455, 635], "robohiveenv": 456, "smacv2env": 457, "unity_mlag": 458, "unitymlagentsenv": 458, "activationconfig": [464, 465], "normconfig": 464, "aggregatorconfig": 464, "layerconfig": 465, "valuemodelconfig": 466, "mlpconfig": [468, 469, 470], "eval_mod": 468, "extract_normal_param": 468, "param_kei": 468, "_make_tanh_normal_model": 468, "_make_tensordict_modul": 469, "_make_value_model": 470, "networkconfig": 470, "loss_typ": [471, 472], "_make_ppo_loss": 472, "_make_ppo_train": 473, "sensibl": 473, "batchsizetransform": [478, 624], "binarizereward": 479, "burnintransform": 480, "centercrop": 483, "cliptransform": 484, "conditionalpolicyswitch": 486, "dtypecasttransform": 489, "devicecasttransform": 490, "discreteactionproject": 491, "gym_transform": 493, "endoflifetransform": 493, "exclude_kei": 494, "finitetensordictcheck": 495, "flattenobserv": 496, "frameskiptransform": 497, "linearisereward": 502, "multiact": 503, "rb_transform": 504, "multisteptransform": 504, "noopresetenv": [505, 641, 642], "permutetransform": 507, "pinmemorytransform": 508, "r3mtransform": [509, 638], "crop_siz": 510, "randomcroptensordict": [510, 620], "key_map": 512, "reward2gotransform": 514, "include_kei": 518, "signtransform": 519, "squeezetransform": 520, "targetreturn": 523, "primer_spec": 524, "timemaxpool": 525, "vc1transform": 533, "viprewardtransform": 534, "viptransform": 535, "lambd": 539, "t0": [539, 624, 630], "weight_decai": [539, 540, 541, 542, 543, 544, 546, 547, 548, 549, 551, 620, 621], "foreach": [539, 540, 541, 543, 547, 549, 550, 551], "maxim": [539, 540, 541, 543, 549, 550, 551, 620, 627, 637], "asgd": 539, "rho": 540, "adadelta": 540, "lr_decai": 541, "initial_accumulator_valu": 541, "adagrad": 541, "amsgrad": [542, 543], "fuse": 543, "adamw": 543, "002": [544, 547], "adamax": 544, "max_it": 545, "max_ev": 545, "tolerance_grad": 545, "07": 545, "tolerance_chang": 545, "09": 545, "history_s": 545, "line_search_fn": 545, "lbfg": 545, "lion": 546, "momentum_decai": 547, "004": 547, "nadam": 547, "radam": 548, "momentum": [549, 551], "rmsprop": 549, "eta": 550, "step_siz": 550, "rprop": 550, "dampen": 551, "nesterov": 551, "sgd": 551, "sparseadam": 552, "dictconfig": [553, 554, 555, 556, 558, 559, 560, 561, 564], "unknowingli": 553, "annealing_fram": [553, 620], "init_env_step": [553, 554, 620], "proof_environ": [554, 620], "sta": 554, "ot": 554, "actor_model_explor": [555, 556, 620], "make_env_kwarg": [555, 556], "replayargsconfig": 558, "constitu": 560, "egreedywrapp": 560, "ddpgloss": [560, 606, 620, 627, 635, 641], "env_proof": 560, "obs_spec": 560, "net_valu": 560, "dir": [560, 621], "gettempdir": 560, "transformed_env_constructor": 561, "num_env_per_collector": [562, 563], "_multi_sync": 563, "video_tag": 564, "norm_obs_onli": 564, "custom_env_mak": 564, "custom_env": 564, "return_transformed_env": 564, "action_dim_gsd": 564, "state_dim_gsd": 564, "obs_norm_state_dict": 564, "weights_buff": 565, "ONE": [565, 570, 573, 579], "receive_initial_weight": 565, "interf": 565, "surround": [565, 636], "send_initial_weight": 565, "send_weight": [565, 570, 573, 575, 577, 580, 582], "send_weights_async": [565, 567, 570, 573], "acknowledg": [565, 566, 567, 568, 571, 572, 574, 575, 576, 579, 581, 587], "wait_ack": [565, 567, 570, 573], "setup_connection_and_weights_on_send": [565, 567, 570, 573, 575, 577], "3600": 566, "get_store_info": 566, "hour": 566, "apply_weight": [566, 568, 569, 571, 572, 574, 576, 578, 579, 581, 583, 585, 587], "rendez": [566, 568, 571, 572, 574, 576, 579, 581, 587], "vou": [566, 568, 571, 572, 574, 576, 579, 581, 587], "_setup_connection_and_weights_on_sender_impl": [566, 567, 568, 571, 572, 574, 576, 579, 581, 587], "_setup_connection_and_weights_on_receiver_impl": [566, 568, 571, 572, 574, 576, 579, 581, 587], "create_transport": [566, 568, 569, 571, 572, 574, 576, 579, 581, 587], "_run_process": [566, 568, 569, 571, 572, 574, 576, 579, 581, 587], "prepare_weight": [566, 568, 569, 571, 572, 574, 576, 579, 581, 587], "lookup": [566, 568, 569, 571, 572, 574, 576, 579, 581, 587, 621], "sharedmemweightsyncschem": [566, 568, 569, 571, 572, 574, 579, 581, 587], "receiver_transport": [566, 568, 569, 571, 572, 574, 576, 579, 581, 587], "sender_transport": [566, 568, 569, 571, 572, 574, 576, 579, 581, 587], "shared_transport": [566, 568, 569, 571, 572, 574, 576, 579, 581, 587], "weight_queu": 567, "ack_queu": 567, "listen": [568, 576], "phase": [568, 636, 639], "benefici": 568, "transmiss": [568, 572, 573, 574, 576, 578], "wait_async": [568, 576], "_unique_weight": [568, 576], "_receiver_shared_weight": [568, 576], "worker_rank": [570, 571], "deadlock": 570, "somecollector": 572, "transform_modul": 572, "connection_info_nam": [572, 573, 574], "collis": [572, 574, 635, 636], "remote_actor": [572, 573, 574], "connection_info": 573, "set_model": 573, "_setup_distributed_connection_send": 573, "pure": 575, "register_weight": 575, "params_map": [575, 579], "basecontext": 575, "init_queu": 575, "send_ack": 575, "60": [575, 633, 641], "unique_weight": 575, "_send_instruct": 576, "notifi": 576, "extract_a": 578, "extract_weight": [578, 588], "device_map_fn": 579, "gpus_per_replica": [580, 587, 592], "init_all_workers_group": [580, 585, 586, 587, 592], "check_connect": [580, 582], "mono": 580, "remote_addr": [581, 582], "local_addr": [581, 582], "tmp": 581, "mnt": 581, "nf": 581, "mount": 581, "create_receiv": [581, 583, 587], "vllmdoublebufferweightreceiv": 581, "llm_engin": 581, "model_executor": 581, "create_send": [581, 584, 587], "vllmdoublebufferweightsend": 581, "vllmdoublebuffertransport": 581, "vllmdoublebuffersyncschem": [583, 584, 592], "load_weight": 583, "poll_and_appli": [583, 585], "_update_weights_with_nccl_broadcast_simpl": 583, "180": 583, "register_model": [584, 586, 587, 592], "vllmweightsyncschem": [585, 586, 592], "get_actor": 585, "particip": [585, 587], "torchrpcvllmreceiv": 585, "rpc_sync": 585, "get_metadata": 585, "grpc": 586, "vllmcollectivetransport": [586, 587], "bandwidth": 586, "torchrpcvllmsend": 586, "rpc_async": 586, "prepare_rec": 586, "tp_size": 587, "dp_size": 587, "pp_size": 587, "approxim": [587, 636, 642], "handshak": 587, "12345": 587, "vllmweightsend": 587, "vllmweightreceiv": 587, "init_send": 587, "sender_actor": 587, "init_receiv": 587, "receiver_actor": 587, "llmlossoutput": 590, "cispoloss": 590, "mcadvantag": 590, "sftloss": [590, 592], "sftlossoutput": 590, "topkrewardselector": 590, "sweep": 590, "journei": 591, "textbook": 591, "highlight": [591, 635], "ever": [591, 636], "bump": 591, "pr": [591, 592], "five": [592, 621], "make_polici": 592, "29500": 592, "_weight_send": 592, "training_model": 592, "policy_version_track": 592, "migrat": 592, "ref_servic": 592, "step_data": 592, "gsm8krewardpars": 592, "ifevalscor": 592, "excel": 592, "bsz": 592, "num_token": 592, "predetermin": 592, "hasattr": [592, 620], "text_complet": 592, "sophist": [592, 622, 636], "format_compon": 592, "structure_scor": 592, "think_scor": 592, "answer_scor": 592, "completion_bonu": 592, "potential_answ": 592, "compl": 592, "et": 592, "parseerror": 592, "unnecessari": 592, "\u03b5": 599, "satisfi": 599, "consistentdropoutmodul": 599, "egreedymodul": [599, 621, 623, 624, 626, 630], "ornsteinuhlenbeckprocessmodul": [599, 620, 626], "duelingcnndqnet": [599, 621], "ddpgcnnactor": 599, "ddpgcnnqnet": 599, "ddpgmlpactor": [599, 620], "ddpgmlpqnet": [599, 620], "onlinedtactor": 599, "dtactor": 599, "dreameractor": 599, "obsencod": 599, "obsdecod": 599, "rssmposterior": 599, "rssmprior": 599, "rssmrollout": 599, "independentnorm": 599, "tanhdelta": [599, 620, 635], "truncatednorm": 599, "reusabl": [606, 620, 639], "trainabl": [606, 620, 627, 638], "\u03bb": 606, "customiz": [606, 623], "total_loss": [606, 627], "distributionaldqnloss": [606, 621], "iqlloss": 606, "discreteiqlloss": 606, "cqlloss": 606, "discretecqlloss": 606, "ppoloss": 606, "a2closs": 606, "reinforceloss": 606, "discretesacloss": 606, "td3loss": 606, "redqloss": 606, "crossqloss": 606, "td3bcloss": 606, "gailloss": 606, "dtloss": 606, "onlinedtloss": 606, "dreameractorloss": 606, "dreamermodelloss": 606, "dreamervalueloss": 606, "agnost": [613, 632], "monarch": 613, "anywher": 613, "tenant": 613, "my_namespac": 613, "tokenizerservic": 613, "50000": 613, "my_servic": 613, "myserviceclass": 613, "arg1": 613, "value1": 613, "arg2": 613, "value2": 613, "gpu_servic": 613, "gpuservic": 613, "collid": [613, 624, 636], "register_servic": 613, "shared_token": 613, "use_servic": 613, "worker2": 613, "train_servic": 613, "eval_servic": 613, "30000": 613, "busi": 613, "infrequ": 613, "use_distributed_servic": 613, "queu": 613, "persistentpythonprocess": 613, "_lock": 613, "next_idx": 613, "python_executor_fast": 613, "python_executor_heavi": 613, "fast_env": 613, "heavy_env": 613, "mycustomservic": 613, "param1": 613, "tokenizer_servic": 613, "servicecontext": 613, "__enter__": 613, "__exit__": 613, "myservic": 613, "stick": [613, 624], "distributed_servic": 613, "python_executor_servic": 613, "test_servic": 613, "test_python_executor_servic": 613, "ref_llm": [613, 632], "torchsnapshot": 614, "logscalar": [614, 621], "mlflowlogg": 614, "trackiologg": 614, "get_logg": 614, "generate_exp_nam": 614, "batchsubsampl": 614, "clearcudacach": 614, "countframeslog": 614, "optimizerhook": [614, 621], "logvalidationreward": [614, 620, 621], "replaybuffertrain": [614, 621], "rewardnorm": 614, "selectkei": 614, "targetnetupdaterhook": 614, "utdrhook": 614, "000": [619, 623, 640], "galleri": [619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "mem": [619, 640], "mb": [619, 640], "coding_ddpg": [619, 620, 640], "coding_dqn": [619, 621, 640], "coding_ppo": [619, 622, 640], "dqn_with_rnn": [619, 623, 640], "llm_browser": [619, 632, 640], "llm_wrapper": [619, 633, 640], "multi_task": [619, 634, 640], "multiagent_competitive_ddpg": [619, 635, 640], "multiagent_ppo": [619, 636, 640], "pretrained_model": [619, 638, 640], "rb_tutori": [619, 639, 640], "torchrl_demo": [619, 640, 641], "torchrl_env": [619, 640, 642], "author": [620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 635, 636, 637, 639, 642], "vincent": [620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 637, 639, 642], "moen": [620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 637, 639, 642], "assembl": 620, "ground": [620, 637], "transpar": [620, 623], "bash": 620, "is_fork": [620, 621, 622, 623, 635, 636, 638], "get_start_method": [620, 621, 622, 623, 635, 636, 638], "collector_devic": 620, "swappabl": 620, "smth": 620, "loss_dict": 620, "oblivi": [620, 622, 639], "elementari": 620, "didact": [620, 624], "dilut": 620, "pessimist": [620, 621, 622], "target_actor_network_param": 620, "actor_in_kei": 620, "actor_crit": 620, "compromis": 620, "td0estim": 620, "td1estim": 620, "tdlambdaestim": 620, "hp": 620, "_value_estim": 620, "hold_out_param": 620, "_loss_actor": 620, "td_copi": 620, "actor_network_param": [620, 635], "value_network_param": [620, 635], "distance_loss": 620, "_loss_valu": 620, "pred_val": 620, "target_value_network_param": 620, "smooth": [620, 621, 627], "pow": 620, "glue": 620, "_forward": 620, "remaind": 620, "env_librari": 620, "env_task": 620, "env_arg": [620, 621], "torchr": 620, "rescal": 620, "presum": 620, "make_transformed_env": 620, "reward_sc": 620, "parallel_env_constructor": 620, "env_per_collector": 620, "transform_state_dict": 620, "make_t_env": 620, "seem": [620, 623, 625], "cheat": 620, "10m": 620, "nutshel": 620, "cautiou": 620, "thousand": [620, 623], "get_env_stat": 620, "proof_env": 620, "5000": [620, 624, 630], "recal": [620, 622, 632, 639], "materi": 620, "make_ddpg_actor": 620, "q_net": 620, "qnet": 620, "suggest": [620, 636], "tight": 620, "10_000": [620, 622], "traj_len": [620, 623], "make_record": 620, "recorder_obj": 620, "pick": [620, 621, 626, 632], "make_replay_buff": 620, "buffer_s": [620, 621, 623], "random_crop_len": 620, "prb": 620, "buffer_scratch_dir": [620, 621, 623, 628, 638], "dataflow": 620, "ceil_div": 620, "update_to_data": 620, "realiz": 620, "ve": [620, 623, 630, 632], "_must_": 620, "outdat": 620, "trick": [620, 621], "despit": 620, "hardupd": [620, 627], "optimizer_actor": 620, "optimizer_valu": 620, "total_collection_step": 620, "rewards_ev": 620, "collected_fram": 620, "r0": 620, "numel": [620, 622, 624, 630, 635, 638, 639], "current_fram": [620, 635], "sampled_tensordict": 620, "gn1": 620, "clip_grad_norm_": [620, 622, 635, 636, 637], "gn2": 620, "gn": [620, 637], "td_record": 620, "rn": 620, "2f": 620, "plot": [620, 622, 623, 635, 636, 637], "mention": [620, 623, 639, 642], "matplotlib": [620, 622, 623, 624, 635, 636, 637, 639, 642], "pyplot": [620, 622, 623, 624, 635, 636, 637, 639, 642], "plt": [620, 622, 623, 624, 635, 636, 637, 639, 642], "legend": [620, 635], "xlabel": [620, 623, 636, 637], "ylabel": [620, 636], "tight_layout": 620, "concret": [620, 622, 632], "takeawai": [620, 621, 624, 632], "distpatch": 620, "jupyt": [620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "ipynb": [620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "sphinx": [620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642], "road": 621, "aspect": [621, 627], "highest": [621, 626], "prerequisit": [621, 623, 632], "amort": [621, 622], "cart": 621, "pole": 621, "un": 621, "actuat": 621, "frictionless": 621, "is_notebook": 621, "shell": 621, "get_ipython": 621, "__class__": [621, 633], "zmqinteractiveshel": 621, "qtconsol": 621, "terminalinteractiveshel": 621, "ipython": [621, 636, 637], "nameerror": [621, 633, 635], "umbrella": 621, "misplac": 621, "misus": 621, "64x64": 621, "motion": [621, 637], "obs_norm_sd": 621, "mp_context": 621, "get_norm_stat": 621, "test_env": 621, "mathbb": 621, "rightarrow": 621, "make_model": 621, "dummy_env": 621, "init_bia": 621, "exploration_modul": [621, 623, 624, 626, 630], "eps_greedy_v": 621, "eps_greedy_val_env": 621, "actor_explor": 621, "get_replay_buff": 621, "n_optim": [621, 627, 628], "parametriz": 621, "get_collector": 621, "bunch": 621, "ubiquit": [621, 625], "get_loss_modul": 621, "target_updat": [621, 635], "995": 621, "hopefulli": 621, "sensit": [621, 623], "variat": 621, "2e": [621, 637], "wd": 621, "upd": 621, "harder": [621, 641], "5_000": 621, "500000": 621, "005": [621, 635], "mandatori": [621, 622, 636, 637], "fairer": 621, "budget": 621, "dqn_exp_": 621, "uuid1": [621, 642], "cumbersom": 621, "buffer_hook": 621, "trainerhookbas": 621, "aliv": 621, "total_reward": 621, "ti": 621, "print_csv_files_in_fold": 621, "folder_path": 621, "csv_file": 621, "output_str": 621, "dirpath": 621, "endswith": 621, "qvaluenetwork": 621, "worst": 621, "accuraci": 621, "fanci": [621, 628], "talk": 622, "six": 622, "invent": 622, "theta_k": 622, "pi_": 622, "exceed": 622, "indispens": 622, "loader": 622, "analyz": 622, "lingua": 622, "franca": 622, "defaultdict": [622, 637], "max_grad_norm": [622, 635, 636], "sub_batch_s": 622, "95": [622, 623], "entropy_ep": [622, 636], "inverteddoublependulum": 622, "transmit": 622, "stai": 622, "told": 622, "confid": [622, 635, 636], "ran": 622, "f_": 622, "mu_": 622, "difficulti": [622, 642], "brought": [622, 623, 626], "d_ob": 622, "d_action": 622, "said": 622, "value_modul": [622, 641], "briefli": [622, 635, 636], "refil": [622, 636], "easiest": [622, 627, 635, 636], "hide": [622, 635, 636], "mathemat": [622, 635, 636], "tradeoff": [622, 636], "advantage_modul": 622, "entropy_coef": [622, 636], "critic_coef": 622, "lr_schedul": [622, 637], "cosineannealinglr": [622, 637], "eval_str": 622, "tensordict_data": [622, 636], "data_view": [622, 636], "subdata": [622, 635, 636], "cum_reward_str": 622, "stepcount_str": 622, "param_group": [622, 635], "lr_str": 622, "eval_rollout": 622, "figsiz": [622, 637], "subplot": [622, 635, 637, 642], "84x84": [623, 624], "accessori": 623, "stamp": 623, "backbon": [623, 626, 634, 641], "emb": 623, "n_cell": 623, "bidirect": 623, "wouldn": 623, "qval": 623, "stoch_polici": 623, "opportun": [623, 635], "uniniti": 623, "again": [623, 624, 625, 626, 628, 636, 638, 639, 642], "strongli": 623, "sake": [623, 638, 639], "longest": 623, "enough": [623, 639], "strong": 624, "impress": 624, "edg": 624, "arduino": 624, "raspberri": 624, "alon": 624, "examplifi": 624, "ship": 624, "nearest": 624, "value_mlp": [624, 630], "init_rand_step": [624, 630], "total_count": [624, 630], "total_episod": [624, 630], "screen": [624, 635], "color": [624, 635], "clearer": [624, 626], "unblock": 624, "policy_transform": 624, "fake_td": 624, "exported_polici": 624, "div": 624, "graph_modul": 624, "print_read": 624, "group0": 624, "group0_agent0_ob": 624, "group0_agent0": 624, "agent0_ob": 624, "obvious": 624, "digress": 624, "exported_stochastic_polici": 624, "hidden0": 624, "hidden1": 624, "recurrent_polici": 624, "happi": 624, "fake_ob": 624, "fake_hidden0": 624, "fake_hidden1": 624, "fake_is_init": 624, "exported_recurrent_polici": 624, "platform": [624, 641], "aoti": 624, "_inductor": 624, "aoti_compile_and_packag": 624, "aoti_load_packag": 624, "pt2": 624, "pkg_path": 624, "package_path": 624, "compiled_modul": 624, "onnxruntim": 624, "showcas": [624, 637], "plenti": 624, "tensorrt": 624, "android": 624, "aleinterfac": 624, "rom": [624, 642], "loadrom": 624, "reset_gam": 624, "screen_ob": 624, "getscreenrgb": 624, "tick_param": 624, "bottom": 624, "labelleft": 624, "labelbottom": 624, "imshow": [624, 642], "dynamo_export": 624, "as_tensor": 624, "onnx_policy_export": 624, "onnx_file_path": 624, "ort_sess": 624, "inferencesess": 624, "cpuexecutionprovid": 624, "onnxruntime_input": 624, "get_input": 624, "onnx_polici": 624, "f811": 624, "onnxruntime_output": 624, "num_step": 624, "deploy": 624, "topic": [625, 626, 627], "straight": 625, "backtrack": 625, "reset_with_act": 625, "stepped_data": 625, "spatial": 625, "useless": 625, "policyless": 625, "glanc": 625, "appreci": 625, "examin": [625, 635], "tackl": 626, "intric": 626, "delv": 626, "extractor": 626, "analog": 626, "realm": 626, "exploration_polici": [626, 635], "2d": [626, 635, 636], "innov": [626, 627], "rollout_explor": 626, "sole": 627, "n_collect": 627, "get_next_batch": 627, "ddpg_loss": 627, "prove": 627, "reliev": 627, "accustom": 628, "surprisingli": 628, "matter": 628, "art": [628, 635, 636], "pseudo": [628, 637], "countless": 628, "yourself": [628, 635, 636], "chapter": 629, "everywher": 629, "log_scalar": 629, "my_scalar": 629, "excess": 629, "lesson": 630, "voluntarili": 630, "training_loop": 630, "video_record": 630, "arbitrarili": 630, "num": 630, "t1": 630, "conclud": [630, 638], "tutorials_python": 631, "tutorials_jupyt": 631, "playwright": 632, "autom": 632, "__future__": 632, "browsertransform": 632, "filterwarn": [632, 633], "browser_transform": 632, "rewardtransform": 632, "last_item": 632, "execute_tool_act": 632, "current_st": 632, "nllm": 632, "nenviron": 632, "button": 632, "css": 632, "btnk": 632, "extract_typ": 632, "suppress": 633, "vllm_use_v1": 633, "5b": 633, "canada": 633, "vllm_wrapper": 633, "return_text": 633, "return_token": 633, "return_mask": 633, "data_histori": 633, "nload": 633, "transformers_token": 633, "transformers_wrapp": 633, "result_tf": 633, "data_text": 633, "vllm_text_wrapp": 633, "result_vllm_text": 633, "nvllm": 633, "transformers_text_wrapp": 633, "result_tf_text": 633, "vllm_logprobs_wrapp": 633, "result_vllm_lp": 633, "transformers_logprobs_wrapp": 633, "result_tf_lp": 633, "ntensorclass": 633, "analysi": 633, "ntext": 633, "__annotations__": 633, "ntoken": 633, "nlogprob": 633, "nmask": 633, "nerror": 633, "invalid_mod": 633, "nrl": 633, "env_stat": 633, "action_output": 633, "env1_obs_kei": 634, "observation_stand": 634, "env2_obs_kei": 634, "observation_walk": 634, "tdreset1": 634, "tdreset2": 634, "policy_common": 634, "policy_stand": 634, "policy_walk": 634, "env1_mak": 634, "env2_mak": 634, "_single_task": 634, "td_rollout": 634, "matteo": [635, 636], "bettini": [635, 636], "benchmarl": [635, 636], "simple_tag": 635, "maddpg": [635, 636], "multiagentparticleenviron": 635, "mpe": 635, "centralis": [635, 636], "tie": [635, 636], "iddpg": [635, 636], "optimis": [635, 636], "sutton": [635, 636], "richard": 635, "andrew": 635, "barto": [635, 636], "mit": 635, "press": 635, "2018": 635, "mathbf": [635, 636], "decentralis": [635, 636], "literatur": [635, 636], "overcom": [635, 636], "stationari": [635, 636], "establish": 635, "gui": [635, 636], "multiagentmlp": [635, 636], "is_sphinx": 635, "__sphinx_build__": 635, "n_iter": [635, 636, 637], "evad": 635, "iteration_when_stop_training_evad": 635, "memory_s": 635, "n_optimiser_step": 635, "train_batch_s": 635, "polyak_tau": 635, "furthermor": [635, 636], "chaser": 635, "red": 635, "circl": [635, 636], "touch": [635, 637], "penal": [635, 636], "obstacl": 635, "drag": [635, 636], "elast": [635, 636], "Their": [635, 636], "imped": 635, "n_chaser": 635, "n_evad": 635, "n_obstacl": 635, "use_vma": 635, "simple_tag_v3": 635, "num_good": 635, "num_adversari": 635, "num_obstacl": 635, "max_cycl": 635, "num_vmas_env": [635, 636], "num_good_ag": 635, "num_landmark": 635, "four": [635, 636, 637], "n_agents_in_that_group": 635, "stress": [635, 636], "paramount": [635, 636], "n_rollout_step": [635, 636], "evolut": [635, 636], "group_nam": 635, "n_agents_in_group": 635, "signifi": [635, 636], "agents_exploration_polici": 635, "utilis": [635, 636], "homogen": [635, 636], "n_obs_per_ag": [635, 636], "n_actions_per_ag": [635, 636], "share_parameters_polici": [635, 636], "policy_net": [635, 636], "n_agent_input": [635, 636], "n_agent_output": [635, 636], "share_param": [635, 636], "_agent": 635, "grant": [635, 636], "converg": [635, 636], "share_parameters_crit": [635, 636], "obs_act": 635, "cat_modul": 635, "critic_modul": 635, "fantast": [635, 636], "reset_td": 635, "interfer": 635, "subject": [635, 637], "flatten_kei": 635, "process_batch": 635, "group_shap": 635, "get_item_shap": [635, 636], "nested_done_kei": 635, "nested_terminated_kei": 635, "desc": [635, 636], "episode_reward_mean_": 635, "episode_reward_mean_map": 635, "train_group_map": 635, "group_batch": 635, "_group": 635, "loss_nam": 635, "episode_reward_mean": [635, 636], "proce": 635, "fig": [635, 639], "set_ylabel": 635, "axvlin": 635, "orang": 635, "set_xlabel": 635, "video_logg": 635, "vmas_log": 635, "env_with_rend": 635, "vmas_rend": 635, "print_log_dir": 635, "profici": [635, 636], "qmix": [635, 636], "lidar": 636, "sensor": 636, "mappo": 636, "ippo": 636, "_t": [636, 637], "analys": 636, "visualis": 636, "vmas_devic": 636, "6_000": 636, "minibatch_s": 636, "generalis": 636, "simd": 636, "warp": 636, "todai": 636, "dot": [636, 637], "scenario_nam": 636, "critic_net": 636, "minibatch": 636, "episode_reward_mean_list": 636, "critic_network_param": 636, "target_critic_network_param": 636, "xvfb": 636, "pyvirtualdisplai": 636, "1400": 636, "900": 636, "pil": 636, "rendering_callback": 636, "fromarrai": 636, "gif": 636, "save_al": 636, "append_imag": 636, "freeli": 637, "undertaken": 637, "broader": 637, "wider": 637, "acquaint": 637, "avenu": 637, "_apply_to_composit": 637, "default_x": 637, "default_i": 637, "upward": 637, "angular": 637, "sin": 637, "theta_t": 637, "rad": 637, "theta_": 637, "angl": 637, "new_th": 637, "new_thdot": 637, "g_forc": 637, "angle_norm": 637, "zeros_lik": 637, "albeit": 637, "high_th": 637, "high_thdot": 637, "low_th": 637, "low_thdot": 637, "trivial": 637, "irrelev": 637, "_make_spec": 637, "td_param": 637, "render_fp": 637, "random_": 637, "_make_step": 637, "staticmethod": 637, "skeleton": 637, "sine": 637, "cosin": 637, "sintransform": 637, "costransform": 637, "t_sin": 637, "t_co": 637, "cat_transform": 637, "simple_rollout": 637, "_data": 637, "unexplor": 637, "recreat": 637, "20_000": 637, "init_td": 637, "traj_return": 637, "last_reward": 637, "is_ipython": 637, "inlin": 637, "get_backend": 637, "ion": 637, "gcf": 637, "clear_output": 637, "env_transform": [638, 642], "wiser": 638, "_storag": [638, 639], "batteri": 639, "gc": 639, "filesystem": 639, "buffer_list": 639, "lowest": 639, "medium": 639, "buffer_lazytensor": 639, "tempdir": 639, "buffer_lazymemmap": 639, "fullest": 639, "mydata": 639, "buffer_lazi": 639, "_i": 639, "artifici": 639, "hamper": 639, "hist": 639, "recycl": 639, "reappear": 639, "unfold": 639, "problemat": 639, "4th": 639, "tensordictmaxvaluewrit": 639, "demo": 641, "icml": 641, "vmoen": 641, "fb": 641, "invest": 641, "media": 641, "predominantli": 641, "data2": 641, "sub_key1": 641, "scturctur": 641, "data_stack": 641, "data_sampl": 641, "_sampler": 641, "_sum_tre": 641, "modulenotfounderror": 641, "backbone_modul": 641, "params_expand": 641, "exec_sequ": 641, "tensordict_exp": 641, "base_modul": 641, "roughli": 641, "tensordicts_prealloc": 641, "tensordicts_stack": 641, "tensordict_rollout": [641, 642], "automatical": 641, "particularili": 641, "concatmodul": 641, "loss_td": 641, "contributor": 641, "curiou": 641, "nascent": 641, "unsupervis": 642, "licens": 642, "pygam": 642, "_build_env": 642, "deserv": 642, "__episode__": 642, "__trajectory__": 642, "void": 642, "reproduct": 642, "tensordict_tprim": 642, "inconsist": 642, "wrapper1": 642, "wrapper2": 642, "obviou": 642, "truth": 642, "env_transformed_bi": 642, "stanc": 642, "transformeddistribut": 642, "base_dist": 642, "concat": 642, "mofidi": 642, "transformedenviron": 642, "moderet": 642, "computation": 642, "incom": 642, "amongst": 642, "has_cuda": 642, "device_count": 642, "worri": 642, "convention": 642, "markovian": 642, "bar_": 642, "get_someth": 642, "aargh": 642, "is_clos": 642, "foo_list": 642, "121": 642, "evolv": 642, "steadi": 642, "approx": 642, "sd": 642, "absor": 642, "_extra_st": 642}, "objects": {"torchrl": [[31, 0, 1, "", "auto_unwrap_transformed_env"], [282, 0, 1, "", "implement_for"], [405, 0, 1, "", "set_auto_unwrap_transformed_env"]], "torchrl.collectors": [[32, 0, 1, "", "AsyncCollector"], [33, 0, 1, "", "BaseCollector"], [34, 0, 1, "", "Collector"], [35, 0, 1, "", "MultiAsyncCollector"], [36, 0, 1, "", "MultiCollector"], [37, 0, 1, "", "MultiProcessedWeightUpdater"], [38, 0, 1, "", "MultiSyncCollector"], [39, 0, 1, "", "RayWeightUpdater"], [40, 0, 1, "", "VanillaWeightUpdater"], [41, 0, 1, "", "WeightUpdaterBase"]], "torchrl.collectors.AsyncCollector": [[32, 1, 1, "", "async_shutdown"], [32, 1, 1, "", "cascade_execute"], [32, 1, 1, "", "enable_profile"], [32, 1, 1, "", "get_cached_weights"], [32, 1, 1, "", "get_model"], [32, 1, 1, "", "get_policy_version"], [32, 1, 1, "", "getattr_env"], [32, 1, 1, "", "getattr_policy"], [32, 1, 1, "", "getattr_rb"], [32, 1, 1, "", "increment_version"], [32, 1, 1, "", "init_updater"], [32, 1, 1, "", "load_state_dict"], [32, 1, 1, "", "pause"], [32, 2, 1, "", "policy_version"], [32, 2, 1, "", "profile_config"], [32, 1, 1, "", "receive_weights"], [32, 1, 1, "", "register_scheme_receiver"], [32, 1, 1, "", "reset"], [32, 1, 1, "", "set_seed"], [32, 1, 1, "", "shutdown"], [32, 1, 1, "", "start"], [32, 1, 1, "", "state_dict"], [32, 1, 1, "", "update_policy_weights_"], [32, 2, 1, "", "worker_idx"]], "torchrl.collectors.BaseCollector": [[33, 1, 1, "", "async_shutdown"], [33, 1, 1, "", "cascade_execute"], [33, 1, 1, "", "enable_profile"], [33, 1, 1, "", "init_updater"], [33, 1, 1, "", "pause"], [33, 2, 1, "", "profile_config"], [33, 1, 1, "", "receive_weights"], [33, 1, 1, "", "register_scheme_receiver"], [33, 1, 1, "", "start"], [33, 1, 1, "", "update_policy_weights_"], [33, 2, 1, "", "worker_idx"]], "torchrl.collectors.Collector": [[34, 1, 1, "", "async_shutdown"], [34, 1, 1, "", "cascade_execute"], [34, 1, 1, "", "enable_profile"], [34, 1, 1, "", "get_model"], [34, 1, 1, "", "get_policy_version"], [34, 1, 1, "", "getattr_env"], [34, 1, 1, "", "getattr_policy"], [34, 1, 1, "", "getattr_rb"], [34, 1, 1, "", "increment_version"], [34, 1, 1, "", "init_updater"], [34, 1, 1, "", "iterator"], [34, 1, 1, "", "load_state_dict"], [34, 1, 1, "", "pause"], [34, 2, 1, "", "policy_version"], [34, 2, 1, "", "profile_config"], [34, 1, 1, "", "receive_weights"], [34, 1, 1, "", "register_scheme_receiver"], [34, 1, 1, "", "reset"], [34, 1, 1, "", "rollout"], [34, 1, 1, "", "set_seed"], [34, 1, 1, "", "shutdown"], [34, 1, 1, "", "start"], [34, 1, 1, "", "state_dict"], [34, 1, 1, "", "update_policy_weights_"], [34, 2, 1, "", "worker_idx"]], "torchrl.collectors.MultiAsyncCollector": [[35, 1, 1, "", "async_shutdown"], [35, 1, 1, "", "cascade_execute"], [35, 1, 1, "", "enable_profile"], [35, 1, 1, "", "get_cached_weights"], [35, 1, 1, "", "get_model"], [35, 1, 1, "", "get_policy_version"], [35, 1, 1, "", "getattr_env"], [35, 1, 1, "", "getattr_policy"], [35, 1, 1, "", "getattr_rb"], [35, 1, 1, "", "increment_version"], [35, 1, 1, "", "init_updater"], [35, 1, 1, "", "load_state_dict"], [35, 1, 1, "", "pause"], [35, 2, 1, "", "policy_version"], [35, 2, 1, "", "profile_config"], [35, 1, 1, "", "receive_weights"], [35, 1, 1, "", "register_scheme_receiver"], [35, 1, 1, "", "reset"], [35, 1, 1, "", "set_seed"], [35, 1, 1, "", "shutdown"], [35, 1, 1, "", "start"], [35, 1, 1, "", "state_dict"], [35, 1, 1, "", "update_policy_weights_"], [35, 2, 1, "", "worker_idx"]], "torchrl.collectors.MultiCollector": [[36, 1, 1, "", "async_shutdown"], [36, 1, 1, "", "cascade_execute"], [36, 1, 1, "", "enable_profile"], [36, 1, 1, "", "get_cached_weights"], [36, 1, 1, "", "get_model"], [36, 1, 1, "", "get_policy_version"], [36, 1, 1, "", "getattr_env"], [36, 1, 1, "", "getattr_policy"], [36, 1, 1, "", "getattr_rb"], [36, 1, 1, "", "increment_version"], [36, 1, 1, "", "init_updater"], [36, 1, 1, "", "load_state_dict"], [36, 1, 1, "", "pause"], [36, 2, 1, "", "policy_version"], [36, 2, 1, "", "profile_config"], [36, 1, 1, "", "receive_weights"], [36, 1, 1, "", "register_scheme_receiver"], [36, 1, 1, "", "reset"], [36, 1, 1, "", "set_seed"], [36, 1, 1, "", "shutdown"], [36, 1, 1, "", "start"], [36, 1, 1, "", "state_dict"], [36, 1, 1, "", "update_policy_weights_"], [36, 2, 1, "", "worker_idx"]], "torchrl.collectors.MultiProcessedWeightUpdater": [[37, 1, 1, "", "all_worker_ids"], [37, 2, 1, "", "collector"], [37, 2, 1, "", "collectors"], [37, 1, 1, "", "from_policy"], [37, 1, 1, "", "increment_version"], [37, 1, 1, "", "init"], [37, 2, 1, "", "post_hooks"], [37, 1, 1, "", "push_weights"], [37, 1, 1, "", "register_collector"], [37, 1, 1, "", "register_post_hook"]], "torchrl.collectors.MultiSyncCollector": [[38, 1, 1, "", "async_shutdown"], [38, 1, 1, "", "cascade_execute"], [38, 1, 1, "", "enable_profile"], [38, 1, 1, "", "get_cached_weights"], [38, 1, 1, "", "get_model"], [38, 1, 1, "", "get_policy_version"], [38, 1, 1, "", "getattr_env"], [38, 1, 1, "", "getattr_policy"], [38, 1, 1, "", "getattr_rb"], [38, 1, 1, "", "increment_version"], [38, 1, 1, "", "init_updater"], [38, 1, 1, "", "load_state_dict"], [38, 1, 1, "", "pause"], [38, 2, 1, "", "policy_version"], [38, 2, 1, "", "profile_config"], [38, 1, 1, "", "receive_weights"], [38, 1, 1, "", "register_scheme_receiver"], [38, 1, 1, "", "reset"], [38, 1, 1, "", "set_seed"], [38, 1, 1, "", "shutdown"], [38, 1, 1, "", "start"], [38, 1, 1, "", "state_dict"], [38, 1, 1, "", "update_policy_weights_"], [38, 2, 1, "", "worker_idx"]], "torchrl.collectors.RayWeightUpdater": [[39, 1, 1, "", "_get_server_weights"], [39, 1, 1, "", "_maybe_map_weights"], [39, 1, 1, "", "_skip_update"], [39, 1, 1, "", "_sync_weights_with_worker"], [39, 1, 1, "id0", "all_worker_ids"], [39, 2, 1, "", "collector"], [39, 2, 1, "", "collectors"], [39, 1, 1, "", "from_policy"], [39, 1, 1, "", "increment_version"], [39, 1, 1, "", "init"], [39, 2, 1, "", "post_hooks"], [39, 1, 1, "", "push_weights"], [39, 1, 1, "", "register_collector"], [39, 1, 1, "", "register_post_hook"]], "torchrl.collectors.VanillaWeightUpdater": [[40, 1, 1, "", "all_worker_ids"], [40, 2, 1, "", "collector"], [40, 2, 1, "", "collectors"], [40, 1, 1, "", "from_policy"], [40, 1, 1, "", "increment_version"], [40, 1, 1, "", "init"], [40, 2, 1, "", "post_hooks"], [40, 1, 1, "", "push_weights"], [40, 1, 1, "", "register_collector"], [40, 1, 1, "", "register_post_hook"]], "torchrl.collectors.WeightUpdaterBase": [[41, 1, 1, "", "all_worker_ids"], [41, 2, 1, "", "collector"], [41, 2, 1, "", "collectors"], [41, 1, 1, "id0", "from_policy"], [41, 1, 1, "", "increment_version"], [41, 1, 1, "", "init"], [41, 2, 1, "", "post_hooks"], [41, 1, 1, "id1", "push_weights"], [41, 1, 1, "id2", "register_collector"], [41, 1, 1, "", "register_post_hook"]], "torchrl.collectors.distributed": [[42, 0, 1, "", "DistributedCollector"], [43, 0, 1, "", "DistributedDataCollector"], [44, 0, 1, "", "DistributedSyncCollector"], [45, 0, 1, "", "DistributedSyncDataCollector"], [46, 0, 1, "", "DistributedWeightUpdater"], [47, 0, 1, "", "RPCCollector"], [48, 0, 1, "", "RPCDataCollector"], [49, 0, 1, "", "RPCWeightUpdater"], [50, 0, 1, "", "RayCollector"], [51, 0, 1, "", "submitit_delayed_launcher"]], "torchrl.collectors.distributed.DistributedCollector": [[42, 1, 1, "", "async_shutdown"], [42, 1, 1, "", "cascade_execute"], [42, 1, 1, "", "enable_profile"], [42, 1, 1, "", "init_updater"], [42, 1, 1, "", "pause"], [42, 2, 1, "", "profile_config"], [42, 1, 1, "", "receive_weights"], [42, 1, 1, "", "register_scheme_receiver"], [42, 1, 1, "", "start"], [42, 1, 1, "", "update_policy_weights_"], [42, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.DistributedDataCollector": [[43, 1, 1, "", "async_shutdown"], [43, 1, 1, "", "cascade_execute"], [43, 1, 1, "", "enable_profile"], [43, 1, 1, "", "init_updater"], [43, 1, 1, "", "pause"], [43, 2, 1, "", "profile_config"], [43, 1, 1, "", "receive_weights"], [43, 1, 1, "", "register_scheme_receiver"], [43, 1, 1, "", "start"], [43, 1, 1, "", "update_policy_weights_"], [43, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.DistributedSyncCollector": [[44, 1, 1, "", "async_shutdown"], [44, 1, 1, "", "cascade_execute"], [44, 1, 1, "", "enable_profile"], [44, 1, 1, "", "init_updater"], [44, 1, 1, "", "pause"], [44, 2, 1, "", "profile_config"], [44, 1, 1, "", "receive_weights"], [44, 1, 1, "", "register_scheme_receiver"], [44, 1, 1, "", "start"], [44, 1, 1, "", "update_policy_weights_"], [44, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.DistributedSyncDataCollector": [[45, 1, 1, "", "async_shutdown"], [45, 1, 1, "", "cascade_execute"], [45, 1, 1, "", "enable_profile"], [45, 1, 1, "", "init_updater"], [45, 1, 1, "", "pause"], [45, 2, 1, "", "profile_config"], [45, 1, 1, "", "receive_weights"], [45, 1, 1, "", "register_scheme_receiver"], [45, 1, 1, "", "start"], [45, 1, 1, "", "update_policy_weights_"], [45, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.DistributedWeightUpdater": [[46, 1, 1, "", "_get_server_weights"], [46, 1, 1, "", "_maybe_map_weights"], [46, 1, 1, "", "_sync_weights_with_worker"], [46, 1, 1, "id0", "all_worker_ids"], [46, 2, 1, "", "collector"], [46, 2, 1, "", "collectors"], [46, 1, 1, "", "from_policy"], [46, 1, 1, "", "increment_version"], [46, 1, 1, "", "init"], [46, 2, 1, "", "post_hooks"], [46, 1, 1, "", "push_weights"], [46, 1, 1, "", "register_collector"], [46, 1, 1, "", "register_post_hook"], [46, 1, 1, "", "update_weights"]], "torchrl.collectors.distributed.RPCCollector": [[47, 1, 1, "", "async_shutdown"], [47, 1, 1, "", "cascade_execute"], [47, 1, 1, "", "enable_profile"], [47, 1, 1, "", "init_updater"], [47, 1, 1, "", "pause"], [47, 2, 1, "", "profile_config"], [47, 1, 1, "", "receive_weights"], [47, 1, 1, "", "register_scheme_receiver"], [47, 1, 1, "", "start"], [47, 1, 1, "", "update_policy_weights_"], [47, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.RPCDataCollector": [[48, 1, 1, "", "async_shutdown"], [48, 1, 1, "", "cascade_execute"], [48, 1, 1, "", "enable_profile"], [48, 1, 1, "", "init_updater"], [48, 1, 1, "", "pause"], [48, 2, 1, "", "profile_config"], [48, 1, 1, "", "receive_weights"], [48, 1, 1, "", "register_scheme_receiver"], [48, 1, 1, "", "start"], [48, 1, 1, "", "update_policy_weights_"], [48, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.RPCWeightUpdater": [[49, 1, 1, "", "_get_server_weights"], [49, 1, 1, "", "_maybe_map_weights"], [49, 1, 1, "", "_sync_weights_with_worker"], [49, 1, 1, "id0", "all_worker_ids"], [49, 2, 1, "", "collector"], [49, 2, 1, "", "collectors"], [49, 1, 1, "", "from_policy"], [49, 1, 1, "", "increment_version"], [49, 1, 1, "", "init"], [49, 2, 1, "", "post_hooks"], [49, 1, 1, "", "push_weights"], [49, 1, 1, "", "register_collector"], [49, 1, 1, "", "register_post_hook"], [49, 1, 1, "", "update_weights"]], "torchrl.collectors.distributed.RayCollector": [[50, 1, 1, "", "add_collectors"], [50, 1, 1, "", "async_shutdown"], [50, 1, 1, "", "cascade_execute"], [50, 1, 1, "", "enable_profile"], [50, 1, 1, "", "init_updater"], [50, 1, 1, "", "load_state_dict"], [50, 1, 1, "", "local_policy"], [50, 1, 1, "", "pause"], [50, 2, 1, "", "profile_config"], [50, 1, 1, "", "receive_weights"], [50, 1, 1, "", "register_scheme_receiver"], [50, 2, 1, "", "remote_collectors"], [50, 1, 1, "", "set_seed"], [50, 1, 1, "", "shutdown"], [50, 1, 1, "", "start"], [50, 1, 1, "", "state_dict"], [50, 1, 1, "", "stop_remote_collectors"], [50, 1, 1, "", "update_policy_weights_"], [50, 2, 1, "", "worker_idx"]], "torchrl.collectors.llm": [[52, 0, 1, "", "LLMCollector"], [53, 0, 1, "", "RayLLMCollector"], [54, 0, 1, "", "vLLMUpdater"], [55, 0, 1, "", "vLLMUpdaterV2"]], "torchrl.collectors.llm.LLMCollector": [[52, 1, 1, "", "as_remote"], [52, 1, 1, "", "async_shutdown"], [52, 1, 1, "", "cascade_execute"], [52, 2, 1, "", "dialog_turns_per_batch"], [52, 1, 1, "", "enable_profile"], [52, 1, 1, "", "get_model"], [52, 1, 1, "", "get_policy_model"], [52, 1, 1, "", "get_policy_version"], [52, 1, 1, "", "getattr_env"], [52, 1, 1, "", "getattr_policy"], [52, 1, 1, "", "getattr_rb"], [52, 1, 1, "", "increment_version"], [52, 1, 1, "", "init_updater"], [52, 1, 1, "", "is_initialized"], [52, 1, 1, "", "iterator"], [52, 1, 1, "", "load_state_dict"], [52, 1, 1, "", "pause"], [52, 2, 1, "", "policy_version"], [52, 2, 1, "", "profile_config"], [52, 1, 1, "", "receive_weights"], [52, 1, 1, "", "register_scheme_receiver"], [52, 1, 1, "", "reset"], [52, 2, 1, "", "rollout"], [52, 1, 1, "", "set_seed"], [52, 1, 1, "", "shutdown"], [52, 1, 1, "", "start"], [52, 1, 1, "", "state_dict"], [52, 1, 1, "", "update_policy_weights_"], [52, 2, 1, "", "worker_idx"]], "torchrl.collectors.llm.RayLLMCollector": [[53, 1, 1, "", "as_remote"], [53, 1, 1, "", "async_shutdown"], [53, 1, 1, "", "cascade_execute"], [53, 2, 1, "", "dialog_turns_per_batch"], [53, 1, 1, "", "enable_profile"], [53, 1, 1, "", "get_model"], [53, 1, 1, "", "get_policy_model"], [53, 1, 1, "", "get_policy_version"], [53, 1, 1, "", "getattr_env"], [53, 1, 1, "", "getattr_policy"], [53, 1, 1, "", "getattr_rb"], [53, 1, 1, "", "increment_version"], [53, 1, 1, "", "init_updater"], [53, 1, 1, "", "is_initialized"], [53, 1, 1, "", "iterator"], [53, 1, 1, "", "load_state_dict"], [53, 1, 1, "", "next"], [53, 1, 1, "", "pause"], [53, 2, 1, "", "policy_version"], [53, 2, 1, "", "profile_config"], [53, 1, 1, "", "receive_weights"], [53, 1, 1, "", "register_scheme_receiver"], [53, 1, 1, "", "reset"], [53, 2, 1, "", "rollout"], [53, 1, 1, "", "set_seed"], [53, 1, 1, "", "shutdown"], [53, 1, 1, "", "start"], [53, 1, 1, "", "state_dict"], [53, 2, 1, "", "total_dialog_turns"], [53, 1, 1, "", "update_policy_weights_"], [53, 2, 1, "", "weight_updater"], [53, 2, 1, "", "worker_idx"]], "torchrl.collectors.llm.vLLMUpdater": [[54, 1, 1, "", "_get_server_weights"], [54, 1, 1, "", "_maybe_map_weights"], [54, 1, 1, "", "_sync_weights_with_worker"], [54, 1, 1, "id0", "all_worker_ids"], [54, 2, 1, "", "collector"], [54, 2, 1, "", "collectors"], [54, 1, 1, "", "from_policy"], [54, 1, 1, "", "get_model_metadata"], [54, 1, 1, "", "increment_version"], [54, 1, 1, "id1", "init"], [54, 2, 1, "", "post_hooks"], [54, 1, 1, "", "push_weights"], [54, 1, 1, "", "register_collector"], [54, 1, 1, "", "register_post_hook"]], "torchrl.collectors.llm.vLLMUpdaterV2": [[55, 1, 1, "", "all_worker_ids"], [55, 2, 1, "", "collector"], [55, 2, 1, "", "collectors"], [55, 1, 1, "", "from_policy"], [55, 1, 1, "", "get_model_metadata"], [55, 1, 1, "", "get_tp_size"], [55, 1, 1, "", "increment_version"], [55, 1, 1, "", "init"], [55, 2, 1, "", "post_hooks"], [55, 1, 1, "", "push_weights"], [55, 1, 1, "", "push_weights_from_transformers"], [55, 1, 1, "", "push_weights_from_transformers_optimized"], [55, 1, 1, "", "register_collector"], [55, 1, 1, "", "register_post_hook"]], "torchrl.collectors.utils": [[56, 3, 1, "", "split_trajectories"]], "torchrl.data": [[57, 0, 1, "", "Binary"], [58, 0, 1, "", "Bounded"], [59, 0, 1, "", "Categorical"], [60, 0, 1, "", "Composite"], [61, 0, 1, "", "MultiCategorical"], [62, 0, 1, "", "MultiOneHot"], [63, 0, 1, "", "NonTensor"], [64, 0, 1, "", "OneHot"], [65, 0, 1, "", "PrioritizedReplayBuffer"], [66, 0, 1, "", "RayReplayBuffer"], [67, 0, 1, "", "RemoteTensorDictReplayBuffer"], [68, 0, 1, "", "ReplayBuffer"], [69, 0, 1, "", "ReplayBufferEnsemble"], [70, 0, 1, "", "Stacked"], [71, 0, 1, "", "StackedComposite"], [72, 0, 1, "", "TensorDictPrioritizedReplayBuffer"], [73, 0, 1, "", "TensorDictReplayBuffer"], [74, 0, 1, "", "TensorSpec"], [75, 0, 1, "", "Unbounded"], [76, 0, 1, "", "UnboundedContinuous"], [77, 0, 1, "", "UnboundedDiscrete"]], "torchrl.data.Binary": [[57, 1, 1, "", "assert_is_in"], [57, 1, 1, "", "cardinality"], [57, 1, 1, "", "clear_device_"], [57, 1, 1, "", "clone"], [57, 1, 1, "", "contains"], [57, 1, 1, "", "cpu"], [57, 1, 1, "", "cuda"], [57, 4, 1, "", "device"], [57, 1, 1, "", "encode"], [57, 1, 1, "", "enumerate"], [57, 1, 1, "", "erase_memoize_cache"], [57, 1, 1, "", "expand"], [57, 1, 1, "", "flatten"], [57, 1, 1, "", "implements_for_spec"], [57, 1, 1, "", "index"], [57, 1, 1, "", "is_in"], [57, 1, 1, "", "make_neg_dim"], [57, 1, 1, "", "memoize_encode"], [57, 2, 1, "", "ndim"], [57, 1, 1, "", "ndimension"], [57, 1, 1, "", "one"], [57, 1, 1, "", "ones"], [57, 1, 1, "", "project"], [57, 1, 1, "", "rand"], [57, 1, 1, "", "reshape"], [57, 1, 1, "", "sample"], [57, 1, 1, "", "set_provisional_n"], [57, 1, 1, "", "squeeze"], [57, 1, 1, "", "to"], [57, 1, 1, "", "to_categorical"], [57, 1, 1, "", "to_categorical_spec"], [57, 1, 1, "", "to_numpy"], [57, 1, 1, "", "to_one_hot"], [57, 1, 1, "", "to_one_hot_spec"], [57, 1, 1, "", "type_check"], [57, 1, 1, "", "unflatten"], [57, 1, 1, "", "unsqueeze"], [57, 1, 1, "", "update_mask"], [57, 1, 1, "", "view"], [57, 1, 1, "", "zero"], [57, 1, 1, "", "zeros"]], "torchrl.data.Bounded": [[58, 1, 1, "", "assert_is_in"], [58, 1, 1, "", "cardinality"], [58, 1, 1, "", "clear_device_"], [58, 1, 1, "", "clone"], [58, 1, 1, "", "contains"], [58, 1, 1, "", "cpu"], [58, 1, 1, "", "cuda"], [58, 2, 1, "", "device"], [58, 1, 1, "", "encode"], [58, 1, 1, "", "enumerate"], [58, 1, 1, "", "erase_memoize_cache"], [58, 1, 1, "", "expand"], [58, 1, 1, "", "flatten"], [58, 1, 1, "", "implements_for_spec"], [58, 1, 1, "", "index"], [58, 1, 1, "", "is_in"], [58, 1, 1, "", "make_neg_dim"], [58, 1, 1, "", "memoize_encode"], [58, 2, 1, "", "ndim"], [58, 1, 1, "", "ndimension"], [58, 1, 1, "", "one"], [58, 1, 1, "", "ones"], [58, 1, 1, "", "project"], [58, 1, 1, "", "rand"], [58, 1, 1, "", "reshape"], [58, 1, 1, "", "sample"], [58, 1, 1, "", "squeeze"], [58, 1, 1, "", "to"], [58, 1, 1, "", "to_numpy"], [58, 1, 1, "", "type_check"], [58, 1, 1, "", "unflatten"], [58, 1, 1, "", "unsqueeze"], [58, 1, 1, "", "view"], [58, 1, 1, "", "zero"], [58, 1, 1, "", "zeros"]], "torchrl.data.Categorical": [[59, 1, 1, "", "assert_is_in"], [59, 1, 1, "", "cardinality"], [59, 1, 1, "", "clear_device_"], [59, 1, 1, "", "clone"], [59, 1, 1, "", "contains"], [59, 1, 1, "", "cpu"], [59, 1, 1, "", "cuda"], [59, 4, 1, "", "device"], [59, 1, 1, "", "encode"], [59, 1, 1, "", "enumerate"], [59, 1, 1, "", "erase_memoize_cache"], [59, 1, 1, "", "expand"], [59, 1, 1, "", "flatten"], [59, 1, 1, "", "implements_for_spec"], [59, 1, 1, "", "index"], [59, 1, 1, "", "is_in"], [59, 1, 1, "", "make_neg_dim"], [59, 1, 1, "", "memoize_encode"], [59, 2, 1, "", "ndim"], [59, 1, 1, "", "ndimension"], [59, 1, 1, "", "one"], [59, 1, 1, "", "ones"], [59, 1, 1, "", "project"], [59, 1, 1, "", "rand"], [59, 1, 1, "", "reshape"], [59, 1, 1, "", "sample"], [59, 1, 1, "", "set_provisional_n"], [59, 1, 1, "", "squeeze"], [59, 1, 1, "", "to"], [59, 1, 1, "", "to_categorical"], [59, 1, 1, "", "to_categorical_spec"], [59, 1, 1, "", "to_numpy"], [59, 1, 1, "", "to_one_hot"], [59, 1, 1, "", "to_one_hot_spec"], [59, 1, 1, "", "type_check"], [59, 1, 1, "", "unflatten"], [59, 1, 1, "", "unsqueeze"], [59, 1, 1, "", "update_mask"], [59, 1, 1, "", "view"], [59, 1, 1, "", "zero"], [59, 1, 1, "", "zeros"]], "torchrl.data.Composite": [[60, 1, 1, "", "assert_is_in"], [60, 1, 1, "", "cardinality"], [60, 1, 1, "", "clear_device_"], [60, 1, 1, "", "clone"], [60, 1, 1, "", "contains"], [60, 1, 1, "", "cpu"], [60, 1, 1, "", "cuda"], [60, 2, 1, "", "device"], [60, 1, 1, "", "empty"], [60, 1, 1, "", "encode"], [60, 1, 1, "", "enumerate"], [60, 1, 1, "", "erase_memoize_cache"], [60, 1, 1, "", "expand"], [60, 1, 1, "", "flatten"], [60, 1, 1, "", "get"], [60, 1, 1, "", "implements_for_spec"], [60, 1, 1, "", "index"], [60, 1, 1, "", "is_empty"], [60, 1, 1, "", "is_in"], [60, 1, 1, "", "items"], [60, 1, 1, "", "keys"], [60, 1, 1, "", "lock_"], [60, 1, 1, "", "make_neg_dim"], [60, 1, 1, "", "memoize_encode"], [60, 2, 1, "", "names"], [60, 2, 1, "", "ndim"], [60, 1, 1, "", "ndimension"], [60, 1, 1, "", "one"], [60, 1, 1, "", "ones"], [60, 1, 1, "", "ones_update"], [60, 1, 1, "", "pop"], [60, 1, 1, "", "project"], [60, 1, 1, "", "rand"], [60, 1, 1, "", "rand_update"], [60, 1, 1, "", "refine_names"], [60, 1, 1, "", "reshape"], [60, 1, 1, "", "sample"], [60, 1, 1, "", "separates"], [60, 1, 1, "", "set"], [60, 1, 1, "", "squeeze"], [60, 1, 1, "", "to"], [60, 1, 1, "", "to_numpy"], [60, 1, 1, "", "type_check"], [60, 1, 1, "", "unflatten"], [60, 1, 1, "", "unlock_"], [60, 1, 1, "", "unsqueeze"], [60, 1, 1, "", "values"], [60, 1, 1, "", "view"], [60, 1, 1, "", "zero"], [60, 1, 1, "", "zeros"], [60, 1, 1, "", "zeros_update"]], "torchrl.data.MultiCategorical": [[61, 1, 1, "", "assert_is_in"], [61, 1, 1, "", "cardinality"], [61, 1, 1, "", "clear_device_"], [61, 1, 1, "", "clone"], [61, 1, 1, "", "contains"], [61, 1, 1, "", "cpu"], [61, 1, 1, "", "cuda"], [61, 4, 1, "", "device"], [61, 1, 1, "", "encode"], [61, 1, 1, "", "enumerate"], [61, 1, 1, "", "erase_memoize_cache"], [61, 1, 1, "", "expand"], [61, 1, 1, "", "flatten"], [61, 1, 1, "", "implements_for_spec"], [61, 1, 1, "", "index"], [61, 1, 1, "", "is_in"], [61, 1, 1, "", "make_neg_dim"], [61, 1, 1, "", "memoize_encode"], [61, 2, 1, "", "ndim"], [61, 1, 1, "", "ndimension"], [61, 1, 1, "", "one"], [61, 1, 1, "", "ones"], [61, 1, 1, "", "project"], [61, 1, 1, "", "rand"], [61, 1, 1, "", "reshape"], [61, 1, 1, "", "sample"], [61, 1, 1, "", "set_provisional_n"], [61, 1, 1, "", "squeeze"], [61, 1, 1, "", "to"], [61, 1, 1, "", "to_categorical"], [61, 1, 1, "", "to_categorical_spec"], [61, 1, 1, "", "to_numpy"], [61, 1, 1, "", "to_one_hot"], [61, 1, 1, "", "to_one_hot_spec"], [61, 1, 1, "", "type_check"], [61, 1, 1, "", "unflatten"], [61, 1, 1, "", "unsqueeze"], [61, 1, 1, "", "update_mask"], [61, 1, 1, "", "view"], [61, 1, 1, "", "zero"], [61, 1, 1, "", "zeros"]], "torchrl.data.MultiOneHot": [[62, 1, 1, "", "assert_is_in"], [62, 1, 1, "", "cardinality"], [62, 1, 1, "", "clear_device_"], [62, 1, 1, "", "clone"], [62, 1, 1, "", "contains"], [62, 1, 1, "", "cpu"], [62, 1, 1, "", "cuda"], [62, 4, 1, "", "device"], [62, 1, 1, "", "encode"], [62, 1, 1, "", "enumerate"], [62, 1, 1, "", "erase_memoize_cache"], [62, 1, 1, "", "expand"], [62, 1, 1, "", "flatten"], [62, 1, 1, "", "implements_for_spec"], [62, 1, 1, "", "index"], [62, 1, 1, "", "is_in"], [62, 1, 1, "", "make_neg_dim"], [62, 1, 1, "", "memoize_encode"], [62, 2, 1, "", "ndim"], [62, 1, 1, "", "ndimension"], [62, 1, 1, "", "one"], [62, 1, 1, "", "ones"], [62, 1, 1, "", "project"], [62, 1, 1, "", "rand"], [62, 1, 1, "", "reshape"], [62, 1, 1, "", "sample"], [62, 1, 1, "", "squeeze"], [62, 1, 1, "", "to"], [62, 1, 1, "", "to_categorical"], [62, 1, 1, "", "to_categorical_spec"], [62, 1, 1, "", "to_numpy"], [62, 1, 1, "", "to_one_hot"], [62, 1, 1, "", "to_one_hot_spec"], [62, 1, 1, "", "type_check"], [62, 1, 1, "", "unflatten"], [62, 1, 1, "", "unsqueeze"], [62, 1, 1, "", "update_mask"], [62, 1, 1, "", "view"], [62, 1, 1, "", "zero"], [62, 1, 1, "", "zeros"]], "torchrl.data.NonTensor": [[63, 1, 1, "", "assert_is_in"], [63, 1, 1, "", "cardinality"], [63, 1, 1, "", "clear_device_"], [63, 1, 1, "", "clone"], [63, 1, 1, "", "contains"], [63, 1, 1, "", "cpu"], [63, 1, 1, "", "cuda"], [63, 2, 1, "", "device"], [63, 1, 1, "", "encode"], [63, 1, 1, "", "enumerate"], [63, 1, 1, "", "erase_memoize_cache"], [63, 1, 1, "", "expand"], [63, 1, 1, "", "flatten"], [63, 1, 1, "", "implements_for_spec"], [63, 1, 1, "", "index"], [63, 1, 1, "", "is_in"], [63, 1, 1, "", "make_neg_dim"], [63, 1, 1, "", "memoize_encode"], [63, 2, 1, "", "ndim"], [63, 1, 1, "", "ndimension"], [63, 1, 1, "", "one"], [63, 1, 1, "", "ones"], [63, 1, 1, "", "project"], [63, 1, 1, "", "rand"], [63, 1, 1, "", "reshape"], [63, 1, 1, "", "sample"], [63, 1, 1, "", "squeeze"], [63, 1, 1, "", "to"], [63, 1, 1, "", "to_numpy"], [63, 1, 1, "", "type_check"], [63, 1, 1, "", "unflatten"], [63, 1, 1, "", "unsqueeze"], [63, 1, 1, "", "view"], [63, 1, 1, "", "zero"], [63, 1, 1, "", "zeros"]], "torchrl.data.OneHot": [[64, 1, 1, "", "assert_is_in"], [64, 1, 1, "", "cardinality"], [64, 1, 1, "", "clear_device_"], [64, 1, 1, "", "clone"], [64, 1, 1, "", "contains"], [64, 1, 1, "", "cpu"], [64, 1, 1, "", "cuda"], [64, 4, 1, "", "device"], [64, 1, 1, "", "encode"], [64, 1, 1, "", "enumerate"], [64, 1, 1, "", "erase_memoize_cache"], [64, 1, 1, "", "expand"], [64, 1, 1, "", "flatten"], [64, 1, 1, "", "implements_for_spec"], [64, 1, 1, "", "index"], [64, 1, 1, "", "is_in"], [64, 1, 1, "", "make_neg_dim"], [64, 1, 1, "", "memoize_encode"], [64, 2, 1, "", "ndim"], [64, 1, 1, "", "ndimension"], [64, 1, 1, "", "one"], [64, 1, 1, "", "ones"], [64, 1, 1, "", "project"], [64, 1, 1, "", "rand"], [64, 1, 1, "", "reshape"], [64, 1, 1, "", "sample"], [64, 1, 1, "", "squeeze"], [64, 1, 1, "", "to"], [64, 1, 1, "", "to_categorical"], [64, 1, 1, "", "to_categorical_spec"], [64, 1, 1, "", "to_numpy"], [64, 1, 1, "", "to_one_hot"], [64, 1, 1, "", "to_one_hot_spec"], [64, 1, 1, "", "type_check"], [64, 1, 1, "", "unflatten"], [64, 1, 1, "", "unsqueeze"], [64, 1, 1, "", "update_mask"], [64, 1, 1, "", "view"], [64, 1, 1, "", "zero"], [64, 1, 1, "", "zeros"]], "torchrl.data.PrioritizedReplayBuffer": [[65, 1, 1, "", "add"], [65, 1, 1, "", "append_transform"], [65, 1, 1, "", "as_remote"], [65, 2, 1, "", "batch_size"], [65, 1, 1, "", "dump"], [65, 1, 1, "", "dumps"], [65, 1, 1, "", "empty"], [65, 1, 1, "", "extend"], [65, 2, 1, "", "initialized"], [65, 1, 1, "", "insert_transform"], [65, 1, 1, "", "load"], [65, 1, 1, "", "loads"], [65, 1, 1, "", "next"], [65, 1, 1, "", "register_load_hook"], [65, 1, 1, "", "register_save_hook"], [65, 1, 1, "", "sample"], [65, 2, 1, "", "sampler"], [65, 1, 1, "", "save"], [65, 1, 1, "", "set_sampler"], [65, 1, 1, "", "set_storage"], [65, 1, 1, "", "set_writer"], [65, 2, 1, "", "storage"], [65, 2, 1, "", "transform"], [65, 2, 1, "", "write_count"], [65, 2, 1, "", "writer"]], "torchrl.data.RayReplayBuffer": [[66, 1, 1, "", "add"], [66, 1, 1, "", "append_transform"], [66, 1, 1, "", "as_remote"], [66, 2, 1, "", "batch_size"], [66, 1, 1, "", "close"], [66, 1, 1, "", "dump"], [66, 1, 1, "", "dumps"], [66, 1, 1, "", "empty"], [66, 1, 1, "", "extend"], [66, 2, 1, "", "initialized"], [66, 1, 1, "", "insert_transform"], [66, 1, 1, "", "load"], [66, 1, 1, "", "loads"], [66, 1, 1, "", "next"], [66, 1, 1, "", "register_load_hook"], [66, 1, 1, "", "register_save_hook"], [66, 1, 1, "", "sample"], [66, 2, 1, "", "sampler"], [66, 1, 1, "", "save"], [66, 1, 1, "", "set_sampler"], [66, 1, 1, "", "set_storage"], [66, 1, 1, "", "set_writer"], [66, 2, 1, "", "storage"], [66, 2, 1, "", "transform"], [66, 2, 1, "", "write_count"], [66, 2, 1, "", "writer"]], "torchrl.data.RemoteTensorDictReplayBuffer": [[67, 1, 1, "", "add"], [67, 1, 1, "", "append_transform"], [67, 1, 1, "", "as_remote"], [67, 2, 1, "", "batch_size"], [67, 1, 1, "", "dump"], [67, 1, 1, "", "dumps"], [67, 1, 1, "", "empty"], [67, 1, 1, "", "extend"], [67, 2, 1, "", "initialized"], [67, 1, 1, "", "insert_transform"], [67, 1, 1, "", "load"], [67, 1, 1, "", "loads"], [67, 1, 1, "", "next"], [67, 1, 1, "", "register_load_hook"], [67, 1, 1, "", "register_save_hook"], [67, 1, 1, "", "sample"], [67, 2, 1, "", "sampler"], [67, 1, 1, "", "save"], [67, 1, 1, "", "set_sampler"], [67, 1, 1, "", "set_storage"], [67, 1, 1, "", "set_writer"], [67, 2, 1, "", "storage"], [67, 2, 1, "", "transform"], [67, 2, 1, "", "write_count"], [67, 2, 1, "", "writer"]], "torchrl.data.ReplayBuffer": [[68, 1, 1, "", "add"], [68, 1, 1, "", "append_transform"], [68, 1, 1, "", "as_remote"], [68, 2, 1, "", "batch_size"], [68, 1, 1, "", "dump"], [68, 1, 1, "", "dumps"], [68, 1, 1, "", "empty"], [68, 1, 1, "", "extend"], [68, 2, 1, "", "initialized"], [68, 1, 1, "", "insert_transform"], [68, 1, 1, "", "load"], [68, 1, 1, "", "loads"], [68, 1, 1, "", "next"], [68, 1, 1, "", "register_load_hook"], [68, 1, 1, "", "register_save_hook"], [68, 1, 1, "", "sample"], [68, 2, 1, "", "sampler"], [68, 1, 1, "", "save"], [68, 1, 1, "", "set_sampler"], [68, 1, 1, "", "set_storage"], [68, 1, 1, "", "set_writer"], [68, 2, 1, "", "storage"], [68, 2, 1, "", "transform"], [68, 2, 1, "", "write_count"], [68, 2, 1, "", "writer"]], "torchrl.data.ReplayBufferEnsemble": [[69, 1, 1, "", "add"], [69, 1, 1, "", "append_transform"], [69, 1, 1, "", "as_remote"], [69, 2, 1, "", "batch_size"], [69, 1, 1, "", "dump"], [69, 1, 1, "", "dumps"], [69, 1, 1, "", "empty"], [69, 1, 1, "", "extend"], [69, 2, 1, "", "initialized"], [69, 1, 1, "", "insert_transform"], [69, 1, 1, "", "load"], [69, 1, 1, "", "loads"], [69, 1, 1, "", "next"], [69, 1, 1, "", "register_load_hook"], [69, 1, 1, "", "register_save_hook"], [69, 1, 1, "", "sample"], [69, 2, 1, "", "sampler"], [69, 1, 1, "", "save"], [69, 1, 1, "", "set_sampler"], [69, 1, 1, "", "set_storage"], [69, 1, 1, "", "set_writer"], [69, 2, 1, "", "storage"], [69, 2, 1, "", "transform"], [69, 2, 1, "", "write_count"], [69, 2, 1, "", "writer"]], "torchrl.data.Stacked": [[70, 1, 1, "", "assert_is_in"], [70, 1, 1, "", "cardinality"], [70, 1, 1, "", "clear_device_"], [70, 1, 1, "", "clone"], [70, 1, 1, "", "contains"], [70, 1, 1, "", "cpu"], [70, 1, 1, "", "cuda"], [70, 2, 1, "", "device"], [70, 1, 1, "", "encode"], [70, 1, 1, "", "enumerate"], [70, 1, 1, "", "erase_memoize_cache"], [70, 1, 1, "", "expand"], [70, 1, 1, "", "flatten"], [70, 1, 1, "", "implements_for_spec"], [70, 1, 1, "", "index"], [70, 1, 1, "", "is_in"], [70, 1, 1, "", "make_neg_dim"], [70, 1, 1, "", "memoize_encode"], [70, 2, 1, "", "ndim"], [70, 1, 1, "", "ndimension"], [70, 1, 1, "", "one"], [70, 1, 1, "", "ones"], [70, 1, 1, "", "project"], [70, 1, 1, "", "rand"], [70, 1, 1, "", "reshape"], [70, 1, 1, "", "sample"], [70, 1, 1, "", "squeeze"], [70, 1, 1, "", "to"], [70, 1, 1, "", "to_numpy"], [70, 1, 1, "", "type_check"], [70, 1, 1, "", "unflatten"], [70, 1, 1, "", "unsqueeze"], [70, 1, 1, "", "view"], [70, 1, 1, "", "zero"], [70, 1, 1, "", "zeros"]], "torchrl.data.StackedComposite": [[71, 1, 1, "", "assert_is_in"], [71, 1, 1, "", "cardinality"], [71, 1, 1, "", "clear_device_"], [71, 1, 1, "", "clone"], [71, 1, 1, "", "contains"], [71, 1, 1, "", "cpu"], [71, 1, 1, "", "cuda"], [71, 2, 1, "", "device"], [71, 1, 1, "", "empty"], [71, 1, 1, "", "encode"], [71, 1, 1, "", "enumerate"], [71, 1, 1, "", "erase_memoize_cache"], [71, 1, 1, "", "expand"], [71, 1, 1, "", "flatten"], [71, 1, 1, "", "get"], [71, 1, 1, "", "implements_for_spec"], [71, 1, 1, "", "index"], [71, 1, 1, "", "is_empty"], [71, 1, 1, "", "is_in"], [71, 1, 1, "", "items"], [71, 1, 1, "", "keys"], [71, 1, 1, "", "lock_"], [71, 1, 1, "", "make_neg_dim"], [71, 1, 1, "", "memoize_encode"], [71, 2, 1, "", "names"], [71, 2, 1, "", "ndim"], [71, 1, 1, "", "ndimension"], [71, 1, 1, "", "one"], [71, 1, 1, "", "ones"], [71, 1, 1, "", "ones_update"], [71, 1, 1, "", "pop"], [71, 1, 1, "", "project"], [71, 1, 1, "", "rand"], [71, 1, 1, "", "rand_update"], [71, 1, 1, "", "refine_names"], [71, 1, 1, "", "reshape"], [71, 1, 1, "", "sample"], [71, 1, 1, "", "separates"], [71, 1, 1, "", "set"], [71, 1, 1, "", "squeeze"], [71, 1, 1, "", "to"], [71, 1, 1, "", "to_numpy"], [71, 1, 1, "", "type_check"], [71, 1, 1, "", "unflatten"], [71, 1, 1, "", "unlock_"], [71, 1, 1, "", "unsqueeze"], [71, 1, 1, "", "values"], [71, 1, 1, "", "view"], [71, 1, 1, "", "zero"], [71, 1, 1, "", "zeros"], [71, 1, 1, "", "zeros_update"]], "torchrl.data.TensorDictPrioritizedReplayBuffer": [[72, 1, 1, "", "add"], [72, 1, 1, "", "append_transform"], [72, 1, 1, "", "as_remote"], [72, 2, 1, "", "batch_size"], [72, 1, 1, "", "dump"], [72, 1, 1, "", "dumps"], [72, 1, 1, "", "empty"], [72, 1, 1, "", "extend"], [72, 2, 1, "", "initialized"], [72, 1, 1, "", "insert_transform"], [72, 1, 1, "", "load"], [72, 1, 1, "", "loads"], [72, 1, 1, "", "next"], [72, 1, 1, "", "register_load_hook"], [72, 1, 1, "", "register_save_hook"], [72, 1, 1, "", "sample"], [72, 2, 1, "", "sampler"], [72, 1, 1, "", "save"], [72, 1, 1, "", "set_sampler"], [72, 1, 1, "", "set_storage"], [72, 1, 1, "", "set_writer"], [72, 2, 1, "", "storage"], [72, 2, 1, "", "transform"], [72, 2, 1, "", "write_count"], [72, 2, 1, "", "writer"]], "torchrl.data.TensorDictReplayBuffer": [[73, 1, 1, "", "add"], [73, 1, 1, "", "append_transform"], [73, 1, 1, "", "as_remote"], [73, 2, 1, "", "batch_size"], [73, 1, 1, "", "dump"], [73, 1, 1, "", "dumps"], [73, 1, 1, "", "empty"], [73, 1, 1, "", "extend"], [73, 2, 1, "", "initialized"], [73, 1, 1, "", "insert_transform"], [73, 1, 1, "", "load"], [73, 1, 1, "", "loads"], [73, 1, 1, "", "next"], [73, 1, 1, "", "register_load_hook"], [73, 1, 1, "", "register_save_hook"], [73, 1, 1, "", "sample"], [73, 2, 1, "", "sampler"], [73, 1, 1, "", "save"], [73, 1, 1, "", "set_sampler"], [73, 1, 1, "", "set_storage"], [73, 1, 1, "", "set_writer"], [73, 2, 1, "", "storage"], [73, 2, 1, "", "transform"], [73, 2, 1, "", "write_count"], [73, 2, 1, "", "writer"]], "torchrl.data.TensorSpec": [[74, 1, 1, "", "assert_is_in"], [74, 1, 1, "", "cardinality"], [74, 1, 1, "", "clear_device_"], [74, 1, 1, "", "clone"], [74, 1, 1, "", "contains"], [74, 1, 1, "", "cpu"], [74, 1, 1, "", "cuda"], [74, 2, 1, "", "device"], [74, 1, 1, "", "encode"], [74, 1, 1, "", "enumerate"], [74, 1, 1, "", "erase_memoize_cache"], [74, 1, 1, "", "expand"], [74, 1, 1, "", "flatten"], [74, 1, 1, "", "implements_for_spec"], [74, 1, 1, "", "index"], [74, 1, 1, "", "is_in"], [74, 1, 1, "", "make_neg_dim"], [74, 1, 1, "", "memoize_encode"], [74, 2, 1, "", "ndim"], [74, 1, 1, "", "ndimension"], [74, 1, 1, "", "one"], [74, 1, 1, "", "ones"], [74, 1, 1, "", "project"], [74, 1, 1, "", "rand"], [74, 1, 1, "", "reshape"], [74, 1, 1, "", "sample"], [74, 1, 1, "", "squeeze"], [74, 1, 1, "", "to"], [74, 1, 1, "", "to_numpy"], [74, 1, 1, "", "type_check"], [74, 1, 1, "", "unflatten"], [74, 1, 1, "", "unsqueeze"], [74, 1, 1, "", "view"], [74, 1, 1, "", "zero"], [74, 1, 1, "", "zeros"]], "torchrl.data.Unbounded": [[75, 1, 1, "", "assert_is_in"], [75, 1, 1, "", "cardinality"], [75, 1, 1, "", "clear_device_"], [75, 1, 1, "", "clone"], [75, 1, 1, "", "contains"], [75, 1, 1, "", "cpu"], [75, 1, 1, "", "cuda"], [75, 2, 1, "", "device"], [75, 1, 1, "", "encode"], [75, 1, 1, "", "enumerate"], [75, 1, 1, "", "erase_memoize_cache"], [75, 1, 1, "", "expand"], [75, 1, 1, "", "flatten"], [75, 1, 1, "", "implements_for_spec"], [75, 1, 1, "", "index"], [75, 1, 1, "", "is_in"], [75, 1, 1, "", "make_neg_dim"], [75, 1, 1, "", "memoize_encode"], [75, 2, 1, "", "ndim"], [75, 1, 1, "", "ndimension"], [75, 1, 1, "", "one"], [75, 1, 1, "", "ones"], [75, 1, 1, "", "project"], [75, 1, 1, "", "rand"], [75, 1, 1, "", "reshape"], [75, 1, 1, "", "sample"], [75, 1, 1, "", "squeeze"], [75, 1, 1, "", "to"], [75, 1, 1, "", "to_numpy"], [75, 1, 1, "", "type_check"], [75, 1, 1, "", "unflatten"], [75, 1, 1, "", "unsqueeze"], [75, 1, 1, "", "view"], [75, 1, 1, "", "zero"], [75, 1, 1, "", "zeros"]], "torchrl.data.UnboundedContinuous": [[76, 1, 1, "", "assert_is_in"], [76, 1, 1, "", "cardinality"], [76, 1, 1, "", "clear_device_"], [76, 1, 1, "", "clone"], [76, 1, 1, "", "contains"], [76, 1, 1, "", "cpu"], [76, 1, 1, "", "cuda"], [76, 2, 1, "", "device"], [76, 1, 1, "", "encode"], [76, 1, 1, "", "enumerate"], [76, 1, 1, "", "erase_memoize_cache"], [76, 1, 1, "", "expand"], [76, 1, 1, "", "flatten"], [76, 1, 1, "", "implements_for_spec"], [76, 1, 1, "", "index"], [76, 1, 1, "", "is_in"], [76, 1, 1, "", "make_neg_dim"], [76, 1, 1, "", "memoize_encode"], [76, 2, 1, "", "ndim"], [76, 1, 1, "", "ndimension"], [76, 1, 1, "", "one"], [76, 1, 1, "", "ones"], [76, 1, 1, "", "project"], [76, 1, 1, "", "rand"], [76, 1, 1, "", "reshape"], [76, 1, 1, "", "sample"], [76, 1, 1, "", "squeeze"], [76, 1, 1, "", "to"], [76, 1, 1, "", "to_numpy"], [76, 1, 1, "", "type_check"], [76, 1, 1, "", "unflatten"], [76, 1, 1, "", "unsqueeze"], [76, 1, 1, "", "view"], [76, 1, 1, "", "zero"], [76, 1, 1, "", "zeros"]], "torchrl.data.UnboundedDiscrete": [[77, 1, 1, "", "assert_is_in"], [77, 1, 1, "", "cardinality"], [77, 1, 1, "", "clear_device_"], [77, 1, 1, "", "clone"], [77, 1, 1, "", "contains"], [77, 1, 1, "", "cpu"], [77, 1, 1, "", "cuda"], [77, 2, 1, "", "device"], [77, 1, 1, "", "encode"], [77, 1, 1, "", "enumerate"], [77, 1, 1, "", "erase_memoize_cache"], [77, 1, 1, "", "expand"], [77, 1, 1, "", "flatten"], [77, 1, 1, "", "implements_for_spec"], [77, 1, 1, "", "index"], [77, 1, 1, "", "is_in"], [77, 1, 1, "", "make_neg_dim"], [77, 1, 1, "", "memoize_encode"], [77, 2, 1, "", "ndim"], [77, 1, 1, "", "ndimension"], [77, 1, 1, "", "one"], [77, 1, 1, "", "ones"], [77, 1, 1, "", "project"], [77, 1, 1, "", "rand"], [77, 1, 1, "", "reshape"], [77, 1, 1, "", "sample"], [77, 1, 1, "", "squeeze"], [77, 1, 1, "", "to"], [77, 1, 1, "", "to_numpy"], [77, 1, 1, "", "type_check"], [77, 1, 1, "", "unflatten"], [77, 1, 1, "", "unsqueeze"], [77, 1, 1, "", "view"], [77, 1, 1, "", "zero"], [77, 1, 1, "", "zeros"]], "torchrl.data.datasets": [[78, 0, 1, "", "AtariDQNExperienceReplay"], [79, 0, 1, "", "D4RLExperienceReplay"], [80, 0, 1, "", "GenDGRLExperienceReplay"], [81, 0, 1, "", "MinariExperienceReplay"], [82, 0, 1, "", "OpenMLExperienceReplay"], [83, 0, 1, "", "OpenXExperienceReplay"], [84, 0, 1, "", "RobosetExperienceReplay"], [85, 0, 1, "", "VD4RLExperienceReplay"]], "torchrl.data.datasets.AtariDQNExperienceReplay": [[78, 1, 1, "", "add"], [78, 1, 1, "", "append_transform"], [78, 1, 1, "", "as_remote"], [78, 2, 1, "", "batch_size"], [78, 2, 1, "", "data_path"], [78, 2, 1, "", "data_path_root"], [78, 1, 1, "", "delete"], [78, 1, 1, "", "dump"], [78, 1, 1, "", "dumps"], [78, 1, 1, "", "empty"], [78, 1, 1, "", "extend"], [78, 2, 1, "", "initialized"], [78, 1, 1, "", "insert_transform"], [78, 1, 1, "", "load"], [78, 1, 1, "", "loads"], [78, 1, 1, "", "next"], [78, 1, 1, "", "preprocess"], [78, 1, 1, "", "register_load_hook"], [78, 1, 1, "", "register_save_hook"], [78, 1, 1, "", "sample"], [78, 2, 1, "", "sampler"], [78, 1, 1, "", "save"], [78, 1, 1, "", "set_sampler"], [78, 1, 1, "", "set_storage"], [78, 1, 1, "", "set_writer"], [78, 2, 1, "", "storage"], [78, 2, 1, "", "transform"], [78, 2, 1, "", "write_count"], [78, 2, 1, "", "writer"]], "torchrl.data.datasets.D4RLExperienceReplay": [[79, 1, 1, "", "add"], [79, 1, 1, "", "append_transform"], [79, 1, 1, "", "as_remote"], [79, 2, 1, "", "batch_size"], [79, 2, 1, "", "data_path"], [79, 2, 1, "", "data_path_root"], [79, 1, 1, "", "delete"], [79, 1, 1, "", "dump"], [79, 1, 1, "", "dumps"], [79, 1, 1, "", "empty"], [79, 1, 1, "", "extend"], [79, 2, 1, "", "initialized"], [79, 1, 1, "", "insert_transform"], [79, 1, 1, "", "load"], [79, 1, 1, "", "loads"], [79, 1, 1, "", "next"], [79, 1, 1, "", "preprocess"], [79, 1, 1, "", "register_load_hook"], [79, 1, 1, "", "register_save_hook"], [79, 1, 1, "", "sample"], [79, 2, 1, "", "sampler"], [79, 1, 1, "", "save"], [79, 1, 1, "", "set_sampler"], [79, 1, 1, "", "set_storage"], [79, 1, 1, "", "set_writer"], [79, 2, 1, "", "storage"], [79, 2, 1, "", "transform"], [79, 2, 1, "", "write_count"], [79, 2, 1, "", "writer"]], "torchrl.data.datasets.GenDGRLExperienceReplay": [[80, 1, 1, "", "add"], [80, 1, 1, "", "append_transform"], [80, 1, 1, "", "as_remote"], [80, 2, 1, "", "batch_size"], [80, 2, 1, "", "data_path"], [80, 2, 1, "", "data_path_root"], [80, 1, 1, "", "delete"], [80, 1, 1, "", "dump"], [80, 1, 1, "", "dumps"], [80, 1, 1, "", "empty"], [80, 1, 1, "", "extend"], [80, 2, 1, "", "initialized"], [80, 1, 1, "", "insert_transform"], [80, 1, 1, "", "load"], [80, 1, 1, "", "loads"], [80, 1, 1, "", "next"], [80, 1, 1, "", "preprocess"], [80, 1, 1, "", "register_load_hook"], [80, 1, 1, "", "register_save_hook"], [80, 1, 1, "", "sample"], [80, 2, 1, "", "sampler"], [80, 1, 1, "", "save"], [80, 1, 1, "", "set_sampler"], [80, 1, 1, "", "set_storage"], [80, 1, 1, "", "set_writer"], [80, 2, 1, "", "storage"], [80, 2, 1, "", "transform"], [80, 2, 1, "", "write_count"], [80, 2, 1, "", "writer"]], "torchrl.data.datasets.MinariExperienceReplay": [[81, 1, 1, "", "add"], [81, 1, 1, "", "append_transform"], [81, 1, 1, "", "as_remote"], [81, 2, 1, "", "batch_size"], [81, 2, 1, "", "data_path"], [81, 2, 1, "", "data_path_root"], [81, 1, 1, "", "delete"], [81, 1, 1, "", "dump"], [81, 1, 1, "", "dumps"], [81, 1, 1, "", "empty"], [81, 1, 1, "", "extend"], [81, 2, 1, "", "initialized"], [81, 1, 1, "", "insert_transform"], [81, 1, 1, "", "load"], [81, 1, 1, "", "loads"], [81, 1, 1, "", "next"], [81, 1, 1, "", "preprocess"], [81, 1, 1, "", "register_load_hook"], [81, 1, 1, "", "register_save_hook"], [81, 1, 1, "", "sample"], [81, 2, 1, "", "sampler"], [81, 1, 1, "", "save"], [81, 1, 1, "", "set_sampler"], [81, 1, 1, "", "set_storage"], [81, 1, 1, "", "set_writer"], [81, 2, 1, "", "storage"], [81, 2, 1, "", "transform"], [81, 2, 1, "", "write_count"], [81, 2, 1, "", "writer"]], "torchrl.data.datasets.OpenMLExperienceReplay": [[82, 1, 1, "", "add"], [82, 1, 1, "", "append_transform"], [82, 1, 1, "", "as_remote"], [82, 2, 1, "", "batch_size"], [82, 2, 1, "", "data_path"], [82, 2, 1, "", "data_path_root"], [82, 1, 1, "", "delete"], [82, 1, 1, "", "dump"], [82, 1, 1, "", "dumps"], [82, 1, 1, "", "empty"], [82, 1, 1, "", "extend"], [82, 2, 1, "", "initialized"], [82, 1, 1, "", "insert_transform"], [82, 1, 1, "", "load"], [82, 1, 1, "", "loads"], [82, 1, 1, "", "next"], [82, 1, 1, "", "preprocess"], [82, 1, 1, "", "register_load_hook"], [82, 1, 1, "", "register_save_hook"], [82, 1, 1, "", "sample"], [82, 2, 1, "", "sampler"], [82, 1, 1, "", "save"], [82, 1, 1, "", "set_sampler"], [82, 1, 1, "", "set_storage"], [82, 1, 1, "", "set_writer"], [82, 2, 1, "", "storage"], [82, 2, 1, "", "transform"], [82, 2, 1, "", "write_count"], [82, 2, 1, "", "writer"]], "torchrl.data.datasets.OpenXExperienceReplay": [[83, 1, 1, "", "add"], [83, 1, 1, "", "append_transform"], [83, 1, 1, "", "as_remote"], [83, 2, 1, "", "batch_size"], [83, 2, 1, "", "data_path"], [83, 2, 1, "", "data_path_root"], [83, 1, 1, "", "delete"], [83, 1, 1, "", "dump"], [83, 1, 1, "", "dumps"], [83, 1, 1, "", "empty"], [83, 1, 1, "", "extend"], [83, 2, 1, "", "initialized"], [83, 1, 1, "", "insert_transform"], [83, 1, 1, "", "load"], [83, 1, 1, "", "loads"], [83, 1, 1, "", "next"], [83, 1, 1, "", "preprocess"], [83, 1, 1, "", "register_load_hook"], [83, 1, 1, "", "register_save_hook"], [83, 1, 1, "", "sample"], [83, 2, 1, "", "sampler"], [83, 1, 1, "", "save"], [83, 1, 1, "", "set_sampler"], [83, 1, 1, "", "set_storage"], [83, 1, 1, "", "set_writer"], [83, 2, 1, "", "storage"], [83, 2, 1, "", "transform"], [83, 2, 1, "", "write_count"], [83, 2, 1, "", "writer"]], "torchrl.data.datasets.RobosetExperienceReplay": [[84, 1, 1, "", "add"], [84, 1, 1, "", "append_transform"], [84, 1, 1, "", "as_remote"], [84, 2, 1, "", "batch_size"], [84, 2, 1, "", "data_path"], [84, 2, 1, "", "data_path_root"], [84, 1, 1, "", "delete"], [84, 1, 1, "", "dump"], [84, 1, 1, "", "dumps"], [84, 1, 1, "", "empty"], [84, 1, 1, "", "extend"], [84, 2, 1, "", "initialized"], [84, 1, 1, "", "insert_transform"], [84, 1, 1, "", "load"], [84, 1, 1, "", "loads"], [84, 1, 1, "", "next"], [84, 1, 1, "", "preprocess"], [84, 1, 1, "", "register_load_hook"], [84, 1, 1, "", "register_save_hook"], [84, 1, 1, "", "sample"], [84, 2, 1, "", "sampler"], [84, 1, 1, "", "save"], [84, 1, 1, "", "set_sampler"], [84, 1, 1, "", "set_storage"], [84, 1, 1, "", "set_writer"], [84, 2, 1, "", "storage"], [84, 2, 1, "", "transform"], [84, 2, 1, "", "write_count"], [84, 2, 1, "", "writer"]], "torchrl.data.datasets.VD4RLExperienceReplay": [[85, 1, 1, "", "add"], [85, 1, 1, "", "append_transform"], [85, 1, 1, "", "as_remote"], [85, 2, 1, "", "batch_size"], [85, 2, 1, "", "data_path"], [85, 2, 1, "", "data_path_root"], [85, 1, 1, "", "delete"], [85, 1, 1, "", "dump"], [85, 1, 1, "", "dumps"], [85, 1, 1, "", "empty"], [85, 1, 1, "", "extend"], [85, 2, 1, "", "initialized"], [85, 1, 1, "", "insert_transform"], [85, 1, 1, "", "load"], [85, 1, 1, "", "loads"], [85, 1, 1, "", "next"], [85, 1, 1, "", "preprocess"], [85, 1, 1, "", "register_load_hook"], [85, 1, 1, "", "register_save_hook"], [85, 1, 1, "", "sample"], [85, 2, 1, "", "sampler"], [85, 1, 1, "", "save"], [85, 1, 1, "", "set_sampler"], [85, 1, 1, "", "set_storage"], [85, 1, 1, "", "set_writer"], [85, 2, 1, "", "storage"], [85, 2, 1, "", "transform"], [85, 2, 1, "", "write_count"], [85, 2, 1, "", "writer"]], "torchrl.data.llm": [[86, 0, 1, "", "ContentBase"], [87, 0, 1, "", "History"], [88, 0, 1, "", "TopKRewardSelector"], [89, 0, 1, "", "add_chat_template"]], "torchrl.data.llm.ContentBase": [[86, 1, 1, "", "cat"], [86, 2, 1, "", "device"], [86, 1, 1, "", "dumps"], [86, 1, 1, "", "fields"], [86, 1, 1, "", "from_any"], [86, 1, 1, "", "from_dataclass"], [86, 1, 1, "", "from_h5"], [86, 1, 1, "", "from_modules"], [86, 1, 1, "", "from_namedtuple"], [86, 1, 1, "", "from_pytree"], [86, 1, 1, "", "from_remote_init"], [86, 1, 1, "", "from_struct_array"], [86, 1, 1, "", "from_tensordict"], [86, 1, 1, "", "from_tuple"], [86, 1, 1, "", "fromkeys"], [86, 1, 1, "", "get"], [86, 1, 1, "", "lazy_stack"], [86, 1, 1, "", "load"], [86, 1, 1, "", "load_"], [86, 1, 1, "", "load_memmap"], [86, 1, 1, "", "load_state_dict"], [86, 1, 1, "", "maybe_dense_stack"], [86, 1, 1, "", "memmap"], [86, 1, 1, "", "memmap_"], [86, 1, 1, "", "memmap_like"], [86, 1, 1, "", "memmap_refresh_"], [86, 1, 1, "", "save"], [86, 1, 1, "", "set"], [86, 1, 1, "", "stack"], [86, 1, 1, "", "state_dict"], [86, 1, 1, "", "to_tensordict"], [86, 1, 1, "", "unbind"]], "torchrl.data.llm.History": [[87, 1, 1, "", "append"], [87, 1, 1, "", "apply_chat_template"], [87, 1, 1, "", "cat"], [87, 1, 1, "", "default_spec"], [87, 2, 1, "", "device"], [87, 1, 1, "", "dumps"], [87, 1, 1, "", "fields"], [87, 1, 1, "", "from_any"], [87, 1, 1, "", "from_chats"], [87, 1, 1, "", "from_dataclass"], [87, 1, 1, "", "from_h5"], [87, 1, 1, "", "from_modules"], [87, 1, 1, "", "from_namedtuple"], [87, 1, 1, "", "from_pytree"], [87, 1, 1, "", "from_remote_init"], [87, 1, 1, "", "from_struct_array"], [87, 1, 1, "", "from_tensordict"], [87, 1, 1, "", "from_text"], [87, 1, 1, "", "from_tuple"], [87, 1, 1, "", "fromkeys"], [87, 1, 1, "", "get"], [87, 1, 1, "", "lazy_stack"], [87, 1, 1, "", "load"], [87, 1, 1, "", "load_"], [87, 1, 1, "", "load_memmap"], [87, 1, 1, "", "load_state_dict"], [87, 1, 1, "", "maybe_dense_stack"], [87, 1, 1, "", "memmap"], [87, 1, 1, "", "memmap_"], [87, 1, 1, "", "memmap_like"], [87, 1, 1, "", "memmap_refresh_"], [87, 1, 1, "", "save"], [87, 1, 1, "", "set"], [87, 1, 1, "", "stack"], [87, 1, 1, "", "state_dict"], [87, 1, 1, "", "to_tensordict"], [87, 1, 1, "", "unbind"]], "torchrl.data.llm.TopKRewardSelector": [[88, 1, 1, "", "add_module"], [88, 1, 1, "", "apply"], [88, 1, 1, "", "bfloat16"], [88, 1, 1, "", "buffers"], [88, 1, 1, "", "children"], [88, 1, 1, "", "close"], [88, 2, 1, "", "collector"], [88, 1, 1, "", "compile"], [88, 2, 1, "", "container"], [88, 1, 1, "", "cpu"], [88, 1, 1, "", "cuda"], [88, 1, 1, "", "double"], [88, 1, 1, "", "eval"], [88, 1, 1, "", "extra_repr"], [88, 1, 1, "", "float"], [88, 1, 1, "", "forward"], [88, 1, 1, "", "get_buffer"], [88, 1, 1, "", "get_extra_state"], [88, 1, 1, "", "get_parameter"], [88, 1, 1, "", "get_submodule"], [88, 1, 1, "", "half"], [88, 1, 1, "", "init"], [88, 1, 1, "", "inv"], [88, 1, 1, "", "ipu"], [88, 1, 1, "", "load_state_dict"], [88, 1, 1, "", "modules"], [88, 1, 1, "", "mtia"], [88, 1, 1, "", "named_buffers"], [88, 1, 1, "", "named_children"], [88, 1, 1, "", "named_modules"], [88, 1, 1, "", "named_parameters"], [88, 1, 1, "", "parameters"], [88, 2, 1, "", "parent"], [88, 1, 1, "", "register_backward_hook"], [88, 1, 1, "", "register_buffer"], [88, 1, 1, "", "register_forward_hook"], [88, 1, 1, "", "register_forward_pre_hook"], [88, 1, 1, "", "register_full_backward_hook"], [88, 1, 1, "", "register_full_backward_pre_hook"], [88, 1, 1, "", "register_load_state_dict_post_hook"], [88, 1, 1, "", "register_load_state_dict_pre_hook"], [88, 1, 1, "", "register_module"], [88, 1, 1, "", "register_parameter"], [88, 1, 1, "", "register_state_dict_post_hook"], [88, 1, 1, "", "register_state_dict_pre_hook"], [88, 1, 1, "", "requires_grad_"], [88, 1, 1, "", "set_extra_state"], [88, 1, 1, "", "set_submodule"], [88, 1, 1, "", "share_memory"], [88, 1, 1, "", "state_dict"], [88, 1, 1, "", "to"], [88, 1, 1, "", "to_empty"], [88, 1, 1, "", "train"], [88, 1, 1, "", "transform_action_spec"], [88, 1, 1, "", "transform_done_spec"], [88, 1, 1, "", "transform_env_batch_size"], [88, 1, 1, "", "transform_env_device"], [88, 1, 1, "", "transform_input_spec"], [88, 1, 1, "", "transform_observation_spec"], [88, 1, 1, "", "transform_output_spec"], [88, 1, 1, "", "transform_reward_spec"], [88, 1, 1, "", "transform_state_spec"], [88, 1, 1, "", "type"], [88, 1, 1, "", "xpu"], [88, 1, 1, "", "zero_grad"]], "torchrl.data.replay_buffers": [[90, 0, 1, "", "CompressedListStorage"], [91, 0, 1, "", "CompressedListStorageCheckpointer"], [92, 0, 1, "", "FlatStorageCheckpointer"], [93, 0, 1, "", "H5StorageCheckpointer"], [94, 0, 1, "", "ImmutableDatasetWriter"], [95, 0, 1, "", "LazyMemmapStorage"], [96, 0, 1, "", "LazyStackStorage"], [97, 0, 1, "", "LazyTensorStorage"], [98, 0, 1, "", "ListStorage"], [99, 0, 1, "", "ListStorageCheckpointer"], [100, 0, 1, "", "NestedStorageCheckpointer"], [101, 0, 1, "", "PrioritizedSampler"], [102, 0, 1, "", "PrioritizedSliceSampler"], [103, 0, 1, "", "RandomSampler"], [104, 0, 1, "", "RoundRobinWriter"], [105, 0, 1, "", "Sampler"], [106, 0, 1, "", "SamplerEnsemble"], [107, 0, 1, "", "SamplerWithoutReplacement"], [108, 0, 1, "", "SliceSampler"], [109, 0, 1, "", "SliceSamplerWithoutReplacement"], [110, 0, 1, "", "Storage"], [111, 0, 1, "", "StorageCheckpointerBase"], [112, 0, 1, "", "StorageEnsemble"], [113, 0, 1, "", "StorageEnsembleCheckpointer"], [114, 0, 1, "", "TensorDictMaxValueWriter"], [115, 0, 1, "", "TensorDictRoundRobinWriter"], [116, 0, 1, "", "TensorStorage"], [117, 0, 1, "", "TensorStorageCheckpointer"], [118, 0, 1, "", "Writer"], [119, 0, 1, "", "WriterEnsemble"]], "torchrl.data.replay_buffers.CompressedListStorage": [[90, 1, 1, "", "attach"], [90, 1, 1, "", "bytes"], [90, 1, 1, "", "dump"], [90, 1, 1, "", "load"], [90, 1, 1, "", "load_state_dict"], [90, 1, 1, "", "save"], [90, 1, 1, "", "state_dict"], [90, 1, 1, "", "to_bytestream"]], "torchrl.data.replay_buffers.CompressedListStorageCheckpointer": [[91, 1, 1, "", "dumps"], [91, 1, 1, "", "loads"]], "torchrl.data.replay_buffers.ImmutableDatasetWriter": [[94, 1, 1, "", "add"], [94, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.LazyMemmapStorage": [[95, 1, 1, "", "attach"], [95, 1, 1, "", "cleanup"], [95, 1, 1, "", "dump"], [95, 1, 1, "", "load"], [95, 1, 1, "", "save"]], "torchrl.data.replay_buffers.LazyStackStorage": [[96, 1, 1, "", "attach"], [96, 1, 1, "", "dump"], [96, 1, 1, "", "load"], [96, 1, 1, "", "save"]], "torchrl.data.replay_buffers.LazyTensorStorage": [[97, 1, 1, "", "attach"], [97, 1, 1, "", "dump"], [97, 1, 1, "", "load"], [97, 1, 1, "", "save"]], "torchrl.data.replay_buffers.ListStorage": [[98, 1, 1, "", "attach"], [98, 1, 1, "", "dump"], [98, 1, 1, "", "load"], [98, 1, 1, "", "save"]], "torchrl.data.replay_buffers.PrioritizedSampler": [[101, 1, 1, "", "update_priority"]], "torchrl.data.replay_buffers.PrioritizedSliceSampler": [[102, 1, 1, "", "update_priority"]], "torchrl.data.replay_buffers.RoundRobinWriter": [[104, 1, 1, "", "add"], [104, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.Storage": [[110, 1, 1, "", "attach"], [110, 1, 1, "", "dump"], [110, 1, 1, "", "load"], [110, 1, 1, "", "save"]], "torchrl.data.replay_buffers.StorageEnsemble": [[112, 1, 1, "", "attach"], [112, 1, 1, "", "dump"], [112, 1, 1, "", "load"], [112, 1, 1, "", "save"]], "torchrl.data.replay_buffers.TensorDictMaxValueWriter": [[114, 1, 1, "", "add"], [114, 1, 1, "", "extend"], [114, 1, 1, "", "get_insert_index"]], "torchrl.data.replay_buffers.TensorDictRoundRobinWriter": [[115, 1, 1, "", "add"], [115, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.TensorStorage": [[116, 1, 1, "", "attach"], [116, 1, 1, "", "dump"], [116, 1, 1, "", "load"], [116, 1, 1, "", "save"]], "torchrl.data.replay_buffers.Writer": [[118, 1, 1, "", "add"], [118, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.WriterEnsemble": [[119, 1, 1, "", "add"], [119, 1, 1, "", "extend"]], "torchrl.envs": [[120, 0, 1, "", "AsyncEnvPool"], [121, 3, 1, "", "BraxEnv"], [122, 3, 1, "", "BraxWrapper"], [123, 0, 1, "", "ChessEnv"], [124, 3, 1, "", "DMControlEnv"], [125, 3, 1, "", "DMControlWrapper"], [126, 0, 1, "", "EnvBase"], [127, 0, 1, "", "EnvCreator"], [128, 0, 1, "", "EnvMetaData"], [129, 3, 1, "", "GymEnv"], [130, 0, 1, "", "GymLikeEnv"], [131, 3, 1, "", "GymWrapper"], [132, 3, 1, "", "HabitatEnv"], [133, 3, 1, "", "IsaacGymEnv"], [134, 3, 1, "", "IsaacGymWrapper"], [135, 3, 1, "", "IsaacLabWrapper"], [136, 3, 1, "", "JumanjiEnv"], [137, 3, 1, "", "JumanjiWrapper"], [138, 0, 1, "", "LLMHashingEnv"], [139, 3, 1, "", "MOGymEnv"], [140, 3, 1, "", "MOGymWrapper"], [141, 3, 1, "", "MarlGroupMapType"], [142, 3, 1, "", "MeltingpotEnv"], [143, 3, 1, "", "MeltingpotWrapper"], [144, 3, 1, "", "ModelBasedEnvBase"], [145, 3, 1, "", "MultiThreadedEnv"], [146, 3, 1, "", "MultiThreadedEnvWrapper"], [147, 3, 1, "", "OpenMLEnv"], [148, 3, 1, "", "OpenSpielEnv"], [149, 3, 1, "", "OpenSpielWrapper"], [150, 0, 1, "", "ParallelEnv"], [151, 0, 1, "", "PendulumEnv"], [152, 3, 1, "", "PettingZooEnv"], [153, 3, 1, "", "PettingZooWrapper"], [154, 0, 1, "", "ProcessorAsyncEnvPool"], [155, 3, 1, "", "RoboHiveEnv"], [156, 3, 1, "", "SMACv2Env"], [157, 3, 1, "", "SMACv2Wrapper"], [158, 0, 1, "", "SerialEnv"], [159, 0, 1, "", "ThreadingAsyncEnvPool"], [160, 0, 1, "", "TicTacToeEnv"], [161, 3, 1, "", "UnityMLAgentsEnv"], [162, 3, 1, "", "UnityMLAgentsWrapper"], [163, 3, 1, "", "VmasEnv"], [164, 3, 1, "", "VmasWrapper"], [165, 3, 1, "", "check_env_specs"], [166, 3, 1, "", "check_marl_grouping"], [167, 3, 1, "", "exploration_type"], [168, 3, 1, "", "get_available_libraries"], [169, 3, 1, "", "gym_backend"], [206, 3, 1, "", "make_composite_from_td"], [144, 1, 1, "", "rand_step"], [209, 3, 1, "", "register_gym_spec_conversion"], [144, 1, 1, "", "reset"], [144, 1, 1, "", "rollout"], [210, 3, 1, "", "set_exploration_type"], [211, 3, 1, "", "set_gym_backend"], [144, 1, 1, "", "set_seed"], [144, 1, 1, "", "step"], [212, 3, 1, "", "step_mdp"], [213, 3, 1, "", "terminated_or_truncated"]], "torchrl.envs.AsyncEnvPool": [[120, 2, 1, "", "action_key"], [120, 2, 1, "", "action_keys"], [120, 2, 1, "", "action_spec"], [120, 2, 1, "", "action_spec_unbatched"], [120, 1, 1, "", "add_module"], [120, 1, 1, "", "add_truncated_keys"], [120, 1, 1, "", "all_actions"], [120, 1, 1, "", "any_done"], [120, 1, 1, "", "append_transform"], [120, 1, 1, "", "apply"], [120, 1, 1, "", "auto_specs_"], [120, 2, 1, "", "batch_dims"], [120, 2, 1, "", "batch_locked"], [120, 2, 1, "", "batch_size"], [120, 1, 1, "", "bfloat16"], [120, 1, 1, "", "buffers"], [120, 1, 1, "", "cardinality"], [120, 1, 1, "", "check_env_specs"], [120, 1, 1, "", "children"], [120, 2, 1, "", "collector"], [120, 1, 1, "", "compile"], [120, 1, 1, "", "cpu"], [120, 1, 1, "", "cuda"], [120, 2, 1, "", "done_key"], [120, 2, 1, "", "done_keys"], [120, 2, 1, "", "done_keys_groups"], [120, 2, 1, "", "done_spec"], [120, 2, 1, "", "done_spec_unbatched"], [120, 1, 1, "", "double"], [120, 1, 1, "", "empty_cache"], [120, 2, 1, "", "env_batch_sizes"], [120, 1, 1, "", "eval"], [120, 1, 1, "", "extra_repr"], [120, 1, 1, "", "fake_tensordict"], [120, 1, 1, "", "float"], [120, 1, 1, "", "forward"], [120, 2, 1, "", "full_action_spec"], [120, 2, 1, "", "full_action_spec_unbatched"], [120, 2, 1, "", "full_done_spec"], [120, 2, 1, "", "full_done_spec_unbatched"], [120, 2, 1, "", "full_observation_spec_unbatched"], [120, 2, 1, "", "full_reward_spec"], [120, 2, 1, "", "full_reward_spec_unbatched"], [120, 2, 1, "", "full_state_spec"], [120, 2, 1, "", "full_state_spec_unbatched"], [120, 1, 1, "", "get_buffer"], [120, 1, 1, "", "get_extra_state"], [120, 1, 1, "", "get_parameter"], [120, 1, 1, "", "get_submodule"], [120, 1, 1, "", "half"], [120, 2, 1, "", "input_spec"], [120, 2, 1, "", "input_spec_unbatched"], [120, 1, 1, "", "ipu"], [120, 2, 1, "", "is_spec_locked"], [120, 1, 1, "", "load_state_dict"], [120, 1, 1, "", "maybe_reset"], [120, 1, 1, "", "modules"], [120, 1, 1, "", "mtia"], [120, 1, 1, "", "named_buffers"], [120, 1, 1, "", "named_children"], [120, 1, 1, "", "named_modules"], [120, 1, 1, "", "named_parameters"], [120, 2, 1, "", "observation_keys"], [120, 2, 1, "", "observation_spec"], [120, 2, 1, "", "observation_spec_unbatched"], [120, 2, 1, "", "output_spec"], [120, 2, 1, "", "output_spec_unbatched"], [120, 1, 1, "", "parameters"], [120, 1, 1, "", "rand_action"], [120, 1, 1, "", "rand_step"], [120, 1, 1, "", "register_backward_hook"], [120, 1, 1, "", "register_buffer"], [120, 1, 1, "", "register_collector"], [120, 1, 1, "", "register_forward_hook"], [120, 1, 1, "", "register_forward_pre_hook"], [120, 1, 1, "", "register_full_backward_hook"], [120, 1, 1, "", "register_full_backward_pre_hook"], [120, 1, 1, "", "register_gym"], [120, 1, 1, "", "register_load_state_dict_post_hook"], [120, 1, 1, "", "register_load_state_dict_pre_hook"], [120, 1, 1, "", "register_module"], [120, 1, 1, "", "register_parameter"], [120, 1, 1, "", "register_state_dict_post_hook"], [120, 1, 1, "", "register_state_dict_pre_hook"], [120, 1, 1, "", "requires_grad_"], [120, 1, 1, "", "reset"], [120, 2, 1, "", "reset_keys"], [120, 2, 1, "", "reward_key"], [120, 2, 1, "", "reward_keys"], [120, 2, 1, "", "reward_spec"], [120, 2, 1, "", "reward_spec_unbatched"], [120, 1, 1, "", "rollout"], [120, 1, 1, "", "set_extra_state"], [120, 1, 1, "", "set_seed"], [120, 1, 1, "", "set_spec_lock_"], [120, 1, 1, "", "set_submodule"], [120, 2, 1, "", "shape"], [120, 1, 1, "", "share_memory"], [120, 2, 1, "", "specs"], [120, 1, 1, "", "state_dict"], [120, 2, 1, "", "state_keys"], [120, 2, 1, "", "state_spec"], [120, 2, 1, "", "state_spec_unbatched"], [120, 1, 1, "", "step"], [120, 1, 1, "", "step_and_maybe_reset"], [120, 1, 1, "", "step_mdp"], [120, 1, 1, "", "to"], [120, 1, 1, "", "to_empty"], [120, 1, 1, "", "train"], [120, 1, 1, "", "type"], [120, 1, 1, "", "xpu"], [120, 1, 1, "", "zero_grad"]], "torchrl.envs.ChessEnv": [[123, 2, 1, "", "action_key"], [123, 2, 1, "", "action_keys"], [123, 2, 1, "", "action_spec"], [123, 2, 1, "", "action_spec_unbatched"], [123, 1, 1, "", "add_module"], [123, 1, 1, "", "add_truncated_keys"], [123, 1, 1, "", "all_actions"], [123, 1, 1, "", "any_done"], [123, 1, 1, "", "append_transform"], [123, 1, 1, "", "apply"], [123, 1, 1, "", "auto_specs_"], [123, 2, 1, "", "batch_dims"], [123, 2, 1, "", "batch_locked"], [123, 2, 1, "", "batch_size"], [123, 1, 1, "", "bfloat16"], [123, 1, 1, "", "buffers"], [123, 1, 1, "", "cardinality"], [123, 1, 1, "", "check_env_specs"], [123, 1, 1, "", "children"], [123, 2, 1, "", "collector"], [123, 1, 1, "", "compile"], [123, 1, 1, "", "cpu"], [123, 1, 1, "", "cuda"], [123, 2, 1, "", "done_key"], [123, 2, 1, "", "done_keys"], [123, 2, 1, "", "done_keys_groups"], [123, 2, 1, "", "done_spec"], [123, 2, 1, "", "done_spec_unbatched"], [123, 1, 1, "", "double"], [123, 1, 1, "", "empty_cache"], [123, 1, 1, "", "eval"], [123, 1, 1, "", "extra_repr"], [123, 1, 1, "", "fake_tensordict"], [123, 1, 1, "", "float"], [123, 1, 1, "", "forward"], [123, 2, 1, "", "full_action_spec"], [123, 2, 1, "", "full_action_spec_unbatched"], [123, 2, 1, "", "full_done_spec"], [123, 2, 1, "", "full_done_spec_unbatched"], [123, 2, 1, "", "full_observation_spec_unbatched"], [123, 2, 1, "", "full_reward_spec"], [123, 2, 1, "", "full_reward_spec_unbatched"], [123, 2, 1, "", "full_state_spec"], [123, 2, 1, "", "full_state_spec_unbatched"], [123, 1, 1, "", "get_buffer"], [123, 1, 1, "", "get_extra_state"], [123, 1, 1, "", "get_legal_moves"], [123, 1, 1, "", "get_parameter"], [123, 1, 1, "", "get_submodule"], [123, 1, 1, "", "half"], [123, 2, 1, "", "input_spec"], [123, 2, 1, "", "input_spec_unbatched"], [123, 1, 1, "", "ipu"], [123, 2, 1, "", "is_spec_locked"], [123, 1, 1, "", "load_state_dict"], [123, 1, 1, "", "maybe_reset"], [123, 1, 1, "", "modules"], [123, 1, 1, "", "mtia"], [123, 1, 1, "", "named_buffers"], [123, 1, 1, "", "named_children"], [123, 1, 1, "", "named_modules"], [123, 1, 1, "", "named_parameters"], [123, 2, 1, "", "observation_keys"], [123, 2, 1, "", "observation_spec"], [123, 2, 1, "", "observation_spec_unbatched"], [123, 2, 1, "", "output_spec"], [123, 2, 1, "", "output_spec_unbatched"], [123, 1, 1, "", "parameters"], [123, 1, 1, "", "rand_action"], [123, 1, 1, "", "rand_step"], [123, 1, 1, "", "register_backward_hook"], [123, 1, 1, "", "register_buffer"], [123, 1, 1, "", "register_collector"], [123, 1, 1, "", "register_forward_hook"], [123, 1, 1, "", "register_forward_pre_hook"], [123, 1, 1, "", "register_full_backward_hook"], [123, 1, 1, "", "register_full_backward_pre_hook"], [123, 1, 1, "", "register_gym"], [123, 1, 1, "", "register_load_state_dict_post_hook"], [123, 1, 1, "", "register_load_state_dict_pre_hook"], [123, 1, 1, "", "register_module"], [123, 1, 1, "", "register_parameter"], [123, 1, 1, "", "register_state_dict_post_hook"], [123, 1, 1, "", "register_state_dict_pre_hook"], [123, 1, 1, "", "requires_grad_"], [123, 1, 1, "", "reset"], [123, 2, 1, "", "reset_keys"], [123, 2, 1, "", "reward_key"], [123, 2, 1, "", "reward_keys"], [123, 2, 1, "", "reward_spec"], [123, 2, 1, "", "reward_spec_unbatched"], [123, 1, 1, "", "rollout"], [123, 1, 1, "", "set_extra_state"], [123, 1, 1, "", "set_seed"], [123, 1, 1, "", "set_spec_lock_"], [123, 1, 1, "", "set_submodule"], [123, 2, 1, "", "shape"], [123, 1, 1, "", "share_memory"], [123, 2, 1, "", "specs"], [123, 1, 1, "", "state_dict"], [123, 2, 1, "", "state_keys"], [123, 2, 1, "", "state_spec"], [123, 2, 1, "", "state_spec_unbatched"], [123, 1, 1, "", "step"], [123, 1, 1, "", "step_and_maybe_reset"], [123, 1, 1, "", "step_mdp"], [123, 1, 1, "", "to"], [123, 1, 1, "", "to_empty"], [123, 1, 1, "", "train"], [123, 1, 1, "", "type"], [123, 1, 1, "", "xpu"], [123, 1, 1, "", "zero_grad"]], "torchrl.envs.EnvBase": [[126, 2, 1, "", "action_key"], [126, 2, 1, "", "action_keys"], [126, 2, 1, "", "action_spec"], [126, 2, 1, "", "action_spec_unbatched"], [126, 1, 1, "", "add_module"], [126, 1, 1, "", "add_truncated_keys"], [126, 1, 1, "", "all_actions"], [126, 1, 1, "", "any_done"], [126, 1, 1, "", "append_transform"], [126, 1, 1, "", "apply"], [126, 1, 1, "", "auto_specs_"], [126, 2, 1, "", "batch_dims"], [126, 2, 1, "", "batch_locked"], [126, 2, 1, "", "batch_size"], [126, 1, 1, "", "bfloat16"], [126, 1, 1, "", "buffers"], [126, 1, 1, "", "cardinality"], [126, 1, 1, "", "check_env_specs"], [126, 1, 1, "", "children"], [126, 2, 1, "", "collector"], [126, 1, 1, "", "compile"], [126, 1, 1, "", "cpu"], [126, 1, 1, "", "cuda"], [126, 2, 1, "", "done_key"], [126, 2, 1, "", "done_keys"], [126, 2, 1, "", "done_keys_groups"], [126, 2, 1, "", "done_spec"], [126, 2, 1, "", "done_spec_unbatched"], [126, 1, 1, "", "double"], [126, 1, 1, "", "empty_cache"], [126, 1, 1, "", "eval"], [126, 1, 1, "", "extra_repr"], [126, 1, 1, "", "fake_tensordict"], [126, 1, 1, "", "float"], [126, 1, 1, "", "forward"], [126, 2, 1, "", "full_action_spec"], [126, 2, 1, "", "full_action_spec_unbatched"], [126, 2, 1, "", "full_done_spec"], [126, 2, 1, "", "full_done_spec_unbatched"], [126, 2, 1, "", "full_observation_spec_unbatched"], [126, 2, 1, "", "full_reward_spec"], [126, 2, 1, "", "full_reward_spec_unbatched"], [126, 2, 1, "", "full_state_spec"], [126, 2, 1, "", "full_state_spec_unbatched"], [126, 1, 1, "", "get_buffer"], [126, 1, 1, "", "get_extra_state"], [126, 1, 1, "", "get_parameter"], [126, 1, 1, "", "get_submodule"], [126, 1, 1, "", "half"], [126, 2, 1, "", "input_spec"], [126, 2, 1, "", "input_spec_unbatched"], [126, 1, 1, "", "ipu"], [126, 2, 1, "", "is_spec_locked"], [126, 1, 1, "", "load_state_dict"], [126, 1, 1, "", "maybe_reset"], [126, 1, 1, "", "modules"], [126, 1, 1, "", "mtia"], [126, 1, 1, "", "named_buffers"], [126, 1, 1, "", "named_children"], [126, 1, 1, "", "named_modules"], [126, 1, 1, "", "named_parameters"], [126, 2, 1, "", "observation_keys"], [126, 2, 1, "", "observation_spec"], [126, 2, 1, "", "observation_spec_unbatched"], [126, 2, 1, "", "output_spec"], [126, 2, 1, "", "output_spec_unbatched"], [126, 1, 1, "", "parameters"], [126, 1, 1, "", "rand_action"], [126, 1, 1, "id0", "rand_step"], [126, 1, 1, "", "register_backward_hook"], [126, 1, 1, "", "register_buffer"], [126, 1, 1, "", "register_collector"], [126, 1, 1, "", "register_forward_hook"], [126, 1, 1, "", "register_forward_pre_hook"], [126, 1, 1, "", "register_full_backward_hook"], [126, 1, 1, "", "register_full_backward_pre_hook"], [126, 1, 1, "", "register_gym"], [126, 1, 1, "", "register_load_state_dict_post_hook"], [126, 1, 1, "", "register_load_state_dict_pre_hook"], [126, 1, 1, "", "register_module"], [126, 1, 1, "", "register_parameter"], [126, 1, 1, "", "register_state_dict_post_hook"], [126, 1, 1, "", "register_state_dict_pre_hook"], [126, 1, 1, "", "requires_grad_"], [126, 1, 1, "id1", "reset"], [126, 2, 1, "", "reset_keys"], [126, 2, 1, "", "reward_key"], [126, 2, 1, "", "reward_keys"], [126, 2, 1, "", "reward_spec"], [126, 2, 1, "", "reward_spec_unbatched"], [126, 1, 1, "id2", "rollout"], [126, 1, 1, "", "set_extra_state"], [126, 1, 1, "id3", "set_seed"], [126, 1, 1, "", "set_spec_lock_"], [126, 1, 1, "", "set_submodule"], [126, 2, 1, "", "shape"], [126, 1, 1, "", "share_memory"], [126, 2, 1, "", "specs"], [126, 1, 1, "", "state_dict"], [126, 2, 1, "", "state_keys"], [126, 2, 1, "", "state_spec"], [126, 2, 1, "", "state_spec_unbatched"], [126, 1, 1, "id4", "step"], [126, 1, 1, "", "step_and_maybe_reset"], [126, 1, 1, "", "step_mdp"], [126, 1, 1, "", "to"], [126, 1, 1, "", "to_empty"], [126, 1, 1, "", "train"], [126, 1, 1, "", "type"], [126, 1, 1, "", "xpu"], [126, 1, 1, "", "zero_grad"]], "torchrl.envs.EnvCreator": [[127, 1, 1, "", "make_variant"]], "torchrl.envs.GymLikeEnv": [[130, 2, 1, "", "action_key"], [130, 2, 1, "", "action_keys"], [130, 2, 1, "", "action_spec"], [130, 2, 1, "", "action_spec_unbatched"], [130, 1, 1, "", "add_module"], [130, 1, 1, "", "add_truncated_keys"], [130, 1, 1, "", "all_actions"], [130, 1, 1, "", "any_done"], [130, 1, 1, "", "append_transform"], [130, 1, 1, "", "apply"], [130, 1, 1, "", "auto_register_info_dict"], [130, 1, 1, "", "auto_specs_"], [130, 2, 1, "", "batch_dims"], [130, 2, 1, "", "batch_locked"], [130, 2, 1, "", "batch_size"], [130, 1, 1, "", "bfloat16"], [130, 1, 1, "", "buffers"], [130, 1, 1, "", "cardinality"], [130, 1, 1, "", "check_env_specs"], [130, 1, 1, "", "children"], [130, 1, 1, "", "close"], [130, 2, 1, "", "collector"], [130, 1, 1, "", "compile"], [130, 1, 1, "", "cpu"], [130, 1, 1, "", "cuda"], [130, 2, 1, "", "done_key"], [130, 2, 1, "", "done_keys"], [130, 2, 1, "", "done_keys_groups"], [130, 2, 1, "", "done_spec"], [130, 2, 1, "", "done_spec_unbatched"], [130, 1, 1, "", "double"], [130, 1, 1, "", "empty_cache"], [130, 1, 1, "", "eval"], [130, 1, 1, "", "extra_repr"], [130, 1, 1, "", "fake_tensordict"], [130, 1, 1, "", "fast_encoding"], [130, 1, 1, "", "float"], [130, 1, 1, "", "forward"], [130, 2, 1, "", "full_action_spec"], [130, 2, 1, "", "full_action_spec_unbatched"], [130, 2, 1, "", "full_done_spec"], [130, 2, 1, "", "full_done_spec_unbatched"], [130, 2, 1, "", "full_observation_spec_unbatched"], [130, 2, 1, "", "full_reward_spec"], [130, 2, 1, "", "full_reward_spec_unbatched"], [130, 2, 1, "", "full_state_spec"], [130, 2, 1, "", "full_state_spec_unbatched"], [130, 1, 1, "", "get_buffer"], [130, 1, 1, "", "get_extra_state"], [130, 1, 1, "", "get_parameter"], [130, 1, 1, "", "get_submodule"], [130, 1, 1, "", "half"], [130, 2, 1, "", "input_spec"], [130, 2, 1, "", "input_spec_unbatched"], [130, 1, 1, "", "ipu"], [130, 2, 1, "", "is_spec_locked"], [130, 1, 1, "", "load_state_dict"], [130, 1, 1, "", "maybe_reset"], [130, 1, 1, "", "modules"], [130, 1, 1, "", "mtia"], [130, 1, 1, "", "named_buffers"], [130, 1, 1, "", "named_children"], [130, 1, 1, "", "named_modules"], [130, 1, 1, "", "named_parameters"], [130, 2, 1, "", "observation_keys"], [130, 2, 1, "", "observation_spec"], [130, 2, 1, "", "observation_spec_unbatched"], [130, 2, 1, "", "output_spec"], [130, 2, 1, "", "output_spec_unbatched"], [130, 1, 1, "", "parameters"], [130, 1, 1, "", "rand_action"], [130, 1, 1, "", "rand_step"], [130, 1, 1, "", "read_action"], [130, 1, 1, "", "read_done"], [130, 1, 1, "", "read_obs"], [130, 1, 1, "", "read_reward"], [130, 1, 1, "", "register_backward_hook"], [130, 1, 1, "", "register_buffer"], [130, 1, 1, "", "register_collector"], [130, 1, 1, "", "register_forward_hook"], [130, 1, 1, "", "register_forward_pre_hook"], [130, 1, 1, "", "register_full_backward_hook"], [130, 1, 1, "", "register_full_backward_pre_hook"], [130, 1, 1, "", "register_gym"], [130, 1, 1, "", "register_load_state_dict_post_hook"], [130, 1, 1, "", "register_load_state_dict_pre_hook"], [130, 1, 1, "", "register_module"], [130, 1, 1, "", "register_parameter"], [130, 1, 1, "", "register_state_dict_post_hook"], [130, 1, 1, "", "register_state_dict_pre_hook"], [130, 1, 1, "", "requires_grad_"], [130, 1, 1, "", "reset"], [130, 2, 1, "", "reset_keys"], [130, 2, 1, "", "reward_key"], [130, 2, 1, "", "reward_keys"], [130, 2, 1, "", "reward_spec"], [130, 2, 1, "", "reward_spec_unbatched"], [130, 1, 1, "", "rollout"], [130, 1, 1, "", "set_extra_state"], [130, 1, 1, "", "set_info_dict_reader"], [130, 1, 1, "", "set_seed"], [130, 1, 1, "", "set_spec_lock_"], [130, 1, 1, "", "set_submodule"], [130, 2, 1, "", "shape"], [130, 1, 1, "", "share_memory"], [130, 2, 1, "", "specs"], [130, 1, 1, "", "state_dict"], [130, 2, 1, "", "state_keys"], [130, 2, 1, "", "state_spec"], [130, 2, 1, "", "state_spec_unbatched"], [130, 1, 1, "", "step"], [130, 1, 1, "", "step_and_maybe_reset"], [130, 1, 1, "", "step_mdp"], [130, 1, 1, "", "to"], [130, 1, 1, "", "to_empty"], [130, 1, 1, "", "train"], [130, 1, 1, "", "type"], [130, 1, 1, "", "xpu"], [130, 1, 1, "", "zero_grad"]], "torchrl.envs.LLMHashingEnv": [[138, 2, 1, "", "action_key"], [138, 2, 1, "", "action_keys"], [138, 2, 1, "", "action_spec"], [138, 2, 1, "", "action_spec_unbatched"], [138, 1, 1, "", "add_module"], [138, 1, 1, "", "add_truncated_keys"], [138, 1, 1, "", "all_actions"], [138, 1, 1, "", "any_done"], [138, 1, 1, "", "append_transform"], [138, 1, 1, "", "apply"], [138, 1, 1, "", "auto_specs_"], [138, 2, 1, "", "batch_dims"], [138, 2, 1, "", "batch_locked"], [138, 2, 1, "", "batch_size"], [138, 1, 1, "", "bfloat16"], [138, 1, 1, "", "buffers"], [138, 1, 1, "", "cardinality"], [138, 1, 1, "", "check_env_specs"], [138, 1, 1, "", "children"], [138, 2, 1, "", "collector"], [138, 1, 1, "", "compile"], [138, 1, 1, "", "cpu"], [138, 1, 1, "", "cuda"], [138, 2, 1, "", "done_key"], [138, 2, 1, "", "done_keys"], [138, 2, 1, "", "done_keys_groups"], [138, 2, 1, "", "done_spec"], [138, 2, 1, "", "done_spec_unbatched"], [138, 1, 1, "", "double"], [138, 1, 1, "", "empty_cache"], [138, 1, 1, "", "eval"], [138, 1, 1, "", "extra_repr"], [138, 1, 1, "", "fake_tensordict"], [138, 1, 1, "", "float"], [138, 1, 1, "", "forward"], [138, 2, 1, "", "full_action_spec"], [138, 2, 1, "", "full_action_spec_unbatched"], [138, 2, 1, "", "full_done_spec"], [138, 2, 1, "", "full_done_spec_unbatched"], [138, 2, 1, "", "full_observation_spec_unbatched"], [138, 2, 1, "", "full_reward_spec"], [138, 2, 1, "", "full_reward_spec_unbatched"], [138, 2, 1, "", "full_state_spec"], [138, 2, 1, "", "full_state_spec_unbatched"], [138, 1, 1, "", "get_buffer"], [138, 1, 1, "", "get_extra_state"], [138, 1, 1, "", "get_parameter"], [138, 1, 1, "", "get_submodule"], [138, 1, 1, "", "half"], [138, 2, 1, "", "input_spec"], [138, 2, 1, "", "input_spec_unbatched"], [138, 1, 1, "", "ipu"], [138, 2, 1, "", "is_spec_locked"], [138, 1, 1, "", "load_state_dict"], [138, 1, 1, "", "make_tensordict"], [138, 1, 1, "", "maybe_reset"], [138, 1, 1, "", "modules"], [138, 1, 1, "", "mtia"], [138, 1, 1, "", "named_buffers"], [138, 1, 1, "", "named_children"], [138, 1, 1, "", "named_modules"], [138, 1, 1, "", "named_parameters"], [138, 2, 1, "", "observation_keys"], [138, 2, 1, "", "observation_spec"], [138, 2, 1, "", "observation_spec_unbatched"], [138, 2, 1, "", "output_spec"], [138, 2, 1, "", "output_spec_unbatched"], [138, 1, 1, "", "parameters"], [138, 1, 1, "", "rand_action"], [138, 1, 1, "", "rand_step"], [138, 1, 1, "", "register_backward_hook"], [138, 1, 1, "", "register_buffer"], [138, 1, 1, "", "register_collector"], [138, 1, 1, "", "register_forward_hook"], [138, 1, 1, "", "register_forward_pre_hook"], [138, 1, 1, "", "register_full_backward_hook"], [138, 1, 1, "", "register_full_backward_pre_hook"], [138, 1, 1, "", "register_gym"], [138, 1, 1, "", "register_load_state_dict_post_hook"], [138, 1, 1, "", "register_load_state_dict_pre_hook"], [138, 1, 1, "", "register_module"], [138, 1, 1, "", "register_parameter"], [138, 1, 1, "", "register_state_dict_post_hook"], [138, 1, 1, "", "register_state_dict_pre_hook"], [138, 1, 1, "", "requires_grad_"], [138, 1, 1, "", "reset"], [138, 2, 1, "", "reset_keys"], [138, 2, 1, "", "reward_key"], [138, 2, 1, "", "reward_keys"], [138, 2, 1, "", "reward_spec"], [138, 2, 1, "", "reward_spec_unbatched"], [138, 1, 1, "", "rollout"], [138, 1, 1, "", "set_extra_state"], [138, 1, 1, "", "set_seed"], [138, 1, 1, "", "set_spec_lock_"], [138, 1, 1, "", "set_submodule"], [138, 2, 1, "", "shape"], [138, 1, 1, "", "share_memory"], [138, 2, 1, "", "specs"], [138, 1, 1, "", "state_dict"], [138, 2, 1, "", "state_keys"], [138, 2, 1, "", "state_spec"], [138, 2, 1, "", "state_spec_unbatched"], [138, 1, 1, "", "step"], [138, 1, 1, "", "step_and_maybe_reset"], [138, 1, 1, "", "step_mdp"], [138, 1, 1, "", "to"], [138, 1, 1, "", "to_empty"], [138, 1, 1, "", "train"], [138, 1, 1, "", "type"], [138, 1, 1, "", "xpu"], [138, 1, 1, "", "zero_grad"]], "torchrl.envs.ParallelEnv": [[150, 2, 1, "", "action_key"], [150, 2, 1, "", "action_keys"], [150, 2, 1, "", "action_spec"], [150, 2, 1, "", "action_spec_unbatched"], [150, 1, 1, "", "add_module"], [150, 1, 1, "", "add_truncated_keys"], [150, 1, 1, "", "all_actions"], [150, 1, 1, "", "any_done"], [150, 1, 1, "", "append_transform"], [150, 1, 1, "", "apply"], [150, 1, 1, "", "auto_specs_"], [150, 2, 1, "", "batch_dims"], [150, 2, 1, "", "batch_locked"], [150, 2, 1, "", "batch_size"], [150, 1, 1, "", "bfloat16"], [150, 1, 1, "", "buffers"], [150, 1, 1, "", "cardinality"], [150, 1, 1, "", "check_env_specs"], [150, 1, 1, "", "children"], [150, 2, 1, "", "collector"], [150, 1, 1, "", "compile"], [150, 1, 1, "", "cpu"], [150, 1, 1, "", "cuda"], [150, 2, 1, "", "done_key"], [150, 2, 1, "", "done_keys"], [150, 2, 1, "", "done_keys_groups"], [150, 2, 1, "", "done_spec"], [150, 2, 1, "", "done_spec_unbatched"], [150, 1, 1, "", "double"], [150, 1, 1, "", "empty_cache"], [150, 1, 1, "", "eval"], [150, 1, 1, "", "extra_repr"], [150, 1, 1, "", "fake_tensordict"], [150, 1, 1, "", "float"], [150, 1, 1, "", "forward"], [150, 2, 1, "", "full_action_spec"], [150, 2, 1, "", "full_action_spec_unbatched"], [150, 2, 1, "", "full_done_spec"], [150, 2, 1, "", "full_done_spec_unbatched"], [150, 2, 1, "", "full_observation_spec_unbatched"], [150, 2, 1, "", "full_reward_spec"], [150, 2, 1, "", "full_reward_spec_unbatched"], [150, 2, 1, "", "full_state_spec"], [150, 2, 1, "", "full_state_spec_unbatched"], [150, 1, 1, "", "get_buffer"], [150, 1, 1, "", "get_extra_state"], [150, 1, 1, "", "get_parameter"], [150, 1, 1, "", "get_submodule"], [150, 1, 1, "", "half"], [150, 2, 1, "", "input_spec"], [150, 2, 1, "", "input_spec_unbatched"], [150, 1, 1, "", "ipu"], [150, 2, 1, "", "is_spec_locked"], [150, 1, 1, "", "load_state_dict"], [150, 1, 1, "", "maybe_reset"], [150, 1, 1, "", "modules"], [150, 1, 1, "", "mtia"], [150, 1, 1, "", "named_buffers"], [150, 1, 1, "", "named_children"], [150, 1, 1, "", "named_modules"], [150, 1, 1, "", "named_parameters"], [150, 2, 1, "", "observation_keys"], [150, 2, 1, "", "observation_spec"], [150, 2, 1, "", "observation_spec_unbatched"], [150, 2, 1, "", "output_spec"], [150, 2, 1, "", "output_spec_unbatched"], [150, 1, 1, "", "parameters"], [150, 1, 1, "", "rand_action"], [150, 1, 1, "", "rand_step"], [150, 1, 1, "", "register_backward_hook"], [150, 1, 1, "", "register_buffer"], [150, 1, 1, "", "register_collector"], [150, 1, 1, "", "register_forward_hook"], [150, 1, 1, "", "register_forward_pre_hook"], [150, 1, 1, "", "register_full_backward_hook"], [150, 1, 1, "", "register_full_backward_pre_hook"], [150, 1, 1, "", "register_gym"], [150, 1, 1, "", "register_load_state_dict_post_hook"], [150, 1, 1, "", "register_load_state_dict_pre_hook"], [150, 1, 1, "", "register_module"], [150, 1, 1, "", "register_parameter"], [150, 1, 1, "", "register_state_dict_post_hook"], [150, 1, 1, "", "register_state_dict_pre_hook"], [150, 1, 1, "", "requires_grad_"], [150, 1, 1, "", "reset"], [150, 2, 1, "", "reset_keys"], [150, 2, 1, "", "reward_key"], [150, 2, 1, "", "reward_keys"], [150, 2, 1, "", "reward_spec"], [150, 2, 1, "", "reward_spec_unbatched"], [150, 1, 1, "", "rollout"], [150, 1, 1, "", "set_extra_state"], [150, 1, 1, "", "set_seed"], [150, 1, 1, "", "set_spec_lock_"], [150, 1, 1, "", "set_submodule"], [150, 2, 1, "", "shape"], [150, 1, 1, "", "share_memory"], [150, 2, 1, "", "specs"], [150, 1, 1, "", "state_dict"], [150, 2, 1, "", "state_keys"], [150, 2, 1, "", "state_spec"], [150, 2, 1, "", "state_spec_unbatched"], [150, 1, 1, "", "step"], [150, 1, 1, "", "step_and_maybe_reset"], [150, 1, 1, "", "step_mdp"], [150, 1, 1, "", "to"], [150, 1, 1, "", "to_empty"], [150, 1, 1, "", "train"], [150, 1, 1, "", "type"], [150, 1, 1, "", "update_kwargs"], [150, 1, 1, "", "xpu"], [150, 1, 1, "", "zero_grad"]], "torchrl.envs.PendulumEnv": [[151, 2, 1, "", "action_key"], [151, 2, 1, "", "action_keys"], [151, 2, 1, "", "action_spec"], [151, 2, 1, "", "action_spec_unbatched"], [151, 1, 1, "", "add_module"], [151, 1, 1, "", "add_truncated_keys"], [151, 1, 1, "", "all_actions"], [151, 1, 1, "", "any_done"], [151, 1, 1, "", "append_transform"], [151, 1, 1, "", "apply"], [151, 1, 1, "", "auto_specs_"], [151, 2, 1, "", "batch_dims"], [151, 2, 1, "", "batch_size"], [151, 1, 1, "", "bfloat16"], [151, 1, 1, "", "buffers"], [151, 1, 1, "", "cardinality"], [151, 1, 1, "", "check_env_specs"], [151, 1, 1, "", "children"], [151, 2, 1, "", "collector"], [151, 1, 1, "", "compile"], [151, 1, 1, "", "cpu"], [151, 1, 1, "", "cuda"], [151, 2, 1, "", "done_key"], [151, 2, 1, "", "done_keys"], [151, 2, 1, "", "done_keys_groups"], [151, 2, 1, "", "done_spec"], [151, 2, 1, "", "done_spec_unbatched"], [151, 1, 1, "", "double"], [151, 1, 1, "", "empty_cache"], [151, 1, 1, "", "eval"], [151, 1, 1, "", "extra_repr"], [151, 1, 1, "", "fake_tensordict"], [151, 1, 1, "", "float"], [151, 1, 1, "", "forward"], [151, 2, 1, "", "full_action_spec"], [151, 2, 1, "", "full_action_spec_unbatched"], [151, 2, 1, "", "full_done_spec"], [151, 2, 1, "", "full_done_spec_unbatched"], [151, 2, 1, "", "full_observation_spec_unbatched"], [151, 2, 1, "", "full_reward_spec"], [151, 2, 1, "", "full_reward_spec_unbatched"], [151, 2, 1, "", "full_state_spec"], [151, 2, 1, "", "full_state_spec_unbatched"], [151, 1, 1, "", "gen_params"], [151, 1, 1, "", "get_buffer"], [151, 1, 1, "", "get_extra_state"], [151, 1, 1, "", "get_parameter"], [151, 1, 1, "", "get_submodule"], [151, 1, 1, "", "half"], [151, 2, 1, "", "input_spec"], [151, 2, 1, "", "input_spec_unbatched"], [151, 1, 1, "", "ipu"], [151, 2, 1, "", "is_spec_locked"], [151, 1, 1, "", "load_state_dict"], [151, 1, 1, "", "maybe_reset"], [151, 1, 1, "", "modules"], [151, 1, 1, "", "mtia"], [151, 1, 1, "", "named_buffers"], [151, 1, 1, "", "named_children"], [151, 1, 1, "", "named_modules"], [151, 1, 1, "", "named_parameters"], [151, 2, 1, "", "observation_keys"], [151, 2, 1, "", "observation_spec"], [151, 2, 1, "", "observation_spec_unbatched"], [151, 2, 1, "", "output_spec"], [151, 2, 1, "", "output_spec_unbatched"], [151, 1, 1, "", "parameters"], [151, 1, 1, "", "rand_action"], [151, 1, 1, "", "rand_step"], [151, 1, 1, "", "register_backward_hook"], [151, 1, 1, "", "register_buffer"], [151, 1, 1, "", "register_collector"], [151, 1, 1, "", "register_forward_hook"], [151, 1, 1, "", "register_forward_pre_hook"], [151, 1, 1, "", "register_full_backward_hook"], [151, 1, 1, "", "register_full_backward_pre_hook"], [151, 1, 1, "", "register_gym"], [151, 1, 1, "", "register_load_state_dict_post_hook"], [151, 1, 1, "", "register_load_state_dict_pre_hook"], [151, 1, 1, "", "register_module"], [151, 1, 1, "", "register_parameter"], [151, 1, 1, "", "register_state_dict_post_hook"], [151, 1, 1, "", "register_state_dict_pre_hook"], [151, 1, 1, "", "requires_grad_"], [151, 1, 1, "", "reset"], [151, 2, 1, "", "reset_keys"], [151, 2, 1, "", "reward_key"], [151, 2, 1, "", "reward_keys"], [151, 2, 1, "", "reward_spec"], [151, 2, 1, "", "reward_spec_unbatched"], [151, 1, 1, "", "rollout"], [151, 1, 1, "", "set_extra_state"], [151, 1, 1, "", "set_seed"], [151, 1, 1, "", "set_spec_lock_"], [151, 1, 1, "", "set_submodule"], [151, 2, 1, "", "shape"], [151, 1, 1, "", "share_memory"], [151, 2, 1, "", "specs"], [151, 1, 1, "", "state_dict"], [151, 2, 1, "", "state_keys"], [151, 2, 1, "", "state_spec"], [151, 2, 1, "", "state_spec_unbatched"], [151, 1, 1, "", "step"], [151, 1, 1, "", "step_and_maybe_reset"], [151, 1, 1, "", "step_mdp"], [151, 1, 1, "", "to"], [151, 1, 1, "", "to_empty"], [151, 1, 1, "", "train"], [151, 1, 1, "", "type"], [151, 1, 1, "", "xpu"], [151, 1, 1, "", "zero_grad"]], "torchrl.envs.ProcessorAsyncEnvPool": [[154, 1, 1, "", "_setup"], [154, 2, 1, "", "action_key"], [154, 2, 1, "", "action_keys"], [154, 2, 1, "", "action_spec"], [154, 2, 1, "", "action_spec_unbatched"], [154, 1, 1, "", "add_module"], [154, 1, 1, "", "add_truncated_keys"], [154, 1, 1, "", "all_actions"], [154, 1, 1, "", "any_done"], [154, 1, 1, "", "append_transform"], [154, 1, 1, "", "apply"], [154, 1, 1, "", "async_reset_recv"], [154, 1, 1, "", "async_reset_send"], [154, 1, 1, "", "async_step_recv"], [154, 1, 1, "", "async_step_send"], [154, 1, 1, "", "auto_specs_"], [154, 2, 1, "", "batch_dims"], [154, 2, 1, "", "batch_locked"], [154, 2, 1, "", "batch_size"], [154, 1, 1, "", "bfloat16"], [154, 1, 1, "", "buffers"], [154, 1, 1, "", "cardinality"], [154, 1, 1, "", "check_env_specs"], [154, 1, 1, "", "children"], [154, 2, 1, "", "collector"], [154, 1, 1, "", "compile"], [154, 1, 1, "", "cpu"], [154, 1, 1, "", "cuda"], [154, 2, 1, "", "done_key"], [154, 2, 1, "", "done_keys"], [154, 2, 1, "", "done_keys_groups"], [154, 2, 1, "", "done_spec"], [154, 2, 1, "", "done_spec_unbatched"], [154, 1, 1, "", "double"], [154, 1, 1, "", "empty_cache"], [154, 2, 1, "", "env_batch_sizes"], [154, 1, 1, "", "eval"], [154, 1, 1, "", "extra_repr"], [154, 1, 1, "", "fake_tensordict"], [154, 1, 1, "", "float"], [154, 1, 1, "", "forward"], [154, 2, 1, "", "full_action_spec"], [154, 2, 1, "", "full_action_spec_unbatched"], [154, 2, 1, "", "full_done_spec"], [154, 2, 1, "", "full_done_spec_unbatched"], [154, 2, 1, "", "full_observation_spec_unbatched"], [154, 2, 1, "", "full_reward_spec"], [154, 2, 1, "", "full_reward_spec_unbatched"], [154, 2, 1, "", "full_state_spec"], [154, 2, 1, "", "full_state_spec_unbatched"], [154, 1, 1, "", "get_buffer"], [154, 1, 1, "", "get_extra_state"], [154, 1, 1, "", "get_parameter"], [154, 1, 1, "", "get_submodule"], [154, 1, 1, "", "half"], [154, 2, 1, "", "input_spec"], [154, 2, 1, "", "input_spec_unbatched"], [154, 1, 1, "", "ipu"], [154, 2, 1, "", "is_spec_locked"], [154, 1, 1, "", "load_state_dict"], [154, 1, 1, "", "maybe_reset"], [154, 1, 1, "", "modules"], [154, 1, 1, "", "mtia"], [154, 1, 1, "", "named_buffers"], [154, 1, 1, "", "named_children"], [154, 1, 1, "", "named_modules"], [154, 1, 1, "", "named_parameters"], [154, 2, 1, "", "observation_keys"], [154, 2, 1, "", "observation_spec"], [154, 2, 1, "", "observation_spec_unbatched"], [154, 2, 1, "", "output_spec"], [154, 2, 1, "", "output_spec_unbatched"], [154, 1, 1, "", "parameters"], [154, 1, 1, "", "rand_action"], [154, 1, 1, "", "rand_step"], [154, 1, 1, "", "register_backward_hook"], [154, 1, 1, "", "register_buffer"], [154, 1, 1, "", "register_collector"], [154, 1, 1, "", "register_forward_hook"], [154, 1, 1, "", "register_forward_pre_hook"], [154, 1, 1, "", "register_full_backward_hook"], [154, 1, 1, "", "register_full_backward_pre_hook"], [154, 1, 1, "", "register_gym"], [154, 1, 1, "", "register_load_state_dict_post_hook"], [154, 1, 1, "", "register_load_state_dict_pre_hook"], [154, 1, 1, "", "register_module"], [154, 1, 1, "", "register_parameter"], [154, 1, 1, "", "register_state_dict_post_hook"], [154, 1, 1, "", "register_state_dict_pre_hook"], [154, 1, 1, "", "requires_grad_"], [154, 1, 1, "", "reset"], [154, 2, 1, "", "reset_keys"], [154, 2, 1, "", "reward_key"], [154, 2, 1, "", "reward_keys"], [154, 2, 1, "", "reward_spec"], [154, 2, 1, "", "reward_spec_unbatched"], [154, 1, 1, "", "rollout"], [154, 1, 1, "", "set_extra_state"], [154, 1, 1, "", "set_seed"], [154, 1, 1, "", "set_spec_lock_"], [154, 1, 1, "", "set_submodule"], [154, 2, 1, "", "shape"], [154, 1, 1, "", "share_memory"], [154, 1, 1, "", "shutdown"], [154, 2, 1, "", "specs"], [154, 1, 1, "", "state_dict"], [154, 2, 1, "", "state_keys"], [154, 2, 1, "", "state_spec"], [154, 2, 1, "", "state_spec_unbatched"], [154, 1, 1, "", "step"], [154, 1, 1, "", "step_and_maybe_reset"], [154, 1, 1, "", "step_mdp"], [154, 1, 1, "", "to"], [154, 1, 1, "", "to_empty"], [154, 1, 1, "", "train"], [154, 1, 1, "", "type"], [154, 1, 1, "", "xpu"], [154, 1, 1, "", "zero_grad"]], "torchrl.envs.SerialEnv": [[158, 2, 1, "", "action_key"], [158, 2, 1, "", "action_keys"], [158, 2, 1, "", "action_spec"], [158, 2, 1, "", "action_spec_unbatched"], [158, 1, 1, "", "add_module"], [158, 1, 1, "", "add_truncated_keys"], [158, 1, 1, "", "all_actions"], [158, 1, 1, "", "any_done"], [158, 1, 1, "", "append_transform"], [158, 1, 1, "", "apply"], [158, 1, 1, "", "auto_specs_"], [158, 2, 1, "", "batch_dims"], [158, 2, 1, "", "batch_locked"], [158, 2, 1, "", "batch_size"], [158, 1, 1, "", "bfloat16"], [158, 1, 1, "", "buffers"], [158, 1, 1, "", "cardinality"], [158, 1, 1, "", "check_env_specs"], [158, 1, 1, "", "children"], [158, 2, 1, "", "collector"], [158, 1, 1, "", "compile"], [158, 1, 1, "", "cpu"], [158, 1, 1, "", "cuda"], [158, 2, 1, "", "done_key"], [158, 2, 1, "", "done_keys"], [158, 2, 1, "", "done_keys_groups"], [158, 2, 1, "", "done_spec"], [158, 2, 1, "", "done_spec_unbatched"], [158, 1, 1, "", "double"], [158, 1, 1, "", "empty_cache"], [158, 1, 1, "", "eval"], [158, 1, 1, "", "extra_repr"], [158, 1, 1, "", "fake_tensordict"], [158, 1, 1, "", "float"], [158, 1, 1, "", "forward"], [158, 2, 1, "", "full_action_spec"], [158, 2, 1, "", "full_action_spec_unbatched"], [158, 2, 1, "", "full_done_spec"], [158, 2, 1, "", "full_done_spec_unbatched"], [158, 2, 1, "", "full_observation_spec_unbatched"], [158, 2, 1, "", "full_reward_spec"], [158, 2, 1, "", "full_reward_spec_unbatched"], [158, 2, 1, "", "full_state_spec"], [158, 2, 1, "", "full_state_spec_unbatched"], [158, 1, 1, "", "get_buffer"], [158, 1, 1, "", "get_extra_state"], [158, 1, 1, "", "get_parameter"], [158, 1, 1, "", "get_submodule"], [158, 1, 1, "", "half"], [158, 2, 1, "", "input_spec"], [158, 2, 1, "", "input_spec_unbatched"], [158, 1, 1, "", "ipu"], [158, 2, 1, "", "is_spec_locked"], [158, 1, 1, "", "load_state_dict"], [158, 1, 1, "", "maybe_reset"], [158, 1, 1, "", "modules"], [158, 1, 1, "", "mtia"], [158, 1, 1, "", "named_buffers"], [158, 1, 1, "", "named_children"], [158, 1, 1, "", "named_modules"], [158, 1, 1, "", "named_parameters"], [158, 2, 1, "", "observation_keys"], [158, 2, 1, "", "observation_spec"], [158, 2, 1, "", "observation_spec_unbatched"], [158, 2, 1, "", "output_spec"], [158, 2, 1, "", "output_spec_unbatched"], [158, 1, 1, "", "parameters"], [158, 1, 1, "", "rand_action"], [158, 1, 1, "", "rand_step"], [158, 1, 1, "", "register_backward_hook"], [158, 1, 1, "", "register_buffer"], [158, 1, 1, "", "register_collector"], [158, 1, 1, "", "register_forward_hook"], [158, 1, 1, "", "register_forward_pre_hook"], [158, 1, 1, "", "register_full_backward_hook"], [158, 1, 1, "", "register_full_backward_pre_hook"], [158, 1, 1, "", "register_gym"], [158, 1, 1, "", "register_load_state_dict_post_hook"], [158, 1, 1, "", "register_load_state_dict_pre_hook"], [158, 1, 1, "", "register_module"], [158, 1, 1, "", "register_parameter"], [158, 1, 1, "", "register_state_dict_post_hook"], [158, 1, 1, "", "register_state_dict_pre_hook"], [158, 1, 1, "", "requires_grad_"], [158, 1, 1, "", "reset"], [158, 2, 1, "", "reset_keys"], [158, 2, 1, "", "reward_key"], [158, 2, 1, "", "reward_keys"], [158, 2, 1, "", "reward_spec"], [158, 2, 1, "", "reward_spec_unbatched"], [158, 1, 1, "", "rollout"], [158, 1, 1, "", "set_extra_state"], [158, 1, 1, "", "set_seed"], [158, 1, 1, "", "set_spec_lock_"], [158, 1, 1, "", "set_submodule"], [158, 2, 1, "", "shape"], [158, 1, 1, "", "share_memory"], [158, 2, 1, "", "specs"], [158, 1, 1, "", "state_dict"], [158, 2, 1, "", "state_keys"], [158, 2, 1, "", "state_spec"], [158, 2, 1, "", "state_spec_unbatched"], [158, 1, 1, "", "step"], [158, 1, 1, "", "step_and_maybe_reset"], [158, 1, 1, "", "step_mdp"], [158, 1, 1, "", "to"], [158, 1, 1, "", "to_empty"], [158, 1, 1, "", "train"], [158, 1, 1, "", "type"], [158, 1, 1, "", "update_kwargs"], [158, 1, 1, "", "xpu"], [158, 1, 1, "", "zero_grad"]], "torchrl.envs.ThreadingAsyncEnvPool": [[159, 1, 1, "", "_setup"], [159, 2, 1, "", "action_key"], [159, 2, 1, "", "action_keys"], [159, 2, 1, "", "action_spec"], [159, 2, 1, "", "action_spec_unbatched"], [159, 1, 1, "", "add_module"], [159, 1, 1, "", "add_truncated_keys"], [159, 1, 1, "", "all_actions"], [159, 1, 1, "", "any_done"], [159, 1, 1, "", "append_transform"], [159, 1, 1, "", "apply"], [159, 1, 1, "", "async_reset_recv"], [159, 1, 1, "", "async_reset_send"], [159, 1, 1, "", "async_step_recv"], [159, 1, 1, "", "async_step_send"], [159, 1, 1, "", "auto_specs_"], [159, 2, 1, "", "batch_dims"], [159, 2, 1, "", "batch_locked"], [159, 2, 1, "", "batch_size"], [159, 1, 1, "", "bfloat16"], [159, 1, 1, "", "buffers"], [159, 1, 1, "", "cardinality"], [159, 1, 1, "", "check_env_specs"], [159, 1, 1, "", "children"], [159, 2, 1, "", "collector"], [159, 1, 1, "", "compile"], [159, 1, 1, "", "cpu"], [159, 1, 1, "", "cuda"], [159, 2, 1, "", "done_key"], [159, 2, 1, "", "done_keys"], [159, 2, 1, "", "done_keys_groups"], [159, 2, 1, "", "done_spec"], [159, 2, 1, "", "done_spec_unbatched"], [159, 1, 1, "", "double"], [159, 1, 1, "", "empty_cache"], [159, 2, 1, "", "env_batch_sizes"], [159, 1, 1, "", "eval"], [159, 1, 1, "", "extra_repr"], [159, 1, 1, "", "fake_tensordict"], [159, 1, 1, "", "float"], [159, 1, 1, "", "forward"], [159, 2, 1, "", "full_action_spec"], [159, 2, 1, "", "full_action_spec_unbatched"], [159, 2, 1, "", "full_done_spec"], [159, 2, 1, "", "full_done_spec_unbatched"], [159, 2, 1, "", "full_observation_spec_unbatched"], [159, 2, 1, "", "full_reward_spec"], [159, 2, 1, "", "full_reward_spec_unbatched"], [159, 2, 1, "", "full_state_spec"], [159, 2, 1, "", "full_state_spec_unbatched"], [159, 1, 1, "", "get_buffer"], [159, 1, 1, "", "get_extra_state"], [159, 1, 1, "", "get_parameter"], [159, 1, 1, "", "get_submodule"], [159, 1, 1, "", "half"], [159, 2, 1, "", "input_spec"], [159, 2, 1, "", "input_spec_unbatched"], [159, 1, 1, "", "ipu"], [159, 2, 1, "", "is_spec_locked"], [159, 1, 1, "", "load_state_dict"], [159, 1, 1, "", "maybe_reset"], [159, 1, 1, "", "modules"], [159, 1, 1, "", "mtia"], [159, 1, 1, "", "named_buffers"], [159, 1, 1, "", "named_children"], [159, 1, 1, "", "named_modules"], [159, 1, 1, "", "named_parameters"], [159, 2, 1, "", "observation_keys"], [159, 2, 1, "", "observation_spec"], [159, 2, 1, "", "observation_spec_unbatched"], [159, 2, 1, "", "output_spec"], [159, 2, 1, "", "output_spec_unbatched"], [159, 1, 1, "", "parameters"], [159, 1, 1, "", "rand_action"], [159, 1, 1, "", "rand_step"], [159, 1, 1, "", "register_backward_hook"], [159, 1, 1, "", "register_buffer"], [159, 1, 1, "", "register_collector"], [159, 1, 1, "", "register_forward_hook"], [159, 1, 1, "", "register_forward_pre_hook"], [159, 1, 1, "", "register_full_backward_hook"], [159, 1, 1, "", "register_full_backward_pre_hook"], [159, 1, 1, "", "register_gym"], [159, 1, 1, "", "register_load_state_dict_post_hook"], [159, 1, 1, "", "register_load_state_dict_pre_hook"], [159, 1, 1, "", "register_module"], [159, 1, 1, "", "register_parameter"], [159, 1, 1, "", "register_state_dict_post_hook"], [159, 1, 1, "", "register_state_dict_pre_hook"], [159, 1, 1, "", "requires_grad_"], [159, 1, 1, "", "reset"], [159, 2, 1, "", "reset_keys"], [159, 2, 1, "", "reward_key"], [159, 2, 1, "", "reward_keys"], [159, 2, 1, "", "reward_spec"], [159, 2, 1, "", "reward_spec_unbatched"], [159, 1, 1, "", "rollout"], [159, 1, 1, "", "set_extra_state"], [159, 1, 1, "", "set_seed"], [159, 1, 1, "", "set_spec_lock_"], [159, 1, 1, "", "set_submodule"], [159, 2, 1, "", "shape"], [159, 1, 1, "", "share_memory"], [159, 1, 1, "", "shutdown"], [159, 2, 1, "", "specs"], [159, 1, 1, "", "state_dict"], [159, 2, 1, "", "state_keys"], [159, 2, 1, "", "state_spec"], [159, 2, 1, "", "state_spec_unbatched"], [159, 1, 1, "", "step"], [159, 1, 1, "", "step_and_maybe_reset"], [159, 1, 1, "", "step_mdp"], [159, 1, 1, "", "to"], [159, 1, 1, "", "to_empty"], [159, 1, 1, "", "train"], [159, 1, 1, "", "type"], [159, 1, 1, "", "xpu"], [159, 1, 1, "", "zero_grad"]], "torchrl.envs.TicTacToeEnv": [[160, 2, 1, "", "action_key"], [160, 2, 1, "", "action_keys"], [160, 2, 1, "", "action_spec"], [160, 2, 1, "", "action_spec_unbatched"], [160, 1, 1, "", "add_module"], [160, 1, 1, "", "add_truncated_keys"], [160, 1, 1, "", "all_actions"], [160, 1, 1, "", "any_done"], [160, 1, 1, "", "append_transform"], [160, 1, 1, "", "apply"], [160, 1, 1, "", "auto_specs_"], [160, 2, 1, "", "batch_dims"], [160, 2, 1, "", "batch_size"], [160, 1, 1, "", "bfloat16"], [160, 1, 1, "", "buffers"], [160, 1, 1, "", "cardinality"], [160, 1, 1, "", "check_env_specs"], [160, 1, 1, "", "children"], [160, 2, 1, "", "collector"], [160, 1, 1, "", "compile"], [160, 1, 1, "", "cpu"], [160, 1, 1, "", "cuda"], [160, 2, 1, "", "done_key"], [160, 2, 1, "", "done_keys"], [160, 2, 1, "", "done_keys_groups"], [160, 2, 1, "", "done_spec"], [160, 2, 1, "", "done_spec_unbatched"], [160, 1, 1, "", "double"], [160, 1, 1, "", "empty_cache"], [160, 1, 1, "", "eval"], [160, 1, 1, "", "extra_repr"], [160, 1, 1, "", "fake_tensordict"], [160, 1, 1, "", "float"], [160, 1, 1, "", "forward"], [160, 2, 1, "", "full_action_spec"], [160, 2, 1, "", "full_action_spec_unbatched"], [160, 2, 1, "", "full_done_spec"], [160, 2, 1, "", "full_done_spec_unbatched"], [160, 2, 1, "", "full_observation_spec_unbatched"], [160, 2, 1, "", "full_reward_spec"], [160, 2, 1, "", "full_reward_spec_unbatched"], [160, 2, 1, "", "full_state_spec"], [160, 2, 1, "", "full_state_spec_unbatched"], [160, 1, 1, "", "get_buffer"], [160, 1, 1, "", "get_extra_state"], [160, 1, 1, "", "get_parameter"], [160, 1, 1, "", "get_submodule"], [160, 1, 1, "", "half"], [160, 2, 1, "", "input_spec"], [160, 2, 1, "", "input_spec_unbatched"], [160, 1, 1, "", "ipu"], [160, 2, 1, "", "is_spec_locked"], [160, 1, 1, "", "load_state_dict"], [160, 1, 1, "", "maybe_reset"], [160, 1, 1, "", "modules"], [160, 1, 1, "", "mtia"], [160, 1, 1, "", "named_buffers"], [160, 1, 1, "", "named_children"], [160, 1, 1, "", "named_modules"], [160, 1, 1, "", "named_parameters"], [160, 2, 1, "", "observation_keys"], [160, 2, 1, "", "observation_spec"], [160, 2, 1, "", "observation_spec_unbatched"], [160, 2, 1, "", "output_spec"], [160, 2, 1, "", "output_spec_unbatched"], [160, 1, 1, "", "parameters"], [160, 1, 1, "", "rand_action"], [160, 1, 1, "", "rand_step"], [160, 1, 1, "", "register_backward_hook"], [160, 1, 1, "", "register_buffer"], [160, 1, 1, "", "register_collector"], [160, 1, 1, "", "register_forward_hook"], [160, 1, 1, "", "register_forward_pre_hook"], [160, 1, 1, "", "register_full_backward_hook"], [160, 1, 1, "", "register_full_backward_pre_hook"], [160, 1, 1, "", "register_gym"], [160, 1, 1, "", "register_load_state_dict_post_hook"], [160, 1, 1, "", "register_load_state_dict_pre_hook"], [160, 1, 1, "", "register_module"], [160, 1, 1, "", "register_parameter"], [160, 1, 1, "", "register_state_dict_post_hook"], [160, 1, 1, "", "register_state_dict_pre_hook"], [160, 1, 1, "", "requires_grad_"], [160, 1, 1, "", "reset"], [160, 2, 1, "", "reset_keys"], [160, 2, 1, "", "reward_key"], [160, 2, 1, "", "reward_keys"], [160, 2, 1, "", "reward_spec"], [160, 2, 1, "", "reward_spec_unbatched"], [160, 1, 1, "", "rollout"], [160, 1, 1, "", "set_extra_state"], [160, 1, 1, "", "set_seed"], [160, 1, 1, "", "set_spec_lock_"], [160, 1, 1, "", "set_submodule"], [160, 2, 1, "", "shape"], [160, 1, 1, "", "share_memory"], [160, 2, 1, "", "specs"], [160, 1, 1, "", "state_dict"], [160, 2, 1, "", "state_keys"], [160, 2, 1, "", "state_spec"], [160, 2, 1, "", "state_spec_unbatched"], [160, 1, 1, "", "step"], [160, 1, 1, "", "step_and_maybe_reset"], [160, 1, 1, "", "step_mdp"], [160, 1, 1, "", "to"], [160, 1, 1, "", "to_empty"], [160, 1, 1, "", "train"], [160, 1, 1, "", "type"], [160, 1, 1, "", "xpu"], [160, 1, 1, "", "zero_grad"]], "torchrl.envs.llm": [[170, 0, 1, "", "ChatEnv"], [171, 0, 1, "", "DatasetChatEnv"], [172, 0, 1, "", "GSM8KEnv"], [173, 0, 1, "", "GSM8KPrepareQuestion"], [174, 0, 1, "", "GSM8KRewardParser"], [175, 0, 1, "", "IFEvalEnv"], [176, 0, 1, "", "IFEvalScoreData"], [177, 0, 1, "", "IfEvalScorer"], [178, 0, 1, "", "LLMEnv"], [179, 0, 1, "", "LLMHashingEnv"], [180, 0, 1, "", "MLGymWrapper"], [181, 0, 1, "", "make_gsm8k_env"], [182, 0, 1, "", "make_mlgym"]], "torchrl.envs.llm.ChatEnv": [[170, 2, 1, "", "action_key"], [170, 2, 1, "", "action_keys"], [170, 2, 1, "", "action_spec"], [170, 2, 1, "", "action_spec_unbatched"], [170, 1, 1, "", "add_module"], [170, 1, 1, "", "add_truncated_keys"], [170, 1, 1, "", "all_actions"], [170, 1, 1, "", "any_done"], [170, 1, 1, "", "append_transform"], [170, 1, 1, "", "apply"], [170, 1, 1, "", "auto_specs_"], [170, 2, 1, "", "batch_dims"], [170, 2, 1, "", "batch_locked"], [170, 2, 1, "", "batch_size"], [170, 1, 1, "", "bfloat16"], [170, 1, 1, "", "buffers"], [170, 1, 1, "", "cardinality"], [170, 1, 1, "", "check_env_specs"], [170, 1, 1, "", "children"], [170, 2, 1, "", "collector"], [170, 1, 1, "", "compile"], [170, 1, 1, "", "cpu"], [170, 1, 1, "", "cuda"], [170, 2, 1, "", "done_key"], [170, 2, 1, "", "done_keys"], [170, 2, 1, "", "done_keys_groups"], [170, 2, 1, "", "done_spec"], [170, 2, 1, "", "done_spec_unbatched"], [170, 1, 1, "", "double"], [170, 1, 1, "", "empty_cache"], [170, 1, 1, "", "eval"], [170, 1, 1, "", "extra_repr"], [170, 1, 1, "", "fake_tensordict"], [170, 1, 1, "", "float"], [170, 1, 1, "", "forward"], [170, 1, 1, "", "from_dataloader"], [170, 2, 1, "", "full_action_spec"], [170, 2, 1, "", "full_action_spec_unbatched"], [170, 2, 1, "", "full_done_spec"], [170, 2, 1, "", "full_done_spec_unbatched"], [170, 2, 1, "", "full_observation_spec_unbatched"], [170, 2, 1, "", "full_reward_spec"], [170, 2, 1, "", "full_reward_spec_unbatched"], [170, 2, 1, "", "full_state_spec"], [170, 2, 1, "", "full_state_spec_unbatched"], [170, 1, 1, "", "get_buffer"], [170, 1, 1, "", "get_extra_state"], [170, 1, 1, "", "get_parameter"], [170, 1, 1, "", "get_submodule"], [170, 1, 1, "", "half"], [170, 2, 1, "", "input_spec"], [170, 2, 1, "", "input_spec_unbatched"], [170, 1, 1, "", "ipu"], [170, 2, 1, "", "is_spec_locked"], [170, 1, 1, "", "load_state_dict"], [170, 1, 1, "", "maybe_reset"], [170, 1, 1, "", "modules"], [170, 1, 1, "", "mtia"], [170, 1, 1, "", "named_buffers"], [170, 1, 1, "", "named_children"], [170, 1, 1, "", "named_modules"], [170, 1, 1, "", "named_parameters"], [170, 2, 1, "", "observation_keys"], [170, 2, 1, "", "observation_spec"], [170, 2, 1, "", "observation_spec_unbatched"], [170, 2, 1, "", "output_spec"], [170, 2, 1, "", "output_spec_unbatched"], [170, 1, 1, "", "parameters"], [170, 1, 1, "", "rand_action"], [170, 1, 1, "", "rand_step"], [170, 1, 1, "", "register_backward_hook"], [170, 1, 1, "", "register_buffer"], [170, 1, 1, "", "register_collector"], [170, 1, 1, "", "register_forward_hook"], [170, 1, 1, "", "register_forward_pre_hook"], [170, 1, 1, "", "register_full_backward_hook"], [170, 1, 1, "", "register_full_backward_pre_hook"], [170, 1, 1, "", "register_gym"], [170, 1, 1, "", "register_load_state_dict_post_hook"], [170, 1, 1, "", "register_load_state_dict_pre_hook"], [170, 1, 1, "", "register_module"], [170, 1, 1, "", "register_parameter"], [170, 1, 1, "", "register_state_dict_post_hook"], [170, 1, 1, "", "register_state_dict_pre_hook"], [170, 1, 1, "", "requires_grad_"], [170, 1, 1, "id0", "reset"], [170, 2, 1, "", "reset_keys"], [170, 2, 1, "", "reward_key"], [170, 2, 1, "", "reward_keys"], [170, 2, 1, "", "reward_spec"], [170, 2, 1, "", "reward_spec_unbatched"], [170, 1, 1, "", "rollout"], [170, 1, 1, "", "set_extra_state"], [170, 1, 1, "", "set_seed"], [170, 1, 1, "", "set_spec_lock_"], [170, 1, 1, "", "set_submodule"], [170, 2, 1, "", "shape"], [170, 1, 1, "", "share_memory"], [170, 2, 1, "", "specs"], [170, 1, 1, "", "state_dict"], [170, 2, 1, "", "state_keys"], [170, 2, 1, "", "state_spec"], [170, 2, 1, "", "state_spec_unbatched"], [170, 1, 1, "id1", "step"], [170, 1, 1, "", "step_and_maybe_reset"], [170, 1, 1, "", "step_mdp"], [170, 1, 1, "", "to"], [170, 1, 1, "", "to_empty"], [170, 1, 1, "", "train"], [170, 1, 1, "", "type"], [170, 1, 1, "", "xpu"], [170, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.DatasetChatEnv": [[171, 2, 1, "", "action_key"], [171, 2, 1, "", "action_keys"], [171, 2, 1, "", "action_spec"], [171, 2, 1, "", "action_spec_unbatched"], [171, 1, 1, "", "add_module"], [171, 1, 1, "", "add_truncated_keys"], [171, 1, 1, "", "all_actions"], [171, 1, 1, "", "any_done"], [171, 1, 1, "", "append_transform"], [171, 1, 1, "", "apply"], [171, 1, 1, "", "auto_specs_"], [171, 2, 1, "", "batch_dims"], [171, 2, 1, "", "batch_locked"], [171, 2, 1, "", "batch_size"], [171, 1, 1, "", "bfloat16"], [171, 1, 1, "", "buffers"], [171, 1, 1, "", "cardinality"], [171, 1, 1, "", "check_env_specs"], [171, 1, 1, "", "children"], [171, 2, 1, "", "collector"], [171, 1, 1, "", "compile"], [171, 1, 1, "", "cpu"], [171, 1, 1, "", "cuda"], [171, 2, 1, "", "done_key"], [171, 2, 1, "", "done_keys"], [171, 2, 1, "", "done_keys_groups"], [171, 2, 1, "", "done_spec"], [171, 2, 1, "", "done_spec_unbatched"], [171, 1, 1, "", "double"], [171, 1, 1, "", "empty_cache"], [171, 1, 1, "", "eval"], [171, 1, 1, "", "extra_repr"], [171, 1, 1, "", "fake_tensordict"], [171, 1, 1, "", "float"], [171, 1, 1, "", "forward"], [171, 1, 1, "", "from_dataloader"], [171, 2, 1, "", "full_action_spec"], [171, 2, 1, "", "full_action_spec_unbatched"], [171, 2, 1, "", "full_done_spec"], [171, 2, 1, "", "full_done_spec_unbatched"], [171, 2, 1, "", "full_observation_spec_unbatched"], [171, 2, 1, "", "full_reward_spec"], [171, 2, 1, "", "full_reward_spec_unbatched"], [171, 2, 1, "", "full_state_spec"], [171, 2, 1, "", "full_state_spec_unbatched"], [171, 1, 1, "", "get_buffer"], [171, 1, 1, "", "get_extra_state"], [171, 1, 1, "", "get_parameter"], [171, 1, 1, "", "get_submodule"], [171, 1, 1, "", "half"], [171, 2, 1, "", "input_spec"], [171, 2, 1, "", "input_spec_unbatched"], [171, 1, 1, "", "insert_transform"], [171, 1, 1, "", "ipu"], [171, 2, 1, "", "is_spec_locked"], [171, 1, 1, "", "load_state_dict"], [171, 1, 1, "", "maybe_reset"], [171, 1, 1, "", "modules"], [171, 1, 1, "", "mtia"], [171, 1, 1, "", "named_buffers"], [171, 1, 1, "", "named_children"], [171, 1, 1, "", "named_modules"], [171, 1, 1, "", "named_parameters"], [171, 2, 1, "", "observation_keys"], [171, 2, 1, "", "observation_spec"], [171, 2, 1, "", "observation_spec_unbatched"], [171, 2, 1, "", "output_spec"], [171, 2, 1, "", "output_spec_unbatched"], [171, 1, 1, "", "parameters"], [171, 1, 1, "", "rand_action"], [171, 1, 1, "", "rand_step"], [171, 1, 1, "", "register_backward_hook"], [171, 1, 1, "", "register_buffer"], [171, 1, 1, "", "register_collector"], [171, 1, 1, "", "register_forward_hook"], [171, 1, 1, "", "register_forward_pre_hook"], [171, 1, 1, "", "register_full_backward_hook"], [171, 1, 1, "", "register_full_backward_pre_hook"], [171, 1, 1, "", "register_gym"], [171, 1, 1, "", "register_load_state_dict_post_hook"], [171, 1, 1, "", "register_load_state_dict_pre_hook"], [171, 1, 1, "", "register_module"], [171, 1, 1, "", "register_parameter"], [171, 1, 1, "", "register_state_dict_post_hook"], [171, 1, 1, "", "register_state_dict_pre_hook"], [171, 1, 1, "", "requires_grad_"], [171, 1, 1, "", "reset"], [171, 1, 1, "", "reset_dataloader"], [171, 2, 1, "", "reset_keys"], [171, 2, 1, "", "reward_key"], [171, 2, 1, "", "reward_keys"], [171, 2, 1, "", "reward_spec"], [171, 2, 1, "", "reward_spec_unbatched"], [171, 1, 1, "", "rollout"], [171, 1, 1, "", "set_extra_state"], [171, 1, 1, "", "set_missing_tolerance"], [171, 1, 1, "", "set_seed"], [171, 1, 1, "", "set_spec_lock_"], [171, 1, 1, "", "set_submodule"], [171, 2, 1, "", "shape"], [171, 1, 1, "", "share_memory"], [171, 2, 1, "", "specs"], [171, 1, 1, "", "state_dict"], [171, 2, 1, "", "state_keys"], [171, 2, 1, "", "state_spec"], [171, 2, 1, "", "state_spec_unbatched"], [171, 1, 1, "", "step"], [171, 1, 1, "", "step_and_maybe_reset"], [171, 1, 1, "", "step_mdp"], [171, 1, 1, "", "to"], [171, 1, 1, "", "to_empty"], [171, 1, 1, "", "train"], [171, 1, 1, "", "type"], [171, 1, 1, "", "xpu"], [171, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KEnv": [[172, 2, 1, "", "action_key"], [172, 2, 1, "", "action_keys"], [172, 2, 1, "", "action_spec"], [172, 2, 1, "", "action_spec_unbatched"], [172, 1, 1, "", "add_module"], [172, 1, 1, "", "add_truncated_keys"], [172, 1, 1, "", "all_actions"], [172, 1, 1, "", "any_done"], [172, 1, 1, "", "append_transform"], [172, 1, 1, "", "apply"], [172, 1, 1, "", "auto_specs_"], [172, 2, 1, "", "batch_dims"], [172, 2, 1, "", "batch_locked"], [172, 2, 1, "", "batch_size"], [172, 1, 1, "", "bfloat16"], [172, 1, 1, "", "buffers"], [172, 1, 1, "", "cardinality"], [172, 1, 1, "", "check_env_specs"], [172, 1, 1, "", "children"], [172, 2, 1, "", "collector"], [172, 1, 1, "", "compile"], [172, 1, 1, "", "cpu"], [172, 1, 1, "", "cuda"], [172, 2, 1, "", "done_key"], [172, 2, 1, "", "done_keys"], [172, 2, 1, "", "done_keys_groups"], [172, 2, 1, "", "done_spec"], [172, 2, 1, "", "done_spec_unbatched"], [172, 1, 1, "", "double"], [172, 1, 1, "", "empty_cache"], [172, 1, 1, "", "eval"], [172, 1, 1, "", "extra_repr"], [172, 1, 1, "", "fake_tensordict"], [172, 1, 1, "", "float"], [172, 1, 1, "", "forward"], [172, 1, 1, "", "from_dataloader"], [172, 2, 1, "", "full_action_spec"], [172, 2, 1, "", "full_action_spec_unbatched"], [172, 2, 1, "", "full_done_spec"], [172, 2, 1, "", "full_done_spec_unbatched"], [172, 2, 1, "", "full_observation_spec_unbatched"], [172, 2, 1, "", "full_reward_spec"], [172, 2, 1, "", "full_reward_spec_unbatched"], [172, 2, 1, "", "full_state_spec"], [172, 2, 1, "", "full_state_spec_unbatched"], [172, 1, 1, "", "get_buffer"], [172, 1, 1, "", "get_extra_state"], [172, 1, 1, "", "get_parameter"], [172, 1, 1, "", "get_submodule"], [172, 1, 1, "", "half"], [172, 2, 1, "", "input_spec"], [172, 2, 1, "", "input_spec_unbatched"], [172, 1, 1, "", "insert_transform"], [172, 1, 1, "", "ipu"], [172, 2, 1, "", "is_spec_locked"], [172, 1, 1, "", "load_state_dict"], [172, 1, 1, "", "maybe_reset"], [172, 1, 1, "", "modules"], [172, 1, 1, "", "mtia"], [172, 1, 1, "", "named_buffers"], [172, 1, 1, "", "named_children"], [172, 1, 1, "", "named_modules"], [172, 1, 1, "", "named_parameters"], [172, 2, 1, "", "observation_keys"], [172, 2, 1, "", "observation_spec"], [172, 2, 1, "", "observation_spec_unbatched"], [172, 2, 1, "", "output_spec"], [172, 2, 1, "", "output_spec_unbatched"], [172, 1, 1, "", "parameters"], [172, 1, 1, "", "rand_action"], [172, 1, 1, "", "rand_step"], [172, 1, 1, "", "register_backward_hook"], [172, 1, 1, "", "register_buffer"], [172, 1, 1, "", "register_collector"], [172, 1, 1, "", "register_forward_hook"], [172, 1, 1, "", "register_forward_pre_hook"], [172, 1, 1, "", "register_full_backward_hook"], [172, 1, 1, "", "register_full_backward_pre_hook"], [172, 1, 1, "", "register_gym"], [172, 1, 1, "", "register_load_state_dict_post_hook"], [172, 1, 1, "", "register_load_state_dict_pre_hook"], [172, 1, 1, "", "register_module"], [172, 1, 1, "", "register_parameter"], [172, 1, 1, "", "register_state_dict_post_hook"], [172, 1, 1, "", "register_state_dict_pre_hook"], [172, 1, 1, "", "requires_grad_"], [172, 1, 1, "", "reset"], [172, 1, 1, "", "reset_dataloader"], [172, 2, 1, "", "reset_keys"], [172, 2, 1, "", "reward_key"], [172, 2, 1, "", "reward_keys"], [172, 2, 1, "", "reward_spec"], [172, 2, 1, "", "reward_spec_unbatched"], [172, 1, 1, "", "rollout"], [172, 1, 1, "", "set_extra_state"], [172, 1, 1, "", "set_missing_tolerance"], [172, 1, 1, "", "set_seed"], [172, 1, 1, "", "set_spec_lock_"], [172, 1, 1, "", "set_submodule"], [172, 2, 1, "", "shape"], [172, 1, 1, "", "share_memory"], [172, 2, 1, "", "specs"], [172, 1, 1, "", "state_dict"], [172, 2, 1, "", "state_keys"], [172, 2, 1, "", "state_spec"], [172, 2, 1, "", "state_spec_unbatched"], [172, 1, 1, "", "step"], [172, 1, 1, "", "step_and_maybe_reset"], [172, 1, 1, "", "step_mdp"], [172, 1, 1, "", "to"], [172, 1, 1, "", "to_empty"], [172, 1, 1, "", "train"], [172, 1, 1, "", "type"], [172, 1, 1, "", "xpu"], [172, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KPrepareQuestion": [[173, 1, 1, "", "add_module"], [173, 1, 1, "", "apply"], [173, 1, 1, "", "bfloat16"], [173, 1, 1, "", "buffers"], [173, 1, 1, "", "children"], [173, 1, 1, "", "close"], [173, 2, 1, "", "collector"], [173, 1, 1, "", "compile"], [173, 2, 1, "", "container"], [173, 1, 1, "", "cpu"], [173, 1, 1, "", "cuda"], [173, 1, 1, "", "double"], [173, 1, 1, "", "eval"], [173, 1, 1, "", "extra_repr"], [173, 1, 1, "", "float"], [173, 1, 1, "", "forward"], [173, 1, 1, "", "get_buffer"], [173, 1, 1, "", "get_extra_state"], [173, 1, 1, "", "get_parameter"], [173, 1, 1, "", "get_submodule"], [173, 1, 1, "", "half"], [173, 1, 1, "", "init"], [173, 1, 1, "", "inv"], [173, 1, 1, "", "ipu"], [173, 1, 1, "", "load_state_dict"], [173, 1, 1, "", "modules"], [173, 1, 1, "", "mtia"], [173, 1, 1, "", "named_buffers"], [173, 1, 1, "", "named_children"], [173, 1, 1, "", "named_modules"], [173, 1, 1, "", "named_parameters"], [173, 1, 1, "", "parameters"], [173, 2, 1, "", "parent"], [173, 1, 1, "", "register_backward_hook"], [173, 1, 1, "", "register_buffer"], [173, 1, 1, "", "register_forward_hook"], [173, 1, 1, "", "register_forward_pre_hook"], [173, 1, 1, "", "register_full_backward_hook"], [173, 1, 1, "", "register_full_backward_pre_hook"], [173, 1, 1, "", "register_load_state_dict_post_hook"], [173, 1, 1, "", "register_load_state_dict_pre_hook"], [173, 1, 1, "", "register_module"], [173, 1, 1, "", "register_parameter"], [173, 1, 1, "", "register_state_dict_post_hook"], [173, 1, 1, "", "register_state_dict_pre_hook"], [173, 1, 1, "", "requires_grad_"], [173, 1, 1, "", "set_extra_state"], [173, 1, 1, "", "set_submodule"], [173, 1, 1, "", "share_memory"], [173, 1, 1, "", "state_dict"], [173, 1, 1, "", "to"], [173, 1, 1, "", "to_empty"], [173, 1, 1, "", "train"], [173, 1, 1, "", "transform_action_spec"], [173, 1, 1, "", "transform_done_spec"], [173, 1, 1, "", "transform_env_batch_size"], [173, 1, 1, "", "transform_env_device"], [173, 1, 1, "", "transform_input_spec"], [173, 1, 1, "", "transform_observation_spec"], [173, 1, 1, "", "transform_output_spec"], [173, 1, 1, "", "transform_reward_spec"], [173, 1, 1, "", "transform_state_spec"], [173, 1, 1, "", "type"], [173, 1, 1, "", "xpu"], [173, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KRewardParser": [[174, 1, 1, "", "add_module"], [174, 1, 1, "", "apply"], [174, 1, 1, "", "bfloat16"], [174, 1, 1, "", "buffers"], [174, 1, 1, "", "children"], [174, 1, 1, "", "close"], [174, 2, 1, "", "collector"], [174, 1, 1, "", "compile"], [174, 2, 1, "", "container"], [174, 1, 1, "", "cpu"], [174, 1, 1, "", "cuda"], [174, 1, 1, "", "double"], [174, 1, 1, "", "eval"], [174, 1, 1, "", "extra_repr"], [174, 1, 1, "", "extract_tags"], [174, 1, 1, "", "float"], [174, 1, 1, "", "forward"], [174, 1, 1, "", "get_buffer"], [174, 1, 1, "", "get_extra_state"], [174, 1, 1, "", "get_parameter"], [174, 1, 1, "", "get_submodule"], [174, 1, 1, "", "half"], [174, 1, 1, "", "init"], [174, 1, 1, "", "inv"], [174, 1, 1, "", "ipu"], [174, 1, 1, "", "load_state_dict"], [174, 1, 1, "", "modules"], [174, 1, 1, "", "mtia"], [174, 1, 1, "", "named_buffers"], [174, 1, 1, "", "named_children"], [174, 1, 1, "", "named_modules"], [174, 1, 1, "", "named_parameters"], [174, 1, 1, "", "parameters"], [174, 2, 1, "", "parent"], [174, 1, 1, "", "register_backward_hook"], [174, 1, 1, "", "register_buffer"], [174, 1, 1, "", "register_forward_hook"], [174, 1, 1, "", "register_forward_pre_hook"], [174, 1, 1, "", "register_full_backward_hook"], [174, 1, 1, "", "register_full_backward_pre_hook"], [174, 1, 1, "", "register_load_state_dict_post_hook"], [174, 1, 1, "", "register_load_state_dict_pre_hook"], [174, 1, 1, "", "register_module"], [174, 1, 1, "", "register_parameter"], [174, 1, 1, "", "register_state_dict_post_hook"], [174, 1, 1, "", "register_state_dict_pre_hook"], [174, 1, 1, "", "requires_grad_"], [174, 1, 1, "", "set_extra_state"], [174, 1, 1, "", "set_submodule"], [174, 1, 1, "", "share_memory"], [174, 1, 1, "", "state_dict"], [174, 1, 1, "", "to"], [174, 1, 1, "", "to_empty"], [174, 1, 1, "", "train"], [174, 1, 1, "", "transform_action_spec"], [174, 1, 1, "", "transform_done_spec"], [174, 1, 1, "", "transform_env_batch_size"], [174, 1, 1, "", "transform_env_device"], [174, 1, 1, "", "transform_input_spec"], [174, 1, 1, "", "transform_observation_spec"], [174, 1, 1, "", "transform_output_spec"], [174, 1, 1, "", "transform_reward_spec"], [174, 1, 1, "", "transform_state_spec"], [174, 1, 1, "", "type"], [174, 1, 1, "", "xpu"], [174, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.IFEvalEnv": [[175, 2, 1, "", "action_key"], [175, 2, 1, "", "action_keys"], [175, 2, 1, "", "action_spec"], [175, 2, 1, "", "action_spec_unbatched"], [175, 1, 1, "", "add_module"], [175, 1, 1, "", "add_truncated_keys"], [175, 1, 1, "", "all_actions"], [175, 1, 1, "", "any_done"], [175, 1, 1, "", "append_transform"], [175, 1, 1, "", "apply"], [175, 1, 1, "", "auto_specs_"], [175, 2, 1, "", "batch_dims"], [175, 2, 1, "", "batch_locked"], [175, 2, 1, "", "batch_size"], [175, 1, 1, "", "bfloat16"], [175, 1, 1, "", "buffers"], [175, 1, 1, "", "cardinality"], [175, 1, 1, "", "check_env_specs"], [175, 1, 1, "", "children"], [175, 2, 1, "", "collector"], [175, 1, 1, "", "compile"], [175, 1, 1, "", "cpu"], [175, 1, 1, "", "cuda"], [175, 2, 1, "", "done_key"], [175, 2, 1, "", "done_keys"], [175, 2, 1, "", "done_keys_groups"], [175, 2, 1, "", "done_spec"], [175, 2, 1, "", "done_spec_unbatched"], [175, 1, 1, "", "double"], [175, 1, 1, "", "empty_cache"], [175, 1, 1, "", "eval"], [175, 1, 1, "", "extra_repr"], [175, 1, 1, "", "fake_tensordict"], [175, 1, 1, "", "float"], [175, 1, 1, "", "forward"], [175, 1, 1, "", "from_dataloader"], [175, 2, 1, "", "full_action_spec"], [175, 2, 1, "", "full_action_spec_unbatched"], [175, 2, 1, "", "full_done_spec"], [175, 2, 1, "", "full_done_spec_unbatched"], [175, 2, 1, "", "full_observation_spec_unbatched"], [175, 2, 1, "", "full_reward_spec"], [175, 2, 1, "", "full_reward_spec_unbatched"], [175, 2, 1, "", "full_state_spec"], [175, 2, 1, "", "full_state_spec_unbatched"], [175, 1, 1, "", "get_buffer"], [175, 1, 1, "", "get_extra_state"], [175, 1, 1, "", "get_parameter"], [175, 1, 1, "", "get_submodule"], [175, 1, 1, "", "half"], [175, 2, 1, "", "input_spec"], [175, 2, 1, "", "input_spec_unbatched"], [175, 1, 1, "", "insert_transform"], [175, 1, 1, "", "ipu"], [175, 2, 1, "", "is_spec_locked"], [175, 1, 1, "", "load_state_dict"], [175, 1, 1, "", "maybe_reset"], [175, 1, 1, "", "modules"], [175, 1, 1, "", "mtia"], [175, 1, 1, "", "named_buffers"], [175, 1, 1, "", "named_children"], [175, 1, 1, "", "named_modules"], [175, 1, 1, "", "named_parameters"], [175, 2, 1, "", "observation_keys"], [175, 2, 1, "", "observation_spec"], [175, 2, 1, "", "observation_spec_unbatched"], [175, 2, 1, "", "output_spec"], [175, 2, 1, "", "output_spec_unbatched"], [175, 1, 1, "", "parameters"], [175, 1, 1, "", "rand_action"], [175, 1, 1, "", "rand_step"], [175, 1, 1, "", "register_backward_hook"], [175, 1, 1, "", "register_buffer"], [175, 1, 1, "", "register_collector"], [175, 1, 1, "", "register_forward_hook"], [175, 1, 1, "", "register_forward_pre_hook"], [175, 1, 1, "", "register_full_backward_hook"], [175, 1, 1, "", "register_full_backward_pre_hook"], [175, 1, 1, "", "register_gym"], [175, 1, 1, "", "register_load_state_dict_post_hook"], [175, 1, 1, "", "register_load_state_dict_pre_hook"], [175, 1, 1, "", "register_module"], [175, 1, 1, "", "register_parameter"], [175, 1, 1, "", "register_state_dict_post_hook"], [175, 1, 1, "", "register_state_dict_pre_hook"], [175, 1, 1, "", "requires_grad_"], [175, 1, 1, "", "reset"], [175, 1, 1, "", "reset_dataloader"], [175, 2, 1, "", "reset_keys"], [175, 2, 1, "", "reward_key"], [175, 2, 1, "", "reward_keys"], [175, 2, 1, "", "reward_spec"], [175, 2, 1, "", "reward_spec_unbatched"], [175, 1, 1, "", "rollout"], [175, 1, 1, "", "set_extra_state"], [175, 1, 1, "", "set_missing_tolerance"], [175, 1, 1, "", "set_seed"], [175, 1, 1, "", "set_spec_lock_"], [175, 1, 1, "", "set_submodule"], [175, 2, 1, "", "shape"], [175, 1, 1, "", "share_memory"], [175, 2, 1, "", "specs"], [175, 1, 1, "", "state_dict"], [175, 2, 1, "", "state_keys"], [175, 2, 1, "", "state_spec"], [175, 2, 1, "", "state_spec_unbatched"], [175, 1, 1, "", "step"], [175, 1, 1, "", "step_and_maybe_reset"], [175, 1, 1, "", "step_mdp"], [175, 1, 1, "", "to"], [175, 1, 1, "", "to_empty"], [175, 1, 1, "", "train"], [175, 1, 1, "", "type"], [175, 1, 1, "", "xpu"], [175, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.IFEvalScoreData": [[176, 1, 1, "", "cat"], [176, 2, 1, "", "device"], [176, 1, 1, "", "dumps"], [176, 1, 1, "", "fields"], [176, 1, 1, "", "from_any"], [176, 1, 1, "", "from_dataclass"], [176, 1, 1, "", "from_h5"], [176, 1, 1, "", "from_modules"], [176, 1, 1, "", "from_namedtuple"], [176, 1, 1, "", "from_pytree"], [176, 1, 1, "", "from_remote_init"], [176, 1, 1, "", "from_struct_array"], [176, 1, 1, "", "from_tensordict"], [176, 1, 1, "", "from_tuple"], [176, 1, 1, "", "fromkeys"], [176, 1, 1, "", "get"], [176, 1, 1, "", "lazy_stack"], [176, 1, 1, "", "load"], [176, 1, 1, "", "load_"], [176, 1, 1, "", "load_memmap"], [176, 1, 1, "", "load_state_dict"], [176, 1, 1, "", "maybe_dense_stack"], [176, 1, 1, "", "memmap"], [176, 1, 1, "", "memmap_"], [176, 1, 1, "", "memmap_like"], [176, 1, 1, "", "memmap_refresh_"], [176, 1, 1, "", "save"], [176, 1, 1, "", "set"], [176, 1, 1, "", "stack"], [176, 1, 1, "", "state_dict"], [176, 1, 1, "", "to_tensordict"], [176, 1, 1, "", "unbind"]], "torchrl.envs.llm.IfEvalScorer": [[177, 1, 1, "", "add_module"], [177, 1, 1, "", "apply"], [177, 1, 1, "", "bfloat16"], [177, 1, 1, "", "buffers"], [177, 1, 1, "", "children"], [177, 1, 1, "", "close"], [177, 2, 1, "", "collector"], [177, 1, 1, "", "compile"], [177, 2, 1, "", "container"], [177, 1, 1, "", "cpu"], [177, 1, 1, "", "cuda"], [177, 1, 1, "", "default_reward_aggregator"], [177, 1, 1, "", "double"], [177, 1, 1, "", "eval"], [177, 1, 1, "", "extra_repr"], [177, 1, 1, "", "float"], [177, 1, 1, "", "forward"], [177, 1, 1, "", "get_buffer"], [177, 1, 1, "", "get_extra_state"], [177, 1, 1, "", "get_parameter"], [177, 1, 1, "", "get_submodule"], [177, 1, 1, "", "half"], [177, 1, 1, "", "init"], [177, 1, 1, "", "inv"], [177, 1, 1, "", "ipu"], [177, 1, 1, "", "load_state_dict"], [177, 1, 1, "", "modules"], [177, 1, 1, "", "mtia"], [177, 1, 1, "", "named_buffers"], [177, 1, 1, "", "named_children"], [177, 1, 1, "", "named_modules"], [177, 1, 1, "", "named_parameters"], [177, 1, 1, "", "parameters"], [177, 2, 1, "", "parent"], [177, 1, 1, "", "register_backward_hook"], [177, 1, 1, "", "register_buffer"], [177, 1, 1, "", "register_forward_hook"], [177, 1, 1, "", "register_forward_pre_hook"], [177, 1, 1, "", "register_full_backward_hook"], [177, 1, 1, "", "register_full_backward_pre_hook"], [177, 1, 1, "", "register_load_state_dict_post_hook"], [177, 1, 1, "", "register_load_state_dict_pre_hook"], [177, 1, 1, "", "register_module"], [177, 1, 1, "", "register_parameter"], [177, 1, 1, "", "register_state_dict_post_hook"], [177, 1, 1, "", "register_state_dict_pre_hook"], [177, 1, 1, "", "requires_grad_"], [177, 1, 1, "", "set_extra_state"], [177, 1, 1, "", "set_submodule"], [177, 1, 1, "", "share_memory"], [177, 1, 1, "", "state_dict"], [177, 1, 1, "", "to"], [177, 1, 1, "", "to_empty"], [177, 1, 1, "", "train"], [177, 1, 1, "", "transform_action_spec"], [177, 1, 1, "", "transform_done_spec"], [177, 1, 1, "", "transform_env_batch_size"], [177, 1, 1, "", "transform_env_device"], [177, 1, 1, "", "transform_input_spec"], [177, 1, 1, "", "transform_observation_spec"], [177, 1, 1, "", "transform_output_spec"], [177, 1, 1, "", "transform_reward_spec"], [177, 1, 1, "", "transform_state_spec"], [177, 1, 1, "", "type"], [177, 1, 1, "", "xpu"], [177, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.LLMEnv": [[178, 2, 1, "", "action_key"], [178, 2, 1, "", "action_keys"], [178, 2, 1, "", "action_spec"], [178, 2, 1, "", "action_spec_unbatched"], [178, 1, 1, "", "add_module"], [178, 1, 1, "", "add_truncated_keys"], [178, 1, 1, "", "all_actions"], [178, 1, 1, "", "any_done"], [178, 1, 1, "", "append_transform"], [178, 1, 1, "", "apply"], [178, 1, 1, "", "auto_specs_"], [178, 2, 1, "", "batch_dims"], [178, 2, 1, "", "batch_locked"], [178, 2, 1, "", "batch_size"], [178, 1, 1, "", "bfloat16"], [178, 1, 1, "", "buffers"], [178, 1, 1, "", "cardinality"], [178, 1, 1, "", "check_env_specs"], [178, 1, 1, "", "children"], [178, 2, 1, "", "collector"], [178, 1, 1, "", "compile"], [178, 1, 1, "", "cpu"], [178, 1, 1, "", "cuda"], [178, 2, 1, "", "done_key"], [178, 2, 1, "", "done_keys"], [178, 2, 1, "", "done_keys_groups"], [178, 2, 1, "", "done_spec"], [178, 2, 1, "", "done_spec_unbatched"], [178, 1, 1, "", "double"], [178, 1, 1, "", "empty_cache"], [178, 1, 1, "", "eval"], [178, 1, 1, "", "extra_repr"], [178, 1, 1, "", "fake_tensordict"], [178, 1, 1, "", "float"], [178, 1, 1, "", "forward"], [178, 1, 1, "id0", "from_dataloader"], [178, 2, 1, "", "full_action_spec"], [178, 2, 1, "", "full_action_spec_unbatched"], [178, 2, 1, "", "full_done_spec"], [178, 2, 1, "", "full_done_spec_unbatched"], [178, 2, 1, "", "full_observation_spec_unbatched"], [178, 2, 1, "", "full_reward_spec"], [178, 2, 1, "", "full_reward_spec_unbatched"], [178, 2, 1, "", "full_state_spec"], [178, 2, 1, "", "full_state_spec_unbatched"], [178, 1, 1, "", "get_buffer"], [178, 1, 1, "", "get_extra_state"], [178, 1, 1, "", "get_parameter"], [178, 1, 1, "", "get_submodule"], [178, 1, 1, "", "half"], [178, 2, 1, "", "input_spec"], [178, 2, 1, "", "input_spec_unbatched"], [178, 1, 1, "", "ipu"], [178, 2, 1, "", "is_spec_locked"], [178, 1, 1, "", "load_state_dict"], [178, 1, 1, "", "maybe_reset"], [178, 1, 1, "", "modules"], [178, 1, 1, "", "mtia"], [178, 1, 1, "", "named_buffers"], [178, 1, 1, "", "named_children"], [178, 1, 1, "", "named_modules"], [178, 1, 1, "", "named_parameters"], [178, 2, 1, "", "observation_keys"], [178, 2, 1, "", "observation_spec"], [178, 2, 1, "", "observation_spec_unbatched"], [178, 2, 1, "", "output_spec"], [178, 2, 1, "", "output_spec_unbatched"], [178, 1, 1, "", "parameters"], [178, 1, 1, "", "rand_action"], [178, 1, 1, "", "rand_step"], [178, 1, 1, "", "register_backward_hook"], [178, 1, 1, "", "register_buffer"], [178, 1, 1, "", "register_collector"], [178, 1, 1, "", "register_forward_hook"], [178, 1, 1, "", "register_forward_pre_hook"], [178, 1, 1, "", "register_full_backward_hook"], [178, 1, 1, "", "register_full_backward_pre_hook"], [178, 1, 1, "", "register_gym"], [178, 1, 1, "", "register_load_state_dict_post_hook"], [178, 1, 1, "", "register_load_state_dict_pre_hook"], [178, 1, 1, "", "register_module"], [178, 1, 1, "", "register_parameter"], [178, 1, 1, "", "register_state_dict_post_hook"], [178, 1, 1, "", "register_state_dict_pre_hook"], [178, 1, 1, "", "requires_grad_"], [178, 1, 1, "", "reset"], [178, 2, 1, "", "reset_keys"], [178, 2, 1, "", "reward_key"], [178, 2, 1, "", "reward_keys"], [178, 2, 1, "", "reward_spec"], [178, 2, 1, "", "reward_spec_unbatched"], [178, 1, 1, "", "rollout"], [178, 1, 1, "", "set_extra_state"], [178, 1, 1, "", "set_seed"], [178, 1, 1, "", "set_spec_lock_"], [178, 1, 1, "", "set_submodule"], [178, 2, 1, "", "shape"], [178, 1, 1, "", "share_memory"], [178, 2, 1, "", "specs"], [178, 1, 1, "", "state_dict"], [178, 2, 1, "", "state_keys"], [178, 2, 1, "", "state_spec"], [178, 2, 1, "", "state_spec_unbatched"], [178, 1, 1, "", "step"], [178, 1, 1, "", "step_and_maybe_reset"], [178, 1, 1, "", "step_mdp"], [178, 1, 1, "", "to"], [178, 1, 1, "", "to_empty"], [178, 1, 1, "", "train"], [178, 1, 1, "", "type"], [178, 1, 1, "", "xpu"], [178, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.LLMHashingEnv": [[179, 2, 1, "", "action_key"], [179, 2, 1, "", "action_keys"], [179, 2, 1, "", "action_spec"], [179, 2, 1, "", "action_spec_unbatched"], [179, 1, 1, "", "add_module"], [179, 1, 1, "", "add_truncated_keys"], [179, 1, 1, "", "all_actions"], [179, 1, 1, "", "any_done"], [179, 1, 1, "", "append_transform"], [179, 1, 1, "", "apply"], [179, 1, 1, "", "auto_specs_"], [179, 2, 1, "", "batch_dims"], [179, 2, 1, "", "batch_locked"], [179, 2, 1, "", "batch_size"], [179, 1, 1, "", "bfloat16"], [179, 1, 1, "", "buffers"], [179, 1, 1, "", "cardinality"], [179, 1, 1, "", "check_env_specs"], [179, 1, 1, "", "children"], [179, 2, 1, "", "collector"], [179, 1, 1, "", "compile"], [179, 1, 1, "", "cpu"], [179, 1, 1, "", "cuda"], [179, 2, 1, "", "done_key"], [179, 2, 1, "", "done_keys"], [179, 2, 1, "", "done_keys_groups"], [179, 2, 1, "", "done_spec"], [179, 2, 1, "", "done_spec_unbatched"], [179, 1, 1, "", "double"], [179, 1, 1, "", "empty_cache"], [179, 1, 1, "", "eval"], [179, 1, 1, "", "extra_repr"], [179, 1, 1, "", "fake_tensordict"], [179, 1, 1, "", "float"], [179, 1, 1, "", "forward"], [179, 2, 1, "", "full_action_spec"], [179, 2, 1, "", "full_action_spec_unbatched"], [179, 2, 1, "", "full_done_spec"], [179, 2, 1, "", "full_done_spec_unbatched"], [179, 2, 1, "", "full_observation_spec_unbatched"], [179, 2, 1, "", "full_reward_spec"], [179, 2, 1, "", "full_reward_spec_unbatched"], [179, 2, 1, "", "full_state_spec"], [179, 2, 1, "", "full_state_spec_unbatched"], [179, 1, 1, "", "get_buffer"], [179, 1, 1, "", "get_extra_state"], [179, 1, 1, "", "get_parameter"], [179, 1, 1, "", "get_submodule"], [179, 1, 1, "", "half"], [179, 2, 1, "", "input_spec"], [179, 2, 1, "", "input_spec_unbatched"], [179, 1, 1, "", "ipu"], [179, 2, 1, "", "is_spec_locked"], [179, 1, 1, "", "load_state_dict"], [179, 1, 1, "", "make_tensordict"], [179, 1, 1, "", "maybe_reset"], [179, 1, 1, "", "modules"], [179, 1, 1, "", "mtia"], [179, 1, 1, "", "named_buffers"], [179, 1, 1, "", "named_children"], [179, 1, 1, "", "named_modules"], [179, 1, 1, "", "named_parameters"], [179, 2, 1, "", "observation_keys"], [179, 2, 1, "", "observation_spec"], [179, 2, 1, "", "observation_spec_unbatched"], [179, 2, 1, "", "output_spec"], [179, 2, 1, "", "output_spec_unbatched"], [179, 1, 1, "", "parameters"], [179, 1, 1, "", "rand_action"], [179, 1, 1, "", "rand_step"], [179, 1, 1, "", "register_backward_hook"], [179, 1, 1, "", "register_buffer"], [179, 1, 1, "", "register_collector"], [179, 1, 1, "", "register_forward_hook"], [179, 1, 1, "", "register_forward_pre_hook"], [179, 1, 1, "", "register_full_backward_hook"], [179, 1, 1, "", "register_full_backward_pre_hook"], [179, 1, 1, "", "register_gym"], [179, 1, 1, "", "register_load_state_dict_post_hook"], [179, 1, 1, "", "register_load_state_dict_pre_hook"], [179, 1, 1, "", "register_module"], [179, 1, 1, "", "register_parameter"], [179, 1, 1, "", "register_state_dict_post_hook"], [179, 1, 1, "", "register_state_dict_pre_hook"], [179, 1, 1, "", "requires_grad_"], [179, 1, 1, "", "reset"], [179, 2, 1, "", "reset_keys"], [179, 2, 1, "", "reward_key"], [179, 2, 1, "", "reward_keys"], [179, 2, 1, "", "reward_spec"], [179, 2, 1, "", "reward_spec_unbatched"], [179, 1, 1, "", "rollout"], [179, 1, 1, "", "set_extra_state"], [179, 1, 1, "", "set_seed"], [179, 1, 1, "", "set_spec_lock_"], [179, 1, 1, "", "set_submodule"], [179, 2, 1, "", "shape"], [179, 1, 1, "", "share_memory"], [179, 2, 1, "", "specs"], [179, 1, 1, "", "state_dict"], [179, 2, 1, "", "state_keys"], [179, 2, 1, "", "state_spec"], [179, 2, 1, "", "state_spec_unbatched"], [179, 1, 1, "", "step"], [179, 1, 1, "", "step_and_maybe_reset"], [179, 1, 1, "", "step_mdp"], [179, 1, 1, "", "to"], [179, 1, 1, "", "to_empty"], [179, 1, 1, "", "train"], [179, 1, 1, "", "type"], [179, 1, 1, "", "xpu"], [179, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.MLGymWrapper": [[180, 2, 1, "", "action_key"], [180, 2, 1, "", "action_keys"], [180, 2, 1, "", "action_spec"], [180, 2, 1, "", "action_spec_unbatched"], [180, 1, 1, "", "add_module"], [180, 1, 1, "", "add_truncated_keys"], [180, 1, 1, "", "all_actions"], [180, 1, 1, "", "any_done"], [180, 1, 1, "", "append_transform"], [180, 1, 1, "", "apply"], [180, 1, 1, "", "auto_register_info_dict"], [180, 1, 1, "", "auto_specs_"], [180, 2, 1, "", "batch_dims"], [180, 2, 1, "", "batch_locked"], [180, 2, 1, "", "batch_size"], [180, 1, 1, "", "bfloat16"], [180, 1, 1, "", "buffers"], [180, 1, 1, "", "cardinality"], [180, 1, 1, "", "check_env_specs"], [180, 1, 1, "", "children"], [180, 1, 1, "", "close"], [180, 2, 1, "", "collector"], [180, 1, 1, "", "compile"], [180, 1, 1, "", "cpu"], [180, 1, 1, "", "cuda"], [180, 2, 1, "", "done_key"], [180, 2, 1, "", "done_keys"], [180, 2, 1, "", "done_keys_groups"], [180, 2, 1, "", "done_spec"], [180, 2, 1, "", "done_spec_unbatched"], [180, 1, 1, "", "double"], [180, 1, 1, "", "empty_cache"], [180, 1, 1, "", "eval"], [180, 1, 1, "", "extra_repr"], [180, 1, 1, "", "fake_tensordict"], [180, 1, 1, "", "fast_encoding"], [180, 1, 1, "", "float"], [180, 1, 1, "", "forward"], [180, 2, 1, "", "full_action_spec"], [180, 2, 1, "", "full_action_spec_unbatched"], [180, 2, 1, "", "full_done_spec"], [180, 2, 1, "", "full_done_spec_unbatched"], [180, 2, 1, "", "full_observation_spec_unbatched"], [180, 2, 1, "", "full_reward_spec"], [180, 2, 1, "", "full_reward_spec_unbatched"], [180, 2, 1, "", "full_state_spec"], [180, 2, 1, "", "full_state_spec_unbatched"], [180, 1, 1, "", "get_buffer"], [180, 1, 1, "", "get_extra_state"], [180, 1, 1, "", "get_library_name"], [180, 1, 1, "", "get_parameter"], [180, 1, 1, "", "get_submodule"], [180, 1, 1, "", "half"], [180, 2, 1, "", "input_spec"], [180, 2, 1, "", "input_spec_unbatched"], [180, 1, 1, "", "ipu"], [180, 2, 1, "", "is_spec_locked"], [180, 1, 1, "", "load_state_dict"], [180, 1, 1, "", "maybe_reset"], [180, 1, 1, "", "modules"], [180, 1, 1, "", "mtia"], [180, 1, 1, "", "named_buffers"], [180, 1, 1, "", "named_children"], [180, 1, 1, "", "named_modules"], [180, 1, 1, "", "named_parameters"], [180, 2, 1, "", "observation_keys"], [180, 2, 1, "", "observation_spec"], [180, 2, 1, "", "observation_spec_unbatched"], [180, 2, 1, "", "output_spec"], [180, 2, 1, "", "output_spec_unbatched"], [180, 1, 1, "", "parameters"], [180, 1, 1, "", "rand_action"], [180, 1, 1, "", "rand_step"], [180, 1, 1, "", "read_action"], [180, 1, 1, "", "read_done"], [180, 1, 1, "", "read_obs"], [180, 1, 1, "", "read_reward"], [180, 1, 1, "", "register_backward_hook"], [180, 1, 1, "", "register_buffer"], [180, 1, 1, "", "register_collector"], [180, 1, 1, "", "register_forward_hook"], [180, 1, 1, "", "register_forward_pre_hook"], [180, 1, 1, "", "register_full_backward_hook"], [180, 1, 1, "", "register_full_backward_pre_hook"], [180, 1, 1, "", "register_gym"], [180, 1, 1, "", "register_load_state_dict_post_hook"], [180, 1, 1, "", "register_load_state_dict_pre_hook"], [180, 1, 1, "", "register_module"], [180, 1, 1, "", "register_parameter"], [180, 1, 1, "", "register_state_dict_post_hook"], [180, 1, 1, "", "register_state_dict_pre_hook"], [180, 1, 1, "", "requires_grad_"], [180, 1, 1, "", "reset"], [180, 2, 1, "", "reset_keys"], [180, 2, 1, "", "reward_key"], [180, 2, 1, "", "reward_keys"], [180, 2, 1, "", "reward_spec"], [180, 2, 1, "", "reward_spec_unbatched"], [180, 1, 1, "", "rollout"], [180, 1, 1, "", "set_extra_state"], [180, 1, 1, "", "set_info_dict_reader"], [180, 1, 1, "", "set_seed"], [180, 1, 1, "", "set_spec_lock_"], [180, 1, 1, "", "set_submodule"], [180, 2, 1, "", "shape"], [180, 1, 1, "", "share_memory"], [180, 2, 1, "", "specs"], [180, 1, 1, "", "state_dict"], [180, 2, 1, "", "state_keys"], [180, 2, 1, "", "state_spec"], [180, 2, 1, "", "state_spec_unbatched"], [180, 1, 1, "", "step"], [180, 1, 1, "", "step_and_maybe_reset"], [180, 1, 1, "", "step_mdp"], [180, 1, 1, "", "to"], [180, 1, 1, "", "to_empty"], [180, 1, 1, "", "train"], [180, 1, 1, "", "type"], [180, 1, 1, "", "xpu"], [180, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms": [[183, 0, 1, "", "AddThinkingPrompt"], [184, 0, 1, "", "BrowserTransform"], [185, 0, 1, "", "DataLoadingPrimer"], [186, 0, 1, "", "ExecuteToolsInOrder"], [187, 0, 1, "", "JSONCallParser"], [188, 0, 1, "", "KLComputation"], [189, 0, 1, "", "KLRewardTransform"], [190, 0, 1, "", "MCPToolTransform"], [191, 0, 1, "", "PolicyVersion"], [192, 0, 1, "", "PythonExecutorService"], [193, 0, 1, "", "PythonInterpreter"], [194, 0, 1, "", "RayDataLoadingPrimer"], [195, 0, 1, "", "RetrieveKL"], [196, 0, 1, "", "RetrieveLogProb"], [197, 0, 1, "", "SimpleToolTransform"], [198, 0, 1, "", "TemplateTransform"], [199, 0, 1, "", "Tokenizer"], [200, 0, 1, "", "ToolCall"], [201, 0, 1, "", "ToolRegistry"], [202, 0, 1, "", "ToolService"], [203, 0, 1, "", "XMLBlockParser"], [204, 0, 1, "", "as_nested_tensor"], [205, 0, 1, "", "as_padded_tensor"]], "torchrl.envs.llm.transforms.AddThinkingPrompt": [[183, 1, 1, "", "add_module"], [183, 1, 1, "", "apply"], [183, 1, 1, "", "bfloat16"], [183, 1, 1, "", "buffers"], [183, 1, 1, "", "children"], [183, 1, 1, "", "close"], [183, 2, 1, "", "collector"], [183, 1, 1, "", "compile"], [183, 2, 1, "", "container"], [183, 1, 1, "", "cpu"], [183, 1, 1, "", "cuda"], [183, 1, 1, "", "double"], [183, 1, 1, "", "eval"], [183, 1, 1, "", "extra_repr"], [183, 1, 1, "", "float"], [183, 1, 1, "", "forward"], [183, 1, 1, "", "get_buffer"], [183, 1, 1, "", "get_extra_state"], [183, 1, 1, "", "get_parameter"], [183, 1, 1, "", "get_submodule"], [183, 1, 1, "", "half"], [183, 1, 1, "", "init"], [183, 1, 1, "", "inv"], [183, 1, 1, "", "ipu"], [183, 1, 1, "", "load_state_dict"], [183, 1, 1, "", "modules"], [183, 1, 1, "", "mtia"], [183, 1, 1, "", "named_buffers"], [183, 1, 1, "", "named_children"], [183, 1, 1, "", "named_modules"], [183, 1, 1, "", "named_parameters"], [183, 1, 1, "", "parameters"], [183, 2, 1, "", "parent"], [183, 1, 1, "", "register_backward_hook"], [183, 1, 1, "", "register_buffer"], [183, 1, 1, "", "register_forward_hook"], [183, 1, 1, "", "register_forward_pre_hook"], [183, 1, 1, "", "register_full_backward_hook"], [183, 1, 1, "", "register_full_backward_pre_hook"], [183, 1, 1, "", "register_load_state_dict_post_hook"], [183, 1, 1, "", "register_load_state_dict_pre_hook"], [183, 1, 1, "", "register_module"], [183, 1, 1, "", "register_parameter"], [183, 1, 1, "", "register_state_dict_post_hook"], [183, 1, 1, "", "register_state_dict_pre_hook"], [183, 1, 1, "", "requires_grad_"], [183, 1, 1, "", "set_extra_state"], [183, 1, 1, "", "set_submodule"], [183, 1, 1, "", "share_memory"], [183, 1, 1, "", "state_dict"], [183, 1, 1, "", "to"], [183, 1, 1, "", "to_empty"], [183, 1, 1, "", "train"], [183, 1, 1, "", "transform_action_spec"], [183, 1, 1, "", "transform_done_spec"], [183, 1, 1, "", "transform_env_batch_size"], [183, 1, 1, "", "transform_env_device"], [183, 1, 1, "", "transform_input_spec"], [183, 1, 1, "", "transform_observation_spec"], [183, 1, 1, "", "transform_output_spec"], [183, 1, 1, "", "transform_reward_spec"], [183, 1, 1, "", "transform_state_spec"], [183, 1, 1, "", "type"], [183, 1, 1, "", "xpu"], [183, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.BrowserTransform": [[184, 1, 1, "", "add_module"], [184, 1, 1, "", "apply"], [184, 1, 1, "", "bfloat16"], [184, 1, 1, "", "buffers"], [184, 1, 1, "", "children"], [184, 1, 1, "", "clone"], [184, 1, 1, "", "close"], [184, 2, 1, "", "collector"], [184, 1, 1, "", "compile"], [184, 2, 1, "", "container"], [184, 1, 1, "", "cpu"], [184, 1, 1, "", "cuda"], [184, 1, 1, "", "double"], [184, 1, 1, "", "eval"], [184, 1, 1, "", "extra_repr"], [184, 1, 1, "", "float"], [184, 1, 1, "", "forward"], [184, 1, 1, "", "get_buffer"], [184, 1, 1, "", "get_extra_state"], [184, 1, 1, "", "get_parameter"], [184, 1, 1, "", "get_submodule"], [184, 1, 1, "", "half"], [184, 1, 1, "", "init"], [184, 1, 1, "", "inv"], [184, 1, 1, "", "ipu"], [184, 1, 1, "", "load_state_dict"], [184, 1, 1, "", "modules"], [184, 1, 1, "", "mtia"], [184, 1, 1, "", "named_buffers"], [184, 1, 1, "", "named_children"], [184, 1, 1, "", "named_modules"], [184, 1, 1, "", "named_parameters"], [184, 1, 1, "", "parameters"], [184, 2, 1, "", "parent"], [184, 1, 1, "", "register_backward_hook"], [184, 1, 1, "", "register_buffer"], [184, 1, 1, "", "register_forward_hook"], [184, 1, 1, "", "register_forward_pre_hook"], [184, 1, 1, "", "register_full_backward_hook"], [184, 1, 1, "", "register_full_backward_pre_hook"], [184, 1, 1, "", "register_load_state_dict_post_hook"], [184, 1, 1, "", "register_load_state_dict_pre_hook"], [184, 1, 1, "", "register_module"], [184, 1, 1, "", "register_parameter"], [184, 1, 1, "", "register_state_dict_post_hook"], [184, 1, 1, "", "register_state_dict_pre_hook"], [184, 1, 1, "", "requires_grad_"], [184, 1, 1, "", "set_extra_state"], [184, 1, 1, "", "set_submodule"], [184, 1, 1, "", "share_memory"], [184, 1, 1, "", "state_dict"], [184, 1, 1, "", "to"], [184, 1, 1, "", "to_empty"], [184, 1, 1, "", "train"], [184, 1, 1, "", "transform_action_spec"], [184, 1, 1, "", "transform_done_spec"], [184, 1, 1, "", "transform_env_batch_size"], [184, 1, 1, "", "transform_env_device"], [184, 1, 1, "", "transform_input_spec"], [184, 1, 1, "", "transform_observation_spec"], [184, 1, 1, "", "transform_output_spec"], [184, 1, 1, "", "transform_reward_spec"], [184, 1, 1, "", "transform_state_spec"], [184, 1, 1, "", "type"], [184, 1, 1, "", "xpu"], [184, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.DataLoadingPrimer": [[185, 1, 1, "", "add_module"], [185, 1, 1, "", "apply"], [185, 1, 1, "", "bfloat16"], [185, 1, 1, "", "buffers"], [185, 1, 1, "", "children"], [185, 1, 1, "", "close"], [185, 2, 1, "", "collector"], [185, 1, 1, "", "compile"], [185, 2, 1, "", "container"], [185, 1, 1, "", "cpu"], [185, 1, 1, "", "cuda"], [185, 1, 1, "", "double"], [185, 1, 1, "", "eval"], [185, 1, 1, "", "extra_repr"], [185, 1, 1, "", "float"], [185, 1, 1, "", "forward"], [185, 1, 1, "", "get_buffer"], [185, 1, 1, "", "get_extra_state"], [185, 1, 1, "", "get_parameter"], [185, 1, 1, "", "get_submodule"], [185, 1, 1, "", "half"], [185, 1, 1, "", "init"], [185, 1, 1, "", "inv"], [185, 1, 1, "", "ipu"], [185, 1, 1, "", "load_state_dict"], [185, 1, 1, "", "modules"], [185, 1, 1, "", "mtia"], [185, 1, 1, "", "named_buffers"], [185, 1, 1, "", "named_children"], [185, 1, 1, "", "named_modules"], [185, 1, 1, "", "named_parameters"], [185, 1, 1, "", "parameters"], [185, 2, 1, "", "parent"], [185, 1, 1, "", "register_backward_hook"], [185, 1, 1, "", "register_buffer"], [185, 1, 1, "", "register_forward_hook"], [185, 1, 1, "", "register_forward_pre_hook"], [185, 1, 1, "", "register_full_backward_hook"], [185, 1, 1, "", "register_full_backward_pre_hook"], [185, 1, 1, "", "register_load_state_dict_post_hook"], [185, 1, 1, "", "register_load_state_dict_pre_hook"], [185, 1, 1, "", "register_module"], [185, 1, 1, "", "register_parameter"], [185, 1, 1, "", "register_state_dict_post_hook"], [185, 1, 1, "", "register_state_dict_pre_hook"], [185, 1, 1, "", "requires_grad_"], [185, 1, 1, "", "reset_dataloader"], [185, 1, 1, "", "set_extra_state"], [185, 1, 1, "", "set_submodule"], [185, 1, 1, "", "share_memory"], [185, 1, 1, "", "state_dict"], [185, 1, 1, "", "to"], [185, 1, 1, "", "to_empty"], [185, 1, 1, "", "train"], [185, 1, 1, "", "transform_action_spec"], [185, 1, 1, "", "transform_done_spec"], [185, 1, 1, "", "transform_env_batch_size"], [185, 1, 1, "", "transform_env_device"], [185, 1, 1, "", "transform_input_spec"], [185, 1, 1, "", "transform_observation_spec"], [185, 1, 1, "", "transform_output_spec"], [185, 1, 1, "", "transform_reward_spec"], [185, 1, 1, "", "transform_state_spec"], [185, 1, 1, "", "type"], [185, 1, 1, "", "xpu"], [185, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.ExecuteToolsInOrder": [[186, 1, 1, "", "add_module"], [186, 1, 1, "", "apply"], [186, 1, 1, "", "bfloat16"], [186, 1, 1, "", "buffers"], [186, 1, 1, "", "children"], [186, 1, 1, "", "close"], [186, 2, 1, "", "collector"], [186, 1, 1, "", "compile"], [186, 2, 1, "", "container"], [186, 1, 1, "", "cpu"], [186, 1, 1, "", "cuda"], [186, 1, 1, "", "double"], [186, 1, 1, "", "eval"], [186, 1, 1, "", "extra_repr"], [186, 1, 1, "", "float"], [186, 1, 1, "", "forward"], [186, 1, 1, "", "get_buffer"], [186, 1, 1, "", "get_extra_state"], [186, 1, 1, "", "get_parameter"], [186, 1, 1, "", "get_submodule"], [186, 1, 1, "", "half"], [186, 1, 1, "", "init"], [186, 1, 1, "", "inv"], [186, 1, 1, "", "ipu"], [186, 1, 1, "", "load_state_dict"], [186, 1, 1, "", "modules"], [186, 1, 1, "", "mtia"], [186, 1, 1, "", "named_buffers"], [186, 1, 1, "", "named_children"], [186, 1, 1, "", "named_modules"], [186, 1, 1, "", "named_parameters"], [186, 1, 1, "", "parameters"], [186, 2, 1, "", "parent"], [186, 1, 1, "", "register_backward_hook"], [186, 1, 1, "", "register_buffer"], [186, 1, 1, "", "register_forward_hook"], [186, 1, 1, "", "register_forward_pre_hook"], [186, 1, 1, "", "register_full_backward_hook"], [186, 1, 1, "", "register_full_backward_pre_hook"], [186, 1, 1, "", "register_load_state_dict_post_hook"], [186, 1, 1, "", "register_load_state_dict_pre_hook"], [186, 1, 1, "", "register_module"], [186, 1, 1, "", "register_parameter"], [186, 1, 1, "", "register_state_dict_post_hook"], [186, 1, 1, "", "register_state_dict_pre_hook"], [186, 1, 1, "", "requires_grad_"], [186, 1, 1, "", "set_extra_state"], [186, 1, 1, "", "set_submodule"], [186, 1, 1, "", "share_memory"], [186, 1, 1, "", "state_dict"], [186, 1, 1, "", "to"], [186, 1, 1, "", "to_empty"], [186, 1, 1, "", "train"], [186, 1, 1, "", "transform_action_spec"], [186, 1, 1, "", "transform_done_spec"], [186, 1, 1, "", "transform_env_batch_size"], [186, 1, 1, "", "transform_env_device"], [186, 1, 1, "", "transform_input_spec"], [186, 1, 1, "", "transform_observation_spec"], [186, 1, 1, "", "transform_output_spec"], [186, 1, 1, "", "transform_reward_spec"], [186, 1, 1, "", "transform_state_spec"], [186, 1, 1, "", "type"], [186, 1, 1, "", "xpu"], [186, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.KLComputation": [[188, 1, 1, "", "add_module"], [188, 1, 1, "", "apply"], [188, 1, 1, "", "bfloat16"], [188, 1, 1, "", "buffers"], [188, 1, 1, "", "children"], [188, 1, 1, "", "close"], [188, 2, 1, "", "collector"], [188, 1, 1, "", "compile"], [188, 2, 1, "", "container"], [188, 1, 1, "", "cpu"], [188, 1, 1, "", "cuda"], [188, 1, 1, "", "double"], [188, 1, 1, "", "eval"], [188, 1, 1, "", "extra_repr"], [188, 1, 1, "", "float"], [188, 1, 1, "", "forward"], [188, 1, 1, "", "get_buffer"], [188, 1, 1, "", "get_extra_state"], [188, 1, 1, "", "get_parameter"], [188, 1, 1, "", "get_submodule"], [188, 1, 1, "", "half"], [188, 1, 1, "", "init"], [188, 1, 1, "", "inv"], [188, 1, 1, "", "ipu"], [188, 1, 1, "", "load_state_dict"], [188, 1, 1, "", "modules"], [188, 1, 1, "", "mtia"], [188, 1, 1, "", "named_buffers"], [188, 1, 1, "", "named_children"], [188, 1, 1, "", "named_modules"], [188, 1, 1, "", "named_parameters"], [188, 1, 1, "", "parameters"], [188, 2, 1, "", "parent"], [188, 1, 1, "", "register_backward_hook"], [188, 1, 1, "", "register_buffer"], [188, 1, 1, "", "register_forward_hook"], [188, 1, 1, "", "register_forward_pre_hook"], [188, 1, 1, "", "register_full_backward_hook"], [188, 1, 1, "", "register_full_backward_pre_hook"], [188, 1, 1, "", "register_load_state_dict_post_hook"], [188, 1, 1, "", "register_load_state_dict_pre_hook"], [188, 1, 1, "", "register_module"], [188, 1, 1, "", "register_parameter"], [188, 1, 1, "", "register_state_dict_post_hook"], [188, 1, 1, "", "register_state_dict_pre_hook"], [188, 1, 1, "", "requires_grad_"], [188, 1, 1, "", "set_extra_state"], [188, 1, 1, "", "set_submodule"], [188, 1, 1, "", "share_memory"], [188, 1, 1, "", "state_dict"], [188, 1, 1, "", "to"], [188, 1, 1, "", "to_empty"], [188, 1, 1, "", "train"], [188, 1, 1, "", "transform_action_spec"], [188, 1, 1, "", "transform_done_spec"], [188, 1, 1, "", "transform_env_batch_size"], [188, 1, 1, "", "transform_env_device"], [188, 1, 1, "", "transform_input_spec"], [188, 1, 1, "", "transform_observation_spec"], [188, 1, 1, "", "transform_output_spec"], [188, 1, 1, "", "transform_reward_spec"], [188, 1, 1, "", "transform_state_spec"], [188, 1, 1, "", "type"], [188, 1, 1, "", "xpu"], [188, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.KLRewardTransform": [[189, 1, 1, "", "add_module"], [189, 1, 1, "", "apply"], [189, 1, 1, "", "bfloat16"], [189, 1, 1, "", "buffers"], [189, 1, 1, "", "children"], [189, 1, 1, "", "close"], [189, 2, 1, "", "collector"], [189, 1, 1, "", "compile"], [189, 2, 1, "", "container"], [189, 1, 1, "", "cpu"], [189, 1, 1, "", "cuda"], [189, 1, 1, "", "double"], [189, 1, 1, "", "eval"], [189, 1, 1, "", "extra_repr"], [189, 1, 1, "", "float"], [189, 1, 1, "", "forward"], [189, 1, 1, "", "get_buffer"], [189, 1, 1, "", "get_extra_state"], [189, 1, 1, "", "get_parameter"], [189, 1, 1, "", "get_submodule"], [189, 1, 1, "", "half"], [189, 1, 1, "", "init"], [189, 1, 1, "", "inv"], [189, 1, 1, "", "ipu"], [189, 1, 1, "", "load_state_dict"], [189, 1, 1, "", "modules"], [189, 1, 1, "", "mtia"], [189, 1, 1, "", "named_buffers"], [189, 1, 1, "", "named_children"], [189, 1, 1, "", "named_modules"], [189, 1, 1, "", "named_parameters"], [189, 1, 1, "", "parameters"], [189, 2, 1, "", "parent"], [189, 1, 1, "", "register_backward_hook"], [189, 1, 1, "", "register_buffer"], [189, 1, 1, "", "register_forward_hook"], [189, 1, 1, "", "register_forward_pre_hook"], [189, 1, 1, "", "register_full_backward_hook"], [189, 1, 1, "", "register_full_backward_pre_hook"], [189, 1, 1, "", "register_load_state_dict_post_hook"], [189, 1, 1, "", "register_load_state_dict_pre_hook"], [189, 1, 1, "", "register_module"], [189, 1, 1, "", "register_parameter"], [189, 1, 1, "", "register_state_dict_post_hook"], [189, 1, 1, "", "register_state_dict_pre_hook"], [189, 1, 1, "", "requires_grad_"], [189, 1, 1, "", "set_extra_state"], [189, 1, 1, "", "set_submodule"], [189, 1, 1, "", "share_memory"], [189, 1, 1, "", "state_dict"], [189, 1, 1, "", "to"], [189, 1, 1, "", "to_empty"], [189, 1, 1, "", "train"], [189, 1, 1, "", "transform_action_spec"], [189, 1, 1, "", "transform_done_spec"], [189, 1, 1, "", "transform_env_batch_size"], [189, 1, 1, "", "transform_env_device"], [189, 1, 1, "", "transform_input_spec"], [189, 1, 1, "", "transform_observation_spec"], [189, 1, 1, "", "transform_output_spec"], [189, 1, 1, "", "transform_reward_spec"], [189, 1, 1, "", "transform_state_spec"], [189, 1, 1, "", "type"], [189, 1, 1, "", "xpu"], [189, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.MCPToolTransform": [[190, 1, 1, "", "add_module"], [190, 1, 1, "", "apply"], [190, 1, 1, "", "bfloat16"], [190, 1, 1, "", "buffers"], [190, 1, 1, "", "children"], [190, 1, 1, "", "close"], [190, 2, 1, "", "collector"], [190, 1, 1, "", "compile"], [190, 2, 1, "", "container"], [190, 1, 1, "", "cpu"], [190, 1, 1, "", "cuda"], [190, 1, 1, "", "double"], [190, 1, 1, "", "eval"], [190, 1, 1, "", "extra_repr"], [190, 1, 1, "", "float"], [190, 1, 1, "", "forward"], [190, 1, 1, "", "get_buffer"], [190, 1, 1, "", "get_extra_state"], [190, 1, 1, "", "get_parameter"], [190, 1, 1, "", "get_submodule"], [190, 1, 1, "", "half"], [190, 1, 1, "", "init"], [190, 1, 1, "", "inv"], [190, 1, 1, "", "ipu"], [190, 1, 1, "", "load_state_dict"], [190, 1, 1, "", "modules"], [190, 1, 1, "", "mtia"], [190, 1, 1, "", "named_buffers"], [190, 1, 1, "", "named_children"], [190, 1, 1, "", "named_modules"], [190, 1, 1, "", "named_parameters"], [190, 1, 1, "", "parameters"], [190, 2, 1, "", "parent"], [190, 1, 1, "", "register_backward_hook"], [190, 1, 1, "", "register_buffer"], [190, 1, 1, "", "register_forward_hook"], [190, 1, 1, "", "register_forward_pre_hook"], [190, 1, 1, "", "register_full_backward_hook"], [190, 1, 1, "", "register_full_backward_pre_hook"], [190, 1, 1, "", "register_load_state_dict_post_hook"], [190, 1, 1, "", "register_load_state_dict_pre_hook"], [190, 1, 1, "", "register_module"], [190, 1, 1, "", "register_parameter"], [190, 1, 1, "", "register_state_dict_post_hook"], [190, 1, 1, "", "register_state_dict_pre_hook"], [190, 1, 1, "", "requires_grad_"], [190, 1, 1, "", "set_extra_state"], [190, 1, 1, "", "set_submodule"], [190, 1, 1, "", "share_memory"], [190, 1, 1, "", "state_dict"], [190, 1, 1, "", "to"], [190, 1, 1, "", "to_empty"], [190, 1, 1, "", "train"], [190, 1, 1, "", "transform_action_spec"], [190, 1, 1, "", "transform_done_spec"], [190, 1, 1, "", "transform_env_batch_size"], [190, 1, 1, "", "transform_env_device"], [190, 1, 1, "", "transform_input_spec"], [190, 1, 1, "", "transform_observation_spec"], [190, 1, 1, "", "transform_output_spec"], [190, 1, 1, "", "transform_reward_spec"], [190, 1, 1, "", "transform_state_spec"], [190, 1, 1, "", "type"], [190, 1, 1, "", "xpu"], [190, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.PolicyVersion": [[191, 1, 1, "", "add_module"], [191, 1, 1, "", "apply"], [191, 1, 1, "", "bfloat16"], [191, 1, 1, "", "buffers"], [191, 1, 1, "", "children"], [191, 1, 1, "", "close"], [191, 2, 1, "", "collector"], [191, 1, 1, "", "compile"], [191, 2, 1, "", "container"], [191, 1, 1, "", "cpu"], [191, 1, 1, "", "cuda"], [191, 1, 1, "", "double"], [191, 1, 1, "", "eval"], [191, 1, 1, "", "extra_repr"], [191, 1, 1, "", "float"], [191, 1, 1, "", "forward"], [191, 1, 1, "", "get_buffer"], [191, 1, 1, "", "get_extra_state"], [191, 1, 1, "", "get_parameter"], [191, 1, 1, "", "get_submodule"], [191, 1, 1, "", "half"], [191, 1, 1, "", "increment_version"], [191, 1, 1, "", "init"], [191, 1, 1, "", "inv"], [191, 1, 1, "", "ipu"], [191, 1, 1, "", "load_state_dict"], [191, 1, 1, "", "modules"], [191, 1, 1, "", "mtia"], [191, 1, 1, "", "named_buffers"], [191, 1, 1, "", "named_children"], [191, 1, 1, "", "named_modules"], [191, 1, 1, "", "named_parameters"], [191, 1, 1, "", "parameters"], [191, 2, 1, "", "parent"], [191, 1, 1, "", "register_backward_hook"], [191, 1, 1, "", "register_buffer"], [191, 1, 1, "", "register_forward_hook"], [191, 1, 1, "", "register_forward_pre_hook"], [191, 1, 1, "", "register_full_backward_hook"], [191, 1, 1, "", "register_full_backward_pre_hook"], [191, 1, 1, "", "register_load_state_dict_post_hook"], [191, 1, 1, "", "register_load_state_dict_pre_hook"], [191, 1, 1, "", "register_module"], [191, 1, 1, "", "register_parameter"], [191, 1, 1, "", "register_state_dict_post_hook"], [191, 1, 1, "", "register_state_dict_pre_hook"], [191, 1, 1, "", "requires_grad_"], [191, 1, 1, "", "set_extra_state"], [191, 1, 1, "", "set_submodule"], [191, 1, 1, "", "share_memory"], [191, 1, 1, "", "state_dict"], [191, 1, 1, "", "to"], [191, 1, 1, "", "to_empty"], [191, 1, 1, "", "train"], [191, 1, 1, "", "transform_action_spec"], [191, 1, 1, "", "transform_done_spec"], [191, 1, 1, "", "transform_env_batch_size"], [191, 1, 1, "", "transform_env_device"], [191, 1, 1, "", "transform_input_spec"], [191, 1, 1, "", "transform_observation_spec"], [191, 1, 1, "", "transform_output_spec"], [191, 1, 1, "", "transform_reward_spec"], [191, 1, 1, "", "transform_state_spec"], [191, 1, 1, "", "type"], [191, 2, 1, "", "version"], [191, 1, 1, "", "xpu"], [191, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.PythonExecutorService": [[192, 1, 1, "", "cleanup"], [192, 1, 1, "", "execute"]], "torchrl.envs.llm.transforms.PythonInterpreter": [[193, 1, 1, "", "add_module"], [193, 1, 1, "", "apply"], [193, 1, 1, "", "bfloat16"], [193, 1, 1, "", "buffers"], [193, 1, 1, "", "children"], [193, 1, 1, "", "clone"], [193, 1, 1, "", "close"], [193, 2, 1, "", "collector"], [193, 1, 1, "", "compile"], [193, 2, 1, "", "container"], [193, 1, 1, "", "cpu"], [193, 1, 1, "", "cuda"], [193, 1, 1, "", "double"], [193, 1, 1, "", "eval"], [193, 1, 1, "", "extra_repr"], [193, 1, 1, "", "float"], [193, 1, 1, "", "forward"], [193, 1, 1, "", "get_buffer"], [193, 1, 1, "", "get_extra_state"], [193, 1, 1, "", "get_parameter"], [193, 1, 1, "", "get_submodule"], [193, 1, 1, "", "half"], [193, 1, 1, "", "init"], [193, 1, 1, "", "inv"], [193, 1, 1, "", "ipu"], [193, 1, 1, "", "load_state_dict"], [193, 1, 1, "", "modules"], [193, 1, 1, "", "mtia"], [193, 1, 1, "", "named_buffers"], [193, 1, 1, "", "named_children"], [193, 1, 1, "", "named_modules"], [193, 1, 1, "", "named_parameters"], [193, 1, 1, "", "parameters"], [193, 2, 1, "", "parent"], [193, 1, 1, "", "register_backward_hook"], [193, 1, 1, "", "register_buffer"], [193, 1, 1, "", "register_forward_hook"], [193, 1, 1, "", "register_forward_pre_hook"], [193, 1, 1, "", "register_full_backward_hook"], [193, 1, 1, "", "register_full_backward_pre_hook"], [193, 1, 1, "", "register_load_state_dict_post_hook"], [193, 1, 1, "", "register_load_state_dict_pre_hook"], [193, 1, 1, "", "register_module"], [193, 1, 1, "", "register_parameter"], [193, 1, 1, "", "register_state_dict_post_hook"], [193, 1, 1, "", "register_state_dict_pre_hook"], [193, 1, 1, "", "requires_grad_"], [193, 1, 1, "", "set_extra_state"], [193, 1, 1, "", "set_submodule"], [193, 1, 1, "", "share_memory"], [193, 1, 1, "", "state_dict"], [193, 1, 1, "", "to"], [193, 1, 1, "", "to_empty"], [193, 1, 1, "", "train"], [193, 1, 1, "", "transform_action_spec"], [193, 1, 1, "", "transform_done_spec"], [193, 1, 1, "", "transform_env_batch_size"], [193, 1, 1, "", "transform_env_device"], [193, 1, 1, "", "transform_input_spec"], [193, 1, 1, "", "transform_observation_spec"], [193, 1, 1, "", "transform_output_spec"], [193, 1, 1, "", "transform_reward_spec"], [193, 1, 1, "", "transform_state_spec"], [193, 1, 1, "", "type"], [193, 1, 1, "", "xpu"], [193, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.RayDataLoadingPrimer": [[194, 1, 1, "", "add_module"], [194, 1, 1, "", "apply"], [194, 2, 1, "", "base_env"], [194, 1, 1, "", "bfloat16"], [194, 1, 1, "", "buffers"], [194, 1, 1, "", "children"], [194, 1, 1, "", "clone"], [194, 1, 1, "", "close"], [194, 2, 1, "", "collector"], [194, 1, 1, "", "compile"], [194, 2, 1, "", "container"], [194, 1, 1, "", "cpu"], [194, 1, 1, "", "cuda"], [194, 2, 1, "", "data_keys"], [194, 2, 1, "", "dataloader"], [194, 2, 1, "", "device"], [194, 1, 1, "", "double"], [194, 1, 1, "", "dump"], [194, 1, 1, "", "empty_cache"], [194, 2, 1, "", "endless_dataloader"], [194, 1, 1, "", "eval"], [194, 1, 1, "", "extra_repr"], [194, 1, 1, "", "float"], [194, 1, 1, "", "forward"], [194, 1, 1, "", "get_buffer"], [194, 1, 1, "", "get_extra_state"], [194, 1, 1, "", "get_parameter"], [194, 1, 1, "", "get_submodule"], [194, 1, 1, "", "half"], [194, 2, 1, "", "in_keys"], [194, 2, 1, "", "in_keys_inv"], [194, 1, 1, "", "init"], [194, 1, 1, "", "inv"], [194, 1, 1, "", "ipu"], [194, 1, 1, "", "load_state_dict"], [194, 2, 1, "", "missing_tolerance"], [194, 1, 1, "", "modules"], [194, 1, 1, "", "mtia"], [194, 1, 1, "", "named_buffers"], [194, 1, 1, "", "named_children"], [194, 1, 1, "", "named_modules"], [194, 1, 1, "", "named_parameters"], [194, 2, 1, "", "out_keys"], [194, 2, 1, "", "out_keys_inv"], [194, 1, 1, "", "parameters"], [194, 2, 1, "", "parent"], [194, 2, 1, "", "primers"], [194, 1, 1, "", "register_backward_hook"], [194, 1, 1, "", "register_buffer"], [194, 1, 1, "", "register_forward_hook"], [194, 1, 1, "", "register_forward_pre_hook"], [194, 1, 1, "", "register_full_backward_hook"], [194, 1, 1, "", "register_full_backward_pre_hook"], [194, 1, 1, "", "register_load_state_dict_post_hook"], [194, 1, 1, "", "register_load_state_dict_pre_hook"], [194, 1, 1, "", "register_module"], [194, 1, 1, "", "register_parameter"], [194, 1, 1, "", "register_state_dict_post_hook"], [194, 1, 1, "", "register_state_dict_pre_hook"], [194, 2, 1, "", "repeats"], [194, 1, 1, "", "requires_grad_"], [194, 1, 1, "", "reset_dataloader"], [194, 1, 1, "", "reset_parent"], [194, 1, 1, "", "set_container"], [194, 1, 1, "", "set_extra_state"], [194, 1, 1, "", "set_missing_tolerance"], [194, 1, 1, "", "set_submodule"], [194, 1, 1, "", "share_memory"], [194, 2, 1, "", "stack_method"], [194, 1, 1, "", "state_dict"], [194, 1, 1, "", "to"], [194, 1, 1, "", "to_empty"], [194, 1, 1, "", "train"], [194, 1, 1, "", "transform_action_spec"], [194, 1, 1, "", "transform_done_spec"], [194, 1, 1, "", "transform_env_batch_size"], [194, 1, 1, "", "transform_env_device"], [194, 1, 1, "", "transform_input_spec"], [194, 1, 1, "", "transform_observation_spec"], [194, 1, 1, "", "transform_output_spec"], [194, 1, 1, "", "transform_reward_spec"], [194, 1, 1, "", "transform_state_spec"], [194, 1, 1, "", "type"], [194, 1, 1, "", "xpu"], [194, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.RetrieveKL": [[195, 1, 1, "", "add_module"], [195, 1, 1, "", "append"], [195, 1, 1, "", "apply"], [195, 1, 1, "", "bfloat16"], [195, 1, 1, "", "buffers"], [195, 1, 1, "", "children"], [195, 1, 1, "", "close"], [195, 2, 1, "", "collector"], [195, 1, 1, "", "compile"], [195, 2, 1, "", "container"], [195, 1, 1, "", "cpu"], [195, 1, 1, "", "cuda"], [195, 1, 1, "", "double"], [195, 1, 1, "", "eval"], [195, 1, 1, "", "extra_repr"], [195, 1, 1, "", "float"], [195, 1, 1, "", "forward"], [195, 1, 1, "", "get_buffer"], [195, 1, 1, "", "get_extra_state"], [195, 1, 1, "", "get_parameter"], [195, 1, 1, "", "get_submodule"], [195, 1, 1, "", "half"], [195, 1, 1, "", "init"], [195, 1, 1, "", "insert"], [195, 1, 1, "", "inv"], [195, 1, 1, "", "ipu"], [195, 1, 1, "", "load_state_dict"], [195, 1, 1, "", "modules"], [195, 1, 1, "", "mtia"], [195, 1, 1, "", "named_buffers"], [195, 1, 1, "", "named_children"], [195, 1, 1, "", "named_modules"], [195, 1, 1, "", "named_parameters"], [195, 1, 1, "", "parameters"], [195, 2, 1, "", "parent"], [195, 1, 1, "", "pop"], [195, 1, 1, "", "register_backward_hook"], [195, 1, 1, "", "register_buffer"], [195, 1, 1, "", "register_forward_hook"], [195, 1, 1, "", "register_forward_pre_hook"], [195, 1, 1, "", "register_full_backward_hook"], [195, 1, 1, "", "register_full_backward_pre_hook"], [195, 1, 1, "", "register_load_state_dict_post_hook"], [195, 1, 1, "", "register_load_state_dict_pre_hook"], [195, 1, 1, "", "register_module"], [195, 1, 1, "", "register_parameter"], [195, 1, 1, "", "register_state_dict_post_hook"], [195, 1, 1, "", "register_state_dict_pre_hook"], [195, 1, 1, "", "requires_grad_"], [195, 1, 1, "", "set_extra_state"], [195, 1, 1, "", "set_submodule"], [195, 1, 1, "", "share_memory"], [195, 1, 1, "", "state_dict"], [195, 1, 1, "", "to"], [195, 1, 1, "", "to_empty"], [195, 1, 1, "", "train"], [195, 1, 1, "", "transform_action_spec"], [195, 1, 1, "", "transform_done_spec"], [195, 1, 1, "", "transform_env_batch_size"], [195, 1, 1, "", "transform_env_device"], [195, 1, 1, "", "transform_input_spec"], [195, 1, 1, "", "transform_observation_spec"], [195, 1, 1, "", "transform_output_spec"], [195, 1, 1, "", "transform_reward_spec"], [195, 1, 1, "", "transform_state_spec"], [195, 1, 1, "", "type"], [195, 1, 1, "", "xpu"], [195, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.RetrieveLogProb": [[196, 1, 1, "", "add_module"], [196, 1, 1, "", "apply"], [196, 1, 1, "", "bfloat16"], [196, 1, 1, "", "buffers"], [196, 1, 1, "", "children"], [196, 1, 1, "", "close"], [196, 2, 1, "", "collector"], [196, 1, 1, "", "compile"], [196, 2, 1, "", "container"], [196, 1, 1, "", "cpu"], [196, 1, 1, "", "cuda"], [196, 1, 1, "", "double"], [196, 1, 1, "", "eval"], [196, 1, 1, "", "extra_repr"], [196, 1, 1, "", "float"], [196, 1, 1, "", "forward"], [196, 1, 1, "", "get_buffer"], [196, 1, 1, "", "get_extra_state"], [196, 1, 1, "", "get_parameter"], [196, 1, 1, "", "get_submodule"], [196, 1, 1, "", "half"], [196, 1, 1, "", "init"], [196, 1, 1, "", "inv"], [196, 1, 1, "", "ipu"], [196, 1, 1, "", "load_state_dict"], [196, 1, 1, "", "modules"], [196, 1, 1, "", "mtia"], [196, 1, 1, "", "named_buffers"], [196, 1, 1, "", "named_children"], [196, 1, 1, "", "named_modules"], [196, 1, 1, "", "named_parameters"], [196, 1, 1, "", "parameters"], [196, 2, 1, "", "parent"], [196, 1, 1, "", "register_backward_hook"], [196, 1, 1, "", "register_buffer"], [196, 1, 1, "", "register_forward_hook"], [196, 1, 1, "", "register_forward_pre_hook"], [196, 1, 1, "", "register_full_backward_hook"], [196, 1, 1, "", "register_full_backward_pre_hook"], [196, 1, 1, "", "register_load_state_dict_post_hook"], [196, 1, 1, "", "register_load_state_dict_pre_hook"], [196, 1, 1, "", "register_module"], [196, 1, 1, "", "register_parameter"], [196, 1, 1, "", "register_state_dict_post_hook"], [196, 1, 1, "", "register_state_dict_pre_hook"], [196, 1, 1, "", "requires_grad_"], [196, 1, 1, "", "set_extra_state"], [196, 1, 1, "", "set_submodule"], [196, 1, 1, "", "share_memory"], [196, 1, 1, "", "state_dict"], [196, 1, 1, "", "to"], [196, 1, 1, "", "to_empty"], [196, 1, 1, "", "train"], [196, 1, 1, "", "transform_action_spec"], [196, 1, 1, "", "transform_done_spec"], [196, 1, 1, "", "transform_env_batch_size"], [196, 1, 1, "", "transform_env_device"], [196, 1, 1, "", "transform_input_spec"], [196, 1, 1, "", "transform_observation_spec"], [196, 1, 1, "", "transform_output_spec"], [196, 1, 1, "", "transform_reward_spec"], [196, 1, 1, "", "transform_state_spec"], [196, 1, 1, "", "type"], [196, 1, 1, "", "xpu"], [196, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.SimpleToolTransform": [[197, 1, 1, "", "add_module"], [197, 1, 1, "", "apply"], [197, 1, 1, "", "bfloat16"], [197, 1, 1, "", "buffers"], [197, 1, 1, "", "children"], [197, 1, 1, "", "close"], [197, 2, 1, "", "collector"], [197, 1, 1, "", "compile"], [197, 2, 1, "", "container"], [197, 1, 1, "", "cpu"], [197, 1, 1, "", "cuda"], [197, 1, 1, "", "double"], [197, 1, 1, "", "eval"], [197, 1, 1, "", "extra_repr"], [197, 1, 1, "", "float"], [197, 1, 1, "", "forward"], [197, 1, 1, "", "get_buffer"], [197, 1, 1, "", "get_extra_state"], [197, 1, 1, "", "get_parameter"], [197, 1, 1, "", "get_submodule"], [197, 1, 1, "", "half"], [197, 1, 1, "", "init"], [197, 1, 1, "", "inv"], [197, 1, 1, "", "ipu"], [197, 1, 1, "", "load_state_dict"], [197, 1, 1, "", "modules"], [197, 1, 1, "", "mtia"], [197, 1, 1, "", "named_buffers"], [197, 1, 1, "", "named_children"], [197, 1, 1, "", "named_modules"], [197, 1, 1, "", "named_parameters"], [197, 1, 1, "", "parameters"], [197, 2, 1, "", "parent"], [197, 1, 1, "", "register_backward_hook"], [197, 1, 1, "", "register_buffer"], [197, 1, 1, "", "register_forward_hook"], [197, 1, 1, "", "register_forward_pre_hook"], [197, 1, 1, "", "register_full_backward_hook"], [197, 1, 1, "", "register_full_backward_pre_hook"], [197, 1, 1, "", "register_load_state_dict_post_hook"], [197, 1, 1, "", "register_load_state_dict_pre_hook"], [197, 1, 1, "", "register_module"], [197, 1, 1, "", "register_parameter"], [197, 1, 1, "", "register_state_dict_post_hook"], [197, 1, 1, "", "register_state_dict_pre_hook"], [197, 1, 1, "", "requires_grad_"], [197, 1, 1, "", "set_extra_state"], [197, 1, 1, "", "set_submodule"], [197, 1, 1, "", "share_memory"], [197, 1, 1, "", "state_dict"], [197, 1, 1, "", "to"], [197, 1, 1, "", "to_empty"], [197, 1, 1, "", "train"], [197, 1, 1, "", "transform_action_spec"], [197, 1, 1, "", "transform_done_spec"], [197, 1, 1, "", "transform_env_batch_size"], [197, 1, 1, "", "transform_env_device"], [197, 1, 1, "", "transform_input_spec"], [197, 1, 1, "", "transform_observation_spec"], [197, 1, 1, "", "transform_output_spec"], [197, 1, 1, "", "transform_reward_spec"], [197, 1, 1, "", "transform_state_spec"], [197, 1, 1, "", "type"], [197, 1, 1, "", "xpu"], [197, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.TemplateTransform": [[198, 1, 1, "", "add_module"], [198, 1, 1, "", "apply"], [198, 1, 1, "", "bfloat16"], [198, 1, 1, "", "buffers"], [198, 1, 1, "", "children"], [198, 1, 1, "", "close"], [198, 2, 1, "", "collector"], [198, 1, 1, "", "compile"], [198, 2, 1, "", "container"], [198, 1, 1, "", "cpu"], [198, 1, 1, "", "cuda"], [198, 1, 1, "", "double"], [198, 1, 1, "", "eval"], [198, 1, 1, "", "extra_repr"], [198, 1, 1, "", "float"], [198, 1, 1, "", "forward"], [198, 1, 1, "", "get_buffer"], [198, 1, 1, "", "get_extra_state"], [198, 1, 1, "", "get_parameter"], [198, 1, 1, "", "get_submodule"], [198, 1, 1, "", "half"], [198, 1, 1, "", "init"], [198, 1, 1, "", "inv"], [198, 1, 1, "", "ipu"], [198, 1, 1, "", "load_state_dict"], [198, 1, 1, "", "modules"], [198, 1, 1, "", "mtia"], [198, 1, 1, "", "named_buffers"], [198, 1, 1, "", "named_children"], [198, 1, 1, "", "named_modules"], [198, 1, 1, "", "named_parameters"], [198, 1, 1, "", "parameters"], [198, 2, 1, "", "parent"], [198, 1, 1, "", "register_backward_hook"], [198, 1, 1, "", "register_buffer"], [198, 1, 1, "", "register_forward_hook"], [198, 1, 1, "", "register_forward_pre_hook"], [198, 1, 1, "", "register_full_backward_hook"], [198, 1, 1, "", "register_full_backward_pre_hook"], [198, 1, 1, "", "register_load_state_dict_post_hook"], [198, 1, 1, "", "register_load_state_dict_pre_hook"], [198, 1, 1, "", "register_module"], [198, 1, 1, "", "register_parameter"], [198, 1, 1, "", "register_state_dict_post_hook"], [198, 1, 1, "", "register_state_dict_pre_hook"], [198, 1, 1, "", "requires_grad_"], [198, 1, 1, "", "set_extra_state"], [198, 1, 1, "", "set_submodule"], [198, 1, 1, "", "share_memory"], [198, 1, 1, "", "state_dict"], [198, 1, 1, "", "to"], [198, 1, 1, "", "to_empty"], [198, 1, 1, "", "train"], [198, 1, 1, "", "transform_action_spec"], [198, 1, 1, "", "transform_done_spec"], [198, 1, 1, "", "transform_env_batch_size"], [198, 1, 1, "", "transform_env_device"], [198, 1, 1, "", "transform_input_spec"], [198, 1, 1, "", "transform_observation_spec"], [198, 1, 1, "", "transform_output_spec"], [198, 1, 1, "", "transform_reward_spec"], [198, 1, 1, "", "transform_state_spec"], [198, 1, 1, "", "type"], [198, 1, 1, "", "xpu"], [198, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.Tokenizer": [[199, 1, 1, "", "add_module"], [199, 1, 1, "", "apply"], [199, 1, 1, "", "bfloat16"], [199, 1, 1, "", "buffers"], [199, 1, 1, "", "children"], [199, 1, 1, "", "close"], [199, 2, 1, "", "collector"], [199, 1, 1, "", "compile"], [199, 2, 1, "", "container"], [199, 1, 1, "", "cpu"], [199, 1, 1, "", "cuda"], [199, 1, 1, "", "double"], [199, 1, 1, "", "eval"], [199, 1, 1, "", "extra_repr"], [199, 1, 1, "", "float"], [199, 1, 1, "", "forward"], [199, 1, 1, "", "get_buffer"], [199, 1, 1, "", "get_extra_state"], [199, 1, 1, "", "get_parameter"], [199, 1, 1, "", "get_submodule"], [199, 1, 1, "", "half"], [199, 1, 1, "", "init"], [199, 1, 1, "", "inv"], [199, 1, 1, "", "ipu"], [199, 1, 1, "", "load_state_dict"], [199, 1, 1, "", "modules"], [199, 1, 1, "", "mtia"], [199, 1, 1, "", "named_buffers"], [199, 1, 1, "", "named_children"], [199, 1, 1, "", "named_modules"], [199, 1, 1, "", "named_parameters"], [199, 1, 1, "", "parameters"], [199, 2, 1, "", "parent"], [199, 1, 1, "", "register_backward_hook"], [199, 1, 1, "", "register_buffer"], [199, 1, 1, "", "register_forward_hook"], [199, 1, 1, "", "register_forward_pre_hook"], [199, 1, 1, "", "register_full_backward_hook"], [199, 1, 1, "", "register_full_backward_pre_hook"], [199, 1, 1, "", "register_load_state_dict_post_hook"], [199, 1, 1, "", "register_load_state_dict_pre_hook"], [199, 1, 1, "", "register_module"], [199, 1, 1, "", "register_parameter"], [199, 1, 1, "", "register_state_dict_post_hook"], [199, 1, 1, "", "register_state_dict_pre_hook"], [199, 1, 1, "", "requires_grad_"], [199, 1, 1, "", "set_extra_state"], [199, 1, 1, "", "set_submodule"], [199, 1, 1, "", "share_memory"], [199, 1, 1, "", "state_dict"], [199, 1, 1, "", "to"], [199, 1, 1, "", "to_empty"], [199, 1, 1, "", "train"], [199, 1, 1, "", "transform_action_spec"], [199, 1, 1, "", "transform_done_spec"], [199, 1, 1, "", "transform_env_batch_size"], [199, 1, 1, "", "transform_env_device"], [199, 1, 1, "", "transform_input_spec"], [199, 1, 1, "", "transform_observation_spec"], [199, 1, 1, "", "transform_output_spec"], [199, 1, 1, "", "transform_reward_spec"], [199, 1, 1, "", "transform_state_spec"], [199, 1, 1, "", "type"], [199, 1, 1, "", "xpu"], [199, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.ToolRegistry": [[201, 1, 1, "", "get"], [201, 1, 1, "", "register"]], "torchrl.envs.model_based.dreamer": [[207, 3, 1, "", "DreamerDecoder"], [208, 3, 1, "", "DreamerEnv"]], "torchrl.envs.transforms": [[214, 0, 1, "", "ActionDiscretizer"], [215, 0, 1, "", "ActionMask"], [216, 0, 1, "", "AutoResetEnv"], [217, 0, 1, "", "AutoResetTransform"], [218, 0, 1, "", "BatchSizeTransform"], [219, 0, 1, "", "BinarizeReward"], [220, 0, 1, "", "BurnInTransform"], [221, 0, 1, "", "CatFrames"], [222, 0, 1, "", "CatTensors"], [223, 0, 1, "", "CenterCrop"], [224, 0, 1, "", "ClipTransform"], [225, 0, 1, "", "Compose"], [226, 0, 1, "", "ConditionalPolicySwitch"], [227, 0, 1, "", "ConditionalSkip"], [228, 0, 1, "", "Crop"], [229, 0, 1, "", "DTypeCastTransform"], [230, 0, 1, "", "DeviceCastTransform"], [231, 0, 1, "", "DiscreteActionProjection"], [232, 0, 1, "", "DoubleToFloat"], [233, 0, 1, "", "EndOfLifeTransform"], [234, 0, 1, "", "ExcludeTransform"], [235, 0, 1, "", "FiniteTensorDictCheck"], [236, 0, 1, "", "FlattenObservation"], [237, 0, 1, "", "FrameSkipTransform"], [238, 0, 1, "", "GrayScale"], [239, 0, 1, "", "Hash"], [240, 0, 1, "", "InitTracker"], [241, 0, 1, "", "KLRewardTransform"], [242, 0, 1, "", "LineariseRewards"], [243, 0, 1, "", "ModuleTransform"], [244, 0, 1, "", "MultiAction"], [245, 0, 1, "", "NoopResetEnv"], [246, 0, 1, "", "ObservationNorm"], [247, 0, 1, "", "ObservationTransform"], [248, 0, 1, "", "PermuteTransform"], [249, 0, 1, "", "PinMemoryTransform"], [250, 0, 1, "", "R3MTransform"], [251, 0, 1, "", "RandomCropTensorDict"], [252, 0, 1, "", "RemoveEmptySpecs"], [253, 0, 1, "", "RenameTransform"], [254, 0, 1, "", "Resize"], [255, 0, 1, "", "Reward2GoTransform"], [256, 0, 1, "", "RewardClipping"], [257, 0, 1, "", "RewardScaling"], [258, 0, 1, "", "RewardSum"], [259, 0, 1, "", "SelectTransform"], [260, 0, 1, "", "SignTransform"], [261, 0, 1, "", "SqueezeTransform"], [262, 0, 1, "", "Stack"], [263, 0, 1, "", "StepCounter"], [264, 0, 1, "", "TargetReturn"], [265, 0, 1, "", "TensorDictPrimer"], [266, 0, 1, "", "TimeMaxPool"], [267, 0, 1, "", "Timer"], [268, 0, 1, "", "ToTensorImage"], [269, 0, 1, "", "Tokenizer"], [270, 0, 1, "", "TrajCounter"], [271, 0, 1, "", "Transform"], [272, 0, 1, "", "TransformedEnv"], [273, 0, 1, "", "UnaryTransform"], [274, 0, 1, "", "UnsqueezeTransform"], [275, 0, 1, "", "VC1Transform"], [276, 0, 1, "", "VIPRewardTransform"], [277, 0, 1, "", "VIPTransform"], [278, 0, 1, "", "VecGymEnvTransform"], [279, 0, 1, "", "VecNorm"], [280, 0, 1, "", "VecNormV2"], [281, 0, 1, "", "gSDENoise"]], "torchrl.envs.transforms.ActionDiscretizer": [[214, 0, 1, "", "SamplingStrategy"], [214, 1, 1, "", "inv"], [214, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.ActionMask": [[215, 1, 1, "", "forward"]], "torchrl.envs.transforms.AutoResetEnv": [[216, 1, 1, "", "insert_transform"]], "torchrl.envs.transforms.AutoResetTransform": [[217, 1, 1, "", "forward"]], "torchrl.envs.transforms.BatchSizeTransform": [[218, 1, 1, "", "forward"], [218, 1, 1, "", "transform_env_batch_size"], [218, 1, 1, "", "transform_input_spec"], [218, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.BinarizeReward": [[219, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.BurnInTransform": [[220, 1, 1, "", "forward"]], "torchrl.envs.transforms.CatFrames": [[221, 1, 1, "", "forward"], [221, 1, 1, "", "make_rb_transform_and_sampler"], [221, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CatTensors": [[222, 1, 1, "", "forward"], [222, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CenterCrop": [[223, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ClipTransform": [[224, 1, 1, "", "transform_observation_spec"], [224, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.Compose": [[225, 1, 1, "", "append"], [225, 1, 1, "", "close"], [225, 1, 1, "", "forward"], [225, 1, 1, "", "init"], [225, 1, 1, "", "insert"], [225, 1, 1, "", "pop"], [225, 1, 1, "", "to"], [225, 1, 1, "", "transform_action_spec"], [225, 1, 1, "", "transform_env_batch_size"], [225, 1, 1, "", "transform_env_device"], [225, 1, 1, "", "transform_input_spec"], [225, 1, 1, "", "transform_observation_spec"], [225, 1, 1, "", "transform_output_spec"], [225, 1, 1, "", "transform_reward_spec"], [225, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.ConditionalPolicySwitch": [[226, 1, 1, "", "forward"]], "torchrl.envs.transforms.ConditionalSkip": [[227, 1, 1, "", "forward"]], "torchrl.envs.transforms.Crop": [[228, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.DTypeCastTransform": [[229, 1, 1, "", "forward"], [229, 1, 1, "", "transform_input_spec"], [229, 1, 1, "", "transform_observation_spec"], [229, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.DeviceCastTransform": [[230, 1, 1, "", "forward"], [230, 1, 1, "", "transform_action_spec"], [230, 1, 1, "", "transform_done_spec"], [230, 1, 1, "", "transform_env_device"], [230, 1, 1, "", "transform_input_spec"], [230, 1, 1, "", "transform_observation_spec"], [230, 1, 1, "", "transform_output_spec"], [230, 1, 1, "", "transform_reward_spec"], [230, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.DiscreteActionProjection": [[231, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.EndOfLifeTransform": [[233, 1, 1, "", "forward"], [233, 1, 1, "", "register_keys"], [233, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ExcludeTransform": [[234, 1, 1, "", "forward"], [234, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.FiniteTensorDictCheck": [[235, 1, 1, "", "forward"]], "torchrl.envs.transforms.FlattenObservation": [[236, 1, 1, "", "forward"], [236, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.FrameSkipTransform": [[237, 1, 1, "", "forward"]], "torchrl.envs.transforms.GrayScale": [[238, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Hash": [[239, 1, 1, "", "get_input_from_hash"], [239, 1, 1, "", "reproducible_hash"], [239, 1, 1, "", "state_dict"]], "torchrl.envs.transforms.InitTracker": [[240, 1, 1, "", "forward"], [240, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.KLRewardTransform": [[241, 1, 1, "", "forward"], [241, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.LineariseRewards": [[242, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.ModuleTransform": [[243, 1, 1, "", "forward"], [243, 1, 1, "", "transform_action_spec"], [243, 1, 1, "", "transform_done_spec"], [243, 1, 1, "", "transform_observation_spec"], [243, 1, 1, "", "transform_reward_spec"], [243, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.MultiAction": [[244, 1, 1, "", "transform_input_spec"], [244, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.ObservationNorm": [[246, 1, 1, "", "init_stats"], [246, 1, 1, "", "transform_action_spec"], [246, 1, 1, "", "transform_observation_spec"], [246, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.PermuteTransform": [[248, 1, 1, "", "transform_input_spec"], [248, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.PinMemoryTransform": [[249, 1, 1, "", "forward"]], "torchrl.envs.transforms.R3MTransform": [[250, 1, 1, "", "to"]], "torchrl.envs.transforms.RandomCropTensorDict": [[251, 1, 1, "", "forward"]], "torchrl.envs.transforms.RemoveEmptySpecs": [[252, 1, 1, "", "forward"], [252, 1, 1, "", "transform_input_spec"], [252, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.RenameTransform": [[253, 1, 1, "", "forward"], [253, 1, 1, "", "transform_input_spec"], [253, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.Resize": [[254, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Reward2GoTransform": [[255, 1, 1, "", "forward"]], "torchrl.envs.transforms.RewardClipping": [[256, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardScaling": [[257, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardSum": [[258, 1, 1, "", "forward"], [258, 1, 1, "", "transform_input_spec"], [258, 1, 1, "", "transform_observation_spec"], [258, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.SelectTransform": [[259, 1, 1, "", "forward"], [259, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.SignTransform": [[260, 1, 1, "", "transform_observation_spec"], [260, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.Stack": [[262, 1, 1, "", "forward"], [262, 1, 1, "", "transform_done_spec"], [262, 1, 1, "", "transform_input_spec"], [262, 1, 1, "", "transform_observation_spec"], [262, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.StepCounter": [[263, 1, 1, "", "forward"], [263, 1, 1, "", "transform_input_spec"], [263, 1, 1, "", "transform_observation_spec"], [263, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.TargetReturn": [[264, 1, 1, "", "forward"], [264, 1, 1, "", "transform_input_spec"], [264, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TensorDictPrimer": [[265, 1, 1, "", "forward"], [265, 1, 1, "", "to"], [265, 1, 1, "", "transform_input_spec"], [265, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TimeMaxPool": [[266, 1, 1, "", "forward"], [266, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Timer": [[267, 1, 1, "", "forward"], [267, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ToTensorImage": [[268, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Tokenizer": [[269, 1, 1, "", "forward"], [269, 1, 1, "", "transform_done_spec"], [269, 1, 1, "", "transform_input_spec"], [269, 1, 1, "", "transform_observation_spec"], [269, 1, 1, "", "transform_output_spec"], [269, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.TrajCounter": [[270, 1, 1, "", "forward"], [270, 1, 1, "", "load_state_dict"], [270, 1, 1, "", "state_dict"], [270, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Transform": [[271, 1, 1, "", "clone"], [271, 1, 1, "", "close"], [271, 2, 1, "", "collector"], [271, 2, 1, "", "container"], [271, 1, 1, "", "forward"], [271, 1, 1, "", "init"], [271, 1, 1, "", "inv"], [271, 2, 1, "", "parent"], [271, 1, 1, "", "reset_parent"], [271, 1, 1, "", "set_container"], [271, 1, 1, "", "to"], [271, 1, 1, "", "transform_action_spec"], [271, 1, 1, "", "transform_done_spec"], [271, 1, 1, "", "transform_env_batch_size"], [271, 1, 1, "", "transform_env_device"], [271, 1, 1, "", "transform_input_spec"], [271, 1, 1, "", "transform_observation_spec"], [271, 1, 1, "", "transform_output_spec"], [271, 1, 1, "", "transform_reward_spec"], [271, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.TransformedEnv": [[272, 1, 1, "", "add_truncated_keys"], [272, 1, 1, "", "append_transform"], [272, 2, 1, "", "batch_locked"], [272, 2, 1, "", "batch_size"], [272, 1, 1, "", "empty_cache"], [272, 1, 1, "", "eval"], [272, 2, 1, "", "input_spec"], [272, 1, 1, "", "insert_transform"], [272, 1, 1, "", "load_state_dict"], [272, 2, 1, "", "output_spec"], [272, 1, 1, "", "rand_action"], [272, 1, 1, "", "set_missing_tolerance"], [272, 1, 1, "", "set_seed"], [272, 1, 1, "", "state_dict"], [272, 1, 1, "", "to"], [272, 1, 1, "", "train"]], "torchrl.envs.transforms.UnaryTransform": [[273, 1, 1, "", "transform_action_spec"], [273, 1, 1, "", "transform_done_spec"], [273, 1, 1, "", "transform_input_spec"], [273, 1, 1, "", "transform_observation_spec"], [273, 1, 1, "", "transform_output_spec"], [273, 1, 1, "", "transform_reward_spec"], [273, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.UnsqueezeTransform": [[274, 1, 1, "", "transform_action_spec"], [274, 1, 1, "", "transform_observation_spec"], [274, 1, 1, "", "transform_reward_spec"], [274, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.VC1Transform": [[275, 1, 1, "", "forward"], [275, 1, 1, "", "make_noload_model"], [275, 1, 1, "", "to"], [275, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VIPRewardTransform": [[276, 1, 1, "", "forward"], [276, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.VIPTransform": [[277, 1, 1, "", "to"]], "torchrl.envs.transforms.VecGymEnvTransform": [[278, 1, 1, "", "forward"], [278, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VecNorm": [[279, 1, 1, "", "build_td_for_shared_vecnorm"], [279, 1, 1, "", "forward"], [279, 1, 1, "", "freeze"], [279, 1, 1, "", "frozen_copy"], [279, 1, 1, "", "get_extra_state"], [279, 2, 1, "", "loc"], [279, 2, 1, "", "scale"], [279, 1, 1, "", "set_extra_state"], [279, 2, 1, "", "standard_normal"], [279, 1, 1, "", "to_observation_norm"], [279, 1, 1, "", "transform_observation_spec"], [279, 1, 1, "", "unfreeze"]], "torchrl.envs.transforms.VecNormV2": [[280, 1, 1, "", "clone"], [280, 1, 1, "id0", "freeze"], [280, 1, 1, "id1", "frozen_copy"], [280, 1, 1, "id2", "get_extra_state"], [280, 2, 1, "id3", "loc"], [280, 2, 1, "id4", "scale"], [280, 1, 1, "id5", "set_extra_state"], [280, 2, 1, "id6", "standard_normal"], [280, 1, 1, "", "to_observation_norm"], [280, 1, 1, "id7", "transform_observation_spec"], [280, 1, 1, "id8", "transform_output_spec"], [280, 1, 1, "id9", "transform_reward_spec"], [280, 1, 1, "id10", "unfreeze"]], "torchrl.implement_for": [[282, 1, 1, "", "get_class_that_defined_method"], [282, 1, 1, "", "import_module"], [282, 1, 1, "", "module_set"], [282, 1, 1, "", "reset"]], "torchrl.modules": [[283, 0, 1, "", "ActorCriticOperator"], [284, 0, 1, "", "ActorCriticWrapper"], [285, 0, 1, "", "ActorValueOperator"], [286, 0, 1, "", "AdditiveGaussianModule"], [287, 0, 1, "", "ConsistentDropoutModule"], [288, 0, 1, "", "ConvNet"], [289, 0, 1, "", "DTActor"], [290, 0, 1, "", "DdpgCnnActor"], [291, 0, 1, "", "DdpgCnnQNet"], [292, 0, 1, "", "DdpgMlpActor"], [293, 0, 1, "", "DdpgMlpQNet"], [294, 0, 1, "", "DecisionTransformer"], [295, 0, 1, "", "Delta"], [296, 0, 1, "", "DistributionalDQNnet"], [297, 0, 1, "", "DistributionalQValueActor"], [298, 0, 1, "", "DistributionalQValueModule"], [299, 0, 1, "", "DreamerActor"], [300, 0, 1, "", "DuelingCnnDQNet"], [301, 0, 1, "", "EGreedyModule"], [302, 0, 1, "", "GRUModule"], [303, 0, 1, "", "IndependentNormal"], [304, 0, 1, "", "LSTMModule"], [305, 0, 1, "", "MLP"], [306, 0, 1, "", "MaskedCategorical"], [307, 0, 1, "", "NormalParamExtractor"], [308, 0, 1, "", "ObsDecoder"], [309, 0, 1, "", "ObsEncoder"], [310, 0, 1, "", "OneHotCategorical"], [311, 0, 1, "", "OnlineDTActor"], [312, 0, 1, "", "OrnsteinUhlenbeckProcessModule"], [313, 0, 1, "", "QValueActor"], [314, 0, 1, "", "QValueModule"], [315, 0, 1, "", "RSSMPosterior"], [316, 0, 1, "", "RSSMPrior"], [317, 0, 1, "", "RSSMRollout"], [318, 0, 1, "", "ReparamGradientStrategy"], [319, 0, 1, "", "TanhDelta"], [320, 0, 1, "", "TanhNormal"], [321, 0, 1, "", "TruncatedNormal"], [322, 0, 1, "", "ValueOperator"], [323, 0, 1, "", "WorldModelWrapper"], [339, 0, 1, "", "set_exploration_modules_spec_from_env"]], "torchrl.modules.ActorCriticOperator": [[283, 1, 1, "", "get_critic_operator"], [283, 1, 1, "", "get_policy_head"], [283, 1, 1, "", "get_value_head"], [283, 1, 1, "", "get_value_operator"]], "torchrl.modules.ActorCriticWrapper": [[284, 1, 1, "", "get_policy_head"], [284, 1, 1, "", "get_policy_operator"], [284, 1, 1, "", "get_value_head"], [284, 1, 1, "", "get_value_operator"]], "torchrl.modules.ActorValueOperator": [[285, 1, 1, "", "get_policy_head"], [285, 1, 1, "", "get_policy_operator"], [285, 1, 1, "", "get_value_head"], [285, 1, 1, "", "get_value_operator"]], "torchrl.modules.AdditiveGaussianModule": [[286, 1, 1, "", "forward"], [286, 1, 1, "", "step"]], "torchrl.modules.ConsistentDropoutModule": [[287, 1, 1, "", "forward"], [287, 1, 1, "", "make_tensordict_primer"]], "torchrl.modules.ConvNet": [[288, 1, 1, "", "default_atari_dqn"], [288, 1, 1, "", "forward"]], "torchrl.modules.DTActor": [[289, 1, 1, "", "default_config"], [289, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnActor": [[290, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnQNet": [[291, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpActor": [[292, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpQNet": [[293, 1, 1, "", "forward"]], "torchrl.modules.DecisionTransformer": [[294, 0, 1, "", "DTConfig"], [294, 1, 1, "", "forward"]], "torchrl.modules.Delta": [[295, 1, 1, "", "expand"], [295, 1, 1, "", "log_prob"], [295, 2, 1, "", "mean"], [295, 2, 1, "", "mode"], [295, 1, 1, "", "rsample"], [295, 1, 1, "", "sample"]], "torchrl.modules.DistributionalDQNnet": [[296, 1, 1, "", "forward"]], "torchrl.modules.DistributionalQValueModule": [[298, 1, 1, "", "forward"]], "torchrl.modules.DreamerActor": [[299, 1, 1, "", "forward"]], "torchrl.modules.DuelingCnnDQNet": [[300, 1, 1, "", "forward"]], "torchrl.modules.EGreedyModule": [[301, 1, 1, "", "forward"], [301, 1, 1, "", "step"]], "torchrl.modules.GRUModule": [[302, 1, 1, "", "forward"], [302, 1, 1, "", "make_cudnn_based"], [302, 1, 1, "", "make_python_based"], [302, 1, 1, "id0", "make_tensordict_primer"], [302, 1, 1, "", "set_recurrent_mode"]], "torchrl.modules.IndependentNormal": [[303, 2, 1, "", "mode"]], "torchrl.modules.LSTMModule": [[304, 1, 1, "", "forward"], [304, 1, 1, "", "make_cudnn_based"], [304, 1, 1, "", "make_python_based"], [304, 1, 1, "id0", "make_tensordict_primer"], [304, 1, 1, "", "set_recurrent_mode"]], "torchrl.modules.MLP": [[305, 1, 1, "", "forward"]], "torchrl.modules.MaskedCategorical": [[306, 1, 1, "", "entropy"], [306, 1, 1, "", "log_prob"], [306, 2, 1, "", "padding_value"], [306, 1, 1, "", "sample"]], "torchrl.modules.NormalParamExtractor": [[307, 1, 1, "", "forward"]], "torchrl.modules.ObsDecoder": [[308, 1, 1, "", "forward"]], "torchrl.modules.ObsEncoder": [[309, 1, 1, "", "forward"]], "torchrl.modules.OneHotCategorical": [[310, 1, 1, "", "entropy"], [310, 1, 1, "", "log_prob"], [310, 2, 1, "", "mode"], [310, 1, 1, "", "rsample"], [310, 1, 1, "", "sample"]], "torchrl.modules.OnlineDTActor": [[311, 1, 1, "", "default_config"], [311, 1, 1, "", "forward"]], "torchrl.modules.OrnsteinUhlenbeckProcessModule": [[312, 1, 1, "", "forward"], [312, 1, 1, "", "step"]], "torchrl.modules.QValueModule": [[314, 1, 1, "", "forward"]], "torchrl.modules.RSSMPosterior": [[315, 1, 1, "", "forward"]], "torchrl.modules.RSSMPrior": [[316, 1, 1, "", "forward"]], "torchrl.modules.RSSMRollout": [[317, 1, 1, "", "forward"]], "torchrl.modules.TanhDelta": [[319, 2, 1, "", "mean"], [319, 2, 1, "", "mode"]], "torchrl.modules.TanhNormal": [[320, 1, 1, "", "get_mode"], [320, 2, 1, "", "mean"], [320, 2, 1, "", "mode"], [320, 2, 1, "", "support"]], "torchrl.modules.TruncatedNormal": [[321, 1, 1, "", "log_prob"], [321, 2, 1, "", "mode"]], "torchrl.modules.WorldModelWrapper": [[323, 1, 1, "", "get_reward_operator"], [323, 1, 1, "", "get_transition_model_operator"]], "torchrl.modules.llm": [[324, 0, 1, "", "AsyncVLLM"], [325, 0, 1, "", "ChatHistory"], [326, 0, 1, "", "LLMWrapperBase"], [327, 0, 1, "", "LogProbs"], [328, 0, 1, "", "Masks"], [329, 0, 1, "", "RemoteTransformersWrapper"], [330, 0, 1, "", "Text"], [331, 0, 1, "", "Tokens"], [332, 0, 1, "", "TransformersWrapper"], [333, 0, 1, "", "make_async_vllm_engine"], [334, 0, 1, "", "make_vllm_worker"], [335, 0, 1, "", "stateless_init_process_group"], [336, 0, 1, "", "stateless_init_process_group_async"], [337, 0, 1, "", "vLLMWrapper"]], "torchrl.modules.llm.AsyncVLLM": [[324, 1, 1, "", "collective_rpc"], [324, 1, 1, "", "create_load_balancer"], [324, 1, 1, "", "from_pretrained"], [324, 1, 1, "", "generate"], [324, 1, 1, "", "get_cache_usage"], [324, 1, 1, "", "get_master_address"], [324, 1, 1, "", "get_master_port"], [324, 1, 1, "", "get_model_metadata"], [324, 1, 1, "", "get_num_unfinished_requests"], [324, 1, 1, "", "get_random_actor_index"], [324, 1, 1, "", "get_tp_size"], [324, 1, 1, "", "init_weight_update_group"], [324, 1, 1, "", "launch"], [324, 1, 1, "", "shutdown"], [324, 1, 1, "", "update_weights"]], "torchrl.modules.llm.ChatHistory": [[325, 1, 1, "", "cat"], [325, 1, 1, "", "default_spec"], [325, 2, 1, "", "device"], [325, 1, 1, "", "dumps"], [325, 1, 1, "", "fields"], [325, 1, 1, "", "from_any"], [325, 1, 1, "", "from_dataclass"], [325, 1, 1, "", "from_h5"], [325, 1, 1, "", "from_modules"], [325, 1, 1, "", "from_namedtuple"], [325, 1, 1, "", "from_pytree"], [325, 1, 1, "", "from_remote_init"], [325, 1, 1, "", "from_struct_array"], [325, 1, 1, "", "from_tensordict"], [325, 1, 1, "", "from_tuple"], [325, 1, 1, "", "fromkeys"], [325, 1, 1, "", "get"], [325, 1, 1, "", "lazy_stack"], [325, 1, 1, "", "load"], [325, 1, 1, "", "load_"], [325, 1, 1, "", "load_memmap"], [325, 1, 1, "", "load_state_dict"], [325, 1, 1, "", "maybe_dense_stack"], [325, 1, 1, "", "memmap"], [325, 1, 1, "", "memmap_"], [325, 1, 1, "", "memmap_like"], [325, 1, 1, "", "memmap_refresh_"], [325, 1, 1, "", "save"], [325, 1, 1, "", "set"], [325, 1, 1, "", "stack"], [325, 1, 1, "", "state_dict"], [325, 1, 1, "", "to_tensordict"], [325, 1, 1, "", "to_text"], [325, 1, 1, "", "to_tokens"], [325, 1, 1, "", "unbind"]], "torchrl.modules.llm.LLMWrapperBase": [[326, 1, 1, "", "add_module"], [326, 1, 1, "", "apply"], [326, 2, 1, "", "batching"], [326, 1, 1, "", "bfloat16"], [326, 1, 1, "", "buffers"], [326, 1, 1, "", "children"], [326, 1, 1, "", "cleanup_batching"], [326, 2, 1, "", "collector"], [326, 1, 1, "", "compile"], [326, 1, 1, "", "cpu"], [326, 1, 1, "", "cuda"], [326, 1, 1, "", "double"], [326, 1, 1, "", "eval"], [326, 1, 1, "", "extra_repr"], [326, 1, 1, "", "float"], [326, 1, 1, "", "forward"], [326, 1, 1, "", "get_batching_state"], [326, 1, 1, "", "get_buffer"], [326, 1, 1, "", "get_dist"], [326, 1, 1, "", "get_extra_state"], [326, 1, 1, "", "get_new_version"], [326, 1, 1, "", "get_parameter"], [326, 1, 1, "", "get_submodule"], [326, 1, 1, "", "half"], [326, 1, 1, "", "ipu"], [326, 1, 1, "", "is_tdmodule_compatible"], [326, 1, 1, "", "load_state_dict"], [326, 1, 1, "", "modules"], [326, 1, 1, "", "mtia"], [326, 1, 1, "", "named_buffers"], [326, 1, 1, "", "named_children"], [326, 1, 1, "", "named_modules"], [326, 1, 1, "", "named_parameters"], [326, 1, 1, "", "parameters"], [326, 1, 1, "", "register_backward_hook"], [326, 1, 1, "", "register_buffer"], [326, 1, 1, "", "register_collector"], [326, 1, 1, "", "register_forward_hook"], [326, 1, 1, "", "register_forward_pre_hook"], [326, 1, 1, "", "register_full_backward_hook"], [326, 1, 1, "", "register_full_backward_pre_hook"], [326, 1, 1, "", "register_load_state_dict_post_hook"], [326, 1, 1, "", "register_load_state_dict_pre_hook"], [326, 1, 1, "", "register_module"], [326, 1, 1, "", "register_parameter"], [326, 1, 1, "", "register_state_dict_post_hook"], [326, 1, 1, "", "register_state_dict_pre_hook"], [326, 1, 1, "", "requires_grad_"], [326, 1, 1, "", "reset_out_keys"], [326, 1, 1, "", "reset_parameters_recursive"], [326, 1, 1, "", "select_out_keys"], [326, 1, 1, "", "set_extra_state"], [326, 1, 1, "", "set_submodule"], [326, 1, 1, "", "share_memory"], [326, 1, 1, "", "state_dict"], [326, 1, 1, "", "to"], [326, 1, 1, "", "to_empty"], [326, 1, 1, "", "train"], [326, 1, 1, "", "type"], [326, 1, 1, "", "xpu"], [326, 1, 1, "", "zero_grad"]], "torchrl.modules.llm.LogProbs": [[327, 1, 1, "", "cat"], [327, 1, 1, "", "default_spec"], [327, 2, 1, "", "device"], [327, 1, 1, "", "dumps"], [327, 1, 1, "", "fields"], [327, 1, 1, "", "from_any"], [327, 1, 1, "", "from_dataclass"], [327, 1, 1, "", "from_h5"], [327, 1, 1, "", "from_modules"], [327, 1, 1, "", "from_namedtuple"], [327, 1, 1, "", "from_pytree"], [327, 1, 1, "", "from_remote_init"], [327, 1, 1, "", "from_struct_array"], [327, 1, 1, "", "from_tensordict"], [327, 1, 1, "", "from_tuple"], [327, 1, 1, "", "fromkeys"], [327, 1, 1, "", "get"], [327, 1, 1, "", "lazy_stack"], [327, 1, 1, "", "load"], [327, 1, 1, "", "load_"], [327, 1, 1, "", "load_memmap"], [327, 1, 1, "", "load_state_dict"], [327, 1, 1, "", "maybe_dense_stack"], [327, 1, 1, "", "memmap"], [327, 1, 1, "", "memmap_"], [327, 1, 1, "", "memmap_like"], [327, 1, 1, "", "memmap_refresh_"], [327, 1, 1, "", "save"], [327, 1, 1, "", "set"], [327, 1, 1, "", "stack"], [327, 1, 1, "", "state_dict"], [327, 1, 1, "", "to_tensordict"], [327, 1, 1, "", "unbind"]], "torchrl.modules.llm.Masks": [[328, 1, 1, "", "cat"], [328, 1, 1, "", "default_spec"], [328, 2, 1, "", "device"], [328, 1, 1, "", "dumps"], [328, 1, 1, "", "fields"], [328, 1, 1, "", "from_any"], [328, 1, 1, "", "from_dataclass"], [328, 1, 1, "", "from_h5"], [328, 1, 1, "", "from_modules"], [328, 1, 1, "", "from_namedtuple"], [328, 1, 1, "", "from_pytree"], [328, 1, 1, "", "from_remote_init"], [328, 1, 1, "", "from_struct_array"], [328, 1, 1, "", "from_tensordict"], [328, 1, 1, "", "from_tuple"], [328, 1, 1, "", "fromkeys"], [328, 1, 1, "", "get"], [328, 1, 1, "", "lazy_stack"], [328, 1, 1, "", "load"], [328, 1, 1, "", "load_"], [328, 1, 1, "", "load_memmap"], [328, 1, 1, "", "load_state_dict"], [328, 1, 1, "", "maybe_dense_stack"], [328, 1, 1, "", "memmap"], [328, 1, 1, "", "memmap_"], [328, 1, 1, "", "memmap_like"], [328, 1, 1, "", "memmap_refresh_"], [328, 1, 1, "", "save"], [328, 1, 1, "", "set"], [328, 1, 1, "", "stack"], [328, 1, 1, "", "state_dict"], [328, 1, 1, "", "to_tensordict"], [328, 1, 1, "", "unbind"]], "torchrl.modules.llm.RemoteTransformersWrapper": [[329, 2, 1, "", "batching"], [329, 1, 1, "", "cleanup_batching"], [329, 2, 1, "", "collector"], [329, 2, 1, "", "device"], [329, 2, 1, "", "dist_params_keys"], [329, 2, 1, "", "dist_sample_keys"], [329, 2, 1, "", "generate"], [329, 1, 1, "", "get_batching_state"], [329, 1, 1, "", "get_dist"], [329, 1, 1, "", "get_dist_with_prompt_mask"], [329, 1, 1, "", "get_new_version"], [329, 2, 1, "", "in_keys"], [329, 2, 1, "", "inplace"], [329, 2, 1, "", "layout"], [329, 1, 1, "", "log_prob"], [329, 2, 1, "", "log_prob_keys"], [329, 2, 1, "", "log_probs_key"], [329, 2, 1, "", "masks_key"], [329, 2, 1, "", "num_samples"], [329, 2, 1, "", "out_keys"], [329, 2, 1, "", "pad_output"], [329, 2, 1, "", "text_key"], [329, 2, 1, "", "tokens_key"]], "torchrl.modules.llm.Text": [[330, 1, 1, "", "cat"], [330, 1, 1, "", "default_spec"], [330, 2, 1, "", "device"], [330, 1, 1, "", "dumps"], [330, 1, 1, "", "fields"], [330, 1, 1, "", "from_any"], [330, 1, 1, "", "from_dataclass"], [330, 1, 1, "", "from_h5"], [330, 1, 1, "", "from_modules"], [330, 1, 1, "", "from_namedtuple"], [330, 1, 1, "", "from_pytree"], [330, 1, 1, "", "from_remote_init"], [330, 1, 1, "", "from_struct_array"], [330, 1, 1, "", "from_tensordict"], [330, 1, 1, "", "from_tuple"], [330, 1, 1, "", "fromkeys"], [330, 1, 1, "", "get"], [330, 1, 1, "", "lazy_stack"], [330, 1, 1, "", "load"], [330, 1, 1, "", "load_"], [330, 1, 1, "", "load_memmap"], [330, 1, 1, "", "load_state_dict"], [330, 1, 1, "", "maybe_dense_stack"], [330, 1, 1, "", "memmap"], [330, 1, 1, "", "memmap_"], [330, 1, 1, "", "memmap_like"], [330, 1, 1, "", "memmap_refresh_"], [330, 1, 1, "", "save"], [330, 1, 1, "", "set"], [330, 1, 1, "", "stack"], [330, 1, 1, "", "state_dict"], [330, 1, 1, "", "to_history"], [330, 1, 1, "", "to_tensordict"], [330, 1, 1, "", "to_tokens"], [330, 1, 1, "", "unbind"]], "torchrl.modules.llm.Tokens": [[331, 1, 1, "", "cat"], [331, 1, 1, "", "default_spec"], [331, 2, 1, "", "device"], [331, 1, 1, "", "dumps"], [331, 1, 1, "", "fields"], [331, 1, 1, "", "from_any"], [331, 1, 1, "", "from_dataclass"], [331, 1, 1, "", "from_h5"], [331, 1, 1, "", "from_modules"], [331, 1, 1, "", "from_namedtuple"], [331, 1, 1, "", "from_pytree"], [331, 1, 1, "", "from_remote_init"], [331, 1, 1, "", "from_struct_array"], [331, 1, 1, "", "from_tensordict"], [331, 1, 1, "", "from_tuple"], [331, 1, 1, "", "fromkeys"], [331, 1, 1, "", "get"], [331, 1, 1, "", "lazy_stack"], [331, 1, 1, "", "load"], [331, 1, 1, "", "load_"], [331, 1, 1, "", "load_memmap"], [331, 1, 1, "", "load_state_dict"], [331, 1, 1, "", "maybe_dense_stack"], [331, 1, 1, "", "memmap"], [331, 1, 1, "", "memmap_"], [331, 1, 1, "", "memmap_like"], [331, 1, 1, "", "memmap_refresh_"], [331, 1, 1, "", "save"], [331, 1, 1, "", "set"], [331, 1, 1, "", "stack"], [331, 1, 1, "", "state_dict"], [331, 1, 1, "", "to_history"], [331, 1, 1, "", "to_tensordict"], [331, 1, 1, "", "to_text"], [331, 1, 1, "", "unbind"]], "torchrl.modules.llm.TransformersWrapper": [[332, 1, 1, "", "add_module"], [332, 1, 1, "", "apply"], [332, 2, 1, "", "batching"], [332, 1, 1, "", "bfloat16"], [332, 1, 1, "", "buffers"], [332, 1, 1, "", "children"], [332, 1, 1, "", "cleanup_batching"], [332, 2, 1, "", "collector"], [332, 1, 1, "", "compile"], [332, 1, 1, "", "cpu"], [332, 1, 1, "", "cuda"], [332, 1, 1, "", "double"], [332, 1, 1, "", "eval"], [332, 1, 1, "", "extra_repr"], [332, 1, 1, "", "float"], [332, 1, 1, "", "forward"], [332, 1, 1, "", "get_batching_state"], [332, 1, 1, "", "get_buffer"], [332, 1, 1, "", "get_dist"], [332, 1, 1, "", "get_extra_state"], [332, 1, 1, "", "get_new_version"], [332, 1, 1, "", "get_parameter"], [332, 1, 1, "", "get_submodule"], [332, 1, 1, "", "half"], [332, 1, 1, "", "ipu"], [332, 1, 1, "", "is_tdmodule_compatible"], [332, 1, 1, "", "load_state_dict"], [332, 1, 1, "", "modules"], [332, 1, 1, "", "mtia"], [332, 1, 1, "", "named_buffers"], [332, 1, 1, "", "named_children"], [332, 1, 1, "", "named_modules"], [332, 1, 1, "", "named_parameters"], [332, 1, 1, "", "parameters"], [332, 1, 1, "", "register_backward_hook"], [332, 1, 1, "", "register_buffer"], [332, 1, 1, "", "register_collector"], [332, 1, 1, "", "register_forward_hook"], [332, 1, 1, "", "register_forward_pre_hook"], [332, 1, 1, "", "register_full_backward_hook"], [332, 1, 1, "", "register_full_backward_pre_hook"], [332, 1, 1, "", "register_load_state_dict_post_hook"], [332, 1, 1, "", "register_load_state_dict_pre_hook"], [332, 1, 1, "", "register_module"], [332, 1, 1, "", "register_parameter"], [332, 1, 1, "", "register_state_dict_post_hook"], [332, 1, 1, "", "register_state_dict_pre_hook"], [332, 1, 1, "", "repeat_interleave_causal"], [332, 1, 1, "", "requires_grad_"], [332, 1, 1, "", "reset_out_keys"], [332, 1, 1, "", "reset_parameters_recursive"], [332, 1, 1, "", "select_out_keys"], [332, 1, 1, "", "set_extra_state"], [332, 1, 1, "", "set_submodule"], [332, 1, 1, "", "share_memory"], [332, 1, 1, "", "state_dict"], [332, 1, 1, "", "to"], [332, 1, 1, "", "to_empty"], [332, 1, 1, "", "train"], [332, 1, 1, "", "type"], [332, 1, 1, "", "xpu"], [332, 1, 1, "", "zero_grad"]], "torchrl.modules.llm.vLLMWrapper": [[337, 1, 1, "", "add_module"], [337, 1, 1, "", "apply"], [337, 2, 1, "", "batching"], [337, 1, 1, "", "bfloat16"], [337, 1, 1, "", "buffers"], [337, 1, 1, "", "children"], [337, 1, 1, "", "cleanup_batching"], [337, 2, 1, "", "collector"], [337, 1, 1, "", "compile"], [337, 1, 1, "", "cpu"], [337, 1, 1, "", "cuda"], [337, 1, 1, "", "double"], [337, 1, 1, "", "eval"], [337, 1, 1, "", "extra_repr"], [337, 1, 1, "", "float"], [337, 1, 1, "", "forward"], [337, 1, 1, "", "get_batching_state"], [337, 1, 1, "", "get_buffer"], [337, 1, 1, "", "get_dist"], [337, 1, 1, "", "get_dist_with_prompt_mask"], [337, 1, 1, "", "get_extra_state"], [337, 1, 1, "", "get_new_version"], [337, 1, 1, "", "get_parameter"], [337, 1, 1, "", "get_submodule"], [337, 1, 1, "", "half"], [337, 1, 1, "", "ipu"], [337, 1, 1, "", "is_tdmodule_compatible"], [337, 1, 1, "", "load_state_dict"], [337, 1, 1, "", "modules"], [337, 1, 1, "", "mtia"], [337, 1, 1, "", "named_buffers"], [337, 1, 1, "", "named_children"], [337, 1, 1, "", "named_modules"], [337, 1, 1, "", "named_parameters"], [337, 1, 1, "", "parameters"], [337, 1, 1, "", "register_backward_hook"], [337, 1, 1, "", "register_buffer"], [337, 1, 1, "", "register_collector"], [337, 1, 1, "", "register_forward_hook"], [337, 1, 1, "", "register_forward_pre_hook"], [337, 1, 1, "", "register_full_backward_hook"], [337, 1, 1, "", "register_full_backward_pre_hook"], [337, 1, 1, "", "register_load_state_dict_post_hook"], [337, 1, 1, "", "register_load_state_dict_pre_hook"], [337, 1, 1, "", "register_module"], [337, 1, 1, "", "register_parameter"], [337, 1, 1, "", "register_state_dict_post_hook"], [337, 1, 1, "", "register_state_dict_pre_hook"], [337, 1, 1, "", "requires_grad_"], [337, 1, 1, "", "reset_out_keys"], [337, 1, 1, "", "reset_parameters_recursive"], [337, 1, 1, "", "select_out_keys"], [337, 1, 1, "", "set_extra_state"], [337, 1, 1, "", "set_submodule"], [337, 1, 1, "", "set_tokenizer"], [337, 1, 1, "", "share_memory"], [337, 1, 1, "", "state_dict"], [337, 1, 1, "", "to"], [337, 1, 1, "", "to_empty"], [337, 1, 1, "", "train"], [337, 1, 1, "", "type"], [337, 1, 1, "", "xpu"], [337, 1, 1, "", "zero_grad"]], "torchrl.modules.models.utils": [[338, 0, 1, "", "SquashDims"]], "torchrl.modules.models.utils.SquashDims": [[338, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module": [[340, 0, 1, "", "Actor"], [341, 0, 1, "", "MultiStepActorWrapper"], [342, 0, 1, "", "ProbabilisticActor"], [343, 0, 1, "", "RandomPolicy"], [344, 0, 1, "", "SafeModule"], [345, 0, 1, "", "SafeProbabilisticModule"], [346, 0, 1, "", "SafeProbabilisticTensorDictSequential"], [347, 0, 1, "", "SafeSequential"], [348, 0, 1, "", "TanhModule"]], "torchrl.modules.tensordict_module.MultiStepActorWrapper": [[341, 1, 1, "", "forward"], [341, 2, 1, "", "init_key"]], "torchrl.modules.tensordict_module.SafeModule": [[344, 1, 1, "", "random"], [344, 1, 1, "", "random_sample"], [344, 1, 1, "", "to"]], "torchrl.modules.tensordict_module.SafeProbabilisticModule": [[345, 1, 1, "", "random"], [345, 1, 1, "", "random_sample"]], "torchrl.modules.tensordict_module.TanhModule": [[348, 1, 1, "", "forward"]], "torchrl.objectives": [[349, 0, 1, "", "A2CLoss"], [350, 0, 1, "", "CQLLoss"], [351, 0, 1, "", "ClipPPOLoss"], [352, 0, 1, "", "CrossQLoss"], [353, 0, 1, "", "DDPGLoss"], [354, 0, 1, "", "DQNLoss"], [355, 0, 1, "", "DTLoss"], [356, 0, 1, "", "DiscreteCQLLoss"], [357, 0, 1, "", "DiscreteIQLLoss"], [358, 0, 1, "", "DiscreteSACLoss"], [359, 0, 1, "", "DistributionalDQNLoss"], [360, 0, 1, "", "DreamerActorLoss"], [361, 0, 1, "", "DreamerModelLoss"], [362, 0, 1, "", "DreamerValueLoss"], [363, 0, 1, "", "GAILLoss"], [364, 0, 1, "", "IQLLoss"], [365, 0, 1, "", "KLPENPPOLoss"], [366, 0, 1, "", "LossModule"], [367, 0, 1, "", "OnlineDTLoss"], [368, 0, 1, "", "PPOLoss"], [369, 0, 1, "", "REDQLoss"], [370, 0, 1, "", "ReinforceLoss"], [371, 0, 1, "", "SACLoss"], [372, 0, 1, "", "TD3BCLoss"], [373, 0, 1, "", "TD3Loss"], [374, 0, 1, "", "ValueEstimators"], [375, 0, 1, "", "add_random_module"]], "torchrl.objectives.A2CLoss": [[349, 4, 1, "", "default_keys"], [349, 1, 1, "", "forward"], [349, 2, 1, "", "functional"], [349, 1, 1, "", "loss_critic"], [349, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.CQLLoss": [[350, 4, 1, "", "default_keys"], [350, 1, 1, "", "forward"], [350, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ClipPPOLoss": [[351, 1, 1, "", "forward"]], "torchrl.objectives.CrossQLoss": [[352, 1, 1, "", "actor_loss"], [352, 1, 1, "", "alpha_loss"], [352, 4, 1, "", "default_keys"], [352, 1, 1, "", "forward"], [352, 1, 1, "", "load_state_dict"], [352, 1, 1, "", "make_value_estimator"], [352, 1, 1, "", "maybe_init_target_entropy"], [352, 1, 1, "", "qvalue_loss"], [352, 1, 1, "", "set_keys"], [352, 1, 1, "", "state_dict"], [352, 2, 1, "", "target_entropy_buffer"]], "torchrl.objectives.DDPGLoss": [[353, 4, 1, "", "default_keys"], [353, 1, 1, "", "forward"], [353, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DQNLoss": [[354, 4, 1, "", "default_keys"], [354, 1, 1, "", "forward"], [354, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DTLoss": [[355, 4, 1, "", "default_keys"], [355, 1, 1, "", "forward"]], "torchrl.objectives.DiscreteCQLLoss": [[356, 4, 1, "", "default_keys"], [356, 1, 1, "", "forward"], [356, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DiscreteIQLLoss": [[357, 4, 1, "", "default_keys"], [357, 1, 1, "", "forward"]], "torchrl.objectives.DiscreteSACLoss": [[358, 1, 1, "", "alpha_loss"], [358, 4, 1, "", "default_keys"], [358, 1, 1, "", "forward"], [358, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DistributionalDQNLoss": [[359, 4, 1, "", "default_keys"], [359, 1, 1, "", "forward"], [359, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerActorLoss": [[360, 4, 1, "", "default_keys"], [360, 1, 1, "", "forward"], [360, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerModelLoss": [[361, 4, 1, "", "default_keys"], [361, 1, 1, "", "forward"]], "torchrl.objectives.DreamerValueLoss": [[362, 4, 1, "", "default_keys"], [362, 1, 1, "", "forward"]], "torchrl.objectives.GAILLoss": [[363, 4, 1, "", "default_keys"], [363, 1, 1, "", "forward"]], "torchrl.objectives.IQLLoss": [[364, 4, 1, "", "default_keys"], [364, 1, 1, "", "forward"], [364, 1, 1, "", "loss_value_diff"], [364, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.KLPENPPOLoss": [[365, 1, 1, "", "forward"]], "torchrl.objectives.LossModule": [[366, 1, 1, "", "convert_to_functional"], [366, 1, 1, "", "forward"], [366, 1, 1, "", "from_stateful_net"], [366, 2, 1, "", "functional"], [366, 1, 1, "", "get_stateful_net"], [366, 1, 1, "", "make_value_estimator"], [366, 1, 1, "", "named_parameters"], [366, 1, 1, "", "parameters"], [366, 1, 1, "", "reset_parameters_recursive"], [366, 1, 1, "", "set_keys"], [366, 2, 1, "", "value_estimator"], [366, 2, 1, "", "vmap_randomness"]], "torchrl.objectives.OnlineDTLoss": [[367, 4, 1, "", "default_keys"], [367, 1, 1, "", "forward"]], "torchrl.objectives.PPOLoss": [[368, 4, 1, "", "default_keys"], [368, 1, 1, "", "forward"], [368, 2, 1, "", "functional"], [368, 1, 1, "", "loss_critic"], [368, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.REDQLoss": [[369, 4, 1, "", "default_keys"], [369, 1, 1, "", "forward"], [369, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ReinforceLoss": [[370, 4, 1, "", "default_keys"], [370, 1, 1, "", "forward"], [370, 2, 1, "", "functional"], [370, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.SACLoss": [[371, 1, 1, "", "alpha_loss"], [371, 4, 1, "", "default_keys"], [371, 1, 1, "", "forward"], [371, 1, 1, "", "load_state_dict"], [371, 1, 1, "", "make_value_estimator"], [371, 1, 1, "", "state_dict"]], "torchrl.objectives.TD3BCLoss": [[372, 1, 1, "", "actor_loss"], [372, 4, 1, "", "default_keys"], [372, 1, 1, "", "forward"], [372, 1, 1, "", "make_value_estimator"], [372, 1, 1, "", "qvalue_loss"]], "torchrl.objectives.TD3Loss": [[373, 4, 1, "", "default_keys"], [373, 1, 1, "", "forward"], [373, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.llm": [[376, 0, 1, "", "CISPOLoss"], [377, 0, 1, "", "CISPOLossOutput"], [378, 0, 1, "", "DAPO"], [379, 0, 1, "", "DAPOLossOutput"], [380, 0, 1, "", "GRPOLoss"], [381, 0, 1, "", "GRPOLossOutput"], [382, 0, 1, "", "LLMLossOutput"], [383, 0, 1, "", "MCAdvantage"], [384, 0, 1, "", "SFTLoss"], [385, 0, 1, "", "SFTLossOutput"]], "torchrl.objectives.llm.CISPOLoss": [[376, 1, 1, "", "add_module"], [376, 1, 1, "", "apply"], [376, 1, 1, "", "bfloat16"], [376, 1, 1, "", "buffers"], [376, 1, 1, "", "children"], [376, 1, 1, "", "compile"], [376, 1, 1, "", "convert_to_functional"], [376, 1, 1, "", "cpu"], [376, 1, 1, "", "cuda"], [376, 1, 1, "", "double"], [376, 1, 1, "", "eval"], [376, 1, 1, "", "extra_repr"], [376, 1, 1, "", "float"], [376, 1, 1, "", "forward"], [376, 1, 1, "", "from_stateful_net"], [376, 2, 1, "", "functional"], [376, 1, 1, "", "get_buffer"], [376, 1, 1, "", "get_extra_state"], [376, 1, 1, "", "get_parameter"], [376, 1, 1, "", "get_stateful_net"], [376, 1, 1, "", "get_submodule"], [376, 1, 1, "", "half"], [376, 1, 1, "", "ipu"], [376, 1, 1, "", "is_tdmodule_compatible"], [376, 1, 1, "", "load_state_dict"], [376, 1, 1, "", "make_value_estimator"], [376, 1, 1, "", "modules"], [376, 1, 1, "", "mtia"], [376, 1, 1, "", "named_buffers"], [376, 1, 1, "", "named_children"], [376, 1, 1, "", "named_modules"], [376, 1, 1, "", "named_parameters"], [376, 4, 1, "", "output_type"], [376, 1, 1, "", "parameters"], [376, 1, 1, "", "register_backward_hook"], [376, 1, 1, "", "register_buffer"], [376, 1, 1, "", "register_forward_hook"], [376, 1, 1, "", "register_forward_pre_hook"], [376, 1, 1, "", "register_full_backward_hook"], [376, 1, 1, "", "register_full_backward_pre_hook"], [376, 1, 1, "", "register_load_state_dict_post_hook"], [376, 1, 1, "", "register_load_state_dict_pre_hook"], [376, 1, 1, "", "register_module"], [376, 1, 1, "", "register_parameter"], [376, 1, 1, "", "register_state_dict_post_hook"], [376, 1, 1, "", "register_state_dict_pre_hook"], [376, 1, 1, "", "requires_grad_"], [376, 1, 1, "", "reset_out_keys"], [376, 1, 1, "", "reset_parameters_recursive"], [376, 1, 1, "", "select_out_keys"], [376, 1, 1, "", "set_extra_state"], [376, 1, 1, "", "set_keys"], [376, 1, 1, "", "set_submodule"], [376, 1, 1, "", "share_memory"], [376, 1, 1, "", "state_dict"], [376, 2, 1, "", "tensor_keys"], [376, 1, 1, "", "to"], [376, 1, 1, "", "to_empty"], [376, 1, 1, "", "train"], [376, 1, 1, "", "type"], [376, 2, 1, "", "value_estimator"], [376, 2, 1, "", "vmap_randomness"], [376, 1, 1, "", "xpu"], [376, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.CISPOLossOutput": [[377, 1, 1, "", "cat"], [377, 2, 1, "", "device"], [377, 1, 1, "", "dumps"], [377, 1, 1, "", "fields"], [377, 1, 1, "", "from_any"], [377, 1, 1, "", "from_dataclass"], [377, 1, 1, "", "from_h5"], [377, 1, 1, "", "from_modules"], [377, 1, 1, "", "from_namedtuple"], [377, 1, 1, "", "from_pytree"], [377, 1, 1, "", "from_remote_init"], [377, 1, 1, "", "from_struct_array"], [377, 1, 1, "", "from_tensordict"], [377, 1, 1, "", "from_tuple"], [377, 1, 1, "", "fromkeys"], [377, 1, 1, "", "get"], [377, 1, 1, "", "lazy_stack"], [377, 1, 1, "", "load"], [377, 1, 1, "", "load_"], [377, 1, 1, "", "load_memmap"], [377, 1, 1, "", "load_state_dict"], [377, 1, 1, "", "maybe_dense_stack"], [377, 1, 1, "", "memmap"], [377, 1, 1, "", "memmap_"], [377, 1, 1, "", "memmap_like"], [377, 1, 1, "", "memmap_refresh_"], [377, 1, 1, "", "save"], [377, 1, 1, "", "set"], [377, 1, 1, "", "stack"], [377, 1, 1, "", "state_dict"], [377, 1, 1, "", "to_tensordict"], [377, 1, 1, "", "unbind"]], "torchrl.objectives.llm.DAPO": [[378, 1, 1, "", "add_module"], [378, 1, 1, "", "apply"], [378, 1, 1, "", "bfloat16"], [378, 1, 1, "", "buffers"], [378, 1, 1, "", "children"], [378, 1, 1, "", "compile"], [378, 1, 1, "", "convert_to_functional"], [378, 1, 1, "", "cpu"], [378, 1, 1, "", "cuda"], [378, 1, 1, "", "double"], [378, 1, 1, "", "eval"], [378, 1, 1, "", "extra_repr"], [378, 1, 1, "", "float"], [378, 1, 1, "", "forward"], [378, 1, 1, "", "from_stateful_net"], [378, 2, 1, "", "functional"], [378, 1, 1, "", "get_buffer"], [378, 1, 1, "", "get_extra_state"], [378, 1, 1, "", "get_parameter"], [378, 1, 1, "", "get_stateful_net"], [378, 1, 1, "", "get_submodule"], [378, 1, 1, "", "half"], [378, 1, 1, "", "ipu"], [378, 1, 1, "", "is_tdmodule_compatible"], [378, 1, 1, "", "load_state_dict"], [378, 1, 1, "", "make_value_estimator"], [378, 1, 1, "", "modules"], [378, 1, 1, "", "mtia"], [378, 1, 1, "", "named_buffers"], [378, 1, 1, "", "named_children"], [378, 1, 1, "", "named_modules"], [378, 1, 1, "", "named_parameters"], [378, 4, 1, "", "output_type"], [378, 1, 1, "", "parameters"], [378, 1, 1, "", "register_backward_hook"], [378, 1, 1, "", "register_buffer"], [378, 1, 1, "", "register_forward_hook"], [378, 1, 1, "", "register_forward_pre_hook"], [378, 1, 1, "", "register_full_backward_hook"], [378, 1, 1, "", "register_full_backward_pre_hook"], [378, 1, 1, "", "register_load_state_dict_post_hook"], [378, 1, 1, "", "register_load_state_dict_pre_hook"], [378, 1, 1, "", "register_module"], [378, 1, 1, "", "register_parameter"], [378, 1, 1, "", "register_state_dict_post_hook"], [378, 1, 1, "", "register_state_dict_pre_hook"], [378, 1, 1, "", "requires_grad_"], [378, 1, 1, "", "reset_out_keys"], [378, 1, 1, "", "reset_parameters_recursive"], [378, 1, 1, "", "select_out_keys"], [378, 1, 1, "", "set_extra_state"], [378, 1, 1, "", "set_keys"], [378, 1, 1, "", "set_submodule"], [378, 1, 1, "", "share_memory"], [378, 1, 1, "", "state_dict"], [378, 2, 1, "", "tensor_keys"], [378, 1, 1, "", "to"], [378, 1, 1, "", "to_empty"], [378, 1, 1, "", "train"], [378, 1, 1, "", "type"], [378, 2, 1, "", "value_estimator"], [378, 2, 1, "", "vmap_randomness"], [378, 1, 1, "", "xpu"], [378, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.DAPOLossOutput": [[379, 1, 1, "", "cat"], [379, 2, 1, "", "device"], [379, 1, 1, "", "dumps"], [379, 1, 1, "", "fields"], [379, 1, 1, "", "from_any"], [379, 1, 1, "", "from_dataclass"], [379, 1, 1, "", "from_h5"], [379, 1, 1, "", "from_modules"], [379, 1, 1, "", "from_namedtuple"], [379, 1, 1, "", "from_pytree"], [379, 1, 1, "", "from_remote_init"], [379, 1, 1, "", "from_struct_array"], [379, 1, 1, "", "from_tensordict"], [379, 1, 1, "", "from_tuple"], [379, 1, 1, "", "fromkeys"], [379, 1, 1, "", "get"], [379, 1, 1, "", "lazy_stack"], [379, 1, 1, "", "load"], [379, 1, 1, "", "load_"], [379, 1, 1, "", "load_memmap"], [379, 1, 1, "", "load_state_dict"], [379, 1, 1, "", "maybe_dense_stack"], [379, 1, 1, "", "memmap"], [379, 1, 1, "", "memmap_"], [379, 1, 1, "", "memmap_like"], [379, 1, 1, "", "memmap_refresh_"], [379, 1, 1, "", "save"], [379, 1, 1, "", "set"], [379, 1, 1, "", "stack"], [379, 1, 1, "", "state_dict"], [379, 1, 1, "", "to_tensordict"], [379, 1, 1, "", "unbind"]], "torchrl.objectives.llm.GRPOLoss": [[380, 1, 1, "", "add_module"], [380, 1, 1, "", "apply"], [380, 1, 1, "", "bfloat16"], [380, 1, 1, "", "buffers"], [380, 1, 1, "", "children"], [380, 1, 1, "", "compile"], [380, 1, 1, "", "convert_to_functional"], [380, 1, 1, "", "cpu"], [380, 1, 1, "", "cuda"], [380, 1, 1, "", "double"], [380, 1, 1, "", "eval"], [380, 1, 1, "", "extra_repr"], [380, 1, 1, "", "float"], [380, 1, 1, "", "forward"], [380, 1, 1, "", "from_stateful_net"], [380, 2, 1, "", "functional"], [380, 1, 1, "", "get_buffer"], [380, 1, 1, "", "get_extra_state"], [380, 1, 1, "", "get_parameter"], [380, 1, 1, "", "get_stateful_net"], [380, 1, 1, "", "get_submodule"], [380, 1, 1, "", "half"], [380, 1, 1, "", "ipu"], [380, 1, 1, "", "is_tdmodule_compatible"], [380, 1, 1, "", "load_state_dict"], [380, 1, 1, "", "make_value_estimator"], [380, 1, 1, "", "modules"], [380, 1, 1, "", "mtia"], [380, 1, 1, "", "named_buffers"], [380, 1, 1, "", "named_children"], [380, 1, 1, "", "named_modules"], [380, 1, 1, "", "named_parameters"], [380, 4, 1, "", "output_type"], [380, 1, 1, "", "parameters"], [380, 1, 1, "", "register_backward_hook"], [380, 1, 1, "", "register_buffer"], [380, 1, 1, "", "register_forward_hook"], [380, 1, 1, "", "register_forward_pre_hook"], [380, 1, 1, "", "register_full_backward_hook"], [380, 1, 1, "", "register_full_backward_pre_hook"], [380, 1, 1, "", "register_load_state_dict_post_hook"], [380, 1, 1, "", "register_load_state_dict_pre_hook"], [380, 1, 1, "", "register_module"], [380, 1, 1, "", "register_parameter"], [380, 1, 1, "", "register_state_dict_post_hook"], [380, 1, 1, "", "register_state_dict_pre_hook"], [380, 1, 1, "", "requires_grad_"], [380, 1, 1, "", "reset_out_keys"], [380, 1, 1, "", "reset_parameters_recursive"], [380, 1, 1, "", "select_out_keys"], [380, 1, 1, "", "set_extra_state"], [380, 1, 1, "", "set_keys"], [380, 1, 1, "", "set_submodule"], [380, 1, 1, "", "share_memory"], [380, 1, 1, "", "state_dict"], [380, 2, 1, "", "tensor_keys"], [380, 1, 1, "", "to"], [380, 1, 1, "", "to_empty"], [380, 1, 1, "", "train"], [380, 1, 1, "", "type"], [380, 2, 1, "", "value_estimator"], [380, 2, 1, "", "vmap_randomness"], [380, 1, 1, "", "xpu"], [380, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.GRPOLossOutput": [[381, 1, 1, "", "cat"], [381, 2, 1, "", "device"], [381, 1, 1, "", "dumps"], [381, 1, 1, "", "fields"], [381, 1, 1, "", "from_any"], [381, 1, 1, "", "from_dataclass"], [381, 1, 1, "", "from_h5"], [381, 1, 1, "", "from_modules"], [381, 1, 1, "", "from_namedtuple"], [381, 1, 1, "", "from_pytree"], [381, 1, 1, "", "from_remote_init"], [381, 1, 1, "", "from_struct_array"], [381, 1, 1, "", "from_tensordict"], [381, 1, 1, "", "from_tuple"], [381, 1, 1, "", "fromkeys"], [381, 1, 1, "", "get"], [381, 1, 1, "", "lazy_stack"], [381, 1, 1, "", "load"], [381, 1, 1, "", "load_"], [381, 1, 1, "", "load_memmap"], [381, 1, 1, "", "load_state_dict"], [381, 1, 1, "", "maybe_dense_stack"], [381, 1, 1, "", "memmap"], [381, 1, 1, "", "memmap_"], [381, 1, 1, "", "memmap_like"], [381, 1, 1, "", "memmap_refresh_"], [381, 1, 1, "", "save"], [381, 1, 1, "", "set"], [381, 1, 1, "", "stack"], [381, 1, 1, "", "state_dict"], [381, 1, 1, "", "to_tensordict"], [381, 1, 1, "", "unbind"]], "torchrl.objectives.llm.LLMLossOutput": [[382, 1, 1, "", "cat"], [382, 2, 1, "", "device"], [382, 1, 1, "", "dumps"], [382, 1, 1, "", "fields"], [382, 1, 1, "", "from_any"], [382, 1, 1, "", "from_dataclass"], [382, 1, 1, "", "from_h5"], [382, 1, 1, "", "from_modules"], [382, 1, 1, "", "from_namedtuple"], [382, 1, 1, "", "from_pytree"], [382, 1, 1, "", "from_remote_init"], [382, 1, 1, "", "from_struct_array"], [382, 1, 1, "", "from_tensordict"], [382, 1, 1, "", "from_tuple"], [382, 1, 1, "", "fromkeys"], [382, 1, 1, "", "get"], [382, 1, 1, "", "lazy_stack"], [382, 1, 1, "", "load"], [382, 1, 1, "", "load_"], [382, 1, 1, "", "load_memmap"], [382, 1, 1, "", "load_state_dict"], [382, 1, 1, "", "maybe_dense_stack"], [382, 1, 1, "", "memmap"], [382, 1, 1, "", "memmap_"], [382, 1, 1, "", "memmap_like"], [382, 1, 1, "", "memmap_refresh_"], [382, 1, 1, "", "save"], [382, 1, 1, "", "set"], [382, 1, 1, "", "stack"], [382, 1, 1, "", "state_dict"], [382, 1, 1, "", "to_tensordict"], [382, 1, 1, "", "unbind"]], "torchrl.objectives.llm.MCAdvantage": [[383, 1, 1, "", "add_module"], [383, 1, 1, "", "apply"], [383, 1, 1, "", "bfloat16"], [383, 1, 1, "", "buffers"], [383, 1, 1, "", "children"], [383, 1, 1, "", "close"], [383, 2, 1, "", "collector"], [383, 1, 1, "", "compile"], [383, 2, 1, "", "container"], [383, 1, 1, "", "cpu"], [383, 1, 1, "", "cuda"], [383, 1, 1, "", "double"], [383, 1, 1, "", "eval"], [383, 1, 1, "", "extra_repr"], [383, 1, 1, "", "float"], [383, 1, 1, "", "forward"], [383, 1, 1, "", "get_buffer"], [383, 1, 1, "", "get_extra_state"], [383, 1, 1, "", "get_parameter"], [383, 1, 1, "", "get_submodule"], [383, 1, 1, "", "half"], [383, 1, 1, "", "init"], [383, 1, 1, "", "inv"], [383, 1, 1, "", "ipu"], [383, 1, 1, "", "load_state_dict"], [383, 1, 1, "", "modules"], [383, 1, 1, "", "mtia"], [383, 1, 1, "", "named_buffers"], [383, 1, 1, "", "named_children"], [383, 1, 1, "", "named_modules"], [383, 1, 1, "", "named_parameters"], [383, 1, 1, "", "parameters"], [383, 2, 1, "", "parent"], [383, 1, 1, "", "register_backward_hook"], [383, 1, 1, "", "register_buffer"], [383, 1, 1, "", "register_forward_hook"], [383, 1, 1, "", "register_forward_pre_hook"], [383, 1, 1, "", "register_full_backward_hook"], [383, 1, 1, "", "register_full_backward_pre_hook"], [383, 1, 1, "", "register_load_state_dict_post_hook"], [383, 1, 1, "", "register_load_state_dict_pre_hook"], [383, 1, 1, "", "register_module"], [383, 1, 1, "", "register_parameter"], [383, 1, 1, "", "register_state_dict_post_hook"], [383, 1, 1, "", "register_state_dict_pre_hook"], [383, 1, 1, "", "requires_grad_"], [383, 1, 1, "", "set_extra_state"], [383, 1, 1, "", "set_submodule"], [383, 1, 1, "", "share_memory"], [383, 1, 1, "", "state_dict"], [383, 1, 1, "", "to"], [383, 1, 1, "", "to_empty"], [383, 1, 1, "", "train"], [383, 1, 1, "", "transform_action_spec"], [383, 1, 1, "", "transform_done_spec"], [383, 1, 1, "", "transform_env_batch_size"], [383, 1, 1, "", "transform_env_device"], [383, 1, 1, "", "transform_input_spec"], [383, 1, 1, "", "transform_observation_spec"], [383, 1, 1, "", "transform_output_spec"], [383, 1, 1, "", "transform_reward_spec"], [383, 1, 1, "", "transform_state_spec"], [383, 1, 1, "", "type"], [383, 1, 1, "", "xpu"], [383, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.SFTLoss": [[384, 1, 1, "", "add_module"], [384, 1, 1, "", "apply"], [384, 1, 1, "", "bfloat16"], [384, 1, 1, "", "buffers"], [384, 1, 1, "", "children"], [384, 1, 1, "", "compile"], [384, 1, 1, "", "convert_to_functional"], [384, 1, 1, "", "cpu"], [384, 1, 1, "", "cuda"], [384, 4, 1, "", "default_keys"], [384, 1, 1, "", "double"], [384, 1, 1, "", "eval"], [384, 1, 1, "", "extra_repr"], [384, 1, 1, "", "float"], [384, 1, 1, "", "forward"], [384, 1, 1, "", "from_stateful_net"], [384, 2, 1, "", "functional"], [384, 1, 1, "", "get_buffer"], [384, 1, 1, "", "get_extra_state"], [384, 1, 1, "", "get_parameter"], [384, 1, 1, "", "get_stateful_net"], [384, 1, 1, "", "get_submodule"], [384, 1, 1, "", "half"], [384, 1, 1, "", "ipu"], [384, 1, 1, "", "is_tdmodule_compatible"], [384, 1, 1, "", "load_state_dict"], [384, 1, 1, "", "make_value_estimator"], [384, 1, 1, "", "modules"], [384, 1, 1, "", "mtia"], [384, 1, 1, "", "named_buffers"], [384, 1, 1, "", "named_children"], [384, 1, 1, "", "named_modules"], [384, 1, 1, "", "named_parameters"], [384, 1, 1, "", "parameters"], [384, 1, 1, "", "register_backward_hook"], [384, 1, 1, "", "register_buffer"], [384, 1, 1, "", "register_forward_hook"], [384, 1, 1, "", "register_forward_pre_hook"], [384, 1, 1, "", "register_full_backward_hook"], [384, 1, 1, "", "register_full_backward_pre_hook"], [384, 1, 1, "", "register_load_state_dict_post_hook"], [384, 1, 1, "", "register_load_state_dict_pre_hook"], [384, 1, 1, "", "register_module"], [384, 1, 1, "", "register_parameter"], [384, 1, 1, "", "register_state_dict_post_hook"], [384, 1, 1, "", "register_state_dict_pre_hook"], [384, 1, 1, "", "requires_grad_"], [384, 1, 1, "", "reset_out_keys"], [384, 1, 1, "", "reset_parameters_recursive"], [384, 1, 1, "", "select_out_keys"], [384, 1, 1, "", "set_extra_state"], [384, 1, 1, "", "set_keys"], [384, 1, 1, "", "set_submodule"], [384, 1, 1, "", "share_memory"], [384, 1, 1, "", "state_dict"], [384, 1, 1, "", "to"], [384, 1, 1, "", "to_empty"], [384, 1, 1, "", "train"], [384, 1, 1, "", "type"], [384, 2, 1, "", "value_estimator"], [384, 2, 1, "", "vmap_randomness"], [384, 1, 1, "", "xpu"], [384, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.SFTLossOutput": [[385, 1, 1, "", "cat"], [385, 2, 1, "", "device"], [385, 1, 1, "", "dumps"], [385, 1, 1, "", "fields"], [385, 1, 1, "", "from_any"], [385, 1, 1, "", "from_dataclass"], [385, 1, 1, "", "from_h5"], [385, 1, 1, "", "from_modules"], [385, 1, 1, "", "from_namedtuple"], [385, 1, 1, "", "from_pytree"], [385, 1, 1, "", "from_remote_init"], [385, 1, 1, "", "from_struct_array"], [385, 1, 1, "", "from_tensordict"], [385, 1, 1, "", "from_tuple"], [385, 1, 1, "", "fromkeys"], [385, 1, 1, "", "get"], [385, 1, 1, "", "lazy_stack"], [385, 1, 1, "", "load"], [385, 1, 1, "", "load_"], [385, 1, 1, "", "load_memmap"], [385, 1, 1, "", "load_state_dict"], [385, 1, 1, "", "maybe_dense_stack"], [385, 1, 1, "", "memmap"], [385, 1, 1, "", "memmap_"], [385, 1, 1, "", "memmap_like"], [385, 1, 1, "", "memmap_refresh_"], [385, 1, 1, "", "save"], [385, 1, 1, "", "set"], [385, 1, 1, "", "stack"], [385, 1, 1, "", "state_dict"], [385, 1, 1, "", "to_tensordict"], [385, 1, 1, "", "unbind"]], "torchrl.objectives.value": [[386, 0, 1, "", "GAE"], [387, 0, 1, "", "TD0Estimator"], [388, 0, 1, "", "TD1Estimator"], [389, 0, 1, "", "TDLambdaEstimator"], [390, 0, 1, "", "ValueEstimatorBase"]], "torchrl.objectives.value.GAE": [[386, 1, 1, "", "forward"], [386, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD0Estimator": [[387, 1, 1, "", "forward"], [387, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD1Estimator": [[388, 1, 1, "", "forward"], [388, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TDLambdaEstimator": [[389, 1, 1, "", "forward"], [389, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.ValueEstimatorBase": [[390, 4, 1, "", "default_keys"], [390, 1, 1, "", "forward"], [390, 1, 1, "", "set_keys"], [390, 1, 1, "", "value_estimate"]], "torchrl.record": [[391, 3, 1, "", "PixelRenderTransform"], [392, 3, 1, "", "TensorDictRecorder"], [393, 3, 1, "", "VideoRecorder"]], "torchrl.record.loggers": [[394, 3, 1, "", "Logger"], [396, 3, 1, "", "generate_exp_name"], [397, 3, 1, "", "get_logger"]], "torchrl.record.loggers.csv": [[395, 3, 1, "", "CSVLogger"]], "torchrl.record.loggers.mlflow": [[398, 3, 1, "", "MLFlowLogger"]], "torchrl.record.loggers.tensorboard": [[399, 3, 1, "", "TensorboardLogger"]], "torchrl.record.loggers.trackio": [[400, 3, 1, "", "TrackioLogger"]], "torchrl.record.loggers.wandb": [[401, 3, 1, "", "WandbLogger"]], "torchrl.services": [[402, 0, 1, "", "RayService"], [403, 0, 1, "", "ServiceBase"], [404, 0, 1, "", "get_services"]], "torchrl.services.RayService": [[402, 1, 1, "", "get"], [402, 1, 1, "", "list"], [402, 1, 1, "", "register"], [402, 1, 1, "", "register_with_options"], [402, 1, 1, "", "reset"], [402, 1, 1, "", "shutdown"]], "torchrl.services.ServiceBase": [[403, 1, 1, "", "get"], [403, 1, 1, "", "list"], [403, 1, 1, "", "register"], [403, 1, 1, "", "reset"]], "torchrl.trainers": [[406, 0, 1, "", "BatchSubSampler"], [407, 0, 1, "", "ClearCudaCache"], [408, 0, 1, "", "CountFramesLog"], [409, 0, 1, "", "LogScalar"], [410, 0, 1, "", "LogValidationReward"], [411, 0, 1, "", "OptimizerHook"], [412, 0, 1, "", "ReplayBufferTrainer"], [413, 0, 1, "", "RewardNormalizer"], [414, 0, 1, "", "SelectKeys"], [415, 0, 1, "", "TargetNetUpdaterHook"], [416, 0, 1, "", "Trainer"], [417, 0, 1, "", "TrainerHookBase"], [418, 0, 1, "", "UTDRHook"], [419, 0, 1, "", "UpdateWeights"]], "torchrl.trainers.BatchSubSampler": [[406, 1, 1, "", "register"]], "torchrl.trainers.ClearCudaCache": [[407, 1, 1, "", "register"]], "torchrl.trainers.CountFramesLog": [[408, 1, 1, "", "register"]], "torchrl.trainers.LogScalar": [[409, 1, 1, "", "register"]], "torchrl.trainers.LogValidationReward": [[410, 1, 1, "", "register"]], "torchrl.trainers.OptimizerHook": [[411, 1, 1, "", "register"]], "torchrl.trainers.ReplayBufferTrainer": [[412, 1, 1, "", "register"]], "torchrl.trainers.RewardNormalizer": [[413, 1, 1, "", "register"]], "torchrl.trainers.SelectKeys": [[414, 1, 1, "", "register"]], "torchrl.trainers.TargetNetUpdaterHook": [[415, 1, 1, "", "register"]], "torchrl.trainers.Trainer": [[416, 1, 1, "", "load_from_file"]], "torchrl.trainers.TrainerHookBase": [[417, 1, 1, "", "register"]], "torchrl.trainers.UTDRHook": [[418, 1, 1, "", "load_state_dict"], [418, 1, 1, "", "register"], [418, 1, 1, "", "state_dict"]], "torchrl.trainers.UpdateWeights": [[419, 1, 1, "", "register"]], "torchrl.trainers.algorithms": [[420, 0, 1, "", "PPOTrainer"], [421, 0, 1, "", "SACTrainer"]], "torchrl.trainers.algorithms.PPOTrainer": [[420, 1, 1, "", "load_from_file"]], "torchrl.trainers.algorithms.SACTrainer": [[421, 1, 1, "", "load_from_file"]], "torchrl.trainers.algorithms.configs.collectors": [[422, 4, 1, "", "AsyncDataCollectorConfig"], [423, 4, 1, "", "SyncDataCollectorConfig"]], "torchrl.trainers.algorithms.configs.common": [[424, 0, 1, "", "ConfigBase"]], "torchrl.trainers.algorithms.configs.data": [[425, 0, 1, "", "LazyMemmapStorageConfig"], [426, 0, 1, "", "LazyStackStorageConfig"], [427, 0, 1, "", "LazyTensorStorageConfig"], [428, 0, 1, "", "ListStorageConfig"], [429, 0, 1, "", "PrioritizedSamplerConfig"], [430, 0, 1, "", "RandomSamplerConfig"], [431, 0, 1, "", "ReplayBufferConfig"], [432, 0, 1, "", "RoundRobinWriterConfig"], [433, 0, 1, "", "SamplerWithoutReplacementConfig"], [434, 0, 1, "", "SliceSamplerConfig"], [435, 0, 1, "", "SliceSamplerWithoutReplacementConfig"], [436, 0, 1, "", "StorageEnsembleConfig"], [437, 0, 1, "", "StorageEnsembleWriterConfig"], [438, 0, 1, "", "TensorDictReplayBufferConfig"], [439, 0, 1, "", "TensorStorageConfig"]], "torchrl.trainers.algorithms.configs.envs": [[440, 0, 1, "", "BatchedEnvConfig"], [441, 0, 1, "", "EnvConfig"], [442, 0, 1, "", "TransformedEnvConfig"]], "torchrl.trainers.algorithms.configs.envs_libs": [[443, 0, 1, "", "BraxEnvConfig"], [444, 0, 1, "", "DMControlEnvConfig"], [445, 0, 1, "", "EnvLibsConfig"], [446, 0, 1, "", "GymEnvConfig"], [447, 0, 1, "", "HabitatEnvConfig"], [448, 0, 1, "", "IsaacGymEnvConfig"], [449, 0, 1, "", "JumanjiEnvConfig"], [450, 0, 1, "", "MOGymEnvConfig"], [451, 0, 1, "", "MeltingpotEnvConfig"], [452, 0, 1, "", "MultiThreadedEnvConfig"], [453, 0, 1, "", "OpenMLEnvConfig"], [454, 0, 1, "", "OpenSpielEnvConfig"], [455, 0, 1, "", "PettingZooEnvConfig"], [456, 0, 1, "", "RoboHiveEnvConfig"], [457, 0, 1, "", "SMACv2EnvConfig"], [458, 0, 1, "", "UnityMLAgentsEnvConfig"], [459, 0, 1, "", "VmasEnvConfig"]], "torchrl.trainers.algorithms.configs.logging": [[460, 0, 1, "", "CSVLoggerConfig"], [461, 0, 1, "", "LoggerConfig"], [462, 0, 1, "", "TensorboardLoggerConfig"], [463, 0, 1, "", "WandbLoggerConfig"]], "torchrl.trainers.algorithms.configs.modules": [[464, 0, 1, "", "ConvNetConfig"], [465, 0, 1, "", "MLPConfig"], [466, 0, 1, "", "ModelConfig"], [467, 0, 1, "", "NetworkConfig"], [468, 0, 1, "", "TanhNormalModelConfig"], [469, 0, 1, "", "TensorDictModuleConfig"], [470, 0, 1, "", "ValueModelConfig"]], "torchrl.trainers.algorithms.configs.objectives": [[471, 0, 1, "", "LossConfig"], [472, 0, 1, "", "PPOLossConfig"]], "torchrl.trainers.algorithms.configs.trainers": [[473, 0, 1, "", "PPOTrainerConfig"], [474, 0, 1, "", "TrainerConfig"]], "torchrl.trainers.algorithms.configs.transforms": [[475, 0, 1, "", "ActionDiscretizerConfig"], [476, 0, 1, "", "ActionMaskConfig"], [477, 0, 1, "", "AutoResetTransformConfig"], [478, 0, 1, "", "BatchSizeTransformConfig"], [479, 0, 1, "", "BinarizeRewardConfig"], [480, 0, 1, "", "BurnInTransformConfig"], [481, 0, 1, "", "CatFramesConfig"], [482, 0, 1, "", "CatTensorsConfig"], [483, 0, 1, "", "CenterCropConfig"], [484, 0, 1, "", "ClipTransformConfig"], [485, 0, 1, "", "ComposeConfig"], [486, 0, 1, "", "ConditionalPolicySwitchConfig"], [487, 0, 1, "", "ConditionalSkipConfig"], [488, 0, 1, "", "CropConfig"], [489, 0, 1, "", "DTypeCastTransformConfig"], [490, 0, 1, "", "DeviceCastTransformConfig"], [491, 0, 1, "", "DiscreteActionProjectionConfig"], [492, 0, 1, "", "DoubleToFloatConfig"], [493, 0, 1, "", "EndOfLifeTransformConfig"], [494, 0, 1, "", "ExcludeTransformConfig"], [495, 0, 1, "", "FiniteTensorDictCheckConfig"], [496, 0, 1, "", "FlattenObservationConfig"], [497, 0, 1, "", "FrameSkipTransformConfig"], [498, 0, 1, "", "GrayScaleConfig"], [499, 0, 1, "", "HashConfig"], [500, 0, 1, "", "InitTrackerConfig"], [501, 0, 1, "", "KLRewardTransformConfig"], [502, 0, 1, "", "LineariseRewardsConfig"], [503, 0, 1, "", "MultiActionConfig"], [504, 0, 1, "", "MultiStepTransformConfig"], [505, 0, 1, "", "NoopResetEnvConfig"], [506, 0, 1, "", "ObservationNormConfig"], [507, 0, 1, "", "PermuteTransformConfig"], [508, 0, 1, "", "PinMemoryTransformConfig"], [509, 0, 1, "", "R3MTransformConfig"], [510, 0, 1, "", "RandomCropTensorDictConfig"], [511, 0, 1, "", "RemoveEmptySpecsConfig"], [512, 0, 1, "", "RenameTransformConfig"], [513, 0, 1, "", "ResizeConfig"], [514, 0, 1, "", "Reward2GoTransformConfig"], [515, 0, 1, "", "RewardClippingConfig"], [516, 0, 1, "", "RewardScalingConfig"], [517, 0, 1, "", "RewardSumConfig"], [518, 0, 1, "", "SelectTransformConfig"], [519, 0, 1, "", "SignTransformConfig"], [520, 0, 1, "", "SqueezeTransformConfig"], [521, 0, 1, "", "StackConfig"], [522, 0, 1, "", "StepCounterConfig"], [523, 0, 1, "", "TargetReturnConfig"], [524, 0, 1, "", "TensorDictPrimerConfig"], [525, 0, 1, "", "TimeMaxPoolConfig"], [526, 0, 1, "", "TimerConfig"], [527, 0, 1, "", "ToTensorImageConfig"], [528, 0, 1, "", "TokenizerConfig"], [529, 0, 1, "", "TrajCounterConfig"], [530, 0, 1, "", "TransformConfig"], [531, 0, 1, "", "UnaryTransformConfig"], [532, 0, 1, "", "UnsqueezeTransformConfig"], [533, 0, 1, "", "VC1TransformConfig"], [534, 0, 1, "", "VIPRewardTransformConfig"], [535, 0, 1, "", "VIPTransformConfig"], [536, 0, 1, "", "VecGymEnvTransformConfig"], [537, 0, 1, "", "VecNormConfig"], [538, 0, 1, "", "VecNormV2Config"]], "torchrl.trainers.algorithms.configs.utils": [[539, 0, 1, "", "ASGDConfig"], [540, 0, 1, "", "AdadeltaConfig"], [541, 0, 1, "", "AdagradConfig"], [542, 0, 1, "", "AdamConfig"], [543, 0, 1, "", "AdamWConfig"], [544, 0, 1, "", "AdamaxConfig"], [545, 0, 1, "", "LBFGSConfig"], [546, 0, 1, "", "LionConfig"], [547, 0, 1, "", "NAdamConfig"], [548, 0, 1, "", "RAdamConfig"], [549, 0, 1, "", "RMSpropConfig"], [550, 0, 1, "", "RpropConfig"], [551, 0, 1, "", "SGDConfig"], [552, 0, 1, "", "SparseAdamConfig"]], "torchrl.trainers.helpers": [[553, 3, 1, "", "correct_for_frame_skip"], [554, 3, 1, "", "get_stats_random_rollout"], [555, 3, 1, "", "make_collector_offpolicy"], [556, 3, 1, "", "make_collector_onpolicy"], [557, 3, 1, "", "make_dqn_loss"], [558, 3, 1, "", "make_replay_buffer"], [559, 3, 1, "", "make_target_updater"], [560, 3, 1, "", "make_trainer"], [561, 3, 1, "", "parallel_env_constructor"], [562, 3, 1, "", "sync_async_collector"], [563, 3, 1, "", "sync_sync_collector"], [564, 3, 1, "", "transformed_env_constructor"]], "torchrl.weight_update": [[565, 0, 1, "", "DistributedTransport"], [566, 0, 1, "", "DistributedWeightSyncScheme"], [567, 0, 1, "", "MPTransport"], [568, 0, 1, "", "MultiProcessWeightSyncScheme"], [569, 0, 1, "", "NoWeightSyncScheme"], [570, 0, 1, "", "RPCTransport"], [571, 0, 1, "", "RPCWeightSyncScheme"], [572, 0, 1, "", "RayModuleTransformScheme"], [573, 0, 1, "", "RayTransport"], [574, 0, 1, "", "RayWeightSyncScheme"], [575, 0, 1, "", "SharedMemTransport"], [576, 0, 1, "", "SharedMemWeightSyncScheme"], [577, 0, 1, "", "TransportBackend"], [578, 0, 1, "", "WeightStrategy"], [579, 0, 1, "", "WeightSyncScheme"]], "torchrl.weight_update.DistributedTransport": [[565, 1, 1, "", "receive_initial_weights"], [565, 1, 1, "", "receive_weights"], [565, 1, 1, "", "send_initial_weights"], [565, 1, 1, "", "send_weights"], [565, 1, 1, "", "send_weights_async"], [565, 1, 1, "", "setup_connection_and_weights_on_receiver"], [565, 1, 1, "", "setup_connection_and_weights_on_sender"], [565, 1, 1, "", "wait_ack"]], "torchrl.weight_update.DistributedWeightSyncScheme": [[566, 1, 1, "", "apply_weights"], [566, 1, 1, "", "connect"], [566, 2, 1, "", "context"], [566, 1, 1, "", "create_transport"], [566, 1, 1, "", "init_on_receiver"], [566, 1, 1, "", "init_on_sender"], [566, 2, 1, "", "model"], [566, 2, 1, "", "model_id"], [566, 1, 1, "", "prepare_weights"], [566, 1, 1, "", "receive"], [566, 2, 1, "", "receiver_transport"], [566, 1, 1, "", "send"], [566, 2, 1, "", "sender_transports"], [566, 2, 1, "", "shared_transport"], [566, 1, 1, "", "shutdown"], [566, 2, 1, "", "weights"], [566, 2, 1, "", "worker_idx"]], "torchrl.weight_update.MPTransport": [[567, 1, 1, "", "receive_weights"], [567, 1, 1, "", "send_weights_async"], [567, 1, 1, "", "setup_connection_and_weights_on_receiver"], [567, 1, 1, "", "setup_connection_and_weights_on_sender"]], "torchrl.weight_update.MultiProcessWeightSyncScheme": [[568, 1, 1, "", "apply_weights"], [568, 1, 1, "", "connect"], [568, 2, 1, "", "context"], [568, 1, 1, "", "create_transport"], [568, 1, 1, "", "init_on_receiver"], [568, 1, 1, "", "init_on_sender"], [568, 2, 1, "", "model"], [568, 2, 1, "", "model_id"], [568, 1, 1, "", "prepare_weights"], [568, 1, 1, "", "receive"], [568, 2, 1, "", "receiver_transport"], [568, 1, 1, "", "send"], [568, 2, 1, "", "sender_transports"], [568, 2, 1, "", "shared_transport"], [568, 1, 1, "", "shutdown"], [568, 2, 1, "", "weights"], [568, 2, 1, "", "worker_idx"]], "torchrl.weight_update.NoWeightSyncScheme": [[569, 1, 1, "", "apply_weights"], [569, 1, 1, "", "connect"], [569, 2, 1, "", "context"], [569, 1, 1, "", "create_transport"], [569, 1, 1, "", "init_on_receiver"], [569, 1, 1, "", "init_on_sender"], [569, 2, 1, "", "model"], [569, 2, 1, "", "model_id"], [569, 1, 1, "", "prepare_weights"], [569, 1, 1, "", "receive"], [569, 2, 1, "", "receiver_transport"], [569, 1, 1, "", "send"], [569, 2, 1, "", "sender_transports"], [569, 2, 1, "", "shared_transport"], [569, 1, 1, "", "shutdown"], [569, 2, 1, "", "weights"], [569, 2, 1, "", "worker_idx"]], "torchrl.weight_update.RPCTransport": [[570, 1, 1, "", "receive_weights"], [570, 1, 1, "", "send_weights"], [570, 1, 1, "", "send_weights_async"], [570, 1, 1, "", "setup_connection_and_weights_on_receiver"], [570, 1, 1, "", "setup_connection_and_weights_on_sender"], [570, 1, 1, "", "wait_ack"]], "torchrl.weight_update.RPCWeightSyncScheme": [[571, 1, 1, "", "apply_weights"], [571, 1, 1, "", "connect"], [571, 2, 1, "", "context"], [571, 1, 1, "", "create_transport"], [571, 1, 1, "", "init_on_receiver"], [571, 1, 1, "", "init_on_sender"], [571, 2, 1, "", "model"], [571, 2, 1, "", "model_id"], [571, 1, 1, "", "prepare_weights"], [571, 1, 1, "", "receive"], [571, 2, 1, "", "receiver_transport"], [571, 1, 1, "", "send"], [571, 2, 1, "", "sender_transports"], [571, 2, 1, "", "shared_transport"], [571, 1, 1, "", "shutdown"], [571, 2, 1, "", "weights"], [571, 2, 1, "", "worker_idx"]], "torchrl.weight_update.RayModuleTransformScheme": [[572, 1, 1, "", "apply_weights"], [572, 1, 1, "", "connect"], [572, 2, 1, "", "connection_info_name"], [572, 2, 1, "", "context"], [572, 1, 1, "", "create_transport"], [572, 1, 1, "", "init_on_receiver"], [572, 1, 1, "", "init_on_sender"], [572, 2, 1, "", "model"], [572, 2, 1, "", "model_id"], [572, 1, 1, "", "prepare_weights"], [572, 1, 1, "", "receive"], [572, 2, 1, "", "receiver_transport"], [572, 1, 1, "", "send"], [572, 2, 1, "", "sender_transports"], [572, 2, 1, "", "shared_transport"], [572, 1, 1, "", "shutdown"], [572, 2, 1, "", "weights"], [572, 2, 1, "", "worker_idx"]], "torchrl.weight_update.RayTransport": [[573, 1, 1, "", "receive_weights"], [573, 1, 1, "", "send_weights"], [573, 1, 1, "", "send_weights_async"], [573, 1, 1, "", "set_model"], [573, 1, 1, "", "setup_connection_and_weights_on_receiver"], [573, 1, 1, "", "setup_connection_and_weights_on_sender"], [573, 1, 1, "", "wait_ack"]], "torchrl.weight_update.RayWeightSyncScheme": [[574, 1, 1, "", "apply_weights"], [574, 1, 1, "", "connect"], [574, 2, 1, "", "connection_info_name"], [574, 2, 1, "", "context"], [574, 1, 1, "", "create_transport"], [574, 1, 1, "", "init_on_receiver"], [574, 1, 1, "", "init_on_sender"], [574, 2, 1, "", "model"], [574, 2, 1, "", "model_id"], [574, 1, 1, "", "prepare_weights"], [574, 1, 1, "", "receive"], [574, 2, 1, "", "receiver_transport"], [574, 1, 1, "", "send"], [574, 2, 1, "", "sender_transports"], [574, 2, 1, "", "shared_transport"], [574, 1, 1, "", "shutdown"], [574, 2, 1, "", "weights"], [574, 2, 1, "", "worker_idx"]], "torchrl.weight_update.SharedMemTransport": [[575, 1, 1, "", "receive_weights"], [575, 1, 1, "", "register_weights"], [575, 1, 1, "", "send_ack"], [575, 1, 1, "", "send_weights"], [575, 1, 1, "", "setup_connection_and_weights_on_receiver"], [575, 1, 1, "", "setup_connection_and_weights_on_sender"], [575, 2, 1, "", "unique_weights"]], "torchrl.weight_update.SharedMemWeightSyncScheme": [[576, 1, 1, "", "apply_weights"], [576, 1, 1, "", "connect"], [576, 2, 1, "", "context"], [576, 1, 1, "", "create_transport"], [576, 1, 1, "", "init_on_receiver"], [576, 1, 1, "", "init_on_sender"], [576, 2, 1, "", "model"], [576, 2, 1, "", "model_id"], [576, 1, 1, "", "prepare_weights"], [576, 1, 1, "", "receive"], [576, 2, 1, "", "receiver_transport"], [576, 1, 1, "", "send"], [576, 2, 1, "", "sender_transports"], [576, 2, 1, "", "shared_transport"], [576, 1, 1, "", "shutdown"], [576, 2, 1, "", "weights"], [576, 2, 1, "", "worker_idx"]], "torchrl.weight_update.TransportBackend": [[577, 1, 1, "", "receive_weights"], [577, 1, 1, "", "send_weights"], [577, 1, 1, "", "setup_connection_and_weights_on_receiver"], [577, 1, 1, "", "setup_connection_and_weights_on_sender"]], "torchrl.weight_update.WeightStrategy": [[578, 1, 1, "", "apply_weights"], [578, 1, 1, "", "extract_weights"]], "torchrl.weight_update.WeightSyncScheme": [[579, 1, 1, "", "apply_weights"], [579, 1, 1, "", "connect"], [579, 2, 1, "", "context"], [579, 1, 1, "", "create_transport"], [579, 1, 1, "", "init_on_receiver"], [579, 1, 1, "", "init_on_sender"], [579, 2, 1, "", "model"], [579, 2, 1, "", "model_id"], [579, 1, 1, "", "prepare_weights"], [579, 1, 1, "", "receive"], [579, 2, 1, "", "receiver_transport"], [579, 1, 1, "", "send"], [579, 2, 1, "", "sender_transports"], [579, 2, 1, "", "shared_transport"], [579, 1, 1, "", "shutdown"], [579, 2, 1, "", "weights"], [579, 2, 1, "", "worker_idx"]], "torchrl.weight_update.llm": [[580, 0, 1, "", "VLLMCollectiveTransport"], [581, 0, 1, "", "VLLMDoubleBufferSyncScheme"], [582, 0, 1, "", "VLLMDoubleBufferTransport"], [583, 0, 1, "", "VLLMDoubleBufferWeightReceiver"], [584, 0, 1, "", "VLLMDoubleBufferWeightSender"], [585, 0, 1, "", "VLLMWeightReceiver"], [586, 0, 1, "", "VLLMWeightSender"], [587, 0, 1, "", "VLLMWeightSyncScheme"], [588, 0, 1, "", "get_model_metadata"]], "torchrl.weight_update.llm.VLLMCollectiveTransport": [[580, 1, 1, "", "check_connection"], [580, 1, 1, "", "init_all_workers_group"], [580, 1, 1, "", "receive_weights"], [580, 1, 1, "", "send_weights"]], "torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme": [[581, 1, 1, "", "apply_weights"], [581, 1, 1, "", "connect"], [581, 2, 1, "", "context"], [581, 1, 1, "", "create_receiver"], [581, 1, 1, "", "create_sender"], [581, 1, 1, "", "create_transport"], [581, 1, 1, "", "init_on_receiver"], [581, 1, 1, "", "init_on_sender"], [581, 2, 1, "", "model"], [581, 2, 1, "", "model_id"], [581, 1, 1, "", "prepare_weights"], [581, 1, 1, "", "receive"], [581, 2, 1, "", "receiver_transport"], [581, 1, 1, "", "send"], [581, 2, 1, "", "sender_transports"], [581, 2, 1, "", "shared_transport"], [581, 1, 1, "", "shutdown"], [581, 2, 1, "", "weights"], [581, 2, 1, "", "worker_idx"]], "torchrl.weight_update.llm.VLLMDoubleBufferTransport": [[582, 1, 1, "", "check_connection"], [582, 1, 1, "", "receive_weights"], [582, 1, 1, "", "send_weights"]], "torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver": [[583, 1, 1, "", "apply_weights"], [583, 1, 1, "", "poll_and_apply"]], "torchrl.weight_update.llm.VLLMDoubleBufferWeightSender": [[584, 1, 1, "", "register_model"], [584, 1, 1, "", "update_weights"]], "torchrl.weight_update.llm.VLLMWeightReceiver": [[585, 1, 1, "", "apply_weights"], [585, 1, 1, "", "init_all_workers_group"], [585, 1, 1, "", "poll_and_apply"]], "torchrl.weight_update.llm.VLLMWeightSender": [[586, 1, 1, "", "init_all_workers_group"], [586, 1, 1, "", "register_model"], [586, 1, 1, "", "update_weights"]], "torchrl.weight_update.llm.VLLMWeightSyncScheme": [[587, 1, 1, "", "apply_weights"], [587, 1, 1, "", "connect"], [587, 2, 1, "", "context"], [587, 1, 1, "", "create_receiver"], [587, 1, 1, "", "create_sender"], [587, 1, 1, "", "create_transport"], [587, 1, 1, "", "init_on_receiver"], [587, 1, 1, "", "init_on_sender"], [587, 2, 1, "", "model"], [587, 2, 1, "", "model_id"], [587, 1, 1, "", "prepare_weights"], [587, 1, 1, "", "receive"], [587, 2, 1, "", "receiver_transport"], [587, 1, 1, "", "send"], [587, 2, 1, "", "sender_transports"], [587, 2, 1, "", "shared_transport"], [587, 1, 1, "", "shutdown"], [587, 2, 1, "", "weights"], [587, 2, 1, "", "worker_idx"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:property", "3": "py:function", "4": "py:attribute"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "property", "Python property"], "3": ["py", "function", "Python function"], "4": ["py", "attribute", "Python attribute"]}, "titleterms": {"torchrl": [0, 1, 7, 10, 16, 17, 25, 28, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 599, 606, 614, 618, 620, 621, 622, 624, 626, 632, 633, 635, 636, 637, 641, 642], "instal": [0, 25, 26, 632, 641], "get": [0, 7, 613, 625, 626, 627, 628, 629, 630], "start": [0, 7, 613, 625, 626, 627, 628, 629, 630, 632], "tutori": [0, 622, 635, 636], "basic": [0, 2, 7, 613, 615, 632, 639], "intermedi": [0, 27], "advanc": [0, 613], "refer": [0, 590, 613], "knowledg": [0, 591], "base": [0, 7, 17, 26, 591, 592, 604, 612, 624], "indic": 0, "tabl": 0, "collector": [1, 2, 3, 4, 5, 6, 34, 422, 423, 593, 620, 621, 622, 623, 628, 630, 635, 636, 641], "packag": [1, 10, 16, 599, 606, 614, 618], "multicollector": [1, 5, 36], "api": [1, 17, 590, 613], "kei": [1, 10, 16, 21, 592, 599, 606, 613, 614], "featur": [1, 10, 16, 599, 606, 613, 614], "quick": [1, 7, 10, 16, 592, 599, 606, 614], "exampl": [1, 6, 7, 10, 16, 22, 30, 592, 599, 606, 613, 614, 621, 633, 639], "legaci": [1, 3, 6, 592], "name": [1, 3], "document": [1, 10, 16, 28, 592, 599, 606, 614], "section": [1, 10, 16, 592, 599, 606, 614], "batch": [2, 17, 22, 620, 637, 639], "size": [2, 17, 620, 639], "polici": [2, 23, 592, 611, 620, 622, 623, 624, 626, 630, 634, 635, 636, 637], "copi": 2, "distribut": [3, 602], "replai": [4, 7, 12, 21, 620, 621, 622, 623, 628, 630, 635, 636, 639, 641], "buffer": [4, 7, 12, 21, 620, 621, 622, 623, 628, 630, 635, 636, 639, 641], "interoper": 4, "helper": [4, 17, 603, 605, 632], "function": [4, 23, 592, 621, 622, 627, 635, 636, 641], "singl": [5, 23], "node": 5, "data": [5, 7, 10, 12, 23, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 594, 596, 620, 621, 622, 628, 630, 635, 636, 641], "us": [5, 6, 21, 23, 25, 28, 623, 638, 639, 641], "run": [5, 7, 624, 625, 642], "asynchron": 5, "weight": [6, 592, 593], "synchron": [6, 593], "lifecycl": 6, "phase": 6, "1": [6, 26, 632, 633], "initi": 6, "No": 6, "commun": 6, "2": [6, 26, 632, 633], "connect": 6, "rendez": 6, "vou": 6, "3": [6, 632, 633], "ongo": 6, "updat": [6, 592, 620], "scheme": [6, 593], "specif": [6, 17, 592, 615, 634], "behavior": 6, "sharedmemweightsyncschem": [6, 576], "multiprocessweightsyncschem": [6, 568], "distributedweightsyncschem": [6, 566], "rpcweightsyncschem": [6, 571], "rayweightsyncschem": [6, 574], "raymoduletransformschem": [6, 572], "background": 6, "thread": 6, "architectur": [6, 592], "usag": [6, 7, 613], "sync": [6, 641], "standalon": 6, "transport": 6, "interfac": [6, 592], "timeout": 6, "support": [6, 12], "avail": [6, 7, 18, 21], "configur": [7, 613, 632], "system": [7, 14], "simpl": [7, 624, 637], "categori": 7, "group": [7, 635], "more": [7, 639], "complex": [7, 639], "parallel": [7, 22, 620, 634, 642], "environ": [7, 17, 18, 19, 21, 22, 23, 25, 26, 592, 595, 620, 621, 622, 623, 625, 630, 632, 633, 634, 635, 636, 637, 641, 642], "transform": [7, 21, 271, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 592, 598, 620, 622, 625, 633, 635, 636, 637, 639, 641, 642], "option": [7, 26, 613], "complet": 7, "train": [7, 23, 27, 616, 620, 622, 623, 624, 627, 630, 635, 636, 637], "experi": [7, 620, 637], "hyperparamet": [7, 621, 622, 635, 636], "sweep": 7, "custom": [7, 17, 30, 613, 637, 639], "file": 7, "store": [7, 621, 639], "implement": [7, 23], "detail": [7, 22], "class": [7, 12, 17, 22, 594, 596, 602, 637, 641], "librari": [7, 18, 641], "model": [7, 23, 604, 620, 621, 623, 624, 627, 638, 641], "network": [7, 601, 620, 621, 622, 623, 626, 635, 636], "collect": [7, 621, 622, 628], "storag": [7, 12, 15, 110, 620, 628, 639], "optim": [7, 23, 620, 621, 627, 630], "log": [7, 460, 461, 462, 463, 629, 633], "creat": [7, 625], "best": [7, 613], "practic": [7, 613], "futur": 7, "extens": 7, "dataset": 11, "core": [12, 592], "compos": [12, 225], "type": 12, "choos": 12, "sampl": [12, 13, 639], "index": 12, "strategi": [13, 603], "writer": [13, 118], "tensorspec": [14, 74], "backend": 15, "perform": [15, 613, 632], "env": [16, 17, 440, 441, 442, 637, 641, 642], "spec": [17, 18, 21, 637, 642], "lock": [17, 22], "method": [17, 607, 609, 611, 612, 620], "nativ": 17, "domain": 17, "wrapper": [18, 592, 596, 626, 633], "auto": 18, "reset": [18, 22, 637, 642], "dynam": [18, 23, 639], "multi": [19, 634, 635, 636], "agent": [19, 23, 635, 636], "record": [20, 617, 620, 629], "video": [20, 30, 629], "forward": [21, 23, 620], "invers": 21, "understand": 21, "tensor": [21, 639], "expos": 21, "outsid": 21, "world": [21, 604], "design": [21, 592, 630], "your": [21, 23, 25, 620, 624, 630, 637], "own": [21, 630], "tip": 21, "subclass": 21, "clone": [21, 26], "mask": [21, 328], "action": [21, 23, 623, 637], "vector": [22, 641], "partial": 22, "step": [22, 620, 622, 625, 628, 632, 635, 636, 639, 642], "async": [22, 641], "thing": [23, 620, 637], "consid": 23, "when": [23, 26], "debug": 23, "rl": [23, 28, 604, 609, 625, 627, 633, 641], "gener": [23, 30], "have": 23, "you": 23, "valid": [23, 633], "algorithm": [23, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 615], "few": 23, "small": 23, "toi": 23, "problem": 23, "known": 23, "return": 23, "e": 23, "g": 23, "gridworld": 23, "mountaincar": 23, "visual": 23, "Be": 23, "veri": 23, "care": 23, "ani": 23, "augment": 23, "doe": 23, "entropi": 23, "converg": 23, "too": [23, 27], "quickli": 23, "slowli": 23, "chang": [23, 641], "drastic": 23, "reward": [23, 592, 594], "beyond": 23, "go": 23, "up": [23, 25], "Is": 23, "favor": 23, "compon": [23, 592, 608], "i": 23, "veloc": 23, "vs": 23, "l2": 23, "magnitud": 23, "task": [23, 592, 634], "horizon": 23, "extrem": 23, "long": 23, "ar": 23, "normal": [23, 620, 621, 622], "standard": 23, "explor": [23, 603, 620, 621, 626, 633], "valu": [23, 600, 601, 608, 612, 620, 622, 623, 626], "loss": [23, 610, 620, 621, 622, 623, 630, 635, 636], "earli": 23, "roughli": 23, "uniformli": 23, "random": [23, 635, 636], "intrins": 23, "decai": 23, "learn": [23, 622, 635, 636], "progress": 23, "singleton": 23, "episod": 23, "remain": 23, "constant": [23, 621], "increas": 23, "an": [23, 622, 623, 625, 637], "can": 23, "low": 23, "also": [23, 613], "offlin": [23, 609], "observ": [23, 620], "space": 23, "effect": [23, 637], "dramat": 23, "dure": [23, 26], "high": 23, "dimension": 23, "work": [24, 25, 26, 613, 624], "gym": [24, 641, 642], "what": 24, "openai": 24, "version": [24, 26, 29, 592], "habitat": 25, "lab": 25, "set": [25, 30], "from": [25, 26], "pip": [25, 26], "common": [25, 26, 27, 424, 608], "issu": [25, 26, 29], "mujoco": 26, "prerequisit": [26, 620], "render": [26, 30, 630, 635, 636, 642], "all": 26, "new": 26, "bindindg": 26, "old": 26, "bind": 26, "py": 26, "repo": [26, 28], "import": [26, 620, 633], "pytorch": [27, 28, 29, 624], "error": [27, 633], "solut": 27, "gradient": [27, 611], "relat": 27, "newcom": 27, "my": 27, "slow": 27, "bug": 27, "resourc": 28, "paper": 28, "functorch": 28, "blog": 28, "websit": 28, "educ": 28, "forum": 28, "how": [29, 613], "reproduc": [29, 637], "workaround": 29, "customis": 30, "tweak": 30, "principl": 30, "auto_unwrap_transformed_env": 31, "asynccollector": 32, "basecollector": 33, "multiasynccollector": 35, "multiprocessedweightupdat": 37, "multisynccollector": 38, "rayweightupdat": 39, "vanillaweightupdat": 40, "weightupdaterbas": 41, "distributedcollector": 42, "distributeddatacollector": 43, "distributedsynccollector": 44, "distributedsyncdatacollector": 45, "distributedweightupdat": 46, "rpccollector": 47, "rpcdatacollector": 48, "rpcweightupdat": 49, "raycollector": 50, "submitit_delayed_launch": 51, "llmcollector": 52, "rayllmcollector": 53, "vllmupdat": 54, "vllmupdaterv2": 55, "split_trajectori": 56, "binari": [57, 624], "bound": 58, "categor": 59, "composit": 60, "multicategor": 61, "multionehot": 62, "nontensor": 63, "onehot": 64, "prioritizedreplaybuff": 65, "rayreplaybuff": 66, "remotetensordictreplaybuff": 67, "replaybuff": 68, "replaybufferensembl": 69, "stack": [70, 262], "stackedcomposit": 71, "tensordictprioritizedreplaybuff": 72, "tensordictreplaybuff": 73, "unbound": 75, "unboundedcontinu": 76, "unboundeddiscret": 77, "ataridqnexperiencereplai": 78, "d4rlexperiencereplai": 79, "gendgrlexperiencereplai": 80, "minariexperiencereplai": 81, "openmlexperiencereplai": 82, "openxexperiencereplai": 83, "robosetexperiencereplai": 84, "vd4rlexperiencereplai": 85, "contentbas": 86, "histori": [87, 594, 633], "topkrewardselector": 88, "add_chat_templ": 89, "compressedliststorag": 90, "compressedliststoragecheckpoint": 91, "flatstoragecheckpoint": 92, "h5storagecheckpoint": 93, "immutabledatasetwrit": 94, "lazymemmapstorag": 95, "lazystackstorag": 96, "lazytensorstorag": 97, "liststorag": 98, "liststoragecheckpoint": 99, "nestedstoragecheckpoint": 100, "prioritizedsampl": 101, "prioritizedslicesampl": 102, "randomsampl": 103, "roundrobinwrit": 104, "sampler": 105, "samplerensembl": 106, "samplerwithoutreplac": 107, "slicesampl": 108, "slicesamplerwithoutreplac": 109, "storagecheckpointerbas": 111, "storageensembl": 112, "storageensemblecheckpoint": 113, "tensordictmaxvaluewrit": 114, "tensordictroundrobinwrit": 115, "tensorstorag": 116, "tensorstoragecheckpoint": 117, "writerensembl": 119, "asyncenvpool": 120, "braxenv": 121, "braxwrapp": 122, "chessenv": 123, "dmcontrolenv": 124, "dmcontrolwrapp": 125, "envbas": [126, 637], "envcreat": 127, "envmetadata": 128, "gymenv": 129, "gymlikeenv": 130, "gymwrapp": 131, "habitatenv": 132, "isaacgymenv": 133, "isaacgymwrapp": 134, "isaaclabwrapp": 135, "jumanjienv": 136, "jumanjiwrapp": 137, "llmhashingenv": [138, 179], "mogymenv": 139, "mogymwrapp": 140, "marlgroupmaptyp": 141, "meltingpotenv": 142, "meltingpotwrapp": 143, "modelbasedenvbas": 144, "multithreadedenv": 145, "multithreadedenvwrapp": 146, "openmlenv": 147, "openspielenv": 148, "openspielwrapp": 149, "parallelenv": 150, "pendulumenv": 151, "pettingzooenv": 152, "pettingzoowrapp": 153, "processorasyncenvpool": 154, "robohiveenv": 155, "smacv2env": 156, "smacv2wrapp": 157, "serialenv": 158, "threadingasyncenvpool": 159, "tictactoeenv": 160, "unitymlagentsenv": 161, "unitymlagentswrapp": 162, "vmasenv": 163, "vmaswrapp": 164, "check_env_spec": 165, "check_marl_group": 166, "exploration_typ": 167, "get_available_librari": 168, "gym_backend": 169, "chatenv": [170, 592], "datasetchatenv": 171, "gsm8kenv": 172, "gsm8kpreparequest": 173, "gsm8krewardpars": 174, "ifevalenv": 175, "ifevalscoredata": 176, "ifevalscor": 177, "llmenv": 178, "mlgymwrapp": 180, "make_gsm8k_env": 181, "make_mlgym": 182, "addthinkingprompt": 183, "browsertransform": 184, "dataloadingprim": 185, "executetoolsinord": 186, "jsoncallpars": 187, "klcomput": 188, "klrewardtransform": [189, 241], "mcptooltransform": 190, "policyvers": 191, "pythonexecutorservic": 192, "pythoninterpret": 193, "raydataloadingprim": 194, "retrievekl": 195, "retrievelogprob": 196, "simpletooltransform": 197, "templatetransform": 198, "token": [199, 269, 331], "toolcal": 200, "toolregistri": 201, "toolservic": 202, "xmlblockpars": 203, "as_nested_tensor": 204, "as_padded_tensor": 205, "make_composite_from_td": 206, "dreamerdecod": 207, "dreamerenv": 208, "register_gym_spec_convers": 209, "set_exploration_typ": 210, "set_gym_backend": 211, "step_mdp": 212, "terminated_or_trunc": 213, "actiondiscret": 214, "actionmask": 215, "autoresetenv": 216, "autoresettransform": 217, "batchsizetransform": 218, "binarizereward": 219, "burnintransform": 220, "catfram": [221, 639], "cattensor": 222, "centercrop": 223, "cliptransform": 224, "conditionalpolicyswitch": 226, "conditionalskip": 227, "crop": 228, "dtypecasttransform": 229, "devicecasttransform": 230, "discreteactionproject": 231, "doubletofloat": 232, "endoflifetransform": 233, "excludetransform": 234, "finitetensordictcheck": 235, "flattenobserv": 236, "frameskiptransform": 237, "grayscal": 238, "hash": 239, "inittrack": 240, "linearisereward": 242, "moduletransform": 243, "multiact": 244, "noopresetenv": 245, "observationnorm": 246, "observationtransform": 247, "permutetransform": 248, "pinmemorytransform": 249, "r3mtransform": 250, "randomcroptensordict": 251, "removeemptyspec": 252, "renametransform": 253, "resiz": 254, "reward2gotransform": 255, "rewardclip": 256, "rewardsc": 257, "rewardsum": 258, "selecttransform": 259, "signtransform": 260, "squeezetransform": 261, "stepcount": 263, "targetreturn": 264, "tensordictprim": 265, "timemaxpool": 266, "timer": 267, "totensorimag": 268, "trajcount": 270, "transformedenv": 272, "unarytransform": 273, "unsqueezetransform": 274, "vc1transform": 275, "viprewardtransform": 276, "viptransform": 277, "vecgymenvtransform": 278, "vecnorm": [279, 642], "vecnormv2": 280, "gsdenois": 281, "implement_for": 282, "actorcriticoper": 283, "actorcriticwrapp": 284, "actorvalueoper": 285, "additivegaussianmodul": 286, "consistentdropoutmodul": 287, "convnet": 288, "dtactor": 289, "ddpgcnnactor": 290, "ddpgcnnqnet": 291, "ddpgmlpactor": 292, "ddpgmlpqnet": 293, "decisiontransform": 294, "delta": 295, "distributionaldqnnet": 296, "distributionalqvalueactor": 297, "distributionalqvaluemodul": 298, "dreameractor": 299, "duelingcnndqnet": 300, "egreedymodul": 301, "grumodul": 302, "independentnorm": 303, "lstmmodul": 304, "mlp": [305, 623], "maskedcategor": 306, "normalparamextractor": 307, "obsdecod": 308, "obsencod": 309, "onehotcategor": 310, "onlinedtactor": 311, "ornsteinuhlenbeckprocessmodul": 312, "qvalueactor": 313, "qvaluemodul": 314, "rssmposterior": 315, "rssmprior": 316, "rssmrollout": 317, "reparamgradientstrategi": 318, "tanhdelta": 319, "tanhnorm": 320, "truncatednorm": 321, "valueoper": 322, "worldmodelwrapp": 323, "asyncvllm": 324, "chathistori": 325, "llmwrapperbas": 326, "logprob": 327, "remotetransformerswrapp": 329, "text": [330, 633], "transformerswrapp": 332, "make_async_vllm_engin": 333, "make_vllm_work": 334, "stateless_init_process_group": 335, "stateless_init_process_group_async": 336, "vllmwrapper": 337, "squashdim": 338, "set_exploration_modules_spec_from_env": 339, "actor": [340, 600, 607, 620, 626], "multistepactorwrapp": 341, "probabilisticactor": 342, "randompolici": 343, "safemodul": [344, 600], "safeprobabilisticmodul": 345, "safeprobabilistictensordictsequenti": 346, "safesequenti": 347, "tanhmodul": 348, "a2closs": 349, "cqlloss": 350, "clipppoloss": 351, "crossqloss": 352, "ddpgloss": 353, "dqnloss": 354, "dtloss": 355, "discretecqlloss": 356, "discreteiqlloss": 357, "discretesacloss": 358, "distributionaldqnloss": 359, "dreameractorloss": 360, "dreamermodelloss": 361, "dreamervalueloss": 362, "gailloss": 363, "iqlloss": 364, "klpenppoloss": 365, "lossmodul": [366, 620, 627], "onlinedtloss": 367, "ppoloss": 368, "redqloss": 369, "reinforceloss": 370, "sacloss": 371, "td3bcloss": 372, "td3loss": 373, "valueestim": 374, "add_random_modul": 375, "cispoloss": 376, "cispolossoutput": 377, "dapo": 378, "dapolossoutput": 379, "grpoloss": 380, "grpolossoutput": 381, "llmlossoutput": 382, "mcadvantag": 383, "sftloss": 384, "sftlossoutput": 385, "gae": 386, "td0estim": 387, "td1estim": 388, "tdlambdaestim": 389, "valueestimatorbas": 390, "pixelrendertransform": 391, "tensordictrecord": 392, "videorecord": 393, "logger": [394, 617, 629, 630], "csvlogger": 395, "generate_exp_nam": 396, "get_logg": 397, "mlflowlogg": 398, "tensorboardlogg": 399, "trackiologg": 400, "wandblogg": 401, "rayservic": 402, "servicebas": 403, "get_servic": 404, "set_auto_unwrap_transformed_env": 405, "batchsubsampl": 406, "clearcudacach": 407, "countframeslog": 408, "logscalar": 409, "logvalidationreward": 410, "optimizerhook": 411, "replaybuffertrain": 412, "rewardnorm": 413, "selectkei": 414, "targetnetupdaterhook": 415, "trainer": [416, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 614, 615, 621], "trainerhookbas": 417, "utdrhook": 418, "updateweight": 419, "ppotrain": 420, "sactrain": 421, "config": [422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 641], "asyncdatacollectorconfig": 422, "syncdatacollectorconfig": 423, "configbas": 424, "lazymemmapstorageconfig": 425, "lazystackstorageconfig": 426, "lazytensorstorageconfig": 427, "liststorageconfig": 428, "prioritizedsamplerconfig": 429, "randomsamplerconfig": 430, "replaybufferconfig": 431, "roundrobinwriterconfig": 432, "samplerwithoutreplacementconfig": 433, "slicesamplerconfig": 434, "slicesamplerwithoutreplacementconfig": 435, "storageensembleconfig": 436, "storageensemblewriterconfig": 437, "tensordictreplaybufferconfig": 438, "tensorstorageconfig": 439, "batchedenvconfig": 440, "envconfig": 441, "transformedenvconfig": 442, "envs_lib": [443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459], "braxenvconfig": 443, "dmcontrolenvconfig": 444, "envlibsconfig": 445, "gymenvconfig": 446, "habitatenvconfig": 447, "isaacgymenvconfig": 448, "jumanjienvconfig": 449, "mogymenvconfig": 450, "meltingpotenvconfig": 451, "multithreadedenvconfig": 452, "openmlenvconfig": 453, "openspielenvconfig": 454, "pettingzooenvconfig": 455, "robohiveenvconfig": 456, "smacv2envconfig": 457, "unitymlagentsenvconfig": 458, "vmasenvconfig": 459, "csvloggerconfig": 460, "loggerconfig": 461, "tensorboardloggerconfig": 462, "wandbloggerconfig": 463, "modul": [464, 465, 466, 467, 468, 469, 470, 599, 600, 610, 620, 623, 624, 626, 630, 641], "convnetconfig": 464, "mlpconfig": 465, "modelconfig": 466, "networkconfig": 467, "tanhnormalmodelconfig": 468, "tensordictmoduleconfig": 469, "valuemodelconfig": 470, "object": [471, 472, 592, 597, 606, 620, 627, 641], "lossconfig": 471, "ppolossconfig": 472, "ppotrainerconfig": 473, "trainerconfig": 474, "actiondiscretizerconfig": 475, "actionmaskconfig": 476, "autoresettransformconfig": 477, "batchsizetransformconfig": 478, "binarizerewardconfig": 479, "burnintransformconfig": 480, "catframesconfig": 481, "cattensorsconfig": 482, "centercropconfig": 483, "cliptransformconfig": 484, "composeconfig": 485, "conditionalpolicyswitchconfig": 486, "conditionalskipconfig": 487, "cropconfig": 488, "dtypecasttransformconfig": 489, "devicecasttransformconfig": 490, "discreteactionprojectionconfig": 491, "doubletofloatconfig": 492, "endoflifetransformconfig": 493, "excludetransformconfig": 494, "finitetensordictcheckconfig": 495, "flattenobservationconfig": 496, "frameskiptransformconfig": 497, "grayscaleconfig": 498, "hashconfig": 499, "inittrackerconfig": 500, "klrewardtransformconfig": 501, "lineariserewardsconfig": 502, "multiactionconfig": 503, "multisteptransformconfig": 504, "noopresetenvconfig": 505, "observationnormconfig": 506, "permutetransformconfig": 507, "pinmemorytransformconfig": 508, "r3mtransformconfig": 509, "randomcroptensordictconfig": 510, "removeemptyspecsconfig": 511, "renametransformconfig": 512, "resizeconfig": 513, "reward2gotransformconfig": 514, "rewardclippingconfig": 515, "rewardscalingconfig": 516, "rewardsumconfig": 517, "selecttransformconfig": 518, "signtransformconfig": 519, "squeezetransformconfig": 520, "stackconfig": 521, "stepcounterconfig": 522, "targetreturnconfig": 523, "tensordictprimerconfig": 524, "timemaxpoolconfig": 525, "timerconfig": 526, "totensorimageconfig": 527, "tokenizerconfig": 528, "trajcounterconfig": 529, "transformconfig": 530, "unarytransformconfig": 531, "unsqueezetransformconfig": 532, "vc1transformconfig": 533, "viprewardtransformconfig": 534, "viptransformconfig": 535, "vecgymenvtransformconfig": 536, "vecnormconfig": 537, "vecnormv2config": 538, "util": [539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 596, 605, 615, 617, 635], "asgdconfig": 539, "adadeltaconfig": 540, "adagradconfig": 541, "adamconfig": 542, "adamwconfig": 543, "adamaxconfig": 544, "lbfgsconfig": 545, "lionconfig": 546, "nadamconfig": 547, "radamconfig": 548, "rmspropconfig": 549, "rpropconfig": 550, "sgdconfig": 551, "sparseadamconfig": 552, "correct_for_frame_skip": 553, "get_stats_random_rollout": 554, "make_collector_offpolici": 555, "make_collector_onpolici": 556, "make_dqn_loss": 557, "make_replay_buff": 558, "make_target_updat": 559, "make_train": 560, "parallel_env_constructor": 561, "sync_async_collector": 562, "sync_sync_collector": 563, "transformed_env_constructor": 564, "distributedtransport": 565, "mptransport": 567, "noweightsyncschem": 569, "rpctransport": 570, "raytransport": 573, "sharedmemtransport": 575, "transportbackend": 577, "weightstrategi": 578, "weightsyncschem": 579, "vllmcollectivetransport": 580, "vllmdoublebuffersyncschem": 581, "vllmdoublebuffertransport": 582, "vllmdoublebufferweightreceiv": 583, "vllmdoublebufferweightsend": 584, "vllmweightreceiv": 585, "vllmweightsend": 586, "vllmweightsyncschem": 587, "get_model_metadata": 588, "readm": [589, 631], "tuto": [589, 631], "contribut": [591, 641], "content": 591, "llm": [592, 593, 595, 596, 597, 598, 632, 633], "track": 592, "deprec": 592, "integr": [592, 633, 639], "structur": [594, 596, 633, 639], "topk": 594, "selector": 594, "grpo": 597, "sft": 597, "tensordictmodul": [600, 624, 626, 641], "probabilist": [600, 626], "q": [600, 621, 623, 626], "critic": [601, 607, 635, 636], "estim": [608, 620], "other": [610, 639], "servic": 613, "registri": 613, "overview": [613, 620, 623], "registr": 613, "access": [613, 642], "cross": 613, "worker": 613, "visibl": 613, "namespac": 613, "isol": 613, "cleanup": 613, "python": 613, "executor": 613, "condit": 613, "pattern": 613, "It": 613, "consider": [613, 627], "multipl": 613, "see": 613, "hook": [615, 616, 621], "builder": 615, "_util": 618, "comput": [619, 621, 637, 640], "time": [619, 620, 640], "code": [620, 637], "ddpg": [620, 635], "setup": [620, 623, 632, 633], "The": 620, "__init__": 620, "put": 620, "togeth": [620, 637], "call": 620, "execut": [620, 632, 634, 637], "stat": 620, "build": [620, 621, 630, 632, 639], "evalu": 620, "construct": 620, "target": [620, 621, 627], "result": [620, 622, 632, 635, 636], "conclus": [620, 621, 622, 623, 624, 632, 633, 635, 636, 637, 639], "next": [620, 622, 625, 628, 635, 636, 639], "A": [621, 639], "dqn": [621, 623], "deep": 621, "paramet": [621, 622, 627], "regist": 621, "possibl": 621, "improv": 621, "reinforc": [622, 635, 636], "ppo": [622, 636], "defin": [622, 635, 636], "loop": [622, 623, 624, 630, 635, 636, 637], "recurr": [623, 624], "convolut": 623, "lstm": 623, "select": 623, "further": [623, 627], "read": 623, "export": 624, "introduct": [624, 641], "fast": 624, "recap": 624, "stochast": 624, "aotinductor": 624, "free": 624, "c": 624, "onnx": 624, "rollout": [624, 625, 634, 635, 636, 637, 642], "ted": 625, "s": [626, 627], "special": [626, 641], "output": 627, "first": 630, "tool": 632, "enabl": 632, "interact": 632, "4": [632, 633], "search": 632, "5": [632, 633], "extract": 632, "vllm": 633, "input": 633, "mode": 633, "probabl": 633, "onli": 633, "tensorclass": [633, 639], "6": 633, "handl": 633, "7": 633, "divers": 634, "competit": 635, "map": 635, "pendulum": 637, "write": 637, "_step": 637, "simul": 637, "_reset": 637, "metadata": 637, "_spec": 637, "shape": 637, "seed": [637, 642], "wrap": 637, "test": 637, "our": 637, "pretrain": 638, "vanilla": 639, "tensordict": [639, 641], "pytre": 639, "iter": 639, "over": 639, "fix": 639, "priorit": 639, "save": 639, "raw": 639, "imag": 639, "trajectori": 639, "sequenc": 641, "program": 641, "ensembl": 641, "meta": 641, "vmap": 641, "multiprocess": 641, "frame_skip": 642, "deepmind": 642, "control": 642, "devic": 642, "close": 642, "attribut": 642, "kwarg": 642}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 56}})
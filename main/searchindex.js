Search.setIndex({"docnames": ["index", "reference/collectors", "reference/collectors_basics", "reference/collectors_distributed", "reference/collectors_replay", "reference/collectors_single", "reference/collectors_weightsync", "reference/config", "reference/cudnn_persistent_rnn", "reference/cudnn_rnn_determinism", "reference/data", "reference/data_datasets", "reference/data_replaybuffers", "reference/data_samplers", "reference/data_specs", "reference/data_storage", "reference/envs", "reference/envs_api", "reference/envs_libraries", "reference/envs_multiagent", "reference/envs_recorders", "reference/envs_transforms", "reference/envs_vectorized", "reference/generated/knowledge_base/DEBUGGING_RL", "reference/generated/knowledge_base/GYM", "reference/generated/knowledge_base/HABITAT", "reference/generated/knowledge_base/MUJOCO_INSTALLATION", "reference/generated/knowledge_base/PRO-TIPS", "reference/generated/knowledge_base/RESOURCES", "reference/generated/knowledge_base/VERSIONING_ISSUES", "reference/generated/knowledge_base/VIDEO_CUSTOMISATION", "reference/generated/torchrl.auto_unwrap_transformed_env", "reference/generated/torchrl.collectors.AsyncCollector", "reference/generated/torchrl.collectors.BaseCollector", "reference/generated/torchrl.collectors.Collector", "reference/generated/torchrl.collectors.MultiAsyncCollector", "reference/generated/torchrl.collectors.MultiCollector", "reference/generated/torchrl.collectors.MultiProcessedWeightUpdater", "reference/generated/torchrl.collectors.MultiSyncCollector", "reference/generated/torchrl.collectors.RayWeightUpdater", "reference/generated/torchrl.collectors.VanillaWeightUpdater", "reference/generated/torchrl.collectors.WeightUpdaterBase", "reference/generated/torchrl.collectors.distributed.DistributedCollector", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedSyncCollector", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedWeightUpdater", "reference/generated/torchrl.collectors.distributed.RPCCollector", "reference/generated/torchrl.collectors.distributed.RPCDataCollector", "reference/generated/torchrl.collectors.distributed.RPCWeightUpdater", "reference/generated/torchrl.collectors.distributed.RayCollector", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher", "reference/generated/torchrl.collectors.llm.LLMCollector", "reference/generated/torchrl.collectors.llm.RayLLMCollector", "reference/generated/torchrl.collectors.llm.vLLMUpdater", "reference/generated/torchrl.collectors.llm.vLLMUpdaterV2", "reference/generated/torchrl.collectors.utils.split_trajectories", "reference/generated/torchrl.data.Binary", "reference/generated/torchrl.data.Bounded", "reference/generated/torchrl.data.Categorical", "reference/generated/torchrl.data.Composite", "reference/generated/torchrl.data.MultiCategorical", "reference/generated/torchrl.data.MultiOneHot", "reference/generated/torchrl.data.NonTensor", "reference/generated/torchrl.data.OneHot", "reference/generated/torchrl.data.PrioritizedReplayBuffer", "reference/generated/torchrl.data.RayReplayBuffer", "reference/generated/torchrl.data.RemoteTensorDictReplayBuffer", "reference/generated/torchrl.data.ReplayBuffer", "reference/generated/torchrl.data.ReplayBufferEnsemble", "reference/generated/torchrl.data.Stacked", "reference/generated/torchrl.data.StackedComposite", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer", "reference/generated/torchrl.data.TensorDictReplayBuffer", "reference/generated/torchrl.data.TensorSpec", "reference/generated/torchrl.data.Unbounded", "reference/generated/torchrl.data.UnboundedContinuous", "reference/generated/torchrl.data.UnboundedDiscrete", "reference/generated/torchrl.data.datasets.AtariDQNExperienceReplay", "reference/generated/torchrl.data.datasets.D4RLExperienceReplay", "reference/generated/torchrl.data.datasets.GenDGRLExperienceReplay", "reference/generated/torchrl.data.datasets.MinariExperienceReplay", "reference/generated/torchrl.data.datasets.OpenMLExperienceReplay", "reference/generated/torchrl.data.datasets.OpenXExperienceReplay", "reference/generated/torchrl.data.datasets.RobosetExperienceReplay", "reference/generated/torchrl.data.datasets.VD4RLExperienceReplay", "reference/generated/torchrl.data.llm.ContentBase", "reference/generated/torchrl.data.llm.History", "reference/generated/torchrl.data.llm.TopKRewardSelector", "reference/generated/torchrl.data.llm.add_chat_template", "reference/generated/torchrl.data.replay_buffers.CompressedListStorage", "reference/generated/torchrl.data.replay_buffers.CompressedListStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.FlatStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.H5StorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.ImmutableDatasetWriter", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage", "reference/generated/torchrl.data.replay_buffers.LazyStackStorage", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage", "reference/generated/torchrl.data.replay_buffers.ListStorage", "reference/generated/torchrl.data.replay_buffers.ListStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.NestedStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler", "reference/generated/torchrl.data.replay_buffers.PrioritizedSliceSampler", "reference/generated/torchrl.data.replay_buffers.RandomSampler", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.Sampler", "reference/generated/torchrl.data.replay_buffers.SamplerEnsemble", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.SliceSampler", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.Storage", "reference/generated/torchrl.data.replay_buffers.StorageCheckpointerBase", "reference/generated/torchrl.data.replay_buffers.StorageEnsemble", "reference/generated/torchrl.data.replay_buffers.StorageEnsembleCheckpointer", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.TensorStorage", "reference/generated/torchrl.data.replay_buffers.TensorStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.Writer", "reference/generated/torchrl.data.replay_buffers.WriterEnsemble", "reference/generated/torchrl.envs.AsyncEnvPool", "reference/generated/torchrl.envs.BraxEnv", "reference/generated/torchrl.envs.BraxWrapper", "reference/generated/torchrl.envs.ChessEnv", "reference/generated/torchrl.envs.DMControlEnv", "reference/generated/torchrl.envs.DMControlWrapper", "reference/generated/torchrl.envs.EnvBase", "reference/generated/torchrl.envs.EnvCreator", "reference/generated/torchrl.envs.EnvMetaData", "reference/generated/torchrl.envs.GymEnv", "reference/generated/torchrl.envs.GymLikeEnv", "reference/generated/torchrl.envs.GymWrapper", "reference/generated/torchrl.envs.HabitatEnv", "reference/generated/torchrl.envs.IsaacGymEnv", "reference/generated/torchrl.envs.IsaacGymWrapper", "reference/generated/torchrl.envs.IsaacLabWrapper", "reference/generated/torchrl.envs.JumanjiEnv", "reference/generated/torchrl.envs.JumanjiWrapper", "reference/generated/torchrl.envs.LLMHashingEnv", "reference/generated/torchrl.envs.MOGymEnv", "reference/generated/torchrl.envs.MOGymWrapper", "reference/generated/torchrl.envs.MarlGroupMapType", "reference/generated/torchrl.envs.MeltingpotEnv", "reference/generated/torchrl.envs.MeltingpotWrapper", "reference/generated/torchrl.envs.ModelBasedEnvBase", "reference/generated/torchrl.envs.MultiThreadedEnv", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper", "reference/generated/torchrl.envs.OpenMLEnv", "reference/generated/torchrl.envs.OpenSpielEnv", "reference/generated/torchrl.envs.OpenSpielWrapper", "reference/generated/torchrl.envs.ParallelEnv", "reference/generated/torchrl.envs.PendulumEnv", "reference/generated/torchrl.envs.PettingZooEnv", "reference/generated/torchrl.envs.PettingZooWrapper", "reference/generated/torchrl.envs.ProcessorAsyncEnvPool", "reference/generated/torchrl.envs.RoboHiveEnv", "reference/generated/torchrl.envs.SMACv2Env", "reference/generated/torchrl.envs.SMACv2Wrapper", "reference/generated/torchrl.envs.SerialEnv", "reference/generated/torchrl.envs.ThreadingAsyncEnvPool", "reference/generated/torchrl.envs.TicTacToeEnv", "reference/generated/torchrl.envs.UnityMLAgentsEnv", "reference/generated/torchrl.envs.UnityMLAgentsWrapper", "reference/generated/torchrl.envs.VmasEnv", "reference/generated/torchrl.envs.VmasWrapper", "reference/generated/torchrl.envs.check_env_specs", "reference/generated/torchrl.envs.check_marl_grouping", "reference/generated/torchrl.envs.exploration_type", "reference/generated/torchrl.envs.get_available_libraries", "reference/generated/torchrl.envs.gym_backend", "reference/generated/torchrl.envs.llm.ChatEnv", "reference/generated/torchrl.envs.llm.DatasetChatEnv", "reference/generated/torchrl.envs.llm.GSM8KEnv", "reference/generated/torchrl.envs.llm.GSM8KPrepareQuestion", "reference/generated/torchrl.envs.llm.GSM8KRewardParser", "reference/generated/torchrl.envs.llm.IFEvalEnv", "reference/generated/torchrl.envs.llm.IFEvalScoreData", "reference/generated/torchrl.envs.llm.IfEvalScorer", "reference/generated/torchrl.envs.llm.LLMEnv", "reference/generated/torchrl.envs.llm.LLMHashingEnv", "reference/generated/torchrl.envs.llm.MLGymWrapper", "reference/generated/torchrl.envs.llm.make_gsm8k_env", "reference/generated/torchrl.envs.llm.make_mlgym", "reference/generated/torchrl.envs.llm.transforms.AddThinkingPrompt", "reference/generated/torchrl.envs.llm.transforms.BrowserTransform", "reference/generated/torchrl.envs.llm.transforms.DataLoadingPrimer", "reference/generated/torchrl.envs.llm.transforms.ExecuteToolsInOrder", "reference/generated/torchrl.envs.llm.transforms.JSONCallParser", "reference/generated/torchrl.envs.llm.transforms.KLComputation", "reference/generated/torchrl.envs.llm.transforms.KLRewardTransform", "reference/generated/torchrl.envs.llm.transforms.MCPToolTransform", "reference/generated/torchrl.envs.llm.transforms.PolicyVersion", "reference/generated/torchrl.envs.llm.transforms.PythonExecutorService", "reference/generated/torchrl.envs.llm.transforms.PythonInterpreter", "reference/generated/torchrl.envs.llm.transforms.RayDataLoadingPrimer", "reference/generated/torchrl.envs.llm.transforms.RetrieveKL", "reference/generated/torchrl.envs.llm.transforms.RetrieveLogProb", "reference/generated/torchrl.envs.llm.transforms.SimpleToolTransform", "reference/generated/torchrl.envs.llm.transforms.TemplateTransform", "reference/generated/torchrl.envs.llm.transforms.Tokenizer", "reference/generated/torchrl.envs.llm.transforms.ToolCall", "reference/generated/torchrl.envs.llm.transforms.ToolRegistry", "reference/generated/torchrl.envs.llm.transforms.ToolService", "reference/generated/torchrl.envs.llm.transforms.XMLBlockParser", "reference/generated/torchrl.envs.llm.transforms.as_nested_tensor", "reference/generated/torchrl.envs.llm.transforms.as_padded_tensor", "reference/generated/torchrl.envs.make_composite_from_td", "reference/generated/torchrl.envs.model_based.dreamer.DreamerDecoder", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv", "reference/generated/torchrl.envs.register_gym_spec_conversion", "reference/generated/torchrl.envs.set_exploration_type", "reference/generated/torchrl.envs.set_gym_backend", "reference/generated/torchrl.envs.step_mdp", "reference/generated/torchrl.envs.terminated_or_truncated", "reference/generated/torchrl.envs.transforms.ActionDiscretizer", "reference/generated/torchrl.envs.transforms.ActionMask", "reference/generated/torchrl.envs.transforms.AutoResetEnv", "reference/generated/torchrl.envs.transforms.AutoResetTransform", "reference/generated/torchrl.envs.transforms.BatchSizeTransform", "reference/generated/torchrl.envs.transforms.BinarizeReward", "reference/generated/torchrl.envs.transforms.BurnInTransform", "reference/generated/torchrl.envs.transforms.CatFrames", "reference/generated/torchrl.envs.transforms.CatTensors", "reference/generated/torchrl.envs.transforms.CenterCrop", "reference/generated/torchrl.envs.transforms.ClipTransform", "reference/generated/torchrl.envs.transforms.Compose", "reference/generated/torchrl.envs.transforms.ConditionalPolicySwitch", "reference/generated/torchrl.envs.transforms.ConditionalSkip", "reference/generated/torchrl.envs.transforms.Crop", "reference/generated/torchrl.envs.transforms.DTypeCastTransform", "reference/generated/torchrl.envs.transforms.DeviceCastTransform", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection", "reference/generated/torchrl.envs.transforms.DoubleToFloat", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform", "reference/generated/torchrl.envs.transforms.ExcludeTransform", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck", "reference/generated/torchrl.envs.transforms.FlattenObservation", "reference/generated/torchrl.envs.transforms.FrameSkipTransform", "reference/generated/torchrl.envs.transforms.GrayScale", "reference/generated/torchrl.envs.transforms.Hash", "reference/generated/torchrl.envs.transforms.InitTracker", "reference/generated/torchrl.envs.transforms.KLRewardTransform", "reference/generated/torchrl.envs.transforms.LineariseRewards", "reference/generated/torchrl.envs.transforms.ModuleTransform", "reference/generated/torchrl.envs.transforms.MultiAction", "reference/generated/torchrl.envs.transforms.NoopResetEnv", "reference/generated/torchrl.envs.transforms.ObservationNorm", "reference/generated/torchrl.envs.transforms.ObservationTransform", "reference/generated/torchrl.envs.transforms.PermuteTransform", "reference/generated/torchrl.envs.transforms.PinMemoryTransform", "reference/generated/torchrl.envs.transforms.R3MTransform", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict", "reference/generated/torchrl.envs.transforms.RemoveEmptySpecs", "reference/generated/torchrl.envs.transforms.RenameTransform", "reference/generated/torchrl.envs.transforms.Resize", "reference/generated/torchrl.envs.transforms.Reward2GoTransform", "reference/generated/torchrl.envs.transforms.RewardClipping", "reference/generated/torchrl.envs.transforms.RewardScaling", "reference/generated/torchrl.envs.transforms.RewardSum", "reference/generated/torchrl.envs.transforms.SelectTransform", "reference/generated/torchrl.envs.transforms.SignTransform", "reference/generated/torchrl.envs.transforms.SqueezeTransform", "reference/generated/torchrl.envs.transforms.Stack", "reference/generated/torchrl.envs.transforms.StepCounter", "reference/generated/torchrl.envs.transforms.TargetReturn", "reference/generated/torchrl.envs.transforms.TensorDictPrimer", "reference/generated/torchrl.envs.transforms.TimeMaxPool", "reference/generated/torchrl.envs.transforms.Timer", "reference/generated/torchrl.envs.transforms.ToTensorImage", "reference/generated/torchrl.envs.transforms.Tokenizer", "reference/generated/torchrl.envs.transforms.TrajCounter", "reference/generated/torchrl.envs.transforms.Transform", "reference/generated/torchrl.envs.transforms.TransformedEnv", "reference/generated/torchrl.envs.transforms.UnaryTransform", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform", "reference/generated/torchrl.envs.transforms.VC1Transform", "reference/generated/torchrl.envs.transforms.VIPRewardTransform", "reference/generated/torchrl.envs.transforms.VIPTransform", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform", "reference/generated/torchrl.envs.transforms.VecNorm", "reference/generated/torchrl.envs.transforms.VecNormV2", "reference/generated/torchrl.envs.transforms.gSDENoise", "reference/generated/torchrl.implement_for", "reference/generated/torchrl.modules.ActorCriticOperator", "reference/generated/torchrl.modules.ActorCriticWrapper", "reference/generated/torchrl.modules.ActorValueOperator", "reference/generated/torchrl.modules.AdditiveGaussianModule", "reference/generated/torchrl.modules.ConsistentDropoutModule", "reference/generated/torchrl.modules.ConvNet", "reference/generated/torchrl.modules.DTActor", "reference/generated/torchrl.modules.DdpgCnnActor", "reference/generated/torchrl.modules.DdpgCnnQNet", "reference/generated/torchrl.modules.DdpgMlpActor", "reference/generated/torchrl.modules.DdpgMlpQNet", "reference/generated/torchrl.modules.DecisionTransformer", "reference/generated/torchrl.modules.Delta", "reference/generated/torchrl.modules.DistributionalDQNnet", "reference/generated/torchrl.modules.DistributionalQValueActor", "reference/generated/torchrl.modules.DistributionalQValueModule", "reference/generated/torchrl.modules.DreamerActor", "reference/generated/torchrl.modules.DuelingCnnDQNet", "reference/generated/torchrl.modules.EGreedyModule", "reference/generated/torchrl.modules.GRUModule", "reference/generated/torchrl.modules.IndependentNormal", "reference/generated/torchrl.modules.LSTMModule", "reference/generated/torchrl.modules.MLP", "reference/generated/torchrl.modules.MaskedCategorical", "reference/generated/torchrl.modules.NormalParamExtractor", "reference/generated/torchrl.modules.ObsDecoder", "reference/generated/torchrl.modules.ObsEncoder", "reference/generated/torchrl.modules.OneHotCategorical", "reference/generated/torchrl.modules.OnlineDTActor", "reference/generated/torchrl.modules.OrnsteinUhlenbeckProcessModule", "reference/generated/torchrl.modules.QValueActor", "reference/generated/torchrl.modules.QValueModule", "reference/generated/torchrl.modules.RSSMPosterior", "reference/generated/torchrl.modules.RSSMPrior", "reference/generated/torchrl.modules.RSSMRollout", "reference/generated/torchrl.modules.ReparamGradientStrategy", "reference/generated/torchrl.modules.TanhDelta", "reference/generated/torchrl.modules.TanhNormal", "reference/generated/torchrl.modules.TruncatedNormal", "reference/generated/torchrl.modules.ValueOperator", "reference/generated/torchrl.modules.WorldModelWrapper", "reference/generated/torchrl.modules.llm.AsyncVLLM", "reference/generated/torchrl.modules.llm.ChatHistory", "reference/generated/torchrl.modules.llm.LLMWrapperBase", "reference/generated/torchrl.modules.llm.LogProbs", "reference/generated/torchrl.modules.llm.Masks", "reference/generated/torchrl.modules.llm.RemoteTransformersWrapper", "reference/generated/torchrl.modules.llm.Text", "reference/generated/torchrl.modules.llm.Tokens", "reference/generated/torchrl.modules.llm.TransformersWrapper", "reference/generated/torchrl.modules.llm.make_async_vllm_engine", "reference/generated/torchrl.modules.llm.make_vllm_worker", "reference/generated/torchrl.modules.llm.stateless_init_process_group", "reference/generated/torchrl.modules.llm.stateless_init_process_group_async", "reference/generated/torchrl.modules.llm.vLLMWrapper", "reference/generated/torchrl.modules.models.utils.SquashDims", "reference/generated/torchrl.modules.tensordict_module.Actor", "reference/generated/torchrl.modules.tensordict_module.MultiStepActorWrapper", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor", "reference/generated/torchrl.modules.tensordict_module.RandomPolicy", "reference/generated/torchrl.modules.tensordict_module.SafeModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential", "reference/generated/torchrl.modules.tensordict_module.SafeSequential", "reference/generated/torchrl.modules.tensordict_module.TanhModule", "reference/generated/torchrl.objectives.A2CLoss", "reference/generated/torchrl.objectives.CQLLoss", "reference/generated/torchrl.objectives.ClipPPOLoss", "reference/generated/torchrl.objectives.CrossQLoss", "reference/generated/torchrl.objectives.DDPGLoss", "reference/generated/torchrl.objectives.DQNLoss", "reference/generated/torchrl.objectives.DTLoss", "reference/generated/torchrl.objectives.DiscreteCQLLoss", "reference/generated/torchrl.objectives.DiscreteIQLLoss", "reference/generated/torchrl.objectives.DiscreteSACLoss", "reference/generated/torchrl.objectives.DistributionalDQNLoss", "reference/generated/torchrl.objectives.DreamerActorLoss", "reference/generated/torchrl.objectives.DreamerModelLoss", "reference/generated/torchrl.objectives.DreamerValueLoss", "reference/generated/torchrl.objectives.GAILLoss", "reference/generated/torchrl.objectives.IQLLoss", "reference/generated/torchrl.objectives.KLPENPPOLoss", "reference/generated/torchrl.objectives.LossModule", "reference/generated/torchrl.objectives.OnlineDTLoss", "reference/generated/torchrl.objectives.PPOLoss", "reference/generated/torchrl.objectives.REDQLoss", "reference/generated/torchrl.objectives.ReinforceLoss", "reference/generated/torchrl.objectives.SACLoss", "reference/generated/torchrl.objectives.TD3BCLoss", "reference/generated/torchrl.objectives.TD3Loss", "reference/generated/torchrl.objectives.ValueEstimators", "reference/generated/torchrl.objectives.add_random_module", "reference/generated/torchrl.objectives.llm.CISPOLoss", "reference/generated/torchrl.objectives.llm.CISPOLossOutput", "reference/generated/torchrl.objectives.llm.DAPO", "reference/generated/torchrl.objectives.llm.DAPOLossOutput", "reference/generated/torchrl.objectives.llm.GRPOLoss", "reference/generated/torchrl.objectives.llm.GRPOLossOutput", "reference/generated/torchrl.objectives.llm.LLMLossOutput", "reference/generated/torchrl.objectives.llm.MCAdvantage", "reference/generated/torchrl.objectives.llm.SFTLoss", "reference/generated/torchrl.objectives.llm.SFTLossOutput", "reference/generated/torchrl.objectives.value.GAE", "reference/generated/torchrl.objectives.value.TD0Estimator", "reference/generated/torchrl.objectives.value.TD1Estimator", "reference/generated/torchrl.objectives.value.TDLambdaEstimator", "reference/generated/torchrl.objectives.value.ValueEstimatorBase", "reference/generated/torchrl.record.PixelRenderTransform", "reference/generated/torchrl.record.TensorDictRecorder", "reference/generated/torchrl.record.VideoRecorder", "reference/generated/torchrl.record.loggers.Logger", "reference/generated/torchrl.record.loggers.csv.CSVLogger", "reference/generated/torchrl.record.loggers.generate_exp_name", "reference/generated/torchrl.record.loggers.get_logger", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger", "reference/generated/torchrl.record.loggers.wandb.WandbLogger", "reference/generated/torchrl.services.RayService", "reference/generated/torchrl.services.ServiceBase", "reference/generated/torchrl.services.get_services", "reference/generated/torchrl.set_auto_unwrap_transformed_env", "reference/generated/torchrl.trainers.BatchSubSampler", "reference/generated/torchrl.trainers.ClearCudaCache", "reference/generated/torchrl.trainers.CountFramesLog", "reference/generated/torchrl.trainers.LogScalar", "reference/generated/torchrl.trainers.LogValidationReward", "reference/generated/torchrl.trainers.OptimizerHook", "reference/generated/torchrl.trainers.ReplayBufferTrainer", "reference/generated/torchrl.trainers.RewardNormalizer", "reference/generated/torchrl.trainers.SelectKeys", "reference/generated/torchrl.trainers.TargetNetUpdaterHook", "reference/generated/torchrl.trainers.Trainer", "reference/generated/torchrl.trainers.TrainerHookBase", "reference/generated/torchrl.trainers.UTDRHook", "reference/generated/torchrl.trainers.UpdateWeights", "reference/generated/torchrl.trainers.algorithms.PPOTrainer", "reference/generated/torchrl.trainers.algorithms.SACTrainer", "reference/generated/torchrl.trainers.algorithms.configs.collectors.AsyncDataCollectorConfig", "reference/generated/torchrl.trainers.algorithms.configs.collectors.SyncDataCollectorConfig", "reference/generated/torchrl.trainers.algorithms.configs.common.ConfigBase", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyMemmapStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyStackStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyTensorStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.ListStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.PrioritizedSamplerConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.RandomSamplerConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.ReplayBufferConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.RoundRobinWriterConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.SamplerWithoutReplacementConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerWithoutReplacementConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleWriterConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorDictReplayBufferConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs.BatchedEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs.EnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs.TransformedEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.BraxEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.DMControlEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.EnvLibsConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.GymEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.HabitatEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.IsaacGymEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.JumanjiEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MOGymEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MeltingpotEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MultiThreadedEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenMLEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenSpielEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.PettingZooEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.RoboHiveEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.SMACv2EnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.UnityMLAgentsEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.VmasEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.CSVLoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.LoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.TensorboardLoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.WandbLoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.ConvNetConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.MLPConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.ModelConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.NetworkConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.TanhNormalModelConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.TensorDictModuleConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.ValueModelConfig", "reference/generated/torchrl.trainers.algorithms.configs.objectives.LossConfig", "reference/generated/torchrl.trainers.algorithms.configs.objectives.PPOLossConfig", "reference/generated/torchrl.trainers.algorithms.configs.trainers.PPOTrainerConfig", "reference/generated/torchrl.trainers.algorithms.configs.trainers.TrainerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionDiscretizerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionMaskConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.AutoResetTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BatchSizeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BinarizeRewardConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BurnInTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatFramesConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatTensorsConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CenterCropConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ClipTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ComposeConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalPolicySwitchConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalSkipConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CropConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DTypeCastTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DeviceCastTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DiscreteActionProjectionConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DoubleToFloatConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.EndOfLifeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ExcludeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FiniteTensorDictCheckConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FlattenObservationConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FrameSkipTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.GrayScaleConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.HashConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.InitTrackerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.KLRewardTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.LineariseRewardsConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiActionConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiStepTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.NoopResetEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ObservationNormConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PermuteTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PinMemoryTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.R3MTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RandomCropTensorDictConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RemoveEmptySpecsConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RenameTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ResizeConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.Reward2GoTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardClippingConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardScalingConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardSumConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SelectTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SignTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SqueezeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StackConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StepCounterConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TargetReturnConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TensorDictPrimerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimeMaxPoolConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ToTensorImageConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TokenizerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TrajCounterConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnaryTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnsqueezeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VC1TransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPRewardTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecGymEnvTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormV2Config", "reference/generated/torchrl.trainers.algorithms.configs.utils.ASGDConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdadeltaConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdagradConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamWConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamaxConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.LBFGSConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.LionConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.NAdamConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.RAdamConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.RMSpropConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.RpropConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.SGDConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.SparseAdamConfig", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy", "reference/generated/torchrl.trainers.helpers.make_dqn_loss", "reference/generated/torchrl.trainers.helpers.make_replay_buffer", "reference/generated/torchrl.trainers.helpers.make_target_updater", "reference/generated/torchrl.trainers.helpers.make_trainer", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor", "reference/generated/torchrl.trainers.helpers.sync_async_collector", "reference/generated/torchrl.trainers.helpers.sync_sync_collector", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor", "reference/generated/torchrl.weight_update.DistributedTransport", "reference/generated/torchrl.weight_update.DistributedWeightSyncScheme", "reference/generated/torchrl.weight_update.MPTransport", "reference/generated/torchrl.weight_update.MultiProcessWeightSyncScheme", "reference/generated/torchrl.weight_update.NoWeightSyncScheme", "reference/generated/torchrl.weight_update.RPCTransport", "reference/generated/torchrl.weight_update.RPCWeightSyncScheme", "reference/generated/torchrl.weight_update.RayModuleTransformScheme", "reference/generated/torchrl.weight_update.RayTransport", "reference/generated/torchrl.weight_update.RayWeightSyncScheme", "reference/generated/torchrl.weight_update.SharedMemTransport", "reference/generated/torchrl.weight_update.SharedMemWeightSyncScheme", "reference/generated/torchrl.weight_update.TransportBackend", "reference/generated/torchrl.weight_update.WeightStrategy", "reference/generated/torchrl.weight_update.WeightSyncScheme", "reference/generated/torchrl.weight_update.llm.VLLMCollectiveTransport", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferTransport", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightSender", "reference/generated/torchrl.weight_update.llm.VLLMWeightReceiver", "reference/generated/torchrl.weight_update.llm.VLLMWeightSender", "reference/generated/torchrl.weight_update.llm.VLLMWeightSyncScheme", "reference/generated/torchrl.weight_update.llm.get_model_metadata", "reference/generated/tutorials/README", "reference/index", "reference/knowledge_base", "reference/llms", "reference/llms_collectors", "reference/llms_data", "reference/llms_envs", "reference/llms_modules", "reference/llms_objectives", "reference/llms_transforms", "reference/modules", "reference/modules_actors", "reference/modules_critics", "reference/modules_distributions", "reference/modules_exploration", "reference/modules_models", "reference/modules_utils", "reference/objectives", "reference/objectives_actorcritic", "reference/objectives_common", "reference/objectives_offline", "reference/objectives_other", "reference/objectives_policy", "reference/objectives_value", "reference/services", "reference/trainers", "reference/trainers_basics", "reference/trainers_hooks", "reference/trainers_loggers", "reference/utils", "sg_execution_times", "tutorials/coding_ddpg", "tutorials/coding_dqn", "tutorials/coding_ppo", "tutorials/dqn_with_rnn", "tutorials/export", "tutorials/getting-started-0", "tutorials/getting-started-1", "tutorials/getting-started-2", "tutorials/getting-started-3", "tutorials/getting-started-4", "tutorials/getting-started-5", "tutorials/index", "tutorials/llm_browser", "tutorials/llm_wrappers", "tutorials/multi_task", "tutorials/multiagent_competitive_ddpg", "tutorials/multiagent_ppo", "tutorials/pendulum", "tutorials/pretrained_models", "tutorials/rb_tutorial", "tutorials/sg_execution_times", "tutorials/torchrl_demo", "tutorials/torchrl_envs"], "filenames": ["index.rst", "reference/collectors.rst", "reference/collectors_basics.rst", "reference/collectors_distributed.rst", "reference/collectors_replay.rst", "reference/collectors_single.rst", "reference/collectors_weightsync.rst", "reference/config.rst", "reference/cudnn_persistent_rnn.rst", "reference/cudnn_rnn_determinism.rst", "reference/data.rst", "reference/data_datasets.rst", "reference/data_replaybuffers.rst", "reference/data_samplers.rst", "reference/data_specs.rst", "reference/data_storage.rst", "reference/envs.rst", "reference/envs_api.rst", "reference/envs_libraries.rst", "reference/envs_multiagent.rst", "reference/envs_recorders.rst", "reference/envs_transforms.rst", "reference/envs_vectorized.rst", "reference/generated/knowledge_base/DEBUGGING_RL.rst", "reference/generated/knowledge_base/GYM.rst", "reference/generated/knowledge_base/HABITAT.rst", "reference/generated/knowledge_base/MUJOCO_INSTALLATION.rst", "reference/generated/knowledge_base/PRO-TIPS.rst", "reference/generated/knowledge_base/RESOURCES.rst", "reference/generated/knowledge_base/VERSIONING_ISSUES.rst", "reference/generated/knowledge_base/VIDEO_CUSTOMISATION.rst", "reference/generated/torchrl.auto_unwrap_transformed_env.rst", "reference/generated/torchrl.collectors.AsyncCollector.rst", "reference/generated/torchrl.collectors.BaseCollector.rst", "reference/generated/torchrl.collectors.Collector.rst", "reference/generated/torchrl.collectors.MultiAsyncCollector.rst", "reference/generated/torchrl.collectors.MultiCollector.rst", "reference/generated/torchrl.collectors.MultiProcessedWeightUpdater.rst", "reference/generated/torchrl.collectors.MultiSyncCollector.rst", "reference/generated/torchrl.collectors.RayWeightUpdater.rst", "reference/generated/torchrl.collectors.VanillaWeightUpdater.rst", "reference/generated/torchrl.collectors.WeightUpdaterBase.rst", "reference/generated/torchrl.collectors.distributed.DistributedCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedSyncCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedWeightUpdater.rst", "reference/generated/torchrl.collectors.distributed.RPCCollector.rst", "reference/generated/torchrl.collectors.distributed.RPCDataCollector.rst", "reference/generated/torchrl.collectors.distributed.RPCWeightUpdater.rst", "reference/generated/torchrl.collectors.distributed.RayCollector.rst", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher.rst", "reference/generated/torchrl.collectors.llm.LLMCollector.rst", "reference/generated/torchrl.collectors.llm.RayLLMCollector.rst", "reference/generated/torchrl.collectors.llm.vLLMUpdater.rst", "reference/generated/torchrl.collectors.llm.vLLMUpdaterV2.rst", "reference/generated/torchrl.collectors.utils.split_trajectories.rst", "reference/generated/torchrl.data.Binary.rst", "reference/generated/torchrl.data.Bounded.rst", "reference/generated/torchrl.data.Categorical.rst", "reference/generated/torchrl.data.Composite.rst", "reference/generated/torchrl.data.MultiCategorical.rst", "reference/generated/torchrl.data.MultiOneHot.rst", "reference/generated/torchrl.data.NonTensor.rst", "reference/generated/torchrl.data.OneHot.rst", "reference/generated/torchrl.data.PrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.RayReplayBuffer.rst", "reference/generated/torchrl.data.RemoteTensorDictReplayBuffer.rst", "reference/generated/torchrl.data.ReplayBuffer.rst", "reference/generated/torchrl.data.ReplayBufferEnsemble.rst", "reference/generated/torchrl.data.Stacked.rst", "reference/generated/torchrl.data.StackedComposite.rst", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.TensorDictReplayBuffer.rst", "reference/generated/torchrl.data.TensorSpec.rst", "reference/generated/torchrl.data.Unbounded.rst", "reference/generated/torchrl.data.UnboundedContinuous.rst", "reference/generated/torchrl.data.UnboundedDiscrete.rst", "reference/generated/torchrl.data.datasets.AtariDQNExperienceReplay.rst", "reference/generated/torchrl.data.datasets.D4RLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.GenDGRLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.MinariExperienceReplay.rst", "reference/generated/torchrl.data.datasets.OpenMLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.OpenXExperienceReplay.rst", "reference/generated/torchrl.data.datasets.RobosetExperienceReplay.rst", "reference/generated/torchrl.data.datasets.VD4RLExperienceReplay.rst", "reference/generated/torchrl.data.llm.ContentBase.rst", "reference/generated/torchrl.data.llm.History.rst", "reference/generated/torchrl.data.llm.TopKRewardSelector.rst", "reference/generated/torchrl.data.llm.add_chat_template.rst", "reference/generated/torchrl.data.replay_buffers.CompressedListStorage.rst", "reference/generated/torchrl.data.replay_buffers.CompressedListStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.FlatStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.H5StorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.ImmutableDatasetWriter.rst", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage.rst", "reference/generated/torchrl.data.replay_buffers.LazyStackStorage.rst", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.ListStorage.rst", "reference/generated/torchrl.data.replay_buffers.ListStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.NestedStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler.rst", "reference/generated/torchrl.data.replay_buffers.PrioritizedSliceSampler.rst", "reference/generated/torchrl.data.replay_buffers.RandomSampler.rst", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.Sampler.rst", "reference/generated/torchrl.data.replay_buffers.SamplerEnsemble.rst", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.SliceSampler.rst", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.Storage.rst", "reference/generated/torchrl.data.replay_buffers.StorageCheckpointerBase.rst", "reference/generated/torchrl.data.replay_buffers.StorageEnsemble.rst", "reference/generated/torchrl.data.replay_buffers.StorageEnsembleCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.TensorStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.Writer.rst", "reference/generated/torchrl.data.replay_buffers.WriterEnsemble.rst", "reference/generated/torchrl.envs.AsyncEnvPool.rst", "reference/generated/torchrl.envs.BraxEnv.rst", "reference/generated/torchrl.envs.BraxWrapper.rst", "reference/generated/torchrl.envs.ChessEnv.rst", "reference/generated/torchrl.envs.DMControlEnv.rst", "reference/generated/torchrl.envs.DMControlWrapper.rst", "reference/generated/torchrl.envs.EnvBase.rst", "reference/generated/torchrl.envs.EnvCreator.rst", "reference/generated/torchrl.envs.EnvMetaData.rst", "reference/generated/torchrl.envs.GymEnv.rst", "reference/generated/torchrl.envs.GymLikeEnv.rst", "reference/generated/torchrl.envs.GymWrapper.rst", "reference/generated/torchrl.envs.HabitatEnv.rst", "reference/generated/torchrl.envs.IsaacGymEnv.rst", "reference/generated/torchrl.envs.IsaacGymWrapper.rst", "reference/generated/torchrl.envs.IsaacLabWrapper.rst", "reference/generated/torchrl.envs.JumanjiEnv.rst", "reference/generated/torchrl.envs.JumanjiWrapper.rst", "reference/generated/torchrl.envs.LLMHashingEnv.rst", "reference/generated/torchrl.envs.MOGymEnv.rst", "reference/generated/torchrl.envs.MOGymWrapper.rst", "reference/generated/torchrl.envs.MarlGroupMapType.rst", "reference/generated/torchrl.envs.MeltingpotEnv.rst", "reference/generated/torchrl.envs.MeltingpotWrapper.rst", "reference/generated/torchrl.envs.ModelBasedEnvBase.rst", "reference/generated/torchrl.envs.MultiThreadedEnv.rst", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper.rst", "reference/generated/torchrl.envs.OpenMLEnv.rst", "reference/generated/torchrl.envs.OpenSpielEnv.rst", "reference/generated/torchrl.envs.OpenSpielWrapper.rst", "reference/generated/torchrl.envs.ParallelEnv.rst", "reference/generated/torchrl.envs.PendulumEnv.rst", "reference/generated/torchrl.envs.PettingZooEnv.rst", "reference/generated/torchrl.envs.PettingZooWrapper.rst", "reference/generated/torchrl.envs.ProcessorAsyncEnvPool.rst", "reference/generated/torchrl.envs.RoboHiveEnv.rst", "reference/generated/torchrl.envs.SMACv2Env.rst", "reference/generated/torchrl.envs.SMACv2Wrapper.rst", "reference/generated/torchrl.envs.SerialEnv.rst", "reference/generated/torchrl.envs.ThreadingAsyncEnvPool.rst", "reference/generated/torchrl.envs.TicTacToeEnv.rst", "reference/generated/torchrl.envs.UnityMLAgentsEnv.rst", "reference/generated/torchrl.envs.UnityMLAgentsWrapper.rst", "reference/generated/torchrl.envs.VmasEnv.rst", "reference/generated/torchrl.envs.VmasWrapper.rst", "reference/generated/torchrl.envs.check_env_specs.rst", "reference/generated/torchrl.envs.check_marl_grouping.rst", "reference/generated/torchrl.envs.exploration_type.rst", "reference/generated/torchrl.envs.get_available_libraries.rst", "reference/generated/torchrl.envs.gym_backend.rst", "reference/generated/torchrl.envs.llm.ChatEnv.rst", "reference/generated/torchrl.envs.llm.DatasetChatEnv.rst", "reference/generated/torchrl.envs.llm.GSM8KEnv.rst", "reference/generated/torchrl.envs.llm.GSM8KPrepareQuestion.rst", "reference/generated/torchrl.envs.llm.GSM8KRewardParser.rst", "reference/generated/torchrl.envs.llm.IFEvalEnv.rst", "reference/generated/torchrl.envs.llm.IFEvalScoreData.rst", "reference/generated/torchrl.envs.llm.IfEvalScorer.rst", "reference/generated/torchrl.envs.llm.LLMEnv.rst", "reference/generated/torchrl.envs.llm.LLMHashingEnv.rst", "reference/generated/torchrl.envs.llm.MLGymWrapper.rst", "reference/generated/torchrl.envs.llm.make_gsm8k_env.rst", "reference/generated/torchrl.envs.llm.make_mlgym.rst", "reference/generated/torchrl.envs.llm.transforms.AddThinkingPrompt.rst", "reference/generated/torchrl.envs.llm.transforms.BrowserTransform.rst", "reference/generated/torchrl.envs.llm.transforms.DataLoadingPrimer.rst", "reference/generated/torchrl.envs.llm.transforms.ExecuteToolsInOrder.rst", "reference/generated/torchrl.envs.llm.transforms.JSONCallParser.rst", "reference/generated/torchrl.envs.llm.transforms.KLComputation.rst", "reference/generated/torchrl.envs.llm.transforms.KLRewardTransform.rst", "reference/generated/torchrl.envs.llm.transforms.MCPToolTransform.rst", "reference/generated/torchrl.envs.llm.transforms.PolicyVersion.rst", "reference/generated/torchrl.envs.llm.transforms.PythonExecutorService.rst", "reference/generated/torchrl.envs.llm.transforms.PythonInterpreter.rst", "reference/generated/torchrl.envs.llm.transforms.RayDataLoadingPrimer.rst", "reference/generated/torchrl.envs.llm.transforms.RetrieveKL.rst", "reference/generated/torchrl.envs.llm.transforms.RetrieveLogProb.rst", "reference/generated/torchrl.envs.llm.transforms.SimpleToolTransform.rst", "reference/generated/torchrl.envs.llm.transforms.TemplateTransform.rst", "reference/generated/torchrl.envs.llm.transforms.Tokenizer.rst", "reference/generated/torchrl.envs.llm.transforms.ToolCall.rst", "reference/generated/torchrl.envs.llm.transforms.ToolRegistry.rst", "reference/generated/torchrl.envs.llm.transforms.ToolService.rst", "reference/generated/torchrl.envs.llm.transforms.XMLBlockParser.rst", "reference/generated/torchrl.envs.llm.transforms.as_nested_tensor.rst", "reference/generated/torchrl.envs.llm.transforms.as_padded_tensor.rst", "reference/generated/torchrl.envs.make_composite_from_td.rst", "reference/generated/torchrl.envs.model_based.dreamer.DreamerDecoder.rst", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv.rst", "reference/generated/torchrl.envs.register_gym_spec_conversion.rst", "reference/generated/torchrl.envs.set_exploration_type.rst", "reference/generated/torchrl.envs.set_gym_backend.rst", "reference/generated/torchrl.envs.step_mdp.rst", "reference/generated/torchrl.envs.terminated_or_truncated.rst", "reference/generated/torchrl.envs.transforms.ActionDiscretizer.rst", "reference/generated/torchrl.envs.transforms.ActionMask.rst", "reference/generated/torchrl.envs.transforms.AutoResetEnv.rst", "reference/generated/torchrl.envs.transforms.AutoResetTransform.rst", "reference/generated/torchrl.envs.transforms.BatchSizeTransform.rst", "reference/generated/torchrl.envs.transforms.BinarizeReward.rst", "reference/generated/torchrl.envs.transforms.BurnInTransform.rst", "reference/generated/torchrl.envs.transforms.CatFrames.rst", "reference/generated/torchrl.envs.transforms.CatTensors.rst", "reference/generated/torchrl.envs.transforms.CenterCrop.rst", "reference/generated/torchrl.envs.transforms.ClipTransform.rst", "reference/generated/torchrl.envs.transforms.Compose.rst", "reference/generated/torchrl.envs.transforms.ConditionalPolicySwitch.rst", "reference/generated/torchrl.envs.transforms.ConditionalSkip.rst", "reference/generated/torchrl.envs.transforms.Crop.rst", "reference/generated/torchrl.envs.transforms.DTypeCastTransform.rst", "reference/generated/torchrl.envs.transforms.DeviceCastTransform.rst", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection.rst", "reference/generated/torchrl.envs.transforms.DoubleToFloat.rst", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform.rst", "reference/generated/torchrl.envs.transforms.ExcludeTransform.rst", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck.rst", "reference/generated/torchrl.envs.transforms.FlattenObservation.rst", "reference/generated/torchrl.envs.transforms.FrameSkipTransform.rst", "reference/generated/torchrl.envs.transforms.GrayScale.rst", "reference/generated/torchrl.envs.transforms.Hash.rst", "reference/generated/torchrl.envs.transforms.InitTracker.rst", "reference/generated/torchrl.envs.transforms.KLRewardTransform.rst", "reference/generated/torchrl.envs.transforms.LineariseRewards.rst", "reference/generated/torchrl.envs.transforms.ModuleTransform.rst", "reference/generated/torchrl.envs.transforms.MultiAction.rst", "reference/generated/torchrl.envs.transforms.NoopResetEnv.rst", "reference/generated/torchrl.envs.transforms.ObservationNorm.rst", "reference/generated/torchrl.envs.transforms.ObservationTransform.rst", "reference/generated/torchrl.envs.transforms.PermuteTransform.rst", "reference/generated/torchrl.envs.transforms.PinMemoryTransform.rst", "reference/generated/torchrl.envs.transforms.R3MTransform.rst", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict.rst", "reference/generated/torchrl.envs.transforms.RemoveEmptySpecs.rst", "reference/generated/torchrl.envs.transforms.RenameTransform.rst", "reference/generated/torchrl.envs.transforms.Resize.rst", "reference/generated/torchrl.envs.transforms.Reward2GoTransform.rst", "reference/generated/torchrl.envs.transforms.RewardClipping.rst", "reference/generated/torchrl.envs.transforms.RewardScaling.rst", "reference/generated/torchrl.envs.transforms.RewardSum.rst", "reference/generated/torchrl.envs.transforms.SelectTransform.rst", "reference/generated/torchrl.envs.transforms.SignTransform.rst", "reference/generated/torchrl.envs.transforms.SqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.Stack.rst", "reference/generated/torchrl.envs.transforms.StepCounter.rst", "reference/generated/torchrl.envs.transforms.TargetReturn.rst", "reference/generated/torchrl.envs.transforms.TensorDictPrimer.rst", "reference/generated/torchrl.envs.transforms.TimeMaxPool.rst", "reference/generated/torchrl.envs.transforms.Timer.rst", "reference/generated/torchrl.envs.transforms.ToTensorImage.rst", "reference/generated/torchrl.envs.transforms.Tokenizer.rst", "reference/generated/torchrl.envs.transforms.TrajCounter.rst", "reference/generated/torchrl.envs.transforms.Transform.rst", "reference/generated/torchrl.envs.transforms.TransformedEnv.rst", "reference/generated/torchrl.envs.transforms.UnaryTransform.rst", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.VC1Transform.rst", "reference/generated/torchrl.envs.transforms.VIPRewardTransform.rst", "reference/generated/torchrl.envs.transforms.VIPTransform.rst", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform.rst", "reference/generated/torchrl.envs.transforms.VecNorm.rst", "reference/generated/torchrl.envs.transforms.VecNormV2.rst", "reference/generated/torchrl.envs.transforms.gSDENoise.rst", "reference/generated/torchrl.implement_for.rst", "reference/generated/torchrl.modules.ActorCriticOperator.rst", "reference/generated/torchrl.modules.ActorCriticWrapper.rst", "reference/generated/torchrl.modules.ActorValueOperator.rst", "reference/generated/torchrl.modules.AdditiveGaussianModule.rst", "reference/generated/torchrl.modules.ConsistentDropoutModule.rst", "reference/generated/torchrl.modules.ConvNet.rst", "reference/generated/torchrl.modules.DTActor.rst", "reference/generated/torchrl.modules.DdpgCnnActor.rst", "reference/generated/torchrl.modules.DdpgCnnQNet.rst", "reference/generated/torchrl.modules.DdpgMlpActor.rst", "reference/generated/torchrl.modules.DdpgMlpQNet.rst", "reference/generated/torchrl.modules.DecisionTransformer.rst", "reference/generated/torchrl.modules.Delta.rst", "reference/generated/torchrl.modules.DistributionalDQNnet.rst", "reference/generated/torchrl.modules.DistributionalQValueActor.rst", "reference/generated/torchrl.modules.DistributionalQValueModule.rst", "reference/generated/torchrl.modules.DreamerActor.rst", "reference/generated/torchrl.modules.DuelingCnnDQNet.rst", "reference/generated/torchrl.modules.EGreedyModule.rst", "reference/generated/torchrl.modules.GRUModule.rst", "reference/generated/torchrl.modules.IndependentNormal.rst", "reference/generated/torchrl.modules.LSTMModule.rst", "reference/generated/torchrl.modules.MLP.rst", "reference/generated/torchrl.modules.MaskedCategorical.rst", "reference/generated/torchrl.modules.NormalParamExtractor.rst", "reference/generated/torchrl.modules.ObsDecoder.rst", "reference/generated/torchrl.modules.ObsEncoder.rst", "reference/generated/torchrl.modules.OneHotCategorical.rst", "reference/generated/torchrl.modules.OnlineDTActor.rst", "reference/generated/torchrl.modules.OrnsteinUhlenbeckProcessModule.rst", "reference/generated/torchrl.modules.QValueActor.rst", "reference/generated/torchrl.modules.QValueModule.rst", "reference/generated/torchrl.modules.RSSMPosterior.rst", "reference/generated/torchrl.modules.RSSMPrior.rst", "reference/generated/torchrl.modules.RSSMRollout.rst", "reference/generated/torchrl.modules.ReparamGradientStrategy.rst", "reference/generated/torchrl.modules.TanhDelta.rst", "reference/generated/torchrl.modules.TanhNormal.rst", "reference/generated/torchrl.modules.TruncatedNormal.rst", "reference/generated/torchrl.modules.ValueOperator.rst", "reference/generated/torchrl.modules.WorldModelWrapper.rst", "reference/generated/torchrl.modules.llm.AsyncVLLM.rst", "reference/generated/torchrl.modules.llm.ChatHistory.rst", "reference/generated/torchrl.modules.llm.LLMWrapperBase.rst", "reference/generated/torchrl.modules.llm.LogProbs.rst", "reference/generated/torchrl.modules.llm.Masks.rst", "reference/generated/torchrl.modules.llm.RemoteTransformersWrapper.rst", "reference/generated/torchrl.modules.llm.Text.rst", "reference/generated/torchrl.modules.llm.Tokens.rst", "reference/generated/torchrl.modules.llm.TransformersWrapper.rst", "reference/generated/torchrl.modules.llm.make_async_vllm_engine.rst", "reference/generated/torchrl.modules.llm.make_vllm_worker.rst", "reference/generated/torchrl.modules.llm.stateless_init_process_group.rst", "reference/generated/torchrl.modules.llm.stateless_init_process_group_async.rst", "reference/generated/torchrl.modules.llm.vLLMWrapper.rst", "reference/generated/torchrl.modules.models.utils.SquashDims.rst", "reference/generated/torchrl.modules.tensordict_module.Actor.rst", "reference/generated/torchrl.modules.tensordict_module.MultiStepActorWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor.rst", "reference/generated/torchrl.modules.tensordict_module.RandomPolicy.rst", "reference/generated/torchrl.modules.tensordict_module.SafeModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential.rst", "reference/generated/torchrl.modules.tensordict_module.SafeSequential.rst", "reference/generated/torchrl.modules.tensordict_module.TanhModule.rst", "reference/generated/torchrl.objectives.A2CLoss.rst", "reference/generated/torchrl.objectives.CQLLoss.rst", "reference/generated/torchrl.objectives.ClipPPOLoss.rst", "reference/generated/torchrl.objectives.CrossQLoss.rst", "reference/generated/torchrl.objectives.DDPGLoss.rst", "reference/generated/torchrl.objectives.DQNLoss.rst", "reference/generated/torchrl.objectives.DTLoss.rst", "reference/generated/torchrl.objectives.DiscreteCQLLoss.rst", "reference/generated/torchrl.objectives.DiscreteIQLLoss.rst", "reference/generated/torchrl.objectives.DiscreteSACLoss.rst", "reference/generated/torchrl.objectives.DistributionalDQNLoss.rst", "reference/generated/torchrl.objectives.DreamerActorLoss.rst", "reference/generated/torchrl.objectives.DreamerModelLoss.rst", "reference/generated/torchrl.objectives.DreamerValueLoss.rst", "reference/generated/torchrl.objectives.GAILLoss.rst", "reference/generated/torchrl.objectives.IQLLoss.rst", "reference/generated/torchrl.objectives.KLPENPPOLoss.rst", "reference/generated/torchrl.objectives.LossModule.rst", "reference/generated/torchrl.objectives.OnlineDTLoss.rst", "reference/generated/torchrl.objectives.PPOLoss.rst", "reference/generated/torchrl.objectives.REDQLoss.rst", "reference/generated/torchrl.objectives.ReinforceLoss.rst", "reference/generated/torchrl.objectives.SACLoss.rst", "reference/generated/torchrl.objectives.TD3BCLoss.rst", "reference/generated/torchrl.objectives.TD3Loss.rst", "reference/generated/torchrl.objectives.ValueEstimators.rst", "reference/generated/torchrl.objectives.add_random_module.rst", "reference/generated/torchrl.objectives.llm.CISPOLoss.rst", "reference/generated/torchrl.objectives.llm.CISPOLossOutput.rst", "reference/generated/torchrl.objectives.llm.DAPO.rst", "reference/generated/torchrl.objectives.llm.DAPOLossOutput.rst", "reference/generated/torchrl.objectives.llm.GRPOLoss.rst", "reference/generated/torchrl.objectives.llm.GRPOLossOutput.rst", "reference/generated/torchrl.objectives.llm.LLMLossOutput.rst", "reference/generated/torchrl.objectives.llm.MCAdvantage.rst", "reference/generated/torchrl.objectives.llm.SFTLoss.rst", "reference/generated/torchrl.objectives.llm.SFTLossOutput.rst", "reference/generated/torchrl.objectives.value.GAE.rst", "reference/generated/torchrl.objectives.value.TD0Estimator.rst", "reference/generated/torchrl.objectives.value.TD1Estimator.rst", "reference/generated/torchrl.objectives.value.TDLambdaEstimator.rst", "reference/generated/torchrl.objectives.value.ValueEstimatorBase.rst", "reference/generated/torchrl.record.PixelRenderTransform.rst", "reference/generated/torchrl.record.TensorDictRecorder.rst", "reference/generated/torchrl.record.VideoRecorder.rst", "reference/generated/torchrl.record.loggers.Logger.rst", "reference/generated/torchrl.record.loggers.csv.CSVLogger.rst", "reference/generated/torchrl.record.loggers.generate_exp_name.rst", "reference/generated/torchrl.record.loggers.get_logger.rst", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger.rst", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger.rst", "reference/generated/torchrl.record.loggers.wandb.WandbLogger.rst", "reference/generated/torchrl.services.RayService.rst", "reference/generated/torchrl.services.ServiceBase.rst", "reference/generated/torchrl.services.get_services.rst", "reference/generated/torchrl.set_auto_unwrap_transformed_env.rst", "reference/generated/torchrl.trainers.BatchSubSampler.rst", "reference/generated/torchrl.trainers.ClearCudaCache.rst", "reference/generated/torchrl.trainers.CountFramesLog.rst", "reference/generated/torchrl.trainers.LogScalar.rst", "reference/generated/torchrl.trainers.LogValidationReward.rst", "reference/generated/torchrl.trainers.OptimizerHook.rst", "reference/generated/torchrl.trainers.ReplayBufferTrainer.rst", "reference/generated/torchrl.trainers.RewardNormalizer.rst", "reference/generated/torchrl.trainers.SelectKeys.rst", "reference/generated/torchrl.trainers.TargetNetUpdaterHook.rst", "reference/generated/torchrl.trainers.Trainer.rst", "reference/generated/torchrl.trainers.TrainerHookBase.rst", "reference/generated/torchrl.trainers.UTDRHook.rst", "reference/generated/torchrl.trainers.UpdateWeights.rst", "reference/generated/torchrl.trainers.algorithms.PPOTrainer.rst", "reference/generated/torchrl.trainers.algorithms.SACTrainer.rst", "reference/generated/torchrl.trainers.algorithms.configs.collectors.AsyncDataCollectorConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.collectors.SyncDataCollectorConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.common.ConfigBase.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyMemmapStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyStackStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyTensorStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.ListStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.PrioritizedSamplerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.RandomSamplerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.ReplayBufferConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.RoundRobinWriterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.SamplerWithoutReplacementConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerWithoutReplacementConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleWriterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorDictReplayBufferConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs.BatchedEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs.EnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs.TransformedEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.BraxEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.DMControlEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.EnvLibsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.GymEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.HabitatEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.IsaacGymEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.JumanjiEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MOGymEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MeltingpotEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MultiThreadedEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenMLEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenSpielEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.PettingZooEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.RoboHiveEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.SMACv2EnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.UnityMLAgentsEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.VmasEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.CSVLoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.LoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.TensorboardLoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.WandbLoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.ConvNetConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.MLPConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.ModelConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.NetworkConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.TanhNormalModelConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.TensorDictModuleConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.ValueModelConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.objectives.LossConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.objectives.PPOLossConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.trainers.PPOTrainerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.trainers.TrainerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionDiscretizerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionMaskConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.AutoResetTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BatchSizeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BinarizeRewardConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BurnInTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatFramesConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatTensorsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CenterCropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ClipTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ComposeConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalPolicySwitchConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalSkipConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DTypeCastTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DeviceCastTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DiscreteActionProjectionConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DoubleToFloatConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.EndOfLifeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ExcludeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FiniteTensorDictCheckConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FlattenObservationConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FrameSkipTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.GrayScaleConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.HashConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.InitTrackerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.KLRewardTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.LineariseRewardsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiActionConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiStepTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.NoopResetEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ObservationNormConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PermuteTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PinMemoryTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.R3MTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RandomCropTensorDictConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RemoveEmptySpecsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RenameTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ResizeConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.Reward2GoTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardClippingConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardScalingConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardSumConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SelectTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SignTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SqueezeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StackConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StepCounterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TargetReturnConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TensorDictPrimerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimeMaxPoolConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ToTensorImageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TokenizerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TrajCounterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnaryTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnsqueezeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VC1TransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPRewardTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecGymEnvTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormV2Config.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.ASGDConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdadeltaConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdagradConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamWConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamaxConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.LBFGSConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.LionConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.NAdamConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.RAdamConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.RMSpropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.RpropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.SGDConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.SparseAdamConfig.rst", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip.rst", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout.rst", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_dqn_loss.rst", "reference/generated/torchrl.trainers.helpers.make_replay_buffer.rst", "reference/generated/torchrl.trainers.helpers.make_target_updater.rst", "reference/generated/torchrl.trainers.helpers.make_trainer.rst", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor.rst", "reference/generated/torchrl.trainers.helpers.sync_async_collector.rst", "reference/generated/torchrl.trainers.helpers.sync_sync_collector.rst", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor.rst", "reference/generated/torchrl.weight_update.DistributedTransport.rst", "reference/generated/torchrl.weight_update.DistributedWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.MPTransport.rst", "reference/generated/torchrl.weight_update.MultiProcessWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.NoWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.RPCTransport.rst", "reference/generated/torchrl.weight_update.RPCWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.RayModuleTransformScheme.rst", "reference/generated/torchrl.weight_update.RayTransport.rst", "reference/generated/torchrl.weight_update.RayWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.SharedMemTransport.rst", "reference/generated/torchrl.weight_update.SharedMemWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.TransportBackend.rst", "reference/generated/torchrl.weight_update.WeightStrategy.rst", "reference/generated/torchrl.weight_update.WeightSyncScheme.rst", "reference/generated/torchrl.weight_update.llm.VLLMCollectiveTransport.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferTransport.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightSender.rst", "reference/generated/torchrl.weight_update.llm.VLLMWeightReceiver.rst", "reference/generated/torchrl.weight_update.llm.VLLMWeightSender.rst", "reference/generated/torchrl.weight_update.llm.VLLMWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.llm.get_model_metadata.rst", "reference/generated/tutorials/README.rst", "reference/index.rst", "reference/knowledge_base.rst", "reference/llms.rst", "reference/llms_collectors.rst", "reference/llms_data.rst", "reference/llms_envs.rst", "reference/llms_modules.rst", "reference/llms_objectives.rst", "reference/llms_transforms.rst", "reference/modules.rst", "reference/modules_actors.rst", "reference/modules_critics.rst", "reference/modules_distributions.rst", "reference/modules_exploration.rst", "reference/modules_models.rst", "reference/modules_utils.rst", "reference/objectives.rst", "reference/objectives_actorcritic.rst", "reference/objectives_common.rst", "reference/objectives_offline.rst", "reference/objectives_other.rst", "reference/objectives_policy.rst", "reference/objectives_value.rst", "reference/services.rst", "reference/trainers.rst", "reference/trainers_basics.rst", "reference/trainers_hooks.rst", "reference/trainers_loggers.rst", "reference/utils.rst", "sg_execution_times.rst", "tutorials/coding_ddpg.rst", "tutorials/coding_dqn.rst", "tutorials/coding_ppo.rst", "tutorials/dqn_with_rnn.rst", "tutorials/export.rst", "tutorials/getting-started-0.rst", "tutorials/getting-started-1.rst", "tutorials/getting-started-2.rst", "tutorials/getting-started-3.rst", "tutorials/getting-started-4.rst", "tutorials/getting-started-5.rst", "tutorials/index.rst", "tutorials/llm_browser.rst", "tutorials/llm_wrappers.rst", "tutorials/multi_task.rst", "tutorials/multiagent_competitive_ddpg.rst", "tutorials/multiagent_ppo.rst", "tutorials/pendulum.rst", "tutorials/pretrained_models.rst", "tutorials/rb_tutorial.rst", "tutorials/sg_execution_times.rst", "tutorials/torchrl_demo.rst", "tutorials/torchrl_envs.rst"], "titles": ["TorchRL", "torchrl.collectors package", "Collector Basics", "Distributed Collectors", "Collectors and Replay Buffers", "Single Node Collectors", "Weight Synchronization", "TorchRL Configuration System", "&lt;no title&gt;", "&lt;no title&gt;", "torchrl.data package", "Datasets", "Replay Buffers", "Sampling Strategies", "TensorSpec System", "Storage Backends", "torchrl.envs package", "Environment API", "Library Wrappers", "Multi-agent Environments", "Recorders", "Transforms", "Vectorized and Parallel Environments", "Things to consider when debugging RL", "Working with gym", "Working with <code class=\"docutils literal notranslate\"><span class=\"pre\">habitat-lab</span></code>", "Working with MuJoCo-based environments", "Common PyTorch errors and solutions", "Useful resources", "Versioning Issues", "Customising Video Renders", "auto_unwrap_transformed_env", "AsyncCollector", "BaseCollector", "Collector", "MultiAsyncCollector", "MultiCollector", "MultiProcessedWeightUpdater", "MultiSyncCollector", "RayWeightUpdater", "VanillaWeightUpdater", "WeightUpdaterBase", "DistributedCollector", "DistributedDataCollector", "DistributedSyncCollector", "DistributedSyncDataCollector", "DistributedWeightUpdater", "RPCCollector", "RPCDataCollector", "RPCWeightUpdater", "RayCollector", "submitit_delayed_launcher", "LLMCollector", "RayLLMCollector", "vLLMUpdater", "vLLMUpdaterV2", "split_trajectories", "Binary", "Bounded", "Categorical", "Composite", "MultiCategorical", "MultiOneHot", "NonTensor", "OneHot", "PrioritizedReplayBuffer", "RayReplayBuffer", "RemoteTensorDictReplayBuffer", "ReplayBuffer", "ReplayBufferEnsemble", "Stacked", "StackedComposite", "TensorDictPrioritizedReplayBuffer", "TensorDictReplayBuffer", "TensorSpec", "Unbounded", "UnboundedContinuous", "UnboundedDiscrete", "AtariDQNExperienceReplay", "D4RLExperienceReplay", "GenDGRLExperienceReplay", "MinariExperienceReplay", "OpenMLExperienceReplay", "OpenXExperienceReplay", "RobosetExperienceReplay", "VD4RLExperienceReplay", "ContentBase", "History", "TopKRewardSelector", "add_chat_template", "CompressedListStorage", "CompressedListStorageCheckpointer", "FlatStorageCheckpointer", "H5StorageCheckpointer", "ImmutableDatasetWriter", "LazyMemmapStorage", "LazyStackStorage", "LazyTensorStorage", "ListStorage", "ListStorageCheckpointer", "NestedStorageCheckpointer", "PrioritizedSampler", "PrioritizedSliceSampler", "RandomSampler", "RoundRobinWriter", "Sampler", "SamplerEnsemble", "SamplerWithoutReplacement", "SliceSampler", "SliceSamplerWithoutReplacement", "Storage", "StorageCheckpointerBase", "StorageEnsemble", "StorageEnsembleCheckpointer", "TensorDictMaxValueWriter", "TensorDictRoundRobinWriter", "TensorStorage", "TensorStorageCheckpointer", "Writer", "WriterEnsemble", "AsyncEnvPool", "BraxEnv", "BraxWrapper", "ChessEnv", "DMControlEnv", "DMControlWrapper", "EnvBase", "EnvCreator", "EnvMetaData", "GymEnv", "GymLikeEnv", "GymWrapper", "HabitatEnv", "IsaacGymEnv", "IsaacGymWrapper", "IsaacLabWrapper", "JumanjiEnv", "JumanjiWrapper", "LLMHashingEnv", "MOGymEnv", "MOGymWrapper", "MarlGroupMapType", "MeltingpotEnv", "MeltingpotWrapper", "ModelBasedEnvBase", "MultiThreadedEnv", "MultiThreadedEnvWrapper", "OpenMLEnv", "OpenSpielEnv", "OpenSpielWrapper", "ParallelEnv", "PendulumEnv", "PettingZooEnv", "PettingZooWrapper", "ProcessorAsyncEnvPool", "RoboHiveEnv", "SMACv2Env", "SMACv2Wrapper", "SerialEnv", "ThreadingAsyncEnvPool", "TicTacToeEnv", "UnityMLAgentsEnv", "UnityMLAgentsWrapper", "VmasEnv", "VmasWrapper", "check_env_specs", "check_marl_grouping", "exploration_type", "get_available_libraries", "gym_backend", "ChatEnv", "DatasetChatEnv", "GSM8KEnv", "GSM8KPrepareQuestion", "GSM8KRewardParser", "IFEvalEnv", "IFEvalScoreData", "IfEvalScorer", "LLMEnv", "LLMHashingEnv", "MLGymWrapper", "make_gsm8k_env", "make_mlgym", "AddThinkingPrompt", "BrowserTransform", "DataLoadingPrimer", "ExecuteToolsInOrder", "JSONCallParser", "KLComputation", "KLRewardTransform", "MCPToolTransform", "PolicyVersion", "PythonExecutorService", "PythonInterpreter", "RayDataLoadingPrimer", "RetrieveKL", "RetrieveLogProb", "SimpleToolTransform", "TemplateTransform", "Tokenizer", "ToolCall", "ToolRegistry", "ToolService", "XMLBlockParser", "as_nested_tensor", "as_padded_tensor", "make_composite_from_td", "DreamerDecoder", "DreamerEnv", "register_gym_spec_conversion", "set_exploration_type", "set_gym_backend", "step_mdp", "terminated_or_truncated", "ActionDiscretizer", "ActionMask", "AutoResetEnv", "AutoResetTransform", "BatchSizeTransform", "BinarizeReward", "BurnInTransform", "CatFrames", "CatTensors", "CenterCrop", "ClipTransform", "Compose", "ConditionalPolicySwitch", "ConditionalSkip", "Crop", "DTypeCastTransform", "DeviceCastTransform", "DiscreteActionProjection", "DoubleToFloat", "EndOfLifeTransform", "ExcludeTransform", "FiniteTensorDictCheck", "FlattenObservation", "FrameSkipTransform", "GrayScale", "Hash", "InitTracker", "KLRewardTransform", "LineariseRewards", "ModuleTransform", "MultiAction", "NoopResetEnv", "ObservationNorm", "ObservationTransform", "PermuteTransform", "PinMemoryTransform", "R3MTransform", "RandomCropTensorDict", "RemoveEmptySpecs", "RenameTransform", "Resize", "Reward2GoTransform", "RewardClipping", "RewardScaling", "RewardSum", "SelectTransform", "SignTransform", "SqueezeTransform", "Stack", "StepCounter", "TargetReturn", "TensorDictPrimer", "TimeMaxPool", "Timer", "ToTensorImage", "Tokenizer", "TrajCounter", "Transform", "TransformedEnv", "UnaryTransform", "UnsqueezeTransform", "VC1Transform", "VIPRewardTransform", "VIPTransform", "VecGymEnvTransform", "VecNorm", "VecNormV2", "gSDENoise", "implement_for", "ActorCriticOperator", "ActorCriticWrapper", "ActorValueOperator", "AdditiveGaussianModule", "ConsistentDropoutModule", "ConvNet", "DTActor", "DdpgCnnActor", "DdpgCnnQNet", "DdpgMlpActor", "DdpgMlpQNet", "DecisionTransformer", "Delta", "DistributionalDQNnet", "DistributionalQValueActor", "DistributionalQValueModule", "DreamerActor", "DuelingCnnDQNet", "EGreedyModule", "GRUModule", "IndependentNormal", "LSTMModule", "MLP", "MaskedCategorical", "NormalParamExtractor", "ObsDecoder", "ObsEncoder", "OneHotCategorical", "OnlineDTActor", "OrnsteinUhlenbeckProcessModule", "QValueActor", "QValueModule", "RSSMPosterior", "RSSMPrior", "RSSMRollout", "ReparamGradientStrategy", "TanhDelta", "TanhNormal", "TruncatedNormal", "ValueOperator", "WorldModelWrapper", "AsyncVLLM", "ChatHistory", "LLMWrapperBase", "LogProbs", "Masks", "RemoteTransformersWrapper", "Text", "Tokens", "TransformersWrapper", "make_async_vllm_engine", "make_vllm_worker", "stateless_init_process_group", "stateless_init_process_group_async", "vLLMWrapper", "SquashDims", "Actor", "MultiStepActorWrapper", "ProbabilisticActor", "RandomPolicy", "SafeModule", "SafeProbabilisticModule", "SafeProbabilisticTensorDictSequential", "SafeSequential", "TanhModule", "A2CLoss", "CQLLoss", "ClipPPOLoss", "CrossQLoss", "DDPGLoss", "DQNLoss", "DTLoss", "DiscreteCQLLoss", "DiscreteIQLLoss", "DiscreteSACLoss", "DistributionalDQNLoss", "DreamerActorLoss", "DreamerModelLoss", "DreamerValueLoss", "GAILLoss", "IQLLoss", "KLPENPPOLoss", "LossModule", "OnlineDTLoss", "PPOLoss", "REDQLoss", "ReinforceLoss", "SACLoss", "TD3BCLoss", "TD3Loss", "ValueEstimators", "add_random_module", "CISPOLoss", "CISPOLossOutput", "DAPO", "DAPOLossOutput", "GRPOLoss", "GRPOLossOutput", "LLMLossOutput", "MCAdvantage", "SFTLoss", "SFTLossOutput", "GAE", "TD0Estimator", "TD1Estimator", "TDLambdaEstimator", "ValueEstimatorBase", "PixelRenderTransform", "TensorDictRecorder", "VideoRecorder", "Logger", "CSVLogger", "generate_exp_name", "get_logger", "MLFlowLogger", "TensorboardLogger", "WandbLogger", "RayService", "ServiceBase", "get_services", "set_auto_unwrap_transformed_env", "BatchSubSampler", "ClearCudaCache", "CountFramesLog", "LogScalar", "LogValidationReward", "OptimizerHook", "ReplayBufferTrainer", "RewardNormalizer", "SelectKeys", "TargetNetUpdaterHook", "Trainer", "TrainerHookBase", "UTDRHook", "UpdateWeights", "PPOTrainer", "SACTrainer", "torchrl.trainers.algorithms.configs.collectors.AsyncDataCollectorConfig", "torchrl.trainers.algorithms.configs.collectors.SyncDataCollectorConfig", "torchrl.trainers.algorithms.configs.common.ConfigBase", "torchrl.trainers.algorithms.configs.data.LazyMemmapStorageConfig", "torchrl.trainers.algorithms.configs.data.LazyStackStorageConfig", "torchrl.trainers.algorithms.configs.data.LazyTensorStorageConfig", "torchrl.trainers.algorithms.configs.data.ListStorageConfig", "torchrl.trainers.algorithms.configs.data.PrioritizedSamplerConfig", "torchrl.trainers.algorithms.configs.data.RandomSamplerConfig", "torchrl.trainers.algorithms.configs.data.ReplayBufferConfig", "torchrl.trainers.algorithms.configs.data.RoundRobinWriterConfig", "torchrl.trainers.algorithms.configs.data.SamplerWithoutReplacementConfig", "torchrl.trainers.algorithms.configs.data.SliceSamplerConfig", "torchrl.trainers.algorithms.configs.data.SliceSamplerWithoutReplacementConfig", "torchrl.trainers.algorithms.configs.data.StorageEnsembleConfig", "torchrl.trainers.algorithms.configs.data.StorageEnsembleWriterConfig", "torchrl.trainers.algorithms.configs.data.TensorDictReplayBufferConfig", "torchrl.trainers.algorithms.configs.data.TensorStorageConfig", "torchrl.trainers.algorithms.configs.envs.BatchedEnvConfig", "torchrl.trainers.algorithms.configs.envs.EnvConfig", "torchrl.trainers.algorithms.configs.envs.TransformedEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.BraxEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.DMControlEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.EnvLibsConfig", "torchrl.trainers.algorithms.configs.envs_libs.GymEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.HabitatEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.IsaacGymEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.JumanjiEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.MOGymEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.MeltingpotEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.MultiThreadedEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.OpenMLEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.OpenSpielEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.PettingZooEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.RoboHiveEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.SMACv2EnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.UnityMLAgentsEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.VmasEnvConfig", "torchrl.trainers.algorithms.configs.logging.CSVLoggerConfig", "torchrl.trainers.algorithms.configs.logging.LoggerConfig", "torchrl.trainers.algorithms.configs.logging.TensorboardLoggerConfig", "torchrl.trainers.algorithms.configs.logging.WandbLoggerConfig", "torchrl.trainers.algorithms.configs.modules.ConvNetConfig", "torchrl.trainers.algorithms.configs.modules.MLPConfig", "torchrl.trainers.algorithms.configs.modules.ModelConfig", "torchrl.trainers.algorithms.configs.modules.NetworkConfig", "torchrl.trainers.algorithms.configs.modules.TanhNormalModelConfig", "torchrl.trainers.algorithms.configs.modules.TensorDictModuleConfig", "torchrl.trainers.algorithms.configs.modules.ValueModelConfig", "torchrl.trainers.algorithms.configs.objectives.LossConfig", "torchrl.trainers.algorithms.configs.objectives.PPOLossConfig", "torchrl.trainers.algorithms.configs.trainers.PPOTrainerConfig", "torchrl.trainers.algorithms.configs.trainers.TrainerConfig", "torchrl.trainers.algorithms.configs.transforms.ActionDiscretizerConfig", "torchrl.trainers.algorithms.configs.transforms.ActionMaskConfig", "torchrl.trainers.algorithms.configs.transforms.AutoResetTransformConfig", "torchrl.trainers.algorithms.configs.transforms.BatchSizeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.BinarizeRewardConfig", "torchrl.trainers.algorithms.configs.transforms.BurnInTransformConfig", "torchrl.trainers.algorithms.configs.transforms.CatFramesConfig", "torchrl.trainers.algorithms.configs.transforms.CatTensorsConfig", "torchrl.trainers.algorithms.configs.transforms.CenterCropConfig", "torchrl.trainers.algorithms.configs.transforms.ClipTransformConfig", "torchrl.trainers.algorithms.configs.transforms.ComposeConfig", "torchrl.trainers.algorithms.configs.transforms.ConditionalPolicySwitchConfig", "torchrl.trainers.algorithms.configs.transforms.ConditionalSkipConfig", "torchrl.trainers.algorithms.configs.transforms.CropConfig", "torchrl.trainers.algorithms.configs.transforms.DTypeCastTransformConfig", "torchrl.trainers.algorithms.configs.transforms.DeviceCastTransformConfig", "torchrl.trainers.algorithms.configs.transforms.DiscreteActionProjectionConfig", "torchrl.trainers.algorithms.configs.transforms.DoubleToFloatConfig", "torchrl.trainers.algorithms.configs.transforms.EndOfLifeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.ExcludeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.FiniteTensorDictCheckConfig", "torchrl.trainers.algorithms.configs.transforms.FlattenObservationConfig", "torchrl.trainers.algorithms.configs.transforms.FrameSkipTransformConfig", "torchrl.trainers.algorithms.configs.transforms.GrayScaleConfig", "torchrl.trainers.algorithms.configs.transforms.HashConfig", "torchrl.trainers.algorithms.configs.transforms.InitTrackerConfig", "torchrl.trainers.algorithms.configs.transforms.KLRewardTransformConfig", "torchrl.trainers.algorithms.configs.transforms.LineariseRewardsConfig", "torchrl.trainers.algorithms.configs.transforms.MultiActionConfig", "torchrl.trainers.algorithms.configs.transforms.MultiStepTransformConfig", "torchrl.trainers.algorithms.configs.transforms.NoopResetEnvConfig", "torchrl.trainers.algorithms.configs.transforms.ObservationNormConfig", "torchrl.trainers.algorithms.configs.transforms.PermuteTransformConfig", "torchrl.trainers.algorithms.configs.transforms.PinMemoryTransformConfig", "torchrl.trainers.algorithms.configs.transforms.R3MTransformConfig", "torchrl.trainers.algorithms.configs.transforms.RandomCropTensorDictConfig", "torchrl.trainers.algorithms.configs.transforms.RemoveEmptySpecsConfig", "torchrl.trainers.algorithms.configs.transforms.RenameTransformConfig", "torchrl.trainers.algorithms.configs.transforms.ResizeConfig", "torchrl.trainers.algorithms.configs.transforms.Reward2GoTransformConfig", "torchrl.trainers.algorithms.configs.transforms.RewardClippingConfig", "torchrl.trainers.algorithms.configs.transforms.RewardScalingConfig", "torchrl.trainers.algorithms.configs.transforms.RewardSumConfig", "torchrl.trainers.algorithms.configs.transforms.SelectTransformConfig", "torchrl.trainers.algorithms.configs.transforms.SignTransformConfig", "torchrl.trainers.algorithms.configs.transforms.SqueezeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.StackConfig", "torchrl.trainers.algorithms.configs.transforms.StepCounterConfig", "torchrl.trainers.algorithms.configs.transforms.TargetReturnConfig", "torchrl.trainers.algorithms.configs.transforms.TensorDictPrimerConfig", "torchrl.trainers.algorithms.configs.transforms.TimeMaxPoolConfig", "torchrl.trainers.algorithms.configs.transforms.TimerConfig", "torchrl.trainers.algorithms.configs.transforms.ToTensorImageConfig", "torchrl.trainers.algorithms.configs.transforms.TokenizerConfig", "torchrl.trainers.algorithms.configs.transforms.TrajCounterConfig", "torchrl.trainers.algorithms.configs.transforms.TransformConfig", "torchrl.trainers.algorithms.configs.transforms.UnaryTransformConfig", "torchrl.trainers.algorithms.configs.transforms.UnsqueezeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VC1TransformConfig", "torchrl.trainers.algorithms.configs.transforms.VIPRewardTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VIPTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VecGymEnvTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VecNormConfig", "torchrl.trainers.algorithms.configs.transforms.VecNormV2Config", "torchrl.trainers.algorithms.configs.utils.ASGDConfig", "torchrl.trainers.algorithms.configs.utils.AdadeltaConfig", "torchrl.trainers.algorithms.configs.utils.AdagradConfig", "torchrl.trainers.algorithms.configs.utils.AdamConfig", "torchrl.trainers.algorithms.configs.utils.AdamWConfig", "torchrl.trainers.algorithms.configs.utils.AdamaxConfig", "torchrl.trainers.algorithms.configs.utils.LBFGSConfig", "torchrl.trainers.algorithms.configs.utils.LionConfig", "torchrl.trainers.algorithms.configs.utils.NAdamConfig", "torchrl.trainers.algorithms.configs.utils.RAdamConfig", "torchrl.trainers.algorithms.configs.utils.RMSpropConfig", "torchrl.trainers.algorithms.configs.utils.RpropConfig", "torchrl.trainers.algorithms.configs.utils.SGDConfig", "torchrl.trainers.algorithms.configs.utils.SparseAdamConfig", "correct_for_frame_skip", "get_stats_random_rollout", "make_collector_offpolicy", "make_collector_onpolicy", "make_dqn_loss", "make_replay_buffer", "make_target_updater", "make_trainer", "parallel_env_constructor", "sync_async_collector", "sync_sync_collector", "transformed_env_constructor", "DistributedTransport", "DistributedWeightSyncScheme", "MPTransport", "MultiProcessWeightSyncScheme", "NoWeightSyncScheme", "RPCTransport", "RPCWeightSyncScheme", "RayModuleTransformScheme", "RayTransport", "RayWeightSyncScheme", "SharedMemTransport", "SharedMemWeightSyncScheme", "TransportBackend", "WeightStrategy", "WeightSyncScheme", "VLLMCollectiveTransport", "VLLMDoubleBufferSyncScheme", "VLLMDoubleBufferTransport", "VLLMDoubleBufferWeightReceiver", "VLLMDoubleBufferWeightSender", "VLLMWeightReceiver", "VLLMWeightSender", "VLLMWeightSyncScheme", "get_model_metadata", "README Tutos", "API Reference", "Knowledge Base", "LLM Interface", "LLM Collectors", "Data Structures", "LLM Environments", "LLM Wrappers", "LLM Objectives", "LLM Transforms", "torchrl.modules package", "Actor Modules", "Value Networks and Critics", "Distribution Classes", "Exploration Strategies", "World Models and Model-Based RL", "Utilities and Helpers", "torchrl.objectives package", "Actor-Critic Methods", "Common Components", "Offline RL Methods", "Other Loss Modules", "Policy Gradient Methods", "Value-Based Methods", "Service Registry", "torchrl.trainers package", "Trainer Basics", "Training Hooks", "Loggers", "torchrl._utils package", "Computation times", "TorchRL objectives: Coding a DDPG loss", "TorchRL trainer: A DQN example", "Reinforcement Learning (PPO) with TorchRL Tutorial", "Recurrent DQN: Training recurrent policies", "Exporting TorchRL modules", "Get started with Environments, TED and transforms", "Get started with TorchRL\u2019s modules", "Getting started with model optimization", "Get started with data collection and storage", "Get started with logging", "Get started with your own first training loop", "README Tutos", "TorchRL LLM: Building Tool-Enabled Environments", "LLM Wrappers in TorchRL", "Task-specific policy in multi-task environments", "Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial", "Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial", "Pendulum: Writing your environment and transforms with TorchRL", "Using pretrained models", "Using Replay Buffers", "Computation times", "Introduction to TorchRL", "TorchRL envs"], "terms": {"an": [0, 2, 6, 12, 16, 17, 18, 19, 20, 21, 22, 24, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 94, 95, 96, 97, 98, 102, 104, 106, 108, 109, 110, 112, 114, 115, 116, 118, 119, 120, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 137, 138, 144, 145, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 165, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 214, 215, 217, 218, 220, 221, 223, 229, 231, 232, 235, 239, 243, 245, 246, 250, 251, 252, 253, 255, 264, 265, 266, 267, 268, 270, 271, 272, 275, 278, 279, 280, 283, 284, 285, 288, 290, 291, 292, 293, 295, 297, 298, 301, 302, 304, 305, 312, 313, 320, 323, 324, 325, 326, 327, 328, 330, 331, 332, 333, 335, 336, 337, 338, 340, 341, 344, 345, 348, 349, 350, 351, 353, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 395, 399, 402, 408, 409, 414, 415, 418, 419, 552, 559, 560, 561, 562, 566, 574, 589, 590, 618, 619, 622, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 636, 637, 639, 640], "open": [0, 24, 26, 83, 86, 87, 95, 176, 282, 325, 327, 328, 330, 331, 335, 336, 376, 378, 380, 381, 384, 619, 630, 633, 634, 639], "sourc": [0, 2, 4, 23, 26, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "reinforc": [0, 7, 15, 22, 28, 80, 142, 143, 170, 171, 221, 280, 290, 291, 292, 293, 298, 312, 348, 349, 351, 354, 355, 356, 358, 363, 369, 370, 371, 418, 590, 602, 604, 607, 617, 619, 623, 624, 629, 631, 635, 638, 639], "learn": [0, 7, 15, 19, 22, 26, 27, 28, 42, 80, 81, 82, 84, 85, 86, 87, 101, 102, 126, 142, 143, 147, 150, 158, 170, 171, 176, 177, 221, 280, 290, 291, 292, 293, 298, 312, 325, 327, 328, 330, 331, 348, 349, 350, 351, 354, 355, 356, 358, 362, 363, 367, 368, 369, 370, 371, 376, 378, 379, 380, 381, 384, 418, 419, 590, 602, 604, 607, 617, 618, 619, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 635, 637, 638, 639, 640], "rl": [0, 2, 6, 10, 11, 12, 16, 18, 22, 24, 27, 29, 32, 34, 35, 38, 78, 135, 144, 170, 221, 264, 322, 332, 337, 339, 341, 348, 350, 364, 365, 367, 369, 379, 404, 587, 588, 589, 597, 598, 600, 603, 604, 610, 618, 619, 620, 626, 629, 633, 634, 636, 637, 640], "librari": [0, 2, 3, 6, 10, 16, 17, 20, 22, 24, 25, 26, 27, 28, 29, 30, 35, 36, 38, 42, 44, 47, 123, 124, 125, 134, 145, 168, 177, 190, 324, 402, 588, 589, 616, 618, 619, 620, 622, 623, 624, 626, 633, 634, 635, 640], "pytorch": [0, 2, 3, 6, 19, 20, 56, 81, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 175, 178, 179, 180, 221, 267, 268, 414, 576, 578, 587, 589, 600, 618, 620, 621, 625, 629, 633, 634, 635, 639, 640], "you": [0, 2, 5, 6, 7, 12, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 54, 80, 87, 88, 89, 120, 123, 126, 130, 134, 138, 141, 142, 143, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 221, 242, 271, 279, 280, 326, 332, 337, 344, 367, 375, 377, 379, 382, 383, 399, 403, 585, 589, 590, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "can": [0, 2, 3, 4, 6, 7, 8, 12, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 101, 102, 107, 108, 109, 114, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 134, 136, 137, 138, 141, 142, 143, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 202, 209, 211, 213, 214, 215, 217, 218, 220, 221, 224, 225, 227, 229, 231, 232, 233, 236, 239, 244, 245, 246, 250, 251, 255, 258, 262, 263, 264, 265, 269, 270, 271, 272, 273, 275, 277, 279, 280, 282, 287, 288, 290, 297, 298, 301, 302, 303, 304, 306, 307, 312, 313, 314, 321, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 337, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 399, 400, 401, 403, 407, 408, 418, 464, 560, 561, 562, 564, 566, 567, 569, 570, 572, 573, 574, 575, 576, 577, 579, 584, 585, 589, 590, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "directli": [0, 6, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 69, 78, 81, 88, 120, 121, 122, 123, 126, 129, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 246, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 273, 275, 276, 278, 279, 280, 324, 329, 344, 365, 371, 375, 377, 379, 382, 383, 562, 564, 566, 569, 570, 572, 573, 577, 579, 585, 590, 619, 620, 621, 622, 623, 633, 634, 635, 637], "from": [0, 1, 2, 4, 5, 6, 7, 10, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 96, 97, 98, 101, 102, 106, 107, 108, 109, 110, 112, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 206, 211, 212, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 239, 240, 241, 242, 246, 248, 250, 251, 252, 253, 254, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 277, 278, 279, 280, 282, 283, 284, 285, 287, 290, 291, 292, 293, 294, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 317, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 400, 404, 407, 410, 414, 416, 417, 418, 419, 427, 428, 432, 471, 551, 552, 556, 558, 559, 562, 563, 564, 565, 566, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 589, 590, 597, 604, 611, 612, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640], "pypi": [0, 639], "see": [0, 1, 3, 17, 18, 19, 21, 22, 25, 26, 27, 28, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 96, 102, 108, 109, 120, 123, 126, 130, 133, 135, 137, 138, 142, 143, 145, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 225, 227, 244, 250, 265, 268, 270, 271, 272, 275, 277, 279, 280, 281, 283, 285, 287, 288, 302, 303, 304, 305, 307, 317, 321, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 344, 350, 351, 362, 364, 365, 367, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 399, 400, 410, 418, 564, 566, 569, 570, 572, 573, 574, 577, 579, 585, 588, 590, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 630, 633, 634, 635, 637, 639, 640], "more": [0, 2, 6, 9, 17, 21, 22, 23, 25, 27, 28, 32, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 49, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 101, 102, 114, 120, 123, 126, 129, 130, 131, 133, 134, 137, 138, 142, 143, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 268, 271, 275, 280, 281, 282, 286, 287, 297, 298, 305, 307, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 339, 343, 344, 348, 358, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 399, 400, 409, 585, 588, 589, 590, 604, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 630, 631, 632, 633, 634, 635, 636, 639, 640], "about": [0, 21, 24, 26, 28, 42, 44, 47, 49, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 81, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 183, 195, 326, 332, 337, 618, 619, 620, 622, 623, 624, 625, 626, 627, 628, 633, 634, 635, 637, 639, 640], "instruct": [0, 6, 25, 26, 29, 51, 79, 87, 135, 172, 177, 231, 233, 563, 566, 574, 590, 618, 619, 620, 621, 630, 633, 634, 637], "dedic": [0, 3, 6, 19, 42, 44, 47, 50, 68, 69, 72, 73, 150, 158, 283, 284, 285, 324, 573, 590, 618, 623, 625, 626, 628, 632, 634], "section": [0, 7, 17, 23, 126, 588, 619, 622, 623, 628, 633, 634], "below": [0, 1, 6, 17, 22, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 68, 72, 73, 75, 86, 87, 88, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 227, 244, 250, 265, 270, 271, 272, 275, 277, 288, 303, 305, 317, 321, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 350, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 410, 618, 619, 620, 621, 622, 623, 633, 635], "pip": [0, 29, 82, 190, 622, 623, 624, 625, 626, 627, 628, 630, 634, 639, 640], "provid": [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 15, 16, 17, 18, 19, 21, 22, 24, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 98, 101, 102, 103, 106, 108, 109, 117, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 218, 220, 221, 222, 223, 224, 228, 229, 232, 236, 239, 243, 245, 246, 248, 250, 251, 254, 255, 258, 259, 264, 265, 266, 269, 270, 272, 274, 275, 277, 278, 279, 280, 282, 288, 294, 295, 298, 301, 302, 304, 305, 306, 313, 314, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 337, 339, 340, 341, 344, 347, 348, 349, 350, 351, 352, 353, 355, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 396, 400, 401, 404, 410, 416, 417, 422, 552, 558, 564, 566, 584, 589, 590, 592, 594, 604, 611, 612, 618, 619, 620, 621, 622, 623, 624, 626, 627, 631, 632, 633, 634, 635, 636, 637, 639, 640], "python": [0, 5, 7, 22, 24, 25, 26, 29, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 146, 161, 162, 170, 190, 192, 193, 211, 302, 304, 306, 588, 590, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "first": [0, 1, 2, 5, 6, 9, 17, 18, 19, 20, 22, 23, 24, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 95, 97, 102, 108, 109, 114, 116, 120, 123, 126, 129, 130, 131, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 186, 217, 218, 221, 222, 226, 227, 236, 244, 246, 250, 251, 267, 268, 272, 275, 280, 282, 288, 295, 297, 298, 302, 304, 305, 306, 309, 313, 324, 331, 339, 341, 343, 344, 350, 360, 364, 365, 367, 375, 377, 379, 383, 391, 392, 412, 572, 617, 618, 619, 620, 621, 622, 623, 626, 627, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640], "low": [0, 6, 18, 58, 60, 74, 75, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 183, 206, 214, 224, 231, 239, 242, 265, 273, 298, 319, 320, 321, 341, 344, 347, 367, 482, 618, 619, 620, 622, 633, 634, 635, 639], "high": [0, 1, 18, 22, 28, 58, 60, 72, 75, 86, 87, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 183, 206, 214, 224, 231, 239, 242, 245, 265, 273, 298, 319, 320, 321, 325, 327, 328, 330, 331, 341, 344, 347, 367, 376, 378, 380, 381, 384, 385, 482, 584, 612, 618, 619, 620, 631, 633, 634, 635, 637, 639], "level": [0, 6, 19, 21, 22, 23, 35, 36, 38, 51, 60, 65, 66, 68, 69, 71, 86, 87, 90, 129, 131, 176, 188, 196, 221, 263, 271, 302, 304, 325, 327, 328, 330, 331, 357, 364, 370, 376, 378, 380, 381, 384, 612, 618, 619, 622, 626, 639], "abstract": [0, 19, 27, 41, 74, 78, 82, 118, 126, 247, 389, 401, 405, 415, 422, 575, 577, 620, 622, 635, 639], "ar": [0, 1, 2, 3, 5, 6, 7, 9, 10, 12, 17, 18, 19, 20, 21, 22, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 96, 97, 98, 100, 101, 102, 106, 107, 108, 109, 110, 112, 114, 116, 120, 123, 126, 127, 129, 130, 131, 137, 138, 141, 142, 143, 144, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 213, 214, 216, 217, 218, 220, 221, 224, 225, 227, 229, 230, 231, 232, 233, 235, 236, 239, 241, 242, 244, 245, 248, 250, 255, 258, 262, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 278, 279, 280, 286, 293, 295, 297, 301, 302, 304, 306, 307, 310, 313, 316, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 337, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 399, 400, 401, 402, 403, 410, 414, 416, 417, 418, 419, 558, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 577, 579, 583, 585, 590, 597, 604, 611, 616, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "intend": [0, 6, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 220, 231, 365, 639], "effici": [0, 1, 3, 6, 9, 10, 12, 23, 27, 39, 91, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 192, 332, 351, 416, 566, 571, 590, 592, 604, 611, 618, 619, 620, 621, 622, 625, 626, 628, 632, 633, 634, 636, 637, 639], "modular": [0, 7, 78, 189, 346, 597, 612, 622, 637, 639], "document": [0, 6, 24, 26, 30, 42, 44, 47, 50, 83, 88, 120, 123, 126, 130, 135, 138, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 326, 332, 337, 375, 377, 379, 382, 383, 587, 588, 611, 619, 621, 622, 623, 626, 629, 639], "properli": [0, 4, 5, 21, 22, 52, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 195, 196, 212, 227, 302, 304, 385, 590, 620, 621, 627, 633, 634, 635, 639], "test": [0, 7, 20, 22, 24, 52, 120, 121, 122, 123, 126, 130, 136, 137, 138, 142, 143, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 183, 185, 270, 275, 408, 558, 579, 580, 583, 584, 590, 611, 620, 621, 622, 636, 639], "The": [0, 1, 2, 3, 5, 6, 7, 9, 10, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 93, 101, 102, 106, 108, 109, 110, 114, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 136, 137, 138, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 205, 209, 212, 213, 214, 217, 218, 220, 221, 225, 226, 227, 229, 232, 233, 234, 239, 242, 243, 244, 246, 248, 250, 255, 257, 258, 259, 262, 263, 264, 265, 267, 270, 271, 272, 275, 277, 278, 279, 280, 283, 286, 290, 291, 292, 293, 294, 297, 298, 302, 304, 306, 307, 312, 313, 314, 315, 316, 317, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 343, 344, 346, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 394, 397, 398, 399, 400, 401, 403, 404, 409, 416, 417, 418, 419, 459, 469, 471, 558, 560, 561, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 582, 583, 585, 590, 592, 593, 594, 611, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 633, 634, 635, 636, 637, 639, 640], "code": [0, 6, 17, 18, 22, 24, 26, 27, 35, 38, 60, 71, 83, 120, 123, 126, 130, 135, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 189, 190, 192, 193, 250, 272, 275, 326, 341, 344, 346, 590, 611, 617, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 636, 637, 638, 639, 640], "aim": [0, 21, 26, 70, 71, 250, 275, 277, 305, 551, 589, 618, 619, 639], "support": [0, 2, 3, 4, 7, 10, 16, 18, 19, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 82, 85, 86, 87, 89, 95, 97, 110, 112, 116, 117, 119, 120, 121, 122, 123, 129, 131, 136, 145, 147, 150, 152, 155, 168, 176, 178, 184, 189, 199, 218, 221, 233, 239, 246, 265, 266, 269, 272, 273, 280, 297, 298, 320, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 341, 343, 346, 358, 365, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 397, 402, 564, 566, 569, 570, 572, 574, 575, 576, 577, 579, 585, 590, 592, 597, 604, 611, 612, 620, 621, 623, 624, 630, 631, 634, 635, 637, 639], "research": [0, 26, 28, 142, 143, 631, 639], "most": [0, 4, 6, 12, 17, 21, 26, 27, 35, 36, 38, 63, 101, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 231, 278, 611, 618, 620, 622, 623, 624, 625, 626, 627, 628, 635, 639, 640], "written": [0, 4, 13, 17, 22, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 93, 95, 102, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 183, 212, 213, 214, 221, 233, 236, 241, 242, 258, 263, 266, 267, 272, 278, 282, 287, 312, 322, 325, 327, 328, 330, 331, 339, 341, 343, 344, 348, 350, 364, 367, 369, 376, 378, 379, 380, 381, 384, 390, 391, 392, 416, 590, 618, 621, 622, 624, 632, 635, 639], "highli": [0, 15, 332, 350, 367, 623, 639, 640], "wai": [0, 1, 2, 4, 5, 19, 21, 22, 23, 50, 60, 69, 71, 78, 81, 114, 134, 171, 172, 175, 195, 221, 225, 250, 253, 270, 271, 277, 278, 302, 304, 367, 385, 386, 387, 388, 419, 590, 611, 618, 619, 620, 622, 623, 625, 626, 632, 633, 634, 635, 636, 637, 639, 640], "easili": [0, 2, 7, 17, 18, 22, 26, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 611, 618, 619, 620, 623, 624, 625, 628, 633, 634, 639, 640], "swap": [0, 2, 16, 17, 129, 278, 620, 622, 636, 639], "compon": [0, 2, 6, 7, 10, 12, 19, 21, 22, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 95, 96, 97, 98, 110, 112, 116, 171, 297, 298, 314, 324, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 409, 414, 588, 604, 618, 619, 620, 621, 622, 624, 625, 628, 630, 632, 633, 634, 635, 636, 639], "transform": [0, 3, 4, 6, 10, 12, 16, 17, 18, 20, 22, 23, 27, 32, 34, 35, 36, 38, 40, 41, 42, 44, 47, 50, 52, 53, 54, 55, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 93, 100, 112, 117, 120, 123, 126, 127, 130, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 207, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 287, 289, 290, 294, 299, 302, 304, 311, 317, 320, 325, 327, 328, 329, 330, 331, 332, 337, 340, 347, 354, 366, 376, 378, 380, 381, 382, 383, 384, 390, 392, 410, 417, 418, 429, 434, 435, 436, 440, 471, 562, 570, 571, 572, 588, 592, 611, 617, 619, 621, 622, 624, 626, 627, 628, 629, 630, 636, 638], "them": [0, 6, 12, 19, 26, 28, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 114, 119, 120, 123, 126, 127, 130, 134, 138, 141, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 199, 229, 232, 239, 242, 265, 269, 272, 273, 279, 280, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 338, 340, 347, 349, 351, 357, 363, 364, 368, 370, 371, 372, 386, 387, 388, 392, 563, 566, 573, 575, 580, 581, 582, 611, 618, 619, 621, 622, 623, 624, 626, 627, 631, 632, 633, 634, 635, 636, 637, 639, 640], "write": [0, 17, 27, 32, 34, 35, 36, 38, 52, 56, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 112, 119, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 213, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 248, 249, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 274, 275, 276, 278, 279, 322, 325, 327, 328, 330, 331, 339, 343, 344, 346, 351, 352, 353, 355, 356, 357, 363, 368, 370, 371, 372, 376, 378, 380, 381, 382, 384, 389, 392, 579, 580, 582, 590, 611, 612, 617, 618, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 632, 633, 634, 636, 637, 638, 639, 640], "new": [0, 2, 6, 7, 18, 21, 23, 27, 32, 34, 35, 36, 38, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 101, 102, 107, 120, 123, 126, 130, 138, 145, 150, 151, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 212, 213, 218, 243, 258, 262, 271, 272, 279, 280, 295, 302, 304, 312, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 343, 344, 348, 349, 350, 353, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 399, 417, 564, 566, 569, 570, 572, 573, 574, 577, 579, 581, 585, 590, 618, 620, 623, 625, 631, 633, 634, 635, 639, 640], "ones": [0, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 86, 87, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 222, 225, 226, 229, 230, 232, 246, 250, 255, 262, 265, 271, 272, 275, 277, 280, 306, 325, 326, 327, 328, 330, 331, 332, 337, 342, 343, 348, 349, 350, 351, 352, 363, 364, 367, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 590, 618, 620, 622, 631, 633, 634, 635, 637, 639, 640], "littl": [0, 4, 5, 17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272, 348, 350, 364, 367, 369, 620, 621, 622, 626, 637, 639, 640], "effort": [0, 16, 17, 18, 324, 635, 637, 639], "thi": [0, 2, 3, 4, 5, 6, 7, 8, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 100, 101, 102, 106, 107, 108, 109, 110, 112, 114, 116, 117, 119, 120, 121, 122, 123, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 147, 150, 151, 152, 153, 154, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 209, 211, 212, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 243, 244, 246, 249, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 320, 321, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 399, 400, 401, 402, 403, 404, 406, 407, 408, 410, 414, 416, 417, 418, 419, 422, 471, 551, 552, 558, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 589, 590, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "repo": [0, 25, 79, 221, 266, 275, 589, 634, 639], "attempt": [0, 32, 34, 35, 36, 38, 42, 44, 47, 50, 86, 87, 88, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 325, 326, 327, 328, 330, 331, 332, 337, 344, 353, 356, 363, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 625, 639], "align": [0, 639], "exist": [0, 19, 23, 32, 34, 35, 36, 38, 42, 50, 52, 53, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 222, 230, 243, 270, 271, 272, 282, 295, 325, 326, 327, 328, 330, 331, 332, 337, 344, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 401, 402, 552, 562, 571, 611, 633, 634, 639, 640], "ecosystem": [0, 622, 626, 639], "ha": [0, 2, 4, 6, 7, 18, 21, 22, 23, 24, 26, 27, 29, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 97, 101, 102, 106, 108, 114, 116, 120, 123, 126, 127, 130, 134, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 218, 221, 243, 244, 263, 264, 265, 266, 267, 269, 270, 271, 272, 286, 298, 302, 304, 320, 325, 326, 327, 328, 330, 331, 332, 337, 340, 344, 348, 351, 364, 365, 367, 369, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 392, 418, 471, 563, 571, 590, 618, 619, 620, 621, 622, 623, 626, 627, 630, 632, 633, 634, 635, 636, 637, 639, 640], "dataset": [0, 10, 65, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 94, 102, 106, 108, 109, 147, 170, 171, 172, 175, 176, 177, 178, 181, 185, 194, 279, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 392, 588, 590, 618, 619, 623, 636, 637, 639, 640], "pillar": [0, 639], "environ": [0, 1, 2, 3, 4, 6, 16, 20, 24, 27, 29, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 66, 70, 71, 74, 75, 76, 77, 88, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 208, 214, 215, 217, 218, 220, 221, 222, 226, 227, 229, 230, 231, 232, 237, 244, 245, 246, 250, 251, 252, 255, 258, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 278, 279, 280, 287, 302, 304, 317, 332, 337, 340, 355, 359, 382, 385, 386, 387, 388, 389, 390, 392, 403, 404, 406, 408, 418, 419, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 471, 551, 552, 553, 554, 558, 559, 560, 561, 562, 588, 589, 596, 611, 617, 622, 624, 625, 626, 627, 629, 636, 637, 638], "model": [0, 2, 3, 6, 17, 19, 27, 28, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 55, 86, 87, 88, 89, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 229, 250, 265, 275, 277, 281, 283, 284, 285, 288, 289, 294, 296, 305, 311, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 343, 348, 349, 350, 351, 353, 354, 355, 356, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 401, 414, 464, 466, 468, 553, 554, 555, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 582, 584, 585, 586, 588, 589, 590, 592, 597, 617, 620, 623, 626, 629, 631, 633, 634, 635, 637, 638, 640], "data": [0, 1, 2, 3, 4, 6, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 27, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 135, 136, 137, 138, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 165, 170, 171, 172, 175, 176, 177, 178, 179, 180, 182, 185, 188, 189, 190, 191, 194, 195, 196, 199, 202, 206, 213, 215, 218, 220, 221, 226, 229, 230, 232, 234, 236, 239, 241, 246, 252, 255, 262, 263, 265, 269, 271, 272, 273, 278, 280, 297, 301, 302, 304, 312, 313, 322, 325, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336, 337, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 376, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 390, 392, 399, 404, 407, 410, 414, 416, 417, 418, 419, 471, 553, 558, 560, 561, 562, 565, 571, 578, 583, 588, 590, 593, 597, 611, 612, 617, 621, 622, 623, 624, 625, 629, 630, 631, 635, 636, 637, 638, 640], "util": [0, 11, 17, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 56, 68, 86, 87, 88, 108, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 143, 150, 151, 152, 153, 154, 158, 159, 160, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 265, 277, 287, 288, 294, 302, 304, 325, 326, 327, 328, 330, 331, 332, 337, 338, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 555, 558, 588, 596, 597, 606, 612, 616, 618, 620, 622, 624, 625, 634, 635, 637, 639, 640], "e": [0, 2, 6, 7, 17, 19, 20, 21, 22, 26, 27, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 89, 90, 95, 97, 101, 102, 114, 116, 120, 123, 126, 127, 130, 131, 138, 150, 151, 154, 158, 159, 160, 163, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 220, 222, 225, 226, 227, 228, 236, 239, 242, 244, 246, 250, 258, 265, 267, 270, 271, 272, 275, 277, 282, 298, 302, 303, 304, 307, 314, 320, 321, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 340, 341, 343, 344, 348, 350, 351, 352, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 401, 404, 414, 418, 471, 551, 561, 564, 565, 566, 567, 569, 570, 571, 572, 574, 577, 578, 579, 582, 585, 590, 611, 619, 620, 622, 624, 625, 627, 631, 633, 634, 636, 637, 639, 640], "g": [0, 2, 6, 7, 17, 19, 20, 21, 22, 26, 27, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 89, 114, 120, 123, 126, 127, 130, 131, 138, 150, 151, 154, 158, 159, 160, 163, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 220, 222, 225, 226, 236, 239, 242, 246, 250, 258, 265, 267, 270, 271, 272, 275, 277, 282, 302, 303, 304, 320, 321, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 341, 343, 344, 351, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 401, 414, 418, 471, 561, 564, 565, 566, 567, 569, 570, 572, 574, 577, 578, 579, 582, 585, 590, 611, 619, 620, 622, 624, 627, 633, 634, 635, 636, 637, 639, 640], "collector": [0, 7, 17, 18, 22, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 255, 263, 271, 302, 304, 312, 326, 329, 332, 337, 342, 350, 364, 367, 379, 382, 410, 414, 417, 418, 419, 471, 553, 554, 558, 560, 561, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 574, 577, 579, 585, 588, 590, 604, 611, 612, 622, 637, 640], "contain": [0, 17, 21, 22, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 94, 102, 104, 106, 108, 109, 110, 115, 118, 119, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 221, 225, 229, 232, 239, 250, 262, 265, 270, 271, 272, 275, 277, 278, 279, 280, 288, 297, 298, 305, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 343, 344, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 396, 404, 551, 558, 559, 560, 561, 562, 573, 580, 581, 590, 604, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 633, 634, 635, 636, 637, 639, 640], "etc": [0, 6, 7, 12, 17, 21, 22, 26, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 262, 272, 282, 305, 320, 326, 332, 337, 375, 377, 379, 382, 383, 400, 564, 565, 566, 567, 569, 570, 572, 574, 577, 579, 585, 597, 619, 620, 626, 637, 639, 640], "have": [0, 2, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 32, 35, 36, 38, 42, 46, 47, 50, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 107, 110, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 209, 213, 214, 217, 221, 226, 229, 232, 233, 241, 245, 246, 262, 263, 265, 269, 270, 271, 272, 279, 280, 286, 288, 305, 306, 312, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 345, 346, 348, 350, 364, 367, 369, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 392, 400, 404, 414, 416, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585, 590, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 632, 633, 634, 635, 636, 637, 639, 640], "few": [0, 12, 27, 86, 87, 109, 130, 176, 180, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 392, 404, 590, 611, 620, 621, 624, 633, 634, 637, 639, 640], "depend": [0, 2, 3, 5, 6, 18, 21, 22, 23, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 58, 75, 120, 123, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 175, 177, 178, 179, 180, 190, 229, 232, 322, 332, 337, 344, 367, 394, 611, 618, 620, 621, 630, 633, 634, 635, 639, 640], "possibl": [0, 19, 20, 22, 23, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 80, 83, 85, 86, 87, 88, 96, 102, 108, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 225, 250, 265, 270, 271, 272, 275, 277, 288, 324, 325, 326, 327, 328, 330, 331, 332, 337, 343, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 408, 414, 590, 618, 620, 621, 622, 624, 626, 627, 633, 634, 635, 637, 639, 640], "standard": [0, 19, 21, 63, 123, 246, 257, 279, 280, 286, 299, 311, 324, 326, 332, 337, 350, 364, 367, 371, 372, 385, 386, 387, 388, 407, 618, 619, 623, 624, 634, 637, 639], "numpi": [0, 20, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 239, 268, 273, 282, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 414, 622, 635, 637, 639, 640], "common": [0, 22, 23, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 74, 88, 120, 130, 136, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 233, 271, 283, 284, 285, 326, 348, 349, 350, 351, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 379, 382, 400, 401, 418, 558, 588, 589, 590, 604, 611, 618, 620, 624, 627, 632, 633, 634, 635, 636, 639, 640], "openai": [0, 26, 129, 131, 138, 155, 179, 620, 635, 639, 640], "gym": [0, 3, 7, 16, 17, 18, 22, 23, 27, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 88, 120, 123, 126, 127, 129, 130, 131, 132, 134, 135, 138, 142, 143, 145, 146, 150, 151, 154, 155, 158, 159, 160, 163, 164, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 209, 211, 217, 221, 224, 233, 240, 241, 246, 248, 253, 255, 258, 265, 271, 278, 279, 282, 382, 448, 558, 589, 618, 619, 620, 621, 623, 627, 628, 635, 636, 637], "onli": [0, 2, 6, 7, 17, 19, 20, 22, 23, 26, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 95, 97, 101, 102, 108, 109, 116, 120, 123, 124, 125, 126, 129, 130, 131, 132, 134, 137, 138, 145, 146, 150, 151, 152, 153, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 217, 221, 222, 224, 225, 226, 227, 229, 231, 232, 236, 239, 244, 246, 250, 251, 255, 262, 263, 264, 265, 266, 270, 271, 272, 275, 277, 279, 280, 282, 297, 304, 306, 313, 326, 329, 332, 337, 339, 341, 343, 344, 345, 346, 348, 350, 351, 352, 356, 357, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 392, 399, 400, 402, 414, 416, 552, 565, 574, 578, 585, 611, 618, 619, 620, 621, 622, 624, 625, 626, 627, 628, 630, 632, 633, 634, 635, 637, 639, 640], "option": [0, 3, 6, 10, 18, 22, 23, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 101, 102, 103, 104, 106, 107, 108, 109, 112, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 205, 206, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 228, 229, 231, 232, 233, 234, 236, 237, 239, 240, 241, 242, 243, 244, 245, 246, 250, 251, 253, 254, 257, 258, 259, 262, 263, 264, 265, 266, 268, 269, 270, 272, 273, 274, 275, 277, 278, 279, 280, 282, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 339, 340, 341, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 394, 397, 399, 400, 401, 402, 404, 406, 407, 408, 409, 410, 411, 414, 417, 418, 419, 471, 552, 558, 560, 561, 562, 564, 566, 567, 569, 570, 571, 572, 574, 577, 578, 579, 582, 584, 585, 588, 590, 621, 623, 626, 633, 634, 637, 639], "On": [0, 5, 19, 21, 26, 42, 44, 47, 50, 60, 80, 566, 574, 579, 590, 619, 633, 634], "end": [0, 6, 17, 32, 35, 36, 38, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 93, 102, 107, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 233, 239, 248, 263, 264, 270, 272, 288, 326, 332, 337, 340, 351, 370, 375, 377, 379, 382, 383, 432, 433, 491, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "come": [0, 1, 2, 4, 5, 6, 18, 20, 21, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 114, 120, 123, 126, 130, 137, 138, 141, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 229, 232, 283, 284, 285, 322, 339, 341, 348, 350, 364, 367, 369, 392, 565, 573, 618, 619, 620, 621, 625, 626, 627, 628, 633, 634, 637, 639, 640], "set": [0, 2, 3, 6, 7, 15, 17, 18, 21, 22, 26, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 98, 107, 110, 116, 120, 123, 126, 128, 130, 131, 137, 138, 142, 143, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 211, 213, 215, 217, 218, 221, 222, 225, 229, 232, 239, 240, 241, 242, 250, 255, 263, 264, 265, 266, 270, 271, 272, 275, 277, 279, 280, 282, 302, 304, 306, 312, 317, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 343, 344, 350, 351, 357, 362, 364, 365, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 389, 392, 403, 404, 408, 410, 419, 554, 562, 564, 566, 567, 569, 570, 571, 572, 574, 577, 579, 585, 589, 590, 616, 618, 619, 620, 621, 622, 624, 625, 626, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "re": [0, 21, 27, 33, 42, 43, 44, 45, 47, 48, 50, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 107, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 236, 304, 306, 326, 332, 337, 341, 344, 375, 377, 379, 382, 383, 399, 612, 618, 620, 621, 623, 625, 630, 632, 633, 635, 639, 640], "usabl": [0, 612, 621, 639], "function": [0, 1, 7, 12, 17, 18, 19, 20, 21, 22, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 126, 127, 130, 131, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 211, 212, 213, 217, 218, 229, 232, 239, 241, 243, 269, 270, 272, 273, 279, 280, 282, 283, 284, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 304, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 321, 322, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 341, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 400, 402, 414, 418, 419, 470, 471, 558, 566, 577, 586, 592, 595, 603, 618, 621, 622, 623, 624, 627, 630, 632, 635, 637, 640], "cost": [0, 15, 59, 83, 96, 98, 348, 350, 364, 367, 369, 618, 619, 622, 633, 634, 635, 637], "return": [0, 1, 5, 6, 10, 16, 17, 18, 19, 20, 21, 22, 26, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 94, 96, 102, 104, 106, 108, 109, 112, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 204, 205, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 288, 289, 290, 291, 292, 293, 295, 302, 303, 304, 305, 306, 307, 310, 311, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 343, 344, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 396, 400, 401, 402, 403, 414, 416, 417, 551, 553, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 583, 585, 586, 590, 604, 611, 618, 619, 620, 622, 624, 625, 627, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "process": [0, 1, 2, 3, 5, 6, 7, 12, 18, 21, 22, 23, 24, 27, 32, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 49, 50, 52, 53, 65, 68, 72, 73, 78, 80, 84, 85, 86, 87, 88, 90, 95, 97, 101, 102, 104, 108, 116, 120, 123, 126, 127, 130, 134, 138, 141, 145, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 220, 221, 229, 232, 239, 265, 268, 270, 271, 279, 280, 298, 302, 304, 312, 314, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 350, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 564, 565, 566, 567, 569, 570, 571, 572, 574, 577, 578, 579, 585, 590, 611, 618, 619, 621, 622, 623, 630, 631, 633, 634, 635, 636, 637, 639, 640], "good": [0, 2, 23, 28, 101, 102, 150, 191, 590, 611, 618, 620, 621, 622, 624, 634, 639, 640], "runtim": [0, 22, 56, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 611, 635], "perform": [0, 5, 6, 7, 10, 18, 20, 22, 23, 27, 32, 33, 35, 36, 38, 42, 43, 44, 45, 47, 48, 54, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 123, 124, 125, 126, 129, 130, 131, 132, 137, 138, 150, 151, 154, 155, 158, 159, 160, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 239, 245, 267, 270, 272, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 338, 340, 347, 350, 351, 360, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 408, 414, 416, 563, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585, 588, 590, 618, 619, 620, 621, 622, 623, 626, 628, 631, 632, 633, 634, 635, 640], "To": [0, 7, 18, 19, 20, 21, 23, 25, 26, 27, 28, 41, 42, 44, 47, 65, 66, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 93, 102, 108, 109, 112, 119, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 141, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 227, 263, 265, 279, 283, 284, 285, 287, 302, 304, 312, 326, 332, 337, 344, 351, 357, 362, 365, 371, 375, 377, 379, 382, 383, 392, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 417, 583, 584, 590, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 633, 634, 635, 636, 637, 639, 640], "read": [0, 6, 17, 26, 56, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 110, 112, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 233, 234, 235, 236, 237, 240, 241, 243, 248, 249, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 269, 270, 271, 274, 275, 276, 278, 279, 283, 284, 285, 287, 297, 310, 322, 323, 325, 327, 328, 330, 331, 339, 340, 341, 343, 344, 346, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 392, 408, 414, 566, 573, 579, 580, 581, 618, 619, 620, 622, 623, 624, 632, 633, 634, 635, 636, 639, 640], "philosophi": [0, 28], "capabl": [0, 3, 18, 20, 26, 28, 30, 39, 50, 56, 170, 184, 418, 580, 590, 618, 623, 626, 630, 632, 636, 640], "beyond": [0, 6, 7, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 611, 622], "api": [0, 6, 16, 18, 22, 24, 46, 56, 60, 71, 74, 86, 87, 123, 126, 152, 153, 155, 176, 180, 182, 190, 250, 277, 279, 280, 324, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 383, 384, 418, 419, 579, 581, 583, 585, 590, 592, 594, 622, 623, 624, 625, 626, 627, 631, 633, 634, 635, 637, 639, 640], "check": [0, 17, 22, 23, 24, 25, 26, 28, 32, 34, 35, 36, 38, 42, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 86, 87, 88, 92, 93, 100, 108, 120, 123, 126, 127, 129, 130, 131, 138, 144, 150, 151, 154, 158, 159, 160, 165, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 222, 227, 235, 241, 251, 265, 268, 272, 282, 295, 297, 298, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 343, 344, 351, 362, 367, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 400, 402, 563, 564, 566, 569, 570, 572, 574, 577, 578, 579, 580, 585, 587, 611, 619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636, 637, 639, 640], "paper": [0, 80, 83, 121, 122, 124, 125, 132, 136, 137, 142, 143, 145, 146, 155, 163, 164, 250, 275, 277, 288, 355, 371, 375, 377, 379, 618, 620, 633, 634], "releas": [0, 6, 23, 26, 29, 54, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383, 567, 569, 570, 572, 577, 579, 585, 590, 611], "sync": [0, 1, 2, 5, 7, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 120, 191, 324, 417, 558, 563, 564, 566, 574, 618], "so": [0, 5, 21, 22, 23, 25, 26, 29, 30, 50, 60, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 265, 270, 279, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 345, 346, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 392, 566, 574, 590, 618, 620, 621, 625, 628, 633, 634, 635, 640], "make": [0, 1, 5, 6, 7, 16, 17, 18, 19, 21, 23, 26, 30, 60, 65, 66, 68, 69, 74, 78, 79, 82, 84, 85, 86, 87, 88, 106, 110, 112, 119, 120, 123, 126, 130, 131, 134, 135, 137, 138, 140, 146, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 227, 234, 242, 246, 250, 251, 255, 259, 263, 267, 271, 275, 287, 297, 302, 304, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 348, 350, 364, 367, 369, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 400, 410, 554, 562, 597, 618, 619, 620, 621, 622, 623, 624, 625, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "sure": [0, 5, 19, 23, 26, 50, 82, 88, 110, 123, 130, 134, 173, 174, 175, 177, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 255, 271, 297, 382, 562, 618, 620, 621, 622, 625, 633, 634, 635, 637, 639, 640], "alwai": [0, 19, 21, 22, 35, 36, 38, 47, 52, 58, 74, 75, 78, 88, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 245, 267, 279, 280, 326, 332, 337, 358, 365, 375, 377, 379, 382, 383, 464, 564, 566, 567, 569, 570, 572, 574, 577, 579, 580, 585, 611, 619, 620, 621, 622, 633, 634, 635, 637], "enjoi": [0, 22, 83, 626], "latest": [0, 21, 29, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 145, 148, 149, 152, 153, 190, 410, 620, 633, 634, 635, 639], "featur": [0, 5, 6, 18, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 54, 56, 63, 64, 74, 81, 86, 87, 102, 108, 109, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 197, 218, 221, 236, 239, 241, 248, 265, 266, 274, 279, 288, 299, 300, 302, 304, 305, 325, 326, 327, 328, 330, 331, 332, 337, 344, 348, 350, 364, 367, 369, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 400, 418, 419, 562, 588, 592, 618, 619, 620, 621, 622, 624, 625, 626, 628, 631, 635, 637, 639, 640], "recent": [0, 26, 189, 278, 280, 282, 640], "version": [0, 2, 5, 6, 7, 18, 25, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 48, 49, 52, 53, 54, 55, 76, 77, 80, 85, 86, 87, 88, 108, 120, 123, 126, 129, 130, 131, 132, 138, 145, 146, 150, 151, 152, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 221, 269, 278, 279, 280, 282, 285, 302, 304, 325, 326, 327, 328, 329, 330, 331, 332, 336, 337, 348, 350, 364, 365, 367, 369, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 388, 418, 419, 588, 589, 592, 618, 620, 621, 622, 623, 625, 628, 633, 634, 635, 636, 640], "although": [0, 2, 5, 21, 27, 50, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 338, 340, 347, 618, 619, 626, 637], "core": [0, 7, 10, 19, 27, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 170, 611, 612, 613, 621, 624, 639], "guarante": [0, 12, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 344, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 626], "backward": [0, 1, 3, 5, 7, 8, 9, 27, 35, 36, 38, 54, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 344, 348, 349, 351, 352, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 417, 618, 620, 621, 622, 625, 626, 628, 633, 634, 635], "compat": [0, 1, 3, 5, 6, 7, 17, 18, 26, 34, 35, 36, 38, 50, 54, 56, 60, 69, 71, 79, 86, 87, 88, 96, 98, 106, 108, 109, 110, 114, 120, 123, 126, 130, 132, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 263, 272, 275, 279, 280, 282, 302, 304, 313, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 351, 352, 353, 355, 356, 357, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 417, 571, 579, 581, 585, 590, 618, 621, 630, 637], "2": [0, 2, 4, 7, 8, 10, 18, 19, 21, 22, 27, 28, 29, 34, 35, 38, 50, 51, 52, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 95, 97, 101, 102, 108, 109, 114, 116, 120, 121, 122, 123, 126, 127, 130, 136, 137, 138, 141, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 206, 213, 217, 218, 220, 222, 225, 226, 227, 229, 230, 231, 232, 241, 242, 246, 248, 250, 252, 255, 258, 262, 263, 264, 265, 270, 271, 272, 275, 277, 279, 280, 282, 287, 288, 289, 290, 291, 292, 293, 294, 297, 298, 300, 301, 302, 304, 305, 306, 307, 311, 312, 320, 322, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 337, 338, 340, 343, 347, 348, 349, 350, 351, 352, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 392, 400, 404, 462, 463, 466, 467, 468, 548, 564, 565, 566, 568, 569, 570, 571, 572, 574, 577, 579, 585, 590, 597, 611, 617, 618, 619, 620, 621, 622, 624, 625, 632, 633, 634, 635, 637, 638, 639, 640], "0": [0, 2, 6, 7, 9, 10, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 101, 102, 108, 109, 116, 120, 121, 122, 123, 126, 129, 130, 132, 133, 136, 137, 138, 144, 145, 146, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 203, 205, 214, 215, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 230, 231, 233, 234, 235, 237, 240, 241, 242, 243, 244, 245, 246, 249, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 275, 276, 277, 278, 279, 280, 282, 286, 287, 288, 290, 291, 292, 293, 294, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 310, 312, 314, 315, 316, 319, 320, 321, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 339, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 400, 404, 411, 417, 418, 424, 444, 448, 462, 466, 470, 471, 486, 502, 504, 512, 514, 518, 519, 521, 530, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 558, 562, 564, 565, 570, 571, 572, 573, 578, 581, 583, 584, 585, 590, 604, 611, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640], "nightli": [0, 25], "via": [0, 3, 6, 17, 18, 22, 23, 26, 27, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 79, 81, 82, 83, 84, 85, 87, 89, 96, 130, 150, 158, 178, 180, 186, 190, 242, 250, 253, 277, 326, 332, 337, 351, 354, 365, 375, 377, 379, 383, 418, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 577, 578, 579, 583, 585, 604, 618, 619, 620, 621, 624, 626, 637, 639, 640], "tensordict": [0, 1, 2, 6, 10, 16, 17, 18, 19, 20, 21, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 96, 97, 98, 100, 101, 102, 106, 108, 109, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 206, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 283, 284, 285, 286, 287, 296, 297, 298, 301, 302, 304, 307, 312, 313, 314, 317, 322, 325, 326, 327, 328, 329, 330, 331, 332, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 404, 408, 409, 410, 412, 414, 417, 436, 467, 563, 564, 566, 567, 569, 570, 571, 572, 573, 574, 576, 577, 578, 579, 580, 581, 582, 585, 590, 597, 604, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 635, 636, 640], "git": [0, 25, 26, 29], "clone": [0, 23, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 95, 172, 184, 193, 194, 241, 252, 270, 271, 280, 283, 284, 285, 326, 332, 337, 343, 356, 363, 371, 618, 633, 635, 639], "willing": 0, "contribut": [0, 306, 418], "cd": [0, 26], "path": [0, 18, 25, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 93, 95, 111, 117, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 250, 277, 325, 326, 327, 328, 329, 330, 331, 332, 337, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 394, 399, 400, 414, 417, 418, 419, 471, 579, 580, 619, 622, 628, 633], "root": [0, 19, 21, 22, 60, 65, 66, 68, 69, 71, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 221, 244, 266, 267, 302, 303, 304, 320, 321, 385, 621, 623, 633, 634, 635, 637, 640], "http": [0, 24, 25, 26, 29, 35, 38, 42, 44, 47, 65, 78, 80, 81, 82, 83, 84, 85, 101, 102, 121, 122, 124, 125, 132, 134, 136, 137, 142, 143, 145, 146, 147, 148, 149, 152, 153, 155, 161, 162, 163, 164, 177, 186, 190, 221, 250, 275, 289, 290, 291, 292, 293, 294, 298, 299, 300, 306, 308, 309, 312, 315, 316, 317, 348, 349, 351, 353, 354, 355, 356, 358, 359, 360, 361, 362, 363, 366, 367, 368, 369, 370, 371, 385, 587, 629, 630, 636, 639], "github": [0, 24, 25, 26, 29, 42, 44, 47, 78, 80, 81, 83, 121, 122, 124, 125, 129, 132, 136, 137, 142, 143, 145, 146, 148, 149, 152, 153, 155, 161, 162, 163, 164, 218, 221, 275, 624, 628, 630, 633, 634, 639], "com": [0, 24, 25, 26, 29, 42, 44, 47, 80, 83, 84, 121, 122, 124, 125, 132, 134, 136, 137, 142, 143, 145, 146, 148, 149, 152, 153, 155, 161, 162, 163, 164, 221, 630, 639], "setup": [0, 1, 6, 26, 42, 47, 50, 121, 122, 134, 136, 137, 161, 195, 196, 383, 418, 579, 584, 585], "py": [0, 6, 7, 18, 22, 129, 131, 211, 221, 295, 611, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640], "develop": [0, 6, 22, 23, 26, 134, 332, 337, 590, 618, 631, 639], "If": [0, 2, 3, 4, 5, 6, 9, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 102, 104, 106, 107, 108, 109, 114, 116, 120, 123, 124, 125, 126, 127, 129, 130, 131, 132, 134, 137, 138, 142, 143, 144, 145, 146, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 209, 212, 213, 214, 217, 218, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 236, 239, 241, 242, 243, 244, 245, 246, 250, 251, 254, 255, 258, 259, 264, 265, 266, 267, 268, 269, 270, 272, 273, 275, 277, 279, 280, 282, 287, 288, 297, 298, 301, 302, 304, 305, 306, 312, 313, 314, 322, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 339, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 357, 358, 359, 360, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 396, 399, 400, 401, 402, 403, 407, 409, 410, 414, 417, 418, 419, 471, 552, 558, 562, 563, 564, 566, 568, 569, 570, 571, 572, 573, 574, 577, 579, 580, 582, 584, 585, 589, 618, 619, 620, 621, 622, 623, 625, 627, 628, 630, 632, 633, 634, 635, 637, 639, 640], "us": [0, 1, 2, 3, 4, 7, 8, 9, 12, 15, 16, 17, 18, 19, 20, 22, 24, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 98, 100, 101, 102, 103, 108, 109, 114, 116, 120, 121, 122, 123, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 210, 211, 212, 213, 214, 215, 217, 218, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 244, 246, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 282, 286, 287, 288, 289, 290, 291, 294, 296, 297, 298, 299, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 317, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 343, 344, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 395, 396, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 459, 469, 471, 552, 553, 554, 556, 558, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 577, 578, 579, 580, 581, 582, 583, 584, 585, 589, 590, 591, 604, 611, 612, 616, 617, 618, 619, 620, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 638, 640], "uv": 0, "specif": [0, 1, 2, 7, 16, 18, 22, 24, 27, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 72, 73, 74, 75, 76, 77, 120, 123, 126, 130, 138, 148, 149, 150, 151, 154, 158, 159, 160, 163, 170, 171, 172, 175, 178, 179, 180, 185, 190, 209, 244, 265, 280, 294, 302, 304, 324, 326, 332, 333, 334, 337, 348, 350, 365, 367, 369, 375, 377, 379, 383, 392, 400, 401, 402, 414, 418, 563, 564, 566, 567, 568, 569, 570, 571, 572, 577, 579, 585, 588, 597, 611, 612, 617, 620, 621, 623, 624, 625, 626, 627, 628, 629, 630, 633, 634, 637, 638, 639], "build": [0, 3, 7, 21, 26, 56, 60, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 121, 122, 123, 126, 130, 131, 132, 136, 137, 138, 142, 143, 145, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 255, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 414, 555, 556, 557, 592, 597, 603, 617, 620, 621, 622, 624, 625, 626, 627, 629, 633, 634, 635, 636, 638, 639, 640], "beforehand": 0, "wheel": [0, 620], "dep": 0, "edit": [0, 21, 183, 271, 626], "prevent": [0, 23, 57, 59, 60, 61, 62, 64, 66, 71, 93, 101, 102, 121, 122, 279, 280, 303, 320, 321, 324, 332, 337, 348, 350, 364, 367, 369, 379, 411, 590, 627, 637], "resolut": [0, 326, 332, 337, 347, 564, 567, 569, 570, 572, 577, 579, 585], "potenti": [0, 2, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 635, 637], "downgrad": 0, "A": [0, 2, 6, 21, 22, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 107, 108, 110, 114, 115, 116, 117, 118, 120, 123, 126, 128, 130, 132, 133, 135, 138, 150, 151, 154, 155, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 203, 204, 205, 207, 212, 214, 216, 217, 218, 220, 221, 224, 225, 226, 227, 231, 237, 241, 243, 244, 250, 251, 253, 260, 265, 267, 270, 271, 272, 275, 276, 278, 279, 280, 281, 282, 286, 287, 288, 297, 298, 301, 302, 304, 305, 306, 307, 313, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 338, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 393, 394, 397, 399, 401, 402, 403, 406, 413, 414, 417, 419, 458, 459, 460, 461, 462, 463, 464, 466, 467, 468, 469, 470, 558, 566, 574, 577, 579, 585, 586, 611, 617, 618, 620, 622, 624, 625, 626, 629, 630, 635, 638, 640], "seri": [0, 12, 17, 26, 27, 64, 94, 104, 114, 115, 118, 119, 158, 245, 271, 392, 618, 619, 620, 627, 628, 633, 634, 637, 640], "quick": [0, 78, 588, 622], "ramp": 0, "up": [0, 1, 2, 5, 6, 7, 8, 21, 22, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 201, 217, 220, 239, 242, 266, 271, 324, 329, 367, 382, 401, 419, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585, 589, 611, 618, 619, 620, 621, 624, 628, 630, 631, 633, 634, 635, 637, 639, 640], "hurri": [0, 623], "last": [0, 2, 17, 18, 23, 32, 34, 35, 36, 38, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 107, 108, 109, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 183, 195, 206, 214, 217, 220, 225, 226, 236, 244, 246, 251, 264, 266, 268, 278, 282, 286, 288, 301, 302, 304, 305, 306, 308, 320, 326, 332, 337, 338, 340, 344, 351, 385, 387, 388, 590, 619, 620, 621, 622, 623, 624, 630, 633, 634, 635, 636, 637, 639, 640], "item": [0, 21, 27, 34, 38, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 96, 102, 107, 114, 214, 235, 271, 280, 306, 352, 353, 355, 383, 404, 604, 618, 620, 621, 625, 626, 630, 633, 634, 635, 637], "navig": [0, 184, 630, 634], "previou": [0, 22, 23, 29, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 236, 265, 316, 317, 620, 621, 622, 623, 624, 628, 635, 640], "whenev": [0, 2, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 83, 88, 101, 102, 108, 109, 124, 125, 129, 131, 132, 142, 143, 155, 163, 164, 171, 172, 173, 174, 175, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 236, 240, 271, 272, 278, 326, 332, 337, 365, 375, 377, 379, 382, 383, 385, 386, 387, 388, 390, 417, 627, 630, 637], "want": [0, 5, 6, 21, 22, 25, 26, 27, 34, 50, 52, 109, 171, 172, 175, 185, 221, 246, 326, 332, 337, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 611, 618, 619, 620, 621, 622, 623, 625, 626, 627, 633, 634, 635, 636, 637, 639, 640], "ted": [0, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 100, 617, 629, 638], "s": [0, 1, 2, 3, 5, 6, 7, 17, 18, 19, 21, 22, 25, 26, 27, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 60, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 108, 109, 114, 120, 121, 122, 123, 126, 130, 134, 136, 137, 138, 142, 143, 145, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 225, 226, 239, 244, 250, 263, 265, 268, 269, 270, 271, 272, 275, 277, 279, 280, 283, 285, 286, 288, 295, 298, 301, 302, 304, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 343, 344, 347, 349, 350, 351, 356, 362, 363, 364, 365, 367, 370, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 400, 416, 417, 418, 563, 564, 565, 566, 567, 569, 570, 571, 572, 574, 577, 578, 579, 580, 581, 585, 590, 611, 617, 618, 619, 620, 621, 622, 623, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640], "modul": [0, 6, 7, 17, 18, 21, 22, 23, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 65, 68, 69, 72, 73, 86, 87, 88, 114, 120, 121, 122, 123, 126, 130, 138, 144, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 214, 220, 221, 225, 231, 233, 239, 241, 243, 250, 251, 255, 264, 265, 270, 271, 272, 275, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 413, 414, 416, 418, 419, 471, 555, 558, 564, 566, 567, 569, 570, 571, 572, 576, 577, 579, 585, 588, 590, 601, 602, 603, 604, 605, 606, 607, 609, 610, 617, 619, 620, 623, 625, 626, 627, 629, 631, 632, 633, 634, 635, 636, 637, 638], "optim": [0, 1, 2, 15, 27, 55, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 351, 365, 366, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 408, 409, 414, 416, 418, 419, 471, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 558, 588, 611, 612, 617, 620, 621, 622, 623, 624, 626, 629, 631, 633, 634, 635, 638], "collect": [0, 1, 2, 3, 4, 5, 6, 12, 20, 22, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 60, 61, 65, 66, 67, 68, 69, 71, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 107, 120, 123, 126, 130, 138, 150, 151, 154, 155, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 218, 219, 220, 221, 222, 223, 225, 228, 229, 232, 236, 238, 242, 246, 247, 250, 252, 254, 255, 256, 257, 258, 262, 264, 265, 266, 268, 271, 272, 273, 277, 279, 280, 282, 288, 295, 305, 306, 310, 312, 325, 326, 327, 328, 330, 331, 332, 337, 340, 349, 352, 355, 357, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 404, 407, 409, 410, 414, 416, 417, 418, 419, 471, 551, 552, 558, 560, 561, 563, 566, 571, 575, 578, 583, 584, 585, 588, 590, 597, 604, 612, 617, 618, 621, 622, 623, 624, 625, 628, 629, 633, 634, 635, 636, 637, 638, 639, 640], "storag": [0, 2, 4, 10, 13, 27, 32, 34, 35, 36, 38, 50, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 107, 108, 109, 111, 112, 113, 114, 116, 117, 120, 123, 126, 128, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 220, 221, 229, 232, 255, 325, 326, 327, 328, 330, 331, 332, 337, 350, 364, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 401, 419, 423, 424, 425, 426, 429, 430, 434, 435, 436, 437, 579, 580, 581, 582, 588, 617, 619, 620, 621, 622, 623, 625, 628, 629, 633, 634, 636, 638], "log": [0, 20, 23, 27, 30, 188, 189, 195, 196, 295, 296, 297, 298, 306, 310, 320, 321, 324, 326, 329, 332, 333, 337, 341, 344, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 399, 406, 407, 408, 414, 416, 418, 419, 471, 558, 565, 578, 580, 588, 617, 618, 619, 620, 623, 624, 628, 629, 633, 634, 635, 638, 639], "your": [0, 1, 5, 7, 16, 22, 26, 27, 29, 30, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 52, 88, 120, 123, 126, 130, 134, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 344, 350, 367, 375, 377, 379, 382, 383, 403, 562, 589, 590, 611, 617, 619, 620, 621, 623, 624, 625, 626, 627, 629, 631, 633, 634, 637, 638, 639], "own": [0, 2, 5, 7, 16, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 55, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 392, 564, 569, 572, 573, 611, 617, 619, 620, 623, 629, 633, 634, 635, 638], "train": [0, 1, 2, 5, 6, 9, 18, 20, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 54, 59, 78, 80, 86, 87, 88, 101, 102, 120, 123, 126, 130, 135, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 237, 250, 264, 269, 272, 275, 277, 286, 290, 292, 301, 312, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 348, 349, 350, 351, 352, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 401, 407, 414, 416, 417, 418, 419, 471, 558, 570, 582, 588, 590, 594, 595, 601, 611, 612, 617, 619, 623, 626, 627, 629, 636, 637, 638, 639, 640], "loop": [0, 1, 5, 6, 7, 27, 34, 42, 47, 50, 52, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 286, 301, 312, 325, 327, 328, 330, 331, 349, 351, 357, 363, 367, 368, 370, 371, 372, 376, 378, 380, 381, 384, 385, 386, 387, 388, 410, 414, 563, 564, 565, 566, 569, 570, 572, 574, 577, 579, 582, 585, 612, 614, 617, 618, 619, 623, 625, 626, 627, 629, 632, 637, 638, 639], "ppo": [0, 1, 5, 7, 23, 27, 35, 36, 38, 341, 344, 350, 364, 367, 375, 418, 470, 471, 612, 617, 618, 619, 622, 624, 625, 629, 633, 638], "pendulum": [0, 1, 7, 16, 18, 21, 22, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 88, 114, 120, 123, 124, 125, 126, 127, 129, 130, 131, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 221, 224, 225, 227, 234, 240, 241, 246, 253, 255, 259, 260, 263, 265, 266, 267, 270, 271, 272, 273, 279, 280, 287, 302, 304, 382, 558, 597, 617, 619, 620, 623, 624, 625, 629, 638, 639, 640], "introduct": [0, 617, 623, 629, 633, 634, 638, 640], "multi": [0, 1, 4, 5, 16, 17, 26, 28, 32, 35, 36, 38, 65, 68, 70, 71, 72, 73, 88, 92, 93, 100, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 242, 272, 302, 304, 305, 324, 326, 332, 337, 340, 344, 375, 377, 379, 382, 383, 385, 386, 387, 388, 463, 588, 590, 592, 611, 617, 618, 619, 620, 621, 623, 624, 629, 635, 638, 639], "agent": [0, 16, 21, 22, 28, 67, 70, 71, 135, 141, 142, 143, 148, 149, 152, 153, 156, 157, 161, 162, 163, 164, 166, 184, 242, 262, 263, 264, 306, 350, 364, 367, 418, 588, 617, 623, 629, 635, 638], "env": [0, 1, 2, 4, 5, 6, 7, 18, 19, 20, 21, 22, 24, 25, 26, 27, 30, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 53, 60, 65, 66, 69, 72, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 114, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 287, 302, 304, 325, 326, 327, 328, 330, 331, 332, 337, 340, 343, 365, 375, 377, 379, 382, 383, 390, 391, 392, 403, 419, 441, 442, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 529, 530, 531, 532, 533, 534, 535, 536, 552, 553, 554, 558, 560, 561, 562, 570, 588, 590, 597, 611, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 636, 637, 638], "pretrain": [0, 324, 617, 629, 638], "recurr": [0, 220, 302, 304, 316, 385, 617, 619, 624, 629, 637, 638], "dqn": [0, 1, 5, 7, 78, 214, 233, 288, 297, 298, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 555, 617, 622, 624, 625, 628, 629, 638], "polici": [0, 1, 3, 4, 5, 6, 7, 10, 12, 17, 21, 22, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 66, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 226, 231, 241, 244, 264, 267, 271, 283, 284, 285, 286, 287, 297, 298, 301, 302, 304, 312, 313, 314, 326, 329, 332, 337, 339, 340, 341, 342, 343, 344, 347, 348, 349, 350, 351, 352, 356, 357, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 408, 416, 417, 418, 419, 471, 484, 553, 554, 558, 560, 561, 564, 565, 566, 567, 569, 570, 572, 577, 579, 585, 588, 597, 598, 604, 617, 619, 623, 625, 626, 629, 631, 636, 637, 638, 639, 640], "replai": [0, 1, 5, 10, 13, 15, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 101, 102, 103, 104, 105, 107, 109, 110, 112, 114, 115, 119, 220, 221, 231, 251, 255, 265, 271, 351, 352, 353, 355, 356, 357, 363, 368, 370, 371, 372, 382, 401, 410, 414, 416, 418, 419, 426, 427, 428, 429, 432, 436, 437, 471, 556, 558, 588, 590, 611, 612, 617, 622, 629, 635, 636, 638], "buffer": [0, 1, 3, 5, 6, 10, 13, 15, 18, 22, 23, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 114, 115, 116, 119, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 220, 221, 225, 230, 231, 239, 250, 251, 255, 265, 270, 271, 272, 275, 277, 286, 312, 325, 326, 327, 328, 330, 331, 332, 337, 343, 346, 350, 351, 352, 353, 355, 356, 357, 363, 364, 367, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 400, 401, 410, 414, 416, 418, 419, 426, 427, 428, 429, 432, 436, 437, 471, 556, 558, 563, 565, 566, 568, 571, 573, 574, 575, 579, 580, 581, 582, 588, 590, 611, 612, 617, 622, 627, 629, 635, 636, 638, 640], "export": [0, 25, 26, 617, 629, 638], "llm": [0, 6, 52, 53, 54, 55, 86, 87, 88, 89, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 499, 578, 579, 580, 581, 582, 583, 584, 585, 586, 588, 592, 611, 617, 629, 638], "tool": [0, 3, 18, 20, 24, 87, 170, 184, 186, 187, 190, 193, 197, 200, 201, 202, 203, 590, 592, 593, 596, 617, 621, 623, 629, 633, 635, 637, 638, 640], "enabl": [0, 7, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 79, 89, 95, 97, 107, 116, 170, 184, 218, 302, 304, 312, 324, 326, 329, 332, 333, 334, 337, 340, 379, 390, 392, 408, 416, 418, 419, 570, 590, 601, 611, 617, 620, 623, 629, 633, 634, 635, 637, 638], "competit": [0, 22, 142, 143, 617, 629, 634, 638], "ddpg": [0, 290, 291, 292, 293, 352, 419, 617, 619, 625, 629, 634, 638], "task": [0, 7, 19, 22, 28, 70, 71, 80, 83, 120, 123, 124, 125, 126, 130, 133, 138, 142, 143, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 175, 177, 178, 179, 180, 182, 250, 263, 272, 275, 277, 356, 363, 419, 588, 617, 618, 619, 620, 621, 623, 624, 629, 630, 633, 634, 635, 638, 640], "object": [0, 6, 17, 21, 23, 25, 26, 32, 34, 35, 36, 38, 39, 42, 44, 47, 50, 52, 53, 60, 63, 69, 74, 86, 87, 88, 89, 90, 95, 96, 97, 98, 106, 110, 112, 116, 119, 120, 123, 126, 130, 136, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 229, 232, 233, 239, 242, 246, 250, 270, 271, 272, 275, 279, 280, 283, 302, 304, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 342, 343, 344, 345, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 392, 419, 552, 553, 554, 555, 557, 558, 562, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585, 588, 617, 619, 620, 621, 622, 626, 628, 629, 631, 633, 634, 635, 637, 638, 640], "loss": [0, 6, 7, 19, 21, 27, 233, 306, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375, 377, 379, 383, 385, 409, 413, 414, 418, 419, 469, 470, 471, 555, 558, 588, 590, 595, 604, 605, 606, 607, 609, 610, 612, 617, 622, 623, 625, 626, 627, 629, 635, 637, 638], "trainer": [0, 6, 7, 324, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 416, 417, 418, 419, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 570, 578, 579, 583, 584, 585, 588, 617, 618, 629, 638], "exampl": [0, 2, 3, 5, 18, 19, 21, 23, 28, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 101, 102, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 203, 206, 207, 211, 212, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 246, 248, 249, 250, 251, 252, 253, 254, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 300, 301, 302, 304, 305, 306, 307, 310, 311, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 392, 400, 402, 403, 404, 405, 406, 407, 409, 410, 411, 412, 413, 417, 418, 419, 462, 463, 466, 467, 468, 471, 558, 566, 570, 574, 579, 581, 582, 585, 588, 617, 618, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636, 638, 639, 640], "packag": [0, 18, 25, 26, 29, 190, 211, 588, 589, 630, 640], "multicollector": [0, 2, 6, 35, 38, 588], "kei": [0, 2, 6, 7, 17, 18, 19, 22, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 86, 87, 88, 92, 101, 102, 106, 108, 109, 114, 120, 123, 126, 130, 136, 137, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 243, 246, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 286, 287, 296, 297, 298, 301, 302, 304, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 407, 408, 409, 411, 412, 414, 417, 418, 552, 580, 581, 586, 588, 618, 620, 621, 622, 623, 625, 630, 631, 632, 633, 634, 635, 637, 639, 640], "legaci": [0, 5, 26, 35, 36, 38, 56, 86, 87, 176, 188, 189, 195, 196, 325, 326, 327, 328, 330, 331, 332, 337, 376, 378, 380, 381, 384, 417, 570, 572, 588], "name": [0, 5, 6, 7, 17, 18, 21, 25, 26, 32, 34, 35, 36, 38, 54, 55, 60, 71, 78, 80, 82, 85, 86, 87, 88, 89, 120, 121, 123, 124, 126, 130, 136, 138, 142, 143, 145, 148, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 209, 213, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 231, 233, 234, 235, 237, 239, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 282, 297, 302, 304, 313, 318, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 389, 390, 394, 396, 397, 398, 399, 400, 401, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 416, 417, 570, 571, 572, 578, 583, 584, 586, 588, 604, 611, 618, 619, 620, 621, 622, 625, 626, 627, 630, 633, 634, 635, 636, 640], "interfac": [0, 1, 16, 22, 55, 120, 133, 147, 305, 324, 326, 329, 332, 337, 401, 422, 571, 575, 581, 585, 588, 594, 618, 620, 622, 627, 630, 631, 635, 637], "servic": [0, 50, 186, 189, 192, 193, 195, 201, 202, 243, 324, 333, 400, 401, 402, 588, 590], "registri": [0, 129, 161, 186, 193, 201, 400, 401, 402, 588, 590], "overview": [0, 588, 620, 622, 625, 633, 634, 639], "usag": [0, 1, 12, 18, 24, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 79, 85, 91, 93, 114, 171, 189, 191, 192, 218, 221, 233, 302, 304, 324, 326, 332, 337, 350, 351, 356, 363, 364, 367, 370, 373, 375, 377, 379, 383, 400, 402, 417, 418, 566, 574, 588, 590, 618, 620, 621, 624, 625, 627, 633, 634, 637], "executor": [0, 22, 42, 44, 47, 159, 193, 588], "best": [0, 5, 24, 28, 134, 302, 304, 324, 367, 588, 633, 634, 637, 639], "practic": [0, 3, 4, 18, 21, 22, 23, 24, 27, 52, 63, 78, 271, 303, 320, 321, 588, 589, 618, 619, 620, 621, 622, 625, 630, 633, 634, 636, 640], "also": [0, 2, 5, 6, 7, 12, 17, 18, 19, 21, 22, 27, 28, 30, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 57, 59, 61, 62, 64, 68, 69, 72, 73, 74, 78, 80, 81, 83, 84, 85, 86, 87, 88, 95, 96, 97, 102, 108, 109, 114, 116, 120, 123, 126, 130, 137, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 211, 212, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 231, 233, 234, 235, 237, 239, 240, 241, 243, 246, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 282, 288, 305, 316, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 345, 346, 347, 348, 349, 351, 352, 353, 355, 356, 357, 362, 363, 367, 370, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 392, 407, 588, 590, 618, 619, 620, 621, 622, 623, 624, 625, 626, 630, 632, 633, 634, 635, 637, 639, 640], "_util": [0, 18, 150, 588, 622, 628], "implement_for": [0, 18, 588], "set_auto_unwrap_transformed_env": [0, 31, 272, 588], "auto_unwrap_transformed_env": [0, 403, 588], "configur": [0, 2, 4, 27, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 45, 47, 48, 50, 51, 52, 55, 123, 171, 190, 241, 289, 294, 311, 324, 326, 333, 350, 365, 367, 375, 377, 379, 383, 400, 401, 418, 419, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 566, 569, 570, 572, 577, 588, 597, 612, 618, 619, 620, 625, 631, 633, 634, 635], "system": [0, 10, 16, 23, 24, 87, 93, 170, 171, 172, 175, 177, 191, 193, 195, 196, 379, 383, 422, 588, 590, 611, 612, 620, 631, 633, 634, 635], "simpl": [0, 19, 21, 28, 40, 41, 64, 74, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 290, 324, 326, 332, 337, 340, 344, 353, 355, 365, 367, 369, 375, 377, 379, 382, 383, 385, 407, 588, 590, 611, 618, 619, 620, 623, 624, 625, 631, 633, 634, 637, 640], "categori": [0, 60, 80, 588], "group": [0, 6, 18, 19, 22, 54, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 86, 87, 88, 120, 123, 126, 130, 138, 141, 142, 143, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 166, 170, 171, 172, 175, 176, 178, 179, 180, 185, 242, 262, 324, 325, 327, 328, 330, 331, 332, 333, 335, 336, 376, 378, 380, 381, 384, 571, 572, 578, 579, 583, 584, 588, 590, 619, 624, 626, 634, 637], "complex": [0, 6, 12, 22, 37, 39, 40, 41, 46, 49, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383, 400, 585, 588, 590, 611, 618, 619, 623, 624], "parallel": [0, 1, 2, 3, 4, 5, 16, 18, 19, 21, 27, 35, 36, 38, 54, 55, 120, 123, 126, 129, 130, 131, 138, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 272, 278, 302, 304, 324, 333, 334, 348, 438, 559, 560, 561, 562, 585, 588, 611, 619, 620, 633, 634, 639], "avail": [0, 2, 3, 5, 16, 20, 23, 25, 32, 35, 36, 38, 50, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 102, 107, 108, 109, 121, 122, 124, 125, 134, 136, 137, 142, 143, 148, 149, 150, 152, 153, 155, 161, 162, 163, 164, 182, 186, 192, 194, 195, 201, 214, 217, 220, 239, 241, 333, 341, 344, 365, 375, 377, 379, 383, 392, 560, 561, 564, 565, 566, 567, 569, 570, 572, 573, 574, 575, 577, 579, 585, 588, 590, 611, 618, 619, 620, 621, 622, 623, 624, 631, 633, 634, 635, 637, 640], "complet": [0, 1, 5, 6, 26, 28, 35, 36, 38, 46, 52, 53, 102, 107, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 184, 221, 263, 324, 382, 418, 568, 571, 578, 585, 588, 589, 590, 611, 618, 620, 623, 630, 631, 632], "run": [0, 1, 2, 6, 16, 18, 19, 22, 23, 24, 25, 26, 27, 29, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 66, 78, 80, 88, 102, 108, 109, 120, 121, 122, 123, 124, 125, 126, 129, 130, 136, 137, 138, 144, 145, 146, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 239, 245, 246, 262, 270, 271, 272, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 317, 324, 326, 332, 337, 338, 340, 344, 345, 346, 347, 351, 357, 370, 375, 377, 379, 382, 383, 392, 399, 408, 419, 560, 561, 562, 570, 588, 589, 611, 612, 618, 619, 620, 621, 624, 625, 626, 627, 628, 630, 633, 634, 635, 639], "experi": [0, 1, 16, 17, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 394, 395, 396, 397, 398, 399, 400, 419, 588, 589, 615, 619, 620, 622, 626, 627, 633, 634, 637], "store": [0, 2, 6, 12, 17, 27, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 60, 63, 65, 66, 68, 69, 72, 73, 80, 81, 83, 84, 86, 87, 88, 90, 93, 95, 96, 97, 98, 101, 102, 108, 114, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 267, 278, 279, 280, 286, 312, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 399, 418, 419, 471, 563, 564, 566, 570, 571, 572, 574, 588, 618, 620, 621, 624, 626, 628, 633, 634, 636, 640], "implement": [0, 1, 6, 9, 10, 12, 17, 21, 22, 28, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 70, 71, 74, 75, 76, 77, 88, 99, 101, 110, 111, 120, 123, 126, 130, 138, 144, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 237, 241, 244, 252, 253, 259, 263, 269, 271, 272, 273, 279, 280, 282, 302, 303, 304, 319, 320, 321, 324, 326, 332, 334, 337, 348, 349, 351, 354, 355, 356, 362, 363, 365, 366, 367, 369, 370, 371, 375, 377, 379, 382, 383, 390, 404, 418, 419, 553, 583, 584, 585, 588, 590, 611, 612, 618, 619, 620, 621, 622, 633, 634, 635, 639], "detail": [0, 6, 21, 24, 25, 26, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 268, 272, 298, 307, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 350, 358, 364, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 564, 588, 589, 590, 619, 622, 626, 632, 637], "class": [0, 1, 2, 4, 5, 6, 10, 14, 16, 18, 19, 20, 21, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 126, 127, 128, 129, 130, 131, 132, 137, 138, 141, 144, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 211, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 588, 590, 591, 597, 606, 611, 613, 615, 618, 619, 620, 621, 623, 624, 625, 626, 627, 630, 633, 634, 637, 640], "creat": [0, 1, 4, 6, 10, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 29, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 98, 114, 120, 123, 126, 127, 130, 134, 138, 150, 151, 152, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 218, 221, 226, 239, 243, 250, 270, 271, 272, 275, 278, 279, 280, 288, 290, 291, 292, 293, 294, 295, 300, 302, 304, 305, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 343, 344, 351, 353, 358, 367, 368, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 400, 401, 402, 410, 418, 419, 471, 552, 553, 554, 558, 560, 561, 563, 564, 566, 567, 568, 569, 570, 571, 572, 573, 574, 577, 579, 585, 588, 590, 597, 604, 611, 612, 618, 619, 620, 621, 622, 624, 627, 630, 631, 633, 634, 635, 636, 637, 639, 640], "custom": [0, 6, 10, 16, 21, 22, 24, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 81, 86, 87, 88, 89, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 275, 324, 325, 326, 327, 328, 330, 331, 332, 337, 347, 358, 367, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 402, 418, 471, 562, 567, 569, 570, 572, 577, 579, 583, 584, 585, 588, 600, 612, 614, 618, 619, 620, 621, 624, 625, 627, 630, 633, 634], "futur": [0, 23, 34, 41, 54, 56, 86, 87, 88, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 250, 270, 272, 277, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 418, 419, 571, 588, 589, 590, 611], "extens": [0, 65, 68, 72, 73, 109, 588, 637], "thing": [0, 5, 19, 21, 22, 26, 27, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 271, 325, 327, 328, 330, 331, 357, 370, 376, 378, 380, 381, 384, 589, 620, 621, 622, 623, 624, 625, 626, 627, 633, 634, 637, 640], "consid": [0, 2, 18, 21, 27, 34, 35, 36, 37, 38, 39, 42, 46, 47, 49, 50, 52, 54, 60, 65, 68, 71, 72, 73, 88, 95, 97, 108, 109, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 231, 279, 295, 306, 319, 326, 332, 337, 349, 351, 363, 368, 370, 371, 372, 375, 377, 379, 382, 383, 385, 387, 388, 589, 590, 611, 618, 623, 624, 625, 635, 637], "when": [0, 1, 2, 3, 6, 7, 8, 17, 18, 20, 21, 22, 24, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 96, 97, 98, 100, 101, 102, 103, 107, 108, 109, 110, 112, 116, 120, 121, 122, 123, 126, 127, 129, 130, 131, 137, 138, 141, 142, 143, 145, 147, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 212, 215, 217, 220, 221, 225, 226, 229, 231, 232, 241, 242, 245, 246, 250, 251, 258, 265, 267, 270, 271, 272, 275, 277, 278, 279, 280, 282, 295, 302, 304, 305, 306, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 343, 344, 346, 349, 350, 351, 353, 357, 358, 363, 364, 365, 367, 368, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 394, 397, 399, 400, 410, 416, 417, 562, 563, 564, 566, 569, 570, 572, 573, 574, 577, 578, 579, 585, 589, 590, 611, 618, 619, 620, 621, 622, 624, 626, 627, 633, 634, 635, 636, 637, 639, 640], "debug": [0, 6, 25, 27, 78, 79, 80, 81, 82, 83, 84, 85, 191, 267, 326, 332, 337, 565, 589, 640], "work": [0, 4, 6, 18, 20, 21, 22, 23, 27, 46, 49, 54, 55, 60, 68, 71, 78, 79, 80, 81, 82, 83, 84, 85, 88, 95, 101, 102, 106, 108, 109, 112, 119, 120, 123, 126, 129, 130, 131, 134, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 212, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 280, 282, 288, 298, 305, 314, 324, 326, 332, 337, 347, 350, 364, 367, 375, 377, 379, 382, 383, 400, 401, 414, 571, 585, 588, 589, 590, 597, 618, 619, 620, 621, 623, 626, 631, 632, 633, 634, 635, 636, 637, 639, 640], "habitat": [0, 18, 132, 445, 589, 636], "lab": [0, 17, 124, 125, 132, 135, 589], "mujoco": [0, 25, 27, 155, 589, 618, 620, 621], "error": [0, 2, 22, 26, 29, 32, 34, 35, 36, 38, 52, 57, 59, 61, 62, 64, 70, 86, 87, 88, 95, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 165, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 251, 270, 282, 324, 325, 326, 327, 328, 330, 331, 332, 337, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 589, 590, 611, 618, 620, 633, 634, 640], "solut": [0, 12, 18, 25, 26, 28, 50, 108, 589, 622, 639], "resourc": [0, 3, 33, 42, 43, 44, 45, 47, 48, 50, 132, 171, 172, 175, 184, 185, 192, 194, 195, 324, 329, 337, 400, 401, 567, 569, 570, 572, 577, 579, 585, 589, 590, 611, 618, 620, 622, 633, 634], "issu": [0, 6, 20, 22, 23, 24, 27, 66, 78, 81, 93, 95, 97, 101, 102, 108, 116, 120, 123, 126, 129, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 194, 195, 212, 221, 251, 266, 297, 298, 313, 314, 324, 339, 341, 343, 344, 350, 367, 418, 589, 590, 631, 639], "customis": [0, 589, 619, 627], "video": [0, 16, 23, 28, 86, 392, 394, 397, 399, 408, 562, 589, 628, 633, 634], "render": [0, 20, 27, 137, 163, 390, 392, 408, 589, 618, 619, 620, 622, 623, 627], "index": [0, 21, 26, 27, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 94, 95, 96, 97, 101, 102, 104, 106, 108, 112, 114, 115, 116, 118, 119, 120, 123, 126, 130, 138, 142, 143, 148, 149, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 195, 212, 216, 221, 225, 231, 272, 306, 324, 325, 327, 328, 330, 331, 340, 376, 378, 380, 381, 384, 564, 565, 566, 567, 569, 570, 571, 572, 573, 574, 575, 577, 579, 585, 623, 630, 632, 633, 634, 637, 639], "search": [0, 60, 71, 147, 186, 187, 203, 213, 326, 332, 337, 619], "page": [0, 26, 184, 399, 625, 630], "bridg": [1, 419], "between": [1, 2, 6, 19, 21, 23, 24, 32, 34, 35, 36, 38, 39, 46, 50, 52, 53, 54, 65, 66, 68, 69, 72, 73, 83, 86, 87, 88, 90, 97, 101, 102, 104, 107, 108, 109, 116, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 231, 245, 256, 267, 270, 272, 279, 280, 288, 296, 298, 302, 304, 305, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 341, 344, 348, 350, 351, 352, 355, 356, 357, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 408, 414, 419, 566, 570, 586, 592, 611, 618, 619, 621, 622, 626, 630, 631, 633, 634, 635, 637, 640], "manag": [1, 2, 6, 10, 11, 22, 27, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 190, 192, 201, 302, 304, 324, 337, 367, 385, 386, 387, 388, 401, 402, 403, 408, 419, 577, 590, 592, 611, 621, 622, 625, 630, 639], "gather": [1, 2, 17, 18, 42, 47, 50, 95, 97, 102, 108, 116, 195, 244, 251, 310, 326, 332, 337, 365, 375, 377, 379, 383, 418, 419, 471, 552, 589, 619, 620, 621, 626, 633, 634, 635, 637, 639, 640], "thei": [1, 2, 3, 6, 7, 17, 20, 21, 22, 23, 27, 28, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 120, 123, 126, 129, 130, 131, 138, 141, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 220, 235, 241, 250, 259, 267, 271, 272, 277, 304, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 410, 414, 564, 566, 569, 570, 572, 574, 577, 579, 585, 598, 611, 618, 619, 620, 621, 622, 625, 632, 633, 634, 635, 636, 637, 639, 640], "handl": [1, 5, 6, 7, 16, 17, 18, 20, 22, 35, 36, 37, 38, 39, 40, 41, 42, 46, 47, 49, 50, 54, 55, 63, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 278, 279, 280, 304, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 401, 407, 414, 419, 560, 561, 563, 564, 565, 567, 568, 569, 570, 571, 572, 576, 577, 578, 579, 585, 590, 592, 611, 618, 619, 620, 621, 623, 625, 630, 634, 637], "reset": [1, 2, 7, 16, 17, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 109, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 216, 217, 218, 221, 233, 236, 240, 245, 250, 258, 263, 264, 265, 266, 267, 270, 271, 272, 275, 278, 279, 282, 287, 302, 304, 312, 326, 332, 337, 340, 365, 375, 377, 379, 382, 383, 391, 400, 401, 590, 611, 618, 619, 620, 621, 623, 626, 630, 632, 633, 634, 639], "execut": [1, 2, 3, 5, 17, 18, 20, 21, 22, 25, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 95, 96, 98, 108, 109, 120, 121, 122, 123, 126, 127, 130, 131, 132, 134, 136, 137, 138, 144, 145, 150, 151, 154, 155, 158, 159, 160, 161, 170, 171, 172, 175, 176, 178, 179, 180, 186, 190, 192, 193, 197, 201, 215, 226, 227, 244, 267, 272, 301, 302, 304, 324, 325, 327, 328, 329, 330, 331, 334, 340, 345, 346, 365, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 552, 562, 590, 593, 611, 617, 619, 620, 621, 622, 623, 624, 625, 626, 627, 633, 634, 637, 638, 639, 640], "aggreg": [1, 2, 22, 78, 102, 114, 152, 153, 177, 213, 242, 280, 288, 290, 291, 346, 379, 401, 590, 634], "easi": [1, 7, 16, 17, 18, 21, 24, 30, 78, 82, 120, 123, 124, 125, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 301, 312, 597, 618, 619, 620, 631, 634, 636, 637, 639, 640], "qualiti": [1, 30, 177, 285, 367], "sever": [1, 2, 5, 6, 7, 12, 20, 27, 55, 61, 80, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 222, 224, 225, 242, 272, 325, 326, 327, 328, 330, 331, 332, 337, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 464, 590, 618, 620, 622, 627, 628, 637, 640], "differ": [1, 2, 5, 6, 7, 15, 16, 17, 19, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 83, 86, 87, 88, 101, 106, 120, 121, 122, 123, 126, 127, 130, 136, 137, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 221, 226, 230, 231, 242, 246, 253, 262, 270, 272, 274, 282, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 363, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 400, 408, 414, 417, 560, 561, 566, 570, 572, 575, 579, 583, 584, 590, 594, 611, 612, 618, 619, 620, 622, 623, 625, 627, 631, 632, 633, 634, 635, 636, 637, 639, 640], "scenario": [1, 4, 6, 40, 46, 49, 142, 143, 150, 163, 164, 226, 270, 379, 390, 611, 618, 624, 633, 634, 635], "singl": [1, 2, 3, 4, 7, 16, 17, 18, 19, 20, 21, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 60, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 96, 109, 114, 120, 123, 126, 129, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 214, 221, 222, 242, 250, 255, 265, 270, 272, 277, 288, 302, 304, 305, 314, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 346, 349, 350, 351, 353, 355, 357, 358, 363, 364, 367, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 562, 563, 564, 566, 568, 569, 570, 571, 572, 577, 579, 585, 588, 590, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 630, 632, 633, 634, 635, 636, 637, 639], "worker": [1, 2, 4, 5, 6, 7, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 65, 68, 69, 72, 73, 74, 80, 85, 86, 87, 88, 127, 145, 150, 158, 173, 174, 176, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 271, 279, 280, 324, 325, 327, 328, 330, 331, 334, 335, 336, 376, 378, 380, 381, 382, 384, 400, 401, 402, 414, 560, 561, 562, 563, 564, 565, 566, 567, 569, 570, 571, 572, 573, 574, 575, 577, 578, 579, 581, 582, 583, 584, 585, 588, 618, 619, 620, 639, 640], "across": [1, 2, 3, 16, 19, 27, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 87, 102, 108, 109, 121, 122, 124, 125, 129, 131, 132, 134, 136, 137, 145, 146, 150, 155, 160, 171, 172, 175, 185, 194, 195, 270, 279, 280, 302, 304, 312, 324, 326, 365, 367, 375, 377, 379, 382, 383, 401, 402, 417, 430, 564, 569, 572, 577, 590, 594, 611, 618, 623, 627, 633, 634, 635], "multipl": [1, 2, 3, 6, 7, 17, 18, 21, 22, 24, 27, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 62, 68, 69, 72, 73, 87, 90, 97, 104, 116, 120, 121, 122, 136, 137, 150, 158, 160, 171, 172, 175, 177, 178, 185, 192, 194, 195, 222, 224, 231, 240, 244, 245, 255, 258, 262, 263, 270, 279, 297, 304, 313, 324, 337, 339, 341, 343, 344, 347, 350, 357, 364, 367, 401, 418, 430, 562, 563, 566, 567, 568, 569, 570, 571, 572, 577, 579, 585, 588, 590, 592, 618, 619, 620, 623, 625, 626, 631, 633, 634, 635, 637, 639], "distribut": [1, 6, 10, 15, 21, 22, 23, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 123, 152, 153, 191, 241, 246, 280, 286, 295, 296, 297, 298, 299, 303, 306, 307, 310, 311, 315, 316, 317, 319, 320, 321, 324, 326, 329, 332, 335, 336, 337, 341, 344, 345, 348, 349, 350, 351, 356, 357, 358, 363, 364, 367, 368, 369, 370, 371, 372, 379, 400, 401, 402, 430, 563, 564, 565, 568, 569, 570, 571, 572, 573, 578, 579, 583, 584, 588, 597, 611, 619, 620, 622, 624, 626, 633, 634, 635, 639, 640], "For": [1, 2, 5, 6, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 32, 34, 35, 36, 38, 42, 44, 47, 50, 53, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69, 72, 73, 74, 75, 76, 77, 79, 83, 85, 86, 87, 88, 89, 95, 97, 102, 108, 116, 120, 123, 126, 129, 130, 131, 135, 137, 138, 150, 151, 152, 153, 154, 158, 159, 160, 161, 163, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 229, 232, 236, 246, 264, 271, 272, 278, 283, 285, 298, 302, 304, 306, 313, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 356, 358, 363, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 402, 408, 564, 566, 569, 570, 572, 573, 574, 577, 578, 579, 580, 583, 585, 590, 611, 618, 619, 620, 621, 623, 624, 626, 627, 630, 633, 634, 635, 636, 637, 640], "node": [1, 3, 7, 15, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 60, 71, 85, 86, 87, 138, 176, 179, 270, 324, 325, 327, 328, 330, 331, 335, 336, 376, 378, 380, 381, 384, 578, 579, 585, 588, 611, 626, 639], "rai": [1, 3, 6, 10, 32, 34, 35, 36, 38, 39, 50, 52, 53, 54, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 171, 172, 175, 185, 189, 192, 193, 194, 195, 243, 324, 329, 334, 337, 400, 401, 402, 570, 571, 572, 578, 583, 584, 585, 611], "rpc": [1, 3, 6, 32, 34, 35, 36, 38, 47, 49, 51, 52, 53, 67, 324, 568, 569, 578, 581, 583, 584], "backend": [1, 3, 6, 7, 8, 10, 16, 17, 18, 20, 22, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 175, 178, 179, 180, 192, 193, 211, 282, 326, 332, 333, 334, 337, 401, 402, 444, 448, 564, 570, 571, 572, 577, 583, 584, 588, 594, 611, 618, 620, 621, 622, 623, 626, 627, 631, 635], "distributedcollector": [1, 3, 43], "rpccollector": [1, 3, 48], "unifi": [1, 16, 324, 337, 576, 590, 594, 631, 640], "paramet": [1, 2, 5, 6, 7, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 96, 97, 98, 101, 102, 103, 104, 106, 107, 110, 112, 114, 116, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 204, 205, 206, 210, 211, 212, 213, 214, 215, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 394, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 459, 469, 471, 551, 552, 553, 554, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 604, 611, 618, 621, 622, 624, 628, 633, 634, 635, 636, 639], "choos": [1, 2, 3, 6, 22, 30, 63, 120, 123, 141, 302, 304, 367, 618, 619, 620, 622, 633, 634, 637, 639], "synchron": [1, 3, 5, 22, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 86, 87, 145, 176, 190, 324, 325, 327, 328, 330, 331, 337, 376, 378, 380, 381, 384, 400, 560, 561, 564, 565, 566, 567, 569, 570, 571, 572, 574, 575, 577, 578, 579, 585, 588, 590, 619, 620, 633], "asynchron": [1, 2, 3, 22, 28, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 324, 325, 326, 327, 328, 330, 331, 332, 337, 343, 348, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 414, 416, 560, 568, 618, 619, 620], "import": [1, 5, 6, 7, 10, 16, 18, 19, 20, 21, 22, 23, 25, 29, 30, 32, 34, 35, 36, 38, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 101, 102, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 140, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 206, 211, 212, 213, 214, 215, 217, 218, 220, 221, 224, 226, 227, 233, 234, 239, 240, 241, 242, 246, 248, 250, 252, 253, 254, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 270, 271, 273, 277, 279, 280, 282, 283, 284, 285, 287, 290, 291, 292, 293, 296, 297, 298, 300, 301, 302, 304, 305, 307, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 392, 406, 408, 418, 419, 558, 585, 590, 597, 604, 611, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 632, 633, 634, 635, 636, 637, 639, 640], "all": [1, 2, 3, 5, 6, 7, 17, 18, 19, 21, 22, 23, 27, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 124, 125, 126, 127, 129, 130, 131, 132, 137, 138, 142, 143, 144, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 166, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 206, 210, 212, 214, 220, 221, 224, 225, 229, 230, 232, 235, 241, 245, 246, 250, 258, 260, 262, 265, 266, 271, 272, 275, 277, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 340, 343, 344, 346, 347, 348, 349, 350, 351, 360, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 400, 401, 402, 409, 414, 418, 422, 471, 551, 560, 561, 562, 563, 564, 565, 566, 569, 570, 571, 572, 574, 577, 578, 579, 581, 583, 585, 589, 606, 611, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 629, 630, 632, 633, 634, 635, 637, 639, 640], "befor": [1, 2, 4, 5, 6, 17, 21, 22, 23, 25, 26, 29, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 59, 61, 82, 88, 107, 109, 114, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 278, 279, 280, 302, 304, 305, 324, 326, 332, 337, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 386, 387, 388, 410, 564, 566, 569, 570, 571, 572, 575, 577, 578, 579, 583, 585, 590, 611, 618, 620, 621, 622, 626, 627, 633, 634, 635, 637, 640], "deliv": [1, 2, 5, 18, 34, 35, 36, 38, 83, 185, 618, 619, 623, 626, 639], "batch": [1, 4, 5, 6, 7, 9, 16, 18, 19, 20, 32, 34, 35, 36, 38, 39, 42, 44, 47, 50, 52, 53, 55, 56, 60, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 98, 102, 103, 107, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 144, 145, 147, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 218, 221, 225, 227, 236, 244, 246, 248, 251, 255, 262, 265, 267, 271, 272, 274, 278, 279, 280, 295, 302, 304, 306, 310, 312, 319, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 340, 343, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 404, 407, 410, 411, 412, 414, 416, 417, 418, 419, 438, 471, 560, 561, 562, 590, 592, 604, 619, 620, 621, 622, 623, 626, 628, 630, 632, 633, 634, 636, 639, 640], "create_env_fn": [1, 5, 6, 7, 32, 34, 35, 36, 38, 42, 44, 47, 50, 127, 150, 158, 438, 471, 566, 618, 639], "make_env": [1, 4, 5, 16, 20, 22, 35, 36, 38, 150, 158, 164, 270, 279, 280, 390, 553, 554, 590, 618, 619, 639, 640], "4": [1, 4, 5, 6, 7, 10, 16, 17, 22, 26, 35, 36, 38, 57, 60, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 101, 102, 108, 109, 116, 120, 121, 122, 123, 124, 125, 126, 130, 136, 137, 138, 139, 140, 141, 144, 146, 150, 151, 154, 156, 157, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 194, 214, 215, 217, 218, 221, 226, 227, 233, 255, 262, 263, 264, 270, 279, 280, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 297, 298, 299, 300, 301, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 322, 325, 327, 328, 330, 331, 338, 339, 340, 341, 343, 346, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 390, 391, 400, 418, 419, 471, 479, 489, 495, 564, 566, 569, 570, 572, 577, 579, 585, 590, 611, 617, 618, 619, 620, 621, 627, 633, 634, 635, 637, 638, 639, 640], "my_polici": [1, 5, 35, 36, 38], "frames_per_batch": [1, 2, 4, 5, 6, 7, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 66, 218, 221, 255, 302, 304, 419, 551, 566, 618, 619, 620, 621, 622, 626, 628, 633, 634, 637, 639], "200": [1, 7, 16, 34, 35, 38, 50, 66, 78, 88, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 255, 290, 291, 299, 315, 316, 326, 332, 337, 375, 377, 379, 382, 383, 390, 392, 618, 621, 622, 626, 628, 637], "total_fram": [1, 4, 5, 6, 7, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 66, 218, 221, 255, 414, 418, 419, 471, 551, 558, 566, 612, 618, 619, 620, 621, 622, 626, 628, 633, 634, 637, 639], "10000": [1, 6, 32, 35, 36, 38, 50, 150, 414, 418, 419, 471, 621], "true": [1, 2, 5, 6, 7, 9, 18, 21, 22, 23, 27, 30, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 95, 96, 97, 98, 101, 102, 104, 106, 107, 108, 109, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 213, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 231, 234, 236, 239, 240, 241, 242, 244, 245, 246, 250, 251, 253, 254, 257, 258, 259, 262, 263, 265, 268, 269, 270, 271, 272, 273, 274, 275, 277, 279, 280, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 297, 298, 300, 302, 304, 305, 306, 312, 313, 314, 319, 320, 321, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 339, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 399, 400, 403, 406, 407, 408, 410, 414, 416, 418, 419, 431, 432, 433, 440, 442, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 462, 463, 466, 470, 471, 473, 501, 503, 520, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 562, 563, 564, 566, 567, 569, 570, 572, 574, 576, 577, 579, 580, 581, 583, 585, 590, 611, 618, 619, 620, 621, 622, 624, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "deliveri": [1, 5, 17, 35, 36, 38], "serv": [1, 2, 5, 16, 22, 35, 36, 38, 42, 47, 50, 86, 87, 132, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 422, 590, 637, 639, 640], "fals": [1, 2, 3, 5, 18, 22, 30, 31, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 106, 107, 108, 109, 110, 115, 116, 118, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 213, 214, 215, 217, 218, 221, 222, 225, 227, 229, 232, 233, 234, 236, 239, 240, 241, 243, 244, 245, 246, 248, 250, 251, 252, 253, 255, 257, 258, 259, 262, 263, 265, 268, 269, 270, 271, 272, 273, 274, 275, 277, 279, 280, 282, 283, 284, 285, 286, 287, 288, 290, 296, 297, 298, 301, 302, 303, 304, 305, 306, 312, 313, 314, 320, 321, 322, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 337, 339, 340, 341, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 392, 399, 403, 406, 407, 408, 410, 411, 414, 418, 419, 423, 424, 425, 426, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 475, 476, 501, 504, 514, 525, 537, 538, 539, 540, 541, 547, 548, 549, 562, 564, 566, 574, 581, 583, 611, 618, 619, 620, 621, 622, 627, 628, 630, 631, 632, 633, 634, 635, 636, 639, 640], "async": [1, 7, 16, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 66, 120, 154, 159, 190, 278, 324, 333, 336, 337, 416, 418, 471], "faster": [1, 3, 23, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 84, 85, 101, 145, 306, 385, 386, 387, 388, 621, 622, 633, 634], "mai": [1, 2, 3, 5, 6, 17, 18, 19, 21, 22, 23, 24, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 54, 56, 60, 70, 71, 74, 79, 85, 86, 87, 88, 93, 96, 101, 102, 108, 120, 123, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 246, 259, 270, 272, 274, 279, 280, 302, 304, 305, 325, 326, 327, 328, 330, 331, 332, 337, 344, 350, 357, 364, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 418, 419, 564, 566, 569, 570, 572, 574, 575, 577, 579, 585, 590, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 633, 634, 635, 636, 637, 640], "lag": [1, 2, 618, 619, 620], "vs": [1, 6, 280, 282, 326, 332, 337, 400], "algorithm": [1, 5, 7, 10, 12, 18, 20, 27, 28, 33, 35, 36, 38, 42, 43, 44, 45, 47, 48, 144, 214, 262, 348, 367, 368, 370, 416, 418, 419, 604, 605, 608, 609, 610, 612, 618, 619, 620, 621, 622, 624, 625, 626, 627, 633, 634, 636, 637, 639], "a2c": [1, 5, 348], "where": [1, 2, 4, 6, 7, 17, 18, 19, 20, 21, 22, 23, 26, 27, 32, 34, 35, 36, 37, 38, 39, 40, 42, 44, 46, 47, 49, 50, 52, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 95, 97, 102, 108, 109, 114, 116, 117, 120, 123, 126, 130, 138, 141, 144, 147, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 212, 213, 214, 215, 218, 221, 226, 233, 241, 250, 255, 258, 263, 264, 265, 266, 267, 271, 272, 274, 277, 278, 286, 301, 302, 304, 306, 312, 317, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 344, 348, 349, 350, 351, 356, 357, 358, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 394, 399, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 579, 580, 612, 618, 619, 620, 622, 623, 630, 632, 633, 634, 635, 637, 640], "must": [1, 4, 6, 18, 21, 22, 26, 30, 32, 34, 35, 36, 38, 40, 41, 42, 44, 47, 50, 51, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 95, 96, 97, 98, 102, 108, 109, 110, 111, 112, 114, 116, 120, 121, 123, 126, 127, 130, 136, 138, 148, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 163, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 214, 217, 218, 221, 224, 226, 227, 233, 237, 239, 241, 243, 244, 246, 248, 259, 262, 264, 265, 266, 269, 270, 272, 273, 274, 279, 288, 297, 298, 302, 304, 305, 306, 313, 314, 322, 324, 326, 329, 332, 337, 339, 340, 341, 343, 344, 347, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 394, 399, 400, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 578, 579, 585, 586, 590, 618, 619, 620, 621, 624, 630, 632, 635, 637], "match": [1, 10, 19, 21, 22, 25, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 112, 120, 123, 124, 125, 126, 127, 129, 130, 131, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 238, 240, 241, 242, 243, 244, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 288, 295, 297, 302, 304, 305, 313, 319, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 343, 344, 347, 349, 350, 351, 357, 364, 366, 367, 368, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 410, 417, 573, 618, 620, 622, 632, 634, 635, 637, 640], "current": [1, 4, 18, 22, 31, 32, 34, 35, 36, 37, 38, 39, 46, 49, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 99, 102, 109, 120, 123, 126, 130, 132, 138, 145, 148, 149, 150, 151, 154, 158, 159, 160, 167, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 217, 218, 221, 239, 251, 264, 265, 266, 270, 271, 272, 280, 299, 312, 316, 317, 320, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 340, 348, 350, 351, 358, 364, 367, 369, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 395, 400, 401, 402, 564, 566, 567, 569, 570, 572, 573, 574, 577, 579, 582, 583, 584, 585, 611, 618, 619, 620, 621, 625, 633, 634, 635, 637, 640], "off": [1, 2, 5, 10, 12, 23, 35, 36, 38, 297, 303, 321, 370, 390, 408, 416, 419, 553, 618, 619, 620, 624, 625, 633, 634, 636, 639, 640], "sac": [1, 5, 7, 35, 36, 38, 357, 368, 370, 419, 612], "slight": [1, 150, 158, 619], "accept": [1, 2, 6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 68, 75, 80, 81, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 216, 221, 225, 236, 239, 250, 258, 262, 265, 270, 271, 272, 273, 274, 275, 277, 305, 325, 326, 327, 328, 330, 331, 332, 337, 343, 344, 345, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 611, 620, 623, 627, 637, 639, 640], "flexibl": [1, 6, 10, 16, 22, 28, 145, 170, 373, 590, 611, 618, 622, 631, 637, 640], "devic": [1, 2, 3, 6, 12, 17, 18, 19, 21, 22, 26, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 108, 109, 116, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 209, 212, 214, 218, 225, 229, 230, 232, 233, 234, 239, 241, 242, 243, 248, 249, 250, 252, 253, 255, 259, 262, 263, 265, 268, 271, 272, 273, 275, 277, 279, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 300, 301, 302, 304, 305, 311, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 343, 344, 346, 348, 349, 350, 351, 352, 353, 355, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 410, 417, 423, 425, 437, 438, 441, 442, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 462, 463, 470, 488, 507, 531, 532, 533, 556, 566, 577, 578, 585, 618, 619, 620, 621, 622, 633, 634, 635, 636, 639], "control": [1, 2, 7, 13, 17, 18, 22, 24, 27, 34, 56, 60, 68, 69, 71, 72, 73, 101, 102, 108, 120, 123, 124, 125, 126, 130, 137, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 194, 195, 196, 212, 231, 290, 291, 292, 293, 302, 304, 312, 316, 324, 343, 344, 345, 348, 350, 351, 364, 365, 367, 375, 377, 379, 383, 385, 390, 403, 419, 590, 611, 618, 619, 620, 621, 622, 623, 624, 625, 633, 634, 635, 637, 639], "weight": [1, 2, 23, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 65, 69, 86, 87, 88, 101, 102, 106, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 239, 242, 250, 265, 270, 271, 272, 275, 277, 302, 304, 324, 325, 326, 327, 328, 330, 331, 332, 337, 343, 348, 349, 350, 351, 357, 360, 367, 370, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 417, 419, 500, 557, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 588, 618, 619, 620, 632, 635, 637, 639], "keep": [1, 2, 7, 20, 21, 22, 23, 26, 27, 35, 65, 68, 69, 72, 73, 86, 87, 88, 107, 114, 123, 150, 158, 176, 189, 191, 195, 212, 246, 250, 277, 279, 280, 312, 325, 327, 328, 330, 331, 340, 350, 367, 376, 378, 379, 380, 381, 382, 384, 392, 406, 414, 618, 619, 620, 621, 626, 627, 628, 634, 635, 637, 640], "infer": [1, 2, 6, 21, 34, 35, 36, 37, 38, 39, 41, 42, 46, 47, 49, 50, 52, 53, 54, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 194, 195, 196, 221, 279, 306, 324, 334, 337, 341, 344, 355, 379, 383, 390, 401, 579, 585, 590, 594, 618, 620, 622, 626, 628, 631, 637, 639], "date": [1, 37, 39, 123, 220, 395], "integr": [1, 6, 7, 16, 54, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 293, 302, 304, 324, 326, 332, 337, 343, 375, 377, 379, 382, 383, 623, 624, 626, 630, 633, 634, 635, 636], "seamless": [1, 305, 324, 590, 631], "strategi": [1, 2, 5, 6, 7, 10, 12, 22, 34, 83, 86, 87, 106, 141, 176, 188, 214, 301, 310, 324, 325, 327, 328, 330, 331, 337, 376, 378, 379, 380, 381, 384, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 585, 588, 590, 597, 611, 618, 619, 622, 624, 633, 634, 637, 639], "organ": [1, 2, 7, 16, 630, 635, 637], "gymenv": [1, 5, 6, 16, 18, 20, 21, 22, 24, 30, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 88, 114, 120, 123, 126, 127, 130, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 217, 218, 221, 224, 225, 226, 227, 233, 239, 240, 241, 246, 248, 253, 254, 255, 258, 260, 264, 265, 266, 267, 270, 271, 272, 273, 279, 280, 287, 302, 304, 340, 382, 390, 392, 444, 558, 566, 597, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 636, 637, 639, 640], "parallelenv": [1, 3, 4, 16, 18, 20, 22, 32, 34, 35, 36, 38, 47, 52, 53, 88, 114, 120, 123, 126, 130, 138, 145, 151, 152, 153, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 271, 280, 302, 304, 382, 390, 559, 618, 619, 620, 623, 632, 639, 640], "def": [1, 5, 6, 7, 16, 18, 20, 21, 22, 35, 36, 38, 51, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 120, 123, 126, 127, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 209, 211, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 280, 282, 322, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 349, 351, 352, 357, 363, 365, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 403, 583, 584, 590, 611, 618, 619, 622, 630, 632, 633, 634, 635, 637, 639, 640], "v1": [1, 5, 6, 7, 16, 18, 20, 21, 22, 30, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 79, 81, 86, 87, 88, 114, 120, 123, 126, 127, 129, 130, 131, 136, 137, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 217, 218, 221, 224, 226, 227, 234, 240, 241, 246, 253, 255, 258, 259, 260, 263, 264, 265, 266, 267, 270, 271, 273, 279, 280, 287, 302, 304, 325, 327, 328, 330, 331, 340, 376, 378, 380, 381, 382, 384, 390, 566, 597, 619, 621, 623, 624, 625, 626, 627, 628, 635, 637, 639, 640], "shape": [1, 4, 6, 14, 17, 18, 19, 22, 34, 35, 38, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 95, 96, 97, 101, 108, 114, 116, 120, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 175, 176, 177, 178, 179, 180, 183, 185, 188, 195, 196, 206, 212, 214, 218, 220, 222, 229, 232, 233, 234, 239, 241, 242, 246, 248, 252, 253, 255, 259, 262, 263, 265, 268, 273, 279, 281, 283, 284, 285, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 302, 304, 305, 306, 307, 310, 311, 312, 313, 314, 319, 320, 322, 325, 326, 327, 328, 330, 331, 332, 337, 338, 339, 340, 341, 343, 344, 346, 347, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 390, 392, 404, 410, 414, 462, 463, 466, 467, 468, 558, 578, 583, 584, 586, 590, 618, 619, 620, 621, 622, 624, 625, 628, 630, 631, 632, 633, 634, 636, 637, 639, 640], "50": [1, 34, 35, 38, 50, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 85, 88, 108, 109, 142, 143, 183, 324, 329, 332, 337, 548, 611, 621, 631, 637], "step": [1, 2, 3, 4, 6, 7, 16, 17, 18, 19, 21, 23, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 78, 86, 87, 88, 92, 93, 100, 102, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 212, 213, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 236, 237, 240, 241, 243, 244, 246, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 286, 299, 301, 302, 304, 312, 317, 325, 327, 328, 330, 331, 340, 341, 344, 348, 359, 367, 376, 378, 380, 381, 382, 384, 385, 386, 387, 388, 391, 394, 404, 408, 414, 416, 418, 419, 471, 590, 612, 619, 621, 622, 624, 625, 627, 628, 631, 632, 635, 636, 639], "each": [1, 2, 3, 5, 6, 7, 12, 15, 17, 19, 20, 21, 22, 23, 26, 27, 32, 34, 35, 36, 37, 38, 39, 42, 44, 46, 47, 49, 50, 52, 53, 55, 56, 60, 61, 62, 68, 69, 71, 72, 78, 79, 80, 83, 86, 87, 88, 101, 102, 106, 108, 109, 111, 114, 120, 123, 126, 127, 130, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 240, 242, 244, 250, 255, 258, 263, 264, 265, 266, 270, 271, 277, 279, 280, 282, 286, 297, 298, 301, 302, 304, 308, 314, 317, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 346, 350, 364, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 392, 400, 408, 410, 560, 561, 564, 566, 567, 569, 570, 572, 573, 574, 575, 577, 578, 579, 585, 590, 611, 618, 619, 620, 621, 624, 625, 626, 628, 633, 634, 635, 636, 637, 639, 640], "updat": [1, 17, 18, 21, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 144, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 215, 217, 218, 229, 231, 232, 239, 252, 263, 264, 270, 272, 276, 279, 280, 286, 301, 312, 313, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 344, 348, 349, 350, 351, 352, 353, 355, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 408, 413, 414, 416, 417, 419, 553, 554, 557, 558, 563, 564, 565, 566, 568, 569, 570, 571, 572, 573, 574, 577, 579, 581, 583, 585, 588, 619, 620, 621, 622, 625, 628, 633, 634, 635, 637, 640], "period": [1, 191, 578], "should_upd": 1, "update_policy_weights_": [1, 2, 6, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 191, 564, 566, 569, 570, 572, 574, 577, 579, 585, 618, 634, 639], "shutdown": [1, 5, 6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 154, 159, 190, 218, 324, 400, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585, 611, 618, 619, 637, 639], "follow": [1, 2, 3, 4, 5, 6, 9, 17, 18, 19, 21, 22, 25, 26, 27, 30, 41, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 109, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 144, 147, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 217, 221, 241, 250, 275, 279, 280, 288, 298, 302, 304, 305, 313, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 348, 349, 350, 351, 352, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 414, 563, 564, 565, 566, 568, 569, 571, 572, 578, 590, 604, 618, 619, 620, 621, 622, 625, 626, 632, 633, 634, 635, 637, 639, 640], "kept": [1, 3, 19, 22, 46, 49, 56, 107, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 212, 231, 259, 303, 320, 321, 579, 581, 583, 585, 625, 633], "syncdatacollector": [1, 4, 5, 18, 618, 619, 620, 621, 622, 626, 628, 633, 634, 637], "multisyncdatacollector": [1, 2, 4, 5, 620, 626, 639], "multiasyncdatacollector": [1, 2, 5, 53, 618, 619, 620, 626, 639], "datacollectorbas": [1, 5], "basecollector": [1, 5, 37, 39, 40, 41, 44, 46, 49, 54, 55, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 271, 341, 344, 382, 417, 418, 419, 553, 554, 558], "basic": [1, 6, 21, 40, 89, 144, 170, 400, 402, 418, 566, 574, 588, 590, 612, 620, 625, 626, 628, 633, 639, 640], "size": [1, 16, 18, 19, 22, 34, 35, 38, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 103, 107, 108, 109, 110, 116, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 214, 218, 220, 221, 222, 225, 228, 229, 232, 233, 234, 236, 239, 242, 244, 248, 250, 252, 253, 255, 259, 261, 262, 263, 265, 267, 268, 271, 272, 273, 274, 277, 279, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 304, 305, 306, 307, 310, 311, 312, 313, 314, 315, 316, 319, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 339, 340, 341, 343, 346, 348, 349, 350, 351, 352, 353, 355, 356, 357, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 392, 400, 404, 410, 416, 418, 419, 578, 583, 584, 590, 619, 620, 621, 622, 623, 624, 626, 630, 633, 634, 635, 640], "copi": [1, 6, 18, 35, 36, 37, 38, 39, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 74, 75, 76, 77, 83, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 217, 221, 239, 253, 264, 270, 271, 272, 279, 280, 282, 302, 304, 325, 326, 327, 328, 330, 331, 332, 337, 351, 365, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 564, 566, 569, 570, 572, 573, 574, 577, 579, 585, 590, 618, 619, 621, 623, 633, 637, 639], "distributedsynccollector": [1, 3, 45], "distributeddatacollector": [1, 3, 42, 46, 51, 568], "rpcdatacollector": [1, 3, 34, 35, 36, 38, 47, 49, 51], "distributedsyncdatacollector": [1, 3], "submitit_delayed_launch": 1, "raycollector": [1, 39, 66], "lifecycl": [1, 22, 324], "scheme": [1, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 563, 564, 565, 566, 567, 569, 570, 571, 572, 574, 577, 579, 581, 582, 583, 584, 585, 590, 640], "behavior": [1, 2, 18, 21, 22, 23, 35, 36, 38, 50, 74, 83, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 222, 229, 232, 246, 251, 264, 272, 280, 302, 303, 304, 321, 324, 325, 326, 327, 328, 330, 331, 332, 337, 350, 356, 363, 367, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 403, 408, 577, 611, 619, 621, 633, 634, 635, 637], "transport": [1, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 577, 578, 579, 580, 581, 585], "interoper": [1, 35, 36, 38], "helper": [1, 16, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 588, 597, 612, 618, 619, 621, 633, 635], "somewhat": [2, 185, 624, 640], "equival": [2, 7, 17, 50, 53, 54, 57, 59, 60, 61, 62, 64, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 230, 233, 265, 267, 272, 297, 298, 305, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 410, 626, 639, 640], "dataload": [2, 6, 52, 107, 109, 170, 171, 172, 175, 178, 185, 194, 619, 626, 637], "except": [2, 17, 21, 32, 34, 35, 36, 38, 42, 44, 47, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 235, 255, 264, 265, 266, 270, 272, 286, 301, 302, 304, 310, 312, 325, 326, 327, 328, 330, 331, 332, 337, 348, 351, 365, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 590, 618, 619, 623, 631, 633, 637, 639, 640], "1": [2, 4, 7, 8, 10, 18, 19, 21, 22, 23, 27, 29, 32, 34, 35, 36, 38, 42, 44, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 95, 96, 97, 101, 102, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 206, 212, 214, 215, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 237, 239, 241, 242, 244, 246, 248, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 270, 271, 272, 273, 275, 277, 279, 280, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 298, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 360, 363, 364, 366, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 392, 400, 402, 404, 408, 410, 411, 419, 423, 425, 438, 444, 462, 463, 466, 468, 470, 471, 475, 480, 501, 504, 514, 523, 538, 543, 548, 558, 562, 564, 565, 566, 568, 569, 570, 571, 572, 574, 577, 578, 579, 580, 583, 584, 585, 589, 590, 611, 617, 618, 619, 620, 621, 622, 624, 625, 626, 628, 632, 633, 634, 635, 636, 637, 638, 639, 640], "over": [2, 5, 7, 18, 20, 21, 22, 23, 27, 35, 36, 38, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 101, 102, 107, 108, 109, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 231, 246, 258, 266, 280, 306, 310, 317, 320, 326, 332, 337, 346, 358, 360, 365, 375, 377, 379, 382, 383, 385, 390, 410, 551, 618, 619, 620, 622, 623, 624, 625, 626, 633, 634, 635, 640], "non": [2, 6, 12, 17, 22, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 53, 55, 57, 58, 60, 63, 65, 70, 71, 74, 75, 76, 77, 83, 86, 87, 88, 96, 98, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 218, 219, 221, 225, 236, 250, 262, 265, 271, 272, 273, 274, 275, 277, 280, 287, 302, 304, 307, 325, 326, 327, 328, 330, 331, 332, 337, 343, 344, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 360, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 564, 566, 568, 569, 570, 572, 574, 577, 579, 585, 618, 621, 622, 633, 634, 635, 637, 640], "static": [2, 60, 71, 102, 108, 109, 132, 151, 174, 180, 279, 282, 326, 332, 337, 363, 375, 377, 379, 383, 623, 635, 637], "like": [2, 4, 6, 7, 17, 19, 21, 22, 23, 26, 30, 34, 35, 36, 38, 46, 50, 60, 63, 65, 68, 69, 71, 72, 73, 86, 87, 88, 90, 98, 109, 120, 123, 126, 127, 130, 132, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 233, 265, 268, 325, 326, 327, 328, 329, 330, 331, 332, 337, 344, 348, 350, 364, 367, 368, 369, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 401, 565, 611, 618, 620, 621, 622, 623, 624, 625, 626, 627, 628, 633, 634, 635, 636, 637, 639, 640], "being": [2, 3, 17, 18, 21, 22, 26, 27, 32, 34, 35, 36, 38, 41, 42, 44, 47, 49, 50, 70, 86, 87, 88, 96, 98, 101, 102, 114, 117, 120, 123, 126, 129, 130, 131, 132, 137, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 220, 229, 231, 232, 239, 245, 253, 265, 270, 271, 272, 301, 302, 304, 312, 325, 326, 327, 328, 330, 331, 332, 337, 350, 351, 364, 365, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 410, 417, 560, 561, 562, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585, 611, 618, 619, 620, 621, 626, 633, 634, 635, 637], "torchrl": [2, 3, 5, 6, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 590, 611, 617, 621, 623, 625, 626, 627, 628, 629, 632, 636, 637, 638], "two": [2, 6, 7, 18, 22, 23, 27, 29, 61, 62, 65, 68, 69, 72, 73, 83, 86, 87, 88, 107, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 226, 246, 250, 270, 277, 293, 302, 304, 317, 320, 325, 326, 327, 328, 330, 331, 332, 337, 344, 364, 367, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 408, 414, 566, 590, 618, 619, 620, 621, 622, 623, 624, 626, 627, 631, 632, 633, 634, 635, 637, 639, 640], "main": [2, 6, 7, 19, 24, 35, 36, 38, 41, 42, 47, 50, 51, 56, 66, 85, 127, 170, 193, 221, 226, 324, 344, 414, 563, 564, 565, 566, 567, 569, 570, 572, 574, 577, 579, 585, 590, 618, 619, 630, 631, 632, 639, 640], "argument": [2, 3, 6, 18, 19, 20, 21, 22, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 95, 96, 97, 98, 101, 102, 106, 107, 108, 109, 112, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 152, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 206, 212, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 244, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 286, 287, 288, 297, 298, 301, 302, 304, 305, 306, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 339, 340, 341, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 397, 399, 400, 401, 402, 406, 414, 418, 419, 551, 558, 559, 562, 576, 611, 618, 619, 620, 621, 622, 623, 624, 626, 633, 634, 635, 637, 639, 640], "list": [2, 21, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 96, 98, 106, 107, 108, 109, 110, 112, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 212, 219, 220, 224, 225, 229, 230, 232, 241, 242, 246, 248, 250, 258, 260, 268, 269, 270, 271, 272, 274, 275, 277, 279, 287, 288, 290, 296, 298, 300, 302, 304, 305, 306, 308, 313, 314, 322, 324, 325, 326, 327, 328, 330, 331, 332, 334, 337, 340, 344, 346, 347, 349, 351, 363, 365, 368, 370, 371, 372, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 388, 390, 391, 400, 401, 402, 408, 410, 426, 434, 435, 441, 442, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 474, 476, 477, 478, 479, 480, 481, 482, 483, 486, 487, 488, 489, 490, 492, 493, 494, 495, 496, 497, 499, 500, 502, 504, 505, 506, 507, 508, 511, 512, 513, 514, 515, 516, 517, 518, 519, 521, 522, 523, 524, 525, 526, 529, 530, 531, 532, 533, 534, 535, 536, 560, 561, 564, 566, 567, 569, 570, 572, 573, 574, 577, 579, 585, 611, 618, 620, 623, 624, 625, 626, 630, 631, 632, 633, 635, 636, 637, 639, 640], "constructor": [2, 17, 21, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 66, 68, 72, 73, 83, 86, 87, 101, 114, 120, 123, 126, 130, 138, 145, 150, 151, 154, 158, 159, 160, 163, 170, 171, 172, 175, 176, 177, 178, 179, 180, 195, 196, 217, 221, 270, 288, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 400, 401, 418, 559, 562, 576, 590, 611, 618, 619, 620, 623, 626, 633, 634, 637, 639], "iter": [2, 5, 18, 20, 34, 35, 36, 38, 50, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 98, 107, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 234, 246, 259, 282, 287, 288, 297, 305, 313, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 343, 345, 346, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 408, 410, 412, 414, 618, 620, 621, 626, 628, 633, 634, 635], "queri": [2, 18, 38, 86, 87, 88, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 203, 250, 275, 279, 325, 326, 327, 328, 330, 331, 332, 337, 346, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 618, 625, 630, 635, 639], "defin": [2, 7, 14, 21, 32, 34, 35, 36, 38, 41, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 251, 264, 282, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 347, 353, 355, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 413, 471, 559, 611, 618, 619, 621, 625, 628, 635, 637, 640], "number": [2, 16, 17, 18, 19, 27, 32, 34, 35, 36, 38, 39, 42, 44, 46, 47, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 106, 108, 109, 116, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 144, 145, 146, 147, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 231, 233, 234, 235, 237, 240, 241, 243, 245, 246, 249, 251, 252, 253, 255, 257, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 286, 288, 295, 299, 300, 301, 302, 303, 304, 305, 307, 308, 309, 312, 315, 316, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 397, 399, 400, 404, 406, 408, 414, 416, 417, 418, 419, 471, 551, 552, 560, 561, 562, 578, 579, 580, 585, 590, 618, 619, 620, 621, 623, 624, 626, 628, 633, 634, 635, 636, 637, 640], "stack": [2, 4, 10, 17, 18, 19, 22, 26, 27, 34, 35, 36, 38, 42, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 74, 75, 76, 77, 86, 87, 96, 101, 120, 123, 126, 129, 130, 131, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 186, 195, 196, 204, 205, 221, 226, 244, 279, 302, 304, 317, 325, 327, 328, 330, 331, 340, 345, 346, 349, 351, 363, 368, 370, 371, 372, 376, 378, 380, 381, 384, 385, 391, 404, 424, 519, 590, 619, 622, 623, 630, 631, 632, 633, 635, 639], "user": [2, 6, 12, 18, 20, 21, 22, 24, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 56, 78, 79, 83, 85, 87, 88, 89, 102, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 222, 239, 264, 270, 272, 294, 326, 332, 337, 351, 367, 370, 371, 375, 377, 379, 382, 383, 392, 559, 590, 618, 619, 623, 625, 626, 631, 635, 639, 640], "reach": [2, 18, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 107, 120, 123, 126, 130, 137, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 244, 263, 286, 301, 312, 618, 620, 628, 630, 633, 634, 639, 640], "done": [2, 17, 18, 19, 21, 22, 23, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 92, 93, 100, 102, 108, 109, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 215, 217, 218, 221, 229, 230, 232, 233, 234, 239, 243, 244, 245, 246, 248, 252, 253, 255, 257, 259, 262, 263, 265, 266, 269, 270, 271, 272, 273, 279, 302, 304, 320, 329, 340, 348, 349, 350, 351, 352, 353, 355, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 379, 382, 383, 385, 386, 387, 388, 389, 407, 491, 590, 611, 618, 620, 621, 622, 623, 625, 626, 628, 631, 632, 633, 634, 635, 637, 639, 640], "state": [2, 6, 17, 18, 21, 22, 23, 32, 34, 35, 36, 38, 40, 41, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 100, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 144, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 217, 220, 221, 222, 224, 225, 227, 230, 233, 236, 239, 243, 244, 246, 253, 263, 264, 269, 270, 271, 272, 273, 274, 279, 280, 283, 289, 294, 299, 302, 304, 305, 308, 311, 315, 316, 317, 323, 325, 326, 327, 328, 329, 330, 331, 332, 337, 340, 343, 348, 350, 351, 355, 357, 364, 365, 367, 368, 369, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 400, 407, 414, 416, 418, 419, 471, 562, 571, 576, 590, 599, 604, 612, 618, 619, 620, 621, 622, 623, 624, 625, 626, 630, 631, 633, 634, 635, 640], "after": [2, 4, 6, 19, 20, 22, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 66, 69, 78, 86, 87, 88, 97, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 135, 136, 137, 138, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 286, 297, 301, 302, 304, 313, 325, 326, 327, 328, 330, 331, 332, 337, 351, 360, 370, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 400, 401, 563, 564, 565, 566, 567, 569, 570, 571, 572, 574, 575, 577, 579, 585, 590, 611, 619, 620, 621, 622, 623, 624, 626, 628, 630, 633, 634, 635, 636, 637, 640], "predefin": [2, 7, 183, 392, 619, 621, 626, 637, 639], "becaus": [2, 18, 21, 22, 23, 26, 53, 60, 71, 78, 86, 87, 88, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 233, 241, 263, 278, 293, 297, 298, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 344, 348, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 618, 619, 621, 622, 624, 625, 626, 630, 632, 633, 634, 635, 637, 640], "comput": [2, 6, 17, 18, 21, 22, 23, 27, 34, 38, 39, 50, 52, 59, 86, 87, 88, 101, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 243, 246, 260, 272, 276, 280, 283, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 320, 321, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 340, 341, 344, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 407, 418, 419, 471, 552, 566, 572, 590, 593, 604, 611, 618, 620, 621, 622, 623, 624, 630, 631, 632, 633, 634, 636, 637], "heavi": [2, 6, 27, 78, 611, 637], "crucial": [2, 20, 86, 87, 176, 286, 301, 312, 325, 327, 328, 330, 331, 356, 363, 365, 376, 378, 379, 380, 381, 384, 419, 590, 618, 619, 620, 621, 623, 625, 627, 633, 634, 635, 639, 640], "hyperparamet": [2, 106, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 588, 618, 627, 635, 637], "appropri": [2, 6, 7, 17, 23, 26, 87, 94, 104, 114, 115, 118, 119, 138, 150, 158, 179, 180, 233, 559, 562, 590, 611, 618, 627, 637], "take": [2, 17, 20, 21, 22, 27, 41, 56, 80, 86, 87, 90, 111, 117, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 183, 224, 226, 263, 266, 267, 271, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 325, 327, 328, 330, 331, 338, 340, 341, 344, 347, 367, 376, 378, 380, 381, 384, 392, 404, 417, 590, 618, 619, 620, 622, 623, 624, 625, 633, 634, 635, 637, 640], "consider": [2, 21, 22, 27, 129, 131, 271, 324, 588, 590, 619, 633, 634, 637], "whether": [2, 18, 22, 32, 34, 35, 36, 38, 39, 42, 44, 47, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 97, 104, 116, 120, 123, 126, 130, 137, 138, 142, 143, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 217, 226, 227, 229, 232, 243, 264, 270, 272, 279, 280, 288, 302, 304, 305, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 340, 344, 348, 349, 350, 351, 352, 353, 355, 357, 358, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 403, 414, 418, 419, 471, 562, 564, 566, 567, 569, 570, 572, 574, 576, 577, 579, 581, 583, 585, 611, 618, 619, 620, 622, 623, 633, 634, 635, 639, 640], "should": [2, 5, 6, 7, 17, 18, 20, 21, 22, 23, 24, 26, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 95, 98, 102, 108, 109, 110, 114, 117, 120, 123, 124, 125, 126, 129, 130, 131, 132, 137, 138, 141, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 217, 218, 221, 224, 225, 226, 229, 230, 233, 234, 236, 241, 242, 244, 246, 251, 252, 253, 255, 258, 259, 263, 264, 266, 269, 271, 272, 273, 278, 279, 280, 282, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 341, 343, 344, 347, 348, 350, 351, 357, 364, 365, 367, 368, 369, 370, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 392, 394, 403, 408, 409, 410, 414, 558, 560, 561, 562, 565, 567, 569, 570, 572, 577, 578, 579, 585, 611, 618, 619, 620, 621, 622, 624, 626, 627, 630, 632, 633, 634, 635, 636, 637, 639, 640], "occur": [2, 6, 27, 35, 70, 71, 78, 120, 123, 126, 130, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 222, 234, 246, 251, 278, 297, 298, 313, 314, 326, 332, 337, 339, 341, 343, 344, 360, 375, 377, 379, 383, 590, 622, 637, 640], "serial": [2, 6, 15, 18, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 279, 280, 326, 332, 337, 375, 377, 379, 382, 383], "multisynccollector": [2, 3, 5, 34, 35, 36, 42, 44, 47, 50, 53, 561, 566], "split": [2, 6, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 71, 78, 79, 80, 81, 82, 83, 84, 85, 102, 108, 109, 141, 152, 153, 171, 307, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 620, 624, 637, 639], "workload": [2, 324], "result": [2, 3, 7, 17, 18, 20, 21, 22, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 56, 58, 65, 66, 67, 68, 69, 72, 73, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 102, 107, 108, 109, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 212, 213, 214, 217, 218, 219, 221, 222, 223, 224, 225, 227, 228, 229, 230, 231, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 286, 298, 301, 302, 304, 305, 314, 320, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 337, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 400, 416, 417, 590, 611, 619, 621, 623, 624, 627, 628, 631, 635, 636, 639, 640], "final": [2, 7, 21, 22, 23, 50, 86, 87, 172, 175, 176, 177, 183, 265, 278, 286, 301, 302, 304, 312, 324, 325, 327, 328, 330, 331, 333, 334, 345, 376, 378, 380, 381, 384, 385, 408, 618, 619, 620, 622, 627, 628, 630, 633, 634, 635, 640], "multiasynccollector": [2, 5, 32, 36, 38, 42, 44, 47, 50, 560], "continu": [2, 21, 28, 58, 60, 75, 76, 87, 109, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 206, 214, 239, 265, 273, 290, 291, 292, 293, 312, 326, 346, 349, 385, 419, 565, 618, 620, 621, 624, 633, 634, 637], "concomitantli": [2, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180], "network": [2, 6, 23, 27, 81, 88, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 283, 284, 285, 288, 290, 291, 292, 293, 296, 299, 300, 305, 308, 309, 315, 316, 317, 326, 332, 337, 343, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 413, 419, 462, 464, 465, 466, 468, 471, 557, 558, 588, 597, 603, 622, 625, 628, 632, 635, 640], "impli": [2, 640], "slightli": [2, 56, 78, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 621, 622, 633, 635, 636, 637, 640], "therefor": [2, 19, 21, 22, 26, 65, 68, 72, 73, 84, 85, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 183, 255, 325, 327, 328, 330, 331, 367, 376, 378, 380, 381, 382, 384, 622, 625, 633, 640], "fastest": 2, "price": 2, "suitabl": [2, 6, 221, 379], "curriculum": [2, 23], "remot": [2, 6, 10, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 150, 158, 176, 189, 194, 195, 280, 325, 327, 328, 329, 330, 331, 337, 376, 378, 380, 381, 384, 400, 401, 568, 569, 570, 571, 572, 578, 583, 584, 585, 611, 640], "rollout": [2, 16, 17, 18, 20, 22, 30, 32, 34, 35, 36, 38, 50, 52, 53, 56, 114, 120, 121, 122, 123, 126, 130, 132, 133, 136, 137, 138, 142, 143, 144, 145, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 165, 170, 171, 172, 175, 178, 179, 180, 185, 214, 215, 217, 218, 221, 224, 226, 227, 229, 232, 233, 234, 239, 241, 242, 248, 252, 253, 258, 259, 260, 263, 264, 266, 267, 270, 273, 279, 280, 287, 302, 304, 312, 317, 340, 348, 390, 392, 552, 604, 618, 620, 621, 624, 625, 626, 627, 628, 636, 637, 639], "necessari": [2, 6, 23, 25, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 78, 80, 81, 83, 84, 85, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 259, 368, 385, 386, 387, 388, 389, 618, 620, 624, 625, 626, 630, 631], "synchronis": [2, 127, 633, 634], "either": [2, 5, 24, 51, 55, 57, 65, 66, 68, 69, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 243, 244, 263, 264, 280, 323, 326, 332, 334, 337, 365, 371, 372, 375, 377, 379, 382, 383, 396, 590, 598, 618, 619, 621, 633, 636, 637, 639, 640], "update_at_each_batch": [2, 32, 35, 36, 38], "second": [2, 6, 22, 27, 32, 34, 35, 36, 38, 52, 56, 61, 62, 78, 80, 114, 150, 184, 190, 192, 197, 218, 267, 298, 302, 304, 324, 350, 364, 367, 370, 392, 394, 397, 399, 412, 563, 564, 565, 566, 568, 569, 570, 571, 572, 574, 575, 577, 579, 585, 611, 618, 620, 626, 633, 634, 635, 637, 639, 640], "oper": [2, 3, 6, 17, 21, 22, 23, 26, 27, 32, 34, 35, 36, 38, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 96, 97, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 236, 241, 267, 269, 273, 280, 283, 284, 285, 296, 297, 298, 323, 325, 326, 327, 328, 329, 330, 331, 332, 337, 343, 348, 350, 352, 353, 358, 364, 367, 369, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 400, 401, 414, 564, 566, 571, 578, 579, 580, 583, 590, 592, 604, 618, 619, 620, 621, 622, 623, 624, 632, 633, 634, 635, 640], "instanc": [2, 6, 7, 17, 20, 21, 22, 23, 26, 27, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 58, 60, 65, 66, 67, 68, 69, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 95, 96, 97, 100, 102, 108, 109, 116, 120, 123, 125, 126, 127, 129, 130, 131, 135, 138, 144, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 213, 246, 265, 272, 279, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341, 343, 344, 345, 346, 347, 349, 351, 353, 356, 357, 363, 365, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 392, 396, 402, 403, 408, 416, 417, 464, 552, 553, 554, 558, 560, 561, 574, 577, 579, 585, 590, 611, 618, 620, 621, 622, 623, 624, 630, 635, 637, 640], "cpu": [2, 3, 6, 18, 22, 27, 29, 32, 34, 35, 36, 38, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 101, 108, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 214, 218, 225, 229, 230, 232, 233, 234, 239, 242, 243, 248, 250, 252, 253, 255, 259, 262, 263, 265, 271, 272, 273, 275, 277, 283, 284, 285, 287, 296, 297, 298, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 329, 330, 331, 332, 337, 339, 340, 341, 343, 346, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 400, 441, 442, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 488, 507, 531, 532, 533, 573, 611, 618, 619, 620, 621, 633, 634, 635, 636, 639], "slower": [2, 3, 8, 9, 566, 633], "than": [2, 3, 6, 22, 23, 27, 32, 34, 35, 36, 38, 42, 44, 46, 47, 50, 52, 53, 57, 65, 68, 69, 72, 73, 78, 79, 83, 86, 87, 88, 102, 108, 109, 112, 114, 120, 123, 126, 130, 134, 138, 148, 149, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 189, 195, 226, 242, 244, 253, 280, 286, 293, 297, 302, 304, 305, 307, 322, 325, 327, 328, 330, 331, 332, 339, 343, 344, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 417, 566, 579, 589, 590, 611, 618, 619, 620, 621, 622, 623, 625, 633, 634, 635, 637, 639, 640], "one": [2, 3, 6, 7, 17, 18, 20, 21, 22, 23, 24, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 83, 86, 87, 88, 92, 93, 94, 95, 100, 101, 102, 104, 108, 109, 110, 112, 114, 115, 118, 119, 120, 121, 122, 123, 126, 127, 129, 130, 131, 132, 134, 135, 136, 137, 138, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 221, 224, 226, 227, 229, 230, 231, 232, 239, 242, 243, 245, 246, 250, 255, 258, 261, 262, 264, 265, 266, 271, 272, 274, 277, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 339, 340, 341, 343, 344, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 392, 394, 402, 406, 408, 409, 414, 552, 562, 564, 574, 585, 589, 590, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 632, 633, 634, 635, 636, 637, 640], "cuda": [2, 3, 21, 22, 26, 34, 35, 36, 38, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 121, 122, 123, 126, 130, 132, 133, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 241, 249, 250, 265, 271, 272, 275, 277, 326, 332, 333, 337, 343, 375, 377, 379, 382, 383, 405, 573, 578, 618, 619, 620, 621, 633, 634, 636, 640], "dispatch": [2, 5, 22, 42, 44, 47, 50, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 326, 332, 337, 340, 375, 377, 379, 382, 383, 392, 564, 566, 569, 570, 572, 574, 577, 579, 585, 618, 640], "speed": [2, 5, 22, 23, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 611, 618, 619, 620, 621, 633, 634, 635, 637, 639], "avoid": [2, 7, 17, 20, 81, 88, 95, 97, 108, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 221, 239, 270, 272, 279, 280, 320, 322, 326, 332, 337, 339, 343, 350, 351, 364, 367, 370, 375, 377, 379, 382, 383, 551, 563, 566, 568, 570, 572, 573, 590, 611, 620, 622, 631, 634], "oom": [2, 20, 86, 87, 95, 97, 116, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "choic": [2, 15, 63, 79, 85, 86, 87, 150, 176, 185, 307, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 418, 618, 619, 625, 633, 634], "pass": [2, 4, 5, 6, 9, 12, 17, 18, 19, 20, 21, 22, 23, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 57, 60, 63, 65, 66, 68, 69, 71, 72, 73, 74, 78, 80, 81, 83, 84, 85, 86, 87, 88, 93, 95, 97, 102, 108, 109, 114, 116, 120, 123, 126, 127, 128, 130, 131, 138, 141, 145, 150, 151, 152, 153, 154, 158, 159, 160, 163, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 215, 217, 218, 221, 225, 227, 229, 232, 242, 244, 252, 253, 270, 271, 274, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 313, 314, 315, 316, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 339, 340, 341, 343, 344, 346, 347, 349, 350, 351, 363, 364, 365, 367, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 400, 401, 402, 410, 414, 418, 419, 560, 561, 562, 570, 573, 574, 590, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 632, 633, 634, 635, 637, 639, 640], "ie": [2, 17, 42, 47, 51, 57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 72, 74, 75, 76, 77, 83, 101, 109, 120, 123, 126, 130, 134, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 214, 221, 236, 262, 265, 274, 279, 302, 304, 326, 332, 337, 343, 375, 377, 379, 383, 619, 634], "while": [2, 6, 7, 17, 21, 22, 26, 27, 32, 34, 35, 36, 38, 52, 56, 66, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 255, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 340, 347, 350, 356, 363, 364, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 571, 590, 611, 618, 620, 621, 624, 626, 627, 633, 634, 635, 636, 637, 639], "wait": [2, 6, 32, 33, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 66, 95, 97, 161, 183, 324, 563, 564, 565, 566, 568, 569, 570, 571, 572, 574, 575, 577, 578, 579, 585, 621, 635], "impact": [2, 18, 33, 42, 43, 44, 45, 47, 48, 83, 137, 229, 232, 332, 348, 350, 364, 367, 369, 379, 619, 621, 633, 634], "memori": [2, 3, 4, 6, 9, 10, 12, 18, 21, 27, 32, 35, 36, 38, 50, 55, 59, 66, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 90, 91, 93, 95, 96, 100, 120, 121, 122, 123, 126, 127, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 221, 225, 250, 265, 271, 272, 275, 277, 279, 280, 295, 325, 326, 327, 328, 330, 331, 332, 337, 343, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 423, 562, 564, 565, 566, 569, 570, 572, 573, 574, 577, 579, 580, 585, 590, 611, 618, 619, 621, 633, 637, 639], "which": [2, 3, 5, 6, 7, 10, 17, 18, 19, 21, 22, 23, 26, 27, 32, 34, 35, 36, 37, 38, 41, 42, 44, 47, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 92, 96, 106, 107, 114, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 205, 221, 222, 226, 229, 232, 237, 239, 241, 242, 245, 246, 250, 251, 253, 263, 265, 266, 269, 270, 271, 272, 273, 275, 279, 282, 283, 284, 285, 296, 302, 303, 304, 306, 317, 321, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 343, 344, 345, 346, 348, 349, 350, 351, 353, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 392, 400, 404, 409, 418, 564, 565, 566, 569, 570, 572, 574, 577, 579, 585, 590, 592, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 630, 632, 633, 634, 635, 636, 637, 640], "storing_devic": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 619, 621, 634], "dure": [2, 6, 10, 18, 20, 21, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 93, 95, 97, 98, 101, 102, 106, 108, 120, 123, 126, 127, 130, 137, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 182, 185, 191, 198, 199, 217, 218, 221, 224, 229, 232, 234, 236, 237, 239, 244, 248, 260, 262, 265, 267, 269, 270, 272, 273, 274, 279, 280, 287, 302, 304, 324, 332, 340, 350, 367, 379, 383, 385, 387, 388, 408, 414, 416, 419, 563, 565, 566, 572, 574, 582, 583, 586, 590, 601, 618, 619, 620, 621, 624, 625, 626, 628, 633, 634, 635, 637, 640], "heurist": [2, 23, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 176, 286, 325, 327, 328, 330, 331, 340, 344, 376, 378, 380, 381, 384, 618, 622, 626, 640], "usual": [2, 17, 18, 21, 23, 25, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 79, 106, 114, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 270, 367, 371, 379, 383, 385, 386, 387, 388, 389, 391, 589, 590, 592, 618, 619, 620, 621, 624, 626, 627, 634, 637, 640], "same": [2, 4, 5, 6, 7, 18, 19, 21, 22, 23, 34, 41, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 83, 86, 87, 88, 107, 108, 109, 112, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 141, 145, 146, 150, 151, 152, 153, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 221, 229, 231, 232, 237, 239, 242, 244, 245, 246, 262, 270, 271, 272, 279, 282, 288, 305, 306, 312, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 347, 349, 351, 363, 365, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 418, 563, 564, 566, 568, 569, 571, 572, 579, 580, 585, 586, 590, 611, 618, 619, 620, 623, 624, 626, 630, 631, 632, 633, 634, 636, 637, 640], "default": [2, 3, 6, 7, 17, 19, 21, 22, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 95, 96, 97, 98, 101, 102, 104, 106, 107, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 205, 206, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 245, 246, 248, 249, 250, 251, 252, 253, 255, 257, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311, 312, 313, 314, 315, 316, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 394, 397, 398, 399, 400, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 417, 418, 419, 462, 471, 558, 562, 564, 565, 566, 567, 569, 570, 571, 572, 574, 576, 577, 579, 581, 583, 585, 618, 619, 620, 621, 624, 633, 636, 637, 639, 640], "besid": 2, "those": [2, 22, 24, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 199, 221, 226, 229, 232, 239, 246, 265, 266, 269, 273, 304, 341, 344, 345, 346, 417, 560, 561, 564, 566, 569, 570, 572, 577, 579, 585, 618, 619, 623, 624, 634, 635, 640], "max_frames_per_traj": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 551, 618, 620, 639], "frame": [2, 30, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 78, 90, 221, 237, 286, 301, 312, 340, 391, 392, 394, 397, 399, 406, 408, 414, 418, 419, 471, 551, 552, 618, 619, 620, 621, 624, 633, 634, 637, 639, 640], "call": [2, 6, 7, 8, 17, 18, 20, 21, 22, 26, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 102, 103, 107, 108, 110, 112, 116, 117, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 135, 136, 137, 138, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 203, 210, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 230, 231, 233, 234, 235, 236, 237, 239, 240, 241, 243, 244, 246, 248, 249, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 340, 343, 344, 346, 347, 349, 350, 351, 357, 363, 364, 365, 367, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 394, 400, 401, 408, 410, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 574, 575, 577, 578, 579, 583, 584, 585, 590, 592, 611, 619, 620, 621, 622, 623, 624, 626, 627, 633, 634, 635, 637, 639, 640], "init_random_fram": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 551, 618, 619, 622, 628], "random": [2, 7, 19, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 85, 103, 114, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 185, 214, 231, 245, 246, 265, 272, 287, 301, 302, 324, 326, 332, 337, 341, 342, 343, 344, 349, 365, 368, 374, 375, 377, 379, 383, 408, 418, 419, 428, 466, 471, 503, 552, 604, 618, 619, 620, 622, 623, 624, 626, 635, 636, 637, 639, 640], "rand_step": [2, 19, 22, 120, 123, 124, 125, 126, 127, 129, 130, 131, 138, 139, 140, 144, 145, 146, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 240, 265, 279, 635, 639, 640], "reset_at_each_it": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 618], "split_traj": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 79, 81, 83, 84, 85, 618, 619, 620], "trajectori": [2, 4, 17, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 56, 72, 78, 79, 80, 81, 83, 84, 85, 101, 102, 108, 109, 114, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 251, 263, 270, 304, 312, 367, 382, 385, 388, 404, 432, 433, 618, 619, 620, 621, 623, 626, 628, 635, 639, 640], "pad": [2, 22, 56, 79, 81, 83, 84, 85, 87, 185, 188, 189, 195, 196, 199, 205, 221, 269, 288, 290, 291, 304, 306, 326, 327, 328, 329, 330, 331, 332, 337, 379, 410, 462, 590, 631], "along": [2, 18, 22, 35, 36, 38, 56, 57, 58, 59, 60, 61, 62, 63, 64, 69, 70, 71, 74, 75, 76, 77, 79, 81, 83, 84, 85, 86, 87, 88, 97, 102, 108, 109, 114, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 205, 206, 220, 221, 222, 244, 246, 248, 251, 258, 262, 268, 297, 304, 305, 306, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 344, 351, 365, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 618, 619, 621, 623, 625, 633, 634, 635, 637, 639], "mask": [2, 16, 18, 22, 23, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 87, 89, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 195, 196, 215, 251, 287, 297, 298, 301, 306, 313, 314, 326, 329, 332, 337, 357, 370, 375, 379, 383, 407, 410, 590, 592, 619, 621, 622, 631, 640], "point": [2, 19, 22, 51, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 70, 71, 74, 75, 76, 77, 82, 88, 94, 101, 102, 104, 114, 115, 118, 119, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 275, 276, 277, 278, 279, 324, 326, 332, 337, 343, 358, 375, 377, 379, 382, 383, 414, 589, 612, 614, 619, 620, 632, 633, 634, 635, 637, 639, 640], "boolean": [2, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 108, 109, 130, 180, 213, 217, 226, 251, 263, 306, 312, 590, 621], "repres": [2, 17, 19, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 60, 63, 71, 72, 81, 86, 87, 96, 120, 123, 124, 125, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 237, 251, 267, 279, 297, 298, 306, 313, 314, 320, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 385, 410, 598, 618, 620, 621, 622, 623, 624, 625, 633, 634], "valid": [2, 7, 19, 56, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 166, 170, 171, 172, 175, 178, 179, 180, 217, 251, 270, 272, 286, 288, 305, 306, 312, 326, 329, 350, 357, 364, 367, 370, 377, 379, 385, 386, 387, 388, 410, 622, 640], "valu": [2, 7, 17, 18, 19, 21, 22, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 101, 102, 108, 109, 114, 120, 123, 126, 130, 131, 138, 141, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 203, 206, 211, 212, 213, 214, 217, 219, 221, 222, 224, 227, 229, 230, 231, 232, 233, 239, 245, 246, 250, 251, 254, 255, 256, 258, 260, 262, 265, 266, 270, 271, 272, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 290, 291, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 310, 312, 313, 314, 318, 319, 320, 321, 322, 325, 326, 327, 328, 330, 331, 332, 337, 338, 339, 341, 343, 344, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 392, 403, 404, 406, 407, 408, 409, 410, 414, 418, 468, 471, 558, 588, 597, 604, 619, 622, 625, 626, 627, 632, 633, 634, 635, 637, 639, 640], "exploration_typ": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 408, 466, 618, 619], "explor": [2, 7, 281, 286, 297, 298, 301, 312, 313, 314, 339, 341, 343, 344, 348, 365, 367, 408, 419, 553, 554, 558, 588, 597, 620, 621, 622, 623, 625, 626, 628, 633, 634, 635], "reset_when_don": [2, 32, 34, 35, 36, 38], "its": [2, 6, 17, 18, 19, 21, 22, 23, 24, 26, 28, 30, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 72, 74, 75, 76, 77, 86, 87, 88, 97, 101, 102, 108, 109, 120, 123, 126, 130, 137, 138, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 220, 221, 227, 233, 241, 263, 264, 265, 270, 272, 278, 279, 280, 282, 286, 288, 297, 302, 304, 306, 307, 313, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 347, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 370, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 414, 418, 419, 558, 564, 569, 572, 573, 585, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 633, 634, 635, 636, 637, 639, 640], "within": [2, 20, 21, 22, 32, 35, 36, 38, 41, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 96, 101, 102, 109, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 280, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 344, 347, 353, 358, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 392, 400, 414, 611, 619, 622, 623, 624, 625, 626, 627, 628, 633, 635, 639], "how": [2, 5, 6, 13, 17, 19, 21, 30, 41, 42, 44, 47, 65, 72, 83, 86, 87, 88, 101, 102, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 242, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 348, 350, 364, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 394, 414, 416, 577, 581, 588, 589, 618, 619, 620, 621, 622, 623, 624, 626, 627, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "tabl": [2, 379, 619, 624], "summar": [2, 17, 187, 635], "what": [2, 7, 18, 19, 21, 22, 27, 30, 35, 36, 38, 65, 74, 78, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 195, 196, 212, 233, 265, 270, 313, 351, 362, 365, 371, 375, 377, 379, 383, 589, 618, 619, 620, 621, 622, 623, 624, 625, 626, 628, 630, 631, 633, 634, 635, 636, 637, 639, 640], "expect": [2, 5, 6, 8, 17, 18, 21, 22, 23, 26, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 81, 86, 87, 88, 102, 107, 108, 120, 123, 126, 130, 138, 144, 147, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 214, 218, 219, 220, 221, 222, 223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 238, 240, 241, 242, 243, 244, 246, 248, 250, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 298, 302, 304, 312, 324, 325, 326, 327, 328, 330, 331, 332, 337, 343, 346, 348, 349, 350, 351, 352, 353, 355, 356, 357, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 552, 589, 611, 618, 620, 621, 623, 624, 625, 626, 630, 631, 633, 634, 635, 637, 640], "n": [2, 4, 6, 17, 19, 25, 26, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 101, 102, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 231, 236, 274, 312, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 344, 348, 349, 357, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 410, 479, 590, 619, 621, 622, 631, 637, 639, 640], "b": [2, 22, 26, 27, 52, 56, 60, 68, 71, 72, 73, 86, 87, 95, 96, 114, 123, 176, 197, 201, 239, 273, 325, 326, 327, 328, 330, 331, 332, 337, 347, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 392, 619, 630, 637], "cat_result": [2, 4, 35, 36, 38], "na": [2, 172, 175, 193], "t": [2, 4, 12, 21, 22, 23, 25, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 92, 101, 102, 107, 108, 109, 114, 120, 123, 126, 127, 129, 130, 138, 145, 146, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 239, 240, 241, 243, 249, 250, 251, 252, 253, 254, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 277, 278, 279, 282, 297, 302, 304, 306, 312, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 343, 348, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 392, 399, 414, 417, 562, 579, 589, 590, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 632, 633, 634, 635, 636, 637, 639, 640], "p": [2, 23, 69, 101, 102, 106, 127, 156, 157, 287, 317], "In": [2, 3, 4, 6, 7, 8, 12, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 51, 52, 78, 79, 81, 83, 84, 85, 86, 87, 88, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 229, 230, 232, 240, 250, 255, 259, 264, 265, 268, 270, 271, 272, 275, 277, 278, 280, 282, 303, 305, 316, 320, 321, 325, 326, 327, 328, 330, 331, 332, 337, 343, 344, 346, 348, 349, 351, 352, 353, 355, 356, 357, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 417, 560, 561, 562, 584, 585, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 633, 634, 635, 636, 637, 640], "case": [2, 4, 6, 7, 15, 18, 19, 20, 21, 22, 23, 24, 26, 27, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 92, 93, 100, 114, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 195, 197, 229, 230, 232, 240, 246, 265, 268, 272, 273, 282, 304, 305, 325, 327, 328, 330, 331, 341, 343, 344, 346, 347, 348, 349, 351, 352, 353, 355, 356, 357, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 392, 401, 404, 417, 560, 561, 562, 590, 591, 618, 619, 620, 621, 622, 623, 624, 626, 627, 631, 633, 634, 635, 637, 639, 640], "dimens": [2, 4, 17, 18, 19, 22, 34, 35, 36, 38, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 79, 81, 83, 84, 85, 86, 87, 95, 96, 97, 102, 108, 109, 114, 116, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 177, 178, 179, 180, 185, 205, 206, 214, 220, 221, 222, 236, 244, 246, 248, 251, 258, 261, 262, 265, 268, 274, 279, 280, 288, 289, 294, 295, 297, 302, 304, 305, 306, 311, 319, 320, 325, 327, 328, 330, 331, 332, 337, 338, 340, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 562, 590, 618, 619, 620, 621, 623, 630, 633, 634, 635, 637], "time": [2, 4, 5, 7, 17, 22, 23, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 56, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 92, 95, 114, 120, 121, 122, 123, 126, 127, 130, 136, 137, 138, 141, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 212, 220, 221, 222, 244, 251, 258, 265, 266, 267, 270, 272, 279, 287, 299, 304, 312, 317, 325, 326, 327, 328, 330, 331, 332, 337, 340, 344, 349, 350, 351, 357, 360, 363, 364, 365, 367, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 414, 418, 471, 524, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 574, 575, 577, 579, 585, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 633, 634, 635, 637, 639, 640], "adapt": [2, 4, 215, 244, 263, 279, 324, 357, 364, 370, 590, 618, 622, 635], "equal": [2, 32, 35, 36, 38, 78, 88, 102, 108, 109, 123, 145, 148, 149, 150, 158, 178, 245, 246, 288, 302, 304, 305, 306, 350, 367, 379, 404, 560, 561, 618, 620, 636], "i": [2, 5, 6, 17, 19, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 60, 65, 68, 71, 73, 86, 87, 88, 90, 91, 95, 97, 101, 102, 108, 109, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 228, 244, 250, 255, 258, 270, 272, 277, 298, 302, 304, 307, 314, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 343, 344, 348, 350, 351, 352, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 404, 551, 571, 590, 618, 619, 620, 621, 622, 624, 625, 626, 627, 628, 633, 634, 635, 637, 639, 640], "introduc": [2, 101, 102, 150, 158, 302, 304, 312, 618, 633], "some": [2, 6, 8, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 51, 57, 58, 59, 60, 61, 62, 63, 64, 66, 68, 69, 70, 71, 74, 75, 76, 77, 79, 85, 86, 87, 88, 90, 95, 97, 114, 116, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 203, 217, 250, 265, 272, 275, 290, 302, 325, 326, 327, 328, 330, 331, 332, 337, 344, 345, 346, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 404, 551, 564, 566, 569, 570, 572, 574, 575, 577, 579, 585, 590, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 633, 634, 635, 637, 639, 640], "confus": [2, 57, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 326, 332, 337, 375, 377, 379, 382, 383], "other": [2, 3, 5, 6, 7, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 30, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 74, 75, 76, 77, 78, 79, 81, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 106, 107, 108, 109, 110, 112, 116, 120, 123, 126, 129, 130, 131, 135, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 224, 226, 230, 231, 252, 259, 265, 268, 275, 279, 280, 298, 301, 302, 304, 307, 314, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 344, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 400, 402, 407, 410, 560, 561, 565, 573, 584, 585, 588, 590, 604, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 633, 634, 635, 636, 639, 640], "better": [2, 6, 19, 22, 27, 28, 34, 35, 36, 38, 54, 55, 56, 137, 170, 171, 172, 175, 177, 189, 302, 304, 324, 333, 337, 590, 620, 623, 635, 639], "consist": [2, 5, 16, 17, 18, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 80, 83, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 278, 288, 305, 326, 332, 337, 375, 377, 379, 382, 383, 583, 586, 594, 611, 618, 619, 620, 631, 635, 636, 640], "interact": [2, 20, 21, 23, 24, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 83, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 181, 184, 272, 341, 344, 419, 590, 618, 620, 622, 623, 624, 626, 633, 634, 635, 640], "separ": [2, 4, 6, 7, 23, 27, 32, 34, 35, 36, 38, 42, 47, 50, 52, 56, 60, 68, 71, 72, 73, 78, 80, 86, 87, 176, 183, 221, 250, 277, 324, 325, 327, 328, 330, 331, 349, 352, 355, 357, 368, 370, 371, 372, 376, 378, 380, 381, 384, 385, 400, 578, 590, 611, 618, 619, 624, 625, 633, 634, 637, 640], "interchang": [2, 620, 623, 627, 631, 636, 637], "wherea": [2, 51, 52, 63, 83, 88, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 231, 270, 272, 326, 332, 337, 351, 365, 370, 375, 377, 379, 382, 383, 627], "correspond": [2, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 72, 74, 75, 76, 77, 80, 83, 85, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 250, 265, 270, 272, 277, 279, 280, 301, 302, 304, 306, 312, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 351, 353, 356, 357, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 401, 563, 618, 619, 620, 622, 623, 625, 626, 627, 633, 634, 635, 636], "sub": [2, 3, 6, 21, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 71, 78, 83, 88, 108, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 251, 270, 271, 280, 326, 332, 337, 345, 346, 375, 377, 379, 382, 383, 404, 414, 564, 566, 569, 570, 572, 574, 577, 579, 585, 618, 619, 620, 626, 632, 639, 640], "doesn": [2, 23, 32, 35, 36, 38, 88, 114, 120, 123, 126, 130, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 282, 326, 329, 332, 337, 375, 377, 379, 382, 383, 579, 622, 623], "understood": [2, 618], "basi": [2, 114, 637, 639], "we": [2, 6, 12, 17, 18, 19, 21, 22, 24, 26, 28, 30, 53, 54, 56, 60, 65, 68, 72, 73, 78, 79, 83, 85, 88, 95, 107, 109, 114, 120, 121, 122, 123, 126, 127, 130, 134, 136, 137, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 226, 241, 250, 253, 259, 270, 275, 278, 279, 280, 282, 304, 306, 324, 326, 332, 337, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 392, 418, 563, 566, 574, 589, 590, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 632, 633, 634, 635, 636, 637, 639, 640], "anoth": [2, 18, 21, 22, 27, 37, 39, 40, 41, 46, 49, 54, 74, 83, 87, 96, 102, 108, 120, 123, 126, 129, 130, 131, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 196, 218, 227, 229, 230, 232, 265, 271, 305, 341, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 401, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 417, 618, 620, 621, 622, 624, 625, 632, 633, 634, 635, 640], "wise": [2, 244, 379], "requir": [2, 4, 6, 17, 18, 22, 23, 26, 27, 32, 34, 35, 36, 37, 38, 39, 40, 42, 44, 46, 47, 49, 50, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 81, 83, 86, 87, 88, 96, 101, 102, 108, 109, 120, 123, 126, 130, 134, 138, 145, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 225, 226, 239, 250, 262, 265, 270, 271, 272, 275, 277, 280, 302, 304, 305, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 343, 344, 345, 346, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 392, 394, 402, 417, 418, 471, 579, 584, 585, 590, 618, 619, 620, 621, 623, 624, 625, 627, 630, 631, 633, 634, 635, 637, 639, 640], "method": [2, 6, 16, 20, 21, 22, 23, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 108, 109, 110, 111, 112, 114, 116, 120, 123, 126, 129, 130, 131, 132, 137, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 233, 234, 235, 236, 237, 240, 241, 243, 244, 246, 249, 250, 251, 252, 253, 254, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 295, 297, 298, 301, 302, 304, 313, 314, 317, 324, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 342, 343, 344, 345, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 362, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 389, 390, 391, 400, 401, 407, 419, 559, 563, 564, 565, 566, 567, 569, 570, 571, 572, 573, 574, 577, 578, 579, 581, 583, 585, 588, 604, 611, 616, 619, 620, 621, 622, 623, 624, 625, 626, 627, 630, 633, 635, 637, 640], "op": [2, 6, 7, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 57, 58, 59, 61, 62, 63, 64, 74, 75, 76, 77, 186, 245, 278, 286, 301, 392, 417, 563, 565, 567, 568, 573, 575, 583], "sinc": [2, 3, 6, 19, 21, 23, 24, 26, 30, 32, 34, 35, 36, 38, 41, 52, 53, 54, 56, 65, 68, 72, 73, 78, 85, 86, 87, 88, 101, 102, 109, 114, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 155, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 227, 286, 287, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 347, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 392, 564, 566, 569, 570, 571, 572, 574, 577, 579, 585, 590, 618, 619, 620, 621, 623, 624, 625, 630, 633, 635, 636, 637, 639, 640], "goal": [2, 17, 23, 78, 79, 80, 81, 82, 83, 84, 85, 138, 179, 264, 618, 619, 620, 621, 630, 634, 635], "policy_devic": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 619], "explicitli": [2, 22, 23, 59, 69, 89, 92, 93, 100, 217, 341, 403, 611, 619, 621, 626, 633, 634, 637], "do": [2, 5, 6, 17, 21, 22, 23, 26, 63, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 177, 178, 179, 180, 193, 195, 196, 212, 214, 226, 251, 265, 270, 278, 279, 284, 302, 304, 344, 365, 375, 377, 379, 383, 385, 392, 584, 585, 590, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 632, 633, 634, 635, 637, 639, 640], "deepcopi": [2, 365, 375, 377, 379, 383, 633], "structur": [2, 6, 7, 12, 16, 17, 22, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 63, 65, 68, 72, 73, 74, 86, 87, 96, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 185, 195, 196, 202, 213, 229, 232, 265, 312, 325, 326, 327, 328, 330, 331, 332, 337, 348, 357, 367, 370, 376, 378, 380, 381, 384, 385, 386, 387, 388, 389, 422, 590, 597, 604, 611, 618, 620, 621, 623, 626, 633, 634, 635, 636], "place": [2, 7, 21, 22, 40, 60, 69, 71, 86, 87, 88, 95, 97, 106, 108, 116, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 217, 225, 233, 250, 265, 271, 272, 275, 277, 278, 279, 325, 326, 327, 328, 329, 330, 331, 332, 337, 340, 343, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 410, 417, 551, 564, 566, 567, 569, 570, 572, 573, 574, 576, 577, 579, 581, 583, 585, 590, 619, 620, 624, 627, 633, 634, 635, 637], "instanti": [2, 6, 7, 17, 22, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 101, 102, 134, 137, 176, 180, 217, 225, 239, 265, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 385, 386, 387, 388, 389, 390, 400, 401, 418, 462, 463, 466, 467, 468, 611, 618, 619, 624, 625, 627, 633, 634, 635, 637, 640], "graph": [2, 21, 23, 27, 86, 87, 121, 122, 136, 137, 176, 189, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 383, 384, 618, 622, 635], "reli": [2, 6, 17, 30, 56, 265, 302, 304, 335, 336, 348, 367, 385, 416, 618, 620, 622, 624, 626, 635, 640], "third": [2, 246, 267, 298, 633, 634], "parti": 2, "try": [2, 23, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 60, 71, 86, 87, 176, 325, 326, 327, 328, 330, 331, 332, 337, 376, 378, 380, 381, 384, 590, 618, 619, 620, 622, 625, 626, 631, 633, 634, 635, 639, 640], "limit": [2, 5, 7, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 189, 195, 196, 221, 241, 348, 350, 364, 365, 367, 369, 375, 377, 379, 383, 590, 611, 618, 619, 621, 633, 634, 635], "chart": 2, "show": [2, 7, 30, 35, 36, 38, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 324, 326, 332, 337, 375, 377, 379, 382, 383, 392, 418, 419, 471, 618, 620, 621, 622, 630, 633, 634, 635, 637, 639], "decis": [2, 18, 19, 289, 294, 311, 354, 366, 621, 623, 624, 633, 634, 637, 640], "tree": [2, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 221, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 633, 637], "These": [3, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 80, 85, 117, 163, 250, 277, 280, 375, 377, 379, 383, 590, 597, 604, 611, 618, 620, 633, 634, 635, 637, 640], "gloo": [3, 42, 44, 47, 51, 564, 570, 571, 572], "nccl": [3, 42, 44, 47, 324, 335, 336, 564, 570, 571, 572, 578, 579, 583, 584, 585], "mpi": [3, 42, 44, 47], "launcher": [3, 42, 44, 47, 51], "submitit": [3, 42, 44, 47, 51], "torch": [3, 6, 10, 17, 18, 19, 21, 22, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 104, 107, 108, 109, 114, 115, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 213, 214, 215, 217, 218, 219, 220, 222, 225, 226, 227, 229, 230, 231, 232, 233, 234, 239, 241, 242, 243, 246, 248, 250, 252, 253, 255, 257, 258, 259, 260, 262, 263, 264, 265, 266, 268, 271, 272, 273, 275, 277, 279, 280, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 319, 320, 321, 322, 324, 325, 326, 327, 328, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 394, 404, 411, 412, 419, 462, 463, 466, 467, 468, 487, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 558, 563, 564, 568, 569, 570, 571, 572, 577, 578, 583, 584, 585, 590, 597, 612, 618, 619, 620, 621, 622, 624, 625, 626, 628, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "multiprocess": [3, 5, 6, 22, 35, 36, 37, 38, 42, 44, 47, 50, 68, 69, 72, 73, 78, 85, 95, 96, 97, 98, 120, 127, 128, 150, 154, 158, 279, 280, 563, 564, 565, 566, 569, 571, 572, 573, 611, 618, 619, 620, 621, 626, 633, 634, 635, 636, 640], "mode": [3, 21, 25, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 123, 126, 130, 135, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 264, 272, 279, 280, 295, 302, 303, 304, 310, 319, 320, 321, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 350, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 403, 408, 521, 590, 604, 611, 618, 619, 633, 634, 639, 640], "find": [3, 23, 25, 26, 42, 44, 47, 65, 108, 109, 183, 286, 312, 401, 407, 411, 583, 618, 619, 622, 624, 625, 630, 633, 634], "folder": [3, 86, 87, 163, 176, 221, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 619], "variou": [3, 10, 15, 19, 21, 22, 37, 123, 271, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 373, 375, 377, 379, 383, 392, 560, 561, 592, 614, 618, 619, 620, 622, 623, 624, 625, 627, 633, 634, 637, 640], "machin": [3, 26, 42, 44, 47, 82, 134, 579, 633, 634, 639], "One": [3, 4, 6, 22, 23, 27, 57, 59, 60, 62, 64, 71, 114, 120, 121, 122, 150, 154, 158, 159, 221, 255, 275, 286, 310, 343, 347, 396, 611, 618, 619, 637, 640], "wonder": 3, "why": [3, 22, 212, 633, 635, 640], "instead": [3, 21, 22, 23, 26, 27, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 52, 53, 54, 57, 59, 66, 83, 86, 87, 88, 101, 102, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 236, 282, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 343, 347, 348, 350, 351, 353, 356, 357, 358, 363, 364, 367, 368, 369, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 389, 562, 621, 622, 623, 624, 628, 635, 637, 640], "gener": [3, 5, 6, 16, 17, 21, 22, 26, 27, 28, 32, 34, 35, 36, 38, 42, 44, 47, 50, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 105, 107, 120, 123, 126, 127, 130, 138, 142, 143, 144, 147, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 213, 215, 218, 225, 227, 229, 230, 234, 239, 241, 244, 246, 252, 253, 258, 259, 263, 265, 269, 271, 273, 278, 280, 287, 295, 302, 304, 306, 310, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 337, 339, 341, 344, 362, 368, 376, 378, 379, 380, 381, 382, 383, 384, 385, 395, 407, 414, 429, 590, 592, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "lower": [3, 15, 22, 50, 58, 101, 102, 224, 279, 280, 315, 316, 347, 367, 620, 633, 635], "io": [3, 30, 78, 83, 136, 137, 145, 148, 149, 161, 162, 202, 622], "footprint": [3, 637], "need": [3, 4, 6, 7, 17, 18, 19, 20, 21, 22, 23, 26, 27, 29, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 65, 68, 69, 72, 73, 74, 86, 87, 88, 110, 114, 120, 123, 126, 130, 134, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 224, 226, 227, 236, 242, 250, 253, 266, 270, 271, 272, 277, 279, 280, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 340, 341, 343, 347, 357, 369, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 389, 392, 400, 414, 562, 571, 573, 585, 590, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 633, 634, 635, 637, 639, 640], "commun": [3, 18, 22, 46, 49, 86, 87, 138, 150, 154, 158, 176, 179, 324, 325, 327, 328, 330, 331, 335, 336, 376, 378, 380, 381, 384, 563, 566, 568, 571, 573, 575, 577, 578, 583, 584, 585, 589, 611, 620, 640], "yet": [3, 6, 121, 122, 136, 330, 331, 382, 636], "spec": [3, 16, 19, 22, 34, 35, 36, 38, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 87, 88, 120, 121, 122, 123, 126, 128, 129, 130, 131, 132, 135, 136, 137, 138, 144, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 209, 212, 213, 214, 215, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 232, 233, 234, 236, 238, 240, 241, 242, 243, 244, 246, 248, 250, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 286, 297, 298, 301, 302, 304, 312, 313, 314, 316, 325, 327, 328, 330, 331, 339, 341, 342, 343, 344, 346, 347, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 382, 590, 597, 618, 619, 620, 621, 622, 623, 624, 628, 630, 632, 633, 634, 639], "plai": [3, 19, 152, 153, 160, 170, 221, 619, 620, 625, 637, 640], "role": [3, 19, 87, 89, 143, 170, 172, 175, 183, 190, 195, 196, 197, 332, 337, 383, 619, 625, 631, 640], "opposit": [3, 633], "direct": [3, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 365, 375, 377, 379, 382, 383, 619, 625, 631], "vector": [3, 16, 21, 27, 57, 64, 121, 122, 131, 136, 137, 141, 152, 153, 155, 163, 164, 231, 278, 280, 290, 292, 305, 385, 388, 588, 618, 619, 621, 632, 633, 634, 635, 636, 640], "share": [3, 6, 7, 15, 19, 21, 25, 27, 32, 34, 35, 36, 38, 50, 52, 56, 68, 69, 72, 73, 74, 86, 87, 90, 93, 95, 96, 97, 98, 102, 104, 108, 110, 112, 116, 127, 150, 158, 171, 172, 175, 176, 185, 192, 193, 194, 195, 262, 270, 279, 280, 283, 284, 285, 302, 304, 325, 327, 328, 330, 331, 348, 349, 350, 351, 352, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 376, 378, 380, 381, 384, 401, 429, 464, 466, 467, 468, 562, 564, 565, 566, 567, 569, 570, 571, 572, 573, 574, 577, 579, 580, 581, 582, 585, 590, 611, 620, 622, 628, 630, 631, 632, 633, 634, 639, 640], "among": [3, 18, 63, 152, 153, 270, 357, 370, 633, 634], "achiev": [3, 4, 21, 23, 88, 120, 123, 126, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 264, 287, 326, 332, 337, 341, 375, 377, 379, 382, 383, 410, 618, 619, 620, 621, 622, 630, 633, 634, 635, 637, 639, 640], "prohibit": [3, 21, 114], "slow": [3, 22, 23, 30, 86, 87, 96, 108, 109, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "compar": [3, 21, 22, 83, 114, 349, 351, 363, 368, 370, 371, 372, 408, 611, 618, 620, 622, 624, 625, 633, 634, 637, 640], "gpu": [3, 26, 27, 53, 55, 88, 95, 97, 116, 120, 123, 126, 130, 131, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 243, 324, 326, 329, 332, 333, 334, 337, 375, 377, 379, 382, 383, 400, 578, 584, 585, 618, 620, 621, 633, 634, 640], "nativ": [3, 6, 16, 26, 28, 81, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 324, 337, 392, 621, 637], "driver": [3, 26], "mean": [3, 5, 6, 7, 17, 19, 21, 22, 23, 26, 32, 34, 35, 36, 38, 39, 42, 44, 47, 50, 52, 72, 74, 78, 86, 87, 96, 101, 102, 108, 109, 114, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 183, 217, 246, 270, 279, 280, 286, 295, 299, 302, 304, 311, 319, 320, 325, 327, 328, 330, 331, 341, 344, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 376, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 407, 418, 564, 565, 566, 569, 570, 572, 574, 575, 577, 579, 585, 618, 619, 620, 622, 624, 633, 634, 635, 637, 640], "keyword": [3, 6, 21, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 93, 95, 96, 97, 98, 101, 102, 106, 108, 109, 112, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 206, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 244, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 286, 287, 297, 301, 302, 304, 306, 312, 313, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 339, 340, 341, 343, 344, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 397, 399, 401, 414, 418, 419, 559, 618, 619, 620, 622, 624, 627, 633, 634, 637, 639, 640], "given": [3, 4, 12, 22, 35, 36, 38, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 109, 120, 123, 126, 130, 138, 144, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 225, 231, 239, 246, 250, 265, 269, 271, 272, 273, 275, 277, 279, 280, 286, 287, 297, 298, 299, 301, 302, 304, 314, 317, 318, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 343, 344, 345, 346, 352, 353, 355, 365, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 401, 405, 408, 558, 618, 619, 620, 623, 624, 625, 626, 627, 634, 635, 640], "mani": [3, 7, 16, 18, 19, 22, 23, 68, 86, 87, 121, 122, 124, 125, 126, 129, 131, 132, 136, 137, 145, 146, 155, 176, 178, 183, 185, 265, 325, 327, 328, 330, 331, 348, 350, 357, 364, 367, 376, 378, 379, 380, 381, 384, 416, 566, 611, 618, 619, 620, 622, 623, 624, 626, 628, 633, 634, 635, 637, 639, 640], "eg": [3, 17, 22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 124, 125, 126, 129, 130, 131, 132, 134, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 231, 263, 272, 282, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 392], "gymnasium": [3, 17, 18, 22, 24, 32, 34, 35, 36, 38, 52, 120, 123, 126, 129, 130, 131, 135, 138, 139, 140, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 175, 178, 179, 180, 211, 234, 259, 263, 278, 282, 444, 619, 620, 622, 635, 639], "warn": [3, 22, 35, 36, 38, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 272, 279, 286, 301, 312, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 403, 619, 630, 631], "quickli": [3, 22, 619, 633, 634, 640], "becom": [3, 22, 23, 50, 400, 401, 611, 633, 634, 640], "quit": [3, 22, 30, 78, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 618, 619, 620, 622, 624, 633, 634, 640], "annoi": [3, 22], "By": [3, 17, 21, 22, 34, 37, 39, 40, 41, 46, 49, 60, 64, 71, 88, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 142, 143, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 244, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 344, 365, 375, 377, 379, 382, 383, 403, 408, 562, 590, 618, 621, 633, 636, 637, 640], "filter": [3, 21, 22, 23, 102, 108, 109, 348, 349, 351, 352, 356, 357, 363, 367, 368, 370, 379, 400, 623], "out": [3, 17, 19, 21, 22, 23, 24, 28, 37, 39, 40, 41, 46, 49, 50, 54, 55, 79, 83, 86, 87, 88, 93, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 262, 265, 286, 297, 298, 306, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 343, 344, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 618, 619, 620, 621, 622, 623, 624, 626, 633, 634, 635, 637, 639, 640], "still": [3, 17, 22, 28, 75, 83, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 270, 272, 312, 326, 332, 337, 364, 365, 375, 377, 379, 383, 590, 618, 619, 621, 632, 635, 637, 640], "wish": [3, 22, 30, 32, 35, 36, 38, 83, 211, 625, 637], "displai": [3, 22, 26, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 414, 618, 619, 630, 634, 635], "filter_warnings_subprocess": [3, 22], "simplest": [4, 114, 326, 332, 337, 347, 375, 377, 379, 383, 618, 620, 624, 633, 634, 637, 640], "transit": [4, 35, 36, 38, 79, 83, 88, 102, 109, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 317, 323, 326, 332, 337, 375, 377, 379, 382, 383, 618, 621, 623, 624, 626, 633, 635, 637], "sampl": [4, 5, 7, 10, 15, 23, 27, 28, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 95, 96, 97, 101, 102, 103, 106, 107, 108, 109, 112, 114, 116, 120, 123, 126, 130, 138, 144, 147, 150, 151, 154, 158, 159, 160, 167, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 210, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 280, 286, 295, 297, 298, 301, 303, 306, 310, 311, 312, 313, 314, 315, 317, 320, 321, 326, 329, 332, 337, 339, 341, 343, 344, 348, 349, 350, 351, 352, 353, 355, 364, 366, 367, 371, 372, 375, 379, 382, 404, 410, 414, 416, 419, 427, 428, 431, 432, 433, 473, 551, 588, 618, 619, 620, 621, 622, 623, 624, 626, 628, 633, 634, 636, 639, 640], "attent": [4, 27, 178, 221, 326, 332, 337, 379, 618, 621, 631, 640], "built": [4, 7, 10, 16, 17, 21, 24, 26, 69, 86, 87, 121, 122, 129, 136, 137, 147, 148, 176, 317, 325, 327, 328, 330, 331, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 383, 384, 556, 558, 559, 562, 590, 597, 611, 618, 619, 620, 621, 622, 625, 627, 630, 635, 637, 640], "flatten": [4, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 114, 176, 218, 236, 325, 327, 328, 330, 331, 338, 376, 378, 380, 381, 382, 384, 385, 410, 580, 581, 590, 634], "suffici": [4, 18, 23, 618], "preprocess": [4, 10, 16, 78, 79, 80, 81, 82, 83, 84, 85, 271, 619, 622], "popul": [4, 17, 34, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 178, 240, 265, 295, 365, 375, 377, 379, 383, 618, 620, 621, 624, 626, 635, 637], "replaybuff": [4, 10, 12, 21, 32, 34, 35, 36, 38, 50, 52, 53, 65, 66, 67, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 95, 96, 101, 102, 103, 108, 109, 118, 221, 251, 255, 353, 358, 400, 418, 419, 429, 556, 558, 620, 622, 626, 628, 633, 634, 636, 637, 639], "lazytensorstorag": [4, 10, 12, 32, 34, 35, 36, 38, 52, 65, 68, 72, 73, 101, 108, 109, 114, 255, 419, 425, 620, 622, 628, 633, 634, 637], "lambda": [4, 6, 32, 34, 35, 36, 38, 50, 51, 52, 53, 68, 114, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 183, 211, 218, 226, 227, 239, 241, 265, 273, 280, 282, 287, 297, 313, 326, 332, 337, 340, 341, 359, 361, 362, 371, 375, 377, 379, 383, 385, 388, 390, 417, 418, 558, 566, 583, 590, 618, 619, 621, 622, 633, 634, 636, 637, 639, 640], "reshap": [4, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 108, 114, 218, 302, 304, 305, 390, 590, 620, 633, 634], "extend": [4, 7, 10, 27, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 94, 95, 98, 101, 102, 104, 108, 109, 112, 114, 115, 118, 119, 170, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 220, 255, 271, 365, 375, 377, 379, 382, 383, 410, 418, 583, 584, 590, 592, 600, 618, 619, 620, 622, 626, 628, 633, 634, 636, 637, 639], "slice": [4, 10, 17, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 83, 102, 108, 109, 214, 220, 221, 325, 432, 433, 621, 637], "recommend": [4, 5, 23, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 68, 72, 73, 86, 87, 108, 114, 134, 170, 171, 172, 175, 176, 189, 221, 324, 325, 327, 328, 330, 331, 332, 335, 336, 337, 350, 367, 376, 377, 378, 379, 380, 381, 384, 590, 611, 626, 631, 633, 634], "multidimension": [4, 72, 101, 102, 637], "slicesampl": [4, 10, 78, 102, 109, 221, 432, 621, 637], "sampler": [4, 7, 10, 13, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 95, 96, 97, 98, 101, 102, 103, 106, 107, 108, 109, 110, 112, 114, 116, 221, 251, 353, 358, 429, 436, 618, 620, 621, 633, 634, 637], "ensur": [4, 7, 17, 21, 33, 42, 43, 44, 45, 46, 47, 48, 49, 65, 72, 88, 101, 102, 107, 120, 123, 126, 130, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 221, 250, 263, 272, 275, 279, 280, 297, 302, 304, 324, 326, 332, 337, 350, 364, 367, 375, 377, 379, 382, 383, 400, 564, 566, 567, 569, 570, 572, 577, 578, 579, 583, 585, 586, 590, 594, 611, 619, 620, 621, 635, 637], "clearli": 4, "dimension": [4, 65, 68, 72, 73, 178, 231, 302, 304, 385, 634], "num_slic": [4, 78, 83, 102, 108, 109, 432, 433, 637], "trajectory_kei": [4, 56, 108, 109], "traj_id": [4, 17, 34, 35, 38, 52, 56, 218, 255, 626, 637], "dim": [4, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 108, 176, 190, 205, 221, 222, 244, 248, 261, 262, 265, 274, 279, 325, 327, 328, 330, 331, 340, 376, 378, 380, 381, 384, 479, 480, 501, 505, 518, 519, 523, 530, 562, 590, 619, 620, 622, 633, 635, 637], "ndim": [4, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 95, 97, 101, 102, 114, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 244, 340, 423, 425, 437], "regular": [4, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 86, 87, 88, 101, 106, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 296, 298, 302, 304, 313, 314, 325, 327, 328, 329, 330, 331, 343, 344, 358, 367, 376, 378, 380, 381, 382, 383, 384, 417, 418, 419, 618, 619, 622, 623, 624, 628, 630, 637, 640], "behav": [4, 22, 132, 144, 310, 356, 363, 365, 375, 377, 379, 383, 622, 636], "accordingli": [4, 22, 86, 87, 102, 174, 176, 227, 244, 263, 264, 313, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 621], "3": [4, 18, 19, 20, 22, 25, 26, 29, 30, 32, 34, 35, 36, 38, 50, 52, 53, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 97, 101, 102, 108, 109, 114, 116, 120, 123, 124, 125, 126, 129, 130, 131, 132, 133, 138, 141, 142, 143, 145, 147, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 206, 215, 217, 218, 221, 225, 226, 227, 231, 233, 234, 239, 241, 246, 248, 250, 252, 253, 255, 258, 259, 262, 263, 264, 265, 268, 270, 271, 272, 273, 275, 277, 280, 282, 283, 284, 285, 287, 288, 290, 291, 292, 294, 297, 298, 300, 302, 304, 305, 306, 307, 310, 314, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 339, 341, 342, 343, 346, 347, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 360, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 392, 400, 412, 462, 479, 502, 564, 565, 566, 568, 569, 570, 571, 572, 574, 577, 579, 585, 597, 611, 617, 618, 619, 620, 621, 623, 624, 626, 627, 633, 634, 635, 637, 638, 639, 640], "isn": [4, 22, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 83, 86, 87, 101, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 217, 233, 239, 297, 325, 327, 328, 330, 331, 343, 376, 378, 380, 381, 384, 385, 624, 625, 627, 633, 634], "fulli": [4, 6, 27, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 619, 622, 625, 635, 637], "ani": [4, 6, 7, 12, 17, 18, 19, 21, 22, 24, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 94, 95, 96, 97, 98, 104, 107, 109, 110, 112, 114, 115, 116, 118, 119, 120, 123, 126, 127, 130, 131, 138, 145, 150, 151, 152, 153, 154, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 213, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 236, 237, 239, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 280, 282, 287, 288, 294, 295, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 343, 344, 345, 346, 348, 349, 350, 351, 352, 353, 355, 356, 357, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 390, 392, 397, 400, 401, 407, 414, 416, 417, 418, 423, 425, 429, 432, 433, 434, 435, 436, 437, 438, 440, 444, 448, 462, 463, 464, 466, 467, 468, 470, 471, 476, 483, 484, 485, 522, 529, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 582, 583, 584, 585, 589, 611, 618, 619, 620, 621, 622, 624, 625, 630, 633, 634, 635, 637, 639, 640], "consecut": [4, 17, 78, 107, 134, 304, 312, 392, 621, 623, 626, 634, 637, 640], "won": [4, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 83, 86, 87, 88, 120, 123, 126, 127, 129, 130, 138, 145, 146, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 277, 325, 326, 327, 328, 330, 331, 332, 337, 348, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 414, 562, 619, 620, 623, 624], "therebi": [4, 390, 618, 619], "interrupt": [4, 130, 180, 340, 400, 401], "asyncdatacollector": 5, "asynccollector": 5, "_multidatacollector": 5, "It": [5, 7, 17, 20, 21, 22, 23, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 96, 106, 114, 119, 120, 123, 126, 130, 132, 138, 144, 145, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 212, 215, 218, 220, 221, 233, 239, 241, 246, 251, 264, 270, 272, 278, 280, 286, 290, 292, 298, 299, 301, 312, 314, 315, 316, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 344, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 399, 400, 407, 408, 418, 464, 566, 567, 569, 570, 572, 577, 579, 585, 588, 589, 590, 592, 618, 619, 621, 622, 623, 633, 634, 635, 636, 637, 639, 640], "cartpol": [5, 6, 7, 18, 20, 22, 30, 35, 36, 38, 120, 123, 124, 125, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 218, 221, 226, 258, 264, 279, 340, 390, 566, 619, 621, 624, 626, 627, 628, 637, 640], "sync_collector": [5, 35, 36, 38], "1000": [5, 23, 34, 35, 36, 38, 52, 68, 90, 95, 96, 101, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 279, 286, 301, 312, 341, 344, 419, 526, 566, 618, 619, 620, 621, 622, 624, 626, 628, 631, 635, 636, 637], "100000": [5, 7, 35, 36, 38, 419, 619], "async_collector": [5, 35, 36, 38], "comparison": [5, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 326, 332, 337, 365, 375, 377, 379, 382, 383, 618, 619], "older": [5, 26, 282], "throughput": [5, 28, 137, 324, 333, 337, 618], "slowest": 5, "higher": [5, 22, 23, 101, 102, 177, 188, 196, 224, 324, 326, 332, 337, 347, 377, 379, 383, 618, 619, 620, 633, 637, 640], "allow": [5, 6, 7, 12, 16, 17, 18, 20, 21, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 63, 64, 68, 69, 70, 71, 72, 73, 78, 83, 86, 87, 88, 89, 96, 102, 106, 108, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 212, 217, 218, 253, 280, 305, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 566, 590, 611, 618, 620, 621, 622, 623, 624, 625, 631, 633, 634, 635, 637, 639, 640], "start": [5, 6, 20, 21, 22, 23, 24, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 66, 74, 78, 85, 101, 102, 108, 109, 120, 123, 126, 127, 130, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 214, 228, 318, 373, 409, 564, 566, 567, 568, 569, 570, 571, 572, 574, 575, 577, 578, 579, 583, 585, 588, 617, 618, 619, 621, 622, 629, 634, 635, 637, 638, 640], "get": [5, 6, 18, 19, 21, 22, 23, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 60, 65, 68, 71, 78, 79, 83, 86, 87, 88, 95, 97, 102, 108, 109, 110, 112, 114, 116, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 188, 190, 194, 195, 196, 201, 215, 220, 222, 226, 229, 231, 232, 241, 246, 251, 264, 265, 268, 272, 279, 280, 301, 313, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 339, 341, 344, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 392, 396, 400, 401, 402, 564, 566, 567, 569, 570, 572, 573, 574, 577, 579, 583, 585, 588, 590, 604, 617, 618, 619, 620, 621, 622, 629, 631, 633, 634, 635, 637, 638, 639, 640], "rid": [5, 326, 332, 337, 375, 377, 379, 383], "natur": [5, 18, 33, 42, 43, 44, 45, 47, 48, 170, 186, 618, 624, 625, 626, 637], "background": [5, 32, 33, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 53, 190, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585, 637], "simpli": [5, 6, 7, 20, 22, 25, 86, 87, 112, 114, 119, 176, 182, 234, 259, 278, 325, 327, 328, 330, 331, 365, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 618, 620, 625, 630, 633, 634, 640], "replay_buff": [5, 7, 27, 32, 34, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 221, 410, 417, 418, 419, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 471, 558, 618, 619, 620, 621, 626, 633, 634, 637], "rb": [5, 32, 34, 35, 36, 38, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 96, 101, 102, 108, 109, 114, 221, 255, 619, 621, 622, 626, 628, 634, 636, 637, 639], "paus": [5, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "sleep": [5, 32, 34, 35, 36, 38, 52, 66, 127, 640], "10": [5, 6, 18, 20, 26, 51, 56, 57, 59, 61, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 101, 108, 109, 114, 116, 120, 121, 122, 123, 126, 127, 130, 136, 137, 138, 144, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 183, 185, 188, 190, 192, 193, 197, 214, 215, 218, 220, 221, 226, 227, 264, 266, 267, 268, 279, 280, 287, 289, 290, 292, 294, 296, 301, 302, 304, 306, 311, 312, 325, 327, 328, 330, 331, 341, 344, 347, 349, 353, 355, 362, 367, 368, 369, 372, 376, 377, 378, 379, 380, 381, 384, 385, 386, 387, 388, 392, 400, 404, 463, 466, 467, 468, 473, 478, 521, 539, 565, 573, 611, 612, 618, 619, 620, 621, 622, 623, 624, 628, 633, 635, 637, 639, 640], "rang": [5, 6, 17, 19, 23, 27, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 97, 114, 120, 123, 126, 127, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 185, 255, 268, 279, 282, 325, 327, 328, 330, 331, 364, 371, 372, 376, 378, 380, 381, 384, 618, 620, 621, 622, 625, 626, 628, 633, 634, 635, 637, 639], "optim_step": [5, 622, 628], "rest": [5, 7, 32, 35, 36, 38, 620, 621, 633, 635, 639], "multithread": [5, 22, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 145, 146, 626, 637], "mind": [5, 21, 22, 78, 83, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 633, 634], "gil": 5, "relat": [5, 19, 22, 23, 29, 60, 65, 150, 175, 236, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 619, 628, 635], "restrict": [5, 22, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 619, 630, 636, 637, 640], "hand": [5, 19, 26, 50, 60, 633, 634, 635], "let": [5, 6, 7, 19, 25, 26, 30, 56, 65, 68, 72, 73, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 297, 326, 332, 337, 375, 377, 379, 382, 383, 408, 590, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "child": [5, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 619], "fill": [5, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 130, 180, 217, 265, 278, 304, 385, 621, 635, 636], "truli": [5, 278, 400, 639], "decoupl": [5, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 52, 618, 625, 639], "been": [5, 18, 24, 26, 27, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 107, 120, 123, 126, 130, 134, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 241, 243, 263, 264, 271, 272, 302, 304, 340, 348, 365, 367, 369, 375, 377, 379, 383, 400, 563, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585, 618, 619, 620, 621, 632, 633, 634, 635, 637, 639, 640], "shut": [5, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 154, 159, 400], "down": [5, 23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 154, 159, 400, 621, 623], "async_shutdown": [5, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 66], "drastic": [5, 6, 137, 150, 637], "hardwar": [5, 17, 622], "load": [5, 6, 25, 26, 32, 34, 35, 36, 38, 52, 53, 54, 55, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 95, 96, 97, 98, 110, 111, 112, 116, 117, 120, 123, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 279, 280, 324, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 414, 416, 418, 419, 562, 581, 590, 593, 618, 620, 622, 630, 631, 637], "factor": [5, 27, 30, 255, 286, 301, 303, 312, 320, 321, 349, 355, 358, 359, 361, 418, 618, 619, 622, 624, 628, 633, 634, 637, 640], "signific": [5, 21, 24, 27, 611, 620, 639, 640], "understand": [5, 6, 19, 27, 33, 42, 43, 44, 45, 47, 48, 611, 618, 619, 622, 623, 624, 630, 633, 634], "affect": [5, 22, 27, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 272, 280, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 400, 633], "legitim": [5, 640], "unless": [5, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 86, 87, 88, 92, 107, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 280, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 351, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 620], "benchmark": [5, 18, 22, 28, 121, 122, 130, 136, 137, 180], "pipelin": [6, 19, 26, 130, 180, 333, 375, 590, 594, 620], "typic": [6, 17, 22, 23, 27, 33, 34, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 81, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 233, 264, 326, 332, 337, 341, 349, 351, 365, 367, 370, 375, 377, 379, 382, 383, 418, 571, 578, 585, 590, 620, 622, 623, 625, 626, 631, 633, 634, 635], "big": [6, 620, 626, 637, 640], "bucket": [6, 171], "send": [6, 22, 27, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 86, 87, 154, 159, 176, 324, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 399, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 577, 579, 582, 584, 585, 639], "occasion": 6, "tradit": [6, 625, 633], "neural": [6, 7, 141, 152, 153, 288, 343, 385, 597, 619, 620, 621, 624, 633, 634, 635, 640], "both": [6, 7, 18, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 54, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 127, 129, 130, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 161, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 214, 221, 239, 253, 269, 270, 272, 283, 284, 285, 288, 298, 302, 304, 305, 314, 324, 326, 332, 334, 337, 348, 350, 351, 352, 356, 357, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 400, 401, 407, 408, 417, 471, 568, 571, 573, 576, 577, 583, 584, 585, 590, 611, 618, 620, 622, 623, 625, 630, 631, 633, 634, 635, 636, 637, 640], "anyth": [6, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50], "happen": [6, 7, 18, 21, 22, 46, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 282, 312, 416, 565, 571, 619, 622, 625, 626, 627, 636, 640], "held": 6, "datacollector": [6, 32, 34, 35, 36, 38, 50, 52, 53, 367, 620, 626, 637], "receiv": [6, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 271, 272, 280, 305, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 583, 585, 618, 620, 625, 632, 635], "postprocess": [6, 34], "hook": [6, 37, 39, 40, 41, 46, 49, 54, 55, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 117, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 347, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 471, 588, 612], "itself": [6, 21, 34, 42, 47, 50, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 325, 326, 327, 328, 330, 331, 332, 337, 365, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 620, 623], "transfer": [6, 55, 86, 87, 176, 325, 327, 328, 330, 331, 344, 376, 378, 380, 381, 384, 568, 571, 578, 579, 583, 584], "think": [6, 21, 87, 170, 172, 174, 175, 177, 183, 589, 590, 620, 633, 634, 640], "world": [6, 19, 24, 144, 323, 324, 333, 360, 400, 588, 597, 611, 622, 627, 633, 634, 635, 640], "engin": [6, 26, 54, 55, 155, 324, 333, 334, 337, 382, 578, 579, 581, 583, 584, 585, 590, 630, 635], "veri": [6, 12, 15, 18, 19, 22, 86, 87, 136, 137, 175, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 619, 623, 626, 630, 633, 635, 637, 639, 640], "kernel": [6, 288], "forward": [6, 16, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 240, 241, 243, 246, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 317, 322, 324, 326, 332, 337, 338, 340, 341, 343, 344, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 621, 635, 639], "format": [6, 20, 62, 64, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 92, 93, 100, 106, 114, 120, 123, 126, 130, 138, 150, 151, 152, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 203, 221, 225, 250, 265, 271, 272, 275, 277, 326, 330, 332, 337, 343, 375, 377, 379, 382, 383, 392, 576, 586, 590, 592, 593, 594, 604, 618, 619, 622, 623, 625, 627, 630, 639, 640], "quantiz": 6, "much": [6, 22, 27, 32, 35, 36, 38, 65, 72, 83, 86, 87, 101, 102, 150, 158, 176, 325, 327, 328, 330, 331, 364, 367, 376, 378, 380, 381, 384, 620, 622, 623, 627, 633, 634, 635, 637, 640], "cannot": [6, 18, 22, 23, 26, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 60, 62, 64, 68, 72, 73, 90, 97, 98, 102, 104, 108, 109, 116, 120, 123, 126, 129, 130, 131, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 229, 232, 251, 258, 270, 313, 348, 351, 367, 619, 620, 621, 622, 633, 634, 635], "dump": [6, 20, 30, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 93, 95, 96, 97, 98, 110, 112, 116, 176, 190, 194, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 390, 391, 392, 627, 628, 633], "dict": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 102, 108, 109, 120, 123, 126, 127, 128, 129, 130, 131, 138, 142, 143, 145, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 239, 241, 265, 270, 272, 278, 279, 280, 282, 288, 289, 290, 291, 292, 293, 294, 300, 305, 311, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 351, 370, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 396, 397, 400, 401, 402, 408, 414, 416, 417, 418, 419, 438, 462, 463, 471, 510, 553, 554, 560, 561, 562, 564, 566, 567, 569, 570, 572, 573, 574, 576, 577, 578, 579, 580, 583, 584, 585, 586, 611, 618, 619, 620, 637, 639, 640], "who": 6, "activ": [6, 25, 26, 28, 288, 294, 299, 305, 350, 364, 367, 635, 639], "ask": [6, 22, 27, 78, 83, 102, 108, 109, 332, 392, 620, 621, 623, 624, 633, 634, 636, 640], "push": [6, 55, 383, 583], "intermedi": [6, 23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 220, 287, 298, 302, 304, 317, 326, 332, 337, 375, 377, 379, 383, 618, 622, 636], "approach": [6, 21, 34, 65, 68, 72, 73, 86, 87, 176, 189, 221, 246, 325, 327, 328, 330, 331, 335, 336, 337, 371, 376, 378, 380, 381, 384, 419, 565, 566, 579, 590, 618, 620, 625, 626, 633, 640], "intermediari": 6, "server": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 190], "fetch": [6, 40, 86, 87, 121, 122, 124, 125, 176, 241, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 583, 624, 636, 637], "tri": [6, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 324, 326, 332, 337, 343, 375, 377, 379, 382, 383, 627], "account": [6, 95, 97, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 227, 306, 619, 621, 637, 640], "problem": [6, 18, 26, 27, 28, 34, 175, 379, 619, 620, 621, 626, 633, 634, 635, 637, 640], "manner": [6, 130, 180, 250, 275, 618, 619, 620, 626, 632, 635, 637], "identifi": [6, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 195, 196, 400, 401, 564, 566, 567, 569, 570, 571, 572, 574, 577, 579, 580, 585, 592, 611, 630], "three": [6, 57, 59, 61, 62, 64, 170, 351, 590, 620, 622, 623, 624, 633, 634, 635, 637, 640], "orchestr": [6, 590, 593, 619, 625, 627], "entir": [6, 23, 34, 35, 36, 38, 50, 60, 83, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 280, 567, 590, 620, 623, 635, 637], "includ": [6, 7, 12, 16, 19, 21, 23, 26, 28, 50, 63, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 95, 96, 97, 98, 100, 110, 112, 116, 120, 123, 126, 130, 138, 144, 148, 149, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 236, 239, 264, 270, 272, 279, 280, 302, 304, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 348, 351, 365, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 401, 407, 418, 471, 551, 590, 592, 596, 602, 618, 619, 620, 621, 622, 630, 631, 633, 634, 635, 637, 640], "coordin": [6, 35, 36, 38, 50, 95, 97, 228, 563, 564, 571, 578, 579, 581, 583, 584, 611], "actual": [6, 17, 18, 21, 23, 26, 35, 36, 37, 38, 39, 40, 41, 46, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 278, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 551, 565, 566, 568, 571, 583, 586, 590, 618, 620, 622, 633, 634, 635], "through": [6, 12, 17, 18, 21, 22, 23, 24, 27, 32, 34, 35, 36, 38, 41, 42, 47, 50, 52, 53, 55, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 120, 121, 122, 123, 126, 129, 130, 131, 134, 136, 137, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 184, 185, 190, 217, 227, 229, 232, 251, 282, 287, 305, 324, 325, 327, 328, 330, 331, 337, 340, 341, 344, 345, 346, 365, 376, 378, 380, 381, 384, 385, 386, 387, 388, 403, 565, 566, 573, 578, 611, 618, 619, 620, 621, 623, 625, 632, 633, 634, 635, 636, 637, 640], "queue": [6, 52, 154, 279, 326, 332, 337, 382, 565, 566, 573, 611, 637, 639], "determin": [6, 22, 35, 36, 38, 39, 65, 72, 79, 86, 87, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 174, 175, 176, 178, 179, 180, 183, 186, 250, 277, 312, 325, 326, 327, 328, 330, 331, 332, 337, 351, 376, 378, 379, 380, 381, 384, 577, 619, 624, 633, 634], "state_dict": [6, 32, 34, 35, 36, 38, 50, 52, 53, 54, 55, 86, 87, 88, 90, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 416, 562, 566, 567, 569, 570, 572, 576, 577, 579, 585, 586, 618, 619, 640], "extract": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 60, 71, 80, 102, 170, 184, 186, 190, 193, 197, 199, 217, 239, 269, 273, 564, 565, 566, 567, 569, 570, 572, 574, 576, 577, 579, 582, 584, 585, 586, 590, 618, 620, 639], "appli": [6, 7, 10, 21, 22, 23, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 231, 233, 234, 235, 236, 237, 240, 241, 242, 243, 245, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 297, 320, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 407, 409, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 579, 581, 583, 585, 590, 618, 619, 620, 626, 630, 633, 635, 639, 640], "automat": [6, 7, 18, 19, 20, 22, 24, 31, 35, 36, 38, 41, 55, 58, 69, 74, 75, 85, 86, 87, 89, 95, 97, 109, 116, 120, 121, 122, 123, 126, 129, 130, 131, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 174, 175, 176, 178, 179, 180, 191, 217, 229, 232, 246, 265, 278, 280, 302, 304, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 339, 340, 341, 344, 376, 378, 380, 381, 384, 390, 403, 407, 414, 418, 471, 564, 566, 569, 570, 572, 573, 574, 576, 577, 579, 583, 585, 592, 597, 611, 618, 620, 621, 623, 624, 633, 634, 635, 637, 639], "weight_sync_schem": [6, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 417, 418, 471, 563, 564, 566, 567, 568, 569, 570, 571, 572, 574, 575, 577, 579, 585, 590], "intern": [6, 20, 22, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 280, 324, 326, 332, 337, 400, 566, 567, 574, 577, 578, 583, 616], "propag": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 71, 348, 350, 351, 352, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 385, 386, 387, 388, 620, 621, 633, 634], "convent": [6, 22, 78, 79, 80, 81, 82, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 326, 604, 618, 621, 633, 634, 635], "regist": [6, 7, 20, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 209, 212, 229, 232, 233, 258, 270, 272, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 347, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 392, 400, 401, 402, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 564, 566, 569, 570, 572, 574, 577, 579, 582, 584, 585, 590, 611, 612, 618, 620, 623, 637], "posit": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 102, 120, 123, 124, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 226, 236, 237, 239, 261, 262, 263, 266, 270, 272, 274, 307, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383, 400, 401, 620, 633, 634, 635, 637], "policy_modul": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 620, 633, 634], "weights_tensordict": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "clariti": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 272], "actor_modul": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 639], "weights_td": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "model_id": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 564, 565, 566, 567, 569, 570, 571, 572, 574, 577, 578, 579, 580, 585], "actor": [6, 21, 23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 66, 171, 172, 175, 185, 189, 192, 193, 194, 195, 241, 243, 283, 284, 285, 289, 290, 292, 297, 298, 299, 301, 311, 312, 313, 314, 324, 329, 334, 337, 340, 341, 342, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375, 377, 379, 383, 400, 401, 402, 419, 470, 471, 570, 571, 572, 584, 585, 588, 597, 604, 611, 619, 621, 623, 625, 628, 633, 636, 639], "atom": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "weights_dict": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "actor_td": 6, "critic": [6, 23, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 177, 283, 348, 350, 351, 352, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 379, 419, 470, 471, 568, 588, 597, 604, 611, 618, 625], "critic_td": 6, "primarili": [6, 74, 251, 624], "special": [6, 7, 18, 60, 71, 76, 77, 86, 87, 176, 180, 325, 326, 327, 328, 330, 331, 332, 337, 376, 378, 380, 381, 384, 590, 591, 595, 608, 611, 618, 621, 622, 640], "outsid": [6, 22, 34, 230, 270, 627, 633, 634, 635], "pattern": [6, 89, 190, 197, 563, 564, 566, 568, 569, 571, 572, 573, 578, 588, 590], "clear": [6, 20, 30, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 80, 88, 120, 121, 122, 123, 126, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 400, 405, 611, 623, 626, 631], "local": [6, 23, 26, 29, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 67, 81, 86, 88, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 280, 326, 332, 334, 337, 375, 377, 379, 382, 383, 397, 399, 579, 580, 611, 622, 627, 628, 633, 634], "inter": [6, 22, 150, 154], "base": [6, 10, 12, 16, 19, 21, 22, 23, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 83, 86, 87, 101, 102, 105, 111, 114, 115, 117, 118, 120, 121, 122, 123, 126, 130, 134, 136, 137, 138, 144, 145, 146, 150, 151, 154, 158, 159, 160, 163, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 185, 188, 189, 191, 194, 195, 199, 204, 205, 212, 218, 225, 226, 230, 255, 269, 271, 272, 273, 275, 276, 280, 283, 302, 304, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 351, 352, 353, 355, 356, 357, 359, 363, 367, 368, 369, 370, 371, 372, 376, 378, 380, 381, 384, 385, 386, 387, 388, 389, 399, 400, 401, 414, 418, 422, 426, 436, 437, 439, 443, 472, 528, 563, 564, 565, 566, 567, 569, 570, 572, 573, 574, 576, 577, 579, 580, 581, 583, 585, 588, 597, 604, 606, 611, 618, 619, 621, 623, 624, 625, 627, 630, 631, 633, 634, 635, 637, 640], "tcpstore": [6, 563, 564], "small": [6, 101, 102, 109, 275, 280, 618, 620, 622, 633, 634, 640], "logic": [6, 21, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 89, 567, 569, 570, 572, 577, 579, 585, 633], "sender": [6, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 577, 578, 579, 580, 582, 585, 590], "trigger": [6, 26, 178, 280, 326, 332, 337, 375, 377, 379, 383, 564, 566, 569, 570, 572, 574, 577, 579, 585, 621], "_receive_weights_schem": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "side": [6, 18, 23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 188, 189, 195, 196, 202, 306, 326, 564, 566, 567, 569, 570, 571, 572, 574, 575, 577, 578, 579, 585, 640], "init_on_send": [6, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585], "context": [6, 17, 19, 21, 24, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 109, 120, 123, 126, 127, 130, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 265, 274, 302, 304, 326, 332, 337, 375, 377, 379, 382, 383, 385, 386, 387, 388, 392, 403, 408, 564, 565, 566, 567, 569, 570, 572, 573, 574, 577, 579, 585, 590, 611, 618, 619, 620, 621, 622, 633, 634, 635, 636, 637, 639], "NO": 6, "pickl": [6, 32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 68, 69, 72, 73, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 375, 377, 379, 382, 383], "init": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 66, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 271, 279, 324, 326, 329, 332, 337, 375, 377, 379, 382, 383, 385, 399, 400, 402, 578, 583, 585, 611, 619, 620], "block": [6, 53, 55, 89, 94, 119, 135, 175, 177, 186, 193, 203, 324, 563, 564, 565, 566, 568, 569, 570, 571, 572, 574, 575, 577, 579, 585, 590, 618, 621, 622, 625, 626, 633, 637], "readi": [6, 42, 47, 50, 52, 53, 170, 324, 564, 566, 567, 569, 570, 572, 574, 577, 579, 580, 583, 585, 589, 619, 620, 622, 624, 627, 637, 639], "init_on_receiv": [6, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585], "resolv": [6, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 417], "handler": 6, "prepar": [6, 25, 80, 170, 173, 195, 196, 383, 564, 566, 567, 569, 570, 572, 574, 577, 579, 584, 585, 590, 620], "without": [6, 17, 18, 19, 22, 26, 28, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 83, 86, 87, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 217, 229, 232, 268, 271, 284, 285, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 400, 431, 433, 558, 563, 565, 566, 571, 573, 574, 589, 611, 618, 619, 620, 622, 623, 624, 625, 626, 630, 631, 633, 634, 635, 637, 640], "attribut": [6, 17, 19, 21, 22, 23, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 129, 130, 131, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 233, 244, 250, 272, 275, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 344, 348, 349, 351, 352, 353, 355, 357, 358, 359, 362, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 579, 618, 621, 635], "refer": [6, 7, 17, 18, 21, 26, 27, 28, 30, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 123, 126, 129, 130, 131, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 270, 271, 272, 279, 285, 298, 299, 306, 308, 309, 315, 316, 317, 325, 326, 327, 328, 330, 331, 332, 337, 348, 351, 358, 359, 360, 361, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 564, 565, 566, 567, 569, 570, 572, 573, 577, 578, 579, 585, 617, 618, 620, 622, 624, 625, 626, 627, 633, 634, 637], "indic": [6, 12, 17, 18, 20, 22, 27, 32, 34, 35, 36, 38, 39, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 94, 101, 102, 104, 106, 107, 108, 109, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 213, 214, 221, 222, 226, 263, 264, 265, 266, 272, 280, 282, 288, 305, 306, 312, 313, 314, 325, 327, 328, 330, 331, 340, 348, 349, 350, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 552, 562, 589, 611, 620, 621, 622, 626, 627, 628, 635, 637, 640], "primit": [6, 21, 23, 83, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 564, 568], "NOT": [6, 22, 35, 36, 38, 92, 93, 100, 109, 251, 585], "sent": [6, 35, 36, 38, 65, 68, 69, 72, 73, 86, 87, 90, 95, 97, 116, 176, 279, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 564, 565, 566, 568, 569, 570, 572, 573, 574, 575, 577, 579, 585], "explicit": [6, 23, 34, 35, 36, 38, 171, 172, 175, 185, 194, 195, 282, 329, 400, 573, 574, 611, 637], "param": [6, 27, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 273, 280, 295, 319, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 346, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 578, 583, 584, 618, 622, 628, 633, 634, 635, 636, 639], "num_work": [6, 7, 35, 36, 38, 46, 49, 78, 79, 80, 81, 82, 83, 84, 85, 145, 150, 158, 194, 438, 577, 618, 619], "inner_collector": 6, "worker_idx": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 577, 579, 585], "simultan": [6, 22, 47, 137, 145, 146, 150, 158, 566, 578, 585, 611, 635], "order": [6, 21, 30, 34, 41, 52, 53, 64, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 107, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 222, 229, 232, 239, 248, 262, 270, 272, 297, 322, 324, 326, 332, 337, 339, 343, 345, 346, 348, 349, 351, 352, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 568, 619, 633, 634], "driven": 6, "exchang": 6, "notabl": [6, 22], "until": [6, 20, 26, 50, 52, 88, 137, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 266, 271, 382, 403, 563, 566, 568, 571, 574, 620, 621, 628, 633, 634], "exact": [6, 22, 56, 150, 611], "sharedmem": 6, "put": [6, 65, 66, 68, 69, 130, 142, 143, 160, 163, 164, 279, 399, 562, 619, 620, 621, 623, 630, 633, 635], "recv": [6, 563, 564, 568, 571], "send_async": [6, 566, 574], "train_step": 6, "new_weight": [6, 191], "zero": [6, 18, 22, 23, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 97, 101, 102, 108, 109, 114, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 218, 220, 222, 226, 229, 231, 232, 246, 252, 255, 262, 280, 291, 292, 293, 300, 301, 302, 304, 306, 312, 314, 325, 326, 327, 328, 330, 331, 332, 337, 344, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 573, 621, 622, 631, 637, 639, 640], "instantan": 6, "none": [6, 18, 21, 22, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 95, 96, 97, 98, 100, 101, 102, 106, 108, 109, 110, 112, 114, 116, 120, 123, 126, 127, 129, 130, 138, 142, 143, 144, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 206, 207, 209, 210, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 228, 229, 230, 232, 236, 238, 239, 241, 242, 243, 246, 247, 248, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 318, 320, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 396, 397, 398, 400, 401, 407, 408, 409, 410, 411, 412, 414, 416, 417, 418, 419, 423, 424, 425, 426, 427, 429, 432, 433, 436, 437, 438, 440, 441, 442, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 461, 462, 463, 464, 466, 467, 468, 470, 471, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 492, 493, 494, 495, 496, 497, 498, 499, 500, 502, 504, 505, 506, 507, 508, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 541, 543, 545, 547, 548, 549, 552, 553, 554, 555, 557, 558, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 611, 618, 619, 621, 622, 631, 635, 637, 639], "mp": [6, 42, 44, 47, 78, 79, 80, 81, 82, 83, 84, 85, 127, 279, 280, 565, 573], "signal": [6, 17, 32, 34, 35, 36, 38, 56, 78, 79, 81, 83, 84, 85, 102, 108, 109, 114, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 177, 178, 179, 180, 213, 221, 227, 233, 242, 263, 266, 563, 568, 571, 583, 584, 618, 620, 633, 634, 637, 640], "alreadi": [6, 20, 21, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 243, 265, 282, 325, 326, 327, 328, 329, 330, 331, 332, 337, 344, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 400, 401, 563, 573, 611, 618, 620, 627, 633, 634], "part": [6, 7, 12, 20, 21, 22, 23, 27, 78, 80, 81, 83, 84, 85, 88, 102, 120, 121, 123, 126, 130, 136, 138, 148, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 220, 246, 255, 258, 322, 326, 332, 337, 375, 377, 379, 382, 383, 404, 562, 611, 618, 620, 621, 622, 628, 633, 635, 640], "irecv": 6, "return_prematur": 6, "rank": [6, 46, 86, 87, 114, 176, 324, 325, 327, 328, 330, 331, 335, 336, 376, 378, 380, 381, 384, 563, 569, 570, 571, 572, 578, 583, 584, 585], "flag": [6, 7, 17, 19, 27, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 174, 175, 177, 178, 179, 180, 183, 240, 312, 633, 634, 635, 636], "poll": [6, 581, 583], "ref": [6, 324], "connectioninfo": 6, "init_process_group": [6, 571], "isend": [6, 568, 571], "insid": [6, 7, 21, 86, 87, 150, 176, 230, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 570, 611, 640], "raymoduletransform": [6, 570], "join": [6, 127, 185, 571, 619, 620, 622, 633], "uniqu": [6, 64, 108, 109, 138, 142, 143, 177, 179, 221, 233, 264, 265, 266, 270, 340, 399, 400, 401, 570, 572, 573, 590, 611, 626, 637], "even": [6, 17, 21, 23, 27, 30, 35, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 90, 95, 96, 97, 98, 102, 108, 110, 112, 116, 120, 123, 126, 127, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 217, 618, 620, 623, 630, 633, 634, 635, 640], "invok": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 67, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 326, 332, 337, 375, 377, 379, 382, 383], "mechan": [6, 23, 32, 34, 35, 36, 37, 38, 39, 40, 46, 49, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 324, 326, 332, 337, 375, 377, 379, 382, 383, 575, 583, 584, 590, 611, 619, 625, 635], "benefit": [6, 101, 102, 589, 623, 631, 633, 634, 637], "cascad": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 564, 566, 569, 570, 572, 574, 577, 579, 585], "grace": [6, 324], "runnabl": 6, "repositori": [6, 26, 80, 81, 82, 85, 163, 164, 633, 634], "weight_sync_standalon": 6, "weight_sync_collector": 6, "seamlessli": [6, 19, 170, 191, 590, 597, 631, 635], "nn": [6, 17, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 66, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 167, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 226, 231, 233, 241, 250, 265, 271, 272, 275, 277, 283, 284, 285, 287, 288, 290, 291, 292, 293, 297, 299, 300, 301, 302, 304, 305, 307, 312, 313, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 344, 345, 346, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 467, 558, 564, 566, 567, 569, 570, 571, 572, 576, 577, 579, 585, 597, 618, 619, 620, 621, 622, 624, 625, 628, 632, 633, 634, 635, 636, 639], "tensordictmodul": [6, 17, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 66, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 220, 226, 241, 283, 284, 285, 287, 297, 302, 304, 313, 314, 317, 323, 326, 332, 337, 340, 341, 343, 345, 346, 347, 349, 351, 352, 356, 357, 359, 360, 361, 362, 363, 365, 368, 370, 371, 372, 375, 377, 379, 383, 385, 386, 387, 388, 408, 467, 558, 597, 618, 620, 621, 625, 628, 632, 633, 634, 635, 636, 640], "weight_upd": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 590], "linear": [6, 21, 32, 34, 35, 36, 38, 50, 52, 53, 66, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 241, 250, 265, 271, 272, 275, 277, 283, 284, 285, 287, 288, 290, 291, 292, 293, 300, 301, 305, 307, 312, 313, 315, 316, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 346, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 558, 597, 619, 632, 636, 639], "observation_spec": [6, 17, 18, 19, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 193, 194, 195, 196, 197, 198, 199, 215, 218, 221, 222, 223, 224, 225, 228, 229, 230, 232, 233, 236, 238, 239, 240, 241, 243, 246, 248, 250, 252, 254, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 278, 279, 280, 302, 304, 382, 552, 558, 618, 620, 625, 632, 633, 634, 635, 640], "observ": [6, 7, 10, 16, 17, 18, 19, 21, 22, 27, 32, 34, 35, 36, 38, 50, 52, 53, 66, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 92, 93, 100, 102, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 193, 194, 195, 196, 197, 198, 199, 207, 212, 214, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 233, 234, 236, 238, 239, 240, 241, 243, 244, 246, 247, 248, 252, 253, 254, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 278, 279, 280, 283, 284, 285, 287, 289, 290, 291, 292, 293, 294, 297, 301, 302, 304, 308, 309, 311, 312, 313, 315, 317, 322, 323, 339, 340, 341, 348, 349, 350, 351, 352, 353, 355, 356, 357, 360, 363, 364, 367, 368, 369, 370, 371, 372, 382, 385, 386, 387, 388, 389, 390, 392, 418, 419, 467, 558, 590, 597, 598, 619, 620, 621, 622, 623, 624, 625, 627, 628, 632, 633, 634, 635, 637, 639, 640], "action_spec": [6, 17, 18, 19, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 88, 120, 121, 122, 123, 126, 130, 136, 137, 138, 144, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 218, 221, 225, 229, 230, 232, 241, 243, 246, 252, 255, 271, 272, 273, 274, 297, 313, 316, 339, 341, 342, 349, 351, 353, 355, 368, 370, 371, 372, 382, 558, 597, 618, 619, 620, 621, 622, 624, 625, 626, 628, 632, 633, 634, 635, 636, 637, 639, 640], "in_kei": [6, 7, 20, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 66, 69, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 207, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 283, 284, 285, 287, 296, 297, 302, 304, 313, 322, 326, 329, 332, 337, 339, 340, 341, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 362, 363, 364, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 391, 392, 464, 466, 467, 468, 474, 477, 478, 479, 480, 481, 482, 486, 487, 488, 489, 490, 493, 494, 495, 496, 497, 499, 500, 502, 504, 505, 506, 507, 508, 511, 512, 513, 514, 515, 517, 518, 519, 521, 522, 523, 525, 526, 529, 530, 531, 532, 533, 534, 535, 536, 558, 597, 618, 619, 620, 621, 622, 624, 625, 628, 631, 632, 633, 634, 635, 636, 637, 639, 640], "out_kei": [6, 7, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 66, 69, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 207, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 277, 278, 279, 280, 283, 284, 285, 287, 296, 298, 302, 304, 313, 314, 322, 326, 329, 332, 337, 339, 340, 341, 343, 344, 346, 347, 348, 349, 350, 351, 356, 357, 362, 363, 364, 367, 368, 369, 370, 371, 375, 377, 379, 382, 383, 385, 386, 387, 388, 390, 392, 408, 464, 466, 467, 468, 474, 477, 478, 479, 480, 481, 482, 486, 487, 488, 489, 490, 493, 494, 495, 496, 497, 499, 500, 502, 504, 505, 506, 507, 508, 511, 512, 513, 514, 515, 517, 518, 519, 521, 522, 523, 524, 525, 526, 527, 529, 530, 531, 532, 533, 534, 535, 536, 558, 597, 618, 619, 620, 621, 622, 624, 628, 631, 632, 633, 634, 635, 636, 637, 639, 640], "action": [6, 7, 10, 16, 17, 18, 19, 22, 27, 28, 32, 34, 35, 36, 38, 50, 52, 53, 64, 66, 78, 79, 80, 81, 82, 83, 84, 85, 88, 101, 102, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 214, 215, 218, 224, 225, 226, 229, 230, 231, 232, 233, 234, 236, 237, 239, 241, 243, 244, 245, 246, 248, 252, 253, 255, 259, 263, 265, 269, 271, 272, 273, 274, 278, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 301, 302, 304, 305, 306, 311, 312, 313, 314, 316, 317, 319, 320, 322, 326, 332, 337, 339, 340, 341, 342, 344, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 407, 418, 419, 467, 473, 558, 562, 590, 597, 598, 599, 601, 618, 619, 620, 622, 623, 624, 625, 630, 631, 632, 633, 634, 636, 639, 640], "192": [6, 142, 143], "enumer": [6, 34, 35, 38, 50, 52, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 73, 74, 75, 76, 77, 88, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 373, 375, 377, 379, 382, 383, 618, 619, 620, 621, 628, 633, 637, 639], "worker_fn": 6, "overwritten": [6, 42, 44, 47, 50, 78, 80, 81, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 236], "now": [6, 18, 21, 26, 65, 68, 69, 72, 73, 89, 148, 149, 150, 185, 189, 221, 259, 324, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 630, 632, 633, 634, 636, 637, 640], "from_modul": [6, 35, 36, 38, 86, 87, 176, 325, 326, 327, 328, 330, 331, 332, 337, 343, 346, 376, 378, 380, 381, 384, 417, 639], "spawn": [6, 22, 23, 42, 51, 134, 145, 150, 158, 270, 619, 633, 634], "target": [6, 7, 23, 27, 50, 88, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 264, 324, 326, 332, 337, 343, 344, 348, 349, 350, 351, 352, 353, 355, 357, 358, 361, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 413, 419, 551, 557, 558, 621, 622, 628, 633, 635], "arg": [6, 17, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 58, 60, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 102, 108, 109, 110, 112, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 208, 214, 215, 216, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 244, 249, 250, 251, 252, 253, 255, 258, 259, 261, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 274, 275, 276, 277, 278, 279, 283, 284, 285, 286, 287, 288, 295, 296, 297, 298, 301, 302, 304, 305, 312, 313, 314, 317, 322, 323, 324, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 399, 400, 401, 406, 410, 414, 418, 419, 562, 564, 566, 567, 569, 570, 572, 573, 574, 575, 579, 585, 611, 619, 622, 630], "w": [6, 23, 69, 123, 148, 149, 190, 221, 223, 228, 254, 268, 312, 367, 392, 511, 619, 637], "epoch": [6, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 414, 418, 471, 620, 633, 634], "stop": [6, 17, 32, 34, 35, 36, 38, 50, 52, 85, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 186, 326, 332, 337, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585, 620, 626, 633, 634, 639, 640], "With": [6, 17, 86, 87, 136, 137, 141, 176, 264, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 400, 402, 585, 619, 630, 632, 633, 634, 637, 640], "dictionari": [6, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 60, 86, 87, 88, 89, 102, 106, 108, 109, 120, 123, 126, 129, 130, 131, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 239, 265, 270, 272, 280, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 351, 370, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 408, 416, 560, 561, 562, 576, 619, 620, 623, 625, 633, 635, 640], "map": [6, 17, 21, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 93, 95, 100, 101, 102, 120, 123, 126, 130, 138, 141, 142, 143, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 214, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 232, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 278, 279, 280, 283, 284, 285, 297, 307, 313, 322, 323, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 343, 344, 346, 347, 350, 351, 364, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 408, 417, 418, 423, 471, 566, 578, 579, 580, 583, 584, 586, 598, 618, 619, 620, 621, 624, 625, 636], "transportbackend": [6, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585], "protocol": [6, 190, 197, 202], "stateless": [6, 17, 22, 53, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 218, 227, 280, 335, 336, 365, 375, 377, 379, 383, 390, 618, 623, 635, 640], "design": [6, 7, 10, 16, 17, 18, 22, 37, 46, 49, 63, 64, 86, 87, 88, 106, 112, 119, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 221, 239, 251, 270, 272, 280, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 597, 604, 611, 618, 619, 620, 623, 624, 625, 630, 631, 632, 633, 634, 635, 637, 639, 640], "rather": [6, 23, 65, 68, 69, 72, 73, 112, 148, 149, 178, 185, 253, 280, 618, 619, 620, 621, 623, 625, 633, 634, 637], "kwarg": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 58, 60, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 95, 96, 97, 98, 100, 101, 102, 108, 109, 110, 112, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 202, 208, 209, 215, 216, 218, 225, 243, 250, 252, 261, 265, 270, 271, 272, 274, 276, 277, 279, 281, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 296, 297, 298, 300, 301, 302, 303, 304, 305, 310, 312, 313, 314, 317, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 396, 397, 399, 400, 401, 406, 414, 418, 419, 553, 554, 559, 560, 561, 564, 566, 567, 569, 570, 572, 574, 575, 577, 579, 585, 611, 620, 622, 634], "receive_weight": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 563, 565, 568, 571, 573, 575, 578, 580], "pre": [6, 26, 51, 55, 83, 88, 97, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 269, 275, 277, 326, 332, 337, 375, 377, 379, 382, 383, 563, 566, 568, 571, 575, 640], "alloc": [6, 86, 87, 97, 176, 194, 295, 306, 324, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 563, 568, 571, 575, 590, 611, 618], "weightstrategi": [6, 563, 564, 566, 567, 568, 569, 570, 571, 572, 574, 575, 577, 579, 585, 586], "applic": [6, 86, 87, 150, 158, 170, 176, 325, 327, 328, 330, 331, 370, 376, 378, 380, 381, 384, 576, 578, 611, 623, 624, 635], "setup_connection_and_weights_on_receiv": [6, 563, 565, 568, 571, 573, 575], "recept": [6, 38], "note": [6, 18, 19, 20, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 213, 229, 232, 270, 279, 280, 302, 304, 312, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 350, 358, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 564, 566, 569, 570, 572, 574, 577, 579, 583, 585, 611, 619, 622, 624, 630, 632, 633, 634, 640], "mptransport": [6, 566], "ye": 6, "rpctransport": [6, 569], "raytransport": [6, 570, 572], "distributedtransport": 6, "sharedmemtransport": [6, 565, 575], "instant": [6, 573, 580], "arriv": [6, 566, 574], "specifi": [6, 7, 15, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 228, 229, 230, 232, 258, 261, 264, 269, 273, 274, 282, 307, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 343, 344, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 399, 402, 564, 566, 569, 570, 572, 574, 575, 576, 577, 579, 585, 611, 618, 620, 621, 622, 626, 630, 633], "expir": [6, 563, 568, 571], "weightupdat": 6, "deprec": [6, 34, 35, 36, 38, 41, 43, 45, 46, 48, 50, 56, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 279, 325, 326, 327, 328, 330, 331, 332, 337, 348, 350, 351, 353, 356, 357, 358, 363, 364, 367, 368, 369, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 588, 640], "11": [6, 29, 56, 64, 95, 96, 97, 101, 109, 116, 127, 214, 226, 268, 590], "prefer": [6, 18, 22, 32, 35, 36, 38, 47, 56, 65, 68, 72, 73, 108, 109, 120, 154, 159, 181, 251, 259, 367, 371, 410, 620, 633, 634, 637, 639], "power": [7, 16, 30, 619], "top": [7, 21, 23, 88, 114, 121, 122, 136, 137, 228, 271, 326, 332, 337, 486, 597, 624], "hydra": [7, 418, 612], "dataclass": [7, 74, 86, 87, 176, 325, 327, 328, 330, 331, 365, 376, 378, 380, 381, 384], "compos": [7, 10, 21, 65, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 103, 104, 105, 114, 115, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 226, 227, 239, 254, 270, 271, 272, 279, 326, 332, 337, 340, 351, 360, 370, 375, 377, 379, 382, 383, 392, 483, 597, 618, 619, 620, 621, 622, 626, 630, 632, 634, 636, 637, 639, 640], "overridden": [7, 22, 37, 39, 40, 41, 46, 49, 78, 80, 81, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 338, 340, 347, 385, 387, 388, 621, 633], "advantag": [7, 21, 22, 27, 178, 185, 300, 348, 350, 364, 367, 369, 375, 377, 379, 382, 385, 386, 387, 388, 389, 618, 619, 620, 621, 634, 635, 640], "glimps": 7, "go": [7, 19, 21, 26, 96, 141, 150, 227, 251, 255, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "sota": [7, 35, 38, 144, 237, 369, 404, 553, 618, 619, 639], "ppo_train": 7, "help": [7, 17, 23, 74, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 233, 326, 332, 333, 334, 337, 348, 350, 364, 367, 369, 375, 377, 379, 382, 383, 418, 589, 618, 619, 620, 621, 630, 631, 633, 634], "overrid": [7, 22, 37, 39, 40, 41, 46, 49, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 78, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 295, 326, 332, 337, 375, 377, 379, 382, 383, 392, 562, 567, 569, 570, 572, 577, 579, 584, 585, 630], "reproduc": [7, 17, 21, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 221, 239, 418, 419, 471, 618, 620, 622, 634], "command": [7, 25, 26, 29, 154, 159, 160, 190, 620, 630, 633, 634, 635, 640], "here": [7, 18, 19, 21, 23, 26, 27, 28, 29, 35, 38, 50, 84, 85, 114, 120, 123, 124, 125, 126, 130, 134, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 193, 221, 270, 399, 590, 618, 619, 620, 621, 622, 623, 624, 626, 628, 633, 634, 635, 637, 639, 640], "minim": [7, 16, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 394, 566, 590, 637], "config": [7, 25, 26, 190, 250, 277, 289, 294, 311, 418, 552, 553, 554, 556, 559, 611], "yaml": 7, "training_env": 7, "env_nam": [7, 25, 120, 121, 123, 124, 126, 127, 129, 130, 132, 136, 138, 139, 145, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 441, 442, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 618, 620, 640], "tell": [7, 18, 23, 26, 120, 152, 153, 270, 574, 581, 618, 621, 626, 633, 634], "proper": [7, 22, 23, 25, 26, 189, 324, 385, 386, 387, 388, 590, 619, 620, 630, 633, 634, 635, 637], "select": [7, 23, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 123, 142, 143, 152, 153, 163, 164, 170, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 236, 237, 240, 241, 243, 244, 245, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 297, 313, 324, 326, 332, 337, 342, 375, 377, 379, 382, 383, 412, 618, 622, 623, 631, 633, 637], "syntax": [7, 611, 618], "dmcontrol": [7, 16, 18, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "brax": [7, 16, 27, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 253, 441, 623, 640], "well": [7, 15, 16, 17, 20, 21, 22, 27, 50, 56, 65, 68, 72, 73, 74, 88, 102, 106, 110, 117, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 271, 272, 290, 315, 316, 326, 332, 337, 344, 365, 367, 371, 375, 377, 379, 382, 383, 385, 389, 618, 619, 621, 622, 623, 624, 625, 627, 636, 637, 639, 640], "reward": [7, 10, 17, 18, 19, 22, 34, 35, 38, 78, 79, 80, 81, 82, 83, 84, 85, 88, 101, 102, 114, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 214, 215, 218, 219, 224, 225, 229, 230, 232, 233, 234, 239, 241, 242, 243, 244, 248, 252, 253, 255, 256, 257, 258, 259, 260, 262, 263, 264, 269, 271, 272, 273, 274, 276, 277, 279, 280, 302, 323, 340, 348, 349, 351, 352, 353, 355, 356, 357, 360, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 406, 407, 408, 411, 418, 419, 562, 593, 612, 618, 619, 620, 621, 622, 623, 627, 630, 631, 633, 634, 635, 639, 640], "mlp": [7, 144, 283, 288, 290, 291, 292, 293, 297, 300, 302, 304, 353, 355, 463, 597, 619, 622, 624, 625, 628, 632, 636, 639], "convnet": [7, 290, 291, 300, 462, 597, 621, 622, 624, 639], "writer": [7, 10, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 94, 97, 102, 104, 108, 114, 115, 116, 119, 429, 430, 435, 436, 620, 637], "logger": [7, 20, 30, 390, 392, 394, 395, 396, 397, 398, 399, 407, 414, 418, 419, 458, 459, 460, 461, 471, 558, 562, 588, 612, 619, 633], "assign": [7, 17, 23, 32, 35, 36, 38, 54, 58, 75, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 351, 352, 353, 355, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 585, 611, 620, 624, 630, 633, 634, 637], "locat": [7, 15, 26, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 209, 228, 233, 246, 257, 280, 303, 320, 321, 324, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 417, 611, 618, 619, 620, 627, 633, 634, 637], "batched_env": 7, "transformed_env": [7, 225, 272, 623], "base_env": [7, 21, 22, 120, 122, 123, 126, 130, 131, 137, 138, 149, 150, 151, 154, 158, 159, 160, 162, 170, 171, 172, 175, 178, 179, 180, 194, 214, 215, 218, 224, 226, 227, 229, 231, 232, 241, 248, 252, 254, 260, 263, 265, 266, 270, 272, 392, 403, 440, 570, 590, 618, 619, 620, 622, 633, 636, 639, 640], "transform0": 7, "noop_reset": 7, "transform1": [7, 21], "step_count": [7, 34, 35, 38, 120, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 227, 263, 520, 620, 621, 622, 623, 628], "noop": [7, 245, 503], "30": [7, 18, 20, 68, 81, 88, 108, 109, 184, 217, 245, 315, 316, 390, 394, 397, 399, 458, 503, 611, 626, 631, 634, 635, 637], "max_step": [7, 16, 17, 30, 114, 120, 123, 126, 130, 138, 142, 143, 144, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 183, 263, 270, 390, 520, 623, 624, 625, 627, 628, 633, 634, 639, 640], "step_count_kei": [7, 226, 227, 263, 520], "_partial_": [7, 423, 424, 425, 426, 429, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 462, 463, 464, 465, 466, 467, 468, 469, 470, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550], "individu": [7, 23, 34, 42, 44, 47, 50, 69, 88, 102, 114, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 280, 326, 332, 337, 350, 364, 367, 375, 377, 379, 382, 383, 618, 621, 634], "construct": [7, 18, 24, 56, 65, 68, 69, 72, 73, 74, 78, 88, 120, 123, 126, 127, 129, 130, 138, 150, 151, 152, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 280, 302, 304, 316, 326, 332, 337, 344, 375, 377, 379, 382, 383, 414, 597, 612, 619, 620, 621, 624, 633, 635, 637, 640], "repeat": [7, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 181, 185, 194, 270, 295, 324, 326, 332, 337, 527, 620, 633, 634, 635], "layer": [7, 246, 279, 288, 290, 291, 296, 299, 302, 304, 305, 308, 309, 324, 333, 334, 338, 347, 463, 578, 583, 584, 590, 592, 593, 597, 619, 620, 621, 622, 624, 633, 636], "episod": [7, 18, 78, 79, 80, 81, 82, 83, 84, 85, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 217, 255, 258, 264, 385, 418, 619, 623, 628, 633, 634, 637], "track": [7, 20, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 73, 86, 87, 101, 102, 107, 123, 176, 178, 191, 258, 267, 279, 280, 312, 325, 327, 328, 330, 331, 340, 376, 378, 380, 381, 382, 384, 397, 406, 416, 418, 471, 588, 615, 619, 621, 623, 626, 634, 635, 637], "count": [7, 18, 20, 22, 32, 34, 35, 36, 38, 52, 126, 127, 226, 263, 270, 280, 312, 324, 408, 414, 551, 590, 618, 619, 620, 621, 637, 640], "composit": [7, 10, 17, 18, 19, 21, 57, 58, 59, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 87, 88, 106, 112, 119, 120, 123, 126, 128, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 206, 213, 215, 218, 229, 230, 231, 232, 234, 239, 241, 244, 252, 253, 259, 263, 265, 269, 270, 271, 273, 280, 286, 339, 341, 344, 346, 347, 348, 367, 382, 590, 618, 620, 624, 630, 635, 640], "combin": [7, 23, 102, 188, 195, 196, 324, 371, 619, 622, 627, 637, 639], "maximum": [7, 17, 23, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 47, 48, 50, 57, 75, 90, 95, 96, 97, 98, 101, 102, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 231, 256, 263, 264, 266, 319, 320, 321, 326, 329, 332, 337, 347, 349, 351, 356, 357, 363, 365, 366, 370, 375, 377, 379, 383, 392, 410, 418, 419, 471, 563, 564, 565, 566, 568, 569, 570, 571, 572, 574, 575, 577, 579, 585, 590, 611, 618, 619, 620, 621, 624, 633, 634, 637], "length": [7, 35, 36, 38, 47, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 83, 87, 102, 108, 109, 112, 120, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 196, 214, 221, 242, 251, 279, 288, 290, 292, 294, 305, 322, 325, 326, 332, 337, 339, 343, 382, 383, 404, 410, 590, 618, 620, 621, 626, 628, 630, 635, 637, 640], "concept": [7, 21, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 590, 619, 630, 637], "nest": [7, 16, 17, 19, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 60, 68, 69, 71, 86, 87, 88, 95, 96, 97, 100, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 213, 221, 263, 266, 270, 271, 325, 326, 327, 328, 330, 331, 332, 337, 340, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 403, 407, 612, 619, 620, 622, 634, 635, 637, 639], "deep": [7, 22, 28, 221, 242, 290, 291, 292, 293, 296, 312, 348, 351, 370, 618, 633], "factori": [7, 28, 32, 34, 35, 36, 38, 42, 44, 47, 50, 66, 68, 72, 73, 74, 194, 243, 401, 438, 462, 463, 618], "onc": [7, 22, 26, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 54, 69, 83, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 244, 255, 265, 272, 286, 312, 325, 326, 327, 328, 330, 331, 332, 337, 340, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 411, 564, 566, 567, 569, 570, 572, 574, 575, 577, 579, 585, 611, 619, 620, 621, 624, 627, 635, 637, 640], "per": [7, 19, 20, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 53, 80, 88, 101, 102, 108, 114, 134, 136, 137, 150, 152, 153, 196, 224, 244, 258, 288, 299, 301, 324, 333, 340, 367, 379, 392, 394, 397, 399, 414, 416, 418, 419, 471, 560, 561, 573, 585, 590, 618, 619, 620, 621, 622, 624, 625, 628, 633, 634, 637, 639], "variabl": [7, 18, 20, 22, 23, 26, 27, 41, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 80, 81, 84, 85, 87, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 142, 143, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 175, 178, 179, 180, 185, 196, 200, 202, 225, 267, 271, 280, 283, 284, 285, 302, 304, 326, 332, 337, 365, 368, 403, 590, 619, 631], "interpol": [7, 69, 254, 511, 619, 622], "script": [7, 26, 80, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 403, 558, 562, 612, 618, 619, 622, 627, 633, 634, 635, 637], "discov": [7, 23], "print": [7, 18, 22, 25, 26, 34, 35, 38, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 101, 102, 108, 109, 114, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 136, 137, 138, 139, 140, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 203, 206, 211, 212, 213, 214, 217, 218, 221, 222, 226, 227, 229, 230, 231, 232, 240, 246, 252, 253, 255, 258, 263, 265, 266, 267, 268, 279, 280, 283, 284, 285, 288, 290, 291, 292, 293, 294, 297, 300, 301, 302, 304, 305, 306, 307, 310, 312, 313, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 339, 340, 341, 343, 344, 346, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 400, 558, 581, 590, 611, 619, 620, 621, 622, 623, 624, 625, 626, 627, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "someth": [7, 88, 120, 123, 126, 130, 138, 141, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 589, 619, 620, 635, 640], "policy_model": [7, 582], "tanh_norm": 7, "value_model": [7, 359, 361], "policy_network": 7, "value_network": [7, 352, 353, 355, 356, 358, 363, 370, 385, 386, 387, 388, 604, 618, 620, 622, 625, 628, 633], "tensor": [7, 10, 12, 14, 17, 18, 19, 22, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 106, 108, 109, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 206, 212, 213, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 231, 232, 233, 234, 236, 239, 240, 242, 246, 248, 250, 251, 252, 253, 255, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 270, 271, 272, 273, 274, 275, 277, 279, 280, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 339, 340, 341, 343, 344, 346, 347, 348, 349, 351, 352, 353, 355, 356, 357, 360, 361, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 407, 425, 437, 573, 590, 592, 618, 619, 620, 621, 622, 623, 624, 633, 634, 635, 639, 640], "without_replac": 7, "round_robin": 7, "adam": [7, 172, 320, 419, 540, 618, 619, 620, 621, 622, 625, 628, 633, 634, 635], "wandb": [7, 392, 396, 399, 414, 418, 461, 471, 627, 639], "out_featur": [7, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 283, 288, 290, 291, 292, 293, 297, 299, 300, 302, 304, 305, 326, 332, 337, 343, 353, 355, 375, 377, 379, 382, 383, 463, 466, 467, 468, 618, 621, 622, 624, 625, 628, 639], "in_featur": [7, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 283, 288, 290, 291, 292, 293, 300, 305, 326, 332, 337, 343, 353, 355, 375, 377, 379, 382, 383, 462, 463, 466, 467, 468, 622, 624, 625], "num_cel": [7, 283, 288, 290, 291, 292, 293, 299, 300, 302, 304, 305, 462, 463, 466, 467, 468, 619, 620, 621, 622, 624, 625, 628, 633, 634, 639], "128": [7, 78, 79, 83, 109, 121, 122, 136, 137, 193, 291, 294, 611, 619, 621, 622, 628, 633, 636, 637], "num_cal": 7, "state_valu": [7, 284, 285, 322, 350, 356, 363, 364, 367, 368, 370, 385, 386, 387, 388, 618, 634], "loss_modul": [7, 350, 364, 365, 367, 375, 377, 379, 383, 413, 414, 417, 418, 419, 471, 557, 558, 604, 612, 618, 619, 620, 633, 634, 637], "1024": [7, 50, 66, 294, 400, 637], "lr": [7, 419, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 618, 619, 620, 621, 628, 633, 634, 635], "001": [7, 540, 541, 546, 549, 550, 618, 635], "actor_network": [7, 348, 349, 350, 351, 352, 354, 356, 357, 363, 364, 366, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 413, 417, 418, 419, 470, 471, 604, 618, 620, 625, 633, 634], "critic_network": [7, 348, 350, 364, 367, 369, 417, 418, 470, 471, 620, 634], "exp_nam": [7, 30, 392, 393, 394, 397, 398, 399, 458, 460, 461, 558, 619, 627, 628], "my_experi": [7, 402], "0001": [7, 280, 299, 307, 466, 537, 540, 544], "chang": [7, 18, 21, 24, 26, 30, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 86, 87, 88, 90, 95, 96, 97, 98, 102, 107, 108, 110, 112, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 232, 234, 241, 244, 252, 253, 259, 263, 269, 271, 272, 273, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 418, 419, 566, 574, 590, 611, 618, 621, 631, 633, 634, 635, 636, 637, 640], "rate": [7, 23, 30, 78, 279, 280, 418, 619, 620, 633, 634], "multirun": 7, "01": [7, 217, 246, 280, 312, 348, 350, 364, 367, 379, 537, 539, 541, 547, 548], "8": [7, 25, 26, 60, 68, 71, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 108, 109, 120, 121, 122, 123, 124, 125, 126, 130, 138, 148, 149, 150, 151, 154, 158, 159, 160, 161, 170, 171, 172, 175, 178, 179, 180, 214, 217, 226, 227, 264, 267, 273, 280, 283, 284, 285, 288, 290, 291, 300, 305, 341, 343, 346, 363, 618, 619, 635, 637, 639], "my_custom_config": 7, "under": [7, 17, 18, 21, 23, 50, 60, 71, 78, 79, 80, 81, 83, 84, 85, 88, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 242, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 297, 298, 313, 314, 326, 332, 337, 339, 341, 343, 344, 365, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 392, 414, 590, 618, 619, 624, 633, 635, 640], "hood": [7, 17, 50, 78, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 635], "configstor": 7, "type": [7, 10, 21, 22, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 85, 86, 87, 88, 120, 123, 126, 130, 138, 141, 144, 147, 150, 151, 152, 153, 154, 158, 159, 160, 167, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 204, 205, 209, 210, 212, 214, 218, 221, 225, 229, 230, 233, 234, 239, 241, 244, 250, 252, 253, 259, 263, 265, 269, 270, 271, 272, 273, 275, 277, 279, 280, 286, 288, 297, 305, 318, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 335, 336, 337, 341, 343, 344, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 400, 401, 402, 438, 462, 463, 469, 560, 573, 576, 611, 618, 619, 620, 622, 626, 630, 633, 634, 635, 637, 640], "safeti": [7, 32, 35, 36, 38, 144, 150, 158, 280, 611, 630], "id": [7, 26, 32, 34, 35, 36, 37, 38, 39, 40, 41, 46, 49, 52, 53, 55, 56, 69, 102, 108, 109, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 175, 177, 178, 179, 180, 200, 312, 324, 332, 351, 368, 395, 399, 461, 564, 566, 567, 569, 570, 572, 574, 577, 578, 579, 585, 626, 637], "registr": [7, 41, 400, 588, 619], "config_stor": 7, "cs": 7, "gymenvconfig": 7, "batchedenvconfig": 7, "tanhnormalmodelconfig": [7, 464], "inherit": [7, 21, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 193, 365, 375, 620, 633, 634], "envs_lib": 7, "envlibsconfig": 7, "mycustomenvconfig": 7, "_target_": [7, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 440, 441, 442, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 460, 461, 462, 463, 466, 467, 468, 470, 471, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550], "str": [7, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 95, 96, 97, 98, 101, 102, 114, 116, 120, 121, 123, 124, 125, 126, 128, 129, 130, 131, 132, 136, 138, 142, 143, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 210, 213, 217, 221, 233, 239, 240, 241, 243, 250, 254, 263, 264, 267, 269, 270, 272, 273, 275, 277, 278, 279, 282, 288, 289, 290, 291, 292, 293, 296, 297, 298, 300, 302, 304, 305, 306, 307, 311, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 341, 343, 344, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 440, 441, 442, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 460, 461, 462, 463, 466, 467, 468, 470, 471, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 552, 562, 564, 565, 566, 567, 569, 570, 571, 572, 573, 574, 576, 577, 578, 579, 580, 583, 584, 585, 611, 619, 620, 622, 630], "my_modul": [7, 570], "mycustomenv": 7, "myenv": [7, 150, 218, 229, 232], "custom_param": 7, "float": [7, 18, 21, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 58, 60, 64, 65, 69, 72, 75, 83, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 214, 217, 221, 225, 229, 232, 241, 242, 246, 250, 255, 256, 257, 264, 265, 268, 271, 272, 275, 277, 280, 286, 287, 295, 299, 303, 305, 306, 315, 316, 319, 321, 324, 325, 326, 327, 328, 330, 331, 332, 337, 343, 347, 348, 349, 350, 351, 355, 356, 357, 360, 361, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 411, 418, 419, 427, 463, 466, 470, 471, 482, 500, 502, 504, 512, 513, 514, 521, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 577, 578, 579, 580, 581, 583, 585, 590, 618, 619, 637, 640], "__post_init__": 7, "self": [7, 18, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 71, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 277, 278, 279, 282, 286, 301, 302, 304, 322, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 583, 584, 590, 611, 618, 630, 635, 639], "super": [7, 18, 21, 88, 144, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 322, 349, 351, 352, 357, 363, 368, 370, 371, 372, 382, 567, 569, 570, 572, 577, 579, 584, 585, 618, 635, 639], "my_custom": 7, "begin": [7, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 102, 108, 217, 403, 622, 623, 624, 625, 626, 627, 628, 630], "gradual": 7, "add": [7, 10, 16, 21, 23, 25, 50, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 94, 96, 101, 104, 114, 115, 118, 119, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 221, 239, 241, 269, 272, 302, 304, 326, 332, 337, 348, 374, 375, 377, 379, 382, 383, 409, 418, 471, 567, 569, 570, 572, 577, 579, 585, 590, 601, 611, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 633, 634, 635, 637, 639], "leverag": [7, 39, 50, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 324, 590, 618, 634, 640], "sparingli": 7, "correctli": [7, 22, 26, 88, 90, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 590], "duplic": [7, 88, 107, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 349, 351, 353, 358, 363, 365, 368, 370, 371, 372, 375, 377, 379, 382, 383], "As": [7, 19, 22, 23, 68, 69, 72, 73, 74, 78, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 255, 295, 344, 385, 618, 619, 620, 621, 622, 623, 625, 626, 633, 634, 635, 636, 637, 639, 640], "td3": [7, 371, 372], "expand": [7, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 95, 108, 109, 176, 218, 265, 295, 325, 327, 328, 330, 331, 343, 346, 349, 351, 363, 365, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 633, 634, 635, 637, 639], "sactrainerconfig": 7, "td3trainerconfig": 7, "addit": [7, 16, 19, 22, 23, 37, 39, 46, 49, 63, 79, 86, 87, 88, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 163, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 225, 250, 265, 269, 271, 272, 275, 277, 286, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 337, 340, 343, 350, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 392, 569, 570, 572, 585, 608, 611, 618, 619, 622, 623, 633, 634, 637], "maintain": [7, 18, 24, 28, 35, 36, 38, 63, 189, 192, 201, 221, 280, 357, 370, 573, 577, 590, 611, 635], "circumst": 8, "cudnn": [8, 302, 304, 621, 622], "7": [8, 10, 25, 29, 64, 65, 68, 72, 101, 102, 109, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 214, 217, 226, 227, 264, 267, 280, 287, 288, 291, 305, 324, 332, 337, 585, 618, 637, 639], "5x": 8, "batch_first": [8, 621], "input": [8, 9, 16, 17, 18, 20, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 96, 98, 111, 117, 120, 123, 126, 130, 138, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 243, 244, 248, 249, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 287, 288, 290, 291, 292, 293, 296, 297, 298, 301, 302, 304, 305, 307, 312, 313, 314, 315, 316, 320, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 407, 411, 551, 558, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585, 590, 594, 604, 618, 619, 620, 621, 622, 623, 630, 633, 634, 635, 639, 640], "fix": [8, 27, 150, 265, 349, 351, 366, 370, 611, 619, 628, 635, 640], "5": [8, 10, 18, 19, 32, 34, 35, 36, 38, 52, 56, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 72, 73, 78, 87, 88, 90, 108, 109, 114, 120, 123, 126, 127, 130, 136, 137, 138, 142, 143, 145, 150, 151, 154, 156, 157, 158, 159, 160, 163, 164, 170, 172, 175, 177, 178, 179, 180, 183, 193, 214, 217, 218, 220, 226, 227, 242, 255, 262, 263, 264, 270, 280, 287, 288, 290, 291, 296, 297, 299, 300, 303, 305, 308, 313, 320, 321, 324, 333, 334, 337, 340, 347, 364, 367, 369, 371, 372, 379, 390, 462, 463, 466, 468, 548, 590, 611, 617, 618, 619, 622, 624, 628, 633, 634, 635, 637, 638, 639, 640], "condit": [9, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 178, 183, 226, 227, 264, 279, 297, 298, 313, 314, 340, 484, 573, 588, 590, 618, 633, 635, 637], "met": [9, 226, 227, 633, 635], "packedsequ": 9, "dropout": [9, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 287, 302, 304, 305, 326, 332, 337, 375, 377, 379, 382, 383, 463, 621], "comprehens": [10, 16, 418, 419, 590, 592, 597, 604, 611], "around": [10, 24, 26, 32, 72, 73, 89, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 340, 342, 344, 385, 590, 618, 619, 630, 634, 640], "central": [10, 12, 37, 41, 46, 49, 50, 324, 401, 611, 618, 619, 623, 633, 634, 637], "offer": [10, 16, 17, 20, 22, 26, 120, 121, 122, 123, 126, 130, 136, 137, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 270, 390, 597, 618, 619, 622, 623, 625, 626, 633, 635, 637, 640], "memmap": [10, 86, 87, 95, 97, 150, 158, 176, 279, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 392, 394, 410, 579, 580, 582], "compress": [10, 90, 91], "advanc": [10, 22, 50, 65, 68, 72, 73, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 324, 400, 588, 623, 626, 637], "priorit": [10, 27, 65, 72, 101, 102, 351, 352, 353, 355, 356, 357, 363, 368, 370, 371, 372, 427, 618, 619, 626, 639], "mix": [10, 251, 611, 618, 633, 634], "arbitrari": [10, 16, 17, 22, 57, 64, 68, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 618, 619, 635, 637], "lazymemmapstorag": [10, 12, 15, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 102, 108, 109, 220, 221, 423, 618, 619, 621, 626, 633, 636, 637], "prioritizedsampl": [10, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 102, 353, 358, 427, 618, 637], "max_siz": [10, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 95, 96, 97, 98, 108, 109, 110, 114, 116, 423, 424, 425, 426, 437, 620, 626], "1000000": [10, 78, 79, 80, 81, 82, 83, 84, 85, 400, 419, 537, 612], "max_capac": [10, 101, 102, 427, 618, 637], "alpha": [10, 65, 72, 101, 102, 288, 290, 291, 292, 293, 300, 349, 351, 357, 366, 368, 370, 371, 427, 537, 547, 618, 637, 639], "beta": [10, 23, 65, 72, 101, 102, 356, 363, 364, 383, 427, 540, 541, 542, 544, 545, 546, 550, 618, 619, 637, 639], "batch_siz": [10, 17, 18, 19, 22, 27, 34, 35, 38, 52, 55, 56, 60, 63, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 101, 102, 103, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 133, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 212, 213, 214, 218, 220, 221, 225, 229, 232, 233, 234, 239, 248, 252, 253, 255, 259, 262, 263, 265, 271, 272, 273, 283, 284, 285, 287, 294, 295, 296, 297, 298, 301, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 344, 346, 347, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 400, 404, 410, 416, 418, 419, 429, 436, 441, 442, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 476, 590, 611, 618, 619, 620, 621, 626, 630, 631, 633, 634, 635, 637, 639, 640], "256": [10, 34, 52, 142, 143, 239, 294, 590, 619, 620, 622, 633, 634], "randn": [10, 22, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 95, 96, 97, 102, 108, 109, 116, 120, 176, 188, 206, 220, 246, 283, 284, 285, 287, 289, 290, 294, 296, 297, 306, 307, 310, 311, 313, 322, 325, 327, 328, 330, 331, 338, 339, 341, 343, 346, 347, 348, 349, 351, 352, 353, 355, 356, 357, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 412, 462, 463, 466, 467, 468, 622, 637, 639, 640], "32": [10, 51, 60, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 109, 130, 137, 156, 157, 163, 164, 180, 185, 192, 193, 194, 221, 239, 288, 289, 290, 291, 293, 294, 300, 305, 308, 309, 311, 390, 400, 461, 462, 463, 466, 467, 468, 611, 619, 621, 622, 624, 625, 635, 636, 637, 639, 640], "compressedliststorag": [10, 91], "compressedliststoragecheckpoint": 10, "flatstoragecheckpoint": 10, "h5storagecheckpoint": 10, "immutabledatasetwrit": [10, 78, 79, 80, 81, 82, 83, 84, 85], "liststorag": [10, 12, 65, 66, 68, 69, 72, 73, 96, 426, 637], "lazystackstorag": [10, 88, 424], "liststoragecheckpoint": 10, "nestedstoragecheckpoint": 10, "storagecheckpointerbas": [10, 68, 110], "storageensembl": [10, 69, 106, 434], "storageensemblecheckpoint": 10, "tensorstorag": [10, 12, 68, 78, 79, 80, 81, 82, 83, 84, 85, 95, 101, 102, 114, 117, 437, 626, 637], "tensorstoragecheckpoint": [10, 95], "prioritizedslicesampl": [10, 637], "randomsampl": [10, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 428, 618, 633], "samplerensembl": [10, 69], "samplerwithoutreplac": [10, 88, 114, 431, 620, 634, 637], "slicesamplerwithoutreplac": [10, 108, 433, 637], "ataridqnexperiencereplai": 10, "d4rlexperiencereplai": 10, "gendgrlexperiencereplai": 10, "minariexperiencereplai": [10, 78, 79, 80, 82, 83, 84, 85], "openmlexperiencereplai": 10, "openxexperiencereplai": [10, 392], "robosetexperiencereplai": [10, 108, 109], "vd4rlexperiencereplai": 10, "tensorspec": [10, 17, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 75, 76, 77, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 213, 214, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 238, 240, 241, 242, 243, 244, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 286, 297, 298, 301, 312, 313, 314, 316, 339, 341, 342, 343, 344, 345, 347, 349, 351, 353, 356, 357, 368, 370, 371, 372, 382, 588, 635], "binari": [10, 18, 26, 64, 161, 215, 219, 297, 298, 313, 314, 353, 356, 357, 630], "bound": [10, 18, 23, 50, 60, 75, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 224, 245, 279, 286, 297, 298, 301, 312, 313, 314, 315, 316, 326, 332, 337, 339, 341, 342, 343, 344, 347, 348, 349, 351, 352, 363, 367, 368, 370, 371, 372, 375, 377, 379, 382, 383, 618, 619, 620, 622, 633, 635, 639, 640], "categor": [10, 19, 21, 57, 58, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 175, 178, 179, 180, 213, 214, 215, 233, 252, 297, 298, 310, 313, 314, 326, 341, 353, 356, 357, 473, 621], "multicategor": [10, 62], "multionehot": [10, 61, 353, 356, 357], "nontensor": [10, 17, 87, 175, 180, 239, 273], "onehot": [10, 57, 58, 59, 60, 61, 62, 63, 70, 71, 74, 75, 76, 77, 121, 122, 129, 131, 132, 135, 136, 137, 145, 146, 148, 149, 155, 161, 162, 297, 313, 353, 355, 356, 357], "stackedcomposit": 10, "unbound": [10, 18, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 76, 77, 86, 87, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 206, 215, 218, 229, 232, 252, 265, 322, 325, 327, 328, 330, 331, 339, 343, 346, 369, 376, 378, 380, 381, 384, 590, 630, 635, 637], "unboundedcontinu": [10, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 252, 265, 346], "unboundeddiscret": [10, 75, 151, 239], "offlin": [11, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 78, 80, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 349, 355, 356, 363, 371, 382, 399, 461, 588, 604, 623, 636, 637], "wide": [12, 22, 24, 639], "give": [12, 22, 26, 60, 71, 72, 80, 87, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 350, 364, 367, 589, 611, 618, 619, 622, 633, 634, 635, 636, 639], "abil": [12, 15, 365, 635, 637], "panel": [12, 620], "almost": [12, 280, 306, 621], "physic": [12, 25, 26, 93, 150, 151, 155, 618, 633, 634, 635], "theori": 12, "crude": 12, "made": [12, 18, 22, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 78, 88, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 265, 271, 312, 326, 332, 337, 353, 365, 375, 377, 379, 382, 383, 464, 618, 619, 621, 633, 634, 636, 637, 639], "ineffici": [12, 23], "contigu": [12, 18, 27, 58, 60, 75, 80, 83, 84, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 239, 242, 265, 273, 635, 637, 639], "collate_fn": [12, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 170, 171, 172, 175, 637, 639], "__init__": [12, 18, 21, 26, 88, 126, 144, 161, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 211, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 295, 322, 334, 349, 351, 352, 357, 363, 368, 370, 371, 372, 382, 611, 635, 640], "retriev": [13, 17, 22, 32, 35, 36, 37, 38, 39, 41, 46, 49, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 106, 108, 109, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 188, 189, 195, 196, 201, 212, 222, 230, 233, 246, 325, 327, 328, 330, 331, 337, 340, 341, 344, 347, 348, 349, 350, 351, 353, 364, 367, 368, 370, 371, 372, 376, 378, 379, 380, 381, 384, 385, 386, 387, 388, 400, 401, 402, 562, 571, 619, 620, 624, 635, 640], "dtype": [14, 18, 19, 22, 34, 35, 38, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 101, 102, 108, 109, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 209, 212, 213, 214, 215, 218, 219, 225, 226, 229, 230, 231, 232, 233, 234, 239, 241, 242, 246, 248, 250, 252, 253, 255, 259, 262, 263, 265, 267, 268, 271, 272, 273, 275, 277, 283, 284, 285, 287, 296, 297, 298, 302, 304, 312, 313, 314, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 344, 346, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 487, 525, 578, 583, 584, 586, 590, 622, 630, 631, 632, 635, 637, 639, 640], "domain": [14, 16, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 184, 206, 231, 239, 265, 273, 297, 298, 313, 314, 339, 341, 343, 344, 345, 346, 620, 625, 630, 633, 634, 635, 639, 640], "influenti": 15, "latenc": [15, 22, 611], "especi": [15, 17, 26, 27, 222, 326, 332, 337, 566], "larger": [15, 23, 42, 47, 50, 302, 304, 356, 363, 639], "volum": 15, "advis": [15, 30, 80, 627, 640], "due": [15, 22, 24, 33, 42, 43, 44, 45, 47, 48, 56, 350, 367, 419, 585, 625, 636, 637, 640], "memorymappedtensor": [15, 78, 79, 80, 81, 82, 83, 84, 85, 95, 394, 626], "file": [15, 25, 26, 27, 78, 79, 80, 81, 83, 84, 85, 86, 87, 93, 163, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 391, 392, 394, 414, 418, 419, 471, 579, 580, 581, 588, 611, 617, 619, 633, 637, 638], "improv": [15, 23, 30, 54, 177, 192, 237, 348, 418, 622, 633, 634, 637], "failur": [15, 23, 177, 324, 350, 367, 379, 590], "recoveri": 15, "wrapper": [16, 17, 21, 32, 55, 72, 73, 86, 87, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 169, 170, 171, 172, 175, 176, 178, 179, 180, 185, 189, 278, 282, 287, 323, 325, 326, 327, 328, 329, 330, 331, 332, 334, 337, 340, 342, 344, 376, 378, 380, 381, 384, 385, 397, 398, 399, 562, 586, 588, 597, 617, 620, 621, 623, 629, 630, 633, 634, 636, 638, 639, 640], "popular": [16, 22, 621, 625, 634], "framework": [16, 18, 23, 28, 51, 120, 121, 122, 123, 126, 130, 136, 137, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 590, 611, 630, 631, 639, 640], "jumanji": [16, 18, 120, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 447], "envbas": [16, 17, 18, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 88, 120, 123, 127, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 215, 218, 229, 232, 245, 252, 253, 271, 272, 279, 302, 304, 340, 382, 408, 552, 553, 554, 558, 560, 561, 562, 623], "foundat": [16, 18, 24, 152, 153, 422, 592, 620, 634], "output": [16, 17, 18, 19, 20, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 65, 68, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 137, 138, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 213, 218, 219, 221, 224, 225, 227, 228, 229, 230, 232, 234, 236, 239, 241, 244, 246, 250, 252, 253, 258, 259, 262, 263, 266, 267, 269, 271, 272, 273, 275, 277, 278, 280, 283, 286, 288, 289, 290, 291, 294, 296, 297, 298, 299, 302, 304, 305, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 404, 590, 592, 594, 597, 604, 618, 619, 620, 621, 622, 623, 624, 627, 630, 631, 632, 633, 634, 635, 636, 639, 640], "infrastructur": [16, 19, 197, 633, 634], "transformedenv": [16, 21, 22, 30, 31, 88, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 218, 221, 224, 225, 227, 229, 232, 233, 234, 240, 241, 242, 245, 246, 248, 252, 253, 254, 255, 258, 259, 260, 263, 264, 265, 266, 270, 271, 279, 302, 304, 340, 382, 392, 403, 440, 570, 590, 618, 619, 620, 621, 622, 623, 627, 628, 632, 633, 634, 635, 636, 637, 639, 640], "rewardsum": [16, 21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 212, 271, 382, 515, 633, 634], "stepcount": [16, 88, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 226, 227, 270, 271, 272, 287, 382, 520, 590, 618, 619, 620, 621, 622, 623, 628, 633, 634, 639], "parallel_env": [16, 153, 618, 639, 640], "100": [16, 32, 34, 35, 36, 38, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 95, 97, 108, 109, 114, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 224, 226, 233, 246, 255, 260, 263, 298, 306, 324, 326, 332, 337, 340, 375, 377, 379, 382, 383, 392, 405, 419, 543, 558, 566, 611, 619, 620, 622, 623, 625, 628, 632, 633, 634, 635, 637, 639, 640], "lock": [16, 60, 71, 86, 87, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 218, 227, 265, 279, 280, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 635], "partial": [16, 17, 32, 34, 35, 36, 38, 52, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 220, 221, 264, 265, 266, 341, 414, 621], "invers": [16, 23, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 221, 229, 232, 234, 239, 243, 246, 253, 255, 267, 269, 271, 273, 350, 356, 363, 367, 379, 382, 635], "marlgroupmaptyp": [16, 142, 143, 148, 149, 152, 153, 161, 162, 163, 164, 166, 633], "check_marl_group": 16, "auto": [16, 54, 89, 97, 116, 126, 131, 216, 217, 272, 278, 312, 349, 351, 357, 366, 368, 370, 371, 372, 400, 402, 585, 633, 634], "dynam": [16, 26, 34, 35, 36, 38, 80, 83, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 206, 356, 363, 400, 592, 597, 602, 620, 623, 635], "record": [16, 30, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 207, 214, 241, 326, 332, 337, 367, 375, 377, 379, 382, 383, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 408, 419, 458, 460, 461, 558, 588, 612, 619, 620, 624, 628, 633], "dm": [17, 618, 640], "abl": [17, 21, 22, 120, 141, 152, 153, 154, 159, 302, 304, 618, 620, 621, 624, 632, 633, 634, 635, 637], "simul": [17, 18, 19, 20, 24, 26, 27, 74, 121, 122, 123, 132, 136, 137, 155, 163, 164, 170, 208, 317, 590, 618, 620, 622, 623, 627, 631, 633, 634], "box": [17, 19, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 129, 131, 365, 375, 377, 379, 383, 630], "lib": [17, 18, 19, 24, 25, 26, 28, 29, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 88, 120, 123, 126, 127, 130, 135, 138, 142, 143, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 221, 224, 233, 240, 241, 246, 248, 253, 255, 258, 265, 271, 278, 279, 382, 390, 441, 442, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 558, 618, 619, 620, 621, 632, 634, 636, 637, 639, 640], "hope": [17, 30], "imit": [17, 362], "parent": [17, 20, 21, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 63, 69, 74, 88, 112, 119, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 221, 222, 225, 226, 227, 230, 233, 236, 237, 244, 246, 250, 258, 263, 264, 265, 266, 270, 271, 274, 275, 283, 302, 304, 326, 332, 337, 365, 367, 375, 377, 379, 382, 383, 389, 390, 392, 464, 465, 566, 570, 618, 626, 635, 639, 640], "subclass": [17, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 58, 60, 69, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 216, 217, 271, 278, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 337, 338, 340, 343, 344, 345, 347, 365, 367, 567, 569, 570, 572, 577, 579, 584, 585, 611, 619, 621, 626, 635, 637], "organis": [17, 84, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272, 619], "togeth": [17, 21, 30, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 70, 71, 96, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 251, 262, 271, 283, 284, 285, 302, 304, 323, 585, 590, 619, 621, 623, 633], "live": [17, 22, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 233, 326, 332, 337, 375, 377, 379, 382, 383, 491], "doe": [17, 18, 21, 22, 40, 42, 65, 72, 78, 79, 83, 86, 87, 88, 92, 93, 100, 102, 108, 110, 112, 119, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 280, 294, 295, 302, 304, 325, 326, 327, 328, 330, 331, 332, 337, 345, 346, 348, 350, 358, 364, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 414, 567, 618, 619, 620, 621, 623, 626, 633, 635, 637, 640], "respons": [17, 20, 22, 27, 34, 35, 36, 38, 41, 42, 47, 50, 52, 53, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 174, 175, 177, 178, 179, 180, 183, 186, 187, 190, 193, 203, 325, 327, 329, 330, 331, 332, 337, 379, 383, 414, 563, 590, 592, 625, 626, 630, 631, 640], "just": [17, 22, 23, 86, 87, 112, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 135, 136, 137, 138, 141, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 175, 176, 178, 179, 180, 213, 217, 224, 265, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 404, 590, 611, 618, 619, 620, 621, 622, 623, 624, 626, 630, 633, 634, 635, 637, 639, 640], "care": [17, 20, 21, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 338, 340, 347, 392, 618, 620, 622, 633, 634, 635, 637], "desir": [17, 18, 30, 32, 34, 35, 36, 38, 52, 59, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 216, 218, 225, 227, 246, 248, 250, 251, 265, 271, 272, 275, 277, 288, 295, 297, 298, 305, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 343, 344, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 618, 622, 630, 633, 634, 635, 637], "parametr": [17, 307, 344, 349, 351, 356, 363, 370, 618, 620], "pair": [17, 22, 55, 79, 86, 87, 120, 123, 124, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 255, 265, 270, 283, 302, 325, 327, 328, 330, 331, 341, 344, 365, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 577, 599, 618, 619, 620, 624, 625, 632, 635, 640], "state_spec": [17, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 225, 230, 243, 246, 271, 273, 274, 382, 635, 640], "empti": [17, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 98, 120, 123, 126, 130, 137, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 206, 229, 232, 250, 252, 266, 272, 275, 277, 280, 324, 325, 326, 327, 328, 330, 331, 332, 337, 343, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 396, 401, 611, 618, 635], "reward_spec": [17, 18, 19, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 218, 219, 224, 225, 229, 230, 232, 242, 243, 252, 256, 257, 258, 260, 262, 269, 271, 273, 274, 280, 382, 590, 620, 630, 633, 634, 635, 640], "done_spec": [17, 18, 19, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 229, 230, 232, 233, 243, 252, 262, 269, 271, 273, 382, 633, 634, 635, 640], "termin": [17, 18, 19, 22, 26, 32, 34, 35, 36, 38, 52, 66, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 100, 108, 120, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 142, 143, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 178, 179, 180, 185, 213, 214, 217, 218, 233, 239, 252, 265, 273, 302, 304, 340, 345, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 385, 386, 387, 388, 389, 400, 401, 590, 611, 618, 619, 620, 630, 633, 634, 635, 639, 640], "input_spec": [17, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 225, 229, 230, 231, 244, 248, 252, 253, 258, 259, 262, 263, 264, 265, 269, 271, 272, 273, 276, 382, 620, 635], "full_action_spec": [17, 120, 123, 126, 130, 138, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 175, 178, 179, 180, 214, 230, 633, 634], "full_state_spec": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 214, 230], "output_spec": [17, 19, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 272, 273, 280, 382, 635], "full_observation_spec": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180], "full_reward_spec": [17, 18, 19, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 218, 230, 252, 633, 634], "full_done_spec": [17, 18, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 218, 230, 252, 633, 634], "carri": [17, 19, 50, 62, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 265, 280, 365, 375, 377, 379, 383, 619, 621, 633, 634, 635, 637], "spec_lock": [17, 126], "modif": [17, 19, 22, 24, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 236, 239, 326, 332, 337, 365, 375, 377, 379, 382, 383, 590, 620, 635], "children": [17, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "unlock": [17, 22, 60, 71, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "set_spec_lock_": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "reason": [17, 21, 22, 23, 27, 83, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 275, 304, 326, 332, 337, 375, 377, 379, 382, 383, 590, 618, 619, 620, 625, 626, 633, 635, 637], "cach": [17, 20, 32, 35, 36, 38, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 102, 108, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 194, 212, 217, 229, 232, 250, 271, 272, 277, 324, 405, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585, 590], "modifi": [17, 18, 22, 26, 27, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 225, 227, 236, 239, 241, 243, 250, 265, 271, 272, 275, 277, 280, 312, 325, 326, 327, 328, 330, 331, 332, 337, 343, 344, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 551, 590, 618, 619, 620, 622, 623, 633, 634, 635], "often": [17, 22, 27, 350, 365, 367, 375, 377, 379, 383, 414, 618, 619, 623, 625, 635, 637, 640], "principl": [17, 590], "new_spec": 17, "eras": [17, 21, 22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272], "relock": 17, "wa": [17, 22, 24, 26, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 91, 102, 107, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 185, 213, 221, 239, 272, 325, 326, 327, 328, 330, 331, 332, 337, 348, 350, 364, 367, 369, 376, 378, 379, 380, 381, 384, 401, 564, 566, 569, 570, 571, 572, 574, 577, 579, 585, 619, 620, 623, 624, 632, 633, 637, 639], "previous": [17, 23, 81, 401, 620, 640], "importantli": [17, 341, 344], "action_s": 17, "prealloc": [17, 22, 150, 158, 635], "necessarili": [17, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 640], "present": [17, 18, 19, 22, 52, 65, 66, 68, 69, 74, 78, 79, 83, 86, 87, 88, 101, 102, 107, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 234, 255, 259, 265, 270, 272, 288, 289, 290, 291, 292, 293, 300, 302, 304, 311, 312, 325, 326, 327, 328, 330, 331, 332, 337, 340, 343, 344, 345, 346, 348, 349, 350, 351, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 562, 618, 628, 632, 633, 634, 637, 639], "0s": [17, 78, 83, 265, 621], "step_and_maybe_reset": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 590, 623, 630], "next": [17, 18, 19, 23, 27, 34, 35, 38, 53, 56, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 92, 93, 100, 102, 108, 109, 114, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 136, 137, 138, 142, 143, 144, 148, 149, 150, 151, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 178, 179, 180, 183, 185, 188, 190, 192, 193, 195, 206, 212, 214, 217, 218, 220, 221, 226, 227, 229, 232, 233, 234, 239, 240, 241, 242, 244, 248, 252, 253, 255, 258, 259, 263, 265, 267, 270, 273, 278, 279, 280, 302, 304, 316, 317, 323, 340, 348, 349, 351, 352, 353, 355, 356, 357, 358, 363, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 392, 407, 408, 411, 432, 433, 590, 611, 619, 621, 622, 624, 628, 630, 635, 636, 639, 640], "step_mdp": [17, 60, 71, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 302, 304, 621, 623, 635, 639, 640], "done_kei": [17, 18, 19, 56, 88, 92, 93, 100, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 217, 221, 233, 255, 263, 382, 491, 633, 634], "_reset": [17, 18, 22, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 215, 217, 218, 221, 229, 232, 240, 252, 267, 633], "data_": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "append": [17, 19, 20, 21, 27, 30, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 182, 185, 195, 217, 224, 225, 244, 255, 265, 272, 278, 297, 302, 304, 313, 590, 592, 618, 619, 620, 621, 622, 630, 633, 634, 635, 636, 637, 639], "set_se": [17, 18, 32, 34, 35, 36, 38, 50, 52, 53, 120, 121, 122, 123, 126, 130, 136, 137, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 226, 227, 246, 253, 258, 264, 266, 272, 590, 622, 626, 628, 635, 639, 640], "seed": [17, 18, 32, 34, 35, 36, 38, 50, 52, 53, 68, 69, 72, 73, 84, 120, 123, 126, 130, 138, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 175, 178, 179, 180, 181, 215, 218, 229, 232, 239, 252, 272, 390, 414, 418, 419, 471, 633], "determinist": [17, 32, 34, 35, 36, 38, 42, 44, 47, 50, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 210, 225, 250, 265, 271, 272, 275, 277, 289, 299, 308, 316, 317, 326, 332, 337, 339, 341, 343, 344, 347, 349, 350, 365, 367, 375, 377, 379, 382, 383, 408, 598, 618, 619, 620, 621, 622, 624, 625, 628, 633, 635, 639, 640], "preced": [17, 123, 221, 417, 621], "risk": [17, 251], "overlap": [17, 72, 114], "mark": [17, 34, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 267, 302, 304, 385, 387, 388, 626, 637], "trail": [17, 63, 177, 279, 630], "treat": [17, 21, 624, 625], "figur": [17, 21, 618, 620, 621, 634, 635, 640], "brief": [17, 620, 623, 625, 637], "entri": [17, 19, 21, 22, 32, 35, 36, 38, 56, 60, 71, 79, 80, 81, 82, 84, 85, 86, 87, 88, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 142, 143, 150, 151, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 217, 221, 223, 224, 227, 228, 229, 230, 232, 233, 236, 240, 242, 244, 246, 248, 250, 253, 255, 258, 260, 262, 263, 264, 265, 267, 270, 272, 274, 277, 279, 297, 302, 306, 313, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 349, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 618, 620, 621, 623, 624, 625, 627, 633, 634, 635, 636, 637, 639, 640], "metaclass": [17, 126, 131], "everi": [17, 27, 32, 34, 35, 36, 38, 39, 52, 53, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 110, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 263, 264, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 326, 332, 337, 338, 340, 347, 350, 364, 365, 367, 375, 377, 379, 382, 383, 414, 618, 619, 620, 621, 623, 624, 633, 634, 635], "flank": [17, 621], "dual": 17, "strictli": [17, 27, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 242, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383, 618, 620], "union": [17, 34, 47, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 275, 277, 288, 289, 290, 291, 292, 293, 300, 305, 311, 324, 326, 332, 337, 343, 355, 357, 368, 375, 377, 379, 382, 383, 410, 559, 562], "interpret": [17, 65, 66, 68, 69, 192, 193, 590, 611, 619], "truncat": [17, 18, 19, 22, 32, 34, 35, 36, 38, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 93, 100, 102, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 178, 179, 180, 185, 213, 214, 233, 234, 239, 245, 252, 255, 259, 263, 265, 272, 273, 302, 304, 321, 330, 340, 385, 432, 433, 520, 618, 620, 623, 633, 640], "look": [17, 19, 22, 24, 26, 27, 86, 87, 88, 102, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 226, 239, 250, 251, 275, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 345, 346, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 620, 621, 622, 623, 624, 625, 626, 627, 628, 633, 634, 635, 636, 637, 639, 640], "assess": [17, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 71, 142, 143, 166, 175, 618], "split_trajectori": [17, 32, 34, 35, 36, 38, 42, 44, 47, 50, 78, 83, 102, 108, 109], "adjac": [17, 56, 236, 340], "junction": 17, "miss": [17, 22, 23, 25, 26, 60, 88, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 239, 270, 272, 278, 282, 326, 332, 337, 345, 346, 348, 351, 367, 370, 375, 377, 379, 382, 383, 589, 611, 618, 621, 631], "inittrack": [17, 302, 304, 340, 498, 618, 621], "our": [17, 18, 21, 26, 27, 30, 42, 68, 221, 226, 392, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 632, 633, 634, 636, 637, 639], "tutori": [17, 21, 151, 184, 587, 617, 618, 619, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 635, 636, 637, 638, 640], "inform": [17, 18, 19, 21, 23, 32, 34, 35, 36, 38, 42, 44, 47, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 86, 87, 88, 101, 102, 120, 123, 126, 127, 130, 133, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 287, 288, 305, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 414, 418, 471, 618, 619, 620, 621, 622, 623, 630, 633, 634, 635, 637, 639], "scratch": [17, 27, 619, 635], "mission": 18, "irrespect": [18, 343, 344], "statu": [18, 46, 126, 189, 190], "mostli": [18, 22, 32, 392, 627, 637, 640], "Its": [18, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 279, 326, 332, 337, 343, 375, 377, 379, 382, 383, 389], "success": [18, 78, 79, 80, 81, 82, 83, 84, 85, 172, 174, 177, 178, 185, 190, 192, 221, 267, 301, 351, 371, 590, 619, 626, 628, 631, 635, 637, 639], "inspir": [18, 622, 635], "howev": [18, 24, 26, 54, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 326, 332, 337, 348, 350, 351, 364, 367, 369, 370, 375, 377, 379, 382, 383, 590, 618, 619, 621, 622, 625, 635, 637, 640], "gone": [18, 23, 24, 340], "sometim": [18, 74, 621, 640], "hard": [18, 26, 35, 36, 38, 114, 124, 125, 150, 619, 640], "accommod": [18, 19, 611, 623, 624], "extern": [18, 229, 232, 280, 324, 335, 336, 611, 630, 633, 640], "adopt": [18, 24, 618, 640], "moreov": 18, "facilit": [18, 26, 249, 250, 265, 275, 277, 283, 284, 285, 618, 621, 624, 635], "instal": [18, 24, 29, 42, 44, 47, 79, 82, 120, 123, 126, 130, 135, 138, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 190, 394, 402, 414, 589, 618, 620, 621, 622, 623, 624, 625, 626, 627, 628, 633, 634, 640], "virtual": [18, 129], "concomittantli": 18, "fortun": [18, 21, 621, 622, 623, 624, 627], "decor": [18, 27, 209, 211, 282, 302, 304, 365, 385, 386, 387, 388, 403, 590, 621, 639], "set_gym_backend": [18, 32, 34, 35, 36, 38, 52, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 175, 178, 179, 180, 217, 623, 639], "relev": [18, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 385, 386, 387, 388, 389, 399, 622, 635], "gym_backend": [18, 211], "env1": [18, 287, 632], "venv": 18, "python3": [18, 25, 26, 29], "site": [18, 25, 26, 84, 123, 211], "env2": [18, 632], "_env": [18, 25, 129, 640], "classic_control": 18, "pendulumenv": [18, 635], "0x15147e190": 18, "0x1629916a0": 18, "further": [18, 22, 24, 383, 618, 620, 622, 623], "mo_gymnasium": [18, 140, 169, 242], "handi": [18, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 627], "v0": [18, 35, 36, 38, 60, 71, 86, 87, 120, 123, 126, 130, 132, 135, 136, 137, 138, 139, 140, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 225, 242, 272, 279, 280, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 403, 558], "26": [18, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 195, 196, 226], "fun": [18, 211, 282, 620, 633, 634], "effect": [18, 22, 34, 52, 53, 60, 65, 66, 68, 69, 72, 73, 78, 83, 86, 87, 88, 101, 102, 106, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 217, 221, 227, 272, 325, 326, 327, 328, 330, 331, 332, 337, 350, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 414, 419, 590, 618, 624, 633, 637, 640], "autoresettransform": [18, 475], "skip": [18, 20, 22, 39, 78, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 237, 239, 244, 270, 272, 326, 331, 332, 337, 341, 344, 351, 365, 370, 375, 377, 379, 382, 383, 385, 386, 387, 388, 391, 392, 406, 408, 418, 419, 471, 618, 619, 631, 635], "fine": [18, 68, 69, 72, 73, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 218, 241, 383, 590, 622, 626, 636], "grain": [18, 68, 69, 72, 73, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 218], "invalid": [18, 88, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 166, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 306, 326, 332, 333, 337, 375, 377, 379, 382, 383, 631], "nan": [18, 217, 278, 475], "auto_reset": [18, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 217, 635], "auto_reset_replac": [18, 217], "replac": [18, 21, 25, 26, 78, 83, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 217, 231, 233, 240, 279, 280, 301, 324, 326, 332, 337, 349, 351, 357, 363, 368, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 431, 433, 475, 633, 637, 639], "placehold": [18, 131, 132, 175, 233, 272, 278], "manual_se": [18, 57, 61, 65, 68, 72, 73, 80, 84, 85, 86, 87, 96, 108, 109, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 215, 217, 226, 227, 231, 246, 255, 258, 264, 266, 280, 298, 301, 306, 310, 312, 325, 327, 328, 330, 331, 339, 344, 347, 348, 349, 351, 352, 356, 363, 370, 376, 378, 380, 381, 384, 622, 626, 628, 633, 634, 635, 639, 640], "autoresettinggymenv": [18, 217], "_step": [18, 21, 22, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 236, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 382], "td_reset": [18, 217], "exclud": [18, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 84, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 195, 196, 212, 217, 221, 234, 329, 337, 350, 364, 367, 379, 633, 634, 637], "r": [18, 20, 23, 86, 87, 89, 123, 172, 175, 176, 190, 193, 197, 214, 215, 217, 224, 226, 227, 246, 260, 267, 270, 279, 280, 287, 325, 327, 328, 330, 331, 344, 367, 376, 378, 380, 381, 384, 390, 590, 619, 635, 640], "break_when_any_don": [18, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 217, 270, 287, 340, 634], "squeez": [18, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 217, 218, 221, 226, 261, 264, 288, 618, 622, 635, 637], "creation": [18, 19, 150, 158, 196, 332, 379, 471, 566, 585, 640], "imposs": [18, 20, 68, 72, 73, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 348, 350, 364, 367, 369], "forecast": 18, "awar": [18, 26, 60, 71, 88, 90, 95, 96, 97, 98, 110, 112, 116, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 271, 302, 304, 324, 382, 619, 621], "detect": [18, 20, 85, 87, 89, 174, 178, 365, 374, 375, 377, 379, 383, 400, 576, 590, 592], "return_contigu": [18, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 632], "tensordictbas": [18, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 114, 120, 123, 126, 128, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 212, 213, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 233, 234, 235, 236, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 280, 286, 298, 301, 302, 304, 312, 314, 325, 326, 327, 328, 330, 331, 332, 337, 340, 343, 344, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 414, 563, 564, 566, 567, 569, 570, 572, 573, 574, 576, 577, 579, 585, 618, 633, 635], "envwithdynamicspec": 18, "max_count": 18, "bool": [18, 19, 22, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 94, 95, 96, 97, 98, 101, 102, 104, 106, 107, 108, 109, 110, 115, 116, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 213, 214, 215, 217, 218, 221, 222, 226, 227, 229, 231, 232, 233, 234, 236, 239, 241, 243, 244, 245, 246, 248, 250, 252, 253, 255, 257, 258, 259, 262, 263, 265, 268, 269, 270, 272, 273, 274, 275, 277, 279, 280, 282, 286, 287, 288, 290, 291, 297, 298, 302, 303, 304, 305, 306, 313, 314, 319, 320, 321, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 339, 340, 341, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 399, 400, 403, 406, 407, 408, 410, 411, 414, 418, 419, 423, 424, 425, 426, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 475, 476, 501, 503, 504, 514, 520, 525, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 562, 563, 564, 566, 567, 569, 570, 572, 574, 576, 577, 578, 579, 580, 581, 583, 585, 590, 619, 620, 622, 630, 631, 635, 639, 640], "full": [18, 19, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 188, 190, 195, 196, 197, 298, 302, 304, 325, 327, 328, 330, 331, 332, 337, 344, 367, 375, 376, 377, 378, 379, 380, 381, 384, 404, 590, 611, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "_set_se": [18, 215, 218, 229, 232, 252, 635], "int": [18, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 94, 95, 96, 97, 98, 101, 102, 103, 104, 106, 108, 109, 110, 114, 115, 116, 118, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 142, 143, 144, 145, 146, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 205, 206, 214, 216, 217, 218, 220, 221, 222, 223, 225, 228, 231, 236, 237, 239, 243, 244, 245, 246, 248, 250, 251, 254, 261, 262, 263, 266, 269, 270, 272, 274, 275, 277, 286, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 301, 303, 305, 306, 308, 309, 311, 312, 314, 315, 316, 319, 320, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341, 343, 344, 348, 349, 350, 357, 359, 360, 364, 365, 366, 367, 368, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 391, 392, 394, 397, 399, 400, 404, 405, 406, 408, 410, 414, 417, 418, 419, 423, 424, 425, 426, 427, 429, 432, 433, 436, 437, 438, 441, 442, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 461, 462, 463, 470, 471, 473, 475, 476, 478, 479, 480, 481, 486, 489, 495, 501, 502, 503, 505, 508, 511, 518, 519, 520, 523, 526, 527, 530, 543, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 577, 578, 579, 580, 585, 622, 635, 637], "lazystackedtensordict": [18, 52, 71, 78, 86, 87, 96, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 632], "field": [18, 19, 22, 32, 34, 35, 36, 38, 52, 53, 56, 60, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 101, 108, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 218, 229, 232, 233, 234, 239, 248, 252, 253, 255, 259, 262, 263, 265, 270, 272, 273, 283, 284, 285, 287, 296, 297, 298, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 346, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 471, 552, 589, 590, 619, 631, 635], "float32": [18, 21, 34, 35, 38, 58, 60, 65, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 95, 96, 97, 101, 102, 108, 116, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 144, 147, 148, 149, 150, 151, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 206, 212, 214, 218, 229, 232, 233, 234, 239, 242, 246, 248, 252, 253, 255, 259, 262, 263, 265, 268, 273, 283, 284, 285, 287, 296, 297, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 346, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 487, 630, 635], "is_shar": [18, 22, 34, 35, 38, 52, 56, 60, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 95, 96, 97, 101, 108, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 185, 212, 214, 218, 229, 232, 233, 234, 239, 248, 252, 253, 255, 259, 262, 263, 265, 273, 279, 283, 284, 285, 287, 296, 297, 298, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 346, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 635], "exclusive_field": [18, 52, 78, 86, 87, 96, 120, 172, 175, 176, 185, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "stack_dim": [18, 52, 78, 86, 87, 96, 120, 172, 175, 176, 185, 205, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 424], "absenc": [18, 22], "dramat": 18, "carefulli": [18, 183, 633, 634, 640], "against": [18, 24, 26, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 297, 298, 313, 314, 326, 332, 337, 339, 341, 343, 344, 349, 351, 363, 368, 370, 371, 372, 375, 377, 379, 382, 383, 620, 633, 634], "plain": [18, 27, 349, 351, 357, 363, 368, 370, 371, 372, 386, 387, 388, 623], "deseri": 18, "larg": [18, 23, 59, 86, 87, 101, 102, 108, 109, 176, 229, 232, 275, 324, 325, 327, 328, 330, 331, 332, 348, 350, 364, 367, 369, 376, 378, 379, 380, 381, 384, 566, 619, 620, 631, 633, 634, 637], "expens": [18, 20, 53, 102, 108, 109, 390, 637], "check_env_spec": [18, 20, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 214, 239, 252, 273, 390, 620, 633, 634, 635], "vari": [18, 19, 129, 131, 132, 152, 153, 155, 163, 251, 622, 634], "absent": [18, 60, 71, 79, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 259, 272], "view": [19, 27, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 83, 84, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 305, 326, 332, 337, 375, 377, 379, 382, 383, 590, 623, 635, 637, 639, 640], "act": [19, 22, 23, 108, 109, 152, 153, 272, 296, 349, 351, 352, 363, 368, 370, 371, 372, 621, 622, 633, 634, 637, 639], "paradigm": [19, 32, 634], "decpodp": 19, "markov": [19, 623, 640], "game": [19, 20, 23, 24, 78, 123, 142, 143, 148, 149, 226, 288, 392, 622, 627], "thank": [19, 170, 195, 196, 383, 618, 622, 623, 639], "carrier": [19, 620, 621, 623, 637], "particular": [19, 79, 80, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 272, 326, 332, 337, 375, 377, 379, 382, 383, 619, 621, 623, 632, 634, 637], "thu": [19, 364, 634], "vma": [19, 163, 164, 390, 457, 633, 634], "robot": [19, 24, 26, 83, 250, 275, 277, 367, 622, 634], "vmasenv": [19, 390, 457, 633, 634], "balanc": [19, 101, 102, 124, 125, 324, 618, 619], "num_env": [19, 32, 35, 36, 38, 50, 120, 129, 133, 146, 163, 164, 171, 172, 175, 181, 390, 444, 448, 611, 633, 634], "n_agent": [19, 163, 164, 390, 633, 634], "td": [19, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 101, 102, 114, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 139, 140, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 175, 176, 178, 179, 180, 183, 185, 186, 190, 212, 215, 218, 220, 222, 226, 227, 229, 230, 231, 232, 240, 241, 242, 244, 246, 255, 258, 262, 265, 268, 272, 279, 283, 284, 285, 287, 296, 297, 301, 312, 313, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 342, 343, 346, 375, 376, 377, 378, 379, 380, 381, 383, 384, 386, 387, 388, 391, 404, 412, 590, 604, 618, 619, 621, 634, 635, 636, 639], "info": [19, 35, 38, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 106, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 142, 143, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 175, 178, 179, 180, 190, 239, 273, 275, 278, 281, 399, 569, 570, 571, 572, 623, 628, 630, 633, 634, 637, 639], "ground_rew": 19, "pos_rew": 19, "16": [19, 20, 32, 35, 36, 38, 52, 84, 88, 102, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 324, 326, 329, 332, 337, 375, 377, 379, 382, 383, 611, 621, 637], "style": [19, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 187, 197, 203, 375, 419], "info_spec": [19, 150], "agent_i_action_spec": 19, "agent_i_reward_spec": 19, "agent_i_observation_spec": 19, "prefix": [19, 56, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 267, 270, 272, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 351, 365, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 391, 400, 414, 418, 471, 621, 625, 630, 640], "exactli": [19, 88, 120, 123, 126, 130, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 310, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383, 618, 621, 626, 633, 634], "action_kei": [19, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 214, 215, 231, 241, 244, 286, 301, 312, 340, 342, 473, 633, 634], "reward_kei": [19, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 407, 411, 633, 634], "right": [19, 22, 25, 26, 56, 102, 108, 180, 226, 332, 337, 619, 620, 622, 634, 635, 640], "set_kei": [19, 233, 348, 350, 351, 353, 356, 357, 358, 363, 364, 365, 367, 368, 369, 370, 375, 377, 379, 383, 389, 618, 633, 634], "awai": [19, 620, 623, 633, 634, 639], "eas": [19, 633, 634], "access": [19, 21, 26, 27, 30, 32, 34, 35, 36, 38, 52, 53, 65, 80, 81, 82, 88, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 221, 250, 271, 275, 324, 326, 332, 337, 375, 377, 379, 382, 383, 400, 401, 402, 562, 573, 588, 589, 604, 618, 623, 633, 634, 635, 637, 639], "leaf": [19, 21, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 240, 263, 265, 271, 344], "abov": [19, 21, 22, 26, 54, 75, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 271, 303, 320, 321, 326, 332, 337, 375, 377, 379, 382, 383, 590, 618, 620, 622, 623, 624, 633, 634, 635, 640], "would": [19, 21, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 302, 304, 305, 326, 332, 337, 344, 375, 377, 379, 382, 383, 619, 620, 621, 623, 625, 626, 635, 637, 639, 640], "ey": 20, "report": [20, 121, 122, 136, 137, 418, 627], "foremost": 20, "callback": [20, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 634], "callabl": [20, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 120, 123, 126, 127, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 211, 216, 218, 225, 226, 227, 233, 239, 243, 265, 272, 273, 282, 288, 305, 326, 332, 337, 344, 365, 375, 377, 379, 382, 383, 390, 417, 418, 419, 553, 554, 560, 561, 562, 577, 619, 637], "upon": [20, 27, 41, 633, 635], "ad": [20, 23, 32, 34, 35, 36, 38, 52, 56, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 258, 270, 272, 312, 325, 326, 327, 328, 330, 331, 332, 337, 348, 350, 351, 353, 358, 364, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 590, 619, 621, 622, 624, 630, 633, 637, 639, 640], "save": [20, 27, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 98, 100, 110, 111, 112, 116, 117, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 278, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 391, 392, 394, 399, 414, 418, 419, 471, 611, 612, 622, 626, 627, 628, 633, 634], "disk": [20, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 91, 95, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 414, 618, 619, 621, 622, 626, 627, 633, 637], "tensordictrecord": 20, "imag": [20, 23, 26, 30, 83, 86, 90, 221, 223, 226, 228, 250, 268, 277, 305, 390, 392, 618, 619, 622, 623, 627, 634, 636, 640], "pixel": [20, 21, 22, 26, 60, 69, 85, 123, 124, 125, 129, 131, 132, 155, 221, 223, 228, 233, 236, 238, 246, 248, 250, 254, 268, 275, 277, 290, 308, 309, 390, 392, 618, 619, 621, 622, 627, 633, 636, 637, 639, 640], "atari": [20, 22, 23, 78, 79, 80, 81, 83, 84, 85, 90, 221, 288, 392, 622, 627, 640], "videorecord": [20, 30, 390, 620, 627, 628, 633], "csvlogger": [20, 30, 390, 392, 458, 612, 619, 627, 628, 633], "wandblogg": [20, 461, 612, 627], "tensorboardlogg": [20, 460, 558, 612, 627], "tag": [20, 26, 30, 174, 175, 177, 187, 200, 203, 390, 392, 394, 397, 562, 590, 627, 628, 630, 633], "mp4": [20, 390, 392, 394, 628, 633], "video_format": [20, 390, 392, 394, 458, 628, 633], "whc": 20, "cwh": 20, "dummi": [20, 160, 185, 390, 618, 622, 626, 640], "exp": [20, 307], "al": [20, 32, 34, 35, 36, 38, 52, 129, 131, 233, 248, 491, 622, 640], "pong": [20, 32, 34, 35, 36, 38, 52, 78, 146, 248, 622, 640], "v5": [20, 32, 34, 35, 36, 38, 52, 129, 131, 146, 233, 248, 622, 640], "append_transform": [20, 21, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 207, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 280, 287, 302, 304, 382, 390, 590, 611, 618, 621, 630, 633, 635, 637, 639, 640], "grow": [20, 96], "tediou": [20, 623], "workspac": [20, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 239], "assum": [20, 22, 25, 34, 35, 36, 37, 38, 39, 46, 49, 50, 54, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 72, 73, 74, 75, 76, 77, 79, 81, 83, 84, 85, 92, 93, 100, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 206, 220, 223, 228, 236, 250, 251, 258, 265, 272, 275, 277, 287, 302, 304, 347, 353, 357, 358, 370, 382, 392, 563, 618, 620, 632, 635], "pixelrendertransform": [20, 633], "stream": [20, 83, 90], "alik": [20, 390], "envcreat": [20, 34, 50, 51, 150, 158, 270, 280, 390, 558, 559, 562, 618, 619, 639, 640], "render_mod": [20, 390, 444, 448, 635], "rgb_arrai": [20, 390, 633, 634, 635], "uncom": [20, 627], "line": [20, 26, 78, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 619, 627, 633, 634], "__name__": [20, 32, 34, 35, 36, 38, 51, 52, 66, 127, 280, 390, 619, 639], "__main__": [20, 32, 34, 35, 36, 38, 51, 52, 66, 127, 280, 390, 639], "comment": [20, 619, 639], "pixels_record": [20, 390], "close": [20, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 52, 66, 88, 120, 130, 145, 173, 174, 177, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 241, 271, 280, 348, 350, 364, 367, 379, 382, 390, 565, 618, 619, 623, 630, 632, 633, 635, 639], "purpos": [20, 21, 22, 26, 30, 35, 36, 38, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 197, 221, 325, 327, 328, 330, 331, 348, 350, 362, 364, 367, 369, 376, 378, 379, 380, 381, 384, 558, 611, 618, 620, 621, 622, 625, 627, 633, 634, 636, 640], "raw": [21, 23, 90, 199, 239, 269, 273, 303, 320, 321, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585, 619, 622, 626, 635], "torchvis": [21, 30, 250, 277, 394, 633, 639, 640], "from_pixel": [21, 22, 30, 121, 122, 124, 125, 129, 131, 132, 136, 137, 155, 221, 254, 390, 392, 441, 442, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 618, 619, 621, 623, 627, 628, 636, 637, 639, 640], "totensorimag": [21, 69, 85, 221, 254, 525, 619, 621, 622, 637, 639, 640], "resiz": [21, 69, 85, 221, 511, 619, 621, 622, 623, 637, 640], "64": [21, 69, 78, 83, 86, 87, 176, 221, 254, 290, 291, 300, 302, 304, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 462, 597, 611, 618, 619, 620, 621, 622, 624, 628, 632, 635, 637, 639, 640], "appar": [21, 406], "bring": [21, 620, 623, 640], "speedup": [21, 22, 27, 633, 640], "kind": [21, 68, 74, 625, 633, 637], "great": [21, 22, 26, 27, 622, 631, 633, 639], "consult": 21, "interest": [21, 22, 341, 344, 619, 620, 623, 634, 635, 640], "resize_par": 21, "inv": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 224, 231, 234, 239, 248, 255, 260, 262, 267, 271, 274, 382, 635], "revers": 21, "chain": [21, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 138, 170, 176, 178, 179, 194, 195, 225, 231, 288, 317, 325, 327, 328, 330, 331, 346, 376, 378, 380, 381, 384, 590, 640], "taken": [21, 53, 57, 59, 61, 62, 64, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 214, 254, 306, 618, 620, 621, 624, 633, 634, 635], "in_keys_inv": [21, 194, 199, 207, 224, 229, 230, 232, 239, 246, 247, 248, 252, 253, 255, 260, 269, 271, 273, 274, 482, 487, 488, 490, 618, 632, 635, 640], "doubletofloat": [21, 490, 618, 620, 632], "float64": [21, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 124, 125, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 225, 229, 232, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "paragraph": [21, 22], "in_": 21, "out_": 21, "perspect": [21, 183, 298, 358, 620, 622], "inner": [21, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 231, 272, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585, 612, 619, 620, 634, 640], "outer": [21, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272, 612, 618, 619, 640], "ob": [21, 23, 27, 56, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 101, 108, 109, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 212, 215, 217, 226, 229, 230, 232, 246, 260, 262, 268, 290, 291, 292, 293, 313, 322, 349, 351, 352, 357, 363, 368, 370, 371, 372, 385, 386, 387, 388, 619, 622, 632, 633, 635, 637, 639, 640], "obs_standard": 21, "similarli": [21, 50, 88, 107, 112, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 244, 326, 332, 337, 345, 346, 356, 363, 375, 377, 379, 382, 383, 385, 590, 640], "seen": [21, 42, 44, 47, 50, 60, 71, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 230, 618, 619, 621, 625, 633, 634, 637], "out_keys_inv": [21, 194, 199, 207, 224, 229, 230, 232, 239, 246, 247, 248, 252, 253, 260, 262, 269, 271, 273, 274, 482, 487, 488, 490, 635], "produc": [21, 34, 60, 71, 108, 214, 217, 218, 283, 285, 288, 305, 310, 344, 385, 392, 620, 621, 622, 623, 624, 626, 637, 640], "illustr": [21, 618, 619, 624, 637], "renametransform": [21, 69, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 510], "renam": [21, 60, 69, 71, 86, 87, 171, 176, 212, 253, 255, 272, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 618], "schemat": 21, "outermost": 21, "innermost": 21, "similar": [21, 63, 68, 83, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 276, 277, 279, 280, 283, 285, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 344, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 565, 581, 618, 619, 620, 621, 622, 624, 625, 626, 627, 635, 637, 639, 640], "transform_action_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 230, 243, 246, 271, 273, 274, 382], "pseudocod": 21, "could": [21, 22, 23, 25, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 344, 375, 377, 379, 382, 383, 611, 619, 620, 627, 633, 634, 636, 640], "spec_from_random_valu": 21, "_apply_transform": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 382, 635, 640], "rand": [21, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 96, 121, 122, 136, 137, 144, 148, 149, 161, 162, 215, 218, 229, 232, 252, 262, 341, 342, 348, 349, 351, 352, 353, 355, 356, 357, 363, 365, 367, 368, 370, 371, 372, 375, 377, 379, 383, 635, 639, 640], "did": [21, 68, 278, 619, 620, 626, 637, 640], "_inv_apply_transform": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 271, 382, 635, 640], "actiondiscret": [21, 473], "rand_act": [21, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 218, 272, 623], "action_discret": 21, "counterpart": [21, 221], "obtain": [21, 26, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 196, 220, 250, 264, 277, 287, 410, 618, 620, 623, 624, 625, 633, 634], "addonetoob": 21, "There": [21, 29, 69, 86, 87, 172, 176, 271, 302, 304, 325, 327, 328, 330, 331, 348, 367, 376, 378, 380, 381, 384, 620, 621, 622, 624, 626, 633, 634, 635, 637, 639, 640], "Is": [21, 271], "ident": [21, 34, 35, 38, 68, 69, 72, 73, 86, 87, 95, 108, 120, 123, 126, 129, 130, 131, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 233, 262, 271, 280, 325, 327, 328, 330, 331, 349, 351, 363, 368, 370, 371, 372, 376, 378, 380, 381, 384, 385, 386, 387, 388, 560, 561, 619, 623, 633, 634], "rewrit": [21, 271], "otherwis": [21, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 109, 120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 222, 226, 227, 231, 239, 246, 264, 265, 266, 270, 271, 272, 279, 282, 297, 303, 313, 320, 321, 325, 326, 327, 328, 330, 331, 332, 337, 344, 347, 349, 351, 360, 365, 366, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 408, 410, 564, 565, 566, 567, 569, 570, 571, 572, 574, 577, 579, 581, 585, 618, 619, 620, 621, 630, 635, 640], "_call": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 231, 233, 234, 235, 236, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 382, 630, 635], "_inv_cal": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 271, 382], "overwrit": [21, 271], "till": [21, 271, 278], "encapsul": [21, 271, 623, 624, 625], "don": [21, 22, 23, 25, 26, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 170, 197, 221, 271, 306, 324, 611, 619, 620, 622, 626, 637, 639, 640], "forget": [21, 271], "transform_output_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 273, 280, 382], "transform_input_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 225, 229, 230, 231, 244, 248, 252, 253, 258, 262, 263, 264, 265, 269, 271, 273, 276, 382], "transform_observation_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 222, 223, 224, 225, 228, 229, 230, 233, 234, 236, 238, 240, 241, 243, 244, 246, 248, 252, 253, 254, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 278, 279, 280, 382, 635], "transform_state_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 230, 243, 246, 271, 273, 274, 382], "transform_reward_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 219, 224, 225, 229, 230, 234, 241, 242, 243, 244, 252, 253, 256, 257, 258, 259, 260, 262, 263, 269, 271, 273, 274, 280, 382, 590, 630], "undo": [21, 183], "addonetoact": 21, "subtract": [21, 188, 264], "properti": [21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 270, 271, 272, 279, 280, 295, 303, 306, 310, 319, 320, 321, 325, 326, 327, 328, 329, 330, 331, 332, 337, 340, 348, 351, 365, 367, 369, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 564, 566, 567, 569, 570, 572, 573, 574, 577, 579, 585, 624, 626, 635, 637], "manipul": [21, 23, 27, 124, 125, 250, 271, 275], "third_transform": 21, "assert": [21, 22, 25, 34, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 114, 120, 123, 126, 130, 133, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 183, 206, 211, 214, 218, 221, 224, 229, 232, 241, 253, 260, 272, 279, 287, 307, 325, 327, 328, 330, 331, 376, 378, 380, 381, 383, 384, 385, 386, 387, 388, 403, 404, 412, 462, 463, 466, 467, 468, 611, 626, 632, 637, 640], "lead": [21, 23, 27, 29, 52, 56, 60, 65, 68, 71, 79, 101, 107, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 265, 282, 303, 320, 321, 618, 621, 622, 633, 634, 635, 637, 639], "unexpect": [21, 34, 35, 36, 38, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 640], "behviour": 21, "rais": [21, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 81, 83, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 165, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 221, 235, 245, 255, 264, 265, 266, 270, 272, 279, 286, 301, 312, 325, 326, 327, 328, 330, 331, 332, 333, 337, 351, 365, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 401, 402, 403, 564, 566, 569, 570, 571, 572, 573, 574, 575, 577, 579, 585, 611, 618, 620, 633, 634, 637], "catfram": [21, 340, 479, 619], "hold": [21, 22, 271, 382, 566, 635, 637], "notic": [21, 114, 221, 620, 628, 635], "parenthood": 21, "henc": [21, 53, 65, 213, 251, 618, 620, 633, 634, 635], "transform2": 21, "transform3": 21, "last_two": 21, "isinst": [21, 150, 158, 272, 390, 403, 467, 635], "discret": [21, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 129, 130, 131, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 214, 231, 239, 310, 355, 356, 357, 358, 619, 624, 634], "might": [21, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 396, 589, 618, 623, 640], "throughout": [21, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 620, 633, 640], "action_mask": [21, 123, 136, 137, 152, 153, 156, 157, 215, 474, 631], "unavail": [21, 152, 153], "probabl": [21, 23, 27, 69, 101, 102, 106, 188, 189, 195, 196, 287, 295, 301, 302, 304, 305, 306, 310, 317, 320, 321, 326, 329, 332, 337, 341, 344, 351, 357, 367, 370, 375, 377, 379, 383, 619, 622, 624, 639], "probabilistictensordictmodul": [21, 241, 344, 345, 639], "tensordictsequenti": [21, 287, 297, 301, 302, 304, 312, 326, 332, 337, 340, 345, 346, 375, 377, 379, 383, 618, 619, 621, 622, 624, 628, 632, 633, 636, 639], "maskedcategor": [21, 597], "in_feat": 21, "out_feat": 21, "logit": [21, 296, 298, 306, 310, 326, 329, 332, 337, 341, 356, 357, 590], "dist": [21, 29, 306, 310, 344, 624], "distribution_class": [21, 241, 283, 284, 285, 341, 344, 346, 348, 349, 351, 356, 357, 363, 367, 368, 369, 370, 597, 618, 620, 624, 633, 634, 639], "wrap": [21, 24, 32, 34, 35, 36, 38, 42, 44, 47, 50, 81, 88, 120, 121, 122, 123, 126, 130, 131, 135, 136, 137, 138, 143, 146, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 162, 164, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 227, 243, 270, 272, 282, 283, 284, 285, 302, 304, 313, 323, 326, 329, 332, 337, 340, 344, 365, 375, 377, 379, 382, 383, 590, 618, 619, 620, 621, 625, 628, 630, 633, 634, 640], "actionmask": [21, 123, 474], "know": [21, 22, 23, 28, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 68, 72, 73, 129, 131, 286, 365, 368, 375, 377, 379, 383, 408, 618, 619, 620, 621, 622, 623, 624, 625, 626, 633, 634, 637], "your_base_env": 21, "mask_kei": [21, 56, 215, 251, 326, 332, 337, 474], "intens": [22, 27], "gym3": 22, "envpool": [22, 145, 146, 450], "scale": [22, 23, 79, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 177, 178, 179, 180, 221, 241, 246, 257, 264, 268, 279, 280, 283, 284, 285, 299, 303, 307, 315, 316, 320, 321, 341, 344, 346, 348, 349, 351, 363, 367, 368, 369, 370, 411, 504, 514, 552, 562, 597, 618, 619, 620, 621, 624, 634, 639], "varieti": [22, 30], "serialenv": [22, 120, 123, 126, 130, 138, 150, 151, 154, 159, 160, 170, 171, 172, 175, 178, 179, 180, 265, 280, 287, 340, 639, 640], "Of": [22, 26, 589, 635, 640], "cours": [22, 23, 589, 635, 640], "saniti": [22, 26, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 620], "9": [22, 26, 56, 65, 68, 72, 84, 85, 86, 87, 102, 109, 114, 124, 125, 141, 152, 153, 160, 176, 214, 217, 226, 227, 264, 267, 272, 279, 280, 306, 325, 327, 328, 330, 331, 332, 337, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 383, 384, 403, 418, 538, 540, 541, 542, 544, 545, 546, 550, 618, 619, 633, 634], "81": [22, 86, 87, 108, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "c": [22, 25, 26, 32, 34, 35, 36, 38, 52, 60, 68, 72, 73, 82, 86, 87, 96, 176, 246, 268, 273, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 383, 384, 619, 637], "d": [22, 60, 65, 68, 71, 72, 73, 80, 82, 84, 85, 101, 102, 326, 332, 337, 341, 344, 375, 377, 379, 383, 639], "forc": [22, 25, 26, 32, 35, 36, 38, 42, 44, 47, 50, 78, 80, 81, 83, 84, 85, 151, 332, 619, 633, 634, 635], "launch": [22, 32, 35, 36, 38, 42, 44, 47, 51, 78, 80, 150, 158, 190, 324, 333], "bottleneck": [22, 27, 102, 108, 109], "precis": [22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 212, 229, 232, 618, 620], "misspecifi": 22, "caus": [22, 26, 27, 34, 35, 36, 38, 95, 97, 101, 102, 116, 120, 123, 126, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 251, 379, 640], "breakag": 22, "mismatch": [22, 350, 367, 379, 619], "subprocess": [22, 32, 35, 36, 38, 127, 150, 158], "multithreadedenv": [22, 450], "underneath": 22, "cover": [22, 129, 131, 589, 620, 623, 626, 627, 635, 639], "classic": [22, 135, 144, 153, 619], "benchmark_batched_env": 22, "distinguish": [22, 68, 72, 73, 142, 143, 163, 164], "mere": [22, 32, 622], "element": [22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 56, 57, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 95, 96, 97, 98, 101, 102, 108, 109, 114, 116, 120, 123, 126, 130, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 185, 214, 221, 226, 227, 251, 260, 264, 265, 280, 286, 288, 297, 322, 325, 327, 328, 330, 331, 339, 340, 343, 344, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 404, 618, 620, 624, 626, 630, 637, 640], "batch_lock": [22, 120, 123, 126, 128, 130, 138, 150, 154, 158, 159, 170, 171, 172, 175, 178, 179, 180, 218, 265, 272, 635], "contrast": [22, 637], "braxenv": [22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 253, 441, 623], "jumanjienv": [22, 447], "straightforward": [22, 40, 618, 619, 623, 624, 625, 626, 637], "merg": [22, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 635], "deal": [22, 65, 66, 68, 69, 365, 375, 377, 379, 383, 618, 620, 634, 637], "silent": [22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 326, 338, 340, 347], "temporari": [22, 95, 97, 611, 618], "arm": 22, "unbatch": 22, "captur": [22, 190, 197, 286, 301, 312, 541, 590, 622], "content": [22, 27, 34, 60, 65, 68, 71, 72, 73, 86, 87, 89, 107, 108, 109, 120, 123, 126, 129, 130, 131, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 174, 175, 176, 178, 179, 180, 184, 190, 195, 196, 252, 288, 305, 325, 327, 328, 330, 331, 332, 337, 341, 365, 375, 376, 377, 378, 379, 380, 381, 383, 384, 590, 620, 630, 631, 635, 639], "found": [22, 25, 26, 29, 32, 34, 35, 36, 38, 50, 56, 60, 71, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 213, 215, 221, 242, 255, 258, 266, 279, 280, 301, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 364, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 401, 592, 611, 618, 619, 621, 622, 623, 625, 627, 630, 635, 637, 639], "essenti": [22, 33, 42, 43, 44, 45, 47, 48, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 590, 619, 623, 633, 635, 637], "break_when_all_don": [22, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "conditionalskip": [22, 485], "programmat": 22, "pretti": [22, 618, 623, 627, 637], "likewis": 22, "te": 22, "dive": 22, "privat": [22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 278, 635, 640], "distinct": [22, 65, 66, 68, 69, 86, 87, 176, 218, 221, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 625, 632], "total": [22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 57, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 109, 114, 172, 176, 183, 226, 325, 327, 328, 330, 331, 335, 336, 350, 364, 367, 376, 378, 379, 380, 381, 384, 404, 406, 408, 414, 416, 418, 419, 471, 551, 552, 578, 604, 617, 618, 619, 620, 621, 625, 633, 634, 636, 637, 638, 639], "accord": [22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 69, 71, 86, 87, 106, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 175, 176, 178, 179, 180, 246, 257, 303, 315, 317, 320, 321, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 624, 625, 633, 635, 637], "nevertheless": [22, 620, 623, 637], "wherev": 22, "expos": [22, 155, 229, 232, 345, 350, 367, 619], "lost": [22, 27, 278], "face": [22, 24, 27, 28, 329, 332, 623, 631, 640], "word": [22, 30, 78, 79, 81, 83, 84, 85, 365, 375, 377, 379, 383, 618, 626, 635, 640], "preliminari": 22, "warranti": 22, "long": [22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 95, 102, 148, 149, 231, 270, 324, 356, 379, 621, 622, 626, 637], "assumpt": [22, 74, 635, 637], "preclud": 22, "presenc": [22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 326, 332, 337, 375, 377, 379, 383, 625], "annihil": 22, "known": [22, 24, 26, 27, 130, 180, 265, 618, 619, 623], "supersed": [22, 56], "pettingzoowrapp": 22, "associ": [22, 60, 66, 71, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 271, 315, 325, 326, 327, 328, 329, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 401, 562, 564, 570, 572, 618, 637], "__not__": [22, 341, 349, 351, 363, 368, 370, 371, 372], "constrain": [22, 241, 302, 304, 367, 640], "li": 22, "fact": [22, 26, 27, 590, 618, 620, 623, 633, 634, 635, 636, 637, 640], "predict": [22, 296, 299, 323, 348, 350, 355, 358, 360, 361, 364, 367, 369, 379, 618, 619, 625], "meaning": [22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 177, 416], "perfectli": [22, 618, 622, 635], "meaningless": 22, "discard": [22, 79, 81, 130, 212, 275, 391, 637, 640], "val": [22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 171, 280, 403, 625, 639], "agent0": [22, 367, 622], "agent1": [22, 367], "elimin": [22, 623], "500": [22, 618, 619], "uint8": [22, 60, 78, 83, 86, 87, 124, 125, 142, 143, 176, 233, 239, 248, 268, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 619, 637], "significantli": [22, 33, 42, 43, 44, 45, 47, 48, 90, 108, 109, 221, 350, 367, 379, 566, 618, 619, 625, 634], "asyncenvpool": [22, 52, 154, 159], "thread": [22, 32, 34, 35, 36, 38, 50, 52, 53, 86, 87, 120, 121, 122, 136, 137, 150, 158, 159, 176, 190, 280, 324, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 564, 566, 567, 569, 570, 572, 574, 577, 579, 580, 585], "pool": [22, 78, 79, 80, 81, 82, 83, 84, 85, 120, 154, 159, 192, 266, 611], "concurr": [22, 120, 324, 329, 416, 611, 633, 634], "contrari": 22, "permit": [22, 224, 236, 262, 274, 348, 350, 364, 367, 369], "job": [22, 26, 42, 44, 47, 51, 68, 69, 72, 73, 637, 639], "famili": [22, 87, 89, 592], "particularli": [22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 68, 69, 72, 73, 86, 87, 90, 176, 191, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 416, 419, 611, 622, 639, 640], "pleas": [22, 41, 81, 88, 120, 123, 126, 129, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 239, 266, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383, 418, 589, 590], "processorasyncenvpool": 22, "threadingasyncenvpool": 22, "functool": [22, 32, 34, 35, 36, 38, 52, 120], "lazi": [22, 70, 71, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 250, 275, 325, 327, 328, 330, 331, 345, 346, 376, 378, 380, 381, 384, 423, 424, 425, 618, 619, 624, 626, 632, 637, 640], "s0": [22, 120], "clamp": [22, 120, 344, 347, 360, 414, 633, 635], "env_index": [22, 120], "async_step_send": [22, 120, 154, 159], "s0_result": [22, 120], "async_step_recv": [22, 120, 154, 159], "reveal": 23, "bug": 23, "curv": 23, "exploit": [23, 624], "cv": 23, "flip": [23, 137], "correspondingli": 23, "prescript": 23, "tune": [23, 241, 383, 590, 633, 634, 636], "coeffici": [23, 188, 195, 241, 350, 357, 364, 367, 370, 379, 383, 634], "bonu": [23, 177, 348, 350, 364, 367, 379, 590], "altern": [23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 59, 86, 87, 145, 170, 176, 197, 226, 270, 294, 306, 324, 325, 327, 328, 330, 331, 351, 376, 378, 380, 381, 384, 390, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585, 611, 618, 620, 622, 633, 634], "reduc": [23, 25, 59, 101, 102, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 192, 212, 221, 227, 264, 280, 320, 383, 521, 566, 619, 633], "downstream": [23, 379, 618], "formul": [23, 633, 634], "gradient": [23, 65, 68, 69, 72, 73, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 243, 272, 303, 310, 320, 321, 326, 332, 337, 344, 348, 350, 351, 352, 356, 357, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 414, 418, 419, 471, 588, 604, 618, 620, 633, 634, 635], "norm": [23, 27, 86, 87, 121, 122, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 407, 414, 418, 419, 471, 618, 619, 620, 633, 634, 635], "easier": [23, 618, 639], "optima": 23, "sens": [23, 86, 87, 176, 185, 221, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 626, 635], "product": [23, 28, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 560, 561, 611, 631], "sum": [23, 35, 36, 38, 50, 62, 64, 86, 87, 114, 121, 122, 124, 125, 129, 131, 132, 136, 137, 145, 146, 155, 176, 177, 220, 242, 258, 306, 320, 325, 327, 328, 330, 331, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 376, 378, 379, 380, 381, 383, 384, 407, 590, 604, 618, 619, 620, 622, 625, 628, 633, 634, 635, 640], "stat": [23, 246, 279, 280, 552, 562, 619, 620], "yield": [23, 34, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 324, 326, 332, 337, 365, 375, 377, 379, 382, 383, 618, 621, 625], "insight": [23, 171, 416, 611, 622], "auxiliari": [23, 625], "credit": 23, "past": [23, 221, 340, 619, 637], "difficult": [23, 150, 627], "spars": [23, 590, 621], "instrument": 23, "greatli": 23, "soccer": 23, "kick": 23, "ball": [23, 172], "likelihood": [23, 618], "score": [23, 177, 332, 367, 590], "undesir": 23, "though": [23, 30, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 305, 332, 611, 620, 633, 634], "unintention": 23, "valuabl": 23, "idiosyncrat": 23, "subtask": 23, "hierarch": 23, "fall": [23, 37, 39, 41, 46, 49, 54, 55, 79, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "curios": 23, "magnitudin": 23, "domin": 23, "smaller": [23, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 356, 363, 620, 634], "addition": [23, 295], "timestep": [23, 79, 255, 633, 634], "realli": 23, "huge": [23, 621], "std": [23, 246, 279, 286, 307, 311, 418, 618, 640], "initi": [23, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 59, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 97, 114, 120, 123, 126, 130, 138, 148, 149, 150, 151, 154, 158, 159, 160, 161, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 220, 239, 246, 250, 265, 272, 275, 280, 281, 282, 286, 301, 312, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 340, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 402, 562, 563, 564, 565, 566, 567, 569, 570, 571, 572, 573, 574, 575, 577, 578, 579, 583, 584, 585, 590, 611, 618, 619, 621, 623, 624, 626, 630, 633, 635, 640], "estim": [23, 78, 102, 108, 109, 170, 171, 172, 175, 178, 185, 233, 241, 283, 284, 285, 290, 320, 348, 349, 350, 351, 352, 353, 355, 357, 358, 359, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375, 377, 379, 383, 385, 386, 387, 388, 389, 599, 604, 619, 620, 624, 625, 633, 634], "encount": [23, 83, 244, 340, 589, 619, 624, 635], "unseen": 23, "extrins": 23, "wrong": [23, 102, 108, 183], "goe": [23, 152, 153, 618, 620, 633, 634, 640], "bonus": 23, "denser": 23, "prior": [23, 316, 317, 360, 634], "freshli": 23, "drop": [23, 107, 109, 212, 280, 324, 350, 367, 379], "meant": [23, 144, 178], "encourag": [23, 150, 183, 367, 419, 618, 619, 637], "measur": [23, 88, 95, 97, 101, 116, 121, 122, 136, 137, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 350, 367, 379, 382, 416, 419, 620, 626], "novelti": 23, "revisit": 23, "diminish": 23, "decreas": [23, 624], "ideal": [23, 170, 226, 246, 379, 631, 635], "distil": 23, "nois": [23, 281, 312, 368, 371, 372, 408, 562, 601, 618, 633], "exploratori": [23, 348, 350, 364, 367, 379], "misalign": 23, "trade": [23, 624], "unavoid": 23, "prioriti": [23, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 95, 96, 97, 98, 101, 102, 110, 112, 116, 351, 352, 353, 355, 356, 357, 358, 363, 368, 370, 371, 372, 618, 619, 637], "schedul": [23, 26, 324, 408, 620, 635], "divers": [23, 150, 158, 332], "bootstrap": [23, 358, 385, 386, 618, 621], "noisi": 23, "unstabl": [23, 101, 102, 303, 320, 321], "inher": [23, 348, 367], "stochast": [23, 241, 299, 308, 316, 349, 351, 354, 356, 357, 362, 363, 366, 368, 370, 419, 597, 598, 620, 624, 634], "enemi": 23, "pomdp": [23, 637], "loos": [23, 344, 583, 619, 620], "nonexist": 23, "architectur": [23, 189, 294, 324, 332, 597, 611, 625, 633, 634, 639], "sequenc": [23, 32, 34, 35, 36, 38, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 74, 75, 76, 77, 83, 86, 87, 94, 104, 106, 112, 115, 118, 119, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 199, 201, 207, 219, 220, 221, 222, 223, 228, 229, 231, 232, 236, 238, 239, 242, 246, 247, 251, 252, 253, 254, 255, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 273, 279, 280, 288, 295, 305, 306, 310, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 345, 346, 354, 375, 376, 377, 378, 379, 380, 381, 383, 384, 391, 392, 408, 409, 410, 412, 414, 590, 618, 620, 621, 622, 632, 633, 634, 640], "lstm": [23, 265, 304, 307, 622], "rel": [23, 69, 265, 295, 319, 618, 619, 633, 634, 637], "tend": 23, "stabl": [23, 28, 29, 101, 102, 147], "compens": 23, "descent": 23, "minimum": [23, 75, 120, 150, 158, 256, 299, 307, 319, 320, 321, 326, 332, 337, 347, 349, 351, 357, 365, 366, 370, 375, 377, 379, 383, 404, 618, 620, 628, 633, 634], "manual": [23, 30, 42, 47, 50, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 130, 131, 180, 191, 418, 618, 621, 637], "deviat": [23, 246, 279, 280, 286, 299, 311, 367, 371, 372, 383, 407, 618, 624, 634], "radic": 23, "stabil": [23, 101, 102, 237, 324, 333, 334, 348, 350, 364, 367, 369, 379], "stage": [23, 618, 635], "never": [23, 32, 35, 36, 38, 52, 58, 75, 101, 102, 267, 626, 639], "solv": [23, 26, 28, 29, 65, 66, 68, 69, 183, 589, 618, 619, 620, 626, 628, 633, 634, 635, 637], "submit": [23, 129, 218, 589, 639], "adequ": [23, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 620, 633, 634], "infeas": 23, "allevi": 23, "prune": [23, 138, 179], "fire": [23, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "certain": [23, 42, 44, 47, 50, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 226, 227, 237, 263, 272, 301, 326, 332, 333, 334, 337, 364, 375, 377, 379, 382, 383, 618, 619, 620, 622, 628, 633, 634, 640], "illeg": 23, "move": [23, 74, 85, 88, 96, 98, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 225, 230, 250, 265, 271, 272, 275, 277, 279, 280, 305, 326, 332, 337, 343, 375, 377, 379, 382, 383, 411, 618, 619, 621, 623, 640], "chess": [23, 123, 148, 149], "grasp": 23, "wherein": 23, "cumul": [23, 258, 264, 620], "q": [23, 28, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 285, 290, 291, 292, 293, 296, 298, 300, 313, 314, 317, 349, 351, 352, 353, 355, 356, 357, 358, 363, 368, 370, 371, 372, 597, 618, 625, 630], "flow": [23, 385, 565, 566, 573, 618, 620, 633, 634, 635, 637], "reparameter": [23, 295, 310], "soft": [23, 370, 419, 633], "clip": [23, 183, 224, 256, 348, 350, 364, 367, 369, 371, 372, 375, 377, 379, 414, 418, 419, 470, 471, 620, 634, 635], "oppos": 23, "incorrect": [23, 108, 183, 367], "thought": [23, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 590], "region": [23, 102, 379], "squash": [23, 338, 621, 639], "tanh": [23, 288, 303, 305, 319, 320, 321, 347, 620, 624, 633, 634, 635, 636], "correct": [23, 86, 87, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 182, 183, 188, 221, 241, 325, 327, 328, 330, 331, 376, 378, 379, 380, 381, 384, 551, 611, 620, 621, 630], "prob": [23, 188, 189, 195, 196, 306, 310, 324, 326, 329, 332, 337, 620, 631, 634], "rememb": [23, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 633], "remap": 23, "origin": [23, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 90, 134, 170, 176, 230, 231, 241, 250, 272, 277, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 344, 349, 351, 363, 365, 367, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 590, 618, 622, 630, 632, 635, 640], "real": [24, 35, 36, 38, 83, 326, 332, 337, 344, 571, 621, 622, 635, 636], "histor": 24, "ceas": 24, "fork": [24, 78, 79, 80, 81, 82, 83, 84, 85, 618, 619, 620, 621, 633, 634, 636, 639], "farama": [24, 81, 139, 140, 152, 153, 620, 635], "bc": [24, 371], "break": [24, 32, 34, 35, 36, 38, 50, 52, 54, 66, 68, 73, 78, 80, 81, 83, 84, 85, 88, 102, 108, 109, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 255, 279, 280, 302, 304, 320, 326, 332, 337, 375, 377, 379, 382, 383, 392, 619, 622, 626, 628, 637, 639], "13": [24, 108, 109, 155, 226, 278, 280, 282], "gymwrapp": [24, 120, 123, 126, 130, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 234, 259, 263, 278, 620, 639], "feel": [24, 589, 628, 639], "free": [24, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 176, 212, 229, 232, 325, 327, 328, 330, 331, 348, 360, 367, 376, 378, 380, 381, 384, 611, 620, 628, 634, 639], "gladli": 24, "conda": [25, 26, 589], "cmake": 25, "14": [25, 78, 79, 80, 81, 82, 83, 84, 85, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 226, 246, 282, 367], "sim": 25, "bullet": 25, "headless": [25, 26, 135, 184, 630], "cluster": [25, 26, 27, 42, 50, 80, 400, 401, 402, 589], "withbullet": 25, "forg": [25, 26], "aihabitat": [25, 132], "y": [25, 26, 68, 86, 87, 147, 176, 300, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 383, 384, 462, 463, 466, 468, 618, 634, 637], "facebookresearch": [25, 80, 132], "subdirectori": 25, "verbos": [25, 52, 53, 88, 177, 324, 333, 382, 628, 630], "magnum_log": 25, "quiet": 25, "habitat_sim_log": 25, "remov": [25, 34, 35, 36, 38, 41, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 252, 261, 272, 325, 326, 327, 328, 330, 331, 332, 337, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 401, 590, 633, 634, 639, 640], "readm": [25, 26, 163, 639], "md": [25, 26], "habitatenv": [25, 445], "_has_habitat": 25, "available_env": [25, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 139, 142, 143, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 175, 178, 179, 180, 640], "startswith": [25, 287, 604, 618, 625], "oserror": 25, "libllvmlit": 25, "ionstal": 25, "pointer": [25, 127, 365, 618], "llvmlite": 25, "var": [25, 26, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 280, 326, 332, 337, 351, 365, 370, 375, 377, 379, 382, 383], "ld_preload": [25, 26], "bind": 25, "deactiv": [25, 26, 121, 122, 297, 349, 351, 357, 363, 365, 368, 370, 371, 372, 386, 387, 388], "importerror": [25, 26, 29, 402, 631], "usr": [25, 26, 29], "x86_64": [25, 26], "linux": [25, 26], "gnu": [25, 26], "libopengl": [25, 26], "undefin": [25, 26, 29, 59, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 351, 365, 370, 375, 377, 379, 382, 383, 622, 637], "symbol": [25, 26, 29], "_glapi_tls_curr": [25, 26], "link": [25, 26, 126, 619, 628], "mujoco_env": [25, 26], "libglvnd": [25, 26], "glx": [25, 26], "cos7": [25, 26], "reinstal": [25, 26], "xvfbwrapper": [25, 26], "sysroot": [25, 26], "lib64": [25, 26], "libgldispatch": [25, 26], "offici": [26, 79, 190, 622], "stand": [26, 124, 125, 150, 158, 632, 635], "joint": [26, 619], "contact": [26, 633], "biomechan": 26, "graphic": 26, "anim": [26, 634], "area": 26, "demand": [26, 566, 627, 640], "fast": [26, 28, 96, 121, 122, 212, 253, 368, 611, 618, 619, 620, 639], "accur": [26, 79, 85, 590, 619, 635, 637], "articul": 26, "acquir": [26, 620], "deepmind": [26, 27, 28, 83, 120, 123, 124, 125, 126, 130, 138, 142, 143, 148, 149, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 233, 620, 623], "whomev": 26, "licenc": 26, "were": [26, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 67, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 150, 158, 239, 350, 367, 566, 581, 590, 592, 620, 633, 637], "incorpor": [26, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 301, 312, 371, 419, 621, 624, 635], "relianc": 26, "obsolet": 26, "pro": [26, 589], "tip": [26, 589], "glfw": [26, 618], "osmesa": 26, "egl": 26, "advic": [26, 83, 640], "sudo": [26, 589], "apt": [26, 634], "libglfw3": 26, "libglew2": 26, "libgl1": 26, "mesa": 26, "libosmesa6": 26, "workflow": [26, 283, 284, 285, 324, 590, 631], "glew": 26, "mesalib": 26, "anaconda": 26, "libgl": 26, "cos6": 26, "menpo": 26, "glfw3": 26, "mujoco_gl": 26, "pyopengl_platform": 26, "mkdir": 26, "earlier": [26, 618, 620, 621, 633, 634, 637], "roboti": 26, "download": [26, 29, 78, 79, 80, 81, 83, 84, 85, 134, 250, 277, 392, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "html": [26, 35, 38, 145, 147, 148, 149, 630], "wget": 26, "mujoco210": 26, "tar": [26, 80], "gz": 26, "xf": 26, "charg": [26, 32, 35, 36, 38, 150, 158], "mjkei": 26, "txt": [26, 383], "mjlib_path": 26, "home": 26, "bin": [26, 190, 298], "libmujoco210": 26, "ld_library_path": 26, "mujoco_py_mujoco_path": 26, "too": [26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 245, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 303, 320, 321, 326, 332, 337, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 619, 624, 627, 635, 637, 640], "mujoco_py_mjkey_path": 26, "reload": 26, "later": [26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 101, 102, 293, 341, 344, 401, 565, 618, 620, 622, 637], "nvidia": [26, 134, 622], "hack": [26, 618], "adatp": 26, "unnot": [26, 251], "mujoco_pi": 26, "cymj": 26, "linuxgpuextensionbuild": 26, "filenam": [26, 86, 87, 93, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 619, 637], "troubleshoot": [26, 350, 364, 367], "gl": 26, "h": [26, 69, 221, 223, 228, 254, 268, 302, 304, 392, 511, 619, 637], "eglshim": 26, "fatal": 26, "No": [26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 54, 57, 59, 62, 64, 177, 400, 563, 565, 567, 568, 573], "directori": [26, 78, 79, 80, 81, 83, 84, 85, 86, 87, 91, 95, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 397, 399, 579, 580, 581, 582, 618, 624, 627, 633], "devel": 26, "ubuntu": [26, 134], "libglew": 26, "dev": 26, "cento": 26, "yum": 26, "glu": 26, "38": 26, "disappear": [26, 619, 621, 632], "libstdc": 26, "6": [26, 32, 34, 35, 36, 38, 52, 53, 56, 60, 68, 71, 78, 84, 85, 101, 102, 109, 124, 125, 130, 150, 156, 157, 172, 180, 214, 217, 226, 227, 246, 248, 264, 270, 280, 287, 288, 290, 291, 292, 295, 300, 305, 308, 319, 322, 340, 341, 619, 622, 639], "glibcxx_3": 26, "29": [26, 108, 109], "compil": [26, 34, 35, 36, 38, 56, 68, 72, 73, 86, 87, 88, 90, 94, 95, 96, 97, 98, 102, 104, 108, 109, 110, 115, 116, 118, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 282, 320, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 423, 424, 425, 426, 430, 432, 433, 437], "libosmesa": 26, "libgcc": 26, "Then": [26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 175, 183, 278, 583, 584, 620, 632], "filenotfounderror": [26, 81], "errno": 26, "patchelf": 26, "fatalerror": 26, "gladloadgl": 26, "mj_env": 26, "912": 26, "glfwerror": 26, "65537": 26, "myscript": 26, "runtimeerror": [26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 59, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 245, 270, 272, 326, 332, 333, 337, 351, 370, 375, 377, 379, 382, 383, 571, 640], "slurm": 26, "mjrendercontext": 26, "pyx": 26, "46": [26, 108, 121, 122], "114": 26, "_setup_opengl_context": 26, "opengl_context": 26, "130": 26, "offscreenopenglcontext": 26, "fail": [26, 32, 34, 35, 36, 38, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 195, 215, 326, 332, 337], "opengl": [26, 633, 634], "global": [26, 68, 69, 72, 73, 88, 89, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 270, 326, 332, 335, 336, 337, 341, 344, 375, 377, 379, 382, 383, 400, 401, 618, 633, 634], "cuda_visible_devic": [26, 585], "slurm_step_gpu": 26, "black": [26, 123, 633], "onscreen": 26, "101": 26, "lgl": 26, "libegl": 26, "x11": [26, 634], "xlib": 26, "libx11": 26, "xorg": 26, "attributeerror": [26, 32, 35, 36, 38, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "nonetyp": 26, "glgeterror": 26, "this_dir": 26, "pwd": 26, "ln": 26, "libglut": 26, "12": [26, 29, 35, 36, 38, 84, 86, 87, 95, 97, 109, 116, 136, 137, 150, 156, 157, 158, 172, 176, 190, 226, 272, 280, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 392, 637], "sketch": 27, "_": [27, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 96, 123, 127, 134, 163, 164, 176, 185, 222, 229, 231, 232, 241, 246, 253, 268, 279, 322, 325, 327, 328, 330, 331, 339, 343, 344, 348, 349, 351, 352, 356, 357, 363, 367, 368, 370, 371, 372, 376, 378, 380, 381, 384, 385, 386, 387, 388, 394, 618, 619, 620, 621, 622, 628, 633, 634, 635, 637, 639], "n_training_step": 27, "datapoint": [27, 637], "onlin": [27, 32, 38, 221, 294, 311, 348, 354, 366, 367, 404, 562, 620, 621, 634, 637], "n_data_per_train": 27, "no_grad": [27, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 243, 326, 332, 337, 375, 377, 379, 382, 383, 385, 386, 387, 388, 620, 621, 622, 634], "loss_fn": [27, 621, 625, 626, 639], "zero_grad": [27, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 618, 620, 621, 622, 625, 628, 633, 634, 635], "backpropag": [27, 121, 122, 136, 137, 150, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 625, 634, 635], "differenti": [27, 121, 122, 241, 351, 371, 385, 386, 387, 388, 537, 538, 539, 541, 547, 548, 549, 621, 624, 625, 633, 634, 635], "pai": [27, 221, 618, 621], "denomin": 27, "artifact": 27, "numer": [27, 68, 101, 102, 130, 180, 279, 297, 298, 303, 313, 314, 320, 321, 324, 333, 334, 339, 341, 343, 344, 411, 620, 637, 640], "misconcept": 27, "freed": 27, "appear": [27, 30, 58, 64, 75, 78, 83, 102, 108, 109, 126, 178, 185, 186, 635, 637], "compuat": 27, "twice": [27, 109], "retain_graph": [27, 121, 122], "discuss": [27, 28, 626, 633, 634], "inplac": [27, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 329, 330, 331, 332, 337, 343, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 564, 566, 567, 569, 570, 572, 574, 576, 577, 579, 581, 583, 585, 618], "accumul": [27, 317], "onto": [27, 64, 86, 87, 176, 189, 195, 206, 230, 286, 297, 298, 307, 312, 313, 314, 325, 327, 328, 330, 331, 339, 341, 343, 344, 376, 378, 380, 381, 384, 385, 621, 635], "submodul": [27, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 265, 302, 304, 326, 332, 337, 365, 375, 377, 379, 382, 383], "grad": [27, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 330, 331, 332, 337, 344, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 618, 620], "whose": [27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "neg": [27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 72, 74, 101, 102, 182, 221, 236, 251, 262, 274, 326, 350, 359, 364, 367, 385, 387, 388, 620, 633, 634, 635], "fit": [27, 246, 265, 282, 324, 618], "jax": [27, 121, 122, 136, 137, 282], "improperli": 27, "underli": [27, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 326, 332, 365, 611, 621, 623, 625, 627, 635], "tedeiou": 27, "amount": [27, 150, 312, 385, 619, 637], "costli": [27, 635], "concaten": [27, 35, 36, 38, 50, 61, 62, 83, 86, 87, 176, 178, 221, 222, 246, 262, 305, 325, 327, 328, 330, 331, 346, 376, 378, 380, 381, 384, 618, 619, 624, 633, 634, 635, 637, 640], "constitut": [27, 619, 634, 635], "profil": 27, "frequent": [27, 611, 637], "techniqu": [27, 150, 158, 619, 622, 626, 637], "program": [27, 356, 363, 622, 640], "functorch": [27, 29], "incl": 27, "suit": [27, 125, 611, 620, 623, 639, 640], "mujoco_instal": 27, "valueerror": [27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 330, 331, 332, 333, 337, 375, 377, 379, 382, 383, 400, 401, 402, 564, 566, 569, 570, 572, 573, 574, 575, 577, 579, 585, 631], "bad": 27, "fds_to_keep": 27, "new_shap": 27, "permut": [27, 107, 248, 268, 622, 639, 640], "idea": [28, 101, 102, 368, 612, 621, 624, 633, 634], "introductori": 28, "intro": [28, 620, 621], "dai": [28, 639], "2022": [28, 29, 639], "spin": [28, 124, 125], "hug": [28, 329, 332, 631], "syllabu": 28, "lectur": 28, "awesom": 28, "curat": 28, "succinct": [28, 624], "summari": [28, 246, 279, 280, 618, 619, 620, 621], "reddit": 28, "reagent": 28, "orient": [28, 85, 640], "baselines3": 28, "tf": 28, "bandit": [28, 147], "tensorflow": [28, 306], "kera": 28, "acm": 28, "dopamin": 28, "prototyp": [28, 418, 419, 622, 628], "salina": 28, "sequenti": [28, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 220, 241, 283, 284, 285, 326, 332, 337, 341, 345, 346, 348, 349, 351, 357, 363, 367, 368, 369, 370, 371, 375, 377, 379, 382, 383, 566, 597, 620, 621, 624, 634, 635, 636, 639, 640], "tianshou": 28, "eleg": 28, "rlpyt": 28, "rllib": 28, "industri": [28, 639], "grade": 28, "cherri": 28, "jaxrl": 28, "space": [28, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 87, 92, 93, 100, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 209, 214, 224, 231, 239, 242, 265, 273, 286, 288, 294, 297, 298, 309, 312, 313, 314, 317, 322, 337, 339, 341, 343, 344, 346, 347, 348, 353, 355, 356, 357, 367, 371, 372, 619, 620, 621, 622, 623, 624, 625, 633, 634, 635, 640], "mbrl": [28, 144], "rlmeta": 28, "light": 28, "elegantrl": 28, "cloud": 28, "mtrl": 28, "baselin": 28, "689": 29, "_torchrl": 29, "_zn8pybind116detail11type_casterin2at6tensoreve4loadens_6handleeb": 29, "colab": [29, 620, 621, 633, 634], "notebook": [29, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "24": [29, 84, 109, 129, 145, 146, 172, 183, 338, 340, 392, 633], "pip3": [29, 618, 620, 621, 633, 634], "extra": [29, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 221, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 399, 620, 621, 637], "url": [29, 86, 132, 186, 630], "org": [29, 35, 38, 65, 80, 81, 83, 85, 101, 102, 121, 122, 124, 125, 132, 136, 137, 142, 143, 145, 146, 147, 155, 163, 164, 221, 250, 275, 289, 290, 291, 292, 293, 294, 298, 299, 300, 306, 308, 309, 312, 315, 316, 317, 348, 349, 353, 354, 355, 356, 358, 359, 360, 361, 362, 363, 366, 367, 369, 370, 371, 385, 587, 629, 636], "whl": 29, "u": [29, 82, 635], "upgrad": 29, "lib_version_her": 29, "heavili": 30, "pyav": 30, "conveni": [30, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 221, 324, 400, 620, 633, 634, 635, 637], "knob": 30, "dispos": 30, "guid": [30, 152, 153, 156, 157, 264, 324, 589, 618, 634, 639], "clarifi": 30, "behind": [30, 259], "adjust": [30, 265, 618, 633, 634, 635], "ultim": [30, 303, 320, 321], "ffmpeg": 30, "whatev": [30, 326, 332, 337, 618], "fed": [30, 634, 637], "feed": [30, 250, 277, 365, 375, 377, 379, 383, 618, 633, 634, 637], "suppos": [30, 150, 408, 640], "snippet": [30, 250, 275, 618], "gave": 30, "extrem": [30, 150, 158, 348, 350, 364, 367, 369, 379], "blurri": [30, 622], "stitch": 30, "my_exp": [30, 627], "pixels_onli": [30, 124, 125, 129, 131, 132, 155, 442, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 618, 619, 627, 628, 639, 640], "my_video": [30, 627], "record_env": [30, 627, 628], "codec": 30, "h264": 30, "constant": [30, 101, 102, 221, 246, 264, 618, 620, 621, 640], "crf": 30, "17": [30, 84, 108, 109, 130, 150, 180, 214, 226], "preset": 30, "allow_non": 31, "unwrap": [31, 233, 272, 403, 491], "seealso": 31, "randompolici": [32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 221, 255, 626, 637], "tensordictmodulebas": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 220, 243, 297, 313, 326, 332, 337, 340, 375, 377, 379, 383, 464, 621], "signatur": [32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 66, 68, 69, 88, 89, 112, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 218, 225, 239, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383, 618, 622, 623, 635], "undergon": [32, 34, 35, 36, 38, 42, 44, 47, 50], "env_obs_kei": [32, 34, 35, 36, 38, 42, 44, 47, 50], "mustn": [32, 34, 35, 36, 38, 42, 44, 47, 50], "policy_factori": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53], "exclus": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 63, 68, 72, 73, 78, 83, 86, 87, 102, 108, 109, 176, 182, 218, 234, 236, 243, 297, 298, 302, 304, 306, 313, 314, 325, 327, 328, 330, 331, 334, 371, 372, 376, 378, 380, 381, 384, 385, 386, 387, 388, 389, 399, 562], "lifespan": [32, 34, 35, 36, 38, 42, 44, 47, 52, 53, 619], "divis": [32, 34, 35, 36, 38, 42, 44, 47, 78, 83, 102, 108, 109, 280, 634], "endless": [32, 34, 35, 36, 38, 42, 44, 47, 185, 590], "env_devic": [32, 34, 35, 36, 38, 42, 44, 47, 50, 619], "sit": [32, 34, 35, 36, 38, 42, 44, 47, 50, 417, 619], "cast": [32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 277, 278, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 343, 350, 364, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 633, 640], "create_env_kwarg": [32, 34, 35, 36, 38, 50, 120, 127, 145, 150, 158, 270, 438, 618, 640], "span": [32, 34, 35, 36, 38, 42, 44, 47, 50, 83, 102, 108, 109, 432, 433], "n_step": [32, 34, 35, 36, 38, 42, 44, 47, 50, 340, 502, 619, 620, 633, 634], "independ": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 80, 150, 158, 186, 236, 244, 265, 274, 324, 348, 367, 400, 583, 611, 618, 619, 621, 634, 637, 639], "ignor": [32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 93, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 231, 234, 259, 268, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 306, 307, 308, 309, 311, 312, 314, 315, 316, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 347, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 565, 573, 578, 580, 630, 631, 637], "mainli": [32, 34, 35, 36, 38, 42, 44, 47, 50, 170, 171, 172, 175, 399, 633, 634, 635], "round": [32, 34, 35, 36, 38, 42, 44, 47, 50, 78, 123, 192, 324, 430, 611], "closest": [32, 34, 35, 36, 38, 42, 44, 47, 50], "postproc": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 255, 619, 637], "post": [32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 81, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 590], "multistep": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 619], "explorationtyp": [32, 34, 35, 36, 38, 42, 44, 47, 50, 341, 365, 408, 618, 619, 620, 621, 624, 633, 639], "boolm": [32, 35, 36, 38], "preemptive_threshold": [32, 35, 36, 38], "ratio": [32, 35, 36, 38, 350, 367, 414, 416, 618, 620], "finish": [32, 34, 35, 36, 38, 50, 52, 130, 180, 255, 571, 640], "earli": [32, 35, 36, 38, 101, 102, 130, 180, 263, 326, 332, 337, 639], "num_thread": [32, 35, 36, 38, 86, 87, 130, 150, 158, 176, 180, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 579, 580], "num_sub_thread": [32, 35, 36, 38, 150, 158], "plu": [32, 35, 36, 38, 150, 158, 590, 635], "harm": [32, 35, 36, 38, 150, 158], "set_trunc": [32, 34, 35, 36, 38, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "add_truncated_kei": [32, 34, 35, 36, 38, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272], "track_policy_vers": [32, 34, 35, 36, 38, 52, 53, 191, 590], "policyvers": [32, 34, 35, 36, 38, 52, 53, 590], "mediat": [32, 34, 35, 36, 38, 52], "timeout": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 150, 184, 190, 192, 193, 197, 324, 326, 332, 337, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 577, 578, 579, 580, 581, 583, 585, 611], "close_env": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 52], "cascade_execut": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "attr_path": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "caller": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 324, 326, 332, 337, 375, 377, 379, 382, 383, 578], "_receiver_schem": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "_set_dist_connection_info": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "connection_info_ref": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "get_cached_weight": [32, 35, 36, 38], "get_model": [32, 34, 35, 36, 38, 52, 53, 564, 566, 569, 570, 572, 577, 579, 585], "value_net": [32, 34, 35, 36, 38, 52, 53, 353, 355, 369, 385, 386, 387, 388, 620, 622, 624, 625, 628], "recogn": [32, 34, 35, 36, 38, 52, 53, 400], "get_policy_vers": [32, 34, 35, 36, 38, 52, 53], "uuid": [32, 34, 35, 36, 38, 52, 53, 191, 395, 619, 640], "disabl": [32, 34, 35, 36, 38, 52, 53, 57, 59, 61, 62, 64, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 303, 321, 326, 332, 337, 375, 377, 379, 382, 383, 390, 418, 567, 618, 633, 634], "getattr_env": [32, 34, 35, 36, 38, 52, 53], "attr": [32, 34, 35, 36, 38, 52, 53], "getattr_polici": [32, 34, 35, 36, 38, 52, 53], "getattr_rb": [32, 34, 35, 36, 38, 52, 53], "increment_vers": [32, 34, 35, 36, 37, 38, 39, 40, 41, 46, 49, 52, 53, 54, 55, 191], "increment": [32, 34, 35, 36, 37, 38, 39, 40, 41, 46, 49, 52, 53, 54, 55, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180, 191, 246, 364, 590], "init_updat": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "load_state_dict": [32, 34, 35, 36, 38, 50, 52, 53, 86, 87, 88, 90, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 416, 618], "ordereddict": [32, 34, 35, 36, 38, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 279, 280, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383], "form": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 302, 304, 317, 326, 332, 337, 344, 348, 350, 364, 367, 375, 377, 379, 382, 383, 414, 419, 624], "worker0": [32, 35, 36, 38], "state_dict0": [32, 35, 36, 38], "worker1": [32, 35, 36, 38, 611], "state_dict1": [32, 35, 36, 38], "policy_vers": [32, 34, 35, 36, 38, 52, 53, 191, 590], "policy_or_weight": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54], "deleg": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 176, 194, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 635], "trained_polici": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "mirror": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "conflict": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 171, 326, 332, 337], "register_scheme_receiv": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "weight_recv_schem": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "weightsyncschem": [32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53], "synchronize_weight": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 565, 566, 572], "hierarchi": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 324], "immedi": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 400, 401, 402, 564, 566, 569, 570, 572, 574, 577, 579, 585, 611, 633, 634], "reset_idx": [32, 35, 36, 38], "abc": [32, 34, 35, 36, 37, 38, 39, 40, 41, 46, 49, 50, 52, 53, 54, 55, 60, 61, 65, 67, 68, 69, 71, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 219, 220, 221, 222, 223, 225, 228, 229, 232, 236, 238, 242, 246, 247, 252, 254, 255, 256, 257, 258, 262, 264, 265, 266, 268, 271, 272, 273, 279, 280, 282, 288, 295, 305, 306, 310, 326, 332, 337, 375, 377, 379, 382, 383, 409, 410, 417, 560, 561], "static_se": [32, 34, 35, 36, 38, 50, 52, 53, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272], "integ": [32, 34, 35, 36, 38, 52, 53, 56, 61, 62, 64, 102, 108, 109, 110, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180, 191, 214, 217, 233, 237, 246, 263, 280, 288, 305, 351, 356, 363, 370, 622, 637], "env_fn": [32, 34, 35, 36, 38, 52, 53, 127, 560, 561], "env_fn_parallel": [32, 34, 35, 36, 38, 52, 53], "300": [32, 34, 35, 36, 38, 52, 53, 108, 109, 292, 293], "out_se": [32, 34, 35, 36, 38, 52, 53, 640], "raise_on_error": [32, 34, 35, 36, 38, 52, 400], "irrevers": [32, 35, 36, 38], "pipe": [32, 34, 35, 36, 38, 52, 150], "tqdm": [32, 34, 35, 36, 38, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 414, 618, 620, 621, 633, 634, 635], "ale_pi": [32, 34, 35, 36, 38, 52, 622], "progress": [32, 34, 35, 36, 38, 52, 53, 324, 406, 407, 408, 414, 416, 418, 419, 471, 619, 621, 640], "bar": [32, 34, 35, 36, 38, 52, 95, 97, 116, 324, 406, 407, 408, 414, 418, 419, 471, 619], "pbar": [32, 34, 35, 36, 38, 52, 78, 79, 80, 81, 82, 83, 84, 85, 618, 620, 621, 633, 634, 635], "100_000": [32, 34, 35, 36, 38, 52, 622, 628], "prec_wc": [32, 34, 35, 36, 38, 52], "wc": [32, 34, 35, 36, 38, 52], "write_count": [32, 34, 35, 36, 38, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 416], "set_descript": [32, 34, 35, 36, 38, 52, 618, 620, 621, 633, 634, 635], "f": [32, 34, 35, 36, 38, 52, 84, 88, 121, 122, 130, 136, 137, 180, 188, 190, 193, 195, 196, 267, 282, 383, 385, 386, 387, 388, 389, 611, 618, 619, 620, 621, 628, 631, 633, 634, 635, 637, 640], "worker_id": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585], "actor_weight": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "critic_weight": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "Will": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 86, 87, 102, 108, 145, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 392, 611], "_get_server_weight": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54], "typeerror": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "weight_updat": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 619], "weightupdaterbas": [32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55], "localweightsupdaterbas": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "remoteweightsupdaterbas": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "implic": [33, 42, 43, 44, 45, 47, 48], "notimplementederror": [33, 42, 43, 44, 45, 47, 48, 618], "env_creat": [34, 127, 618], "interactiontyp": [34, 42, 44, 47, 50, 167, 210, 341, 344, 408], "return_same_td": 34, "interruptor": 34, "use_buff": [34, 35, 36, 38, 150, 158], "extend_buff": [34, 35, 36, 38], "local_init_rb": [34, 35, 36, 38], "trust_polici": [34, 35, 36, 38, 50, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "compile_polici": [34, 35, 36, 38], "cudagraph_polici": [34, 35, 36, 38], "no_cuda_sync": [34, 35, 36, 38, 50], "cautious": [34, 367], "whole": [34, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 341, 351, 370, 375, 377, 379, 382, 383, 404, 618, 620], "_interruptor": 34, "start_collect": 34, "stop_collect": 34, "preeptiv": 34, "trust": [34, 35, 36, 38, 50, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 227, 304, 379], "cudagraphmodul": [34, 35, 36, 38, 50, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "behaviour": [34, 35, 36, 38, 326, 332, 337, 375, 377, 379, 383, 621, 622, 639], "bypass": [34, 35, 36, 38, 81, 624], "isaaclab": [34, 35, 36, 38, 131, 135], "maniskil": [34, 35, 36, 38], "crash": [34, 35, 36, 38, 255], "Not": [34, 54, 61, 68, 121, 122, 136, 270, 302, 304, 332, 579, 581, 585], "env_mak": [34, 35, 38, 50, 66, 120, 558, 640], "2000": [34, 35, 38, 133, 392, 637], "int64": [34, 35, 38, 52, 56, 57, 59, 61, 62, 64, 72, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 101, 108, 120, 123, 126, 130, 138, 141, 142, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 214, 218, 226, 233, 248, 255, 263, 297, 298, 312, 313, 314, 325, 327, 328, 330, 331, 341, 376, 378, 380, 381, 384, 635], "del": [34, 35, 38, 52, 618, 619, 620, 632, 633, 637, 639, 640], "chunk": [34, 52, 53, 88, 624], "policy_state_dict": [34, 52, 53], "env_state_dict": [34, 52, 53], "safe": [35, 38, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 102, 108, 176, 286, 297, 298, 312, 313, 314, 319, 320, 325, 327, 328, 330, 331, 339, 341, 343, 344, 346, 376, 378, 380, 381, 384, 567, 569, 570, 572, 577, 579, 585, 597, 639], "guard": [35, 38], "doc": [35, 38, 132, 135, 136, 137, 147, 155, 186, 399, 619, 633, 634, 637], "depopul": [35, 36, 38], "mutual": [35, 36, 38], "collector_class": [35, 36, 38, 42, 44, 47, 49, 50, 568, 569], "deriv": [35, 36, 38, 42, 44, 47, 50, 86, 87, 176, 295, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 414], "fake": [35, 36, 38, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 618, 619, 622], "multiprocessedweightupdat": [35, 36, 38], "multiprocessweightsyncschem": [35, 36, 38, 565], "get_server_weight": 37, "policy_weight": [37, 39, 40, 46, 49], "all_worker_id": [37, 39, 40, 41, 46, 49, 54, 55], "scope": [37, 39, 40, 41, 46, 49, 54, 55, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 622, 640], "classmethod": [37, 39, 40, 41, 46, 49, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 239, 275, 282, 288, 289, 311, 324, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_polici": [37, 39, 40, 41, 46, 49, 54, 55], "back": [37, 39, 41, 46, 49, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 74, 75, 76, 77, 79, 86, 87, 89, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 199, 269, 278, 297, 298, 313, 314, 325, 327, 328, 330, 331, 339, 341, 343, 344, 376, 378, 380, 381, 384, 580, 620, 622, 633, 634, 635, 637], "post_hook": [37, 39, 40, 41, 46, 49, 54, 55], "push_weight": [37, 39, 40, 41, 46, 49, 54, 55], "noth": [37, 39, 40, 41, 46, 49, 54, 138, 179, 567, 618, 620], "register_collector": [37, 39, 40, 41, 46, 49, 54, 55, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 326, 332, 337], "register_post_hook": [37, 39, 40, 41, 46, 49, 54, 55], "remote_collector": [39, 50, 570, 572], "max_interv": 39, "_maybe_map_weight": [39, 41, 46, 49, 54], "_sync_weights_with_work": [39, 41, 46, 49, 54], "_skip_upd": 39, "interv": [39, 214, 267, 391, 392, 405, 417, 418, 419, 471, 619, 635], "weight_gett": 40, "vanillaweightsend": 40, "update_weight": [40, 46, 49, 324, 417, 563, 582, 584, 585, 590], "piec": [41, 94, 104, 115, 118, 119, 618, 619, 620, 627, 633, 634, 635, 637], "_push_weight": 41, "unchang": [41, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 231, 243, 250, 265, 271, 272, 275, 277, 301, 326, 332, 337, 343, 375, 377, 379, 382, 383, 392, 410, 583, 584, 618, 637], "__call__": [41, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 326, 332, 337, 344, 375, 377, 379, 382, 383], "proxi": [41, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 176, 310, 325, 327, 328, 330, 331, 341, 376, 378, 380, 381, 384], "weakref": 41, "exporationtyp": [42, 44, 47], "_singl": [42, 44, 47, 50, 561], "collector_kwarg": [42, 44, 47, 50], "num_workers_per_collector": [42, 44, 47, 50], "slurm_kwarg": [42, 44, 47], "update_after_each_batch": [42, 44, 47, 50], "max_weight_update_interv": [42, 44, 47, 50], "update_interv": [42, 44], "tcp_port": [42, 44, 47, 51], "string": [42, 44, 47, 63, 88, 89, 96, 120, 123, 126, 130, 138, 142, 148, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 239, 250, 263, 269, 277, 297, 302, 304, 313, 324, 325, 326, 329, 332, 337, 340, 341, 375, 377, 379, 382, 383, 391, 407, 412, 590, 618, 620, 621, 630, 637], "respect": [42, 44, 47, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 219, 225, 229, 232, 244, 250, 251, 260, 265, 271, 272, 275, 277, 316, 322, 326, 332, 337, 343, 348, 350, 364, 367, 369, 375, 377, 379, 382, 383, 385, 387, 388, 409, 620, 621, 633, 634], "subnod": [42, 44, 47, 50], "fashion": [42, 47, 50, 86, 87, 109, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "distributed_back": [42, 44], "ucc": [42, 44, 47], "turn": [42, 44, 47, 50, 53, 60, 71, 86, 87, 88, 123, 137, 150, 160, 170, 176, 226, 238, 271, 274, 278, 297, 325, 327, 328, 330, 331, 376, 378, 379, 380, 381, 384, 385, 390, 408, 590, 618, 619, 621, 624, 635, 636], "submitit_delai": [42, 51], "former": [42, 44, 47, 56, 65, 68, 72, 73, 79, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 338, 340, 347, 618], "whilst": [42, 44, 47, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "latter": [42, 44, 47, 79, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 326, 332, 337, 338, 340, 347, 367, 375, 377, 379, 382, 383, 560, 561], "homonym": [42, 44, 47, 635], "visit": [42, 44, 47, 175], "facebookincub": [42, 44, 47], "tcp": [42, 44, 47, 51], "port": [42, 44, 47, 51, 54, 161, 324, 335, 336, 578, 585], "10003": [42, 44, 47, 51], "distributedweightupdat": 42, "distributedweightsyncschem": [42, 46], "liter": [44, 86, 120, 165, 170, 171, 172, 174, 175, 178, 182, 183, 185, 191, 324, 325, 327, 328, 330, 331, 332, 337, 379, 383, 567, 569, 570, 572, 576, 577, 579, 585], "frequenc": [44, 337, 419, 618], "favor": [46, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 326, 332, 337, 375, 377, 379, 382, 383, 590, 620], "restart": 46, "less": [46, 86, 87, 101, 102, 145, 176, 325, 327, 328, 330, 331, 332, 376, 378, 380, 381, 384, 560, 561, 620, 621, 637, 639], "visible_devic": 47, "tensorpipe_opt": 47, "experiment": [47, 54, 56, 64, 78, 341, 344, 418, 419], "tensorpiperpcbackendopt": 47, "rpcweightupdat": 47, "rpcweightsyncschem": 47, "collector_info": [49, 568, 569], "collector_rref": [49, 568, 569], "_td": [50, 88, 127, 359, 367], "ray_init_config": [50, 53, 66, 400, 402], "remote_config": [50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "num_collector": [50, 560, 561, 618, 619], "use_env_cr": [50, 562], "autodetect": 50, "num_cpu": [50, 53, 66, 192, 193, 194, 243, 329, 400, 401, 402, 611], "num_gpu": [50, 53, 66, 194, 243, 329, 400, 401, 611], "equat": [50, 83, 130, 180, 279, 280, 312, 350, 620, 623, 635], "exce": [50, 637], "indefinit": 50, "rayreplaybuff": [50, 65, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "enfoc": 50, "rayweightupdat": 50, "rayweightsyncschem": 50, "lazili": [50, 86, 87, 96, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 635], "defer": [50, 337], "distributed_collector": [50, 66], "add_collector": 50, "shutdown_rai": [50, 66], "kill": [50, 400], "local_polici": 50, "stop_remote_collector": 50, "num_job": 51, "tcpport": 51, "submitit_main_conf": 51, "slurm_cpus_per_task": 51, "slurm_gpus_per_nod": 51, "slurm_partit": 51, "timeout_min": 51, "submitit_collection_conf": 51, "delai": [51, 371, 625], "jump": [51, 623], "host": [51, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "satellit": 51, "rendezv": 51, "hang": 51, "forev": 51, "default_config": [51, 289, 294, 311], "default_slurm_conf_main": 51, "default_slurm_conf": 51, "randompolicyfrom": 51, "boundedcontinu": [51, 58, 60, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 239, 242, 273], "dialog_turns_per_batch": [52, 53, 590], "yield_only_last_step": [52, 53], "yield_completed_trajectori": [52, 53], "total_dialog_turn": [52, 53, 88], "async_env": [52, 53], "flatten_data": [52, 53], "simplifi": [52, 55, 65, 209, 329, 624, 635, 637], "vllm": [52, 54, 55, 178, 324, 333, 334, 335, 336, 337, 578, 579, 580, 581, 582, 583, 584, 585, 590, 630], "vllmwrapper": [52, 170, 178, 326, 332, 590, 631], "mocking_class": [52, 270], "dummystrdataload": 52, "llmenv": [52, 173, 181, 185], "llm_model": 52, "gpt2": [52, 138, 179, 289, 294, 311, 329, 332, 337, 611], "token": [52, 87, 88, 89, 138, 170, 171, 172, 174, 175, 177, 178, 179, 181, 182, 183, 184, 188, 189, 193, 195, 196, 198, 324, 325, 326, 329, 330, 332, 337, 375, 377, 379, 383, 400, 401, 402, 526, 590, 592, 611, 630, 631], "get_token": 52, "pad_token": [52, 195, 196, 383], "eos_token": [52, 174, 195, 196, 383], "from_dataload": [52, 170, 171, 172, 175, 178, 185], "from_text": [52, 87, 89, 178, 185, 383], "group_repeat": [52, 170, 171, 172, 175, 178, 181, 185], "attention_mask": [52, 178, 332, 337], "22": [52, 83, 90, 108, 109, 278], "text": [52, 81, 86, 87, 88, 89, 138, 170, 171, 172, 174, 175, 177, 178, 179, 187, 189, 190, 193, 195, 196, 203, 312, 324, 325, 326, 329, 331, 332, 333, 337, 382, 383, 590, 592, 620, 630], "nontensorstack": [52, 63, 87, 96, 120, 123, 138, 172, 175, 179, 185, 199, 239, 269, 273], "plsgqejeyd": 52, "text_respons": [52, 172, 175, 177, 178, 180, 183, 193, 383, 590, 630], "ec": 52, "tjbjz3perwhz": 52, "tokens_respons": [52, 178], "as_remot": [52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "cl": [52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 619], "quantiti": [52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "reserv": [52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "alia": [52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 348, 349, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 366, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 389, 420, 421, 570, 572], "get_policy_model": [52, 53], "rayllmcollector": [52, 590], "is_initi": [52, 53, 329, 611], "sync_it": 53, "lightweight": [53, 197, 622, 627], "dialog": [53, 88], "yeild": 53, "idl": [53, 150], "somehwat": 53, "serializ": [53, 329], "v2": [54, 55, 86, 87, 136, 137, 156, 157, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 621], "master_address": [54, 324, 335, 336, 578, 585], "master": [54, 324, 335, 336, 578, 585, 633, 634], "address": [54, 324, 335, 336, 400, 402, 578, 585, 590, 637], "localhost": [54, 161, 335, 336, 585], "master_port": [54, 324, 335, 336, 578, 585, 590], "model_metadata": [54, 55, 578, 583, 584], "tupl": [54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 98, 102, 108, 112, 114, 120, 123, 124, 125, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 241, 246, 287, 290, 296, 297, 298, 302, 304, 305, 307, 311, 313, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 347, 348, 349, 350, 351, 352, 356, 357, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 407, 408, 411, 470, 540, 541, 542, 544, 545, 546, 548, 550, 555, 578, 583, 584, 586, 630, 637, 639], "metadata": [54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 79, 86, 87, 91, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 324, 325, 327, 328, 330, 331, 351, 371, 376, 378, 380, 381, 384, 583, 585, 586, 590, 620, 623, 625, 626, 633, 634, 640], "vllm_tp_size": 54, "vllmupdaterv2": [54, 590], "asyncvllm": [54, 333, 337, 578, 581, 590], "vllm_engin": [54, 55, 578, 579, 581, 583, 584, 585, 590], "reliabl": [54, 590], "get_model_metadata": [54, 55, 324, 590], "transformerswrapp": [54, 55, 170, 195, 196, 326, 329, 337, 383, 582, 590, 631], "rlvllmengin": [55, 334, 585], "vllmupdat": [55, 590], "get_tp_siz": [55, 324], "push_weights_from_transform": 55, "transformers_model": [55, 631], "pretrainedmodel": 55, "push_weights_from_transformers_optim": 55, "rollout_tensordict": 56, "_nestedkei": [56, 70, 71, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 178, 179, 180, 212, 219, 220, 221, 222, 223, 228, 229, 232, 236, 238, 241, 242, 246, 247, 251, 252, 254, 255, 256, 257, 258, 262, 264, 265, 266, 268, 271, 273, 280, 326, 332, 337], "nestedkei": [56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 188, 195, 196, 199, 207, 212, 213, 214, 215, 219, 220, 221, 222, 223, 224, 228, 229, 230, 231, 232, 233, 234, 236, 238, 239, 240, 241, 242, 246, 247, 248, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 279, 280, 286, 287, 301, 312, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 344, 350, 353, 364, 367, 376, 378, 380, 381, 382, 384, 390, 392, 407], "as_nest": 56, "x": [56, 68, 83, 86, 87, 109, 138, 176, 179, 239, 241, 268, 273, 282, 287, 288, 297, 300, 302, 304, 305, 313, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 375, 376, 377, 378, 379, 380, 381, 383, 384, 390, 392, 414, 590, 618, 622, 633, 635, 637, 639], "max": [56, 64, 72, 101, 102, 114, 137, 177, 231, 266, 312, 349, 350, 351, 357, 366, 368, 370, 379, 407, 418, 590, 618, 620, 621, 622, 628], "durat": [56, 634], "meta": [56, 74, 79, 86, 87, 89, 128, 132, 176, 190, 325, 327, 328, 330, 331, 348, 350, 364, 367, 369, 376, 378, 380, 381, 384, 620, 633, 634, 637], "aren": [56, 264, 621], "eventu": [56, 621, 635], "recov": [56, 79, 81, 83, 84, 85, 86, 87, 108, 109, 176, 325, 327, 328, 330, 331, 345, 356, 363, 376, 378, 380, 381, 384, 632], "layout": [56, 326, 329, 332, 337], "to_padded_tensor": 56, "nested_tensor": [56, 129, 131], "stride": [56, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 290, 291, 300, 326, 332, 337, 375, 377, 379, 382, 383, 462, 619, 633, 639], "jag": 56, "focu": [56, 618, 619, 620, 622, 624, 625, 626, 633], "team": [56, 633, 634, 639], "cat": [56, 86, 87, 176, 185, 322, 325, 327, 328, 330, 331, 349, 351, 352, 363, 368, 370, 371, 372, 376, 378, 380, 381, 384, 633, 637, 639], "arang": [56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 108, 109, 214, 297, 306, 404, 637], "obs_": 56, "15": [56, 78, 79, 80, 81, 82, 83, 84, 85, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 190, 226, 312, 359, 637], "trajectory_id": 56, "int32": [56, 58, 73, 75, 78, 83, 108, 136, 137, 148, 149, 160, 206, 340], "data_split": 56, "got": [56, 626], "int8": [57, 126, 141, 152, 153, 219], "encod": [57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 74, 75, 76, 77, 86, 87, 121, 122, 126, 129, 130, 131, 132, 135, 136, 137, 145, 146, 148, 149, 155, 161, 162, 176, 180, 214, 231, 309, 310, 315, 317, 325, 326, 327, 328, 330, 331, 332, 337, 376, 378, 380, 381, 384, 400, 611, 619, 620, 621, 624, 635, 637], "unlik": [57, 68, 72, 73, 107, 130, 142, 143, 163, 164, 180, 340, 358, 367, 392, 566, 619, 622, 624, 626, 639], "null": [57, 58, 60, 63, 65, 70, 71, 72, 74, 75, 76, 77, 170, 178, 219, 239], "denot": [57, 634], "assert_is_in": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "belong": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 83, 278, 279, 344, 618, 626, 634], "cardin": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 297, 298, 314, 620], "outcom": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 295, 306, 319, 365, 375, 377, 379, 383, 633], "cartesian": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "clear_device_": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "is_in": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 640], "ndarrai": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 130, 176, 180, 312, 325, 327, 328, 330, 331, 347, 376, 378, 380, 381, 384, 390, 622, 633], "ignore_devic": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "arrai": [57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 74, 75, 76, 77, 86, 87, 90, 101, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 233, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 618, 633], "np": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 90, 130, 176, 180, 278, 325, 327, 328, 330, 331, 347, 376, 378, 380, 381, 384, 390, 622, 633, 635], "use_mask": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 152, 153], "erase_memoize_cach": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "memoiz": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 130, 180], "memoize_encod": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "broadcast": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 295, 324, 357, 370, 578, 583, 584, 585, 586, 590], "least": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 224, 243, 627, 640], "compliant": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "singleton": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 177, 288, 305, 630], "start_dim": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "end_dim": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "implements_for_spec": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "torch_funct": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "tensor_to_index": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "represent": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 250, 275, 277, 325, 326, 327, 328, 330, 331, 332, 337, 348, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 592, 618, 635, 636, 640], "exanpl": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "one_hot": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "categ": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 341], "to_categorical_spec": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "idx_one_hot": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "idx_categ": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "to_categor": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "make_neg_dim": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "convert": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 90, 120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 229, 232, 250, 265, 271, 272, 275, 277, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 343, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585, 592, 618, 619, 620, 635, 637], "shortcut": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 635, 640], "len": [57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 95, 97, 116, 185, 248, 288, 305, 383, 618, 621, 622, 626, 628, 633, 635, 636, 637, 639], "ndimens": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 618], "violat": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "primari": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 138, 179, 611, 626], "project": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 231, 286, 297, 298, 312, 313, 314, 339, 341, 343, 344, 399, 461, 597, 639, 640], "uniformli": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 101, 102, 103, 365, 375, 377, 379, 383, 640], "normal": [57, 58, 59, 60, 61, 62, 63, 64, 67, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 246, 279, 280, 286, 288, 303, 305, 306, 320, 321, 341, 344, 350, 351, 364, 367, 382, 383, 408, 411, 562, 585, 621, 624, 634, 640], "drawn": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 265, 301, 341, 344, 620, 633, 634], "set_provisional_n": [57, 59, 61], "temporarili": [57, 59, 61, 93, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 626, 637], "dest": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 250, 275, 277, 343], "to_numpi": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "transformed_in": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 319, 562], "check_spec_encod": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "to_one_hot": [57, 59, 61, 62, 64], "hot": [57, 59, 61, 62, 64, 121, 122, 129, 131, 132, 135, 136, 137, 142, 143, 145, 146, 148, 149, 152, 153, 155, 161, 162, 163, 164, 214, 231, 297, 298, 310, 313, 314, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 621], "categ_sampl": [57, 59, 62, 64], "onehot_sampl": [57, 59, 62], "to_one_hot_spec": [57, 59, 61, 62, 64], "categoricalbox": [57, 59, 62, 64, 151], "type_check": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "unflatten": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 176, 218, 325, 327, 328, 330, 331, 340, 376, 378, 380, 381, 384], "unsqueez": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 190, 206, 215, 218, 221, 222, 268, 274, 525, 590, 618, 622, 633, 634, 635], "update_mask": [57, 59, 61, 62, 64], "leav": [57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 213, 259, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 618, 626, 637], "unmask": [57, 59, 61, 62, 64, 306], "ts": [57, 59, 61, 62, 64], "boundeddiscret": [58, 60], "upper": [58, 106, 245], "continuousbox": [58, 60, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 239, 242, 265, 273], "provision": [59, 337], "descript": [60, 135, 163, 217, 379, 611, 619, 620], "akin": 60, "unnam": [60, 71], "constraint": [60, 144, 320, 597, 620, 633, 634], "data_cl": 60, "tensorclass": [60, 86, 87, 95, 97, 116, 176, 325, 326, 327, 328, 330, 331, 337, 376, 378, 380, 381, 384, 592], "enforc": [60, 88, 107, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 334, 337, 345, 350, 351, 367, 370, 375, 377, 379, 382, 383, 635], "step_mdp_stat": 60, "pixels_spec": 60, "observation_vector_spec": 60, "33": [60, 69, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 305, 326, 332, 337, 375, 377, 379, 382, 383], "composite_spec": 60, "observation_vector": [60, 222, 618], "_nodefault": [60, 71], "is_empti": [60, 71, 635], "recurs": [60, 71, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 330, 331, 332, 337, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 622], "include_nest": [60, 71], "leaves_onli": [60, 71], "is_leaf": [60, 71], "step_mdp_static_onli": [60, 71], "_compositespecitemsview": [60, 71], "_compositespeckeysview": [60, 71], "reflect": [60, 71, 131, 152, 153, 212, 239, 278, 365, 375, 377, 379, 383, 551, 619, 620, 621, 634], "lock_": [60, 71], "succeed": [60, 71, 239, 273], "ones_upd": [60, 71], "pop": [60, 71, 195, 225], "keyerror": [60, 71, 171, 172, 175, 201, 272, 367, 400, 401, 611], "rand_upd": [60, 71], "refine_nam": [60, 71], "refin": [60, 71, 83, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 590], "lift": [60, 71, 83], "coexist": [60, 71], "nice": [60, 71, 620, 623, 626], "ellipsi": [60, 71], "greedili": [60, 71, 624], "spec_refin": [60, 71], "selected_kei": [60, 71, 259, 618], "unlock_": [60, 71], "_compositespecvaluesview": [60, 71], "zeros_upd": [60, 71], "nvec": [61, 62], "remove_singleton": 61, "ax": [61, 633], "m": [61, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 231, 287, 326, 332, 337, 344, 375, 377, 379, 382, 383, 619, 635], "tensor_spec": [61, 64, 74, 213, 215, 265, 342, 356, 357, 367, 369], "neither": [61, 62, 83, 161, 635], "use_regist": [62, 64], "mone_hot": 62, "boxlist": 62, "example_data": [63, 87, 175, 178, 185], "feature_dim": 63, "conform": 63, "nontensordata": [63, 78, 83, 86, 87, 123, 148, 149, 176, 185, 199, 239, 269, 273, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 390], "left": [63, 78, 79, 83, 88, 102, 108, 173, 174, 177, 178, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 218, 225, 226, 228, 229, 230, 234, 241, 244, 250, 252, 253, 259, 263, 266, 269, 271, 273, 275, 277, 280, 301, 306, 326, 332, 337, 382, 486, 619, 620, 622, 626, 627], "device_typ": [63, 556], "templat": [63, 87, 89, 170, 171, 172, 175, 195, 196, 198, 325, 330, 331, 332, 337, 393, 590, 592], "randomli": [63, 83, 107, 160, 183, 215, 245, 246, 265, 301, 341, 344, 624, 633, 634, 635, 637], "unidimension": 64, "action_valu": [64, 296, 297, 298, 313, 314, 351, 357, 365, 375, 377, 379, 383, 621, 622, 624, 628], "keepdim": [64, 590], "chosen_action_valu": [64, 313, 314, 621, 624], "priori": 64, "definit": [64, 110, 630], "one_hot_sampl": 64, "ep": [65, 72, 101, 102, 246, 279, 280, 312, 350, 379, 411, 427, 504, 514, 535, 536, 538, 539, 540, 541, 542, 545, 546, 547, 550, 618, 619, 621, 622, 625, 628], "1e": [65, 72, 101, 102, 246, 279, 280, 295, 299, 307, 319, 504, 514, 535, 536, 538, 539, 541, 542, 543, 545, 546, 547, 548, 550, 618, 619, 620, 634], "08": [65, 72, 101, 102, 504, 514, 535, 536, 541, 542, 545, 546, 547, 550], "pin_memori": [65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 249, 618, 639], "prefetch": [65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 618, 619, 621, 637], "dim_extend": [65, 68, 72, 73], "delayed_init": [65, 66, 68, 69, 72, 73], "schaul": [65, 101, 102], "quan": [65, 101, 102], "j": [65, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383, 621, 625], "antonogl": [65, 101, 102], "silver": [65, 101, 102], "2015": [65, 101, 102, 226], "arxiv": [65, 80, 83, 85, 101, 102, 121, 122, 124, 125, 136, 137, 142, 143, 145, 146, 155, 163, 164, 221, 250, 275, 289, 290, 291, 292, 293, 294, 298, 299, 300, 308, 309, 312, 315, 316, 317, 348, 349, 353, 354, 355, 356, 358, 359, 360, 361, 362, 363, 366, 367, 370, 371, 385, 636], "ab": [65, 80, 83, 85, 101, 102, 121, 122, 124, 125, 136, 137, 142, 143, 145, 146, 155, 163, 164, 220, 250, 275, 279, 289, 294, 299, 300, 308, 309, 315, 316, 317, 348, 349, 353, 354, 355, 356, 359, 360, 361, 363, 366, 367, 370, 636], "1511": [65, 101, 102, 300], "05952": [65, 101, 102], "expon": [65, 72, 101, 102], "\u03b1": [65, 72], "uniform": [65, 72, 101, 102, 326, 332, 337, 633], "delta": [65, 72, 319, 341, 344, 597, 633], "1_000": [65, 68, 72, 73, 633, 637], "mini": [65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 634], "decid": [65, 68, 72, 73, 611, 633, 639], "incompat": [65, 68, 72, 73, 369, 637], "drop_last": [65, 68, 72, 73, 107, 109, 431], "notion": [65, 68, 72, 73], "capac": [65, 68, 72, 73, 95, 97, 101, 102, 108, 116, 620, 626], "caution": [65, 68, 72, 73, 107, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 400, 640], "codebas": [65, 68, 72, 73, 635], "unbind": [65, 68, 72, 73, 86, 87, 176, 244, 325, 327, 328, 330, 331, 340, 376, 378, 380, 381, 383, 384, 590], "transform_factori": [65, 66, 68, 69, 72, 73], "return_info": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 637], "tensordictprioritizedreplaybuff": [65, 639], "priority_weight": [65, 72, 101, 102], "update_prior": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 410, 619, 637, 639], "36278465": 65, "invert": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 620], "default_remote_class_config": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "overriden": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "tempfil": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 95, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 558, 618, 619, 621, 622, 626, 633, 636, 637], "tensordictreplaybuff": [65, 66, 67, 68, 69, 72, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 108, 109, 114, 220, 221, 410, 436, 558, 618, 619, 621, 637], "1_000_000": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 108, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 618, 621, 633], "td_error": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 351, 352, 353, 355, 356, 357, 358, 363, 365, 368, 370, 371, 372, 375, 377, 379, 383, 618, 637, 639], "update_tensordict_prior": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 618, 637, 639], "temporarydirectori": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 618, 619, 621, 622, 626, 633, 636, 637], "tmpdir": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 618, 619, 622, 633], "rb_load": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "empty_write_count": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "cursor": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "ambigu": [65, 66, 68, 69], "pytre": [65, 66, 68, 69, 72, 73, 86, 87, 98, 117, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "cut": [65, 66, 68, 69], "insert_transform": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 171, 172, 175, 216, 272], "insert": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 94, 104, 114, 115, 118, 119, 171, 172, 175, 195, 216, 221, 225, 262, 272, 274, 590], "__iter__": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 185], "register_load_hook": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "register_save_hook": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "set_sampl": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "set_storag": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "set_writ": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "far": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 175, 303, 320, 321, 379, 590, 628, 635, 640], "replay_buffer_cl": 66, "optiona": 66, "asyncio": [66, 120], "ray_buff": 66, "object_store_memori": 66, "600": 66, "await": 66, "invoc": 67, "friendli": [67, 618], "public": [67, 82, 111, 250, 277], "include_info": [67, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "checkpoint": [68, 91, 93, 95, 99, 110, 111, 113, 117, 400, 416, 612, 637], "roundrobinwrit": [68, 78, 79, 80, 81, 82, 83, 84, 85, 430], "depth": [68, 74, 120, 123, 126, 130, 138, 144, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 288, 290, 291, 292, 293, 297, 299, 300, 305, 308, 309, 462, 463, 466, 467, 468, 619, 623, 625, 626, 632, 633, 634, 637], "_pytre": [68, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 637], "tree_map": [68, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 637], "assert0": [68, 637], "writerensembl": [69, 112], "sample_from_al": [69, 78, 106], "num_buffer_sampl": [69, 106], "_c": [69, 72], "ensembl": [69, 106, 112, 113, 119, 343, 368, 434, 435], "forbidden": 69, "collat": [69, 171, 172, 175], "rb0": 69, "rb1": 69, "another_kei": 69, "pixels33": 69, "0x13a2ef430": 69, "0x13a2f9310": 69, "interpolationmod": 69, "bilinear": [69, 254, 511], "0x13a2f9220": 69, "0x13a2f9f70": 69, "tensordictroundrobinwrit": [69, 73], "0x13a2d9b50": 69, "0x13a2f95b0": 69, "0x128648260": 69, "data0": [69, 96], "randint": [69, 86, 87, 176, 185, 268, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 637], "255": [69, 268, 637], "244": [69, 250, 277], "data1": [69, 96, 639], "thrown": [70, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 637], "heterogen": [70, 71, 96, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 618, 619], "semant": [70, 71, 129, 131, 636], "priority_kei": [72, 73, 101, 351, 353, 356, 357, 358, 363, 365, 368, 370, 371, 372, 375, 377, 379, 383, 637, 639], "reduct": [72, 101, 102, 114, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 379, 383, 407, 427, 470], "prioritizedreplaybuff": [72, 639], "min": [72, 101, 102, 114, 312, 349, 350, 351, 357, 366, 368, 370, 375, 379, 407, 619, 620], "median": [72, 101, 102, 114, 130, 136, 137, 180, 214, 341, 344], "_encode_memo_dict": 74, "possess": [74, 79], "describ": [74, 86, 87, 176, 202, 222, 319, 320, 325, 327, 328, 330, 331, 342, 353, 376, 378, 380, 381, 384, 395, 618, 620, 633, 634, 635, 640], "make_composite_from_td": [74, 635], "educ": 74, "guess": 74, "knowledg": [74, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 625, 627], "dataset_id": [78, 79, 80, 81, 83, 84, 85], "num_proc": 78, "slice_len": [78, 83, 102, 108, 109, 392, 432, 433, 621], "strict_len": 78, "mp_start_method": [78, 79, 80, 81, 82, 83, 84, 85, 150, 158, 270, 619, 639], "arari": 78, "2600": 78, "million": 78, "consequ": [78, 93, 626], "50x10": 78, "available_dataset": [78, 79, 80, 81, 82, 83, 84, 85, 108, 109], "ataridqn": 78, "greater": [78, 102, 108, 109, 226, 242, 244, 302, 304, 351, 618, 619], "strict_length": [78, 83, 102, 108, 109, 392, 432, 433, 621], "shorter": [78, 83, 102, 108, 109], "Be": [78, 83, 102, 108, 109], "game_nam": 78, "krull": 78, "1d": [78, 101, 102, 108, 109, 114], "1m": [78, 83, 551, 618, 620, 621], "cheapli": 78, "invalid_rang": 78, "999998": 78, "999999": 78, "add_count": 78, "84": [78, 90, 108, 254, 481, 486, 511, 621, 622], "valueestim": [78, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 618, 633, 634], "convolut": [78, 288, 290, 291, 462, 622, 624], "2657628": 78, "2657629": 78, "2657630": 78, "2657631": 78, "2657632": 78, "2657633": 78, "2657634": 78, "2657635": 78, "2657636": 78, "2657637": 78, "2657638": 78, "2657639": 78, "2657640": 78, "2657641": 78, "2657642": 78, "2657643": 78, "2657644": 78, "2657645": 78, "2657646": 78, "2657647": 78, "2657648": 78, "2657649": 78, "2657650": 78, "2657651": 78, "2657652": 78, "2657653": 78, "2657654": 78, "2657655": 78, "2657656": 78, "2657657": 78, "2657658": 78, "2657659": 78, "2657660": 78, "2657661": 78, "2657662": 78, "2657663": 78, "2657664": 78, "2657665": 78, "2657666": 78, "2657667": 78, "2657668": 78, "2657669": 78, "2657670": 78, "2657671": 78, "2657672": 78, "2657673": 78, "2657674": 78, "2657675": 78, "2657676": 78, "2657677": 78, "2657678": 78, "2657679": 78, "2657680": 78, "2657681": 78, "2657682": 78, "2657683": 78, "2657684": 78, "2657685": 78, "2657686": 78, "2657687": 78, "2657688": 78, "2657689": 78, "2657690": 78, "2657691": 78, "1995687": 78, "1995688": 78, "1995689": 78, "1995690": 78, "1995691": 78, "1995692": 78, "1995693": 78, "1995694": 78, "1995695": 78, "1995696": 78, "1995697": 78, "1995698": 78, "1995699": 78, "1995700": 78, "1995701": 78, "1995702": 78, "1995703": 78, "1995704": 78, "1995705": 78, "1995706": 78, "1995707": 78, "1995708": 78, "1995709": 78, "1995710": 78, "1995711": 78, "1995712": 78, "1995713": 78, "1995714": 78, "1995715": 78, "1995716": 78, "1995717": 78, "1995718": 78, "1995719": 78, "1995720": 78, "1995721": 78, "1995722": 78, "1995723": 78, "1995724": 78, "1995725": 78, "1995726": 78, "1995727": 78, "1995728": 78, "1995729": 78, "1995730": 78, "1995731": 78, "1995732": 78, "1995733": 78, "1995734": 78, "1995735": 78, "1995736": 78, "1995737": 78, "1995738": 78, "1995739": 78, "1995740": 78, "1995741": 78, "1995742": 78, "1995743": 78, "1995744": 78, "1995745": 78, "1995746": 78, "1995747": 78, "1995748": 78, "1995749": 78, "1995750": 78, "replaybufferensembl": [78, 106, 112, 119], "untouch": [78, 83, 86, 87, 88, 173, 174, 176, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 273, 280, 325, 327, 328, 330, 331, 376, 378, 380, 381, 382, 384], "_max_run": 78, "dataset_asterix": 78, "asterix": 78, "dataset_pong": 78, "buffer_id": [78, 106, 112], "hidden": [78, 150, 158, 220, 283, 284, 285, 290, 299, 302, 304, 308, 309, 315, 316, 343, 346, 350, 364, 367, 621, 632, 639], "data_path": [78, 79, 80, 81, 82, 83, 84, 85], "data_path_root": [78, 79, 80, 81, 82, 83, 84, 85], "delet": [78, 79, 80, 81, 82, 83, 84, 85, 97, 222, 262, 399], "fn": [78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 273, 307, 326, 332, 337, 375, 377, 379, 382, 383, 529, 560, 561], "chunksiz": [78, 79, 80, 81, 82, 83, 84, 85], "num_chunk": [78, 79, 80, 81, 82, 83, 84, 85], "max_tasks_per_child": [78, 79, 80, 81, 82, 83, 84, 85], "worker_thread": [78, 79, 80, 81, 82, 83, 84, 85], "index_with_gener": [78, 79, 80, 81, 82, 83, 84, 85], "num_fram": [78, 79, 80, 81, 82, 83, 84, 85], "unitari": [78, 79, 80, 81, 82, 83, 84, 85, 635], "subsequ": [78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 326, 332, 337, 375, 377, 379, 382, 383, 565, 573, 621, 633], "distance_from_origin": [78, 79, 80, 81, 82, 83, 84, 85], "forward_reward": [78, 79, 80, 81, 82, 83, 84, 85], "qpo": [78, 79, 80, 81, 82, 83, 84, 85], "qvel": [78, 79, 80, 81, 82, 83, 84, 85], "reward_ctrl": [78, 79, 80, 81, 82, 83, 84, 85, 130, 150, 180], "reward_forward": [78, 79, 80, 81, 82, 83, 84, 85], "reward_surv": [78, 79, 80, 81, 82, 83, 84, 85], "x_posit": [78, 79, 80, 81, 82, 83, 84, 85, 130, 150, 180], "x_veloc": [78, 79, 80, 81, 82, 83, 84, 85, 130, 150, 180], "y_posit": [78, 79, 80, 81, 82, 83, 84, 85], "y_veloc": [78, 79, 80, 81, 82, 83, 84, 85], "achieved_go": [78, 79, 80, 81, 82, 83, 84, 85], "desired_go": [78, 79, 80, 81, 82, 83, 84, 85], "27": [78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 108, 109, 121, 122, 150, 158, 176, 226, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "_collate_id": [78, 79, 80, 81, 82, 83, 84, 85], "0x120e21dc0": [78, 79, 80, 81, 82, 83, 84, 85], "cattensor": [78, 79, 80, 81, 82, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 480, 618, 632, 635, 640], "cat_tensor": [78, 79, 80, 81, 82, 83, 84, 85], "cat_next_tensor": [78, 79, 80, 81, 82, 83, 84, 85], "func": [78, 79, 80, 81, 82, 83, 84, 85, 281], "new_storag": [78, 79, 80, 81, 82, 83, 84, 85], "31": [78, 79, 80, 81, 82, 83, 84, 85, 108, 136, 137], "full_storag": [78, 79, 80, 81, 82, 83, 84, 85], "0x168406fc0": [78, 79, 80, 81, 82, 83, 84, 85], "from_env": 79, "use_truncated_as_don": 79, "direct_download": 79, "terminate_on_end": 79, "env_kwarg": [79, 84, 85, 218, 476, 560, 561, 618], "d4rl": [79, 85], "reconstruct": [79, 108, 109, 360, 618, 640], "regard": [79, 85, 298, 348, 358, 367, 618, 620, 635], "get_dataset": 79, "qlearning_dataset": 79, "fewer": [79, 102, 108], "unexpectedli": 79, "traj_split": 79, "observationnorm": [79, 279, 280, 504, 562, 618, 619, 620, 621, 639], "maze2d": 79, "umaz": 79, "loc": [79, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180, 241, 246, 257, 279, 280, 283, 284, 285, 303, 307, 320, 321, 341, 344, 346, 348, 349, 351, 363, 367, 368, 369, 370, 504, 514, 552, 562, 597, 618, 619, 620, 621, 624, 634, 639], "gen": 80, "dgrl": 80, "accompani": [80, 218, 263], "gap": 80, "2312": 80, "05742": 80, "gen_dgrl": 80, "procgen": 80, "bigfish": 80, "bossfight": 80, "1m_e": 80, "1m_": 80, "comma": [80, 622], "npy": 80, "mmap": [80, 84, 85], "minut": 80, "huggingfac": [80, 85, 177, 332], "internet": [80, 85], "connect": [80, 85, 161, 190, 563, 564, 566, 567, 569, 570, 571, 572, 574, 577, 579, 585], "load_from_local_minari": 81, "minari": 81, "websit": [81, 83, 630], "currenrtli": 81, "minari_data": 81, "door": 81, "human": [81, 171, 635], "torchrl_logg": [81, 628, 630], "28": [81, 108, 109, 377, 379], "39": [81, 136, 137], "door_body_po": 81, "openml": [82, 147, 451], "dua": 82, "graff": 82, "2017": 82, "uci": [82, 123], "archiv": 82, "ic": 82, "edu": 82, "ml": [82, 161, 162, 324], "scikit": [82, 147], "sklearn": [82, 147], "panda": 82, "adult_num": [82, 147], "adult_onehot": [82, 147], "mushroom_num": [82, 147], "mushroom_onehot": [82, 147], "covertyp": [82, 147], "shuttl": [82, 147], "magic": [82, 147, 622, 623], "shuffl": [83, 107, 109, 171, 172, 175, 431, 634], "embodi": [83, 636], "collabor": 83, "21": [83, 84, 108, 109, 150, 152, 153, 158, 226, 617, 638], "institut": 83, "demonstr": [83, 590, 620, 622, 626, 630, 631, 633, 634, 635, 637, 640], "527": 83, "skill": 83, "160266": 83, "googl": [83, 84, 121, 122, 142, 143, 148, 149, 175, 177, 620, 621, 630, 633, 634], "open_x_embodi": 83, "2310": [83, 155], "08864": 83, "language_instruct": 83, "get_non_tensor": 83, "nor": [83, 161], "insuffici": 83, "chosen": [83, 163, 164, 264, 265, 314, 392, 611, 627], "openx": 83, "__will": 83, "change__": 83, "crop": [83, 223, 251, 392, 486], "compli": 83, "modal": [83, 326, 332, 337, 618], "cmu_stretch": [83, 392], "discount": [83, 127, 255, 349, 355, 358, 359, 361, 385, 386, 387, 388, 418, 619, 620, 633, 634], "is_init": [83, 85, 220, 240, 302, 304, 312, 340, 385, 621, 622], "language_embed": 83, "512": [83, 300], "green": [83, 633], "garbag": [83, 566], "lid": 83, "roboset": 84, "h5": [84, 85, 86, 87, 93, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "roboh": [84, 155, 454], "excludetransform": [84, 259, 492, 637], "fk1": 84, "v4": [84, 130, 150, 180, 214, 254, 618, 620, 636, 639], "expert": 84, "fk1_microopenrandom_v2d": 84, "concis": [84, 625], "20": [84, 108, 109, 114, 120, 123, 126, 130, 134, 138, 148, 149, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 264, 300, 377, 379, 400, 404, 543, 631, 637, 640], "18": [84, 108, 109, 156, 157, 163, 164, 270], "23": [84, 109, 226, 282], "19": [84, 108, 109, 114, 226], "75": [84, 108, 537], "totensor": 85, "image_s": 85, "v": [85, 279, 283, 356, 363, 370, 604, 618, 619], "npz": 85, "2206": [85, 145, 146], "04779": [85, 349, 355], "vd4rl": 85, "squar": [85, 223, 228, 303, 320, 321, 350, 367, 379, 392, 590], "rectangular": [85, 288], "walker_walk": 85, "64px": 85, "height": [85, 223, 228, 254, 481, 486], "veloc": [85, 120, 123, 124, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 633, 634, 635, 640], "audio": 86, "function_cal": 86, "_wrap_td_method": 86, "wrapped_func": 86, "0x7ff7bf802160": 86, "mime_typ": 86, "function_nam": 86, "function_arg": 86, "copy_exist": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "return_earli": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "share_non_tensor": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "robust_kei": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_ani": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "auto_batch_s": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "batch_dim": [86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 562], "incur": [86, 87, 121, 122, 136, 137, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "overhead": [86, 87, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 212, 325, 327, 328, 330, 331, 344, 376, 378, 380, 381, 384], "involv": [86, 87, 129, 131, 132, 142, 143, 155, 176, 218, 221, 270, 302, 304, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 623, 625], "opinion": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "term": [86, 87, 96, 176, 188, 195, 241, 325, 327, 328, 330, 331, 348, 357, 367, 376, 378, 380, 381, 384, 417, 619, 620, 623, 624, 634], "obj": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_dataclass": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "namedtupl": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 325, 326, 327, 328, 330, 331, 332, 337, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384], "from_namedtupl": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_dict": [86, 87, 176, 185, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_tupl": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_struct_arrai": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "hdf5": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_h5": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "dest_cl": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "as_tensorclass": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "convers": [86, 87, 121, 122, 136, 137, 170, 172, 175, 176, 186, 195, 196, 209, 325, 327, 328, 330, 331, 376, 378, 379, 380, 381, 384, 564, 567, 569, 570, 572, 577, 579, 585, 590, 592, 630, 631], "persistenttensordict": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "key1": [86, 87, 176, 222, 262, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 404, 412, 639], "key2": [86, 87, 176, 222, 262, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 404, 412, 639], "as_modul": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "use_state_dict": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "lazy_stack": [86, 87, 88, 89, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 383, 384, 590, 632], "expand_ident": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "ensebml": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "vmap": [86, 87, 176, 325, 327, 328, 330, 331, 343, 346, 349, 351, 357, 363, 365, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 604], "tensordictparam": [86, 87, 176, 325, 327, 328, 330, 331, 344, 376, 378, 380, 381, 384], "densli": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "dens": [86, 87, 120, 176, 306, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 590], "reinstanti": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "tempt": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "orign": [86, 87, 176, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 383, 384], "longer": [86, 87, 176, 189, 282, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 590, 619, 621, 628, 633, 634, 637], "empty_modul": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "n_model": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "bia": [86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 239, 250, 265, 270, 271, 272, 275, 277, 288, 290, 291, 292, 293, 299, 300, 301, 302, 304, 305, 307, 312, 325, 326, 327, 328, 330, 331, 332, 337, 343, 351, 365, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 618, 619, 620, 621, 634], "exec_modul": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "to_modul": [86, 87, 176, 325, 327, 328, 330, 331, 343, 346, 376, 378, 380, 381, 384, 618, 639], "backprop": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "named_tupl": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "a_tensor": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "a_str": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "nt": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "to_namedtupl": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "genericdict": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_pytre": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "biject": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "castabl": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "surject": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "weird": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "weirdlookingclass": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "weird_kei": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "pytree_recon": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "to_pytre": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_remote_init": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "processgroup": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "init_remot": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "src": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "struct_arrai": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "rex": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "fido": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "u10": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "ag": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "i4": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "f4": [86, 87, 123, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "x_recon": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "to_struct_arrai": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_tensordict": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "non_tensordict": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "my_tupl": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "fromkei": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "getattr": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "load_memmap": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "load_": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "pathlib": [86, 87, 95, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 414, 418, 419, 622], "load_memmap_": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "non_block": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 325, 326, 327, 328, 330, 331, 332, 337, 343, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384], "robust": [86, 87, 176, 251, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 590], "decod": [86, 87, 138, 176, 179, 207, 308, 324, 325, 326, 327, 328, 330, 331, 332, 337, 376, 378, 380, 381, 384, 590], "emit": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "saved_td": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "td_load": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "_subclass": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "faketensormod": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "faketensor": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "strict": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 325, 326, 327, 328, 330, 331, 332, 337, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 611, 622], "from_flatten": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "attemptedli": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "destin": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 220, 229, 230, 232, 239, 270, 272, 275, 279, 325, 326, 327, 328, 330, 331, 332, 337, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 417, 418, 471, 576], "maybe_dense_stack": [86, 87, 176, 185, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "existsok": [86, 87, 95, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "mimic": [86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "non_tensor": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "charact": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 620, 622], "throw": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 640], "cross": [86, 87, 176, 325, 326, 327, 328, 330, 331, 332, 337, 376, 378, 380, 381, 384, 588], "anymor": [86, 87, 176, 272, 325, 327, 328, 330, 331, 343, 376, 378, 380, 381, 384], "tensordictfutur": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "serialis": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "deepli": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "memmap_": [86, 87, 176, 279, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "memmap_lik": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "contentless": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "memmap_refresh_": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "refresh": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 628, 633, 634], "saved_path": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "setattr": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "tent": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "keep_var": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 325, 326, 327, 328, 330, 331, 332, 337, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384], "to_tensordict": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "retain_non": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "discrard": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "contentbas": 87, "is_complet": 87, "tool_cal": 87, "tool_respons": [87, 193, 590], "apply_chat_templ": [87, 89, 170, 193, 383, 590, 630], "autotoken": [87, 89, 170, 171, 172, 174, 175, 182, 183, 189, 193, 195, 196, 325, 330, 331, 332, 337, 383, 590, 630, 631], "autoprocessor": 87, "add_generation_prompt": [87, 89, 195, 196, 325, 383], "chat_templ": [87, 198, 325, 332, 337, 383], "chat_template_nam": [87, 89, 325, 330, 331, 332, 337, 383], "continue_final_messag": 87, "return_tensor": [87, 195, 330], "return_dict": [87, 89, 196], "return_assistant_tokens_mask": [87, 89, 195, 196], "chat": [87, 89, 170, 171, 172, 175, 184, 193, 195, 196, 198, 325, 330, 331, 332, 337, 383, 590, 592, 631], "pretrainedtoken": [87, 170, 181, 332, 337], "prompt": [87, 88, 170, 171, 172, 173, 175, 177, 178, 183, 185, 190, 193, 324, 325, 327, 329, 330, 331, 332, 337, 379, 382, 590, 631], "im_start": [87, 172, 175, 193, 590], "assist": [87, 89, 170, 172, 175, 183, 189, 190, 193, 195, 196, 332, 337, 379, 383, 590, 592, 621, 630, 631], "preval": 87, "messag": [87, 89, 170, 183, 187, 564, 565, 566, 567, 569, 570, 572, 573, 574, 577, 579, 585, 590, 631], "pt": [87, 195, 330, 394, 458], "assistant_mask": 87, "qwen": [87, 172, 175, 183, 193, 324, 332, 333, 334, 337, 383, 590, 630, 631], "dialogpt": 87, "falcon": 87, "deepseek": 87, "chatml_format": [87, 332, 337, 383], "default_spec": [87, 325, 327, 328, 330, 331], "set_list_to_stack": [87, 175, 190, 193, 195, 196, 197, 590, 630], "foo": [87, 95, 97, 116, 637, 640], "from_chat": [87, 89, 170, 195, 196, 332, 337, 383, 631], "from_pretrain": [87, 89, 138, 172, 175, 179, 183, 193, 195, 196, 324, 329, 332, 337, 383, 590, 630, 631], "qwen2": [87, 172, 175, 183, 193, 324, 333, 334, 337, 590, 630, 631], "7b": [87, 89, 324, 590, 630], "nyou": [87, 175], "im_end": [87, 172, 183, 193, 590, 630], "nwrite": 87, "capit": [87, 630, 631], "franc": [87, 630, 631], "germani": 87, "pari": [87, 175, 630], "berlin": 87, "answer": [87, 172, 174, 175, 177, 183, 590, 630], "topk_siz": 88, "prompt_kei": [88, 177, 382], "rewards_kei": [88, 382], "k": [88, 287, 326, 332, 337, 604], "topk": 88, "selector": [88, 630], "25": [88, 226, 470, 611, 618], "wrote": 88, "top3": 88, "r3": 88, "as_padded_tensor": [88, 178, 185, 196, 326, 332, 337], "add_modul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "init_weight": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "fill_": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 619, 621], "net": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 291, 293, 296, 300, 326, 332, 337, 348, 349, 351, 357, 363, 367, 368, 369, 370, 375, 377, 379, 382, 383, 462, 463, 466, 468, 558, 619, 635, 636, 639], "requires_grad": [88, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 270, 272, 326, 332, 337, 344, 351, 370, 375, 377, 379, 382, 383, 441], "bfloat16": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "datatyp": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 637], "member": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 365, 375, 377, 379, 382, 383, 392], "xdoctest": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 239, 250, 265, 270, 271, 272, 275, 277, 326, 332, 337, 343, 351, 365, 370, 375, 377, 379, 382, 383], "buf": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "20l": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 365, 375, 377, 379, 382, 383], "1l": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 365, 375, 377, 379, 382, 383], "5l": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 365, 375, 377, 379, 382, 383], "doubl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 229, 230, 232, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 353, 358, 368, 375, 377, 379, 382, 383, 579, 580, 581, 582, 618, 619, 620, 621, 640], "eval": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 279, 326, 332, 337, 350, 367, 375, 377, 379, 382, 383, 618, 619, 620], "evalu": [88, 120, 123, 126, 130, 131, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 272, 295, 306, 310, 321, 326, 332, 337, 368, 375, 377, 379, 382, 383, 553, 554, 611, 619, 620, 628], "batchnorm": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 326, 332, 337, 375, 377, 379, 382, 383], "extra_repr": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "transformthatmeasuresbyt": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 382], "byte": [88, 90, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 382], "bytes_in_td": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 382], "get_buff": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "docstr": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 623, 624], "get_submodul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "explan": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "qualifi": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "referenc": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "get_extra_st": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 375, 377, 379, 382, 383], "set_extra_st": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 375, 377, 379, 382, 383], "picklabl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 375, 377, 379, 382, 383], "get_paramet": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "sai": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 633, 636, 640], "net_b": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "net_c": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "conv": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 326, 332, 337, 375, 377, 379, 382, 383, 619], "conv2d": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 290, 291, 300, 326, 332, 337, 375, 377, 379, 382, 383], "kernel_s": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 290, 291, 300, 308, 326, 332, 337, 375, 377, 379, 382, 383, 462, 619, 639], "diagram": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "degre": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 326, 332, 337, 375, 377, 379, 382, 383], "named_modul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "o": [88, 91, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "half": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383, 618], "ipu": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "descend": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383], "get_swap_module_params_on_convers": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383], "persist": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 212, 239, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383, 400, 611], "preserv": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 343, 351, 370, 375, 377, 379, 382, 383], "missing_kei": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383], "unexpected_kei": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383], "l": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 620, 635], "idx": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "mtia": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "named_buff": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "remove_dupl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 365, 375, 377, 379, 382, 383], "prepend": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 365, 375, 377, 379, 382, 383, 622], "running_var": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "named_children": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "conv4": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "conv5": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "memo": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "named_paramet": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 326, 332, 337, 365, 375, 377, 379, 382, 383], "register_backward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "removablehandl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_full_backward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_buff": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "running_mean": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "alongsid": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 590, 611, 627], "num_featur": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_forward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "with_kwarg": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "always_cal": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_module_forward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "regardless": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 350, 364, 367, 375, 377, 379, 382, 383], "register_forward_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "And": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 625], "forward_pr": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_module_forward_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "rule": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 326, 332, 337, 344, 375, 377, 379, 382, 383, 620], "ordinarili": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "grad_input": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "grad_output": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "technic": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 619, 621, 622, 624], "register_module_full_backward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_full_backward_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "backward_pr": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_module_full_backward_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_load_state_dict_post_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "incompatible_kei": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_load_state_dict_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "local_metadata": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "error_msg": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "noqa": [88, 120, 123, 126, 130, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 622], "b950": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_modul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_paramet": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_state_dict_post_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_state_dict_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "requires_grad_": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 622], "autograd": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383], "freez": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 375, 377, 379, 382, 383], "finetun": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "gan": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "set_submodul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "share_memori": [88, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 618], "share_memory_": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 639], "averag": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 279, 280, 312, 326, 332, 337, 351, 359, 360, 370, 375, 377, 379, 382, 383, 411, 590, 618, 620], "shallow": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383, 621], "detach": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 351, 362, 365, 370, 371, 375, 377, 379, 382, 383, 385, 386, 387, 388, 618], "memory_format": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "channels_last": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "pin": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "4d": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "ignore_w": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "1913": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "3420": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "5113": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "2325": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "torch_doctest_cuda1": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "gpu1": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "1914": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "5112": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "2324": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "float16": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "cdoubl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "3741": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "2382": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "5593": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "4443": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "complex128": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "6122": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "1150": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "to_empti": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "transform_done_spec": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 230, 243, 262, 269, 271, 273, 382], "transform_env_batch_s": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 271, 382], "transform_env_devic": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 230, 271, 382], "transform_full_done_spec": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 273, 280, 382], "dst_type": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "xpu": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "set_to_non": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "template_nam": 89, "inverse_pars": 89, "model_family_keyword": 89, "llama": 89, "mistral": 89, "histori": [89, 170, 171, 172, 174, 175, 178, 183, 184, 186, 189, 190, 193, 195, 196, 197, 325, 326, 329, 330, 331, 332, 337, 383, 590, 630], "jinja2": 89, "pars": [89, 174, 186, 198, 200, 203, 330, 331, 590, 592, 630, 637], "parser": [89, 135, 174, 186, 187, 197, 203, 559, 562, 590], "llama_templ": 89, "inst": 89, "elif": [89, 590, 618, 619, 630], "endgener": 89, "endif": 89, "endfor": 89, "parse_llama_text": 89, "findal": 89, "dotal": 89, "user_cont": 89, "assistant_cont": 89, "strip": [89, 619], "hf": 89, "hello": [89, 170, 195, 196, 324, 332, 333, 337, 383, 400, 611], "hi": [89, 332, 337], "Or": [89, 156, 157], "compression_fn": 90, "decompression_fn": 90, "compression_level": 90, "decompress": 90, "sensori": 90, "zstd": 90, "verifi": [90, 171, 367], "attach": [90, 95, 96, 97, 98, 110, 112, 116, 619], "entiti": [90, 95, 96, 97, 98, 110, 112, 116], "to_bytestream": 90, "data_to_bytestream": 90, "compact": [92, 93, 100], "shift": [92, 93, 100, 385, 386, 387, 388, 620], "checkpoint_fil": 93, "h5_kwarg": 93, "iff": 93, "suffix": [93, 408], "h5py": 93, "create_dataset": 93, "increas": [93, 221, 266, 312, 350, 367, 379, 383, 633, 634], "immut": [94, 120, 123, 126, 130, 138, 150, 154, 158, 159, 170, 171, 172, 175, 178, 179, 180, 253, 272], "scratch_dir": [95, 618, 619, 621, 626, 633, 636, 637], "shared_init": [95, 97, 423, 425], "mistak": [95, 97, 116], "overewritten": 95, "main_ckpt_dir": 95, "rb_memmap": 95, "10_000_000": 95, "myclass": [95, 97, 116], "lazystacktensordict": 96, "heterougen": 96, "linearli": 96, "densifi": 96, "unlimit": [96, 98], "st": 96, "consolid": 97, "cleanup_memmap": 97, "expans": [97, 365, 375, 377, 379, 383], "ram": [97, 129, 131, 627, 637], "zero_": [97, 116, 206], "liststoag": 99, "max_priority_within_buff": [101, 102], "proport": [101, 637], "magnitud": [101, 102, 618, 633], "tempor": [101, 302, 304, 386, 387], "focus": [101, 102, 611, 618, 625], "p_i": [101, 102], "delta_i": [101, 102], "epsilon": [101, 102, 246, 286, 301, 312, 411, 619, 620, 621, 624], "frac": [101, 102, 620], "sum_j": [101, 102], "p_j": [101, 102], "w_i": [101, 102], "cdot": [101, 102, 383], "aggress": [101, 102, 383], "bias": [101, 102, 618], "toward": [101, 102, 277], "unbias": [101, 102], "anneal": [101, 102, 312, 619, 624, 633], "guidelin": [101, 102], "math": [101, 102, 190], "data_0": 101, "data_1": 101, "smoothen": 101, "tdrb": 101, "pack": [101, 332, 620, 623, 640], "nd": [101, 102], "sum_tre": [101, 102], "min_tre": [101, 102], "end_kei": [102, 108, 109, 432, 433, 621], "traj_kei": [102, 108, 109, 432, 433, 637], "cache_valu": [102, 108, 109, 432, 433, 621], "truncated_kei": [102, 108, 109, 255, 263, 432, 433, 520], "closer": [102, 639], "commonli": [102, 108, 109, 640], "readili": [102, 108, 109, 344], "conjunct": [102, 108, 109, 619], "buffer0": [102, 108], "immutablewrit": [102, 108], "buffer1": [102, 108], "other_sampl": [102, 108], "short": [102, 108, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 332, 619, 620, 623, 624, 634, 637], "tolist": [102, 590], "120110917137936e": 102, "06": [102, 295, 319, 538, 548], "roundrobin": [104, 115], "consum": [107, 109, 340, 619, 620, 626, 634, 637], "incomplet": [107, 109, 183], "fresh": [107, 185, 566, 574], "haven": [107, 636], "remain": [107, 183, 191, 220, 230, 231, 241, 243, 264, 590, 611, 625], "draw": [107, 301], "use_gpu": [108, 109, 432, 433], "acceler": [108, 109, 130, 180, 633, 634], "ep_1": [108, 109], "ep_2": [108, 109], "73": 108, "74": 108, "76": 108, "77": 108, "41": 108, "42": [108, 305, 348, 349, 351, 352, 356, 363, 370], "43": 108, "44": 108, "45": 108, "67": [108, 632], "68": 108, "69": 108, "70": 108, "71": 108, "80": [108, 121, 122], "82": 108, "83": 108, "78": 108, "79": 108, "320": [108, 109, 124, 125], "550": [108, 109], "700": [108, 109], "dataid": [108, 109], "counter": [109, 191, 226, 270, 340, 406, 622], "request": [109, 201, 218, 251, 324, 330, 563, 611], "51": 109, "__len__": 110, "rank_kei": 114, "flat": [114, 385], "get_insert_index": 114, "themselv": [120, 619], "maybe_dens": 120, "maker": [120, 562, 619], "min_get": [120, 154, 159], "sort": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 222, 312], "another_act": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "discretebox": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "mutabl": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "action_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 620, 634], "had": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 624, 626], "all_act": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "any_don": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "_callabletransform": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180], "auto_specs_": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "observation_kei": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "action_spac": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 233, 297, 298, 313, 314, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 621, 622, 624, 628], "discrep": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 348, 350, 352, 353, 364, 367, 369], "broken": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180], "check_dtyp": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180], "rng": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 635], "revert": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 326, 332, 337, 375, 377, 379, 383, 624, 637], "accomplish": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 623, 630], "done_keys_group": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "another_don": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "done_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "empty_cach": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 194, 272], "env_batch_s": [120, 154, 159], "fake_tensordict": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 619, 622], "recip": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 338, 340, 347, 566], "afterward": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 338, 340, 347, 633, 640], "envnam": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "full_action_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 633, 634], "full_done_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "full_observation_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "full_reward_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "pipeline_st": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "full_state_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "input_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "is_spec_lock": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "maybe_reset": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "speak": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 227, 344, 618], "observation_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "output_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "register_gym": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 623], "entry_point": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "info_kei": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "reward_threshold": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "nondeterminist": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "max_episode_step": [120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "order_enforc": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "autoreset": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "disable_env_check": [120, 123, 126, 129, 130, 138, 145, 146, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 444, 448], "apply_api_compat": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "nasium": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 209], "dmcontrolenv": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 392, 442, 618, 623, 632, 640], "dmc": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "cheetah": [120, 123, 124, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 392, 618], "removeemptyspec": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 509], "threshold": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 301, 349, 350, 377, 379, 590, 620], "learnt": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 558], "checker": [120, 123, 126, 129, 130, 138, 145, 146, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "stepapicompat": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "deem": [120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180], "task_nam": [120, 123, 124, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 442], "envgym": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0855": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0215": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0881": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0412": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "1101": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0080": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0254": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0424": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "9609e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "02": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 280, 619, 628], "9776e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "04": [120, 123, 126, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 267, 280], "6347e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "03": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 246, 267], "3842e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5338e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "3064e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0381e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "6656e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "05": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 267, 367, 635], "0204e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0833": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0275": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0612": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0770": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "1256": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0082": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0186": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0476": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "2221": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "2256": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5930": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "6937": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5865": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5479": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0187": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "6825": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5224": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0018": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "1005": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0335": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 227], "0268": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0133": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0627": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0074": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0488": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0353": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0075": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0069": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0098": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0058": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0033": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0157": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0004": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 267], "0381": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0452": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "11355747": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "04257728": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "00408397": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "04155852": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0389733": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "01409826": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0978704": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "08808327": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "03970837": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "00535434": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "02353762": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "05116226": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "02788907": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "06848346": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "05154399": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0371798": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "05128025": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "selecttransform": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 516], "dydact": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "ant": [120, 121, 122, 123, 126, 130, 133, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 636], "gym_env": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 639], "reset_kei": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 258, 264, 265, 266, 521, 633], "multitask": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "multiag": [120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 350, 364, 367], "another_reward": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "reward_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "auto_cast_to_devic": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 634], "soon": [120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "__sort": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "as__": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "categorical_action_encod": [120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 209, 226, 441, 444, 448, 622], "argmaxmodul": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "argmax": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 298, 314, 622, 624], "n_ob": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 241, 340, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 625], "n_act": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 241, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 625], "ourselv": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 620, 640], "emul": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "input_td": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "rollout_td": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "state_kei": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "state_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "prevail": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 222, 258, 326], "newli": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "next_tensordict": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 218, 222, 234, 235, 236, 249, 252, 253, 259, 262, 275, 279, 590], "precomput": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "_stepmdp": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212], "exclude_act": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212], "retain": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "next_data": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "reset_data": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 190, 590, 640], "2106": [121, 122, 354, 371], "13281": [121, 122], "cache_clear_frequ": [121, 122, 441], "leak": [121, 122, 324], "frame_skip": [121, 122, 124, 125, 129, 130, 131, 132, 136, 137, 139, 140, 145, 146, 155, 180, 237, 406, 408, 418, 419, 441, 442, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 471, 495, 551, 618, 619, 620, 639], "allow_done_after_reset": [121, 122, 124, 125, 126, 129, 131, 132, 135, 136, 137, 145, 146, 148, 149, 155, 161, 162, 441, 442, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457], "toler": [121, 122, 124, 125, 129, 131, 132, 135, 136, 137, 145, 146, 148, 149, 155, 161, 162, 194, 295, 319, 324], "is_avail": [121, 122, 618, 619, 620, 621, 633, 634, 636], "els": [121, 122, 185, 218, 308, 611, 618, 619, 620, 621, 630, 631, 633, 634, 635, 636], "87": [121, 122], "acrobot": [121, 122, 124, 125, 640], "advant": [121, 122, 136, 137], "timer": [121, 122, 130, 136, 137, 180, 524], "timeit": [121, 122, 136, 137, 622], "310": [121, 122], "00": [121, 122, 217, 617, 638], "ms": [121, 122, 136, 137], "268": [121, 122], "433": [121, 122], "213": [121, 122], "8605": [121, 122], "pipelineenv": 122, "get_environ": 122, "san": 123, "fen": [123, 148, 149], "pgn": 123, "legal": [123, 215], "board": [123, 160], "include_san": 123, "algebra": [123, 635], "notat": 123, "include_fen": 123, "forsyth": 123, "edward": 123, "include_pgn": 123, "portabl": [123, 611, 627], "include_legal_mov": 123, "include_hash": 123, "hash": [123, 138, 179, 497], "mask_act": 123, "subset": [123, 635, 636], "29275": 123, "rnbqkbnr": [123, 148, 149], "pppppppp": [123, 148, 149], "kqkq": [123, 148, 149], "legal_mov": 123, "219": 123, "5p2": 123, "ppppp1pp": 123, "event": [123, 306, 310, 317, 637], "white": 123, "96": 123, "kq": 123, "5n2": 123, "rnbqkb1r": 123, "nf3": 123, "na6": 123, "c4": 123, "f6": 123, "h4": 123, "rb8": 123, "na3": 123, "ra": 123, "get_legal_mov": 123, "dm_control": [124, 125, 442, 618, 632, 640], "2006": [124, 125, 226, 349, 355], "12983": [124, 125], "240": [124, 125, 639], "swingup": [124, 125, 640], "swingup_spars": [124, 125], "ball_in_cup": [124, 125], "catch": [124, 125, 622], "balance_spars": [124, 125], "three_pol": [124, 125], "two_pol": [124, 125], "finger": [124, 125], "turn_easi": [124, 125], "turn_hard": [124, 125], "fish": [124, 125], "upright": [124, 125, 619], "swim": [124, 125], "hopper": [124, 125], "hop": [124, 125], "humanoid": [124, 125, 150, 158, 632], "walk": [124, 125, 150, 158, 619, 632], "run_pure_st": [124, 125], "bring_bal": [124, 125], "bring_peg": [124, 125], "insert_bal": [124, 125], "insert_peg": [124, 125], "point_mass": [124, 125], "reacher": [124, 125], "swimmer": [124, 125], "swimmer6": [124, 125], "swimmer15": [124, 125], "walker": [124, 125], "dog": [124, 125], "trot": [124, 125], "humanoid_cmu": [124, 125], "lqr": [124, 125], "lqr_2_1": [124, 125], "lqr_6_2": [124, 125], "quadrup": [124, 125], "escap": [124, 125], "stacker": [124, 125], "stack_2": [124, 125], "stack_4": [124, 125], "deviceless": 126, "run_type_check": [126, 144], "hint": 126, "counterenv": 126, "creator": [127, 553, 554, 560, 561, 562], "substitut": [127, 264, 279, 624], "vecnorm": [127, 280, 535, 536, 562], "test_env1": 127, "observation_count": [127, 640], "test_env2": 127, "ps": 127, "p1": 127, "p2": 127, "9934": 127, "make_vari": [127, 270], "variant": [127, 270], "trajcount": [127, 527], "env_creator_pendulum": 127, "env_creator_cartpol": 127, "env_str": 128, "device_map": 128, "asyncvectorenv": 129, "pixel_observ": [129, 131, 132, 155], "pixelobservationwrapp": [129, 131, 132, 155], "adventur": [129, 131], "airraid": [129, 131, 640], "alien": [129, 131], "time_limit": 129, "timelimit": [129, 142, 143, 163, 164], "default_info_dict_read": [129, 130, 131, 150, 180], "reader": [129, 130, 131, 150, 180, 619], "set_info_dict_read": [129, 130, 131, 150, 180, 623], "info_dict": [129, 130, 131, 150, 180], "gymlikeenv": [129, 131, 180], "auto_register_info_dict": [129, 130, 131, 150, 180], "multibinari": [129, 131], "multidiscret": [129, 131], "rag": [129, 131], "gym_conversion_exampl": [129, 131], "info_dict_read": [130, 150, 180], "ignore_priv": [130, 180], "baseinfodictread": [130, 180], "tensordictprim": [130, 150, 180, 287, 302, 304, 522, 621], "succe": [130, 150, 180, 585], "underscor": [130, 180], "primer": [130, 170, 171, 172, 175, 178, 180, 185, 194, 265, 287, 302, 304, 317, 621], "halfcheetah": [130, 150, 180, 214, 254, 618, 639], "reward_run": [130, 150, 180], "raise_if_clos": [130, 180], "fast_encod": [130, 180], "memoize_cach": [130, 180], "adaptive_autorang": [130, 180], "4f": [130, 180, 383, 620, 621, 635], "fp": [130, 180, 392, 397, 399], "10141": [130, 180], "5742fp": [130, 180], "10576": [130, 180], "8388fp": [130, 180], "read_act": [130, 180], "read_don": [130, 180], "nonsens": [130, 180], "fallback": [130, 180, 324], "read_ob": [130, 180], "dictat": [130, 180, 242, 341, 344, 367, 618, 635], "read_reward": [130, 180], "gym_lik": [130, 180], "hoc": [130, 150, 180, 624], "dict_read": [130, 180], "my_info_kei": [130, 180], "some_env": [130, 180], "vecenv": 131, "vectorenv": 131, "convert_actions_to_numpi": [131, 444, 448], "missing_obs_valu": [131, 278, 444, 448], "vecgymenvtransform": [131, 534], "secur": [132, 630], "habitat3": 132, "ai": [132, 636], "habitatrenderpick": 132, "isaacgym": [133, 134, 446], "isaacgymwrapp": 133, "isaacgymenv": [134, 446], "webpag": 134, "isaac": [134, 135], "essenc": [134, 623], "scripts_isaaclab": 135, "managerbasedrlenv": 135, "app": 135, "applaunch": 135, "argpars": [135, 559, 562], "argumentpars": 135, "add_app_launcher_arg": 135, "args_cli": 135, "hydra_arg": 135, "parse_known_arg": 135, "app_launch": 135, "isaaclab_task": 135, "f401": 135, "manager_bas": 135, "ant_env_cfg": 135, "antenvcfg": 135, "isaac_lab": 135, "cfg": [135, 462, 463, 466, 467, 468, 551, 552, 553, 554, 555, 556, 557, 558, 559, 562], "instadeepai": [136, 137], "2306": [136, 137, 280], "09884": [136, 137], "snake": [136, 137, 172], "grid": [136, 137, 392], "bodi": [136, 137], "body_st": [136, 137], "fruit_posit": [136, 137], "col": [136, 137], "row": [136, 137, 242], "head_posit": [136, 137], "tail": [136, 137], "game2048": [136, 137], "maze": [136, 137], "cleaner": [136, 137, 590, 631], "cvrp": [136, 137], "multicvrp": [136, 137], "minesweep": [136, 137], "rubikscub": [136, 137], "knapsack": [136, 137], "sudoku": [136, 137], "tsp": [136, 137], "connector": [136, 137], "mmst": [136, 137], "graphcolor": [136, 137], "partli": [136, 137], "scrambl": [136, 137], "robotwarehous": [136, 137], "tetri": [136, 137], "binpack": [136, 137], "jobshop": [136, 137], "0x1fca91910": 136, "122": [136, 137, 640], "40": [136, 137], "0x1ff9baee0": 136, "134": [136, 137], "0x1ff9ba7c0": 136, "172": [136, 137], "jit": 137, "eager": [137, 334], "tdreset": [137, 632], "whichev": 137, "mctsforest": [138, 179], "vocab_s": [138, 178, 179, 526, 611], "vocabulari": [138, 178, 179, 199, 269], "omit": [138, 179, 185, 286, 301, 312, 409, 620, 625, 635, 637], "hashing_modul": [138, 179], "siphash": [138, 179], "text_output": [138, 179], "batch_decod": [138, 179], "text_kei": [138, 179, 326, 329, 332, 337], "gpt2token": [138, 179], "input_id": [138, 178, 179], "make_tensordict": [138, 179], "mo": [139, 140], "minecart": [139, 140], "mo_gym": [140, 242], "marl": [141, 166, 221, 262, 266, 357, 370, 623, 633, 634], "group_map": [141, 142, 143, 148, 149, 152, 153, 161, 162, 163, 164, 166, 633], "constructiuon": [141, 152, 153], "premad": [141, 142, 143, 152, 153, 163, 164], "all_in_one_group": [141, 148, 149, 166], "agent_0": [141, 152, 153, 161, 166, 262], "agent_1": [141, 152, 153, 161, 166, 262], "agent_2": [141, 152, 153, 161, 166], "agent_3": [141, 161], "one_group_per_ag": [141, 152, 153], "meltingpot": [142, 143, 449], "2211": [142, 143], "13746": [142, 143], "melt": [142, 143], "pot": [142, 143], "novel": [142, 143, 625], "social": [142, 143], "situat": [142, 143, 178, 185], "familiar": [142, 143, 619, 630, 634, 640], "unfamiliar": [142, 143], "broad": [142, 143], "cooper": [142, 143, 633, 634], "decept": [142, 143], "reciproc": [142, 143], "stubborn": [142, 143], "substrat": [142, 143], "ml_collect": 142, "config_dict": 142, "configdict": 142, "horizon": [142, 143, 163, 164, 620], "infinit": [142, 143, 163, 164, 171, 172, 175, 185, 280, 626, 637], "categorical_act": [142, 143, 148, 149, 152, 153, 156, 157, 161, 162, 163, 164], "agent_nam": [142, 143, 163, 164, 166], "agent_names_to_indices_map": [142, 143, 163, 164], "env_torchrl": [142, 143], "commons_harvest__open": [142, 143], "rgb": [142, 143], "144": [142, 143, 190], "collective_reward": [142, 143], "ready_to_shoot": [142, 143], "88": [142, 143, 156, 157], "substrate_config": 143, "get_config": 143, "mp_env": 143, "build_from_config": 143, "default_player_rol": 143, "mymbenv": 144, "world_model": [144, 360], "hidden_observ": 144, "worldmodelwrapp": [144, 597], "activation_class": [144, 288, 290, 291, 292, 293, 299, 300, 305, 462, 463, 619, 624, 633, 634, 639], "relu": [144, 294, 307, 326, 332, 337, 597], "activate_last_lay": [144, 293, 305, 463], "sail": [145, 146], "sg": [145, 146], "10558": [145, 146], "readthedoc": [145, 148, 149], "en": [145, 148, 149], "python_interfac": 145, "envpoolmixin": 146, "env_bas": 146, "task_id": 146, "env_typ": 146, "gym_reset_return_info": 146, "envpool_env": 146, "www": [147, 306], "fetch_openml": 147, "dataset_nam": 147, "106": 147, "openspiel": [148, 149, 452], "open_spiel": [148, 149], "game_str": 148, "return_st": [148, 149, 152, 153], "4672": [148, 149], "current_play": [148, 149], "674": 148, "2048": [148, 149], "add_nois": [148, 149], "amazon": [148, 149], "backgammon": [148, 149], "restor": [148, 149, 590, 612], "td_restor": [148, 149], "pyspiel": 149, "load_gam": 149, "new_initial_st": 149, "3009": 149, "my_env_fun": [150, 158], "custom_attribute_list": [150, 158], "custom_attribut": [150, 158], "custom_method_list": [150, 158], "custom_method": [150, 158], "deploi": [150, 158, 218, 622], "share_individual_td": [150, 158], "shared_memori": [150, 158], "policy_proof": [150, 158], "ll": [150, 158, 226, 618, 619, 620, 621, 623, 624, 625, 626, 628, 630, 634, 640], "serial_for_singl": [150, 158, 619], "circular": [150, 158, 618], "daemon": [150, 158], "list_of_kwarg": [150, 158], "sharabl": [150, 158], "com_veloc": [150, 158], "head_height": [150, 158], "joint_angl": [150, 158], "torso_vert": [150, 158], "batched_pipe_timeout": 150, "stringent": [150, 620, 633, 634], "penv": [150, 270], "env_fix": 150, "influenc": 150, "thumb": [150, 620], "update_kwarg": [150, 158], "th": [151, 236, 274, 635], "thdot": [151, 635], "max_spe": [151, 635], "max_torqu": [151, 635], "dt": [151, 312, 635], "gen_param": [151, 635], "gravit": [151, 635], "torqu": [151, 635], "pettingzoo": [152, 153, 453, 633, 634], "pet": [152, 153], "zoo": [152, 153], "__": [152, 153], "aecenv": [152, 153], "dead": [152, 153], "done_on_ani": [152, 153, 633], "compulsori": [152, 153], "adversary_0": [152, 153], "adversari": [152, 153, 362, 633], "sisl": 152, "multiwalker_v9": 152, "aec": [152, 153], "n_piston": [152, 153], "pistonball_v6": [152, 153], "piston": [152, 153], "piston_0": [152, 153], "piston_1": [152, 153], "piston_20": [152, 153], "tictactoe_v3": [152, 153], "player": [152, 153, 160], "player_1": [152, 153], "player_2": [152, 153], "butterfli": 153, "_setup": [154, 159], "async_reset_send": [154, 159], "async_reset_recv": [154, 159], "vikashplu": 155, "wiki": 155, "06828": 155, "from_depth": 155, "smacv2": [156, 157, 455], "starcraft": [156, 157], "challeng": [156, 157, 623, 635, 636], "10gen_terran": [156, 157], "10gen_zerg": [156, 157], "10gen_protoss": [156, 157], "3m": [156, 157], "8m": [156, 157], "25m": [156, 157], "5m_vs_6m": [156, 157], "8m_vs_9m": [156, 157], "10m_vs_11m": [156, 157], "27m_vs_30m": [156, 157], "mmm": [156, 157], "mmm2": [156, 157], "2s3z": [156, 157], "3s5z": [156, 157], "3s5z_vs_3s6z": [156, 157], "3s_vs_3z": [156, 157], "3s_vs_4z": [156, 157], "3s_vs_5z": [156, 157], "1c3s5z": [156, 157], "2m_vs_1z": [156, 157], "corridor": [156, 157], "6h_vs_8z": [156, 157], "2s_vs_1sc": [156, 157], "so_many_banel": [156, 157], "bane_vs_ban": [156, 157], "2c_vs_64zg": [156, 157], "old": [156, 157, 272, 280, 364, 640], "smac": [156, 157], "map_nam": [156, 157], "176": [156, 157], "battle_won": [156, 157], "dead_al": [156, 157], "dead_enemi": [156, 157], "episode_limit": [156, 157], "322": [156, 157, 183], "procedur": [156, 157, 324], "distribution_config": [156, 157], "n_unit": [156, 157], "n_enemi": [156, 157], "team_gen": [156, 157], "dist_typ": [156, 157], "weighted_team": [156, 157], "unit_typ": [156, 157], "marin": [156, 157], "maraud": [156, 157], "medivac": [156, 157], "exception_unit_typ": [156, 157], "start_posit": [156, 157], "surrounded_and_reflect": [156, 157], "map_x": [156, 157], "map_i": [156, 157], "capability_config": [156, 157], "131": [156, 157], "starcraft2env": 157, "tic": 160, "tac": 160, "toe": 160, "single_play": 160, "player1": 160, "desired_batch_s": 160, "player0": 160, "uniti": [161, 162], "technolog": [161, 162], "llapi": [161, 162], "mlagents_env": [161, 162], "unityenviron": [161, 162], "file_nam": 161, "registered_nam": 161, "3dball": 161, "group_0": 161, "vectorsensor_size8": 161, "continuous_act": [161, 163, 164, 390, 633, 634], "agent_10": 161, "agent_11": 161, "agent_4": 161, "agent_5": 161, "agent_6": 161, "agent_7": 161, "agent_8": 161, "agent_9": 161, "group_reward": 161, "proroklab": [163, 164], "vectorizedmultiagentsimul": [163, 164], "2207": [163, 164], "03530": [163, 164], "basescenario": 163, "defaultt": 163, "sparsiti": 163, "unbatched_action_spec": [163, 164], "unbatched_observation_spec": [163, 164], "unbatched_reward_spec": [163, 164], "het_spec": [163, 164], "het_specs_map": [163, 164], "flock": [163, 164, 390], "agent_collision_rew": [163, 164], "agent_distance_rew": [163, 164], "ca": 166, "environment4": 166, "get_group_map": 166, "probabilist": [167, 241, 341, 348, 367, 597, 620, 639], "sumbodul": 169, "blank": [170, 590], "canva": [170, 590], "fundament": [170, 590, 626], "intention": [170, 590], "data_kei": [170, 171, 172, 175, 178, 194], "dialogu": 170, "klrewardtransform": [170, 188, 195, 196, 499, 590], "kl": [170, 188, 189, 195, 196, 241, 360, 364, 375, 379, 383, 590], "diverg": [170, 188, 189, 195, 196, 241, 341, 344, 360, 364, 379, 383, 590], "pythoninterpret": [170, 192, 590, 611], "dataloadingprim": [170, 171, 178, 194, 265, 590], "addthinkingprompt": [170, 590], "input_mod": [170, 171, 172, 174, 175, 195, 196, 326, 329, 332, 337, 590, 631], "system_prompt": [170, 171, 172, 175, 193, 590, 611, 630], "template_kwarg": [170, 171, 172, 175], "system_rol": [170, 590], "user_rol": [170, 590], "policy_rol": 170, "response_kei": 170, "datasetchatenv": 170, "gsm8kenv": [170, 171, 174, 181, 183, 590], "ifevalenv": [170, 171, 590], "response_data": 170, "next_ob": [170, 246, 385, 386, 387, 388, 639], "mont": [170, 171, 172, 175, 178, 185, 348, 350, 364, 367, 379, 382, 618], "carlo": [170, 171, 172, 175, 178, 185, 348, 350, 364, 367, 379, 382, 618], "pull": [171, 637], "rlhf": [171, 241, 379], "feedback": [171, 418, 590, 628, 639], "rlvr": 171, "batch_size_dl": [171, 172, 175, 181], "apply_templ": [171, 172, 175, 193, 630], "ray_backend": [171, 172, 175], "dataloader_actor_nam": [171, 172, 175], "thin": [171, 180], "chatenv": [171, 172, 175, 180, 186, 190, 193, 197, 588, 611, 630], "reset_dataload": [171, 172, 175, 185, 194], "set_missing_toler": [171, 172, 175, 194, 272], "gsm8k": [172, 173, 181, 590], "compute_reward": [172, 175], "gsm8k_dataload": 172, "3b": [172, 175, 183, 193, 324, 333, 334, 337], "question": [172, 175, 630, 637, 639], "bought": 172, "sandwich": 172, "he": 172, "paid": 172, "calcul": [172, 190, 197, 255, 348, 350, 355, 364, 367, 369, 371, 379, 385, 416], "breed": 172, "36": 172, "mari": 172, "saw": [172, 627, 635, 637], "reward_answ": [172, 174, 590], "reward_contain": [172, 174, 590], "reward_right": [172, 174, 590], "reward_think": [172, 174, 590], "snak": 172, "set_done_if_answ": [174, 177, 590], "make_gsm8k_env": 174, "sentenc": 174, "extract_tag": [174, 590], "xml": [174, 197, 203, 590], "ifev": [175, 177, 590], "ifeval_dataload": 175, "pprint": [175, 590], "instruction_id_list": [175, 177], "detectable_cont": 175, "number_placehold": 175, "num_highlight": 175, "num_": 175, "respond": 175, "plan": [175, 611], "week": 175, "europ": 175, "trip": 175, "london": 175, "rome": 175, "cap": [175, 620, 637], "restaur": 175, "prompt_level_strict_acc": [176, 177], "inst_level_strict_acc": [176, 177], "prompt_level_loose_acc": [176, 177], "inst_level_loose_acc": [176, 177], "instruction_ids_kei": 177, "keyword_args_kei": 177, "id_kei": 177, "response_column": 177, "score_kei": 177, "ifeval_scor": 177, "aggregate_reward": 177, "_scorer": 177, "ifevalscoredata": [177, 590], "format_weight": 177, "scorer": 177, "IF": 177, "co": [177, 233, 324, 635], "column": 177, "builder": [177, 181, 612, 619, 640], "think_block": 177, "answer_block": [177, 590], "langdetect": 177, "nltk": 177, "immutabledict": 177, "default_reward_aggreg": [177, 590], "tier": 177, "eo": [177, 337], "metric": [177, 350, 367, 379, 401, 407, 414, 416, 418, 419, 471, 618], "multipli": [177, 178, 185, 348, 349, 350, 351, 357, 364, 366, 367, 368, 370, 379, 411, 618, 633], "penalti": [177, 182, 188, 326, 332, 337, 362, 364, 375], "formula": [177, 241, 303, 320, 321, 348, 350, 364, 367, 379, 620], "format_scor": [177, 590], "quality_bonu": 177, "structure_multipli": 177, "complexity_scal": 177, "everyth": [177, 619, 620, 621, 627, 628], "incent": 177, "languag": [178, 590, 631], "tailor": [178, 639], "cot": [178, 590], "token_kei": 178, "str_kei": 178, "attention_kei": 178, "assign_reward": 178, "has_attent": 178, "assign_don": 178, "batchless": 178, "eos_token_id": [178, 332], "pretrainedtokenizerbas": [178, 199, 269], "stack_method": [178, 185, 194], "as_nested_tensor": [178, 185, 326, 332, 337], "bert": [178, 199, 269], "uncas": [178, 199, 269], "tokens_in": 178, "tokens_out": 178, "grpo": [178, 185, 375, 377, 379], "mlgym": [180, 182, 590], "get_library_nam": 180, "prisonersdilemma": 182, "reward_wrong_format": 182, "mlgymenv": [182, 590], "wrongli": 182, "cond": [183, 226, 227, 485], "random_prompt": 183, "edit_last_turn": 183, "zero_reward": 183, "undo_don": 183, "egocentr": 183, "reconsid": 183, "But": [183, 611, 632], "me": [183, 187, 190, 630], "wrong_answ": 183, "natalia": 183, "sold": 183, "48": 183, "friend": 183, "april": 183, "she": [183, 637], "72": 183, "altogeth": [183, 227], "undon": 183, "correct_answ": 183, "allowed_domain": [184, 630], "tool_nam": [184, 190, 193, 197, 203], "web": [184, 622, 630], "brows": [184, 630], "browser": [184, 190, 630], "click": [184, 630], "llm_tool": 184, "clean": [184, 324, 329, 401, 564, 566, 567, 569, 570, 572, 574, 577, 579, 585, 590, 611], "use_ray_servic": [185, 189, 195, 243], "mappabl": 185, "dataloader_factori": [185, 194], "unrel": 185, "dl": 185, "raydataloadingprim": 185, "endless_dataload": [185, 194], "set_capture_non_tensor_stack": 185, "dummydataload": 185, "generate_random_str": 185, "ascii_lowercas": 185, "__next__": 185, "zxwvupirska": 185, "stringa": 185, "zxwvupirsk": 185, "roll": 185, "init_st": 185, "nngcmflsana": 185, "vrrbnhzpmga": 185, "nngcmflsan": 185, "vrrb": 185, "dummytensordataload": 185, "max_length": [185, 199, 269, 622, 628], "generate_random_tensor": 185, "pad_tensor": 185, "padding_length": 185, "data_spec": 185, "toolregistri": 186, "llmtoolpars": [186, 197], "stop_on_error": 186, "pass_state_to_tool": 186, "pluggabl": 186, "xmlblockpars": [186, 197], "websearch": 186, "schema_in": [186, 201, 202], "schema_out": [186, 201, 202], "titl": [186, 620, 621, 622, 634, 635], "json": [187, 190, 630], "gen_log_probs_full_kei": [188, 195], "log_prob": [188, 195, 295, 306, 310, 321, 326, 329, 332, 337, 344, 351, 357, 370, 375, 377, 379, 383, 631], "ref_log_probs_full_kei": [188, 195], "ref_log_prob": [188, 195, 196, 375, 377, 379, 383], "kl_kei": [188, 195], "kl_penalti": [188, 195], "add_to_reward": [188, 195], "coeff": [188, 195, 350, 364, 367], "padding_sid": [188, 189, 195, 196, 306, 326, 332, 337], "retrievelogprob": [188, 189, 195, 383], "retrievekl": [188, 189, 196], "pad_output": [188, 195, 196, 326, 329, 332, 337, 631], "gen_log_prob": [188, 195], "pad_sequ": [188, 189, 195, 196], "next_td": [188, 195], "kl_transform": 188, "gen_log_probs_kei": 188, "ref_log_probs_kei": 188, "coef": [188, 241], "chathistori": [189, 195, 196, 330, 331, 332, 337], "ref_model": [189, 195, 196], "llmwrapperbas": [189, 195, 196, 332, 337, 379], "ref_model_factori": [189, 195], "assistant_onli": [189, 195, 196, 383], "upcom": [189, 195, 365, 375, 377, 379, 383, 618], "actor_nam": [189, 194, 195, 243, 329], "gen_model": [189, 195], "klcomput": [189, 195, 196], "tool_call_pattern": [190, 197], "mcp": 190, "npx": 190, "uvx": 190, "browsermcp": 190, "regex": [190, 197, 590], "tool_name_with_serv": 190, "args_json": [190, 197], "os": [190, 619, 631], "deno": 190, "deno_path": 190, "expandus": 190, "stdio": 190, "sqrt": [190, 312], "pi": [190, 622, 633, 634, 635], "run_python_cod": 190, "python_cod": 190, "linkedlist": 190, "successfulli": [190, 193, 581, 590, 630, 631], "textcont": 190, "nresult": 190, "141592653589793": 190, "return_valu": 190, "n15": 190, "annot": [190, 630], "curl": 190, "fssl": 190, "land": 190, "sh": 190, "version_typ": 191, "llmcollector": [191, 195, 326, 332, 337, 590], "tracker": [191, 240], "current_vers": 191, "uuid4": 191, "pool_siz": [192, 193, 611], "get_servic": [192, 193, 611], "python_executor": [192, 193, 611], "max_concurr": [192, 193, 329, 400, 611], "cleanup": [192, 324, 337, 567, 569, 570, 572, 577, 579, 585, 588], "robin": [192, 324, 430, 611], "stdout": 192, "stderr": 192, "returncod": 192, "service_nam": [193, 402, 611], "namespac": [193, 400, 402, 559, 562, 588], "tooltransformbas": 193, "boilerpl": 193, "inject": 193, "nprint": 193, "pythonexecutorservic": [193, 590, 611], "reus": [194, 290, 399, 590], "create_dataload": 194, "primer1": 194, "primer2": 194, "travers": 194, "missing_toler": [194, 199, 269], "reset_par": [194, 271], "set_contain": [194, 271], "ahead": [195, 640], "from_collector": 195, "get_new_vers": [195, 326, 329, 332, 337], "gen_model_factori": 195, "consciou": [195, 196], "identif": [195, 196], "history_kei": [195, 332, 337], "tokenizer_kwarg": [195, 196, 326, 332, 337, 383], "assit": [195, 196, 383], "rayretrievekl": 195, "optconfig": [195, 196, 383], "optforcausallm": [195, 196, 383], "weather": [195, 196, 383], "facebook": [195, 196, 383], "opt": [195, 196, 383], "125m": [195, 196, 383], "return_log_prob": [195, 196, 241, 283, 284, 285, 332, 337, 341, 344, 346, 369, 383, 466, 620, 624, 631, 633, 634, 639], "log_probs_kei": [195, 196, 326, 329, 332, 337], "chat_histori": [195, 196, 332, 337], "log_probs_full_kei": 196, "batchabl": 196, "tool_schema": 197, "mcptooltransform": [197, 590], "schema": [197, 202], "unknown": [197, 618], "use_raw_nontensor": [199, 239, 269, 273], "additional_token": [199, 269], "skip_special_token": [199, 269, 326, 331, 332, 337], "add_special_token": [199, 269], "return_attention_mask": [199, 269], "call_before_reset": [199, 269], "test_input_spec": [199, 273], "visibl": [200, 400, 401, 402, 588, 634], "label": [200, 618, 633, 637], "correl": [200, 312], "toolservic": 201, "addservic": 201, "optional_tag": 203, "nsome": 203, "list_of_tensordict": [204, 205], "unsqueeze_null_shap": 206, "dynamic_shap": 206, "model_bas": [207, 208], "dreamer": [207, 208, 299, 359, 360, 361], "model_based_env": [207, 359], "dreamerenv": [207, 359], "model_based_env_ev": 207, "spec_typ": 209, "convert_specnam": 209, "remap_state_to_observ": 209, "spectyp": 209, "unus": 209, "probabilistictdmodul": [210, 305, 341, 344, 408], "keep_oth": [212, 635], "exclude_reward": 212, "exclude_don": 212, "next_": 212, "mdp": [212, 623, 635], "write_full_fals": 213, "_terminated_or_trunc": 213, "num_interv": [214, 473], "out_action_kei": [214, 473], "samplingstrategi": 214, "optino": 214, "intenum": 214, "action_disc": 214, "qualnam": [214, 318, 373], "boundari": [214, 318, 347, 373, 620, 622, 633, 634], "masker": 215, "finit": [215, 235, 624, 637], "maskedenv": 215, "ones_lik": [215, 306], "scatter": 215, "fill_float": [217, 475], "fill_int": [217, 475], "fill_bool": [217, 475], "someenvclass": 217, "autoresetenv": 217, "fooenv": 217, "sign": [217, 260, 385, 633], "envtyp": 217, "3633e": 217, "4877e": 217, "2849e": 217, "7584e": 217, "6609e": 217, "6166e": 217, "8366e": 217, "2761e": 217, "5685e": 217, "4102e": 217, "8111e": 217, "9959e": 217, "0865e": 217, "5644e": 217, "2119e": 217, "2542e": 217, "9952e": 217, "4059e": 217, "2094e": 217, "9009e": 217, "5140e": 217, "3554e": 217, "2920e": 217, "7893e": 217, "6429e": 217, "3057e": 217, "2867e": 217, "6963e": 217, "3818e": 217, "2576e": 217, "2679e": 217, "1640e": 217, "6972e": 217, "0212e": 217, "5959e": 217, "4637e": 217, "3121e": 217, "2168e": 217, "5232e": 217, "7704e": 217, "7457e": 217, "4127e": 217, "1064e": 217, "0854e": 217, "5712e": 217, "2189e": 217, "5235e": 217, "8289e": 217, "0009e": 217, "0257e": 217, "8893e": 217, "5872e": 217, "9405e": 217, "7766e": 217, "0403e": 217, "0626e": 217, "2959e": 217, "7263e": 217, "2775e": 217, "9564e": 217, "0411e": 217, "6769e": 217, "6354e": 217, "8698e": 217, "1765e": 217, "6292e": 217, "5375e": 217, "1820e": 217, "7023e": 217, "5836e": 217, "9016e": 217, "4826e": 217, "6191e": 217, "6387e": 217, "8667e": 217, "2056e": 217, "1147e": 217, "5991e": 217, "0278e": 217, "5219e": 217, "3067e": 217, "6617e": 217, "3322e": 217, "2629e": 217, "4599e": 217, "7298e": 217, "5848e": 217, "0148e": 217, "5745e": 217, "6982e": 217, "7877e": 217, "3527e": 217, "7285e": 217, "6668e": 217, "0583e": 217, "6956e": 217, "3962e": 217, "9845e": 217, "5015e": 217, "5903e": 217, "9993e": 217, "9418e": 217, "0196e": 217, "6557e": 217, "2109e": 217, "8997e": 217, "1507e": 217, "7363e": 217, "0310e": 217, "9574e": 217, "8980e": 217, "0090e": 217, "reshape_fn": [218, 476, 622], "reset_func": [218, 476], "tensordict_batch_s": 218, "tensordict_reset": [218, 635], "biner": 219, "burn_in": [220, 478], "burn": 220, "burnt": 220, "grumodul": [220, 265, 597, 621], "gru_modul": [220, 302], "input_s": [220, 265, 302, 304, 621, 622], "hidden_s": [220, 265, 302, 304, 621, 622], "default_recurrent_mod": [220, 302, 304], "burn_in_transform": 220, "gru": [220, 265, 302, 622], "num_lay": [220, 302, 304, 308, 309, 622], "86": 220, "3008": 220, "37": 220, "0344": 220, "padding_valu": [221, 306, 326, 332, 337], "as_invers": 221, "movement": [221, 367], "propos": [221, 233, 621, 637], "pdf": [221, 289, 290, 291, 292, 293, 298, 312, 351, 358, 362, 368, 371, 385], "1312": 221, "5602": 221, "unsqueezetransform": [221, 530, 635, 637], "consumpt": 221, "pictur": 221, "pixels_trsf": [221, 637], "grayscal": [221, 496, 619, 621, 622, 637, 640], "data_exclud": [221, 637], "mitig": 221, "make_rb_transform_and_sampl": 221, "sampler_kwarg": 221, "redund": [221, 590, 621], "fly": [221, 279, 364, 590, 620, 635, 637, 640], "del_kei": [222, 262, 275, 632, 635], "unsqueeze_if_oor": 222, "observation_posit": 222, "observation_veloc": 222, "center": [223, 392, 547], "width": [223, 228, 254, 481, 486], "scalar": [224, 256, 286, 291, 293, 301, 312, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 385, 386, 387, 388, 407, 619, 625, 635], "rewardsc": [225, 272, 514, 618, 619, 621], "rewardclip": [225, 513], "transform_list": 225, "condition": 226, "switch": [226, 272, 280, 303, 321, 390, 611, 631], "unalt": 226, "criteria": [226, 332], "mod": [226, 241, 287, 302, 304, 326, 332, 337, 340, 344, 347, 375, 377, 379, 383, 621, 622, 628], "policy_switch": 226, "step_count_tot": 226, "step_count_main": 226, "0322": 226, "1540": 226, "0111": 226, "3190": 226, "0299": 226, "1544": 226, "0181": 226, "3280": 226, "0276": 226, "1550": 226, "0255": 226, "3414": 226, "0253": 226, "1558": 226, "0334": 226, "3596": 226, "0230": 226, "1569": 226, "0422": 226, "3828": 226, "0206": 226, "1582": 226, "0519": 226, "4117": 226, "1598": 226, "0629": 226, "4469": 226, "0156": 226, "1617": 226, "0753": 226, "4891": 226, "0130": 226, "1639": 226, "0895": 226, "5394": 226, "0104": 226, "1665": 226, "1058": 226, "5987": 226, "0076": 226, "1696": 226, "1246": 226, "6685": 226, "0047": 226, "1732": 226, "1463": 226, "7504": 226, "0016": 226, "1774": 226, "1715": 226, "8459": 226, "0020": 226, "0150": 226, "1884": 226, "6117": 226, "0017": 226, "2071": 226, "3838": 226, "0105": 226, "2115": 226, "5110": 226, "exectu": 227, "palliat": [227, 624], "inner_count": 227, "middle_env": 227, "middle_count": 227, "auto_unwrap": [227, 272, 403, 440], "9670": 227, "2546": 227, "9669": 227, "9802": 227, "1981": 227, "1601": 227, "9926": 227, "1214": 227, "5556": 227, "9994": 227, "7622": 227, "9984": 227, "0561": 227, "7933": 227, "9895": 227, "1445": 227, "7779": 227, "dtype_in": 229, "dtype_out": 229, "scan": [229, 232, 345, 346], "resp": [229, 232], "anticip": [229, 232], "not_transform": [229, 232], "orig_devic": 230, "unspecifi": 230, "num_actions_effect": 231, "max_act": 231, "include_forward": 231, "num_act": [231, 288, 357, 489, 622, 624], "action_out": 231, "inde": [231, 620, 622, 635], "eol_kei": [233, 491], "life": [233, 491, 636], "lives_kei": [233, 491], "eol_attribut": [233, 491], "breakout": 233, "210": [233, 248], "160": [233, 248], "eol_transform": 233, "eol": 233, "dqnloss": [233, 348, 349, 351, 352, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 373, 375, 377, 379, 383, 555, 604, 619, 621, 622, 628], "register_kei": 233, "loss_or_advantag": 233, "lossmodul": [233, 414, 418, 419, 557, 558, 604], "valueestimatorbas": [233, 365, 375, 377, 379, 383], "excluded_kei": 234, "first_dim": 236, "last_dim": 236, "allow_positive_dim": [236, 262, 274], "frameskip": 236, "repeatedli": [237, 620, 634], "hash_fn": 239, "repertoir": 239, "reproducible_hash": 239, "unarytransform": [239, 529], "observation_str": 239, "tobyt": [239, 273], "observation_hash": 239, "x08": 239, "x8b": 239, "xbexav": 239, "xbf": 239, "x00": 239, "xee": 239, "xb5": 239, "x17": 239, "x8f": 239, "xbe": [239, 273], "x88": 239, "xccu": 239, "xc0vr": 239, "get_input_from_hash": 239, "hash_tensor": 239, "bit": [239, 620, 621, 623, 633, 634, 637], "init_kei": [240, 340, 498], "log_prob_kei": [241, 329, 344], "sample_log_prob": [241, 283, 284, 285, 341, 344, 346, 367, 375, 377, 379], "pi_curr": 241, "pi_0": 241, "overfit": 241, "get_dist": [241, 326, 329, 332, 337, 344, 345], "frozen": [241, 279, 280], "normalparamextractor": [241, 283, 284, 285, 341, 346, 348, 349, 351, 357, 363, 367, 368, 369, 370, 371, 372, 597, 620, 624, 634, 639], "probabilisticactor": [241, 283, 284, 285, 348, 349, 351, 354, 356, 357, 363, 366, 367, 368, 369, 370, 371, 372, 597, 618, 620, 624, 633, 634], "tanhnorm": [241, 283, 284, 285, 341, 346, 348, 349, 351, 363, 367, 368, 369, 370, 371, 372, 466, 597, 620, 634, 639], "reward_kl": 241, "apply_": 241, "copy_": [241, 618], "mogymwrapp": 242, "mo_env": 242, "sea": 242, "treasur": 242, "so_env": 242, "module_factori": 243, "At": [243, 267, 301, 317, 619, 620, 621, 626, 632, 635, 636], "observation_spec_transform": 243, "done_spec_transform": 243, "reward_spec_transform": 243, "state_spec_transform": 243, "action_spec_transform": 243, "stack_reward": [244, 501], "stack_observ": [244, 501], "auto_batch_size_": 244, "macro": [244, 340], "trial": 245, "standard_norm": [246, 257, 279, 280, 504, 514, 618, 619, 621], "affin": [246, 257, 279, 280], "recover": 246, "set_default_tensor_typ": 246, "doubletensor": 246, "isclos": 246, "rubric": [246, 326, 332, 337, 346, 375, 377, 379, 383], "init_stat": [246, 618, 619, 620, 621], "3752e": 246, "5087e": 246, "9294e": 246, "9636": 246, "5608": 246, "6408": 246, "num_it": [246, 619, 620], "reduce_dim": [246, 618, 619, 620, 621], "cat_dim": [246, 618, 619, 620, 621], "keep_dim": [246, 340, 619, 621], "statist": [246, 279, 280, 324, 333, 369, 418, 419, 562, 618, 619, 620, 640], "gaussian": [246, 265, 286, 311, 620, 622, 633], "empir": [246, 341, 344, 618, 620, 634], "3d": 246, "reorder": 248, "in_keys_in": [248, 274], "channel": [248, 268, 308, 309, 619], "r3m": [250, 507, 636], "resnet": [250, 275, 277], "visual": [250, 275, 277, 392, 615, 620, 633, 635], "embed": [250, 275, 276, 277, 283, 284, 285, 290, 322, 339, 343, 344, 636], "ego4d": [250, 275, 277], "univers": [250, 275, 277, 332, 623], "suraj": [250, 275], "nair": [250, 275], "aravind": [250, 275], "rajeswaran": [250, 275], "vikash": [250, 275, 277], "kumar": [250, 275, 277], "chelsea": [250, 275], "finn": [250, 275], "abhinav": [250, 275], "gupta": [250, 275], "2203": [250, 275, 636], "12601": [250, 275, 636], "_init": [250, 275, 618], "resnet50": [250, 277, 636], "model_nam": [250, 275, 277, 324, 333, 334, 395, 507, 611], "resnet34": 250, "resnet18": [250, 507], "r3m_vec": [250, 636], "stack_imag": [250, 277], "tread": [250, 277], "hub": [250, 277, 623], "resnet50_weight": [250, 277], "imagenet1k_v1": [250, 277], "download_path": [250, 277], "tensor_pixels_kei": [250, 277], "sub_seq_len": 251, "sample_dim": [251, 618], "hesit": 251, "improp": 251, "dummyenv": 252, "another_oth": 252, "other_reward": 252, "create_copi": 253, "stuff": [253, 626], "newnam": 253, "gamma": [255, 348, 349, 351, 352, 353, 355, 357, 358, 359, 361, 363, 365, 367, 368, 369, 370, 371, 372, 373, 375, 377, 379, 383, 385, 386, 387, 388, 418, 470, 502, 512, 558, 604, 618, 619, 620, 633, 634, 639], "r2g": 255, "99": [255, 279, 361, 418, 502, 512, 535, 536, 544, 547, 558, 604, 618, 619, 620, 622, 625, 628, 633, 634, 639], "reward_to_go": 255, "bernoulli_": 255, "9010": 255, "9404": 255, "9701": 255, "9900": 255, "0000": [255, 266, 267, 301, 347], "clamp_min": [256, 513], "clamp_max": [256, 513], "clip_min": 256, "clip_max": 256, "episode_": 258, "reward1": 258, "reward2": 258, "episode_reward": [258, 633, 634], "keep_reward": 259, "keep_don": 259, "logical_or": 260, "in_key_inv": 262, "unstack": 262, "update_don": [263, 520], "disjunct": 263, "recognis": 263, "target_return": [264, 521], "default_valu": 265, "expand_spec": 265, "single_default_valu": 265, "call_before_env_reset": 265, "unit": [265, 299, 308, 309, 315, 316, 620], "scala": 265, "mykei": 265, "__unless": 265, "exists__": 265, "get_primers_from_modul": [265, 287, 302, 304], "recurrent_st": [265, 302, 304, 621], "10th": 266, "0216": 266, "1149": 266, "1990": 266, "2749": 266, "3281": 266, "9290": 266, "3702": 266, "8978": 266, "time_kei": [267, 524], "elaps": [267, 627], "monitor": [267, 324, 326, 332, 337, 350, 367, 416, 418, 564, 623], "expend": 267, "_polici": 267, "time_reset": 267, "time_polici": 267, "time_step": [267, 340], "0882": 267, "0002": 267, "5797e": 267, "6289e": 267, "7990e": 267, "0824e": 267, "0837e": 267, "6056e": 267, "2016e": 267, "1062e": 267, "7009e": 267, "from_int": [268, 525], "shape_toler": [268, 525], "ri": 268, "traj_count": [270, 527], "traj": 270, "countingenv": 270, "make_env_c0": 270, "make_env_c1": 270, "smoothli": 272, "add_1": 272, "cache_spec": [272, 440], "shown": [272, 590, 622, 630, 632, 633, 634, 637], "inv_fn": 273, "unari": 273, "durin": 273, "ommit": 273, "observation_trsf": 273, "xbc": 273, "x7f": 273, "x859": 273, "x81": 273, "x9a": 273, "xbd": 273, "xb8t8": 273, "test_output_spec": 273, "danger": 274, "vc1": [275, 531], "vc1_vec": 275, "untrain": 275, "make_noload_model": 275, "naiv": [275, 623], "vip": [276, 277, 532, 533, 636], "implicit": [277, 356, 363, 584, 637], "jason": 277, "ma": 277, "shagun": 277, "sodhani": 277, "dinesh": 277, "jayaraman": 277, "osbert": 277, "bastani": 277, "ami": 277, "zhang": 277, "vip_vec": 277, "final_nam": 278, "sb3": 278, "terminal_obs_read": 278, "vecnormv2": [279, 536], "new_api": [279, 280], "to_observation_norm": [279, 280], "frozen_copi": [279, 280], "shared_td": 279, "race": [279, 573], "decai": [279, 280, 286, 301, 411, 535, 536, 618, 619, 621, 640], "underflow": [279, 411], "build_td_for_shared_vecnorm": 279, "memmori": 279, "td_share": 279, "unfreez": [279, 280], "train_env": 279, "eval_env": 279, "9999": 280, "shared_data": 280, "reduce_batch_dim": 280, "varianc": [280, 303, 307, 320, 321, 367, 618, 620, 634], "weigh": 280, "_cast_int_to_float": 280, "env_trsf": 280, "observation_norm": 280, "reward_norm": [280, 411], "unnorm": [280, 306, 310], "7967": 280, "1238": 280, "5911": 280, "5275": 280, "8585": 280, "5028": 280, "2505": 280, "3169": [280, 347], "1332": 280, "1235": 280, "6596e": 280, "3072e": 280, "9170e": 280, "9255e": 280, "9131e": 280, "4671e": 280, "3760e": 280, "2058e": 280, "3484e": 280, "6185e": 280, "1456": 280, "1862": 280, "2053": 280, "2605": 280, "4046": 280, "5185": 280, "8023": 280, "1364": 280, "6183": 280, "5406": 280, "0920": 280, "1492": 280, "2702": 280, "3917": 280, "5001": 280, "7947": 280, "0160": 280, "3347": 280, "9082": 280, "9679": 280, "2199": 280, "2918": 280, "1668": 280, "2083": 280, "4981": 280, "5046": 280, "7950": 280, "9791": 280, "1484": 280, "4182": 280, "2201": 280, "0403": 280, "5206": 280, "7791": 280, "8282": 280, "2279": 280, "2907": 280, "4929": 280, "7793": 280, "8626": 280, "1832": 280, "local_env": 280, "testifi": 280, "4307": 280, "9613": 280, "state_dim": [281, 289, 294, 311, 315, 316], "action_dim": [281, 289, 290, 292, 294, 311, 618, 632], "gsde": [281, 368, 562], "gsdemodul": 281, "module_nam": [282, 365, 375, 377, 379, 383], "from_vers": 282, "to_vers": 282, "class_method": 282, "intersect": 282, "import_modul": 282, "get_class_that_defined_method": 282, "module_set": 282, "setters_dict": 282, "pyver": 282, "setter": 282, "setter_dict": 282, "actorvalueoper": [283, 350, 364, 367, 597, 624], "get_policy_oper": [283, 284, 285, 350, 364, 367], "standalon": [283, 284, 285, 622, 624], "tdmodul": [283, 284, 285, 558], "get_critic_oper": 283, "common_oper": [283, 285], "policy_oper": [283, 284, 285], "value_oper": [283, 284, 285], "valueoper": [283, 284, 285, 348, 349, 350, 351, 352, 357, 363, 364, 367, 368, 369, 370, 371, 372, 468, 558, 597, 604, 618, 620, 625], "module_hidden": [283, 285], "td_module_hidden": [283, 285], "safemodul": [283, 285, 344, 348, 349, 351, 356, 357, 363, 367, 368, 369, 370, 371, 372, 553, 554, 558, 597, 639], "module_act": [283, 285], "td_module_act": [283, 284, 285], "module_valu": [283, 284, 285], "td_module_valu": [283, 284, 285], "state_action_valu": [283, 322, 349, 351, 356, 363, 370, 558, 618, 633, 639], "td_modul": [283, 284, 285, 322, 339, 341, 343, 344, 346, 624, 639], "td_clone": [283, 284, 285], "tensordictmodulewrapp": [283, 553, 554, 558], "get_policy_head": [283, 284, 285], "safesequenti": [283, 284, 285], "head": [283, 285, 344, 350, 364, 367], "get_value_head": [283, 284, 285], "get_value_oper": [283, 284, 285, 350, 364, 367], "action_modul": 284, "actorcriticoper": [285, 597, 624], "actorcriticwrapp": [285, 597, 618], "po": 286, "sigma_init": [286, 633], "sigma_end": [286, 633], "annealing_num_step": [286, 301, 312, 618, 619, 621, 622, 624, 628, 633], "sigma": [286, 303, 312, 320, 321, 383, 620, 633], "omiss": [286, 301, 312], "consistentdropout": 287, "input_shap": 287, "batcht": 287, "make_tensordict_prim": [287, 302, 304, 621], "input_dtyp": 287, "get_default_dtyp": [287, 411], "mask_6127171760": 287, "seq": [287, 302, 304, 326, 332, 337, 340, 375, 377, 379, 383, 621, 622, 628, 632], "env0": [287, 640], "elu": [288, 290, 291, 292, 293, 299, 300, 619, 639], "activation_kwarg": [288, 305, 462, 463], "norm_class": [288, 290, 291, 305, 462, 463], "norm_kwarg": [288, 305, 462, 463], "bias_last_lay": [288, 290, 291, 292, 293, 300, 305, 462, 463], "aggregator_class": [288, 290, 291, 462, 619, 621, 639], "squashdim": [288, 290, 300, 597, 639], "aggregator_kwarg": [288, 290, 291, 462, 619, 621], "squeeze_output": [288, 290, 291, 462, 619, 621], "lazyconv2d": [288, 290, 291, 300], "cell": [288, 302, 304, 305, 620, 622, 623, 624, 625, 626, 627, 628], "cnet": 288, "34": [288, 305, 367], "35": [288, 305, 631], "default_atari_dqn": [288, 622], "semin": 288, "transformer_config": [289, 311], "decision_transform": [289, 311], "decisiontransform": [289, 311, 597], "dtconfig": [289, 294, 311], "2202": [289, 294, 366], "05607": [289, 294, 366], "return_to_go": [289, 294, 311], "conv_net_kwarg": [290, 291], "mlp_net_kwarg": [290, 291, 292], "use_avg_pool": [290, 291], "WITH": [290, 291, 292, 293, 312], "1509": [290, 291, 292, 293, 312, 353], "02971": [290, 291, 292, 293, 312], "maximis": [290, 292, 619, 620, 634], "ndims_in": [290, 338], "avgpool": [290, 291], "lazylinear": [290, 291, 292, 293, 300, 305, 620, 624, 635, 636], "2304": 290, "adaptiveavgpool2d": [291, 619, 621], "output_s": [291, 619, 621], "squeeze2dlay": 291, "400": [292, 293, 634], "mlp_net_kwargs_net1": 293, "mlp_net_kwargs_net2": 293, "mlp1": 293, "mlp2": 293, "desdescrib": 294, "n_embd": 294, "n_layer": 294, "n_head": 294, "n_inner": 294, "n_posit": 294, "resid_pdrop": 294, "attn_pdrop": 294, "gpt2config": 294, "atol": [295, 319], "rtol": [295, 319], "batch_shap": [295, 310, 319], "event_shap": [295, 319], "absolut": [295, 319, 618], "_instanc": 295, "densiti": [295, 306, 310, 321], "mass": [295, 306, 310, 321, 635], "rsampl": [295, 310, 344], "sample_shap": [295, 306, 310], "softmax": [296, 297, 298, 310], "qvaluemodul": [297, 313, 621, 622, 624, 628], "distributionaldqnnet": [297, 597], "make_log_softmax": 297, "character": [297, 313, 339, 341, 343, 637], "overflow": [297, 298, 313, 314, 320, 339, 341, 343, 344], "var_num": [297, 298, 314], "mult": [297, 298, 313, 314], "action_value_kei": [297, 298, 313, 314, 351, 365, 375, 377, 379, 383], "action_mask_kei": [297, 298, 301, 313, 314], "nbin": 297, "log_softmax": 297, "qvalue_actor": [297, 313], "greedi": [298, 301, 314, 326, 332, 337, 597, 619, 621, 622, 624], "1707": [298, 358, 367], "06887": [298, 358], "my_action_valu": [298, 314], "chanc": 298, "std_bia": 299, "std_min_val": 299, "belief": [299, 308, 315, 316, 317], "1912": [299, 359, 360, 361], "01603": [299, 359, 360, 361], "softplu": [299, 307], "out_features_valu": 300, "cnn_kwarg": [300, 619], "mlp_kwarg": [300, 619], "duel": [300, 597], "cnn": [300, 619, 622, 624, 639], "06581": 300, "eps_init": [301, 312, 619, 621, 622, 624, 628], "eps_end": [301, 312, 619], "explorative_polici": [301, 312], "9055": 301, "9277": 301, "6295": 301, "2532": 301, "grad_fn": [301, 339, 344], "addbackward0": 301, "embedd": [302, 304], "grucel": [302, 343], "python_bas": [302, 304], "custom_kei": [302, 304], "hasn": [302, 304], "set_recurrent_mod": [302, 304, 621], "recurrent_mod": [302, 304], "rnn": [302, 304, 357, 370, 385, 621, 622, 624], "rs": [302, 618], "gru_module_train": 302, "policy_train": [302, 383], "traj_td": 302, "make_cudnn_bas": [302, 304], "make_python_bas": [302, 304, 622], "supplementari": [302, 304, 620, 640], "That": [302, 304, 620, 633], "dealt": [302, 304], "poorli": [302, 304], "meth": [302, 304, 365, 635], "lstmmodul": [302, 597, 621, 622], "data_collector": [302, 304, 619], "upscal": [303, 320, 321], "tanh_loc": [303, 320, 321], "event_dim": [303, 319, 320], "poor": [303, 320, 321], "explos": [303, 320, 321], "lstmcell": [304, 622], "b_ih": 304, "b_hh": 304, "recurrent_state_h": 304, "recurrent_state_c": 304, "triplet": [304, 313, 314], "lstm_modul": 304, "rs_h": 304, "rs_c": 304, "single_bias_last_lay": [305, 463], "layer_class": [305, 463], "layer_kwarg": [305, 463], "perceptron": [305, 463, 624], "noisylinear": [305, 619], "noisylazylinear": 305, "neg_inf": 306, "inf": 306, "use_cross_entropi": 306, "api_doc": 306, "tf_agent": 306, "sparse_mask": 306, "cross_entropi": 306, "1203": 306, "0928": 306, "0831": 306, "1972": 306, "entropi": [306, 310, 348, 349, 350, 351, 356, 357, 363, 364, 366, 367, 368, 370, 371, 372, 375, 376, 378, 379, 380, 381, 418, 419, 634], "scale_map": [307, 466], "biased_softplus_1": [307, 466], "scale_lb": [307, 315, 316, 466], "normal_param": 307, "1803": [308, 309], "10122": [308, 309], "rnn_hidden": 308, "latent": [309, 317], "grad_method": 310, "reparamgradientstrategi": [310, 597], "passthrough": 310, "relaxedonehot": 310, "inres": 311, "mu": [311, 312, 620], "ornstein": [312, 597, 618, 622], "uhlenbeck": [312, 597, 618, 622], "ou": [312, 618], "noise_t": 312, "noise_": 312, "theta": [312, 620, 635], "sigma_t": 312, "sigma_": 312, "ou_prev_nois": 312, "ou_step": 312, "x0": 312, "sigma_min": 312, "n_steps_ann": 312, "is_init_kei": 312, "_ou_prev_nois": 312, "_ou_step": 312, "tensordict_modul": [313, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 351, 352, 356, 357, 363, 367, 368, 369, 370, 371, 372], "chose": 314, "hidden_dim": [315, 316], "posterior": [315, 317, 360], "rssm": [315, 316, 317, 360], "1811": [315, 316, 317], "04551": [315, 316, 317], "obs_embed": 315, "rnn_hidden_dim": 316, "dream": 316, "rssm_prior": 317, "rssm_posterior": 317, "s_": [317, 590, 630], "s_t": 317, "a_t": 317, "b_t": 317, "a_": 317, "evid": 317, "o_t": 317, "b_": 317, "o_": 317, "amend": 317, "safe_tanh": 320, "tanhtransform": 320, "get_mod": [320, 344], "custommodul": 322, "imaginari": 323, "imagin": 323, "transition_model": 323, "reward_model": 323, "get_reward_oper": 323, "get_transition_model_oper": 323, "engine_arg": 324, "asyncenginearg": [324, 333], "num_replica": [324, 333, 337, 578, 585, 590], "actor_class": 324, "enable_prefix_cach": 324, "replica": [324, 333, 337, 585], "placement": 324, "samplingparam": 324, "num_devic": [324, 333, 334], "max_model_len": 324, "4096": 324, "sampling_param": [324, 333], "temperatur": [324, 326, 332, 337, 349, 356, 363], "max_token": [324, 326, 332, 337], "tensor_parallel_s": [324, 333], "actor_index": 324, "fault": 324, "resili": 324, "collective_rpc": [324, 581], "create_load_balanc": 324, "kv": 324, "loadbalanc": 324, "rout": 324, "smart": 324, "lb": 324, "selected_actor_index": 324, "select_actor": 324, "prefix_length": 324, "overload_threshold": 324, "enable_fp32_output": [324, 333, 334], "fp32": [324, 333, 334], "prompt_token_id": 324, "use_tqdm": 324, "lora_request": 324, "prompt_adapter_request": 324, "guided_options_request": 324, "timeout_second": 324, "requestoutput": 324, "tokensprompt": 324, "lora": 324, "get_cache_usag": 324, "fraction": [324, 348, 350, 367], "get_master_address": 324, "get_master_port": 324, "get_num_unfinished_request": 324, "unfinish": 324, "get_random_actor_index": 324, "init_weight_update_group": 324, "asyncvllmengineservic": 324, "asyncllmengin": 324, "parameter_nam": 324, "to_text": [325, 331], "to_token": [325, 330], "logprob": [326, 332, 337, 631], "input_kei": [326, 332, 337, 631], "attention_mask_kei": [326, 332, 337], "generate_kwarg": [326, 329, 332, 337, 631], "max_new_token": [326, 329, 332, 337, 631], "num_return_sequ": [326, 332, 337], "top_p": [326, 332, 337], "nucleu": [326, 332, 337], "top_k": [326, 332, 337], "repetition_penalti": [326, 332, 337], "do_sampl": [326, 332, 337], "num_beam": [326, 332, 337], "beam": [326, 332, 337], "length_penalti": [326, 332, 337], "early_stop": [326, 332, 337], "stop_sequ": [326, 332, 337], "win": 326, "pad_model_input": [326, 332, 337], "num_sampl": [326, 329, 332, 337], "tokens_kei": [326, 329, 332, 337], "masks_kei": [326, 329, 332, 337], "ref_batch": [326, 332, 337], "min_batch_s": [326, 332, 337], "max_batch_s": [326, 332, 337], "batching_timeout": [326, 332, 337], "ref_transformers_wrapp": [326, 337], "ref_vllm_wrapp": [326, 332], "cleanup_batch": [326, 329, 332, 337], "flush": [326, 332, 337], "cancel": [326, 332, 337], "pend": [326, 332, 337, 571], "_batch_queu": [326, 332, 337], "tensordict_out": [326, 332, 337, 640], "logits_onli": [326, 332, 337], "get_batching_st": [326, 329, 332, 337], "logits_kei": [326, 332, 337], "llmmaskedcategor": 326, "alter": [326, 329, 332, 337, 340, 365], "is_tdmodule_compat": [326, 332, 337, 375, 377, 379, 383], "weak": [326, 332, 337], "reset_out_kei": [326, 332, 337, 375, 377, 379, 383], "select_out_kei": [326, 332, 337, 348, 349, 351, 352, 356, 357, 363, 367, 368, 370, 371, 372, 375, 377, 379, 383, 622], "reset_parameters_recurs": [326, 332, 337, 365, 375, 377, 379, 383], "old_param": [326, 332, 337], "bork": [326, 332, 337], "dork": [326, 332, 337], "reset_paramet": [326, 332, 337], "complic": [326, 332, 337, 375, 377, 379, 383, 635, 637, 640], "out_keys_sourc": [326, 332, 337, 375, 377, 379, 383], "z": [326, 332, 337, 375, 377, 379, 383], "all_attention_mask": [328, 332, 337, 631], "all_assistant_mask": [328, 332, 337, 631], "validate_model": 329, "automodelforcausallm": [329, 332, 631], "remote_wrapp": 329, "tensordict_input": 329, "dist_params_kei": 329, "dist_sample_kei": 329, "get_dist_with_prompt_mask": [329, 337], "to_histori": [330, 331], "wast": 332, "simpler": [332, 579, 619, 623, 631], "unsur": 332, "overlong": 332, "tokenization_util": [332, 337], "output_scor": 332, "discourag": [332, 337, 620, 635], "pad_token_id": 332, "bad_words_id": 332, "force_words_id": 332, "no_repeat_ngram_s": 332, "gram": 332, "encoder_repetition_penalti": 332, "repetit": [332, 620, 623, 626], "num_beam_group": 332, "diversity_penalti": 332, "return_dict_in_gener": 332, "ref_categorical_sequenti": [332, 337], "repeat_interleave_caus": 332, "sequence_length": 332, "_create_block_diagonal_attention_mask": 332, "causal": 332, "data_parallel_s": 333, "pipeline_parallel_s": 333, "_model": [333, 334], "make_ray_work": 334, "enforce_eag": 334, "rayllmwork": 334, "localllmwrapp": 334, "world_siz": [335, 336, 578, 585], "statelessprocessgroup": [335, 336], "plane": [335, 336], "pyncclcommun": [335, 336], "async_engin": 337, "presence_penalti": 337, "frequency_penalti": 337, "ignore_eo": 337, "prompt_logprob": 337, "detoken": 337, "include_stop_str_in_output": 337, "spaces_between_special_token": 337, "sampling_typ": 337, "temperature_last": 337, "top_p_last": 337, "top_k_last": 337, "assistant_mask_kei": 337, "set_token": 337, "translat": [339, 341], "3635": 339, "0340": 339, "1476": 339, "3911": 339, "1664": 339, "5455": 339, "2247": 339, "4583": 339, "2916": 339, "2160": 339, "5337": 339, "5193": 339, "addmmbackward0": 339, "lookahead": 340, "window": [340, 633, 637, 639], "n_action": [340, 349, 351, 353, 355, 366, 370], "reshape_cat": 340, "actor_bas": 340, "obs_cat": 340, "obs_cat_reshap": 340, "action_orig": 340, "multistepenvwrapp": 340, "ego": 340, "default_interaction_typ": [341, 344, 624], "interaction_typ": [341, 344], "set_interaction_typ": [341, 344], "compositedistribut": [341, 344, 348, 367, 624], "distribution_map": [341, 344], "name_map": [341, 344], "distribution_kwarg": [341, 344, 620, 633, 634], "cache_dist": [341, 344], "n_empirical_estim": [341, 344], "compound": [341, 624], "cube": 342, "functionalmodul": 343, "functionalmodulewithbuff": 343, "td_fmodul": 343, "td_function": 343, "td_state": 343, "params_repeat": 343, "td_vmap": [343, 346], "random_sampl": [343, 344], "suppli": 344, "paliat": 344, "get_median": 344, "get_mean": 344, "sample_key_nam": 344, "_log_prob": 344, "composite_lp_aggreg": 344, "induc": 344, "clampbackward0": 344, "anihil": 344, "probabilistictensordictsequenti": [345, 348, 350, 364, 367, 369, 553, 554, 639], "partial_toler": [345, 346, 632], "AND": [345, 346, 351], "tensordictsequ": 346, "safeprobabilisticmodul": 346, "spec1": 346, "net1": 346, "module1": 346, "td_module1": 346, "spec2": 346, "module2": 346, "td_module2": 346, "9944": 347, "9991": 347, "3020": 347, "2299": 347, "5418": 347, "2989": 347, "6849": 347, "2690": 347, "9649": 347, "5686": 347, "8602": 347, "0315": 347, "8455": 347, "6027": 347, "4746": 347, "7843": 347, "7782": 347, "2111": 347, "5115": 347, "4687": 347, "5760": 347, "1602": 348, "01783v2": 348, "entropy_bonu": [348, 350, 364, 367, 379, 470, 620], "favour": [348, 350, 364, 367, 379], "samples_mc_entropi": [348, 350, 364, 366, 367, 379, 470], "entropy_coeff": [348, 350, 364, 367, 379, 470], "critic_coeff": [348, 350, 364, 367, 470], "loss_critic_typ": [348, 350, 364, 367, 369, 470, 620], "l1": [348, 350, 352, 353, 357, 364, 367, 368, 369, 371, 372, 618], "l2": [348, 350, 352, 353, 354, 355, 357, 360, 361, 364, 367, 368, 369, 371, 372, 618, 633], "smooth_l1": [348, 349, 350, 351, 352, 353, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 470, 620], "separate_loss": [348, 350, 351, 352, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 470], "advantage_kei": [348, 350, 364, 367, 369, 379, 382, 385, 386, 387, 388, 470], "value_target_kei": [348, 350, 364, 367, 369, 385, 386, 387, 388, 470], "value_target": [348, 350, 364, 367, 369, 385, 386, 387, 388, 620, 634], "ddp": [348, 350, 364, 367, 369], "fsdp": [348, 350, 364, 367, 369], "divid": [348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 379, 551, 618, 633, 634, 635], "clip_valu": [348, 350, 364, 367, 369, 379, 470], "loss_crit": [348, 367, 620, 634], "loss_entropi": [348, 367, 376, 378, 380, 381, 620, 634], "loss_object": [348, 367, 376, 378, 380, 381, 620, 634], "recur": [348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 385, 386, 387, 388, 389, 624], "next_reward": [348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 385, 386, 387, 388], "next_don": [348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 385, 386, 387, 388], "next_termin": [348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 385, 386, 387, 388], "loss_obj": 348, "next_observ": [348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 632], "sacloss": [348, 413, 419, 604], "default_kei": [348, 349, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 366, 367, 368, 369, 370, 371, 372, 383, 389], "_acceptedkei": [348, 349, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 389], "make_value_estim": [348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 373, 375, 377, 379, 383, 618, 619, 633, 634, 639], "value_typ": [348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 618], "hyperparam": [348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 618], "enum": [348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 618], "default_value_estim": [348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 618, 639], "default_value_kwarg": [348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 618], "dqn_loss": [348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 373, 375, 377, 379, 383], "td1": [348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 618], "cql": [349, 355], "conserv": [349, 355], "qvalue_network": [349, 351, 356, 357, 363, 368, 370, 371, 372, 413, 419], "unti": [349, 351, 363, 368, 370, 371, 372], "loss_funct": [349, 351, 352, 353, 354, 355, 356, 357, 363, 368, 370, 371, 372, 383, 618, 633], "alpha_init": [349, 351, 357, 366, 368, 370], "min_alpha": [349, 351, 357, 366, 368, 370], "max_alpha": [349, 351, 357, 366, 368, 370], "fixed_alpha": [349, 351, 357, 366, 368, 370], "target_entropi": [349, 351, 357, 366, 368, 370], "prod": [349, 351, 366, 370], "delay_actor": [349, 352, 370, 371, 372], "delay_qvalu": [349, 357, 368, 370, 371, 372], "min_q_weight": 349, "max_q_backup": 349, "backup": 349, "deterministic_backup": 349, "num_random": 349, "with_lagrang": 349, "lagrang": 349, "lagrange_thresh": 349, "deactivate_vmap": [349, 351, 357, 363, 368, 370, 371, 372, 385, 386, 387, 388], "valueclass": [349, 351, 352, 357, 368, 370, 371, 372], "qvalu": [349, 351, 356, 357, 363, 368, 370, 371, 372], "loss_actor": [349, 351, 352, 356, 357, 363, 368, 369, 370, 371, 372, 409, 618, 633], "loss_actor_bc": 349, "loss_alpha": [349, 351, 357, 368, 370], "loss_cql": [349, 355], "loss_qvalu": [349, 351, 355, 356, 357, 363, 368, 370, 371, 372], "loss_alpha_prim": 349, "ess": [350, 367, 375, 376, 378, 379, 380, 381], "coupl": [350, 367, 583, 621, 624, 625, 635, 637], "clip_epsilon": [350, 379, 620, 634], "head_nam": [350, 364, 367], "ppo_entropy_coeffici": [350, 364, 367], "normalize_advantag": [350, 364, 367, 470, 634], "normalize_advantage_exclude_dim": [350, 364, 367, 470], "multiobject": [350, 364, 367], "value_kei": [350, 364, 367, 385, 386, 387, 388, 470, 618], "somemodul": [350, 364, 367], "actor_head": [350, 364, 367], "someactor": [350, 364, 367], "value_head": [350, 364, 367], "somevalu": [350, 364, 367], "crossq": 351, "IN": 351, "FOR": 351, "simplic": [351, 619, 620, 626, 636, 637, 639], "openreview": [351, 368], "pczqttstix": 351, "qvalue_loss": [351, 371], "actor_loss": [351, 371], "alpha_loss": [351, 357, 370], "num_qvalue_net": [351, 356, 357, 363, 368, 370, 371, 372], "maybe_init_target_entropi": 351, "fault_toler": 351, "target_entropy_buff": 351, "delay_valu": [352, 353, 355, 358, 369, 370, 619, 621, 622, 628, 633], "loss_valu": [352, 356, 363, 369, 370, 618, 620, 633, 634], "pred_valu": [352, 355, 371, 372, 618], "pred_value_max": [352, 618], "target_valu": [352, 355, 368, 371, 372, 618], "target_value_max": [352, 618], "qvalueactor": [353, 355, 619, 621], "double_dqn": 353, "06461": 353, "mult_one_hot": [353, 356, 357], "loss_val": [353, 355, 383, 604, 618, 620, 621, 622, 625, 626, 628, 633, 634, 637], "01345": 354, "distanc": [355, 364, 385, 634], "dcql_loss": 355, "iql": [356, 363, 618, 633, 634], "2110": [356, 363], "06169": [356, 363], "expectil": [356, 363], "tau": [356, 363, 618, 619, 633], "antmaz": [356, 363], "sticht": [356, 363], "onehotcategor": [356, 357, 597], "target_entropy_weight": 357, "skip_done_st": [357, 370], "disctount": 358, "distributionalqvalueactor": 358, "input_tensordict": [358, 618], "actor_model": 359, "imagination_horizon": 359, "unrol": 359, "discount_loss": [359, 361], "lambda_kl": 360, "lambda_reco": 360, "lambda_reward": 360, "reco_loss": 360, "reward_loss": 360, "free_nat": 360, "nat": 360, "delayed_clamp": 360, "global_averag": 360, "value_loss": 361, "fake_data": 361, "gail": 362, "1606": 362, "03476": 362, "discriminator_network": 362, "use_grad_penalti": 362, "gp_lambda": 362, "discrimin": 362, "qvalueclass": 363, "loss_value_diff": 363, "diff": 363, "old_polici": 364, "new_polici": 364, "apart": [364, 634], "dtarg": 364, "samples_mc_kl": 364, "analyt": 364, "decrement": 364, "loss_": [365, 409, 604, 618, 625], "equip": [365, 621, 622, 624], "gh": 365, "_forward_value_estimator_kei": 365, "value_estim": [365, 375, 377, 379, 383, 385, 386, 387, 388, 389, 618, 634], "myloss": 365, "action2": 365, "augment": [365, 590, 626, 628, 637], "set_exploration_typ": [365, 408, 620, 621, 622, 624, 633, 639], "deterministic_sampling_mod": 365, "convert_to_funct": [365, 375, 377, 379, 383, 618], "expand_dim": [365, 375, 377, 379, 383], "create_target_param": [365, 375, 377, 379, 383, 618], "compare_against": [365, 375, 377, 379, 383, 618], "isol": [365, 375, 377, 379, 383, 400, 402, 585, 588, 622], "_param": [365, 375, 377, 379, 383], "resampl": [365, 375, 377, 379, 383], "_target_param": [365, 375, 377, 379, 383], "from_stateful_net": [365, 375, 377, 379, 383], "network_nam": [365, 375, 377, 379, 383], "stateful_net": [365, 375, 377, 379, 383], "get_stateful_net": [365, 375, 377, 379, 383], "Such": [365, 375, 377, 379, 383], "blend": [365, 375, 377, 379, 383], "vmap_random": [365, 374, 375, 377, 379, 383], "add_random_modul": [365, 375, 377, 379, 383, 604], "proxim": [367, 418, 471, 620, 634], "flavor": [367, 618, 633, 634, 639], "clipppoloss": [367, 604, 620, 634], "klpenppoloss": [367, 604], "06347": 367, "log_explained_vari": [367, 470], "explain": [367, 622, 636], "explained_vari": 367, "wors": 367, "gae": [367, 418, 471, 604, 618, 620, 634], "ppo_loss": 367, "tdlambda": [367, 618], "base_lay": 367, "action_log_prob": 367, "randn_lik": 367, "kl_approx": [367, 376, 378, 380, 381], "samplelogprob": 367, "gripper": 367, "composite_entropi": 367, "0234": 367, "set_composite_lp_aggreg": [367, 634], "redq": 368, "ay8zfzm0tdd": 368, "sub_sample_len": 368, "subsampl": [368, 404], "action_log_prob_actor": 368, "state_action_value_actor": [368, 371, 372], "connectionist": 369, "william": 369, "1992": 369, "doi": 369, "1007": 369, "bf00992696": 369, "actor_net": [369, 618, 620], "1801": 370, "01290": 370, "1812": 370, "05905": 370, "minimalist": 371, "06860": 371, "policy_nois": [371, 372], "noise_clip": [371, 372], "td3_bc": 371, "bc_loss": 371, "lmbd": 371, "next_state_valu": [371, 372], "td0": [373, 618, 633], "cispo": 375, "eps_low": [375, 379], "eps_high": [375, 379], "minimax": 375, "m1": 375, "llmoutputtyp": [375, 377, 379], "output_typ": [375, 377, 379], "cispolossoutput": [375, 588], "tensor_kei": [375, 377, 379, 385, 386, 387, 388, 389], "grpoloss": [375, 377, 588, 590], "my_advantage_kei": [375, 377, 379], "clip_fract": [376, 378, 380, 381], "loss_kl_to_ref": [376, 378, 380, 381, 383, 384], "kl_to_ref": [376, 378, 380, 381, 384], "loss_kl_to_infer": [376, 378, 380, 381], "kl_to_infer": [376, 378, 380, 381], "asymmetr": [377, 379], "eq": [377, 379], "dapolossoutput": [377, 588], "instabl": 379, "diagnost": 379, "masking_strategi": 379, "sft": [379, 383], "surrog": 379, "symmetr": 379, "dapo": [379, 588], "kl_mask_threshold": 379, "pi_theta": 379, "pi_ref": 379, "drift": 379, "token_mean": 379, "prompt_mean": 379, "kl_to_ref_coeff": [379, 383], "kl_to_inference_coeff": 379, "grpolossoutput": [379, 382, 588], "grpo_siz": 382, "hit": 382, "supervis": [383, 625, 626, 637, 640], "normalize_by_seq_length": 383, "minor_sft": 383, "minorsft": 383, "shime": 383, "xie": 383, "hong": 383, "chen": 383, "fred": 383, "yu": 383, "zey": 383, "sun": 383, "xiuyu": 383, "wu": 383, "2024": 383, "minor": [383, 633], "_chat_templ": 383, "policy_ref": 383, "txt_start": 383, "zip": [383, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "loss_sft": [383, 384], "1506": 385, "02438": 385, "exponenti": [385, 386, 387, 388, 411], "lmbda": [385, 388, 418, 618, 620, 634], "average_ga": [385, 620], "skip_exist": [385, 386, 387, 388], "get_default_devic": [385, 386, 387, 388, 389], "time_dim": [385, 387, 388], "auto_reset_env": 385, "next_valu": [385, 386, 387, 388, 389], "gradient_mod": 385, "value_error": [385, 386, 387, 388, 389], "marker": [385, 618], "trajecotri": 385, "fair": 385, "target_param": [385, 386, 387, 388, 389, 618, 634], "98": [385, 386, 387, 388], "94": [385, 388], "unpack": [385, 386, 387, 388], "aka": [386, 619, 633], "average_reward": [386, 387, 388], "tdestim": [386, 387, 389], "infti": 387, "valuefunctionbas": 389, "preproc": [390, 622, 633], "as_non_tensor": [390, 633], "render_method": 390, "pass_tensordict": 390, "syntact": 390, "sugar": 390, "relax": 390, "out_file_bas": 391, "skip_reset": 391, "center_crop": 392, "make_grid": 392, "log_video": 392, "csv": [392, 394, 396, 458, 619, 627, 628], "tensorboard": [392, 396, 398, 414, 418, 460, 471, 627, 639], "log_dir": [392, 393, 394, 396, 398, 399, 458, 460, 461, 619, 628], "cheetah_video": 392, "run_video": 392, "sec": [392, 635], "video_fp": [392, 394, 397, 458, 461], "run_video_0": 392, "cur_dir": 394, "csv_log": 394, "add_video": 394, "video_": 394, "experiment_nam": [395, 396], "logger_typ": 396, "logger_nam": 396, "mlflow": [396, 397], "wandb_kwarg": 396, "mlflow_kwarg": 396, "tracking_uri": 397, "uri": 397, "datastor": 397, "tb_log": [398, 460], "tensoarboard": 398, "td_log": 398, "save_dir": [399, 461], "resum": 399, "uncategor": 399, "torchrl_servic": [400, 402], "discoveri": 400, "instantli": 400, "tokenizerclass": [400, 402], "modelclass": 400, "tok": 400, "service_factori": [400, 401, 611], "max_restart": 400, "register_with_opt": [400, 611], "actor_opt": [400, 611], "constructor_kwarg": 400, "readabl": 400, "concern": [400, 578, 590, 625], "model_path": 400, "ongo": [400, 401], "destruct": [400, 401], "init_kwarg": 402, "servicebas": [402, 611], "unsupport": [402, 573], "my_funct": 403, "sub_traj_len": 404, "min_sub_traj_len": 404, "register_op": [404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 417, 619], "process_optim_batch": [404, 410, 411], "td_out": [404, 412], "_process_optim_batch_hook": 404, "batch_subsampl": 404, "clear_cuda": 405, "pre_optim_step": 405, "log_pbar": [406, 407, 408, 411, 619], "count_fram": 406, "pre_steps_log": [406, 407], "count_frames_log": 406, "lognam": 407, "include_std": 407, "log_reward": [407, 418, 419, 619], "r_train": 407, "log_action_norm": 407, "action_norm": 407, "percentag": 407, "log_don": 407, "done_percentag": 407, "record_interv": [408, 618, 619], "record_fram": [408, 551, 618, 619], "policy_explor": [408, 558, 618, 619, 622, 624, 628], "log_kei": [408, 619], "underestim": 408, "r_evalu": [408, 618], "loss_compon": 409, "appl": 409, "optimizer_hook": 409, "flatten_tensordict": [410, 619], "max_dim": 410, "rb_trainer": 410, "batch_process": [410, 411, 412], "post_loss": 410, "999": [411, 540, 541, 542, 545, 546, 550, 619], "jitter": 411, "finfo": 411, "default_dtyp": 411, "update_reward_stat": 411, "normalize_reward": 411, "make_train": 412, "_process_batch_hook": 412, "select_kei": 412, "target_params_updat": 413, "targetnetupdat": [413, 419, 555, 557, 558], "target_net_updat": [413, 419, 558, 618, 619], "softupd": [413, 618, 619, 621, 622, 625, 628, 633], "target_net_updater_hook": 413, "post_optim": [413, 619], "versatil": [414, 623], "optim_steps_per_batch": [414, 418, 419, 471, 619], "clip_grad_norm": [414, 418, 419, 471], "clip_norm": [414, 418, 419, 471], "progress_bar": [414, 418, 419, 471], "save_trainer_interv": [414, 418, 419, 471], "log_interv": [414, 418, 419, 471, 619], "save_trainer_fil": [414, 418, 419, 471], "async_collect": [414, 416, 418, 471], "utd": [414, 416, 618, 621], "utd_ratio": 414, "log_tim": [414, 418, 471], "logtim": [414, 418], "updateweight": [414, 418, 471, 612, 619], "load_from_fil": [414, 418, 419], "update_count": 416, "utdr_hook": 416, "update_weights_interv": [417, 619], "policy_weights_gett": 417, "weight_update_map": [417, 418, 471], "post_step": [417, 619], "num_epoch": [418, 471, 620, 634], "enable_log": [418, 419], "log_act": [418, 419], "log_observ": [418, 419], "add_ga": [418, 471], "ppotrainerconfig": 418, "welcom": [418, 590, 623], "elsewher": 419, "3e": [419, 620, 621, 633, 634], "asynccollectorconfig": 420, "collectorconfig": 421, "storageensemblewrit": 435, "batched_env_typ": 438, "make_batched_env": 438, "make_gym_env": 444, "mogymenv": 448, "meltingpotenv": 449, "openmlenv": 451, "openspielenv": 452, "pettingzooenv": [453, 633], "robohiveenv": 454, "smacv2env": 455, "unity_mlag": 456, "unitymlagentsenv": 456, "activationconfig": [462, 463], "normconfig": 462, "aggregatorconfig": 462, "layerconfig": 463, "valuemodelconfig": 464, "mlpconfig": [466, 467, 468], "eval_mod": 466, "extract_normal_param": 466, "param_kei": 466, "_make_tanh_normal_model": 466, "_make_tensordict_modul": 467, "_make_value_model": 468, "networkconfig": 468, "loss_typ": [469, 470], "_make_ppo_loss": 470, "_make_ppo_train": 471, "sensibl": 471, "batchsizetransform": [476, 622], "binarizereward": 477, "burnintransform": 478, "centercrop": 481, "cliptransform": 482, "conditionalpolicyswitch": 484, "dtypecasttransform": 487, "devicecasttransform": 488, "discreteactionproject": 489, "gym_transform": 491, "endoflifetransform": 491, "exclude_kei": 492, "finitetensordictcheck": 493, "flattenobserv": 494, "frameskiptransform": 495, "linearisereward": 500, "multiact": 501, "rb_transform": 502, "multisteptransform": 502, "noopresetenv": [503, 639, 640], "permutetransform": 505, "pinmemorytransform": 506, "r3mtransform": [507, 636], "crop_siz": 508, "randomcroptensordict": [508, 618], "key_map": 510, "reward2gotransform": 512, "include_kei": 516, "signtransform": 517, "squeezetransform": 518, "targetreturn": 521, "primer_spec": 522, "timemaxpool": 523, "vc1transform": 531, "viprewardtransform": 532, "viptransform": 533, "lambd": 537, "t0": [537, 622, 628], "weight_decai": [537, 538, 539, 540, 541, 542, 544, 545, 546, 547, 549, 618, 619], "foreach": [537, 538, 539, 541, 545, 547, 548, 549], "maxim": [537, 538, 539, 541, 547, 548, 549, 618, 625, 635], "asgd": 537, "rho": 538, "adadelta": 538, "lr_decai": 539, "initial_accumulator_valu": 539, "adagrad": 539, "amsgrad": [540, 541], "fuse": 541, "adamw": 541, "002": [542, 545], "adamax": 542, "max_it": 543, "max_ev": 543, "tolerance_grad": 543, "07": 543, "tolerance_chang": 543, "09": 543, "history_s": 543, "line_search_fn": 543, "lbfg": 543, "lion": 544, "momentum_decai": 545, "004": 545, "nadam": 545, "radam": 546, "momentum": [547, 549], "rmsprop": 547, "eta": 548, "step_siz": 548, "rprop": 548, "dampen": 549, "nesterov": 549, "sgd": 549, "sparseadam": 550, "dictconfig": [551, 552, 553, 554, 556, 557, 558, 559, 562], "unknowingli": 551, "annealing_fram": [551, 618], "init_env_step": [551, 552, 618], "proof_environ": [552, 618], "sta": 552, "ot": 552, "actor_model_explor": [553, 554, 618], "make_env_kwarg": [553, 554], "replayargsconfig": 556, "constitu": 558, "egreedywrapp": 558, "ddpgloss": [558, 604, 618, 625, 633, 639], "env_proof": 558, "obs_spec": 558, "net_valu": 558, "dir": [558, 619], "gettempdir": 558, "transformed_env_constructor": 559, "num_env_per_collector": [560, 561], "_multi_sync": 561, "video_tag": 562, "norm_obs_onli": 562, "custom_env_mak": 562, "custom_env": 562, "return_transformed_env": 562, "action_dim_gsd": 562, "state_dim_gsd": 562, "obs_norm_state_dict": 562, "weights_buff": 563, "ONE": [563, 568, 571, 577], "receive_initial_weight": 563, "interf": 563, "surround": [563, 634], "send_initial_weight": 563, "send_weight": [563, 568, 571, 573, 575, 578, 580], "send_weights_async": [563, 565, 568, 571], "acknowledg": [563, 564, 565, 566, 569, 570, 572, 573, 574, 577, 579, 585], "wait_ack": [563, 565, 568, 571], "setup_connection_and_weights_on_send": [563, 565, 568, 571, 573, 575], "3600": 564, "get_store_info": 564, "hour": 564, "apply_weight": [564, 566, 567, 569, 570, 572, 574, 576, 577, 579, 581, 583, 585], "rendez": [564, 566, 569, 570, 572, 574, 577, 579, 585], "vou": [564, 566, 569, 570, 572, 574, 577, 579, 585], "_setup_connection_and_weights_on_sender_impl": [564, 565, 566, 569, 570, 572, 574, 577, 579, 585], "_setup_connection_and_weights_on_receiver_impl": [564, 566, 569, 570, 572, 574, 577, 579, 585], "create_transport": [564, 566, 567, 569, 570, 572, 574, 577, 579, 585], "_run_process": [564, 566, 567, 569, 570, 572, 574, 577, 579, 585], "prepare_weight": [564, 566, 567, 569, 570, 572, 574, 577, 579, 585], "lookup": [564, 566, 567, 569, 570, 572, 574, 577, 579, 585, 619], "sharedmemweightsyncschem": [564, 566, 567, 569, 570, 572, 577, 579, 585], "receiver_transport": [564, 566, 567, 569, 570, 572, 574, 577, 579, 585], "sender_transport": [564, 566, 567, 569, 570, 572, 574, 577, 579, 585], "shared_transport": [564, 566, 567, 569, 570, 572, 574, 577, 579, 585], "weight_queu": 565, "ack_queu": 565, "listen": [566, 574], "phase": [566, 634, 637], "benefici": 566, "transmiss": [566, 570, 571, 572, 574, 576], "wait_async": [566, 574], "_unique_weight": [566, 574], "_receiver_shared_weight": [566, 574], "worker_rank": [568, 569], "deadlock": 568, "somecollector": 570, "transform_modul": 570, "connection_info_nam": [570, 571, 572], "collis": [570, 572, 633, 634], "remote_actor": [570, 571, 572], "connection_info": 571, "set_model": 571, "_setup_distributed_connection_send": 571, "pure": 573, "register_weight": 573, "params_map": [573, 577], "basecontext": 573, "init_queu": 573, "send_ack": 573, "unique_weight": 573, "_send_instruct": 574, "notifi": 574, "extract_a": 576, "extract_weight": [576, 586], "device_map_fn": 577, "gpus_per_replica": [578, 585, 590], "init_all_workers_group": [578, 583, 584, 585, 590], "check_connect": [578, 580], "mono": 578, "remote_addr": [579, 580], "local_addr": [579, 580], "tmp": 579, "mnt": 579, "nf": 579, "mount": 579, "create_receiv": [579, 581, 585], "vllmdoublebufferweightreceiv": 579, "llm_engin": 579, "model_executor": 579, "create_send": [579, 582, 585], "vllmdoublebufferweightsend": 579, "vllmdoublebuffertransport": 579, "vllmdoublebuffersyncschem": [581, 582, 590], "load_weight": 581, "poll_and_appli": [581, 583], "_update_weights_with_nccl_broadcast_simpl": 581, "180": 581, "register_model": [582, 584, 585, 590], "vllmweightsyncschem": [583, 584, 590], "get_actor": 583, "particip": [583, 585], "torchrpcvllmreceiv": 583, "rpc_sync": 583, "get_metadata": 583, "grpc": 584, "vllmcollectivetransport": [584, 585], "bandwidth": 584, "torchrpcvllmsend": 584, "rpc_async": 584, "prepare_rec": 584, "tp_size": 585, "dp_size": 585, "pp_size": 585, "approxim": [585, 634, 640], "handshak": 585, "12345": 585, "vllmweightsend": 585, "vllmweightreceiv": 585, "init_send": 585, "sender_actor": 585, "init_receiv": 585, "receiver_actor": 585, "llmlossoutput": 588, "cispoloss": 588, "mcadvantag": 588, "sftloss": [588, 590], "sftlossoutput": 588, "topkrewardselector": 588, "sweep": 588, "journei": 589, "textbook": 589, "highlight": [589, 633], "ever": [589, 634], "bump": 589, "pr": [589, 590], "five": [590, 619], "make_polici": 590, "29500": 590, "_weight_send": 590, "training_model": 590, "policy_version_track": 590, "migrat": 590, "ref_servic": 590, "step_data": 590, "gsm8krewardpars": 590, "ifevalscor": 590, "excel": 590, "bsz": 590, "num_token": 590, "predetermin": 590, "hasattr": [590, 618], "text_complet": 590, "sophist": [590, 620, 634], "format_compon": 590, "structure_scor": 590, "think_scor": 590, "answer_scor": 590, "completion_bonu": 590, "potential_answ": 590, "compl": 590, "et": 590, "parseerror": 590, "unnecessari": 590, "characterist": [590, 618, 635], "\u03b5": 597, "satisfi": 597, "additivegaussianmodul": [597, 624, 633], "consistentdropoutmodul": 597, "egreedymodul": [597, 619, 621, 622, 624, 628], "ornsteinuhlenbeckprocessmodul": [597, 618, 624], "duelingcnndqnet": [597, 619], "ddpgcnnactor": 597, "ddpgcnnqnet": 597, "ddpgmlpactor": [597, 618], "ddpgmlpqnet": [597, 618], "onlinedtactor": 597, "dtactor": 597, "dreameractor": 597, "obsencod": 597, "obsdecod": 597, "rssmposterior": 597, "rssmprior": 597, "rssmrollout": 597, "independentnorm": 597, "tanhdelta": [597, 618, 633], "truncatednorm": 597, "reusabl": [604, 618, 637], "trainabl": [604, 618, 625, 636], "\u03bb": 604, "customiz": [604, 621], "total_loss": [604, 625], "distributionaldqnloss": [604, 619], "iqlloss": 604, "discreteiqlloss": 604, "cqlloss": 604, "discretecqlloss": 604, "ppoloss": 604, "a2closs": 604, "reinforceloss": 604, "discretesacloss": 604, "td3loss": 604, "redqloss": 604, "crossqloss": 604, "td3bcloss": 604, "gailloss": 604, "dtloss": 604, "onlinedtloss": 604, "dreameractorloss": 604, "dreamermodelloss": 604, "dreamervalueloss": 604, "agnost": [611, 630], "monarch": 611, "anywher": 611, "tenant": 611, "my_namespac": 611, "tokenizerservic": 611, "50000": 611, "my_servic": 611, "myserviceclass": 611, "arg1": 611, "value1": 611, "arg2": 611, "value2": 611, "gpu_servic": 611, "gpuservic": 611, "collid": [611, 622, 634], "register_servic": 611, "shared_token": 611, "use_servic": 611, "worker2": 611, "train_servic": 611, "eval_servic": 611, "30000": 611, "busi": 611, "infrequ": 611, "use_distributed_servic": 611, "queu": 611, "persistentpythonprocess": 611, "_lock": 611, "next_idx": 611, "temp": 611, "python_executor_fast": 611, "python_executor_heavi": 611, "fast_env": 611, "heavy_env": 611, "mycustomservic": 611, "param1": 611, "tokenizer_servic": 611, "servicecontext": 611, "__enter__": 611, "__exit__": 611, "myservic": 611, "stick": [611, 622], "distributed_servic": 611, "python_executor_servic": 611, "test_servic": 611, "test_python_executor_servic": 611, "ref_llm": [611, 630], "torchsnapshot": 612, "logscalar": [612, 619], "mlflowlogg": 612, "get_logg": 612, "generate_exp_nam": 612, "batchsubsampl": 612, "clearcudacach": 612, "countframeslog": 612, "optimizerhook": [612, 619], "logvalidationreward": [612, 618, 619], "replaybuffertrain": [612, 619], "rewardnorm": 612, "selectkei": 612, "targetnetupdaterhook": 612, "utdrhook": 612, "000": [617, 621, 638], "galleri": [617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "mem": [617, 638], "mb": [617, 638], "coding_ddpg": [617, 618, 638], "coding_dqn": [617, 619, 638], "coding_ppo": [617, 620, 638], "dqn_with_rnn": [617, 621, 638], "llm_browser": [617, 630, 638], "llm_wrapper": [617, 631, 638], "multi_task": [617, 632, 638], "multiagent_competitive_ddpg": [617, 633, 638], "multiagent_ppo": [617, 634, 638], "pretrained_model": [617, 636, 638], "rb_tutori": [617, 637, 638], "torchrl_demo": [617, 638, 639], "torchrl_env": [617, 638, 640], "author": [618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 633, 634, 635, 637, 640], "vincent": [618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 635, 637, 640], "moen": [618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 635, 637, 640], "assembl": 618, "ground": [618, 635], "transpar": [618, 621], "bash": 618, "is_fork": [618, 619, 620, 621, 633, 634, 636], "get_start_method": [618, 619, 620, 621, 633, 634, 636], "collector_devic": 618, "swappabl": 618, "smth": 618, "loss_dict": 618, "oblivi": [618, 620, 637], "elementari": 618, "didact": [618, 622], "dilut": 618, "pessimist": [618, 619, 620], "target_actor_network_param": 618, "actor_in_kei": 618, "actor_crit": 618, "compromis": 618, "td0estim": 618, "td1estim": 618, "tdlambdaestim": 618, "hp": 618, "_value_estim": 618, "hold_out_param": 618, "_loss_actor": 618, "td_copi": 618, "actor_network_param": [618, 633], "value_network_param": [618, 633], "distance_loss": 618, "_loss_valu": 618, "pred_val": 618, "target_value_network_param": 618, "smooth": [618, 619, 625], "pow": 618, "glue": 618, "_forward": 618, "remaind": 618, "env_librari": 618, "env_task": 618, "env_arg": [618, 619], "torchr": 618, "rescal": 618, "presum": 618, "make_transformed_env": 618, "reward_sc": 618, "parallel_env_constructor": 618, "env_per_collector": 618, "transform_state_dict": 618, "make_t_env": 618, "seem": [618, 621, 623], "cheat": 618, "10m": 618, "nutshel": 618, "cautiou": 618, "thousand": [618, 621], "get_env_stat": 618, "proof_env": 618, "5000": [618, 622, 628], "recal": [618, 620, 630, 637], "materi": 618, "make_ddpg_actor": 618, "q_net": 618, "qnet": 618, "suggest": [618, 634], "tight": 618, "10_000": [618, 620], "traj_len": [618, 621], "make_record": 618, "recorder_obj": 618, "pick": [618, 619, 624, 630], "make_replay_buff": 618, "buffer_s": [618, 619, 621], "random_crop_len": 618, "prb": 618, "buffer_scratch_dir": [618, 619, 621, 626, 636], "dataflow": 618, "ceil_div": 618, "update_to_data": 618, "realiz": 618, "ve": [618, 621, 628, 630], "_must_": 618, "outdat": 618, "trick": [618, 619], "despit": 618, "hardupd": [618, 625], "optimizer_actor": 618, "optimizer_valu": 618, "total_collection_step": 618, "rewards_ev": 618, "collected_fram": 618, "r0": 618, "numel": [618, 620, 622, 628, 633, 636, 637], "current_fram": [618, 633], "sampled_tensordict": 618, "gn1": 618, "clip_grad_norm_": [618, 620, 633, 634, 635], "gn2": 618, "gn": [618, 635], "td_record": 618, "rn": 618, "2f": 618, "plot": [618, 620, 621, 633, 634, 635], "mention": [618, 621, 637, 640], "matplotlib": [618, 620, 621, 622, 633, 634, 635, 637, 640], "pyplot": [618, 620, 621, 622, 633, 634, 635, 637, 640], "plt": [618, 620, 621, 622, 633, 634, 635, 637, 640], "legend": [618, 633], "xlabel": [618, 621, 634, 635], "ylabel": [618, 634], "tight_layout": 618, "concret": [618, 620, 630], "takeawai": [618, 619, 622, 630], "distpatch": 618, "jupyt": [618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "ipynb": [618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "sphinx": [618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640], "road": 619, "aspect": [619, 625], "highest": [619, 624], "prerequisit": [619, 621, 630], "amort": [619, 620], "cart": 619, "pole": 619, "un": 619, "actuat": 619, "frictionless": 619, "is_notebook": 619, "shell": 619, "get_ipython": 619, "__class__": [619, 631], "zmqinteractiveshel": 619, "qtconsol": 619, "terminalinteractiveshel": 619, "ipython": [619, 634, 635], "nameerror": [619, 631, 633], "umbrella": 619, "misplac": 619, "misus": 619, "64x64": 619, "motion": [619, 635], "obs_norm_sd": 619, "mp_context": 619, "get_norm_stat": 619, "test_env": 619, "mathbb": 619, "rightarrow": 619, "make_model": 619, "dummy_env": 619, "init_bia": 619, "exploration_modul": [619, 621, 622, 624, 628], "eps_greedy_v": 619, "eps_greedy_val_env": 619, "actor_explor": 619, "get_replay_buff": 619, "n_optim": [619, 625, 626], "parametriz": 619, "get_collector": 619, "bunch": 619, "ubiquit": [619, 623], "get_loss_modul": 619, "target_updat": [619, 633], "995": 619, "hopefulli": 619, "sensit": [619, 621], "variat": 619, "2e": [619, 635], "wd": 619, "upd": 619, "harder": [619, 639], "5_000": 619, "500000": 619, "005": [619, 633], "mandatori": [619, 620, 634, 635], "fairer": 619, "budget": 619, "dqn_exp_": 619, "uuid1": [619, 640], "cumbersom": 619, "buffer_hook": 619, "trainerhookbas": 619, "aliv": 619, "total_reward": 619, "ti": 619, "print_csv_files_in_fold": 619, "folder_path": 619, "csv_file": 619, "output_str": 619, "dirpath": 619, "endswith": 619, "qvaluenetwork": 619, "worst": 619, "accuraci": 619, "fanci": [619, 626], "talk": 620, "six": 620, "invent": 620, "theta_k": 620, "pi_": 620, "exceed": 620, "indispens": 620, "loader": 620, "analyz": 620, "lingua": 620, "franca": 620, "defaultdict": [620, 635], "max_grad_norm": [620, 633, 634], "sub_batch_s": 620, "95": [620, 621], "entropy_ep": [620, 634], "inverteddoublependulum": 620, "transmit": 620, "stai": 620, "told": 620, "confid": [620, 633, 634], "ran": 620, "f_": 620, "mu_": 620, "difficulti": [620, 640], "brought": [620, 621, 624], "d_ob": 620, "d_action": 620, "said": 620, "value_modul": [620, 639], "briefli": [620, 633, 634], "refil": [620, 634], "easiest": [620, 625, 633, 634], "hide": [620, 633, 634], "mathemat": [620, 633, 634], "tradeoff": [620, 634], "advantage_modul": 620, "entropy_coef": [620, 634], "critic_coef": 620, "lr_schedul": [620, 635], "cosineannealinglr": [620, 635], "eval_str": 620, "tensordict_data": [620, 634], "data_view": [620, 634], "subdata": [620, 633, 634], "cum_reward_str": 620, "stepcount_str": 620, "param_group": [620, 633], "lr_str": 620, "eval_rollout": 620, "figsiz": [620, 635], "subplot": [620, 633, 635, 640], "84x84": [621, 622], "accessori": 621, "stamp": 621, "backbon": [621, 624, 632, 639], "emb": 621, "n_cell": 621, "bidirect": 621, "wouldn": 621, "qval": 621, "stoch_polici": 621, "opportun": [621, 633], "uniniti": 621, "again": [621, 622, 623, 624, 626, 634, 636, 637, 640], "strongli": 621, "sake": [621, 636, 637], "longest": 621, "enough": [621, 637], "strong": 622, "impress": 622, "edg": 622, "arduino": 622, "raspberri": 622, "alon": 622, "examplifi": 622, "ship": 622, "nearest": 622, "value_mlp": [622, 628], "init_rand_step": [622, 628], "total_count": [622, 628], "total_episod": [622, 628], "screen": [622, 633], "color": [622, 633], "clearer": [622, 624], "unblock": 622, "policy_transform": 622, "fake_td": 622, "exported_polici": 622, "div": 622, "graph_modul": 622, "print_read": 622, "group0": 622, "group0_agent0_ob": 622, "group0_agent0": 622, "agent0_ob": 622, "obvious": 622, "digress": 622, "exported_stochastic_polici": 622, "trace": 622, "hidden0": 622, "hidden1": 622, "recurrent_polici": 622, "happi": 622, "fake_ob": 622, "fake_hidden0": 622, "fake_hidden1": 622, "fake_is_init": 622, "exported_recurrent_polici": 622, "platform": [622, 639], "aoti": 622, "_inductor": 622, "aoti_compile_and_packag": 622, "aoti_load_packag": 622, "pt2": 622, "pkg_path": 622, "package_path": 622, "compiled_modul": 622, "onnxruntim": 622, "showcas": [622, 635], "plenti": 622, "tensorrt": 622, "android": 622, "aleinterfac": 622, "rom": [622, 640], "loadrom": 622, "reset_gam": 622, "screen_ob": 622, "getscreenrgb": 622, "tick_param": 622, "bottom": 622, "labelleft": 622, "labelbottom": 622, "imshow": [622, 640], "dynamo_export": 622, "as_tensor": 622, "onnx_policy_export": 622, "onnx_file_path": 622, "ort_sess": 622, "inferencesess": 622, "cpuexecutionprovid": 622, "onnxruntime_input": 622, "get_input": 622, "onnx_polici": 622, "f811": 622, "onnxruntime_output": 622, "num_step": 622, "deploy": 622, "topic": [623, 624, 625], "straight": 623, "backtrack": 623, "reset_with_act": 623, "stepped_data": 623, "spatial": 623, "useless": 623, "policyless": 623, "glanc": 623, "appreci": 623, "examin": [623, 633], "tackl": 624, "intric": 624, "delv": 624, "extractor": 624, "analog": 624, "realm": 624, "exploration_polici": [624, 633], "2d": [624, 633, 634], "innov": [624, 625], "rollout_explor": 624, "sole": 625, "n_collect": 625, "get_next_batch": 625, "ddpg_loss": 625, "prove": 625, "reliev": 625, "accustom": 626, "surprisingli": 626, "matter": 626, "art": [626, 633, 634], "pseudo": [626, 635], "countless": 626, "yourself": [626, 633, 634], "chapter": 627, "everywher": 627, "log_scalar": 627, "my_scalar": 627, "excess": 627, "lesson": 628, "voluntarili": 628, "training_loop": 628, "video_record": 628, "arbitrarili": 628, "num": 628, "t1": 628, "conclud": [628, 636], "tutorials_python": 629, "tutorials_jupyt": 629, "playwright": 630, "autom": 630, "__future__": 630, "browsertransform": 630, "filterwarn": [630, 631], "browser_transform": 630, "rewardtransform": 630, "last_item": 630, "execute_tool_act": 630, "current_st": 630, "nllm": 630, "nenviron": 630, "button": 630, "css": 630, "btnk": 630, "extract_typ": 630, "suppress": 631, "vllm_use_v1": 631, "5b": 631, "canada": 631, "vllm_wrapper": 631, "return_text": 631, "return_token": 631, "return_mask": 631, "data_histori": 631, "nload": 631, "transformers_token": 631, "transformers_wrapp": 631, "result_tf": 631, "data_text": 631, "vllm_text_wrapp": 631, "result_vllm_text": 631, "nvllm": 631, "transformers_text_wrapp": 631, "result_tf_text": 631, "vllm_logprobs_wrapp": 631, "result_vllm_lp": 631, "transformers_logprobs_wrapp": 631, "result_tf_lp": 631, "ntensorclass": 631, "analysi": 631, "ntext": 631, "__annotations__": 631, "ntoken": 631, "nlogprob": 631, "nmask": 631, "nerror": 631, "invalid_mod": 631, "nrl": 631, "env_stat": 631, "action_output": 631, "60": [631, 639], "env1_obs_kei": 632, "observation_stand": 632, "env2_obs_kei": 632, "observation_walk": 632, "tdreset1": 632, "tdreset2": 632, "policy_common": 632, "policy_stand": 632, "policy_walk": 632, "env1_mak": 632, "env2_mak": 632, "_single_task": 632, "td_rollout": 632, "matteo": [633, 634], "bettini": [633, 634], "benchmarl": [633, 634], "simple_tag": 633, "maddpg": [633, 634], "multiagentparticleenviron": 633, "mpe": 633, "centralis": [633, 634], "tie": [633, 634], "iddpg": [633, 634], "optimis": [633, 634], "sutton": [633, 634], "richard": 633, "andrew": 633, "barto": [633, 634], "mit": 633, "press": 633, "2018": 633, "mathbf": [633, 634], "decentralis": [633, 634], "literatur": [633, 634], "overcom": [633, 634], "stationari": [633, 634], "establish": 633, "gui": [633, 634], "multiagentmlp": [633, 634], "is_sphinx": 633, "__sphinx_build__": 633, "n_iter": [633, 634, 635], "evad": 633, "iteration_when_stop_training_evad": 633, "memory_s": 633, "n_optimiser_step": 633, "train_batch_s": 633, "polyak_tau": 633, "furthermor": [633, 634], "chaser": 633, "red": 633, "circl": [633, 634], "touch": [633, 635], "penal": [633, 634], "obstacl": 633, "drag": [633, 634], "elast": [633, 634], "Their": [633, 634], "imped": 633, "n_chaser": 633, "n_evad": 633, "n_obstacl": 633, "use_vma": 633, "simple_tag_v3": 633, "num_good": 633, "num_adversari": 633, "num_obstacl": 633, "max_cycl": 633, "num_vmas_env": [633, 634], "num_good_ag": 633, "num_landmark": 633, "four": [633, 634, 635], "n_agents_in_that_group": 633, "stress": [633, 634], "paramount": [633, 634], "n_rollout_step": [633, 634], "evolut": [633, 634], "group_nam": 633, "n_agents_in_group": 633, "signifi": [633, 634], "agents_exploration_polici": 633, "utilis": [633, 634], "homogen": [633, 634], "n_obs_per_ag": [633, 634], "n_actions_per_ag": [633, 634], "share_parameters_polici": [633, 634], "policy_net": [633, 634], "n_agent_input": [633, 634], "n_agent_output": [633, 634], "share_param": [633, 634], "_agent": 633, "grant": [633, 634], "converg": [633, 634], "share_parameters_crit": [633, 634], "obs_act": 633, "cat_modul": 633, "critic_modul": 633, "fantast": [633, 634], "reset_td": 633, "interfer": 633, "subject": [633, 635], "flatten_kei": 633, "process_batch": 633, "group_shap": 633, "get_item_shap": [633, 634], "nested_done_kei": 633, "nested_terminated_kei": 633, "desc": [633, 634], "episode_reward_mean_": 633, "episode_reward_mean_map": 633, "train_group_map": 633, "group_batch": 633, "_group": 633, "loss_nam": 633, "episode_reward_mean": [633, 634], "proce": 633, "fig": [633, 637], "set_ylabel": 633, "axvlin": 633, "orang": 633, "set_xlabel": 633, "video_logg": 633, "vmas_log": 633, "env_with_rend": 633, "vmas_rend": 633, "print_log_dir": 633, "profici": [633, 634], "qmix": [633, 634], "lidar": 634, "sensor": 634, "mappo": 634, "ippo": 634, "_t": [634, 635], "analys": 634, "visualis": 634, "vmas_devic": 634, "6_000": 634, "minibatch_s": 634, "generalis": 634, "simd": 634, "warp": 634, "todai": 634, "dot": [634, 635], "scenario_nam": 634, "critic_net": 634, "minibatch": 634, "episode_reward_mean_list": 634, "critic_network_param": 634, "target_critic_network_param": 634, "xvfb": 634, "pyvirtualdisplai": 634, "1400": 634, "900": 634, "pil": 634, "rendering_callback": 634, "fromarrai": 634, "gif": 634, "save_al": 634, "append_imag": 634, "freeli": 635, "undertaken": 635, "broader": 635, "wider": 635, "acquaint": 635, "avenu": 635, "_apply_to_composit": 635, "default_x": 635, "default_i": 635, "upward": 635, "angular": 635, "sin": 635, "theta_t": 635, "rad": 635, "theta_": 635, "angl": 635, "new_th": 635, "new_thdot": 635, "g_forc": 635, "angle_norm": 635, "zeros_lik": 635, "albeit": 635, "high_th": 635, "high_thdot": 635, "low_th": 635, "low_thdot": 635, "trivial": 635, "irrelev": 635, "_make_spec": 635, "td_param": 635, "render_fp": 635, "random_": 635, "_make_step": 635, "staticmethod": 635, "skeleton": 635, "sine": 635, "cosin": 635, "sintransform": 635, "costransform": 635, "t_sin": 635, "t_co": 635, "cat_transform": 635, "simple_rollout": 635, "_data": 635, "unexplor": 635, "recreat": 635, "20_000": 635, "init_td": 635, "traj_return": 635, "last_reward": 635, "is_ipython": 635, "inlin": 635, "get_backend": 635, "ion": 635, "gcf": 635, "clear_output": 635, "env_transform": [636, 640], "wiser": 636, "_storag": [636, 637], "batteri": 637, "gc": 637, "filesystem": 637, "buffer_list": 637, "lowest": 637, "medium": 637, "buffer_lazytensor": 637, "tempdir": 637, "buffer_lazymemmap": 637, "fullest": 637, "mydata": 637, "buffer_lazi": 637, "_i": 637, "artifici": 637, "hamper": 637, "hist": 637, "recycl": 637, "reappear": 637, "unfold": 637, "problemat": 637, "4th": 637, "tensordictmaxvaluewrit": 637, "demo": 639, "icml": 639, "vmoen": 639, "fb": 639, "invest": 639, "media": 639, "predominantli": 639, "data2": 639, "sub_key1": 639, "scturctur": 639, "data_stack": 639, "data_sampl": 639, "_sampler": 639, "_sum_tre": 639, "modulenotfounderror": 639, "backbone_modul": 639, "params_expand": 639, "exec_sequ": 639, "tensordict_exp": 639, "base_modul": 639, "roughli": 639, "tensordicts_prealloc": 639, "tensordicts_stack": 639, "tensordict_rollout": [639, 640], "automatical": 639, "particularili": 639, "concatmodul": 639, "loss_td": 639, "contributor": 639, "curiou": 639, "nascent": 639, "unsupervis": 640, "licens": 640, "pygam": 640, "_build_env": 640, "deserv": 640, "__episode__": 640, "__trajectory__": 640, "void": 640, "reproduct": 640, "tensordict_tprim": 640, "inconsist": 640, "wrapper1": 640, "wrapper2": 640, "obviou": 640, "truth": 640, "env_transformed_bi": 640, "stanc": 640, "transformeddistribut": 640, "base_dist": 640, "concat": 640, "mofidi": 640, "transformedenviron": 640, "moderet": 640, "computation": 640, "incom": 640, "amongst": 640, "has_cuda": 640, "device_count": 640, "worri": 640, "convention": 640, "markovian": 640, "bar_": 640, "get_someth": 640, "aargh": 640, "is_clos": 640, "foo_list": 640, "121": 640, "evolv": 640, "steadi": 640, "approx": 640, "sd": 640, "absor": 640, "_extra_st": 640}, "objects": {"torchrl": [[31, 0, 1, "", "auto_unwrap_transformed_env"], [282, 0, 1, "", "implement_for"], [403, 0, 1, "", "set_auto_unwrap_transformed_env"]], "torchrl.collectors": [[32, 0, 1, "", "AsyncCollector"], [33, 0, 1, "", "BaseCollector"], [34, 0, 1, "", "Collector"], [35, 0, 1, "", "MultiAsyncCollector"], [36, 0, 1, "", "MultiCollector"], [37, 0, 1, "", "MultiProcessedWeightUpdater"], [38, 0, 1, "", "MultiSyncCollector"], [39, 0, 1, "", "RayWeightUpdater"], [40, 0, 1, "", "VanillaWeightUpdater"], [41, 0, 1, "", "WeightUpdaterBase"]], "torchrl.collectors.AsyncCollector": [[32, 1, 1, "", "async_shutdown"], [32, 1, 1, "", "cascade_execute"], [32, 1, 1, "", "get_cached_weights"], [32, 1, 1, "", "get_model"], [32, 1, 1, "", "get_policy_version"], [32, 1, 1, "", "getattr_env"], [32, 1, 1, "", "getattr_policy"], [32, 1, 1, "", "getattr_rb"], [32, 1, 1, "", "increment_version"], [32, 1, 1, "", "init_updater"], [32, 1, 1, "", "load_state_dict"], [32, 1, 1, "", "pause"], [32, 2, 1, "", "policy_version"], [32, 1, 1, "", "receive_weights"], [32, 1, 1, "", "register_scheme_receiver"], [32, 1, 1, "", "reset"], [32, 1, 1, "", "set_seed"], [32, 1, 1, "", "shutdown"], [32, 1, 1, "", "start"], [32, 1, 1, "", "state_dict"], [32, 1, 1, "", "update_policy_weights_"], [32, 2, 1, "", "worker_idx"]], "torchrl.collectors.BaseCollector": [[33, 1, 1, "", "async_shutdown"], [33, 1, 1, "", "cascade_execute"], [33, 1, 1, "", "init_updater"], [33, 1, 1, "", "pause"], [33, 1, 1, "", "receive_weights"], [33, 1, 1, "", "register_scheme_receiver"], [33, 1, 1, "", "start"], [33, 1, 1, "", "update_policy_weights_"], [33, 2, 1, "", "worker_idx"]], "torchrl.collectors.Collector": [[34, 1, 1, "", "async_shutdown"], [34, 1, 1, "", "cascade_execute"], [34, 1, 1, "", "get_model"], [34, 1, 1, "", "get_policy_version"], [34, 1, 1, "", "getattr_env"], [34, 1, 1, "", "getattr_policy"], [34, 1, 1, "", "getattr_rb"], [34, 1, 1, "", "increment_version"], [34, 1, 1, "", "init_updater"], [34, 1, 1, "", "iterator"], [34, 1, 1, "", "load_state_dict"], [34, 1, 1, "", "pause"], [34, 2, 1, "", "policy_version"], [34, 1, 1, "", "receive_weights"], [34, 1, 1, "", "register_scheme_receiver"], [34, 1, 1, "", "reset"], [34, 1, 1, "", "rollout"], [34, 1, 1, "", "set_seed"], [34, 1, 1, "", "shutdown"], [34, 1, 1, "", "start"], [34, 1, 1, "", "state_dict"], [34, 1, 1, "", "update_policy_weights_"], [34, 2, 1, "", "worker_idx"]], "torchrl.collectors.MultiAsyncCollector": [[35, 1, 1, "", "async_shutdown"], [35, 1, 1, "", "cascade_execute"], [35, 1, 1, "", "get_cached_weights"], [35, 1, 1, "", "get_model"], [35, 1, 1, "", "get_policy_version"], [35, 1, 1, "", "getattr_env"], [35, 1, 1, "", "getattr_policy"], [35, 1, 1, "", "getattr_rb"], [35, 1, 1, "", "increment_version"], [35, 1, 1, "", "init_updater"], [35, 1, 1, "", "load_state_dict"], [35, 1, 1, "", "pause"], [35, 2, 1, "", "policy_version"], [35, 1, 1, "", "receive_weights"], [35, 1, 1, "", "register_scheme_receiver"], [35, 1, 1, "", "reset"], [35, 1, 1, "", "set_seed"], [35, 1, 1, "", "shutdown"], [35, 1, 1, "", "start"], [35, 1, 1, "", "state_dict"], [35, 1, 1, "", "update_policy_weights_"], [35, 2, 1, "", "worker_idx"]], "torchrl.collectors.MultiCollector": [[36, 1, 1, "", "async_shutdown"], [36, 1, 1, "", "cascade_execute"], [36, 1, 1, "", "get_cached_weights"], [36, 1, 1, "", "get_model"], [36, 1, 1, "", "get_policy_version"], [36, 1, 1, "", "getattr_env"], [36, 1, 1, "", "getattr_policy"], [36, 1, 1, "", "getattr_rb"], [36, 1, 1, "", "increment_version"], [36, 1, 1, "", "init_updater"], [36, 1, 1, "", "load_state_dict"], [36, 1, 1, "", "pause"], [36, 2, 1, "", "policy_version"], [36, 1, 1, "", "receive_weights"], [36, 1, 1, "", "register_scheme_receiver"], [36, 1, 1, "", "reset"], [36, 1, 1, "", "set_seed"], [36, 1, 1, "", "shutdown"], [36, 1, 1, "", "start"], [36, 1, 1, "", "state_dict"], [36, 1, 1, "", "update_policy_weights_"], [36, 2, 1, "", "worker_idx"]], "torchrl.collectors.MultiProcessedWeightUpdater": [[37, 1, 1, "", "all_worker_ids"], [37, 2, 1, "", "collector"], [37, 2, 1, "", "collectors"], [37, 1, 1, "", "from_policy"], [37, 1, 1, "", "increment_version"], [37, 1, 1, "", "init"], [37, 2, 1, "", "post_hooks"], [37, 1, 1, "", "push_weights"], [37, 1, 1, "", "register_collector"], [37, 1, 1, "", "register_post_hook"]], "torchrl.collectors.MultiSyncCollector": [[38, 1, 1, "", "async_shutdown"], [38, 1, 1, "", "cascade_execute"], [38, 1, 1, "", "get_cached_weights"], [38, 1, 1, "", "get_model"], [38, 1, 1, "", "get_policy_version"], [38, 1, 1, "", "getattr_env"], [38, 1, 1, "", "getattr_policy"], [38, 1, 1, "", "getattr_rb"], [38, 1, 1, "", "increment_version"], [38, 1, 1, "", "init_updater"], [38, 1, 1, "", "load_state_dict"], [38, 1, 1, "", "pause"], [38, 2, 1, "", "policy_version"], [38, 1, 1, "", "receive_weights"], [38, 1, 1, "", "register_scheme_receiver"], [38, 1, 1, "", "reset"], [38, 1, 1, "", "set_seed"], [38, 1, 1, "", "shutdown"], [38, 1, 1, "", "start"], [38, 1, 1, "", "state_dict"], [38, 1, 1, "", "update_policy_weights_"], [38, 2, 1, "", "worker_idx"]], "torchrl.collectors.RayWeightUpdater": [[39, 1, 1, "", "_get_server_weights"], [39, 1, 1, "", "_maybe_map_weights"], [39, 1, 1, "", "_skip_update"], [39, 1, 1, "", "_sync_weights_with_worker"], [39, 1, 1, "id0", "all_worker_ids"], [39, 2, 1, "", "collector"], [39, 2, 1, "", "collectors"], [39, 1, 1, "", "from_policy"], [39, 1, 1, "", "increment_version"], [39, 1, 1, "", "init"], [39, 2, 1, "", "post_hooks"], [39, 1, 1, "", "push_weights"], [39, 1, 1, "", "register_collector"], [39, 1, 1, "", "register_post_hook"]], "torchrl.collectors.VanillaWeightUpdater": [[40, 1, 1, "", "all_worker_ids"], [40, 2, 1, "", "collector"], [40, 2, 1, "", "collectors"], [40, 1, 1, "", "from_policy"], [40, 1, 1, "", "increment_version"], [40, 1, 1, "", "init"], [40, 2, 1, "", "post_hooks"], [40, 1, 1, "", "push_weights"], [40, 1, 1, "", "register_collector"], [40, 1, 1, "", "register_post_hook"]], "torchrl.collectors.WeightUpdaterBase": [[41, 1, 1, "", "all_worker_ids"], [41, 2, 1, "", "collector"], [41, 2, 1, "", "collectors"], [41, 1, 1, "id0", "from_policy"], [41, 1, 1, "", "increment_version"], [41, 1, 1, "", "init"], [41, 2, 1, "", "post_hooks"], [41, 1, 1, "id1", "push_weights"], [41, 1, 1, "id2", "register_collector"], [41, 1, 1, "", "register_post_hook"]], "torchrl.collectors.distributed": [[42, 0, 1, "", "DistributedCollector"], [43, 0, 1, "", "DistributedDataCollector"], [44, 0, 1, "", "DistributedSyncCollector"], [45, 0, 1, "", "DistributedSyncDataCollector"], [46, 0, 1, "", "DistributedWeightUpdater"], [47, 0, 1, "", "RPCCollector"], [48, 0, 1, "", "RPCDataCollector"], [49, 0, 1, "", "RPCWeightUpdater"], [50, 0, 1, "", "RayCollector"], [51, 0, 1, "", "submitit_delayed_launcher"]], "torchrl.collectors.distributed.DistributedCollector": [[42, 1, 1, "", "async_shutdown"], [42, 1, 1, "", "cascade_execute"], [42, 1, 1, "", "init_updater"], [42, 1, 1, "", "pause"], [42, 1, 1, "", "receive_weights"], [42, 1, 1, "", "register_scheme_receiver"], [42, 1, 1, "", "start"], [42, 1, 1, "", "update_policy_weights_"], [42, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.DistributedDataCollector": [[43, 1, 1, "", "async_shutdown"], [43, 1, 1, "", "cascade_execute"], [43, 1, 1, "", "init_updater"], [43, 1, 1, "", "pause"], [43, 1, 1, "", "receive_weights"], [43, 1, 1, "", "register_scheme_receiver"], [43, 1, 1, "", "start"], [43, 1, 1, "", "update_policy_weights_"], [43, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.DistributedSyncCollector": [[44, 1, 1, "", "async_shutdown"], [44, 1, 1, "", "cascade_execute"], [44, 1, 1, "", "init_updater"], [44, 1, 1, "", "pause"], [44, 1, 1, "", "receive_weights"], [44, 1, 1, "", "register_scheme_receiver"], [44, 1, 1, "", "start"], [44, 1, 1, "", "update_policy_weights_"], [44, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.DistributedSyncDataCollector": [[45, 1, 1, "", "async_shutdown"], [45, 1, 1, "", "cascade_execute"], [45, 1, 1, "", "init_updater"], [45, 1, 1, "", "pause"], [45, 1, 1, "", "receive_weights"], [45, 1, 1, "", "register_scheme_receiver"], [45, 1, 1, "", "start"], [45, 1, 1, "", "update_policy_weights_"], [45, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.DistributedWeightUpdater": [[46, 1, 1, "", "_get_server_weights"], [46, 1, 1, "", "_maybe_map_weights"], [46, 1, 1, "", "_sync_weights_with_worker"], [46, 1, 1, "id0", "all_worker_ids"], [46, 2, 1, "", "collector"], [46, 2, 1, "", "collectors"], [46, 1, 1, "", "from_policy"], [46, 1, 1, "", "increment_version"], [46, 1, 1, "", "init"], [46, 2, 1, "", "post_hooks"], [46, 1, 1, "", "push_weights"], [46, 1, 1, "", "register_collector"], [46, 1, 1, "", "register_post_hook"], [46, 1, 1, "", "update_weights"]], "torchrl.collectors.distributed.RPCCollector": [[47, 1, 1, "", "async_shutdown"], [47, 1, 1, "", "cascade_execute"], [47, 1, 1, "", "init_updater"], [47, 1, 1, "", "pause"], [47, 1, 1, "", "receive_weights"], [47, 1, 1, "", "register_scheme_receiver"], [47, 1, 1, "", "start"], [47, 1, 1, "", "update_policy_weights_"], [47, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.RPCDataCollector": [[48, 1, 1, "", "async_shutdown"], [48, 1, 1, "", "cascade_execute"], [48, 1, 1, "", "init_updater"], [48, 1, 1, "", "pause"], [48, 1, 1, "", "receive_weights"], [48, 1, 1, "", "register_scheme_receiver"], [48, 1, 1, "", "start"], [48, 1, 1, "", "update_policy_weights_"], [48, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.RPCWeightUpdater": [[49, 1, 1, "", "_get_server_weights"], [49, 1, 1, "", "_maybe_map_weights"], [49, 1, 1, "", "_sync_weights_with_worker"], [49, 1, 1, "id0", "all_worker_ids"], [49, 2, 1, "", "collector"], [49, 2, 1, "", "collectors"], [49, 1, 1, "", "from_policy"], [49, 1, 1, "", "increment_version"], [49, 1, 1, "", "init"], [49, 2, 1, "", "post_hooks"], [49, 1, 1, "", "push_weights"], [49, 1, 1, "", "register_collector"], [49, 1, 1, "", "register_post_hook"], [49, 1, 1, "", "update_weights"]], "torchrl.collectors.distributed.RayCollector": [[50, 1, 1, "", "add_collectors"], [50, 1, 1, "", "async_shutdown"], [50, 1, 1, "", "cascade_execute"], [50, 1, 1, "", "init_updater"], [50, 1, 1, "", "load_state_dict"], [50, 1, 1, "", "local_policy"], [50, 1, 1, "", "pause"], [50, 1, 1, "", "receive_weights"], [50, 1, 1, "", "register_scheme_receiver"], [50, 2, 1, "", "remote_collectors"], [50, 1, 1, "", "set_seed"], [50, 1, 1, "", "shutdown"], [50, 1, 1, "", "start"], [50, 1, 1, "", "state_dict"], [50, 1, 1, "", "stop_remote_collectors"], [50, 1, 1, "", "update_policy_weights_"], [50, 2, 1, "", "worker_idx"]], "torchrl.collectors.llm": [[52, 0, 1, "", "LLMCollector"], [53, 0, 1, "", "RayLLMCollector"], [54, 0, 1, "", "vLLMUpdater"], [55, 0, 1, "", "vLLMUpdaterV2"]], "torchrl.collectors.llm.LLMCollector": [[52, 1, 1, "", "as_remote"], [52, 1, 1, "", "async_shutdown"], [52, 1, 1, "", "cascade_execute"], [52, 2, 1, "", "dialog_turns_per_batch"], [52, 1, 1, "", "get_model"], [52, 1, 1, "", "get_policy_model"], [52, 1, 1, "", "get_policy_version"], [52, 1, 1, "", "getattr_env"], [52, 1, 1, "", "getattr_policy"], [52, 1, 1, "", "getattr_rb"], [52, 1, 1, "", "increment_version"], [52, 1, 1, "", "init_updater"], [52, 1, 1, "", "is_initialized"], [52, 1, 1, "", "iterator"], [52, 1, 1, "", "load_state_dict"], [52, 1, 1, "", "pause"], [52, 2, 1, "", "policy_version"], [52, 1, 1, "", "receive_weights"], [52, 1, 1, "", "register_scheme_receiver"], [52, 1, 1, "", "reset"], [52, 2, 1, "", "rollout"], [52, 1, 1, "", "set_seed"], [52, 1, 1, "", "shutdown"], [52, 1, 1, "", "start"], [52, 1, 1, "", "state_dict"], [52, 1, 1, "", "update_policy_weights_"], [52, 2, 1, "", "worker_idx"]], "torchrl.collectors.llm.RayLLMCollector": [[53, 1, 1, "", "as_remote"], [53, 1, 1, "", "async_shutdown"], [53, 1, 1, "", "cascade_execute"], [53, 2, 1, "", "dialog_turns_per_batch"], [53, 1, 1, "", "get_model"], [53, 1, 1, "", "get_policy_model"], [53, 1, 1, "", "get_policy_version"], [53, 1, 1, "", "getattr_env"], [53, 1, 1, "", "getattr_policy"], [53, 1, 1, "", "getattr_rb"], [53, 1, 1, "", "increment_version"], [53, 1, 1, "", "init_updater"], [53, 1, 1, "", "is_initialized"], [53, 1, 1, "", "iterator"], [53, 1, 1, "", "load_state_dict"], [53, 1, 1, "", "next"], [53, 1, 1, "", "pause"], [53, 2, 1, "", "policy_version"], [53, 1, 1, "", "receive_weights"], [53, 1, 1, "", "register_scheme_receiver"], [53, 1, 1, "", "reset"], [53, 2, 1, "", "rollout"], [53, 1, 1, "", "set_seed"], [53, 1, 1, "", "shutdown"], [53, 1, 1, "", "start"], [53, 1, 1, "", "state_dict"], [53, 2, 1, "", "total_dialog_turns"], [53, 1, 1, "", "update_policy_weights_"], [53, 2, 1, "", "weight_updater"], [53, 2, 1, "", "worker_idx"]], "torchrl.collectors.llm.vLLMUpdater": [[54, 1, 1, "", "_get_server_weights"], [54, 1, 1, "", "_maybe_map_weights"], [54, 1, 1, "", "_sync_weights_with_worker"], [54, 1, 1, "id0", "all_worker_ids"], [54, 2, 1, "", "collector"], [54, 2, 1, "", "collectors"], [54, 1, 1, "", "from_policy"], [54, 1, 1, "", "get_model_metadata"], [54, 1, 1, "", "increment_version"], [54, 1, 1, "id1", "init"], [54, 2, 1, "", "post_hooks"], [54, 1, 1, "", "push_weights"], [54, 1, 1, "", "register_collector"], [54, 1, 1, "", "register_post_hook"]], "torchrl.collectors.llm.vLLMUpdaterV2": [[55, 1, 1, "", "all_worker_ids"], [55, 2, 1, "", "collector"], [55, 2, 1, "", "collectors"], [55, 1, 1, "", "from_policy"], [55, 1, 1, "", "get_model_metadata"], [55, 1, 1, "", "get_tp_size"], [55, 1, 1, "", "increment_version"], [55, 1, 1, "", "init"], [55, 2, 1, "", "post_hooks"], [55, 1, 1, "", "push_weights"], [55, 1, 1, "", "push_weights_from_transformers"], [55, 1, 1, "", "push_weights_from_transformers_optimized"], [55, 1, 1, "", "register_collector"], [55, 1, 1, "", "register_post_hook"]], "torchrl.collectors.utils": [[56, 3, 1, "", "split_trajectories"]], "torchrl.data": [[57, 0, 1, "", "Binary"], [58, 0, 1, "", "Bounded"], [59, 0, 1, "", "Categorical"], [60, 0, 1, "", "Composite"], [61, 0, 1, "", "MultiCategorical"], [62, 0, 1, "", "MultiOneHot"], [63, 0, 1, "", "NonTensor"], [64, 0, 1, "", "OneHot"], [65, 0, 1, "", "PrioritizedReplayBuffer"], [66, 0, 1, "", "RayReplayBuffer"], [67, 0, 1, "", "RemoteTensorDictReplayBuffer"], [68, 0, 1, "", "ReplayBuffer"], [69, 0, 1, "", "ReplayBufferEnsemble"], [70, 0, 1, "", "Stacked"], [71, 0, 1, "", "StackedComposite"], [72, 0, 1, "", "TensorDictPrioritizedReplayBuffer"], [73, 0, 1, "", "TensorDictReplayBuffer"], [74, 0, 1, "", "TensorSpec"], [75, 0, 1, "", "Unbounded"], [76, 0, 1, "", "UnboundedContinuous"], [77, 0, 1, "", "UnboundedDiscrete"]], "torchrl.data.Binary": [[57, 1, 1, "", "assert_is_in"], [57, 1, 1, "", "cardinality"], [57, 1, 1, "", "clear_device_"], [57, 1, 1, "", "clone"], [57, 1, 1, "", "contains"], [57, 1, 1, "", "cpu"], [57, 1, 1, "", "cuda"], [57, 4, 1, "", "device"], [57, 1, 1, "", "encode"], [57, 1, 1, "", "enumerate"], [57, 1, 1, "", "erase_memoize_cache"], [57, 1, 1, "", "expand"], [57, 1, 1, "", "flatten"], [57, 1, 1, "", "implements_for_spec"], [57, 1, 1, "", "index"], [57, 1, 1, "", "is_in"], [57, 1, 1, "", "make_neg_dim"], [57, 1, 1, "", "memoize_encode"], [57, 2, 1, "", "ndim"], [57, 1, 1, "", "ndimension"], [57, 1, 1, "", "one"], [57, 1, 1, "", "ones"], [57, 1, 1, "", "project"], [57, 1, 1, "", "rand"], [57, 1, 1, "", "reshape"], [57, 1, 1, "", "sample"], [57, 1, 1, "", "set_provisional_n"], [57, 1, 1, "", "squeeze"], [57, 1, 1, "", "to"], [57, 1, 1, "", "to_categorical"], [57, 1, 1, "", "to_categorical_spec"], [57, 1, 1, "", "to_numpy"], [57, 1, 1, "", "to_one_hot"], [57, 1, 1, "", "to_one_hot_spec"], [57, 1, 1, "", "type_check"], [57, 1, 1, "", "unflatten"], [57, 1, 1, "", "unsqueeze"], [57, 1, 1, "", "update_mask"], [57, 1, 1, "", "view"], [57, 1, 1, "", "zero"], [57, 1, 1, "", "zeros"]], "torchrl.data.Bounded": [[58, 1, 1, "", "assert_is_in"], [58, 1, 1, "", "cardinality"], [58, 1, 1, "", "clear_device_"], [58, 1, 1, "", "clone"], [58, 1, 1, "", "contains"], [58, 1, 1, "", "cpu"], [58, 1, 1, "", "cuda"], [58, 2, 1, "", "device"], [58, 1, 1, "", "encode"], [58, 1, 1, "", "enumerate"], [58, 1, 1, "", "erase_memoize_cache"], [58, 1, 1, "", "expand"], [58, 1, 1, "", "flatten"], [58, 1, 1, "", "implements_for_spec"], [58, 1, 1, "", "index"], [58, 1, 1, "", "is_in"], [58, 1, 1, "", "make_neg_dim"], [58, 1, 1, "", "memoize_encode"], [58, 2, 1, "", "ndim"], [58, 1, 1, "", "ndimension"], [58, 1, 1, "", "one"], [58, 1, 1, "", "ones"], [58, 1, 1, "", "project"], [58, 1, 1, "", "rand"], [58, 1, 1, "", "reshape"], [58, 1, 1, "", "sample"], [58, 1, 1, "", "squeeze"], [58, 1, 1, "", "to"], [58, 1, 1, "", "to_numpy"], [58, 1, 1, "", "type_check"], [58, 1, 1, "", "unflatten"], [58, 1, 1, "", "unsqueeze"], [58, 1, 1, "", "view"], [58, 1, 1, "", "zero"], [58, 1, 1, "", "zeros"]], "torchrl.data.Categorical": [[59, 1, 1, "", "assert_is_in"], [59, 1, 1, "", "cardinality"], [59, 1, 1, "", "clear_device_"], [59, 1, 1, "", "clone"], [59, 1, 1, "", "contains"], [59, 1, 1, "", "cpu"], [59, 1, 1, "", "cuda"], [59, 4, 1, "", "device"], [59, 1, 1, "", "encode"], [59, 1, 1, "", "enumerate"], [59, 1, 1, "", "erase_memoize_cache"], [59, 1, 1, "", "expand"], [59, 1, 1, "", "flatten"], [59, 1, 1, "", "implements_for_spec"], [59, 1, 1, "", "index"], [59, 1, 1, "", "is_in"], [59, 1, 1, "", "make_neg_dim"], [59, 1, 1, "", "memoize_encode"], [59, 2, 1, "", "ndim"], [59, 1, 1, "", "ndimension"], [59, 1, 1, "", "one"], [59, 1, 1, "", "ones"], [59, 1, 1, "", "project"], [59, 1, 1, "", "rand"], [59, 1, 1, "", "reshape"], [59, 1, 1, "", "sample"], [59, 1, 1, "", "set_provisional_n"], [59, 1, 1, "", "squeeze"], [59, 1, 1, "", "to"], [59, 1, 1, "", "to_categorical"], [59, 1, 1, "", "to_categorical_spec"], [59, 1, 1, "", "to_numpy"], [59, 1, 1, "", "to_one_hot"], [59, 1, 1, "", "to_one_hot_spec"], [59, 1, 1, "", "type_check"], [59, 1, 1, "", "unflatten"], [59, 1, 1, "", "unsqueeze"], [59, 1, 1, "", "update_mask"], [59, 1, 1, "", "view"], [59, 1, 1, "", "zero"], [59, 1, 1, "", "zeros"]], "torchrl.data.Composite": [[60, 1, 1, "", "assert_is_in"], [60, 1, 1, "", "cardinality"], [60, 1, 1, "", "clear_device_"], [60, 1, 1, "", "clone"], [60, 1, 1, "", "contains"], [60, 1, 1, "", "cpu"], [60, 1, 1, "", "cuda"], [60, 2, 1, "", "device"], [60, 1, 1, "", "empty"], [60, 1, 1, "", "encode"], [60, 1, 1, "", "enumerate"], [60, 1, 1, "", "erase_memoize_cache"], [60, 1, 1, "", "expand"], [60, 1, 1, "", "flatten"], [60, 1, 1, "", "get"], [60, 1, 1, "", "implements_for_spec"], [60, 1, 1, "", "index"], [60, 1, 1, "", "is_empty"], [60, 1, 1, "", "is_in"], [60, 1, 1, "", "items"], [60, 1, 1, "", "keys"], [60, 1, 1, "", "lock_"], [60, 1, 1, "", "make_neg_dim"], [60, 1, 1, "", "memoize_encode"], [60, 2, 1, "", "names"], [60, 2, 1, "", "ndim"], [60, 1, 1, "", "ndimension"], [60, 1, 1, "", "one"], [60, 1, 1, "", "ones"], [60, 1, 1, "", "ones_update"], [60, 1, 1, "", "pop"], [60, 1, 1, "", "project"], [60, 1, 1, "", "rand"], [60, 1, 1, "", "rand_update"], [60, 1, 1, "", "refine_names"], [60, 1, 1, "", "reshape"], [60, 1, 1, "", "sample"], [60, 1, 1, "", "separates"], [60, 1, 1, "", "set"], [60, 1, 1, "", "squeeze"], [60, 1, 1, "", "to"], [60, 1, 1, "", "to_numpy"], [60, 1, 1, "", "type_check"], [60, 1, 1, "", "unflatten"], [60, 1, 1, "", "unlock_"], [60, 1, 1, "", "unsqueeze"], [60, 1, 1, "", "values"], [60, 1, 1, "", "view"], [60, 1, 1, "", "zero"], [60, 1, 1, "", "zeros"], [60, 1, 1, "", "zeros_update"]], "torchrl.data.MultiCategorical": [[61, 1, 1, "", "assert_is_in"], [61, 1, 1, "", "cardinality"], [61, 1, 1, "", "clear_device_"], [61, 1, 1, "", "clone"], [61, 1, 1, "", "contains"], [61, 1, 1, "", "cpu"], [61, 1, 1, "", "cuda"], [61, 4, 1, "", "device"], [61, 1, 1, "", "encode"], [61, 1, 1, "", "enumerate"], [61, 1, 1, "", "erase_memoize_cache"], [61, 1, 1, "", "expand"], [61, 1, 1, "", "flatten"], [61, 1, 1, "", "implements_for_spec"], [61, 1, 1, "", "index"], [61, 1, 1, "", "is_in"], [61, 1, 1, "", "make_neg_dim"], [61, 1, 1, "", "memoize_encode"], [61, 2, 1, "", "ndim"], [61, 1, 1, "", "ndimension"], [61, 1, 1, "", "one"], [61, 1, 1, "", "ones"], [61, 1, 1, "", "project"], [61, 1, 1, "", "rand"], [61, 1, 1, "", "reshape"], [61, 1, 1, "", "sample"], [61, 1, 1, "", "set_provisional_n"], [61, 1, 1, "", "squeeze"], [61, 1, 1, "", "to"], [61, 1, 1, "", "to_categorical"], [61, 1, 1, "", "to_categorical_spec"], [61, 1, 1, "", "to_numpy"], [61, 1, 1, "", "to_one_hot"], [61, 1, 1, "", "to_one_hot_spec"], [61, 1, 1, "", "type_check"], [61, 1, 1, "", "unflatten"], [61, 1, 1, "", "unsqueeze"], [61, 1, 1, "", "update_mask"], [61, 1, 1, "", "view"], [61, 1, 1, "", "zero"], [61, 1, 1, "", "zeros"]], "torchrl.data.MultiOneHot": [[62, 1, 1, "", "assert_is_in"], [62, 1, 1, "", "cardinality"], [62, 1, 1, "", "clear_device_"], [62, 1, 1, "", "clone"], [62, 1, 1, "", "contains"], [62, 1, 1, "", "cpu"], [62, 1, 1, "", "cuda"], [62, 4, 1, "", "device"], [62, 1, 1, "", "encode"], [62, 1, 1, "", "enumerate"], [62, 1, 1, "", "erase_memoize_cache"], [62, 1, 1, "", "expand"], [62, 1, 1, "", "flatten"], [62, 1, 1, "", "implements_for_spec"], [62, 1, 1, "", "index"], [62, 1, 1, "", "is_in"], [62, 1, 1, "", "make_neg_dim"], [62, 1, 1, "", "memoize_encode"], [62, 2, 1, "", "ndim"], [62, 1, 1, "", "ndimension"], [62, 1, 1, "", "one"], [62, 1, 1, "", "ones"], [62, 1, 1, "", "project"], [62, 1, 1, "", "rand"], [62, 1, 1, "", "reshape"], [62, 1, 1, "", "sample"], [62, 1, 1, "", "squeeze"], [62, 1, 1, "", "to"], [62, 1, 1, "", "to_categorical"], [62, 1, 1, "", "to_categorical_spec"], [62, 1, 1, "", "to_numpy"], [62, 1, 1, "", "to_one_hot"], [62, 1, 1, "", "to_one_hot_spec"], [62, 1, 1, "", "type_check"], [62, 1, 1, "", "unflatten"], [62, 1, 1, "", "unsqueeze"], [62, 1, 1, "", "update_mask"], [62, 1, 1, "", "view"], [62, 1, 1, "", "zero"], [62, 1, 1, "", "zeros"]], "torchrl.data.NonTensor": [[63, 1, 1, "", "assert_is_in"], [63, 1, 1, "", "cardinality"], [63, 1, 1, "", "clear_device_"], [63, 1, 1, "", "clone"], [63, 1, 1, "", "contains"], [63, 1, 1, "", "cpu"], [63, 1, 1, "", "cuda"], [63, 2, 1, "", "device"], [63, 1, 1, "", "encode"], [63, 1, 1, "", "enumerate"], [63, 1, 1, "", "erase_memoize_cache"], [63, 1, 1, "", "expand"], [63, 1, 1, "", "flatten"], [63, 1, 1, "", "implements_for_spec"], [63, 1, 1, "", "index"], [63, 1, 1, "", "is_in"], [63, 1, 1, "", "make_neg_dim"], [63, 1, 1, "", "memoize_encode"], [63, 2, 1, "", "ndim"], [63, 1, 1, "", "ndimension"], [63, 1, 1, "", "one"], [63, 1, 1, "", "ones"], [63, 1, 1, "", "project"], [63, 1, 1, "", "rand"], [63, 1, 1, "", "reshape"], [63, 1, 1, "", "sample"], [63, 1, 1, "", "squeeze"], [63, 1, 1, "", "to"], [63, 1, 1, "", "to_numpy"], [63, 1, 1, "", "type_check"], [63, 1, 1, "", "unflatten"], [63, 1, 1, "", "unsqueeze"], [63, 1, 1, "", "view"], [63, 1, 1, "", "zero"], [63, 1, 1, "", "zeros"]], "torchrl.data.OneHot": [[64, 1, 1, "", "assert_is_in"], [64, 1, 1, "", "cardinality"], [64, 1, 1, "", "clear_device_"], [64, 1, 1, "", "clone"], [64, 1, 1, "", "contains"], [64, 1, 1, "", "cpu"], [64, 1, 1, "", "cuda"], [64, 4, 1, "", "device"], [64, 1, 1, "", "encode"], [64, 1, 1, "", "enumerate"], [64, 1, 1, "", "erase_memoize_cache"], [64, 1, 1, "", "expand"], [64, 1, 1, "", "flatten"], [64, 1, 1, "", "implements_for_spec"], [64, 1, 1, "", "index"], [64, 1, 1, "", "is_in"], [64, 1, 1, "", "make_neg_dim"], [64, 1, 1, "", "memoize_encode"], [64, 2, 1, "", "ndim"], [64, 1, 1, "", "ndimension"], [64, 1, 1, "", "one"], [64, 1, 1, "", "ones"], [64, 1, 1, "", "project"], [64, 1, 1, "", "rand"], [64, 1, 1, "", "reshape"], [64, 1, 1, "", "sample"], [64, 1, 1, "", "squeeze"], [64, 1, 1, "", "to"], [64, 1, 1, "", "to_categorical"], [64, 1, 1, "", "to_categorical_spec"], [64, 1, 1, "", "to_numpy"], [64, 1, 1, "", "to_one_hot"], [64, 1, 1, "", "to_one_hot_spec"], [64, 1, 1, "", "type_check"], [64, 1, 1, "", "unflatten"], [64, 1, 1, "", "unsqueeze"], [64, 1, 1, "", "update_mask"], [64, 1, 1, "", "view"], [64, 1, 1, "", "zero"], [64, 1, 1, "", "zeros"]], "torchrl.data.PrioritizedReplayBuffer": [[65, 1, 1, "", "add"], [65, 1, 1, "", "append_transform"], [65, 1, 1, "", "as_remote"], [65, 2, 1, "", "batch_size"], [65, 1, 1, "", "dump"], [65, 1, 1, "", "dumps"], [65, 1, 1, "", "empty"], [65, 1, 1, "", "extend"], [65, 2, 1, "", "initialized"], [65, 1, 1, "", "insert_transform"], [65, 1, 1, "", "load"], [65, 1, 1, "", "loads"], [65, 1, 1, "", "next"], [65, 1, 1, "", "register_load_hook"], [65, 1, 1, "", "register_save_hook"], [65, 1, 1, "", "sample"], [65, 2, 1, "", "sampler"], [65, 1, 1, "", "save"], [65, 1, 1, "", "set_sampler"], [65, 1, 1, "", "set_storage"], [65, 1, 1, "", "set_writer"], [65, 2, 1, "", "storage"], [65, 2, 1, "", "transform"], [65, 2, 1, "", "write_count"], [65, 2, 1, "", "writer"]], "torchrl.data.RayReplayBuffer": [[66, 1, 1, "", "add"], [66, 1, 1, "", "append_transform"], [66, 1, 1, "", "as_remote"], [66, 2, 1, "", "batch_size"], [66, 1, 1, "", "close"], [66, 1, 1, "", "dump"], [66, 1, 1, "", "dumps"], [66, 1, 1, "", "empty"], [66, 1, 1, "", "extend"], [66, 2, 1, "", "initialized"], [66, 1, 1, "", "insert_transform"], [66, 1, 1, "", "load"], [66, 1, 1, "", "loads"], [66, 1, 1, "", "next"], [66, 1, 1, "", "register_load_hook"], [66, 1, 1, "", "register_save_hook"], [66, 1, 1, "", "sample"], [66, 2, 1, "", "sampler"], [66, 1, 1, "", "save"], [66, 1, 1, "", "set_sampler"], [66, 1, 1, "", "set_storage"], [66, 1, 1, "", "set_writer"], [66, 2, 1, "", "storage"], [66, 2, 1, "", "transform"], [66, 2, 1, "", "write_count"], [66, 2, 1, "", "writer"]], "torchrl.data.RemoteTensorDictReplayBuffer": [[67, 1, 1, "", "add"], [67, 1, 1, "", "append_transform"], [67, 1, 1, "", "as_remote"], [67, 2, 1, "", "batch_size"], [67, 1, 1, "", "dump"], [67, 1, 1, "", "dumps"], [67, 1, 1, "", "empty"], [67, 1, 1, "", "extend"], [67, 2, 1, "", "initialized"], [67, 1, 1, "", "insert_transform"], [67, 1, 1, "", "load"], [67, 1, 1, "", "loads"], [67, 1, 1, "", "next"], [67, 1, 1, "", "register_load_hook"], [67, 1, 1, "", "register_save_hook"], [67, 1, 1, "", "sample"], [67, 2, 1, "", "sampler"], [67, 1, 1, "", "save"], [67, 1, 1, "", "set_sampler"], [67, 1, 1, "", "set_storage"], [67, 1, 1, "", "set_writer"], [67, 2, 1, "", "storage"], [67, 2, 1, "", "transform"], [67, 2, 1, "", "write_count"], [67, 2, 1, "", "writer"]], "torchrl.data.ReplayBuffer": [[68, 1, 1, "", "add"], [68, 1, 1, "", "append_transform"], [68, 1, 1, "", "as_remote"], [68, 2, 1, "", "batch_size"], [68, 1, 1, "", "dump"], [68, 1, 1, "", "dumps"], [68, 1, 1, "", "empty"], [68, 1, 1, "", "extend"], [68, 2, 1, "", "initialized"], [68, 1, 1, "", "insert_transform"], [68, 1, 1, "", "load"], [68, 1, 1, "", "loads"], [68, 1, 1, "", "next"], [68, 1, 1, "", "register_load_hook"], [68, 1, 1, "", "register_save_hook"], [68, 1, 1, "", "sample"], [68, 2, 1, "", "sampler"], [68, 1, 1, "", "save"], [68, 1, 1, "", "set_sampler"], [68, 1, 1, "", "set_storage"], [68, 1, 1, "", "set_writer"], [68, 2, 1, "", "storage"], [68, 2, 1, "", "transform"], [68, 2, 1, "", "write_count"], [68, 2, 1, "", "writer"]], "torchrl.data.ReplayBufferEnsemble": [[69, 1, 1, "", "add"], [69, 1, 1, "", "append_transform"], [69, 1, 1, "", "as_remote"], [69, 2, 1, "", "batch_size"], [69, 1, 1, "", "dump"], [69, 1, 1, "", "dumps"], [69, 1, 1, "", "empty"], [69, 1, 1, "", "extend"], [69, 2, 1, "", "initialized"], [69, 1, 1, "", "insert_transform"], [69, 1, 1, "", "load"], [69, 1, 1, "", "loads"], [69, 1, 1, "", "next"], [69, 1, 1, "", "register_load_hook"], [69, 1, 1, "", "register_save_hook"], [69, 1, 1, "", "sample"], [69, 2, 1, "", "sampler"], [69, 1, 1, "", "save"], [69, 1, 1, "", "set_sampler"], [69, 1, 1, "", "set_storage"], [69, 1, 1, "", "set_writer"], [69, 2, 1, "", "storage"], [69, 2, 1, "", "transform"], [69, 2, 1, "", "write_count"], [69, 2, 1, "", "writer"]], "torchrl.data.Stacked": [[70, 1, 1, "", "assert_is_in"], [70, 1, 1, "", "cardinality"], [70, 1, 1, "", "clear_device_"], [70, 1, 1, "", "clone"], [70, 1, 1, "", "contains"], [70, 1, 1, "", "cpu"], [70, 1, 1, "", "cuda"], [70, 2, 1, "", "device"], [70, 1, 1, "", "encode"], [70, 1, 1, "", "enumerate"], [70, 1, 1, "", "erase_memoize_cache"], [70, 1, 1, "", "expand"], [70, 1, 1, "", "flatten"], [70, 1, 1, "", "implements_for_spec"], [70, 1, 1, "", "index"], [70, 1, 1, "", "is_in"], [70, 1, 1, "", "make_neg_dim"], [70, 1, 1, "", "memoize_encode"], [70, 2, 1, "", "ndim"], [70, 1, 1, "", "ndimension"], [70, 1, 1, "", "one"], [70, 1, 1, "", "ones"], [70, 1, 1, "", "project"], [70, 1, 1, "", "rand"], [70, 1, 1, "", "reshape"], [70, 1, 1, "", "sample"], [70, 1, 1, "", "squeeze"], [70, 1, 1, "", "to"], [70, 1, 1, "", "to_numpy"], [70, 1, 1, "", "type_check"], [70, 1, 1, "", "unflatten"], [70, 1, 1, "", "unsqueeze"], [70, 1, 1, "", "view"], [70, 1, 1, "", "zero"], [70, 1, 1, "", "zeros"]], "torchrl.data.StackedComposite": [[71, 1, 1, "", "assert_is_in"], [71, 1, 1, "", "cardinality"], [71, 1, 1, "", "clear_device_"], [71, 1, 1, "", "clone"], [71, 1, 1, "", "contains"], [71, 1, 1, "", "cpu"], [71, 1, 1, "", "cuda"], [71, 2, 1, "", "device"], [71, 1, 1, "", "empty"], [71, 1, 1, "", "encode"], [71, 1, 1, "", "enumerate"], [71, 1, 1, "", "erase_memoize_cache"], [71, 1, 1, "", "expand"], [71, 1, 1, "", "flatten"], [71, 1, 1, "", "get"], [71, 1, 1, "", "implements_for_spec"], [71, 1, 1, "", "index"], [71, 1, 1, "", "is_empty"], [71, 1, 1, "", "is_in"], [71, 1, 1, "", "items"], [71, 1, 1, "", "keys"], [71, 1, 1, "", "lock_"], [71, 1, 1, "", "make_neg_dim"], [71, 1, 1, "", "memoize_encode"], [71, 2, 1, "", "names"], [71, 2, 1, "", "ndim"], [71, 1, 1, "", "ndimension"], [71, 1, 1, "", "one"], [71, 1, 1, "", "ones"], [71, 1, 1, "", "ones_update"], [71, 1, 1, "", "pop"], [71, 1, 1, "", "project"], [71, 1, 1, "", "rand"], [71, 1, 1, "", "rand_update"], [71, 1, 1, "", "refine_names"], [71, 1, 1, "", "reshape"], [71, 1, 1, "", "sample"], [71, 1, 1, "", "separates"], [71, 1, 1, "", "set"], [71, 1, 1, "", "squeeze"], [71, 1, 1, "", "to"], [71, 1, 1, "", "to_numpy"], [71, 1, 1, "", "type_check"], [71, 1, 1, "", "unflatten"], [71, 1, 1, "", "unlock_"], [71, 1, 1, "", "unsqueeze"], [71, 1, 1, "", "values"], [71, 1, 1, "", "view"], [71, 1, 1, "", "zero"], [71, 1, 1, "", "zeros"], [71, 1, 1, "", "zeros_update"]], "torchrl.data.TensorDictPrioritizedReplayBuffer": [[72, 1, 1, "", "add"], [72, 1, 1, "", "append_transform"], [72, 1, 1, "", "as_remote"], [72, 2, 1, "", "batch_size"], [72, 1, 1, "", "dump"], [72, 1, 1, "", "dumps"], [72, 1, 1, "", "empty"], [72, 1, 1, "", "extend"], [72, 2, 1, "", "initialized"], [72, 1, 1, "", "insert_transform"], [72, 1, 1, "", "load"], [72, 1, 1, "", "loads"], [72, 1, 1, "", "next"], [72, 1, 1, "", "register_load_hook"], [72, 1, 1, "", "register_save_hook"], [72, 1, 1, "", "sample"], [72, 2, 1, "", "sampler"], [72, 1, 1, "", "save"], [72, 1, 1, "", "set_sampler"], [72, 1, 1, "", "set_storage"], [72, 1, 1, "", "set_writer"], [72, 2, 1, "", "storage"], [72, 2, 1, "", "transform"], [72, 2, 1, "", "write_count"], [72, 2, 1, "", "writer"]], "torchrl.data.TensorDictReplayBuffer": [[73, 1, 1, "", "add"], [73, 1, 1, "", "append_transform"], [73, 1, 1, "", "as_remote"], [73, 2, 1, "", "batch_size"], [73, 1, 1, "", "dump"], [73, 1, 1, "", "dumps"], [73, 1, 1, "", "empty"], [73, 1, 1, "", "extend"], [73, 2, 1, "", "initialized"], [73, 1, 1, "", "insert_transform"], [73, 1, 1, "", "load"], [73, 1, 1, "", "loads"], [73, 1, 1, "", "next"], [73, 1, 1, "", "register_load_hook"], [73, 1, 1, "", "register_save_hook"], [73, 1, 1, "", "sample"], [73, 2, 1, "", "sampler"], [73, 1, 1, "", "save"], [73, 1, 1, "", "set_sampler"], [73, 1, 1, "", "set_storage"], [73, 1, 1, "", "set_writer"], [73, 2, 1, "", "storage"], [73, 2, 1, "", "transform"], [73, 2, 1, "", "write_count"], [73, 2, 1, "", "writer"]], "torchrl.data.TensorSpec": [[74, 1, 1, "", "assert_is_in"], [74, 1, 1, "", "cardinality"], [74, 1, 1, "", "clear_device_"], [74, 1, 1, "", "clone"], [74, 1, 1, "", "contains"], [74, 1, 1, "", "cpu"], [74, 1, 1, "", "cuda"], [74, 2, 1, "", "device"], [74, 1, 1, "", "encode"], [74, 1, 1, "", "enumerate"], [74, 1, 1, "", "erase_memoize_cache"], [74, 1, 1, "", "expand"], [74, 1, 1, "", "flatten"], [74, 1, 1, "", "implements_for_spec"], [74, 1, 1, "", "index"], [74, 1, 1, "", "is_in"], [74, 1, 1, "", "make_neg_dim"], [74, 1, 1, "", "memoize_encode"], [74, 2, 1, "", "ndim"], [74, 1, 1, "", "ndimension"], [74, 1, 1, "", "one"], [74, 1, 1, "", "ones"], [74, 1, 1, "", "project"], [74, 1, 1, "", "rand"], [74, 1, 1, "", "reshape"], [74, 1, 1, "", "sample"], [74, 1, 1, "", "squeeze"], [74, 1, 1, "", "to"], [74, 1, 1, "", "to_numpy"], [74, 1, 1, "", "type_check"], [74, 1, 1, "", "unflatten"], [74, 1, 1, "", "unsqueeze"], [74, 1, 1, "", "view"], [74, 1, 1, "", "zero"], [74, 1, 1, "", "zeros"]], "torchrl.data.Unbounded": [[75, 1, 1, "", "assert_is_in"], [75, 1, 1, "", "cardinality"], [75, 1, 1, "", "clear_device_"], [75, 1, 1, "", "clone"], [75, 1, 1, "", "contains"], [75, 1, 1, "", "cpu"], [75, 1, 1, "", "cuda"], [75, 2, 1, "", "device"], [75, 1, 1, "", "encode"], [75, 1, 1, "", "enumerate"], [75, 1, 1, "", "erase_memoize_cache"], [75, 1, 1, "", "expand"], [75, 1, 1, "", "flatten"], [75, 1, 1, "", "implements_for_spec"], [75, 1, 1, "", "index"], [75, 1, 1, "", "is_in"], [75, 1, 1, "", "make_neg_dim"], [75, 1, 1, "", "memoize_encode"], [75, 2, 1, "", "ndim"], [75, 1, 1, "", "ndimension"], [75, 1, 1, "", "one"], [75, 1, 1, "", "ones"], [75, 1, 1, "", "project"], [75, 1, 1, "", "rand"], [75, 1, 1, "", "reshape"], [75, 1, 1, "", "sample"], [75, 1, 1, "", "squeeze"], [75, 1, 1, "", "to"], [75, 1, 1, "", "to_numpy"], [75, 1, 1, "", "type_check"], [75, 1, 1, "", "unflatten"], [75, 1, 1, "", "unsqueeze"], [75, 1, 1, "", "view"], [75, 1, 1, "", "zero"], [75, 1, 1, "", "zeros"]], "torchrl.data.UnboundedContinuous": [[76, 1, 1, "", "assert_is_in"], [76, 1, 1, "", "cardinality"], [76, 1, 1, "", "clear_device_"], [76, 1, 1, "", "clone"], [76, 1, 1, "", "contains"], [76, 1, 1, "", "cpu"], [76, 1, 1, "", "cuda"], [76, 2, 1, "", "device"], [76, 1, 1, "", "encode"], [76, 1, 1, "", "enumerate"], [76, 1, 1, "", "erase_memoize_cache"], [76, 1, 1, "", "expand"], [76, 1, 1, "", "flatten"], [76, 1, 1, "", "implements_for_spec"], [76, 1, 1, "", "index"], [76, 1, 1, "", "is_in"], [76, 1, 1, "", "make_neg_dim"], [76, 1, 1, "", "memoize_encode"], [76, 2, 1, "", "ndim"], [76, 1, 1, "", "ndimension"], [76, 1, 1, "", "one"], [76, 1, 1, "", "ones"], [76, 1, 1, "", "project"], [76, 1, 1, "", "rand"], [76, 1, 1, "", "reshape"], [76, 1, 1, "", "sample"], [76, 1, 1, "", "squeeze"], [76, 1, 1, "", "to"], [76, 1, 1, "", "to_numpy"], [76, 1, 1, "", "type_check"], [76, 1, 1, "", "unflatten"], [76, 1, 1, "", "unsqueeze"], [76, 1, 1, "", "view"], [76, 1, 1, "", "zero"], [76, 1, 1, "", "zeros"]], "torchrl.data.UnboundedDiscrete": [[77, 1, 1, "", "assert_is_in"], [77, 1, 1, "", "cardinality"], [77, 1, 1, "", "clear_device_"], [77, 1, 1, "", "clone"], [77, 1, 1, "", "contains"], [77, 1, 1, "", "cpu"], [77, 1, 1, "", "cuda"], [77, 2, 1, "", "device"], [77, 1, 1, "", "encode"], [77, 1, 1, "", "enumerate"], [77, 1, 1, "", "erase_memoize_cache"], [77, 1, 1, "", "expand"], [77, 1, 1, "", "flatten"], [77, 1, 1, "", "implements_for_spec"], [77, 1, 1, "", "index"], [77, 1, 1, "", "is_in"], [77, 1, 1, "", "make_neg_dim"], [77, 1, 1, "", "memoize_encode"], [77, 2, 1, "", "ndim"], [77, 1, 1, "", "ndimension"], [77, 1, 1, "", "one"], [77, 1, 1, "", "ones"], [77, 1, 1, "", "project"], [77, 1, 1, "", "rand"], [77, 1, 1, "", "reshape"], [77, 1, 1, "", "sample"], [77, 1, 1, "", "squeeze"], [77, 1, 1, "", "to"], [77, 1, 1, "", "to_numpy"], [77, 1, 1, "", "type_check"], [77, 1, 1, "", "unflatten"], [77, 1, 1, "", "unsqueeze"], [77, 1, 1, "", "view"], [77, 1, 1, "", "zero"], [77, 1, 1, "", "zeros"]], "torchrl.data.datasets": [[78, 0, 1, "", "AtariDQNExperienceReplay"], [79, 0, 1, "", "D4RLExperienceReplay"], [80, 0, 1, "", "GenDGRLExperienceReplay"], [81, 0, 1, "", "MinariExperienceReplay"], [82, 0, 1, "", "OpenMLExperienceReplay"], [83, 0, 1, "", "OpenXExperienceReplay"], [84, 0, 1, "", "RobosetExperienceReplay"], [85, 0, 1, "", "VD4RLExperienceReplay"]], "torchrl.data.datasets.AtariDQNExperienceReplay": [[78, 1, 1, "", "add"], [78, 1, 1, "", "append_transform"], [78, 1, 1, "", "as_remote"], [78, 2, 1, "", "batch_size"], [78, 2, 1, "", "data_path"], [78, 2, 1, "", "data_path_root"], [78, 1, 1, "", "delete"], [78, 1, 1, "", "dump"], [78, 1, 1, "", "dumps"], [78, 1, 1, "", "empty"], [78, 1, 1, "", "extend"], [78, 2, 1, "", "initialized"], [78, 1, 1, "", "insert_transform"], [78, 1, 1, "", "load"], [78, 1, 1, "", "loads"], [78, 1, 1, "", "next"], [78, 1, 1, "", "preprocess"], [78, 1, 1, "", "register_load_hook"], [78, 1, 1, "", "register_save_hook"], [78, 1, 1, "", "sample"], [78, 2, 1, "", "sampler"], [78, 1, 1, "", "save"], [78, 1, 1, "", "set_sampler"], [78, 1, 1, "", "set_storage"], [78, 1, 1, "", "set_writer"], [78, 2, 1, "", "storage"], [78, 2, 1, "", "transform"], [78, 2, 1, "", "write_count"], [78, 2, 1, "", "writer"]], "torchrl.data.datasets.D4RLExperienceReplay": [[79, 1, 1, "", "add"], [79, 1, 1, "", "append_transform"], [79, 1, 1, "", "as_remote"], [79, 2, 1, "", "batch_size"], [79, 2, 1, "", "data_path"], [79, 2, 1, "", "data_path_root"], [79, 1, 1, "", "delete"], [79, 1, 1, "", "dump"], [79, 1, 1, "", "dumps"], [79, 1, 1, "", "empty"], [79, 1, 1, "", "extend"], [79, 2, 1, "", "initialized"], [79, 1, 1, "", "insert_transform"], [79, 1, 1, "", "load"], [79, 1, 1, "", "loads"], [79, 1, 1, "", "next"], [79, 1, 1, "", "preprocess"], [79, 1, 1, "", "register_load_hook"], [79, 1, 1, "", "register_save_hook"], [79, 1, 1, "", "sample"], [79, 2, 1, "", "sampler"], [79, 1, 1, "", "save"], [79, 1, 1, "", "set_sampler"], [79, 1, 1, "", "set_storage"], [79, 1, 1, "", "set_writer"], [79, 2, 1, "", "storage"], [79, 2, 1, "", "transform"], [79, 2, 1, "", "write_count"], [79, 2, 1, "", "writer"]], "torchrl.data.datasets.GenDGRLExperienceReplay": [[80, 1, 1, "", "add"], [80, 1, 1, "", "append_transform"], [80, 1, 1, "", "as_remote"], [80, 2, 1, "", "batch_size"], [80, 2, 1, "", "data_path"], [80, 2, 1, "", "data_path_root"], [80, 1, 1, "", "delete"], [80, 1, 1, "", "dump"], [80, 1, 1, "", "dumps"], [80, 1, 1, "", "empty"], [80, 1, 1, "", "extend"], [80, 2, 1, "", "initialized"], [80, 1, 1, "", "insert_transform"], [80, 1, 1, "", "load"], [80, 1, 1, "", "loads"], [80, 1, 1, "", "next"], [80, 1, 1, "", "preprocess"], [80, 1, 1, "", "register_load_hook"], [80, 1, 1, "", "register_save_hook"], [80, 1, 1, "", "sample"], [80, 2, 1, "", "sampler"], [80, 1, 1, "", "save"], [80, 1, 1, "", "set_sampler"], [80, 1, 1, "", "set_storage"], [80, 1, 1, "", "set_writer"], [80, 2, 1, "", "storage"], [80, 2, 1, "", "transform"], [80, 2, 1, "", "write_count"], [80, 2, 1, "", "writer"]], "torchrl.data.datasets.MinariExperienceReplay": [[81, 1, 1, "", "add"], [81, 1, 1, "", "append_transform"], [81, 1, 1, "", "as_remote"], [81, 2, 1, "", "batch_size"], [81, 2, 1, "", "data_path"], [81, 2, 1, "", "data_path_root"], [81, 1, 1, "", "delete"], [81, 1, 1, "", "dump"], [81, 1, 1, "", "dumps"], [81, 1, 1, "", "empty"], [81, 1, 1, "", "extend"], [81, 2, 1, "", "initialized"], [81, 1, 1, "", "insert_transform"], [81, 1, 1, "", "load"], [81, 1, 1, "", "loads"], [81, 1, 1, "", "next"], [81, 1, 1, "", "preprocess"], [81, 1, 1, "", "register_load_hook"], [81, 1, 1, "", "register_save_hook"], [81, 1, 1, "", "sample"], [81, 2, 1, "", "sampler"], [81, 1, 1, "", "save"], [81, 1, 1, "", "set_sampler"], [81, 1, 1, "", "set_storage"], [81, 1, 1, "", "set_writer"], [81, 2, 1, "", "storage"], [81, 2, 1, "", "transform"], [81, 2, 1, "", "write_count"], [81, 2, 1, "", "writer"]], "torchrl.data.datasets.OpenMLExperienceReplay": [[82, 1, 1, "", "add"], [82, 1, 1, "", "append_transform"], [82, 1, 1, "", "as_remote"], [82, 2, 1, "", "batch_size"], [82, 2, 1, "", "data_path"], [82, 2, 1, "", "data_path_root"], [82, 1, 1, "", "delete"], [82, 1, 1, "", "dump"], [82, 1, 1, "", "dumps"], [82, 1, 1, "", "empty"], [82, 1, 1, "", "extend"], [82, 2, 1, "", "initialized"], [82, 1, 1, "", "insert_transform"], [82, 1, 1, "", "load"], [82, 1, 1, "", "loads"], [82, 1, 1, "", "next"], [82, 1, 1, "", "preprocess"], [82, 1, 1, "", "register_load_hook"], [82, 1, 1, "", "register_save_hook"], [82, 1, 1, "", "sample"], [82, 2, 1, "", "sampler"], [82, 1, 1, "", "save"], [82, 1, 1, "", "set_sampler"], [82, 1, 1, "", "set_storage"], [82, 1, 1, "", "set_writer"], [82, 2, 1, "", "storage"], [82, 2, 1, "", "transform"], [82, 2, 1, "", "write_count"], [82, 2, 1, "", "writer"]], "torchrl.data.datasets.OpenXExperienceReplay": [[83, 1, 1, "", "add"], [83, 1, 1, "", "append_transform"], [83, 1, 1, "", "as_remote"], [83, 2, 1, "", "batch_size"], [83, 2, 1, "", "data_path"], [83, 2, 1, "", "data_path_root"], [83, 1, 1, "", "delete"], [83, 1, 1, "", "dump"], [83, 1, 1, "", "dumps"], [83, 1, 1, "", "empty"], [83, 1, 1, "", "extend"], [83, 2, 1, "", "initialized"], [83, 1, 1, "", "insert_transform"], [83, 1, 1, "", "load"], [83, 1, 1, "", "loads"], [83, 1, 1, "", "next"], [83, 1, 1, "", "preprocess"], [83, 1, 1, "", "register_load_hook"], [83, 1, 1, "", "register_save_hook"], [83, 1, 1, "", "sample"], [83, 2, 1, "", "sampler"], [83, 1, 1, "", "save"], [83, 1, 1, "", "set_sampler"], [83, 1, 1, "", "set_storage"], [83, 1, 1, "", "set_writer"], [83, 2, 1, "", "storage"], [83, 2, 1, "", "transform"], [83, 2, 1, "", "write_count"], [83, 2, 1, "", "writer"]], "torchrl.data.datasets.RobosetExperienceReplay": [[84, 1, 1, "", "add"], [84, 1, 1, "", "append_transform"], [84, 1, 1, "", "as_remote"], [84, 2, 1, "", "batch_size"], [84, 2, 1, "", "data_path"], [84, 2, 1, "", "data_path_root"], [84, 1, 1, "", "delete"], [84, 1, 1, "", "dump"], [84, 1, 1, "", "dumps"], [84, 1, 1, "", "empty"], [84, 1, 1, "", "extend"], [84, 2, 1, "", "initialized"], [84, 1, 1, "", "insert_transform"], [84, 1, 1, "", "load"], [84, 1, 1, "", "loads"], [84, 1, 1, "", "next"], [84, 1, 1, "", "preprocess"], [84, 1, 1, "", "register_load_hook"], [84, 1, 1, "", "register_save_hook"], [84, 1, 1, "", "sample"], [84, 2, 1, "", "sampler"], [84, 1, 1, "", "save"], [84, 1, 1, "", "set_sampler"], [84, 1, 1, "", "set_storage"], [84, 1, 1, "", "set_writer"], [84, 2, 1, "", "storage"], [84, 2, 1, "", "transform"], [84, 2, 1, "", "write_count"], [84, 2, 1, "", "writer"]], "torchrl.data.datasets.VD4RLExperienceReplay": [[85, 1, 1, "", "add"], [85, 1, 1, "", "append_transform"], [85, 1, 1, "", "as_remote"], [85, 2, 1, "", "batch_size"], [85, 2, 1, "", "data_path"], [85, 2, 1, "", "data_path_root"], [85, 1, 1, "", "delete"], [85, 1, 1, "", "dump"], [85, 1, 1, "", "dumps"], [85, 1, 1, "", "empty"], [85, 1, 1, "", "extend"], [85, 2, 1, "", "initialized"], [85, 1, 1, "", "insert_transform"], [85, 1, 1, "", "load"], [85, 1, 1, "", "loads"], [85, 1, 1, "", "next"], [85, 1, 1, "", "preprocess"], [85, 1, 1, "", "register_load_hook"], [85, 1, 1, "", "register_save_hook"], [85, 1, 1, "", "sample"], [85, 2, 1, "", "sampler"], [85, 1, 1, "", "save"], [85, 1, 1, "", "set_sampler"], [85, 1, 1, "", "set_storage"], [85, 1, 1, "", "set_writer"], [85, 2, 1, "", "storage"], [85, 2, 1, "", "transform"], [85, 2, 1, "", "write_count"], [85, 2, 1, "", "writer"]], "torchrl.data.llm": [[86, 0, 1, "", "ContentBase"], [87, 0, 1, "", "History"], [88, 0, 1, "", "TopKRewardSelector"], [89, 0, 1, "", "add_chat_template"]], "torchrl.data.llm.ContentBase": [[86, 1, 1, "", "cat"], [86, 2, 1, "", "device"], [86, 1, 1, "", "dumps"], [86, 1, 1, "", "fields"], [86, 1, 1, "", "from_any"], [86, 1, 1, "", "from_dataclass"], [86, 1, 1, "", "from_h5"], [86, 1, 1, "", "from_modules"], [86, 1, 1, "", "from_namedtuple"], [86, 1, 1, "", "from_pytree"], [86, 1, 1, "", "from_remote_init"], [86, 1, 1, "", "from_struct_array"], [86, 1, 1, "", "from_tensordict"], [86, 1, 1, "", "from_tuple"], [86, 1, 1, "", "fromkeys"], [86, 1, 1, "", "get"], [86, 1, 1, "", "lazy_stack"], [86, 1, 1, "", "load"], [86, 1, 1, "", "load_"], [86, 1, 1, "", "load_memmap"], [86, 1, 1, "", "load_state_dict"], [86, 1, 1, "", "maybe_dense_stack"], [86, 1, 1, "", "memmap"], [86, 1, 1, "", "memmap_"], [86, 1, 1, "", "memmap_like"], [86, 1, 1, "", "memmap_refresh_"], [86, 1, 1, "", "save"], [86, 1, 1, "", "set"], [86, 1, 1, "", "stack"], [86, 1, 1, "", "state_dict"], [86, 1, 1, "", "to_tensordict"], [86, 1, 1, "", "unbind"]], "torchrl.data.llm.History": [[87, 1, 1, "", "append"], [87, 1, 1, "", "apply_chat_template"], [87, 1, 1, "", "cat"], [87, 1, 1, "", "default_spec"], [87, 2, 1, "", "device"], [87, 1, 1, "", "dumps"], [87, 1, 1, "", "fields"], [87, 1, 1, "", "from_any"], [87, 1, 1, "", "from_chats"], [87, 1, 1, "", "from_dataclass"], [87, 1, 1, "", "from_h5"], [87, 1, 1, "", "from_modules"], [87, 1, 1, "", "from_namedtuple"], [87, 1, 1, "", "from_pytree"], [87, 1, 1, "", "from_remote_init"], [87, 1, 1, "", "from_struct_array"], [87, 1, 1, "", "from_tensordict"], [87, 1, 1, "", "from_text"], [87, 1, 1, "", "from_tuple"], [87, 1, 1, "", "fromkeys"], [87, 1, 1, "", "get"], [87, 1, 1, "", "lazy_stack"], [87, 1, 1, "", "load"], [87, 1, 1, "", "load_"], [87, 1, 1, "", "load_memmap"], [87, 1, 1, "", "load_state_dict"], [87, 1, 1, "", "maybe_dense_stack"], [87, 1, 1, "", "memmap"], [87, 1, 1, "", "memmap_"], [87, 1, 1, "", "memmap_like"], [87, 1, 1, "", "memmap_refresh_"], [87, 1, 1, "", "save"], [87, 1, 1, "", "set"], [87, 1, 1, "", "stack"], [87, 1, 1, "", "state_dict"], [87, 1, 1, "", "to_tensordict"], [87, 1, 1, "", "unbind"]], "torchrl.data.llm.TopKRewardSelector": [[88, 1, 1, "", "add_module"], [88, 1, 1, "", "apply"], [88, 1, 1, "", "bfloat16"], [88, 1, 1, "", "buffers"], [88, 1, 1, "", "children"], [88, 1, 1, "", "close"], [88, 2, 1, "", "collector"], [88, 1, 1, "", "compile"], [88, 2, 1, "", "container"], [88, 1, 1, "", "cpu"], [88, 1, 1, "", "cuda"], [88, 1, 1, "", "double"], [88, 1, 1, "", "eval"], [88, 1, 1, "", "extra_repr"], [88, 1, 1, "", "float"], [88, 1, 1, "", "forward"], [88, 1, 1, "", "get_buffer"], [88, 1, 1, "", "get_extra_state"], [88, 1, 1, "", "get_parameter"], [88, 1, 1, "", "get_submodule"], [88, 1, 1, "", "half"], [88, 1, 1, "", "init"], [88, 1, 1, "", "inv"], [88, 1, 1, "", "ipu"], [88, 1, 1, "", "load_state_dict"], [88, 1, 1, "", "modules"], [88, 1, 1, "", "mtia"], [88, 1, 1, "", "named_buffers"], [88, 1, 1, "", "named_children"], [88, 1, 1, "", "named_modules"], [88, 1, 1, "", "named_parameters"], [88, 1, 1, "", "parameters"], [88, 2, 1, "", "parent"], [88, 1, 1, "", "register_backward_hook"], [88, 1, 1, "", "register_buffer"], [88, 1, 1, "", "register_forward_hook"], [88, 1, 1, "", "register_forward_pre_hook"], [88, 1, 1, "", "register_full_backward_hook"], [88, 1, 1, "", "register_full_backward_pre_hook"], [88, 1, 1, "", "register_load_state_dict_post_hook"], [88, 1, 1, "", "register_load_state_dict_pre_hook"], [88, 1, 1, "", "register_module"], [88, 1, 1, "", "register_parameter"], [88, 1, 1, "", "register_state_dict_post_hook"], [88, 1, 1, "", "register_state_dict_pre_hook"], [88, 1, 1, "", "requires_grad_"], [88, 1, 1, "", "set_extra_state"], [88, 1, 1, "", "set_submodule"], [88, 1, 1, "", "share_memory"], [88, 1, 1, "", "state_dict"], [88, 1, 1, "", "to"], [88, 1, 1, "", "to_empty"], [88, 1, 1, "", "train"], [88, 1, 1, "", "transform_action_spec"], [88, 1, 1, "", "transform_done_spec"], [88, 1, 1, "", "transform_env_batch_size"], [88, 1, 1, "", "transform_env_device"], [88, 1, 1, "", "transform_input_spec"], [88, 1, 1, "", "transform_observation_spec"], [88, 1, 1, "", "transform_output_spec"], [88, 1, 1, "", "transform_reward_spec"], [88, 1, 1, "", "transform_state_spec"], [88, 1, 1, "", "type"], [88, 1, 1, "", "xpu"], [88, 1, 1, "", "zero_grad"]], "torchrl.data.replay_buffers": [[90, 0, 1, "", "CompressedListStorage"], [91, 0, 1, "", "CompressedListStorageCheckpointer"], [92, 0, 1, "", "FlatStorageCheckpointer"], [93, 0, 1, "", "H5StorageCheckpointer"], [94, 0, 1, "", "ImmutableDatasetWriter"], [95, 0, 1, "", "LazyMemmapStorage"], [96, 0, 1, "", "LazyStackStorage"], [97, 0, 1, "", "LazyTensorStorage"], [98, 0, 1, "", "ListStorage"], [99, 0, 1, "", "ListStorageCheckpointer"], [100, 0, 1, "", "NestedStorageCheckpointer"], [101, 0, 1, "", "PrioritizedSampler"], [102, 0, 1, "", "PrioritizedSliceSampler"], [103, 0, 1, "", "RandomSampler"], [104, 0, 1, "", "RoundRobinWriter"], [105, 0, 1, "", "Sampler"], [106, 0, 1, "", "SamplerEnsemble"], [107, 0, 1, "", "SamplerWithoutReplacement"], [108, 0, 1, "", "SliceSampler"], [109, 0, 1, "", "SliceSamplerWithoutReplacement"], [110, 0, 1, "", "Storage"], [111, 0, 1, "", "StorageCheckpointerBase"], [112, 0, 1, "", "StorageEnsemble"], [113, 0, 1, "", "StorageEnsembleCheckpointer"], [114, 0, 1, "", "TensorDictMaxValueWriter"], [115, 0, 1, "", "TensorDictRoundRobinWriter"], [116, 0, 1, "", "TensorStorage"], [117, 0, 1, "", "TensorStorageCheckpointer"], [118, 0, 1, "", "Writer"], [119, 0, 1, "", "WriterEnsemble"]], "torchrl.data.replay_buffers.CompressedListStorage": [[90, 1, 1, "", "attach"], [90, 1, 1, "", "bytes"], [90, 1, 1, "", "dump"], [90, 1, 1, "", "load"], [90, 1, 1, "", "load_state_dict"], [90, 1, 1, "", "save"], [90, 1, 1, "", "state_dict"], [90, 1, 1, "", "to_bytestream"]], "torchrl.data.replay_buffers.CompressedListStorageCheckpointer": [[91, 1, 1, "", "dumps"], [91, 1, 1, "", "loads"]], "torchrl.data.replay_buffers.ImmutableDatasetWriter": [[94, 1, 1, "", "add"], [94, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.LazyMemmapStorage": [[95, 1, 1, "", "attach"], [95, 1, 1, "", "dump"], [95, 1, 1, "", "load"], [95, 1, 1, "", "save"]], "torchrl.data.replay_buffers.LazyStackStorage": [[96, 1, 1, "", "attach"], [96, 1, 1, "", "dump"], [96, 1, 1, "", "load"], [96, 1, 1, "", "save"]], "torchrl.data.replay_buffers.LazyTensorStorage": [[97, 1, 1, "", "attach"], [97, 1, 1, "", "dump"], [97, 1, 1, "", "load"], [97, 1, 1, "", "save"]], "torchrl.data.replay_buffers.ListStorage": [[98, 1, 1, "", "attach"], [98, 1, 1, "", "dump"], [98, 1, 1, "", "load"], [98, 1, 1, "", "save"]], "torchrl.data.replay_buffers.PrioritizedSampler": [[101, 1, 1, "", "update_priority"]], "torchrl.data.replay_buffers.PrioritizedSliceSampler": [[102, 1, 1, "", "update_priority"]], "torchrl.data.replay_buffers.RoundRobinWriter": [[104, 1, 1, "", "add"], [104, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.Storage": [[110, 1, 1, "", "attach"], [110, 1, 1, "", "dump"], [110, 1, 1, "", "load"], [110, 1, 1, "", "save"]], "torchrl.data.replay_buffers.StorageEnsemble": [[112, 1, 1, "", "attach"], [112, 1, 1, "", "dump"], [112, 1, 1, "", "load"], [112, 1, 1, "", "save"]], "torchrl.data.replay_buffers.TensorDictMaxValueWriter": [[114, 1, 1, "", "add"], [114, 1, 1, "", "extend"], [114, 1, 1, "", "get_insert_index"]], "torchrl.data.replay_buffers.TensorDictRoundRobinWriter": [[115, 1, 1, "", "add"], [115, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.TensorStorage": [[116, 1, 1, "", "attach"], [116, 1, 1, "", "dump"], [116, 1, 1, "", "load"], [116, 1, 1, "", "save"]], "torchrl.data.replay_buffers.Writer": [[118, 1, 1, "", "add"], [118, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.WriterEnsemble": [[119, 1, 1, "", "add"], [119, 1, 1, "", "extend"]], "torchrl.envs": [[120, 0, 1, "", "AsyncEnvPool"], [121, 3, 1, "", "BraxEnv"], [122, 3, 1, "", "BraxWrapper"], [123, 0, 1, "", "ChessEnv"], [124, 3, 1, "", "DMControlEnv"], [125, 3, 1, "", "DMControlWrapper"], [126, 0, 1, "", "EnvBase"], [127, 0, 1, "", "EnvCreator"], [128, 0, 1, "", "EnvMetaData"], [129, 3, 1, "", "GymEnv"], [130, 0, 1, "", "GymLikeEnv"], [131, 3, 1, "", "GymWrapper"], [132, 3, 1, "", "HabitatEnv"], [133, 3, 1, "", "IsaacGymEnv"], [134, 3, 1, "", "IsaacGymWrapper"], [135, 3, 1, "", "IsaacLabWrapper"], [136, 3, 1, "", "JumanjiEnv"], [137, 3, 1, "", "JumanjiWrapper"], [138, 0, 1, "", "LLMHashingEnv"], [139, 3, 1, "", "MOGymEnv"], [140, 3, 1, "", "MOGymWrapper"], [141, 3, 1, "", "MarlGroupMapType"], [142, 3, 1, "", "MeltingpotEnv"], [143, 3, 1, "", "MeltingpotWrapper"], [144, 3, 1, "", "ModelBasedEnvBase"], [145, 3, 1, "", "MultiThreadedEnv"], [146, 3, 1, "", "MultiThreadedEnvWrapper"], [147, 3, 1, "", "OpenMLEnv"], [148, 3, 1, "", "OpenSpielEnv"], [149, 3, 1, "", "OpenSpielWrapper"], [150, 0, 1, "", "ParallelEnv"], [151, 0, 1, "", "PendulumEnv"], [152, 3, 1, "", "PettingZooEnv"], [153, 3, 1, "", "PettingZooWrapper"], [154, 0, 1, "", "ProcessorAsyncEnvPool"], [155, 3, 1, "", "RoboHiveEnv"], [156, 3, 1, "", "SMACv2Env"], [157, 3, 1, "", "SMACv2Wrapper"], [158, 0, 1, "", "SerialEnv"], [159, 0, 1, "", "ThreadingAsyncEnvPool"], [160, 0, 1, "", "TicTacToeEnv"], [161, 3, 1, "", "UnityMLAgentsEnv"], [162, 3, 1, "", "UnityMLAgentsWrapper"], [163, 3, 1, "", "VmasEnv"], [164, 3, 1, "", "VmasWrapper"], [165, 3, 1, "", "check_env_specs"], [166, 3, 1, "", "check_marl_grouping"], [167, 3, 1, "", "exploration_type"], [168, 3, 1, "", "get_available_libraries"], [169, 3, 1, "", "gym_backend"], [206, 3, 1, "", "make_composite_from_td"], [144, 1, 1, "", "rand_step"], [209, 3, 1, "", "register_gym_spec_conversion"], [144, 1, 1, "", "reset"], [144, 1, 1, "", "rollout"], [210, 3, 1, "", "set_exploration_type"], [211, 3, 1, "", "set_gym_backend"], [144, 1, 1, "", "set_seed"], [144, 1, 1, "", "step"], [212, 3, 1, "", "step_mdp"], [213, 3, 1, "", "terminated_or_truncated"]], "torchrl.envs.AsyncEnvPool": [[120, 2, 1, "", "action_key"], [120, 2, 1, "", "action_keys"], [120, 2, 1, "", "action_spec"], [120, 2, 1, "", "action_spec_unbatched"], [120, 1, 1, "", "add_module"], [120, 1, 1, "", "add_truncated_keys"], [120, 1, 1, "", "all_actions"], [120, 1, 1, "", "any_done"], [120, 1, 1, "", "append_transform"], [120, 1, 1, "", "apply"], [120, 1, 1, "", "auto_specs_"], [120, 2, 1, "", "batch_dims"], [120, 2, 1, "", "batch_locked"], [120, 2, 1, "", "batch_size"], [120, 1, 1, "", "bfloat16"], [120, 1, 1, "", "buffers"], [120, 1, 1, "", "cardinality"], [120, 1, 1, "", "check_env_specs"], [120, 1, 1, "", "children"], [120, 2, 1, "", "collector"], [120, 1, 1, "", "compile"], [120, 1, 1, "", "cpu"], [120, 1, 1, "", "cuda"], [120, 2, 1, "", "done_key"], [120, 2, 1, "", "done_keys"], [120, 2, 1, "", "done_keys_groups"], [120, 2, 1, "", "done_spec"], [120, 2, 1, "", "done_spec_unbatched"], [120, 1, 1, "", "double"], [120, 1, 1, "", "empty_cache"], [120, 2, 1, "", "env_batch_sizes"], [120, 1, 1, "", "eval"], [120, 1, 1, "", "extra_repr"], [120, 1, 1, "", "fake_tensordict"], [120, 1, 1, "", "float"], [120, 1, 1, "", "forward"], [120, 2, 1, "", "full_action_spec"], [120, 2, 1, "", "full_action_spec_unbatched"], [120, 2, 1, "", "full_done_spec"], [120, 2, 1, "", "full_done_spec_unbatched"], [120, 2, 1, "", "full_observation_spec_unbatched"], [120, 2, 1, "", "full_reward_spec"], [120, 2, 1, "", "full_reward_spec_unbatched"], [120, 2, 1, "", "full_state_spec"], [120, 2, 1, "", "full_state_spec_unbatched"], [120, 1, 1, "", "get_buffer"], [120, 1, 1, "", "get_extra_state"], [120, 1, 1, "", "get_parameter"], [120, 1, 1, "", "get_submodule"], [120, 1, 1, "", "half"], [120, 2, 1, "", "input_spec"], [120, 2, 1, "", "input_spec_unbatched"], [120, 1, 1, "", "ipu"], [120, 2, 1, "", "is_spec_locked"], [120, 1, 1, "", "load_state_dict"], [120, 1, 1, "", "maybe_reset"], [120, 1, 1, "", "modules"], [120, 1, 1, "", "mtia"], [120, 1, 1, "", "named_buffers"], [120, 1, 1, "", "named_children"], [120, 1, 1, "", "named_modules"], [120, 1, 1, "", "named_parameters"], [120, 2, 1, "", "observation_keys"], [120, 2, 1, "", "observation_spec"], [120, 2, 1, "", "observation_spec_unbatched"], [120, 2, 1, "", "output_spec"], [120, 2, 1, "", "output_spec_unbatched"], [120, 1, 1, "", "parameters"], [120, 1, 1, "", "rand_action"], [120, 1, 1, "", "rand_step"], [120, 1, 1, "", "register_backward_hook"], [120, 1, 1, "", "register_buffer"], [120, 1, 1, "", "register_collector"], [120, 1, 1, "", "register_forward_hook"], [120, 1, 1, "", "register_forward_pre_hook"], [120, 1, 1, "", "register_full_backward_hook"], [120, 1, 1, "", "register_full_backward_pre_hook"], [120, 1, 1, "", "register_gym"], [120, 1, 1, "", "register_load_state_dict_post_hook"], [120, 1, 1, "", "register_load_state_dict_pre_hook"], [120, 1, 1, "", "register_module"], [120, 1, 1, "", "register_parameter"], [120, 1, 1, "", "register_state_dict_post_hook"], [120, 1, 1, "", "register_state_dict_pre_hook"], [120, 1, 1, "", "requires_grad_"], [120, 1, 1, "", "reset"], [120, 2, 1, "", "reset_keys"], [120, 2, 1, "", "reward_key"], [120, 2, 1, "", "reward_keys"], [120, 2, 1, "", "reward_spec"], [120, 2, 1, "", "reward_spec_unbatched"], [120, 1, 1, "", "rollout"], [120, 1, 1, "", "set_extra_state"], [120, 1, 1, "", "set_seed"], [120, 1, 1, "", "set_spec_lock_"], [120, 1, 1, "", "set_submodule"], [120, 2, 1, "", "shape"], [120, 1, 1, "", "share_memory"], [120, 2, 1, "", "specs"], [120, 1, 1, "", "state_dict"], [120, 2, 1, "", "state_keys"], [120, 2, 1, "", "state_spec"], [120, 2, 1, "", "state_spec_unbatched"], [120, 1, 1, "", "step"], [120, 1, 1, "", "step_and_maybe_reset"], [120, 1, 1, "", "step_mdp"], [120, 1, 1, "", "to"], [120, 1, 1, "", "to_empty"], [120, 1, 1, "", "train"], [120, 1, 1, "", "type"], [120, 1, 1, "", "xpu"], [120, 1, 1, "", "zero_grad"]], "torchrl.envs.ChessEnv": [[123, 2, 1, "", "action_key"], [123, 2, 1, "", "action_keys"], [123, 2, 1, "", "action_spec"], [123, 2, 1, "", "action_spec_unbatched"], [123, 1, 1, "", "add_module"], [123, 1, 1, "", "add_truncated_keys"], [123, 1, 1, "", "all_actions"], [123, 1, 1, "", "any_done"], [123, 1, 1, "", "append_transform"], [123, 1, 1, "", "apply"], [123, 1, 1, "", "auto_specs_"], [123, 2, 1, "", "batch_dims"], [123, 2, 1, "", "batch_locked"], [123, 2, 1, "", "batch_size"], [123, 1, 1, "", "bfloat16"], [123, 1, 1, "", "buffers"], [123, 1, 1, "", "cardinality"], [123, 1, 1, "", "check_env_specs"], [123, 1, 1, "", "children"], [123, 2, 1, "", "collector"], [123, 1, 1, "", "compile"], [123, 1, 1, "", "cpu"], [123, 1, 1, "", "cuda"], [123, 2, 1, "", "done_key"], [123, 2, 1, "", "done_keys"], [123, 2, 1, "", "done_keys_groups"], [123, 2, 1, "", "done_spec"], [123, 2, 1, "", "done_spec_unbatched"], [123, 1, 1, "", "double"], [123, 1, 1, "", "empty_cache"], [123, 1, 1, "", "eval"], [123, 1, 1, "", "extra_repr"], [123, 1, 1, "", "fake_tensordict"], [123, 1, 1, "", "float"], [123, 1, 1, "", "forward"], [123, 2, 1, "", "full_action_spec"], [123, 2, 1, "", "full_action_spec_unbatched"], [123, 2, 1, "", "full_done_spec"], [123, 2, 1, "", "full_done_spec_unbatched"], [123, 2, 1, "", "full_observation_spec_unbatched"], [123, 2, 1, "", "full_reward_spec"], [123, 2, 1, "", "full_reward_spec_unbatched"], [123, 2, 1, "", "full_state_spec"], [123, 2, 1, "", "full_state_spec_unbatched"], [123, 1, 1, "", "get_buffer"], [123, 1, 1, "", "get_extra_state"], [123, 1, 1, "", "get_legal_moves"], [123, 1, 1, "", "get_parameter"], [123, 1, 1, "", "get_submodule"], [123, 1, 1, "", "half"], [123, 2, 1, "", "input_spec"], [123, 2, 1, "", "input_spec_unbatched"], [123, 1, 1, "", "ipu"], [123, 2, 1, "", "is_spec_locked"], [123, 1, 1, "", "load_state_dict"], [123, 1, 1, "", "maybe_reset"], [123, 1, 1, "", "modules"], [123, 1, 1, "", "mtia"], [123, 1, 1, "", "named_buffers"], [123, 1, 1, "", "named_children"], [123, 1, 1, "", "named_modules"], [123, 1, 1, "", "named_parameters"], [123, 2, 1, "", "observation_keys"], [123, 2, 1, "", "observation_spec"], [123, 2, 1, "", "observation_spec_unbatched"], [123, 2, 1, "", "output_spec"], [123, 2, 1, "", "output_spec_unbatched"], [123, 1, 1, "", "parameters"], [123, 1, 1, "", "rand_action"], [123, 1, 1, "", "rand_step"], [123, 1, 1, "", "register_backward_hook"], [123, 1, 1, "", "register_buffer"], [123, 1, 1, "", "register_collector"], [123, 1, 1, "", "register_forward_hook"], [123, 1, 1, "", "register_forward_pre_hook"], [123, 1, 1, "", "register_full_backward_hook"], [123, 1, 1, "", "register_full_backward_pre_hook"], [123, 1, 1, "", "register_gym"], [123, 1, 1, "", "register_load_state_dict_post_hook"], [123, 1, 1, "", "register_load_state_dict_pre_hook"], [123, 1, 1, "", "register_module"], [123, 1, 1, "", "register_parameter"], [123, 1, 1, "", "register_state_dict_post_hook"], [123, 1, 1, "", "register_state_dict_pre_hook"], [123, 1, 1, "", "requires_grad_"], [123, 1, 1, "", "reset"], [123, 2, 1, "", "reset_keys"], [123, 2, 1, "", "reward_key"], [123, 2, 1, "", "reward_keys"], [123, 2, 1, "", "reward_spec"], [123, 2, 1, "", "reward_spec_unbatched"], [123, 1, 1, "", "rollout"], [123, 1, 1, "", "set_extra_state"], [123, 1, 1, "", "set_seed"], [123, 1, 1, "", "set_spec_lock_"], [123, 1, 1, "", "set_submodule"], [123, 2, 1, "", "shape"], [123, 1, 1, "", "share_memory"], [123, 2, 1, "", "specs"], [123, 1, 1, "", "state_dict"], [123, 2, 1, "", "state_keys"], [123, 2, 1, "", "state_spec"], [123, 2, 1, "", "state_spec_unbatched"], [123, 1, 1, "", "step"], [123, 1, 1, "", "step_and_maybe_reset"], [123, 1, 1, "", "step_mdp"], [123, 1, 1, "", "to"], [123, 1, 1, "", "to_empty"], [123, 1, 1, "", "train"], [123, 1, 1, "", "type"], [123, 1, 1, "", "xpu"], [123, 1, 1, "", "zero_grad"]], "torchrl.envs.EnvBase": [[126, 2, 1, "", "action_key"], [126, 2, 1, "", "action_keys"], [126, 2, 1, "", "action_spec"], [126, 2, 1, "", "action_spec_unbatched"], [126, 1, 1, "", "add_module"], [126, 1, 1, "", "add_truncated_keys"], [126, 1, 1, "", "all_actions"], [126, 1, 1, "", "any_done"], [126, 1, 1, "", "append_transform"], [126, 1, 1, "", "apply"], [126, 1, 1, "", "auto_specs_"], [126, 2, 1, "", "batch_dims"], [126, 2, 1, "", "batch_locked"], [126, 2, 1, "", "batch_size"], [126, 1, 1, "", "bfloat16"], [126, 1, 1, "", "buffers"], [126, 1, 1, "", "cardinality"], [126, 1, 1, "", "check_env_specs"], [126, 1, 1, "", "children"], [126, 2, 1, "", "collector"], [126, 1, 1, "", "compile"], [126, 1, 1, "", "cpu"], [126, 1, 1, "", "cuda"], [126, 2, 1, "", "done_key"], [126, 2, 1, "", "done_keys"], [126, 2, 1, "", "done_keys_groups"], [126, 2, 1, "", "done_spec"], [126, 2, 1, "", "done_spec_unbatched"], [126, 1, 1, "", "double"], [126, 1, 1, "", "empty_cache"], [126, 1, 1, "", "eval"], [126, 1, 1, "", "extra_repr"], [126, 1, 1, "", "fake_tensordict"], [126, 1, 1, "", "float"], [126, 1, 1, "", "forward"], [126, 2, 1, "", "full_action_spec"], [126, 2, 1, "", "full_action_spec_unbatched"], [126, 2, 1, "", "full_done_spec"], [126, 2, 1, "", "full_done_spec_unbatched"], [126, 2, 1, "", "full_observation_spec_unbatched"], [126, 2, 1, "", "full_reward_spec"], [126, 2, 1, "", "full_reward_spec_unbatched"], [126, 2, 1, "", "full_state_spec"], [126, 2, 1, "", "full_state_spec_unbatched"], [126, 1, 1, "", "get_buffer"], [126, 1, 1, "", "get_extra_state"], [126, 1, 1, "", "get_parameter"], [126, 1, 1, "", "get_submodule"], [126, 1, 1, "", "half"], [126, 2, 1, "", "input_spec"], [126, 2, 1, "", "input_spec_unbatched"], [126, 1, 1, "", "ipu"], [126, 2, 1, "", "is_spec_locked"], [126, 1, 1, "", "load_state_dict"], [126, 1, 1, "", "maybe_reset"], [126, 1, 1, "", "modules"], [126, 1, 1, "", "mtia"], [126, 1, 1, "", "named_buffers"], [126, 1, 1, "", "named_children"], [126, 1, 1, "", "named_modules"], [126, 1, 1, "", "named_parameters"], [126, 2, 1, "", "observation_keys"], [126, 2, 1, "", "observation_spec"], [126, 2, 1, "", "observation_spec_unbatched"], [126, 2, 1, "", "output_spec"], [126, 2, 1, "", "output_spec_unbatched"], [126, 1, 1, "", "parameters"], [126, 1, 1, "", "rand_action"], [126, 1, 1, "id0", "rand_step"], [126, 1, 1, "", "register_backward_hook"], [126, 1, 1, "", "register_buffer"], [126, 1, 1, "", "register_collector"], [126, 1, 1, "", "register_forward_hook"], [126, 1, 1, "", "register_forward_pre_hook"], [126, 1, 1, "", "register_full_backward_hook"], [126, 1, 1, "", "register_full_backward_pre_hook"], [126, 1, 1, "", "register_gym"], [126, 1, 1, "", "register_load_state_dict_post_hook"], [126, 1, 1, "", "register_load_state_dict_pre_hook"], [126, 1, 1, "", "register_module"], [126, 1, 1, "", "register_parameter"], [126, 1, 1, "", "register_state_dict_post_hook"], [126, 1, 1, "", "register_state_dict_pre_hook"], [126, 1, 1, "", "requires_grad_"], [126, 1, 1, "id1", "reset"], [126, 2, 1, "", "reset_keys"], [126, 2, 1, "", "reward_key"], [126, 2, 1, "", "reward_keys"], [126, 2, 1, "", "reward_spec"], [126, 2, 1, "", "reward_spec_unbatched"], [126, 1, 1, "id2", "rollout"], [126, 1, 1, "", "set_extra_state"], [126, 1, 1, "id3", "set_seed"], [126, 1, 1, "", "set_spec_lock_"], [126, 1, 1, "", "set_submodule"], [126, 2, 1, "", "shape"], [126, 1, 1, "", "share_memory"], [126, 2, 1, "", "specs"], [126, 1, 1, "", "state_dict"], [126, 2, 1, "", "state_keys"], [126, 2, 1, "", "state_spec"], [126, 2, 1, "", "state_spec_unbatched"], [126, 1, 1, "id4", "step"], [126, 1, 1, "", "step_and_maybe_reset"], [126, 1, 1, "", "step_mdp"], [126, 1, 1, "", "to"], [126, 1, 1, "", "to_empty"], [126, 1, 1, "", "train"], [126, 1, 1, "", "type"], [126, 1, 1, "", "xpu"], [126, 1, 1, "", "zero_grad"]], "torchrl.envs.EnvCreator": [[127, 1, 1, "", "make_variant"]], "torchrl.envs.GymLikeEnv": [[130, 2, 1, "", "action_key"], [130, 2, 1, "", "action_keys"], [130, 2, 1, "", "action_spec"], [130, 2, 1, "", "action_spec_unbatched"], [130, 1, 1, "", "add_module"], [130, 1, 1, "", "add_truncated_keys"], [130, 1, 1, "", "all_actions"], [130, 1, 1, "", "any_done"], [130, 1, 1, "", "append_transform"], [130, 1, 1, "", "apply"], [130, 1, 1, "", "auto_register_info_dict"], [130, 1, 1, "", "auto_specs_"], [130, 2, 1, "", "batch_dims"], [130, 2, 1, "", "batch_locked"], [130, 2, 1, "", "batch_size"], [130, 1, 1, "", "bfloat16"], [130, 1, 1, "", "buffers"], [130, 1, 1, "", "cardinality"], [130, 1, 1, "", "check_env_specs"], [130, 1, 1, "", "children"], [130, 1, 1, "", "close"], [130, 2, 1, "", "collector"], [130, 1, 1, "", "compile"], [130, 1, 1, "", "cpu"], [130, 1, 1, "", "cuda"], [130, 2, 1, "", "done_key"], [130, 2, 1, "", "done_keys"], [130, 2, 1, "", "done_keys_groups"], [130, 2, 1, "", "done_spec"], [130, 2, 1, "", "done_spec_unbatched"], [130, 1, 1, "", "double"], [130, 1, 1, "", "empty_cache"], [130, 1, 1, "", "eval"], [130, 1, 1, "", "extra_repr"], [130, 1, 1, "", "fake_tensordict"], [130, 1, 1, "", "fast_encoding"], [130, 1, 1, "", "float"], [130, 1, 1, "", "forward"], [130, 2, 1, "", "full_action_spec"], [130, 2, 1, "", "full_action_spec_unbatched"], [130, 2, 1, "", "full_done_spec"], [130, 2, 1, "", "full_done_spec_unbatched"], [130, 2, 1, "", "full_observation_spec_unbatched"], [130, 2, 1, "", "full_reward_spec"], [130, 2, 1, "", "full_reward_spec_unbatched"], [130, 2, 1, "", "full_state_spec"], [130, 2, 1, "", "full_state_spec_unbatched"], [130, 1, 1, "", "get_buffer"], [130, 1, 1, "", "get_extra_state"], [130, 1, 1, "", "get_parameter"], [130, 1, 1, "", "get_submodule"], [130, 1, 1, "", "half"], [130, 2, 1, "", "input_spec"], [130, 2, 1, "", "input_spec_unbatched"], [130, 1, 1, "", "ipu"], [130, 2, 1, "", "is_spec_locked"], [130, 1, 1, "", "load_state_dict"], [130, 1, 1, "", "maybe_reset"], [130, 1, 1, "", "modules"], [130, 1, 1, "", "mtia"], [130, 1, 1, "", "named_buffers"], [130, 1, 1, "", "named_children"], [130, 1, 1, "", "named_modules"], [130, 1, 1, "", "named_parameters"], [130, 2, 1, "", "observation_keys"], [130, 2, 1, "", "observation_spec"], [130, 2, 1, "", "observation_spec_unbatched"], [130, 2, 1, "", "output_spec"], [130, 2, 1, "", "output_spec_unbatched"], [130, 1, 1, "", "parameters"], [130, 1, 1, "", "rand_action"], [130, 1, 1, "", "rand_step"], [130, 1, 1, "", "read_action"], [130, 1, 1, "", "read_done"], [130, 1, 1, "", "read_obs"], [130, 1, 1, "", "read_reward"], [130, 1, 1, "", "register_backward_hook"], [130, 1, 1, "", "register_buffer"], [130, 1, 1, "", "register_collector"], [130, 1, 1, "", "register_forward_hook"], [130, 1, 1, "", "register_forward_pre_hook"], [130, 1, 1, "", "register_full_backward_hook"], [130, 1, 1, "", "register_full_backward_pre_hook"], [130, 1, 1, "", "register_gym"], [130, 1, 1, "", "register_load_state_dict_post_hook"], [130, 1, 1, "", "register_load_state_dict_pre_hook"], [130, 1, 1, "", "register_module"], [130, 1, 1, "", "register_parameter"], [130, 1, 1, "", "register_state_dict_post_hook"], [130, 1, 1, "", "register_state_dict_pre_hook"], [130, 1, 1, "", "requires_grad_"], [130, 1, 1, "", "reset"], [130, 2, 1, "", "reset_keys"], [130, 2, 1, "", "reward_key"], [130, 2, 1, "", "reward_keys"], [130, 2, 1, "", "reward_spec"], [130, 2, 1, "", "reward_spec_unbatched"], [130, 1, 1, "", "rollout"], [130, 1, 1, "", "set_extra_state"], [130, 1, 1, "", "set_info_dict_reader"], [130, 1, 1, "", "set_seed"], [130, 1, 1, "", "set_spec_lock_"], [130, 1, 1, "", "set_submodule"], [130, 2, 1, "", "shape"], [130, 1, 1, "", "share_memory"], [130, 2, 1, "", "specs"], [130, 1, 1, "", "state_dict"], [130, 2, 1, "", "state_keys"], [130, 2, 1, "", "state_spec"], [130, 2, 1, "", "state_spec_unbatched"], [130, 1, 1, "", "step"], [130, 1, 1, "", "step_and_maybe_reset"], [130, 1, 1, "", "step_mdp"], [130, 1, 1, "", "to"], [130, 1, 1, "", "to_empty"], [130, 1, 1, "", "train"], [130, 1, 1, "", "type"], [130, 1, 1, "", "xpu"], [130, 1, 1, "", "zero_grad"]], "torchrl.envs.LLMHashingEnv": [[138, 2, 1, "", "action_key"], [138, 2, 1, "", "action_keys"], [138, 2, 1, "", "action_spec"], [138, 2, 1, "", "action_spec_unbatched"], [138, 1, 1, "", "add_module"], [138, 1, 1, "", "add_truncated_keys"], [138, 1, 1, "", "all_actions"], [138, 1, 1, "", "any_done"], [138, 1, 1, "", "append_transform"], [138, 1, 1, "", "apply"], [138, 1, 1, "", "auto_specs_"], [138, 2, 1, "", "batch_dims"], [138, 2, 1, "", "batch_locked"], [138, 2, 1, "", "batch_size"], [138, 1, 1, "", "bfloat16"], [138, 1, 1, "", "buffers"], [138, 1, 1, "", "cardinality"], [138, 1, 1, "", "check_env_specs"], [138, 1, 1, "", "children"], [138, 2, 1, "", "collector"], [138, 1, 1, "", "compile"], [138, 1, 1, "", "cpu"], [138, 1, 1, "", "cuda"], [138, 2, 1, "", "done_key"], [138, 2, 1, "", "done_keys"], [138, 2, 1, "", "done_keys_groups"], [138, 2, 1, "", "done_spec"], [138, 2, 1, "", "done_spec_unbatched"], [138, 1, 1, "", "double"], [138, 1, 1, "", "empty_cache"], [138, 1, 1, "", "eval"], [138, 1, 1, "", "extra_repr"], [138, 1, 1, "", "fake_tensordict"], [138, 1, 1, "", "float"], [138, 1, 1, "", "forward"], [138, 2, 1, "", "full_action_spec"], [138, 2, 1, "", "full_action_spec_unbatched"], [138, 2, 1, "", "full_done_spec"], [138, 2, 1, "", "full_done_spec_unbatched"], [138, 2, 1, "", "full_observation_spec_unbatched"], [138, 2, 1, "", "full_reward_spec"], [138, 2, 1, "", "full_reward_spec_unbatched"], [138, 2, 1, "", "full_state_spec"], [138, 2, 1, "", "full_state_spec_unbatched"], [138, 1, 1, "", "get_buffer"], [138, 1, 1, "", "get_extra_state"], [138, 1, 1, "", "get_parameter"], [138, 1, 1, "", "get_submodule"], [138, 1, 1, "", "half"], [138, 2, 1, "", "input_spec"], [138, 2, 1, "", "input_spec_unbatched"], [138, 1, 1, "", "ipu"], [138, 2, 1, "", "is_spec_locked"], [138, 1, 1, "", "load_state_dict"], [138, 1, 1, "", "make_tensordict"], [138, 1, 1, "", "maybe_reset"], [138, 1, 1, "", "modules"], [138, 1, 1, "", "mtia"], [138, 1, 1, "", "named_buffers"], [138, 1, 1, "", "named_children"], [138, 1, 1, "", "named_modules"], [138, 1, 1, "", "named_parameters"], [138, 2, 1, "", "observation_keys"], [138, 2, 1, "", "observation_spec"], [138, 2, 1, "", "observation_spec_unbatched"], [138, 2, 1, "", "output_spec"], [138, 2, 1, "", "output_spec_unbatched"], [138, 1, 1, "", "parameters"], [138, 1, 1, "", "rand_action"], [138, 1, 1, "", "rand_step"], [138, 1, 1, "", "register_backward_hook"], [138, 1, 1, "", "register_buffer"], [138, 1, 1, "", "register_collector"], [138, 1, 1, "", "register_forward_hook"], [138, 1, 1, "", "register_forward_pre_hook"], [138, 1, 1, "", "register_full_backward_hook"], [138, 1, 1, "", "register_full_backward_pre_hook"], [138, 1, 1, "", "register_gym"], [138, 1, 1, "", "register_load_state_dict_post_hook"], [138, 1, 1, "", "register_load_state_dict_pre_hook"], [138, 1, 1, "", "register_module"], [138, 1, 1, "", "register_parameter"], [138, 1, 1, "", "register_state_dict_post_hook"], [138, 1, 1, "", "register_state_dict_pre_hook"], [138, 1, 1, "", "requires_grad_"], [138, 1, 1, "", "reset"], [138, 2, 1, "", "reset_keys"], [138, 2, 1, "", "reward_key"], [138, 2, 1, "", "reward_keys"], [138, 2, 1, "", "reward_spec"], [138, 2, 1, "", "reward_spec_unbatched"], [138, 1, 1, "", "rollout"], [138, 1, 1, "", "set_extra_state"], [138, 1, 1, "", "set_seed"], [138, 1, 1, "", "set_spec_lock_"], [138, 1, 1, "", "set_submodule"], [138, 2, 1, "", "shape"], [138, 1, 1, "", "share_memory"], [138, 2, 1, "", "specs"], [138, 1, 1, "", "state_dict"], [138, 2, 1, "", "state_keys"], [138, 2, 1, "", "state_spec"], [138, 2, 1, "", "state_spec_unbatched"], [138, 1, 1, "", "step"], [138, 1, 1, "", "step_and_maybe_reset"], [138, 1, 1, "", "step_mdp"], [138, 1, 1, "", "to"], [138, 1, 1, "", "to_empty"], [138, 1, 1, "", "train"], [138, 1, 1, "", "type"], [138, 1, 1, "", "xpu"], [138, 1, 1, "", "zero_grad"]], "torchrl.envs.ParallelEnv": [[150, 2, 1, "", "action_key"], [150, 2, 1, "", "action_keys"], [150, 2, 1, "", "action_spec"], [150, 2, 1, "", "action_spec_unbatched"], [150, 1, 1, "", "add_module"], [150, 1, 1, "", "add_truncated_keys"], [150, 1, 1, "", "all_actions"], [150, 1, 1, "", "any_done"], [150, 1, 1, "", "append_transform"], [150, 1, 1, "", "apply"], [150, 1, 1, "", "auto_specs_"], [150, 2, 1, "", "batch_dims"], [150, 2, 1, "", "batch_locked"], [150, 2, 1, "", "batch_size"], [150, 1, 1, "", "bfloat16"], [150, 1, 1, "", "buffers"], [150, 1, 1, "", "cardinality"], [150, 1, 1, "", "check_env_specs"], [150, 1, 1, "", "children"], [150, 2, 1, "", "collector"], [150, 1, 1, "", "compile"], [150, 1, 1, "", "cpu"], [150, 1, 1, "", "cuda"], [150, 2, 1, "", "done_key"], [150, 2, 1, "", "done_keys"], [150, 2, 1, "", "done_keys_groups"], [150, 2, 1, "", "done_spec"], [150, 2, 1, "", "done_spec_unbatched"], [150, 1, 1, "", "double"], [150, 1, 1, "", "empty_cache"], [150, 1, 1, "", "eval"], [150, 1, 1, "", "extra_repr"], [150, 1, 1, "", "fake_tensordict"], [150, 1, 1, "", "float"], [150, 1, 1, "", "forward"], [150, 2, 1, "", "full_action_spec"], [150, 2, 1, "", "full_action_spec_unbatched"], [150, 2, 1, "", "full_done_spec"], [150, 2, 1, "", "full_done_spec_unbatched"], [150, 2, 1, "", "full_observation_spec_unbatched"], [150, 2, 1, "", "full_reward_spec"], [150, 2, 1, "", "full_reward_spec_unbatched"], [150, 2, 1, "", "full_state_spec"], [150, 2, 1, "", "full_state_spec_unbatched"], [150, 1, 1, "", "get_buffer"], [150, 1, 1, "", "get_extra_state"], [150, 1, 1, "", "get_parameter"], [150, 1, 1, "", "get_submodule"], [150, 1, 1, "", "half"], [150, 2, 1, "", "input_spec"], [150, 2, 1, "", "input_spec_unbatched"], [150, 1, 1, "", "ipu"], [150, 2, 1, "", "is_spec_locked"], [150, 1, 1, "", "load_state_dict"], [150, 1, 1, "", "maybe_reset"], [150, 1, 1, "", "modules"], [150, 1, 1, "", "mtia"], [150, 1, 1, "", "named_buffers"], [150, 1, 1, "", "named_children"], [150, 1, 1, "", "named_modules"], [150, 1, 1, "", "named_parameters"], [150, 2, 1, "", "observation_keys"], [150, 2, 1, "", "observation_spec"], [150, 2, 1, "", "observation_spec_unbatched"], [150, 2, 1, "", "output_spec"], [150, 2, 1, "", "output_spec_unbatched"], [150, 1, 1, "", "parameters"], [150, 1, 1, "", "rand_action"], [150, 1, 1, "", "rand_step"], [150, 1, 1, "", "register_backward_hook"], [150, 1, 1, "", "register_buffer"], [150, 1, 1, "", "register_collector"], [150, 1, 1, "", "register_forward_hook"], [150, 1, 1, "", "register_forward_pre_hook"], [150, 1, 1, "", "register_full_backward_hook"], [150, 1, 1, "", "register_full_backward_pre_hook"], [150, 1, 1, "", "register_gym"], [150, 1, 1, "", "register_load_state_dict_post_hook"], [150, 1, 1, "", "register_load_state_dict_pre_hook"], [150, 1, 1, "", "register_module"], [150, 1, 1, "", "register_parameter"], [150, 1, 1, "", "register_state_dict_post_hook"], [150, 1, 1, "", "register_state_dict_pre_hook"], [150, 1, 1, "", "requires_grad_"], [150, 1, 1, "", "reset"], [150, 2, 1, "", "reset_keys"], [150, 2, 1, "", "reward_key"], [150, 2, 1, "", "reward_keys"], [150, 2, 1, "", "reward_spec"], [150, 2, 1, "", "reward_spec_unbatched"], [150, 1, 1, "", "rollout"], [150, 1, 1, "", "set_extra_state"], [150, 1, 1, "", "set_seed"], [150, 1, 1, "", "set_spec_lock_"], [150, 1, 1, "", "set_submodule"], [150, 2, 1, "", "shape"], [150, 1, 1, "", "share_memory"], [150, 2, 1, "", "specs"], [150, 1, 1, "", "state_dict"], [150, 2, 1, "", "state_keys"], [150, 2, 1, "", "state_spec"], [150, 2, 1, "", "state_spec_unbatched"], [150, 1, 1, "", "step"], [150, 1, 1, "", "step_and_maybe_reset"], [150, 1, 1, "", "step_mdp"], [150, 1, 1, "", "to"], [150, 1, 1, "", "to_empty"], [150, 1, 1, "", "train"], [150, 1, 1, "", "type"], [150, 1, 1, "", "update_kwargs"], [150, 1, 1, "", "xpu"], [150, 1, 1, "", "zero_grad"]], "torchrl.envs.PendulumEnv": [[151, 2, 1, "", "action_key"], [151, 2, 1, "", "action_keys"], [151, 2, 1, "", "action_spec"], [151, 2, 1, "", "action_spec_unbatched"], [151, 1, 1, "", "add_module"], [151, 1, 1, "", "add_truncated_keys"], [151, 1, 1, "", "all_actions"], [151, 1, 1, "", "any_done"], [151, 1, 1, "", "append_transform"], [151, 1, 1, "", "apply"], [151, 1, 1, "", "auto_specs_"], [151, 2, 1, "", "batch_dims"], [151, 2, 1, "", "batch_size"], [151, 1, 1, "", "bfloat16"], [151, 1, 1, "", "buffers"], [151, 1, 1, "", "cardinality"], [151, 1, 1, "", "check_env_specs"], [151, 1, 1, "", "children"], [151, 2, 1, "", "collector"], [151, 1, 1, "", "compile"], [151, 1, 1, "", "cpu"], [151, 1, 1, "", "cuda"], [151, 2, 1, "", "done_key"], [151, 2, 1, "", "done_keys"], [151, 2, 1, "", "done_keys_groups"], [151, 2, 1, "", "done_spec"], [151, 2, 1, "", "done_spec_unbatched"], [151, 1, 1, "", "double"], [151, 1, 1, "", "empty_cache"], [151, 1, 1, "", "eval"], [151, 1, 1, "", "extra_repr"], [151, 1, 1, "", "fake_tensordict"], [151, 1, 1, "", "float"], [151, 1, 1, "", "forward"], [151, 2, 1, "", "full_action_spec"], [151, 2, 1, "", "full_action_spec_unbatched"], [151, 2, 1, "", "full_done_spec"], [151, 2, 1, "", "full_done_spec_unbatched"], [151, 2, 1, "", "full_observation_spec_unbatched"], [151, 2, 1, "", "full_reward_spec"], [151, 2, 1, "", "full_reward_spec_unbatched"], [151, 2, 1, "", "full_state_spec"], [151, 2, 1, "", "full_state_spec_unbatched"], [151, 1, 1, "", "gen_params"], [151, 1, 1, "", "get_buffer"], [151, 1, 1, "", "get_extra_state"], [151, 1, 1, "", "get_parameter"], [151, 1, 1, "", "get_submodule"], [151, 1, 1, "", "half"], [151, 2, 1, "", "input_spec"], [151, 2, 1, "", "input_spec_unbatched"], [151, 1, 1, "", "ipu"], [151, 2, 1, "", "is_spec_locked"], [151, 1, 1, "", "load_state_dict"], [151, 1, 1, "", "maybe_reset"], [151, 1, 1, "", "modules"], [151, 1, 1, "", "mtia"], [151, 1, 1, "", "named_buffers"], [151, 1, 1, "", "named_children"], [151, 1, 1, "", "named_modules"], [151, 1, 1, "", "named_parameters"], [151, 2, 1, "", "observation_keys"], [151, 2, 1, "", "observation_spec"], [151, 2, 1, "", "observation_spec_unbatched"], [151, 2, 1, "", "output_spec"], [151, 2, 1, "", "output_spec_unbatched"], [151, 1, 1, "", "parameters"], [151, 1, 1, "", "rand_action"], [151, 1, 1, "", "rand_step"], [151, 1, 1, "", "register_backward_hook"], [151, 1, 1, "", "register_buffer"], [151, 1, 1, "", "register_collector"], [151, 1, 1, "", "register_forward_hook"], [151, 1, 1, "", "register_forward_pre_hook"], [151, 1, 1, "", "register_full_backward_hook"], [151, 1, 1, "", "register_full_backward_pre_hook"], [151, 1, 1, "", "register_gym"], [151, 1, 1, "", "register_load_state_dict_post_hook"], [151, 1, 1, "", "register_load_state_dict_pre_hook"], [151, 1, 1, "", "register_module"], [151, 1, 1, "", "register_parameter"], [151, 1, 1, "", "register_state_dict_post_hook"], [151, 1, 1, "", "register_state_dict_pre_hook"], [151, 1, 1, "", "requires_grad_"], [151, 1, 1, "", "reset"], [151, 2, 1, "", "reset_keys"], [151, 2, 1, "", "reward_key"], [151, 2, 1, "", "reward_keys"], [151, 2, 1, "", "reward_spec"], [151, 2, 1, "", "reward_spec_unbatched"], [151, 1, 1, "", "rollout"], [151, 1, 1, "", "set_extra_state"], [151, 1, 1, "", "set_seed"], [151, 1, 1, "", "set_spec_lock_"], [151, 1, 1, "", "set_submodule"], [151, 2, 1, "", "shape"], [151, 1, 1, "", "share_memory"], [151, 2, 1, "", "specs"], [151, 1, 1, "", "state_dict"], [151, 2, 1, "", "state_keys"], [151, 2, 1, "", "state_spec"], [151, 2, 1, "", "state_spec_unbatched"], [151, 1, 1, "", "step"], [151, 1, 1, "", "step_and_maybe_reset"], [151, 1, 1, "", "step_mdp"], [151, 1, 1, "", "to"], [151, 1, 1, "", "to_empty"], [151, 1, 1, "", "train"], [151, 1, 1, "", "type"], [151, 1, 1, "", "xpu"], [151, 1, 1, "", "zero_grad"]], "torchrl.envs.ProcessorAsyncEnvPool": [[154, 1, 1, "", "_setup"], [154, 2, 1, "", "action_key"], [154, 2, 1, "", "action_keys"], [154, 2, 1, "", "action_spec"], [154, 2, 1, "", "action_spec_unbatched"], [154, 1, 1, "", "add_module"], [154, 1, 1, "", "add_truncated_keys"], [154, 1, 1, "", "all_actions"], [154, 1, 1, "", "any_done"], [154, 1, 1, "", "append_transform"], [154, 1, 1, "", "apply"], [154, 1, 1, "", "async_reset_recv"], [154, 1, 1, "", "async_reset_send"], [154, 1, 1, "", "async_step_recv"], [154, 1, 1, "", "async_step_send"], [154, 1, 1, "", "auto_specs_"], [154, 2, 1, "", "batch_dims"], [154, 2, 1, "", "batch_locked"], [154, 2, 1, "", "batch_size"], [154, 1, 1, "", "bfloat16"], [154, 1, 1, "", "buffers"], [154, 1, 1, "", "cardinality"], [154, 1, 1, "", "check_env_specs"], [154, 1, 1, "", "children"], [154, 2, 1, "", "collector"], [154, 1, 1, "", "compile"], [154, 1, 1, "", "cpu"], [154, 1, 1, "", "cuda"], [154, 2, 1, "", "done_key"], [154, 2, 1, "", "done_keys"], [154, 2, 1, "", "done_keys_groups"], [154, 2, 1, "", "done_spec"], [154, 2, 1, "", "done_spec_unbatched"], [154, 1, 1, "", "double"], [154, 1, 1, "", "empty_cache"], [154, 2, 1, "", "env_batch_sizes"], [154, 1, 1, "", "eval"], [154, 1, 1, "", "extra_repr"], [154, 1, 1, "", "fake_tensordict"], [154, 1, 1, "", "float"], [154, 1, 1, "", "forward"], [154, 2, 1, "", "full_action_spec"], [154, 2, 1, "", "full_action_spec_unbatched"], [154, 2, 1, "", "full_done_spec"], [154, 2, 1, "", "full_done_spec_unbatched"], [154, 2, 1, "", "full_observation_spec_unbatched"], [154, 2, 1, "", "full_reward_spec"], [154, 2, 1, "", "full_reward_spec_unbatched"], [154, 2, 1, "", "full_state_spec"], [154, 2, 1, "", "full_state_spec_unbatched"], [154, 1, 1, "", "get_buffer"], [154, 1, 1, "", "get_extra_state"], [154, 1, 1, "", "get_parameter"], [154, 1, 1, "", "get_submodule"], [154, 1, 1, "", "half"], [154, 2, 1, "", "input_spec"], [154, 2, 1, "", "input_spec_unbatched"], [154, 1, 1, "", "ipu"], [154, 2, 1, "", "is_spec_locked"], [154, 1, 1, "", "load_state_dict"], [154, 1, 1, "", "maybe_reset"], [154, 1, 1, "", "modules"], [154, 1, 1, "", "mtia"], [154, 1, 1, "", "named_buffers"], [154, 1, 1, "", "named_children"], [154, 1, 1, "", "named_modules"], [154, 1, 1, "", "named_parameters"], [154, 2, 1, "", "observation_keys"], [154, 2, 1, "", "observation_spec"], [154, 2, 1, "", "observation_spec_unbatched"], [154, 2, 1, "", "output_spec"], [154, 2, 1, "", "output_spec_unbatched"], [154, 1, 1, "", "parameters"], [154, 1, 1, "", "rand_action"], [154, 1, 1, "", "rand_step"], [154, 1, 1, "", "register_backward_hook"], [154, 1, 1, "", "register_buffer"], [154, 1, 1, "", "register_collector"], [154, 1, 1, "", "register_forward_hook"], [154, 1, 1, "", "register_forward_pre_hook"], [154, 1, 1, "", "register_full_backward_hook"], [154, 1, 1, "", "register_full_backward_pre_hook"], [154, 1, 1, "", "register_gym"], [154, 1, 1, "", "register_load_state_dict_post_hook"], [154, 1, 1, "", "register_load_state_dict_pre_hook"], [154, 1, 1, "", "register_module"], [154, 1, 1, "", "register_parameter"], [154, 1, 1, "", "register_state_dict_post_hook"], [154, 1, 1, "", "register_state_dict_pre_hook"], [154, 1, 1, "", "requires_grad_"], [154, 1, 1, "", "reset"], [154, 2, 1, "", "reset_keys"], [154, 2, 1, "", "reward_key"], [154, 2, 1, "", "reward_keys"], [154, 2, 1, "", "reward_spec"], [154, 2, 1, "", "reward_spec_unbatched"], [154, 1, 1, "", "rollout"], [154, 1, 1, "", "set_extra_state"], [154, 1, 1, "", "set_seed"], [154, 1, 1, "", "set_spec_lock_"], [154, 1, 1, "", "set_submodule"], [154, 2, 1, "", "shape"], [154, 1, 1, "", "share_memory"], [154, 1, 1, "", "shutdown"], [154, 2, 1, "", "specs"], [154, 1, 1, "", "state_dict"], [154, 2, 1, "", "state_keys"], [154, 2, 1, "", "state_spec"], [154, 2, 1, "", "state_spec_unbatched"], [154, 1, 1, "", "step"], [154, 1, 1, "", "step_and_maybe_reset"], [154, 1, 1, "", "step_mdp"], [154, 1, 1, "", "to"], [154, 1, 1, "", "to_empty"], [154, 1, 1, "", "train"], [154, 1, 1, "", "type"], [154, 1, 1, "", "xpu"], [154, 1, 1, "", "zero_grad"]], "torchrl.envs.SerialEnv": [[158, 2, 1, "", "action_key"], [158, 2, 1, "", "action_keys"], [158, 2, 1, "", "action_spec"], [158, 2, 1, "", "action_spec_unbatched"], [158, 1, 1, "", "add_module"], [158, 1, 1, "", "add_truncated_keys"], [158, 1, 1, "", "all_actions"], [158, 1, 1, "", "any_done"], [158, 1, 1, "", "append_transform"], [158, 1, 1, "", "apply"], [158, 1, 1, "", "auto_specs_"], [158, 2, 1, "", "batch_dims"], [158, 2, 1, "", "batch_locked"], [158, 2, 1, "", "batch_size"], [158, 1, 1, "", "bfloat16"], [158, 1, 1, "", "buffers"], [158, 1, 1, "", "cardinality"], [158, 1, 1, "", "check_env_specs"], [158, 1, 1, "", "children"], [158, 2, 1, "", "collector"], [158, 1, 1, "", "compile"], [158, 1, 1, "", "cpu"], [158, 1, 1, "", "cuda"], [158, 2, 1, "", "done_key"], [158, 2, 1, "", "done_keys"], [158, 2, 1, "", "done_keys_groups"], [158, 2, 1, "", "done_spec"], [158, 2, 1, "", "done_spec_unbatched"], [158, 1, 1, "", "double"], [158, 1, 1, "", "empty_cache"], [158, 1, 1, "", "eval"], [158, 1, 1, "", "extra_repr"], [158, 1, 1, "", "fake_tensordict"], [158, 1, 1, "", "float"], [158, 1, 1, "", "forward"], [158, 2, 1, "", "full_action_spec"], [158, 2, 1, "", "full_action_spec_unbatched"], [158, 2, 1, "", "full_done_spec"], [158, 2, 1, "", "full_done_spec_unbatched"], [158, 2, 1, "", "full_observation_spec_unbatched"], [158, 2, 1, "", "full_reward_spec"], [158, 2, 1, "", "full_reward_spec_unbatched"], [158, 2, 1, "", "full_state_spec"], [158, 2, 1, "", "full_state_spec_unbatched"], [158, 1, 1, "", "get_buffer"], [158, 1, 1, "", "get_extra_state"], [158, 1, 1, "", "get_parameter"], [158, 1, 1, "", "get_submodule"], [158, 1, 1, "", "half"], [158, 2, 1, "", "input_spec"], [158, 2, 1, "", "input_spec_unbatched"], [158, 1, 1, "", "ipu"], [158, 2, 1, "", "is_spec_locked"], [158, 1, 1, "", "load_state_dict"], [158, 1, 1, "", "maybe_reset"], [158, 1, 1, "", "modules"], [158, 1, 1, "", "mtia"], [158, 1, 1, "", "named_buffers"], [158, 1, 1, "", "named_children"], [158, 1, 1, "", "named_modules"], [158, 1, 1, "", "named_parameters"], [158, 2, 1, "", "observation_keys"], [158, 2, 1, "", "observation_spec"], [158, 2, 1, "", "observation_spec_unbatched"], [158, 2, 1, "", "output_spec"], [158, 2, 1, "", "output_spec_unbatched"], [158, 1, 1, "", "parameters"], [158, 1, 1, "", "rand_action"], [158, 1, 1, "", "rand_step"], [158, 1, 1, "", "register_backward_hook"], [158, 1, 1, "", "register_buffer"], [158, 1, 1, "", "register_collector"], [158, 1, 1, "", "register_forward_hook"], [158, 1, 1, "", "register_forward_pre_hook"], [158, 1, 1, "", "register_full_backward_hook"], [158, 1, 1, "", "register_full_backward_pre_hook"], [158, 1, 1, "", "register_gym"], [158, 1, 1, "", "register_load_state_dict_post_hook"], [158, 1, 1, "", "register_load_state_dict_pre_hook"], [158, 1, 1, "", "register_module"], [158, 1, 1, "", "register_parameter"], [158, 1, 1, "", "register_state_dict_post_hook"], [158, 1, 1, "", "register_state_dict_pre_hook"], [158, 1, 1, "", "requires_grad_"], [158, 1, 1, "", "reset"], [158, 2, 1, "", "reset_keys"], [158, 2, 1, "", "reward_key"], [158, 2, 1, "", "reward_keys"], [158, 2, 1, "", "reward_spec"], [158, 2, 1, "", "reward_spec_unbatched"], [158, 1, 1, "", "rollout"], [158, 1, 1, "", "set_extra_state"], [158, 1, 1, "", "set_seed"], [158, 1, 1, "", "set_spec_lock_"], [158, 1, 1, "", "set_submodule"], [158, 2, 1, "", "shape"], [158, 1, 1, "", "share_memory"], [158, 2, 1, "", "specs"], [158, 1, 1, "", "state_dict"], [158, 2, 1, "", "state_keys"], [158, 2, 1, "", "state_spec"], [158, 2, 1, "", "state_spec_unbatched"], [158, 1, 1, "", "step"], [158, 1, 1, "", "step_and_maybe_reset"], [158, 1, 1, "", "step_mdp"], [158, 1, 1, "", "to"], [158, 1, 1, "", "to_empty"], [158, 1, 1, "", "train"], [158, 1, 1, "", "type"], [158, 1, 1, "", "update_kwargs"], [158, 1, 1, "", "xpu"], [158, 1, 1, "", "zero_grad"]], "torchrl.envs.ThreadingAsyncEnvPool": [[159, 1, 1, "", "_setup"], [159, 2, 1, "", "action_key"], [159, 2, 1, "", "action_keys"], [159, 2, 1, "", "action_spec"], [159, 2, 1, "", "action_spec_unbatched"], [159, 1, 1, "", "add_module"], [159, 1, 1, "", "add_truncated_keys"], [159, 1, 1, "", "all_actions"], [159, 1, 1, "", "any_done"], [159, 1, 1, "", "append_transform"], [159, 1, 1, "", "apply"], [159, 1, 1, "", "async_reset_recv"], [159, 1, 1, "", "async_reset_send"], [159, 1, 1, "", "async_step_recv"], [159, 1, 1, "", "async_step_send"], [159, 1, 1, "", "auto_specs_"], [159, 2, 1, "", "batch_dims"], [159, 2, 1, "", "batch_locked"], [159, 2, 1, "", "batch_size"], [159, 1, 1, "", "bfloat16"], [159, 1, 1, "", "buffers"], [159, 1, 1, "", "cardinality"], [159, 1, 1, "", "check_env_specs"], [159, 1, 1, "", "children"], [159, 2, 1, "", "collector"], [159, 1, 1, "", "compile"], [159, 1, 1, "", "cpu"], [159, 1, 1, "", "cuda"], [159, 2, 1, "", "done_key"], [159, 2, 1, "", "done_keys"], [159, 2, 1, "", "done_keys_groups"], [159, 2, 1, "", "done_spec"], [159, 2, 1, "", "done_spec_unbatched"], [159, 1, 1, "", "double"], [159, 1, 1, "", "empty_cache"], [159, 2, 1, "", "env_batch_sizes"], [159, 1, 1, "", "eval"], [159, 1, 1, "", "extra_repr"], [159, 1, 1, "", "fake_tensordict"], [159, 1, 1, "", "float"], [159, 1, 1, "", "forward"], [159, 2, 1, "", "full_action_spec"], [159, 2, 1, "", "full_action_spec_unbatched"], [159, 2, 1, "", "full_done_spec"], [159, 2, 1, "", "full_done_spec_unbatched"], [159, 2, 1, "", "full_observation_spec_unbatched"], [159, 2, 1, "", "full_reward_spec"], [159, 2, 1, "", "full_reward_spec_unbatched"], [159, 2, 1, "", "full_state_spec"], [159, 2, 1, "", "full_state_spec_unbatched"], [159, 1, 1, "", "get_buffer"], [159, 1, 1, "", "get_extra_state"], [159, 1, 1, "", "get_parameter"], [159, 1, 1, "", "get_submodule"], [159, 1, 1, "", "half"], [159, 2, 1, "", "input_spec"], [159, 2, 1, "", "input_spec_unbatched"], [159, 1, 1, "", "ipu"], [159, 2, 1, "", "is_spec_locked"], [159, 1, 1, "", "load_state_dict"], [159, 1, 1, "", "maybe_reset"], [159, 1, 1, "", "modules"], [159, 1, 1, "", "mtia"], [159, 1, 1, "", "named_buffers"], [159, 1, 1, "", "named_children"], [159, 1, 1, "", "named_modules"], [159, 1, 1, "", "named_parameters"], [159, 2, 1, "", "observation_keys"], [159, 2, 1, "", "observation_spec"], [159, 2, 1, "", "observation_spec_unbatched"], [159, 2, 1, "", "output_spec"], [159, 2, 1, "", "output_spec_unbatched"], [159, 1, 1, "", "parameters"], [159, 1, 1, "", "rand_action"], [159, 1, 1, "", "rand_step"], [159, 1, 1, "", "register_backward_hook"], [159, 1, 1, "", "register_buffer"], [159, 1, 1, "", "register_collector"], [159, 1, 1, "", "register_forward_hook"], [159, 1, 1, "", "register_forward_pre_hook"], [159, 1, 1, "", "register_full_backward_hook"], [159, 1, 1, "", "register_full_backward_pre_hook"], [159, 1, 1, "", "register_gym"], [159, 1, 1, "", "register_load_state_dict_post_hook"], [159, 1, 1, "", "register_load_state_dict_pre_hook"], [159, 1, 1, "", "register_module"], [159, 1, 1, "", "register_parameter"], [159, 1, 1, "", "register_state_dict_post_hook"], [159, 1, 1, "", "register_state_dict_pre_hook"], [159, 1, 1, "", "requires_grad_"], [159, 1, 1, "", "reset"], [159, 2, 1, "", "reset_keys"], [159, 2, 1, "", "reward_key"], [159, 2, 1, "", "reward_keys"], [159, 2, 1, "", "reward_spec"], [159, 2, 1, "", "reward_spec_unbatched"], [159, 1, 1, "", "rollout"], [159, 1, 1, "", "set_extra_state"], [159, 1, 1, "", "set_seed"], [159, 1, 1, "", "set_spec_lock_"], [159, 1, 1, "", "set_submodule"], [159, 2, 1, "", "shape"], [159, 1, 1, "", "share_memory"], [159, 1, 1, "", "shutdown"], [159, 2, 1, "", "specs"], [159, 1, 1, "", "state_dict"], [159, 2, 1, "", "state_keys"], [159, 2, 1, "", "state_spec"], [159, 2, 1, "", "state_spec_unbatched"], [159, 1, 1, "", "step"], [159, 1, 1, "", "step_and_maybe_reset"], [159, 1, 1, "", "step_mdp"], [159, 1, 1, "", "to"], [159, 1, 1, "", "to_empty"], [159, 1, 1, "", "train"], [159, 1, 1, "", "type"], [159, 1, 1, "", "xpu"], [159, 1, 1, "", "zero_grad"]], "torchrl.envs.TicTacToeEnv": [[160, 2, 1, "", "action_key"], [160, 2, 1, "", "action_keys"], [160, 2, 1, "", "action_spec"], [160, 2, 1, "", "action_spec_unbatched"], [160, 1, 1, "", "add_module"], [160, 1, 1, "", "add_truncated_keys"], [160, 1, 1, "", "all_actions"], [160, 1, 1, "", "any_done"], [160, 1, 1, "", "append_transform"], [160, 1, 1, "", "apply"], [160, 1, 1, "", "auto_specs_"], [160, 2, 1, "", "batch_dims"], [160, 2, 1, "", "batch_size"], [160, 1, 1, "", "bfloat16"], [160, 1, 1, "", "buffers"], [160, 1, 1, "", "cardinality"], [160, 1, 1, "", "check_env_specs"], [160, 1, 1, "", "children"], [160, 2, 1, "", "collector"], [160, 1, 1, "", "compile"], [160, 1, 1, "", "cpu"], [160, 1, 1, "", "cuda"], [160, 2, 1, "", "done_key"], [160, 2, 1, "", "done_keys"], [160, 2, 1, "", "done_keys_groups"], [160, 2, 1, "", "done_spec"], [160, 2, 1, "", "done_spec_unbatched"], [160, 1, 1, "", "double"], [160, 1, 1, "", "empty_cache"], [160, 1, 1, "", "eval"], [160, 1, 1, "", "extra_repr"], [160, 1, 1, "", "fake_tensordict"], [160, 1, 1, "", "float"], [160, 1, 1, "", "forward"], [160, 2, 1, "", "full_action_spec"], [160, 2, 1, "", "full_action_spec_unbatched"], [160, 2, 1, "", "full_done_spec"], [160, 2, 1, "", "full_done_spec_unbatched"], [160, 2, 1, "", "full_observation_spec_unbatched"], [160, 2, 1, "", "full_reward_spec"], [160, 2, 1, "", "full_reward_spec_unbatched"], [160, 2, 1, "", "full_state_spec"], [160, 2, 1, "", "full_state_spec_unbatched"], [160, 1, 1, "", "get_buffer"], [160, 1, 1, "", "get_extra_state"], [160, 1, 1, "", "get_parameter"], [160, 1, 1, "", "get_submodule"], [160, 1, 1, "", "half"], [160, 2, 1, "", "input_spec"], [160, 2, 1, "", "input_spec_unbatched"], [160, 1, 1, "", "ipu"], [160, 2, 1, "", "is_spec_locked"], [160, 1, 1, "", "load_state_dict"], [160, 1, 1, "", "maybe_reset"], [160, 1, 1, "", "modules"], [160, 1, 1, "", "mtia"], [160, 1, 1, "", "named_buffers"], [160, 1, 1, "", "named_children"], [160, 1, 1, "", "named_modules"], [160, 1, 1, "", "named_parameters"], [160, 2, 1, "", "observation_keys"], [160, 2, 1, "", "observation_spec"], [160, 2, 1, "", "observation_spec_unbatched"], [160, 2, 1, "", "output_spec"], [160, 2, 1, "", "output_spec_unbatched"], [160, 1, 1, "", "parameters"], [160, 1, 1, "", "rand_action"], [160, 1, 1, "", "rand_step"], [160, 1, 1, "", "register_backward_hook"], [160, 1, 1, "", "register_buffer"], [160, 1, 1, "", "register_collector"], [160, 1, 1, "", "register_forward_hook"], [160, 1, 1, "", "register_forward_pre_hook"], [160, 1, 1, "", "register_full_backward_hook"], [160, 1, 1, "", "register_full_backward_pre_hook"], [160, 1, 1, "", "register_gym"], [160, 1, 1, "", "register_load_state_dict_post_hook"], [160, 1, 1, "", "register_load_state_dict_pre_hook"], [160, 1, 1, "", "register_module"], [160, 1, 1, "", "register_parameter"], [160, 1, 1, "", "register_state_dict_post_hook"], [160, 1, 1, "", "register_state_dict_pre_hook"], [160, 1, 1, "", "requires_grad_"], [160, 1, 1, "", "reset"], [160, 2, 1, "", "reset_keys"], [160, 2, 1, "", "reward_key"], [160, 2, 1, "", "reward_keys"], [160, 2, 1, "", "reward_spec"], [160, 2, 1, "", "reward_spec_unbatched"], [160, 1, 1, "", "rollout"], [160, 1, 1, "", "set_extra_state"], [160, 1, 1, "", "set_seed"], [160, 1, 1, "", "set_spec_lock_"], [160, 1, 1, "", "set_submodule"], [160, 2, 1, "", "shape"], [160, 1, 1, "", "share_memory"], [160, 2, 1, "", "specs"], [160, 1, 1, "", "state_dict"], [160, 2, 1, "", "state_keys"], [160, 2, 1, "", "state_spec"], [160, 2, 1, "", "state_spec_unbatched"], [160, 1, 1, "", "step"], [160, 1, 1, "", "step_and_maybe_reset"], [160, 1, 1, "", "step_mdp"], [160, 1, 1, "", "to"], [160, 1, 1, "", "to_empty"], [160, 1, 1, "", "train"], [160, 1, 1, "", "type"], [160, 1, 1, "", "xpu"], [160, 1, 1, "", "zero_grad"]], "torchrl.envs.llm": [[170, 0, 1, "", "ChatEnv"], [171, 0, 1, "", "DatasetChatEnv"], [172, 0, 1, "", "GSM8KEnv"], [173, 0, 1, "", "GSM8KPrepareQuestion"], [174, 0, 1, "", "GSM8KRewardParser"], [175, 0, 1, "", "IFEvalEnv"], [176, 0, 1, "", "IFEvalScoreData"], [177, 0, 1, "", "IfEvalScorer"], [178, 0, 1, "", "LLMEnv"], [179, 0, 1, "", "LLMHashingEnv"], [180, 0, 1, "", "MLGymWrapper"], [181, 0, 1, "", "make_gsm8k_env"], [182, 0, 1, "", "make_mlgym"]], "torchrl.envs.llm.ChatEnv": [[170, 2, 1, "", "action_key"], [170, 2, 1, "", "action_keys"], [170, 2, 1, "", "action_spec"], [170, 2, 1, "", "action_spec_unbatched"], [170, 1, 1, "", "add_module"], [170, 1, 1, "", "add_truncated_keys"], [170, 1, 1, "", "all_actions"], [170, 1, 1, "", "any_done"], [170, 1, 1, "", "append_transform"], [170, 1, 1, "", "apply"], [170, 1, 1, "", "auto_specs_"], [170, 2, 1, "", "batch_dims"], [170, 2, 1, "", "batch_locked"], [170, 2, 1, "", "batch_size"], [170, 1, 1, "", "bfloat16"], [170, 1, 1, "", "buffers"], [170, 1, 1, "", "cardinality"], [170, 1, 1, "", "check_env_specs"], [170, 1, 1, "", "children"], [170, 2, 1, "", "collector"], [170, 1, 1, "", "compile"], [170, 1, 1, "", "cpu"], [170, 1, 1, "", "cuda"], [170, 2, 1, "", "done_key"], [170, 2, 1, "", "done_keys"], [170, 2, 1, "", "done_keys_groups"], [170, 2, 1, "", "done_spec"], [170, 2, 1, "", "done_spec_unbatched"], [170, 1, 1, "", "double"], [170, 1, 1, "", "empty_cache"], [170, 1, 1, "", "eval"], [170, 1, 1, "", "extra_repr"], [170, 1, 1, "", "fake_tensordict"], [170, 1, 1, "", "float"], [170, 1, 1, "", "forward"], [170, 1, 1, "", "from_dataloader"], [170, 2, 1, "", "full_action_spec"], [170, 2, 1, "", "full_action_spec_unbatched"], [170, 2, 1, "", "full_done_spec"], [170, 2, 1, "", "full_done_spec_unbatched"], [170, 2, 1, "", "full_observation_spec_unbatched"], [170, 2, 1, "", "full_reward_spec"], [170, 2, 1, "", "full_reward_spec_unbatched"], [170, 2, 1, "", "full_state_spec"], [170, 2, 1, "", "full_state_spec_unbatched"], [170, 1, 1, "", "get_buffer"], [170, 1, 1, "", "get_extra_state"], [170, 1, 1, "", "get_parameter"], [170, 1, 1, "", "get_submodule"], [170, 1, 1, "", "half"], [170, 2, 1, "", "input_spec"], [170, 2, 1, "", "input_spec_unbatched"], [170, 1, 1, "", "ipu"], [170, 2, 1, "", "is_spec_locked"], [170, 1, 1, "", "load_state_dict"], [170, 1, 1, "", "maybe_reset"], [170, 1, 1, "", "modules"], [170, 1, 1, "", "mtia"], [170, 1, 1, "", "named_buffers"], [170, 1, 1, "", "named_children"], [170, 1, 1, "", "named_modules"], [170, 1, 1, "", "named_parameters"], [170, 2, 1, "", "observation_keys"], [170, 2, 1, "", "observation_spec"], [170, 2, 1, "", "observation_spec_unbatched"], [170, 2, 1, "", "output_spec"], [170, 2, 1, "", "output_spec_unbatched"], [170, 1, 1, "", "parameters"], [170, 1, 1, "", "rand_action"], [170, 1, 1, "", "rand_step"], [170, 1, 1, "", "register_backward_hook"], [170, 1, 1, "", "register_buffer"], [170, 1, 1, "", "register_collector"], [170, 1, 1, "", "register_forward_hook"], [170, 1, 1, "", "register_forward_pre_hook"], [170, 1, 1, "", "register_full_backward_hook"], [170, 1, 1, "", "register_full_backward_pre_hook"], [170, 1, 1, "", "register_gym"], [170, 1, 1, "", "register_load_state_dict_post_hook"], [170, 1, 1, "", "register_load_state_dict_pre_hook"], [170, 1, 1, "", "register_module"], [170, 1, 1, "", "register_parameter"], [170, 1, 1, "", "register_state_dict_post_hook"], [170, 1, 1, "", "register_state_dict_pre_hook"], [170, 1, 1, "", "requires_grad_"], [170, 1, 1, "id0", "reset"], [170, 2, 1, "", "reset_keys"], [170, 2, 1, "", "reward_key"], [170, 2, 1, "", "reward_keys"], [170, 2, 1, "", "reward_spec"], [170, 2, 1, "", "reward_spec_unbatched"], [170, 1, 1, "", "rollout"], [170, 1, 1, "", "set_extra_state"], [170, 1, 1, "", "set_seed"], [170, 1, 1, "", "set_spec_lock_"], [170, 1, 1, "", "set_submodule"], [170, 2, 1, "", "shape"], [170, 1, 1, "", "share_memory"], [170, 2, 1, "", "specs"], [170, 1, 1, "", "state_dict"], [170, 2, 1, "", "state_keys"], [170, 2, 1, "", "state_spec"], [170, 2, 1, "", "state_spec_unbatched"], [170, 1, 1, "id1", "step"], [170, 1, 1, "", "step_and_maybe_reset"], [170, 1, 1, "", "step_mdp"], [170, 1, 1, "", "to"], [170, 1, 1, "", "to_empty"], [170, 1, 1, "", "train"], [170, 1, 1, "", "type"], [170, 1, 1, "", "xpu"], [170, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.DatasetChatEnv": [[171, 2, 1, "", "action_key"], [171, 2, 1, "", "action_keys"], [171, 2, 1, "", "action_spec"], [171, 2, 1, "", "action_spec_unbatched"], [171, 1, 1, "", "add_module"], [171, 1, 1, "", "add_truncated_keys"], [171, 1, 1, "", "all_actions"], [171, 1, 1, "", "any_done"], [171, 1, 1, "", "append_transform"], [171, 1, 1, "", "apply"], [171, 1, 1, "", "auto_specs_"], [171, 2, 1, "", "batch_dims"], [171, 2, 1, "", "batch_locked"], [171, 2, 1, "", "batch_size"], [171, 1, 1, "", "bfloat16"], [171, 1, 1, "", "buffers"], [171, 1, 1, "", "cardinality"], [171, 1, 1, "", "check_env_specs"], [171, 1, 1, "", "children"], [171, 2, 1, "", "collector"], [171, 1, 1, "", "compile"], [171, 1, 1, "", "cpu"], [171, 1, 1, "", "cuda"], [171, 2, 1, "", "done_key"], [171, 2, 1, "", "done_keys"], [171, 2, 1, "", "done_keys_groups"], [171, 2, 1, "", "done_spec"], [171, 2, 1, "", "done_spec_unbatched"], [171, 1, 1, "", "double"], [171, 1, 1, "", "empty_cache"], [171, 1, 1, "", "eval"], [171, 1, 1, "", "extra_repr"], [171, 1, 1, "", "fake_tensordict"], [171, 1, 1, "", "float"], [171, 1, 1, "", "forward"], [171, 1, 1, "", "from_dataloader"], [171, 2, 1, "", "full_action_spec"], [171, 2, 1, "", "full_action_spec_unbatched"], [171, 2, 1, "", "full_done_spec"], [171, 2, 1, "", "full_done_spec_unbatched"], [171, 2, 1, "", "full_observation_spec_unbatched"], [171, 2, 1, "", "full_reward_spec"], [171, 2, 1, "", "full_reward_spec_unbatched"], [171, 2, 1, "", "full_state_spec"], [171, 2, 1, "", "full_state_spec_unbatched"], [171, 1, 1, "", "get_buffer"], [171, 1, 1, "", "get_extra_state"], [171, 1, 1, "", "get_parameter"], [171, 1, 1, "", "get_submodule"], [171, 1, 1, "", "half"], [171, 2, 1, "", "input_spec"], [171, 2, 1, "", "input_spec_unbatched"], [171, 1, 1, "", "insert_transform"], [171, 1, 1, "", "ipu"], [171, 2, 1, "", "is_spec_locked"], [171, 1, 1, "", "load_state_dict"], [171, 1, 1, "", "maybe_reset"], [171, 1, 1, "", "modules"], [171, 1, 1, "", "mtia"], [171, 1, 1, "", "named_buffers"], [171, 1, 1, "", "named_children"], [171, 1, 1, "", "named_modules"], [171, 1, 1, "", "named_parameters"], [171, 2, 1, "", "observation_keys"], [171, 2, 1, "", "observation_spec"], [171, 2, 1, "", "observation_spec_unbatched"], [171, 2, 1, "", "output_spec"], [171, 2, 1, "", "output_spec_unbatched"], [171, 1, 1, "", "parameters"], [171, 1, 1, "", "rand_action"], [171, 1, 1, "", "rand_step"], [171, 1, 1, "", "register_backward_hook"], [171, 1, 1, "", "register_buffer"], [171, 1, 1, "", "register_collector"], [171, 1, 1, "", "register_forward_hook"], [171, 1, 1, "", "register_forward_pre_hook"], [171, 1, 1, "", "register_full_backward_hook"], [171, 1, 1, "", "register_full_backward_pre_hook"], [171, 1, 1, "", "register_gym"], [171, 1, 1, "", "register_load_state_dict_post_hook"], [171, 1, 1, "", "register_load_state_dict_pre_hook"], [171, 1, 1, "", "register_module"], [171, 1, 1, "", "register_parameter"], [171, 1, 1, "", "register_state_dict_post_hook"], [171, 1, 1, "", "register_state_dict_pre_hook"], [171, 1, 1, "", "requires_grad_"], [171, 1, 1, "", "reset"], [171, 1, 1, "", "reset_dataloader"], [171, 2, 1, "", "reset_keys"], [171, 2, 1, "", "reward_key"], [171, 2, 1, "", "reward_keys"], [171, 2, 1, "", "reward_spec"], [171, 2, 1, "", "reward_spec_unbatched"], [171, 1, 1, "", "rollout"], [171, 1, 1, "", "set_extra_state"], [171, 1, 1, "", "set_missing_tolerance"], [171, 1, 1, "", "set_seed"], [171, 1, 1, "", "set_spec_lock_"], [171, 1, 1, "", "set_submodule"], [171, 2, 1, "", "shape"], [171, 1, 1, "", "share_memory"], [171, 2, 1, "", "specs"], [171, 1, 1, "", "state_dict"], [171, 2, 1, "", "state_keys"], [171, 2, 1, "", "state_spec"], [171, 2, 1, "", "state_spec_unbatched"], [171, 1, 1, "", "step"], [171, 1, 1, "", "step_and_maybe_reset"], [171, 1, 1, "", "step_mdp"], [171, 1, 1, "", "to"], [171, 1, 1, "", "to_empty"], [171, 1, 1, "", "train"], [171, 1, 1, "", "type"], [171, 1, 1, "", "xpu"], [171, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KEnv": [[172, 2, 1, "", "action_key"], [172, 2, 1, "", "action_keys"], [172, 2, 1, "", "action_spec"], [172, 2, 1, "", "action_spec_unbatched"], [172, 1, 1, "", "add_module"], [172, 1, 1, "", "add_truncated_keys"], [172, 1, 1, "", "all_actions"], [172, 1, 1, "", "any_done"], [172, 1, 1, "", "append_transform"], [172, 1, 1, "", "apply"], [172, 1, 1, "", "auto_specs_"], [172, 2, 1, "", "batch_dims"], [172, 2, 1, "", "batch_locked"], [172, 2, 1, "", "batch_size"], [172, 1, 1, "", "bfloat16"], [172, 1, 1, "", "buffers"], [172, 1, 1, "", "cardinality"], [172, 1, 1, "", "check_env_specs"], [172, 1, 1, "", "children"], [172, 2, 1, "", "collector"], [172, 1, 1, "", "compile"], [172, 1, 1, "", "cpu"], [172, 1, 1, "", "cuda"], [172, 2, 1, "", "done_key"], [172, 2, 1, "", "done_keys"], [172, 2, 1, "", "done_keys_groups"], [172, 2, 1, "", "done_spec"], [172, 2, 1, "", "done_spec_unbatched"], [172, 1, 1, "", "double"], [172, 1, 1, "", "empty_cache"], [172, 1, 1, "", "eval"], [172, 1, 1, "", "extra_repr"], [172, 1, 1, "", "fake_tensordict"], [172, 1, 1, "", "float"], [172, 1, 1, "", "forward"], [172, 1, 1, "", "from_dataloader"], [172, 2, 1, "", "full_action_spec"], [172, 2, 1, "", "full_action_spec_unbatched"], [172, 2, 1, "", "full_done_spec"], [172, 2, 1, "", "full_done_spec_unbatched"], [172, 2, 1, "", "full_observation_spec_unbatched"], [172, 2, 1, "", "full_reward_spec"], [172, 2, 1, "", "full_reward_spec_unbatched"], [172, 2, 1, "", "full_state_spec"], [172, 2, 1, "", "full_state_spec_unbatched"], [172, 1, 1, "", "get_buffer"], [172, 1, 1, "", "get_extra_state"], [172, 1, 1, "", "get_parameter"], [172, 1, 1, "", "get_submodule"], [172, 1, 1, "", "half"], [172, 2, 1, "", "input_spec"], [172, 2, 1, "", "input_spec_unbatched"], [172, 1, 1, "", "insert_transform"], [172, 1, 1, "", "ipu"], [172, 2, 1, "", "is_spec_locked"], [172, 1, 1, "", "load_state_dict"], [172, 1, 1, "", "maybe_reset"], [172, 1, 1, "", "modules"], [172, 1, 1, "", "mtia"], [172, 1, 1, "", "named_buffers"], [172, 1, 1, "", "named_children"], [172, 1, 1, "", "named_modules"], [172, 1, 1, "", "named_parameters"], [172, 2, 1, "", "observation_keys"], [172, 2, 1, "", "observation_spec"], [172, 2, 1, "", "observation_spec_unbatched"], [172, 2, 1, "", "output_spec"], [172, 2, 1, "", "output_spec_unbatched"], [172, 1, 1, "", "parameters"], [172, 1, 1, "", "rand_action"], [172, 1, 1, "", "rand_step"], [172, 1, 1, "", "register_backward_hook"], [172, 1, 1, "", "register_buffer"], [172, 1, 1, "", "register_collector"], [172, 1, 1, "", "register_forward_hook"], [172, 1, 1, "", "register_forward_pre_hook"], [172, 1, 1, "", "register_full_backward_hook"], [172, 1, 1, "", "register_full_backward_pre_hook"], [172, 1, 1, "", "register_gym"], [172, 1, 1, "", "register_load_state_dict_post_hook"], [172, 1, 1, "", "register_load_state_dict_pre_hook"], [172, 1, 1, "", "register_module"], [172, 1, 1, "", "register_parameter"], [172, 1, 1, "", "register_state_dict_post_hook"], [172, 1, 1, "", "register_state_dict_pre_hook"], [172, 1, 1, "", "requires_grad_"], [172, 1, 1, "", "reset"], [172, 1, 1, "", "reset_dataloader"], [172, 2, 1, "", "reset_keys"], [172, 2, 1, "", "reward_key"], [172, 2, 1, "", "reward_keys"], [172, 2, 1, "", "reward_spec"], [172, 2, 1, "", "reward_spec_unbatched"], [172, 1, 1, "", "rollout"], [172, 1, 1, "", "set_extra_state"], [172, 1, 1, "", "set_missing_tolerance"], [172, 1, 1, "", "set_seed"], [172, 1, 1, "", "set_spec_lock_"], [172, 1, 1, "", "set_submodule"], [172, 2, 1, "", "shape"], [172, 1, 1, "", "share_memory"], [172, 2, 1, "", "specs"], [172, 1, 1, "", "state_dict"], [172, 2, 1, "", "state_keys"], [172, 2, 1, "", "state_spec"], [172, 2, 1, "", "state_spec_unbatched"], [172, 1, 1, "", "step"], [172, 1, 1, "", "step_and_maybe_reset"], [172, 1, 1, "", "step_mdp"], [172, 1, 1, "", "to"], [172, 1, 1, "", "to_empty"], [172, 1, 1, "", "train"], [172, 1, 1, "", "type"], [172, 1, 1, "", "xpu"], [172, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KPrepareQuestion": [[173, 1, 1, "", "add_module"], [173, 1, 1, "", "apply"], [173, 1, 1, "", "bfloat16"], [173, 1, 1, "", "buffers"], [173, 1, 1, "", "children"], [173, 1, 1, "", "close"], [173, 2, 1, "", "collector"], [173, 1, 1, "", "compile"], [173, 2, 1, "", "container"], [173, 1, 1, "", "cpu"], [173, 1, 1, "", "cuda"], [173, 1, 1, "", "double"], [173, 1, 1, "", "eval"], [173, 1, 1, "", "extra_repr"], [173, 1, 1, "", "float"], [173, 1, 1, "", "forward"], [173, 1, 1, "", "get_buffer"], [173, 1, 1, "", "get_extra_state"], [173, 1, 1, "", "get_parameter"], [173, 1, 1, "", "get_submodule"], [173, 1, 1, "", "half"], [173, 1, 1, "", "init"], [173, 1, 1, "", "inv"], [173, 1, 1, "", "ipu"], [173, 1, 1, "", "load_state_dict"], [173, 1, 1, "", "modules"], [173, 1, 1, "", "mtia"], [173, 1, 1, "", "named_buffers"], [173, 1, 1, "", "named_children"], [173, 1, 1, "", "named_modules"], [173, 1, 1, "", "named_parameters"], [173, 1, 1, "", "parameters"], [173, 2, 1, "", "parent"], [173, 1, 1, "", "register_backward_hook"], [173, 1, 1, "", "register_buffer"], [173, 1, 1, "", "register_forward_hook"], [173, 1, 1, "", "register_forward_pre_hook"], [173, 1, 1, "", "register_full_backward_hook"], [173, 1, 1, "", "register_full_backward_pre_hook"], [173, 1, 1, "", "register_load_state_dict_post_hook"], [173, 1, 1, "", "register_load_state_dict_pre_hook"], [173, 1, 1, "", "register_module"], [173, 1, 1, "", "register_parameter"], [173, 1, 1, "", "register_state_dict_post_hook"], [173, 1, 1, "", "register_state_dict_pre_hook"], [173, 1, 1, "", "requires_grad_"], [173, 1, 1, "", "set_extra_state"], [173, 1, 1, "", "set_submodule"], [173, 1, 1, "", "share_memory"], [173, 1, 1, "", "state_dict"], [173, 1, 1, "", "to"], [173, 1, 1, "", "to_empty"], [173, 1, 1, "", "train"], [173, 1, 1, "", "transform_action_spec"], [173, 1, 1, "", "transform_done_spec"], [173, 1, 1, "", "transform_env_batch_size"], [173, 1, 1, "", "transform_env_device"], [173, 1, 1, "", "transform_input_spec"], [173, 1, 1, "", "transform_observation_spec"], [173, 1, 1, "", "transform_output_spec"], [173, 1, 1, "", "transform_reward_spec"], [173, 1, 1, "", "transform_state_spec"], [173, 1, 1, "", "type"], [173, 1, 1, "", "xpu"], [173, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KRewardParser": [[174, 1, 1, "", "add_module"], [174, 1, 1, "", "apply"], [174, 1, 1, "", "bfloat16"], [174, 1, 1, "", "buffers"], [174, 1, 1, "", "children"], [174, 1, 1, "", "close"], [174, 2, 1, "", "collector"], [174, 1, 1, "", "compile"], [174, 2, 1, "", "container"], [174, 1, 1, "", "cpu"], [174, 1, 1, "", "cuda"], [174, 1, 1, "", "double"], [174, 1, 1, "", "eval"], [174, 1, 1, "", "extra_repr"], [174, 1, 1, "", "extract_tags"], [174, 1, 1, "", "float"], [174, 1, 1, "", "forward"], [174, 1, 1, "", "get_buffer"], [174, 1, 1, "", "get_extra_state"], [174, 1, 1, "", "get_parameter"], [174, 1, 1, "", "get_submodule"], [174, 1, 1, "", "half"], [174, 1, 1, "", "init"], [174, 1, 1, "", "inv"], [174, 1, 1, "", "ipu"], [174, 1, 1, "", "load_state_dict"], [174, 1, 1, "", "modules"], [174, 1, 1, "", "mtia"], [174, 1, 1, "", "named_buffers"], [174, 1, 1, "", "named_children"], [174, 1, 1, "", "named_modules"], [174, 1, 1, "", "named_parameters"], [174, 1, 1, "", "parameters"], [174, 2, 1, "", "parent"], [174, 1, 1, "", "register_backward_hook"], [174, 1, 1, "", "register_buffer"], [174, 1, 1, "", "register_forward_hook"], [174, 1, 1, "", "register_forward_pre_hook"], [174, 1, 1, "", "register_full_backward_hook"], [174, 1, 1, "", "register_full_backward_pre_hook"], [174, 1, 1, "", "register_load_state_dict_post_hook"], [174, 1, 1, "", "register_load_state_dict_pre_hook"], [174, 1, 1, "", "register_module"], [174, 1, 1, "", "register_parameter"], [174, 1, 1, "", "register_state_dict_post_hook"], [174, 1, 1, "", "register_state_dict_pre_hook"], [174, 1, 1, "", "requires_grad_"], [174, 1, 1, "", "set_extra_state"], [174, 1, 1, "", "set_submodule"], [174, 1, 1, "", "share_memory"], [174, 1, 1, "", "state_dict"], [174, 1, 1, "", "to"], [174, 1, 1, "", "to_empty"], [174, 1, 1, "", "train"], [174, 1, 1, "", "transform_action_spec"], [174, 1, 1, "", "transform_done_spec"], [174, 1, 1, "", "transform_env_batch_size"], [174, 1, 1, "", "transform_env_device"], [174, 1, 1, "", "transform_input_spec"], [174, 1, 1, "", "transform_observation_spec"], [174, 1, 1, "", "transform_output_spec"], [174, 1, 1, "", "transform_reward_spec"], [174, 1, 1, "", "transform_state_spec"], [174, 1, 1, "", "type"], [174, 1, 1, "", "xpu"], [174, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.IFEvalEnv": [[175, 2, 1, "", "action_key"], [175, 2, 1, "", "action_keys"], [175, 2, 1, "", "action_spec"], [175, 2, 1, "", "action_spec_unbatched"], [175, 1, 1, "", "add_module"], [175, 1, 1, "", "add_truncated_keys"], [175, 1, 1, "", "all_actions"], [175, 1, 1, "", "any_done"], [175, 1, 1, "", "append_transform"], [175, 1, 1, "", "apply"], [175, 1, 1, "", "auto_specs_"], [175, 2, 1, "", "batch_dims"], [175, 2, 1, "", "batch_locked"], [175, 2, 1, "", "batch_size"], [175, 1, 1, "", "bfloat16"], [175, 1, 1, "", "buffers"], [175, 1, 1, "", "cardinality"], [175, 1, 1, "", "check_env_specs"], [175, 1, 1, "", "children"], [175, 2, 1, "", "collector"], [175, 1, 1, "", "compile"], [175, 1, 1, "", "cpu"], [175, 1, 1, "", "cuda"], [175, 2, 1, "", "done_key"], [175, 2, 1, "", "done_keys"], [175, 2, 1, "", "done_keys_groups"], [175, 2, 1, "", "done_spec"], [175, 2, 1, "", "done_spec_unbatched"], [175, 1, 1, "", "double"], [175, 1, 1, "", "empty_cache"], [175, 1, 1, "", "eval"], [175, 1, 1, "", "extra_repr"], [175, 1, 1, "", "fake_tensordict"], [175, 1, 1, "", "float"], [175, 1, 1, "", "forward"], [175, 1, 1, "", "from_dataloader"], [175, 2, 1, "", "full_action_spec"], [175, 2, 1, "", "full_action_spec_unbatched"], [175, 2, 1, "", "full_done_spec"], [175, 2, 1, "", "full_done_spec_unbatched"], [175, 2, 1, "", "full_observation_spec_unbatched"], [175, 2, 1, "", "full_reward_spec"], [175, 2, 1, "", "full_reward_spec_unbatched"], [175, 2, 1, "", "full_state_spec"], [175, 2, 1, "", "full_state_spec_unbatched"], [175, 1, 1, "", "get_buffer"], [175, 1, 1, "", "get_extra_state"], [175, 1, 1, "", "get_parameter"], [175, 1, 1, "", "get_submodule"], [175, 1, 1, "", "half"], [175, 2, 1, "", "input_spec"], [175, 2, 1, "", "input_spec_unbatched"], [175, 1, 1, "", "insert_transform"], [175, 1, 1, "", "ipu"], [175, 2, 1, "", "is_spec_locked"], [175, 1, 1, "", "load_state_dict"], [175, 1, 1, "", "maybe_reset"], [175, 1, 1, "", "modules"], [175, 1, 1, "", "mtia"], [175, 1, 1, "", "named_buffers"], [175, 1, 1, "", "named_children"], [175, 1, 1, "", "named_modules"], [175, 1, 1, "", "named_parameters"], [175, 2, 1, "", "observation_keys"], [175, 2, 1, "", "observation_spec"], [175, 2, 1, "", "observation_spec_unbatched"], [175, 2, 1, "", "output_spec"], [175, 2, 1, "", "output_spec_unbatched"], [175, 1, 1, "", "parameters"], [175, 1, 1, "", "rand_action"], [175, 1, 1, "", "rand_step"], [175, 1, 1, "", "register_backward_hook"], [175, 1, 1, "", "register_buffer"], [175, 1, 1, "", "register_collector"], [175, 1, 1, "", "register_forward_hook"], [175, 1, 1, "", "register_forward_pre_hook"], [175, 1, 1, "", "register_full_backward_hook"], [175, 1, 1, "", "register_full_backward_pre_hook"], [175, 1, 1, "", "register_gym"], [175, 1, 1, "", "register_load_state_dict_post_hook"], [175, 1, 1, "", "register_load_state_dict_pre_hook"], [175, 1, 1, "", "register_module"], [175, 1, 1, "", "register_parameter"], [175, 1, 1, "", "register_state_dict_post_hook"], [175, 1, 1, "", "register_state_dict_pre_hook"], [175, 1, 1, "", "requires_grad_"], [175, 1, 1, "", "reset"], [175, 1, 1, "", "reset_dataloader"], [175, 2, 1, "", "reset_keys"], [175, 2, 1, "", "reward_key"], [175, 2, 1, "", "reward_keys"], [175, 2, 1, "", "reward_spec"], [175, 2, 1, "", "reward_spec_unbatched"], [175, 1, 1, "", "rollout"], [175, 1, 1, "", "set_extra_state"], [175, 1, 1, "", "set_missing_tolerance"], [175, 1, 1, "", "set_seed"], [175, 1, 1, "", "set_spec_lock_"], [175, 1, 1, "", "set_submodule"], [175, 2, 1, "", "shape"], [175, 1, 1, "", "share_memory"], [175, 2, 1, "", "specs"], [175, 1, 1, "", "state_dict"], [175, 2, 1, "", "state_keys"], [175, 2, 1, "", "state_spec"], [175, 2, 1, "", "state_spec_unbatched"], [175, 1, 1, "", "step"], [175, 1, 1, "", "step_and_maybe_reset"], [175, 1, 1, "", "step_mdp"], [175, 1, 1, "", "to"], [175, 1, 1, "", "to_empty"], [175, 1, 1, "", "train"], [175, 1, 1, "", "type"], [175, 1, 1, "", "xpu"], [175, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.IFEvalScoreData": [[176, 1, 1, "", "cat"], [176, 2, 1, "", "device"], [176, 1, 1, "", "dumps"], [176, 1, 1, "", "fields"], [176, 1, 1, "", "from_any"], [176, 1, 1, "", "from_dataclass"], [176, 1, 1, "", "from_h5"], [176, 1, 1, "", "from_modules"], [176, 1, 1, "", "from_namedtuple"], [176, 1, 1, "", "from_pytree"], [176, 1, 1, "", "from_remote_init"], [176, 1, 1, "", "from_struct_array"], [176, 1, 1, "", "from_tensordict"], [176, 1, 1, "", "from_tuple"], [176, 1, 1, "", "fromkeys"], [176, 1, 1, "", "get"], [176, 1, 1, "", "lazy_stack"], [176, 1, 1, "", "load"], [176, 1, 1, "", "load_"], [176, 1, 1, "", "load_memmap"], [176, 1, 1, "", "load_state_dict"], [176, 1, 1, "", "maybe_dense_stack"], [176, 1, 1, "", "memmap"], [176, 1, 1, "", "memmap_"], [176, 1, 1, "", "memmap_like"], [176, 1, 1, "", "memmap_refresh_"], [176, 1, 1, "", "save"], [176, 1, 1, "", "set"], [176, 1, 1, "", "stack"], [176, 1, 1, "", "state_dict"], [176, 1, 1, "", "to_tensordict"], [176, 1, 1, "", "unbind"]], "torchrl.envs.llm.IfEvalScorer": [[177, 1, 1, "", "add_module"], [177, 1, 1, "", "apply"], [177, 1, 1, "", "bfloat16"], [177, 1, 1, "", "buffers"], [177, 1, 1, "", "children"], [177, 1, 1, "", "close"], [177, 2, 1, "", "collector"], [177, 1, 1, "", "compile"], [177, 2, 1, "", "container"], [177, 1, 1, "", "cpu"], [177, 1, 1, "", "cuda"], [177, 1, 1, "", "default_reward_aggregator"], [177, 1, 1, "", "double"], [177, 1, 1, "", "eval"], [177, 1, 1, "", "extra_repr"], [177, 1, 1, "", "float"], [177, 1, 1, "", "forward"], [177, 1, 1, "", "get_buffer"], [177, 1, 1, "", "get_extra_state"], [177, 1, 1, "", "get_parameter"], [177, 1, 1, "", "get_submodule"], [177, 1, 1, "", "half"], [177, 1, 1, "", "init"], [177, 1, 1, "", "inv"], [177, 1, 1, "", "ipu"], [177, 1, 1, "", "load_state_dict"], [177, 1, 1, "", "modules"], [177, 1, 1, "", "mtia"], [177, 1, 1, "", "named_buffers"], [177, 1, 1, "", "named_children"], [177, 1, 1, "", "named_modules"], [177, 1, 1, "", "named_parameters"], [177, 1, 1, "", "parameters"], [177, 2, 1, "", "parent"], [177, 1, 1, "", "register_backward_hook"], [177, 1, 1, "", "register_buffer"], [177, 1, 1, "", "register_forward_hook"], [177, 1, 1, "", "register_forward_pre_hook"], [177, 1, 1, "", "register_full_backward_hook"], [177, 1, 1, "", "register_full_backward_pre_hook"], [177, 1, 1, "", "register_load_state_dict_post_hook"], [177, 1, 1, "", "register_load_state_dict_pre_hook"], [177, 1, 1, "", "register_module"], [177, 1, 1, "", "register_parameter"], [177, 1, 1, "", "register_state_dict_post_hook"], [177, 1, 1, "", "register_state_dict_pre_hook"], [177, 1, 1, "", "requires_grad_"], [177, 1, 1, "", "set_extra_state"], [177, 1, 1, "", "set_submodule"], [177, 1, 1, "", "share_memory"], [177, 1, 1, "", "state_dict"], [177, 1, 1, "", "to"], [177, 1, 1, "", "to_empty"], [177, 1, 1, "", "train"], [177, 1, 1, "", "transform_action_spec"], [177, 1, 1, "", "transform_done_spec"], [177, 1, 1, "", "transform_env_batch_size"], [177, 1, 1, "", "transform_env_device"], [177, 1, 1, "", "transform_input_spec"], [177, 1, 1, "", "transform_observation_spec"], [177, 1, 1, "", "transform_output_spec"], [177, 1, 1, "", "transform_reward_spec"], [177, 1, 1, "", "transform_state_spec"], [177, 1, 1, "", "type"], [177, 1, 1, "", "xpu"], [177, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.LLMEnv": [[178, 2, 1, "", "action_key"], [178, 2, 1, "", "action_keys"], [178, 2, 1, "", "action_spec"], [178, 2, 1, "", "action_spec_unbatched"], [178, 1, 1, "", "add_module"], [178, 1, 1, "", "add_truncated_keys"], [178, 1, 1, "", "all_actions"], [178, 1, 1, "", "any_done"], [178, 1, 1, "", "append_transform"], [178, 1, 1, "", "apply"], [178, 1, 1, "", "auto_specs_"], [178, 2, 1, "", "batch_dims"], [178, 2, 1, "", "batch_locked"], [178, 2, 1, "", "batch_size"], [178, 1, 1, "", "bfloat16"], [178, 1, 1, "", "buffers"], [178, 1, 1, "", "cardinality"], [178, 1, 1, "", "check_env_specs"], [178, 1, 1, "", "children"], [178, 2, 1, "", "collector"], [178, 1, 1, "", "compile"], [178, 1, 1, "", "cpu"], [178, 1, 1, "", "cuda"], [178, 2, 1, "", "done_key"], [178, 2, 1, "", "done_keys"], [178, 2, 1, "", "done_keys_groups"], [178, 2, 1, "", "done_spec"], [178, 2, 1, "", "done_spec_unbatched"], [178, 1, 1, "", "double"], [178, 1, 1, "", "empty_cache"], [178, 1, 1, "", "eval"], [178, 1, 1, "", "extra_repr"], [178, 1, 1, "", "fake_tensordict"], [178, 1, 1, "", "float"], [178, 1, 1, "", "forward"], [178, 1, 1, "id0", "from_dataloader"], [178, 2, 1, "", "full_action_spec"], [178, 2, 1, "", "full_action_spec_unbatched"], [178, 2, 1, "", "full_done_spec"], [178, 2, 1, "", "full_done_spec_unbatched"], [178, 2, 1, "", "full_observation_spec_unbatched"], [178, 2, 1, "", "full_reward_spec"], [178, 2, 1, "", "full_reward_spec_unbatched"], [178, 2, 1, "", "full_state_spec"], [178, 2, 1, "", "full_state_spec_unbatched"], [178, 1, 1, "", "get_buffer"], [178, 1, 1, "", "get_extra_state"], [178, 1, 1, "", "get_parameter"], [178, 1, 1, "", "get_submodule"], [178, 1, 1, "", "half"], [178, 2, 1, "", "input_spec"], [178, 2, 1, "", "input_spec_unbatched"], [178, 1, 1, "", "ipu"], [178, 2, 1, "", "is_spec_locked"], [178, 1, 1, "", "load_state_dict"], [178, 1, 1, "", "maybe_reset"], [178, 1, 1, "", "modules"], [178, 1, 1, "", "mtia"], [178, 1, 1, "", "named_buffers"], [178, 1, 1, "", "named_children"], [178, 1, 1, "", "named_modules"], [178, 1, 1, "", "named_parameters"], [178, 2, 1, "", "observation_keys"], [178, 2, 1, "", "observation_spec"], [178, 2, 1, "", "observation_spec_unbatched"], [178, 2, 1, "", "output_spec"], [178, 2, 1, "", "output_spec_unbatched"], [178, 1, 1, "", "parameters"], [178, 1, 1, "", "rand_action"], [178, 1, 1, "", "rand_step"], [178, 1, 1, "", "register_backward_hook"], [178, 1, 1, "", "register_buffer"], [178, 1, 1, "", "register_collector"], [178, 1, 1, "", "register_forward_hook"], [178, 1, 1, "", "register_forward_pre_hook"], [178, 1, 1, "", "register_full_backward_hook"], [178, 1, 1, "", "register_full_backward_pre_hook"], [178, 1, 1, "", "register_gym"], [178, 1, 1, "", "register_load_state_dict_post_hook"], [178, 1, 1, "", "register_load_state_dict_pre_hook"], [178, 1, 1, "", "register_module"], [178, 1, 1, "", "register_parameter"], [178, 1, 1, "", "register_state_dict_post_hook"], [178, 1, 1, "", "register_state_dict_pre_hook"], [178, 1, 1, "", "requires_grad_"], [178, 1, 1, "", "reset"], [178, 2, 1, "", "reset_keys"], [178, 2, 1, "", "reward_key"], [178, 2, 1, "", "reward_keys"], [178, 2, 1, "", "reward_spec"], [178, 2, 1, "", "reward_spec_unbatched"], [178, 1, 1, "", "rollout"], [178, 1, 1, "", "set_extra_state"], [178, 1, 1, "", "set_seed"], [178, 1, 1, "", "set_spec_lock_"], [178, 1, 1, "", "set_submodule"], [178, 2, 1, "", "shape"], [178, 1, 1, "", "share_memory"], [178, 2, 1, "", "specs"], [178, 1, 1, "", "state_dict"], [178, 2, 1, "", "state_keys"], [178, 2, 1, "", "state_spec"], [178, 2, 1, "", "state_spec_unbatched"], [178, 1, 1, "", "step"], [178, 1, 1, "", "step_and_maybe_reset"], [178, 1, 1, "", "step_mdp"], [178, 1, 1, "", "to"], [178, 1, 1, "", "to_empty"], [178, 1, 1, "", "train"], [178, 1, 1, "", "type"], [178, 1, 1, "", "xpu"], [178, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.LLMHashingEnv": [[179, 2, 1, "", "action_key"], [179, 2, 1, "", "action_keys"], [179, 2, 1, "", "action_spec"], [179, 2, 1, "", "action_spec_unbatched"], [179, 1, 1, "", "add_module"], [179, 1, 1, "", "add_truncated_keys"], [179, 1, 1, "", "all_actions"], [179, 1, 1, "", "any_done"], [179, 1, 1, "", "append_transform"], [179, 1, 1, "", "apply"], [179, 1, 1, "", "auto_specs_"], [179, 2, 1, "", "batch_dims"], [179, 2, 1, "", "batch_locked"], [179, 2, 1, "", "batch_size"], [179, 1, 1, "", "bfloat16"], [179, 1, 1, "", "buffers"], [179, 1, 1, "", "cardinality"], [179, 1, 1, "", "check_env_specs"], [179, 1, 1, "", "children"], [179, 2, 1, "", "collector"], [179, 1, 1, "", "compile"], [179, 1, 1, "", "cpu"], [179, 1, 1, "", "cuda"], [179, 2, 1, "", "done_key"], [179, 2, 1, "", "done_keys"], [179, 2, 1, "", "done_keys_groups"], [179, 2, 1, "", "done_spec"], [179, 2, 1, "", "done_spec_unbatched"], [179, 1, 1, "", "double"], [179, 1, 1, "", "empty_cache"], [179, 1, 1, "", "eval"], [179, 1, 1, "", "extra_repr"], [179, 1, 1, "", "fake_tensordict"], [179, 1, 1, "", "float"], [179, 1, 1, "", "forward"], [179, 2, 1, "", "full_action_spec"], [179, 2, 1, "", "full_action_spec_unbatched"], [179, 2, 1, "", "full_done_spec"], [179, 2, 1, "", "full_done_spec_unbatched"], [179, 2, 1, "", "full_observation_spec_unbatched"], [179, 2, 1, "", "full_reward_spec"], [179, 2, 1, "", "full_reward_spec_unbatched"], [179, 2, 1, "", "full_state_spec"], [179, 2, 1, "", "full_state_spec_unbatched"], [179, 1, 1, "", "get_buffer"], [179, 1, 1, "", "get_extra_state"], [179, 1, 1, "", "get_parameter"], [179, 1, 1, "", "get_submodule"], [179, 1, 1, "", "half"], [179, 2, 1, "", "input_spec"], [179, 2, 1, "", "input_spec_unbatched"], [179, 1, 1, "", "ipu"], [179, 2, 1, "", "is_spec_locked"], [179, 1, 1, "", "load_state_dict"], [179, 1, 1, "", "make_tensordict"], [179, 1, 1, "", "maybe_reset"], [179, 1, 1, "", "modules"], [179, 1, 1, "", "mtia"], [179, 1, 1, "", "named_buffers"], [179, 1, 1, "", "named_children"], [179, 1, 1, "", "named_modules"], [179, 1, 1, "", "named_parameters"], [179, 2, 1, "", "observation_keys"], [179, 2, 1, "", "observation_spec"], [179, 2, 1, "", "observation_spec_unbatched"], [179, 2, 1, "", "output_spec"], [179, 2, 1, "", "output_spec_unbatched"], [179, 1, 1, "", "parameters"], [179, 1, 1, "", "rand_action"], [179, 1, 1, "", "rand_step"], [179, 1, 1, "", "register_backward_hook"], [179, 1, 1, "", "register_buffer"], [179, 1, 1, "", "register_collector"], [179, 1, 1, "", "register_forward_hook"], [179, 1, 1, "", "register_forward_pre_hook"], [179, 1, 1, "", "register_full_backward_hook"], [179, 1, 1, "", "register_full_backward_pre_hook"], [179, 1, 1, "", "register_gym"], [179, 1, 1, "", "register_load_state_dict_post_hook"], [179, 1, 1, "", "register_load_state_dict_pre_hook"], [179, 1, 1, "", "register_module"], [179, 1, 1, "", "register_parameter"], [179, 1, 1, "", "register_state_dict_post_hook"], [179, 1, 1, "", "register_state_dict_pre_hook"], [179, 1, 1, "", "requires_grad_"], [179, 1, 1, "", "reset"], [179, 2, 1, "", "reset_keys"], [179, 2, 1, "", "reward_key"], [179, 2, 1, "", "reward_keys"], [179, 2, 1, "", "reward_spec"], [179, 2, 1, "", "reward_spec_unbatched"], [179, 1, 1, "", "rollout"], [179, 1, 1, "", "set_extra_state"], [179, 1, 1, "", "set_seed"], [179, 1, 1, "", "set_spec_lock_"], [179, 1, 1, "", "set_submodule"], [179, 2, 1, "", "shape"], [179, 1, 1, "", "share_memory"], [179, 2, 1, "", "specs"], [179, 1, 1, "", "state_dict"], [179, 2, 1, "", "state_keys"], [179, 2, 1, "", "state_spec"], [179, 2, 1, "", "state_spec_unbatched"], [179, 1, 1, "", "step"], [179, 1, 1, "", "step_and_maybe_reset"], [179, 1, 1, "", "step_mdp"], [179, 1, 1, "", "to"], [179, 1, 1, "", "to_empty"], [179, 1, 1, "", "train"], [179, 1, 1, "", "type"], [179, 1, 1, "", "xpu"], [179, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.MLGymWrapper": [[180, 2, 1, "", "action_key"], [180, 2, 1, "", "action_keys"], [180, 2, 1, "", "action_spec"], [180, 2, 1, "", "action_spec_unbatched"], [180, 1, 1, "", "add_module"], [180, 1, 1, "", "add_truncated_keys"], [180, 1, 1, "", "all_actions"], [180, 1, 1, "", "any_done"], [180, 1, 1, "", "append_transform"], [180, 1, 1, "", "apply"], [180, 1, 1, "", "auto_register_info_dict"], [180, 1, 1, "", "auto_specs_"], [180, 2, 1, "", "batch_dims"], [180, 2, 1, "", "batch_locked"], [180, 2, 1, "", "batch_size"], [180, 1, 1, "", "bfloat16"], [180, 1, 1, "", "buffers"], [180, 1, 1, "", "cardinality"], [180, 1, 1, "", "check_env_specs"], [180, 1, 1, "", "children"], [180, 1, 1, "", "close"], [180, 2, 1, "", "collector"], [180, 1, 1, "", "compile"], [180, 1, 1, "", "cpu"], [180, 1, 1, "", "cuda"], [180, 2, 1, "", "done_key"], [180, 2, 1, "", "done_keys"], [180, 2, 1, "", "done_keys_groups"], [180, 2, 1, "", "done_spec"], [180, 2, 1, "", "done_spec_unbatched"], [180, 1, 1, "", "double"], [180, 1, 1, "", "empty_cache"], [180, 1, 1, "", "eval"], [180, 1, 1, "", "extra_repr"], [180, 1, 1, "", "fake_tensordict"], [180, 1, 1, "", "fast_encoding"], [180, 1, 1, "", "float"], [180, 1, 1, "", "forward"], [180, 2, 1, "", "full_action_spec"], [180, 2, 1, "", "full_action_spec_unbatched"], [180, 2, 1, "", "full_done_spec"], [180, 2, 1, "", "full_done_spec_unbatched"], [180, 2, 1, "", "full_observation_spec_unbatched"], [180, 2, 1, "", "full_reward_spec"], [180, 2, 1, "", "full_reward_spec_unbatched"], [180, 2, 1, "", "full_state_spec"], [180, 2, 1, "", "full_state_spec_unbatched"], [180, 1, 1, "", "get_buffer"], [180, 1, 1, "", "get_extra_state"], [180, 1, 1, "", "get_library_name"], [180, 1, 1, "", "get_parameter"], [180, 1, 1, "", "get_submodule"], [180, 1, 1, "", "half"], [180, 2, 1, "", "input_spec"], [180, 2, 1, "", "input_spec_unbatched"], [180, 1, 1, "", "ipu"], [180, 2, 1, "", "is_spec_locked"], [180, 1, 1, "", "load_state_dict"], [180, 1, 1, "", "maybe_reset"], [180, 1, 1, "", "modules"], [180, 1, 1, "", "mtia"], [180, 1, 1, "", "named_buffers"], [180, 1, 1, "", "named_children"], [180, 1, 1, "", "named_modules"], [180, 1, 1, "", "named_parameters"], [180, 2, 1, "", "observation_keys"], [180, 2, 1, "", "observation_spec"], [180, 2, 1, "", "observation_spec_unbatched"], [180, 2, 1, "", "output_spec"], [180, 2, 1, "", "output_spec_unbatched"], [180, 1, 1, "", "parameters"], [180, 1, 1, "", "rand_action"], [180, 1, 1, "", "rand_step"], [180, 1, 1, "", "read_action"], [180, 1, 1, "", "read_done"], [180, 1, 1, "", "read_obs"], [180, 1, 1, "", "read_reward"], [180, 1, 1, "", "register_backward_hook"], [180, 1, 1, "", "register_buffer"], [180, 1, 1, "", "register_collector"], [180, 1, 1, "", "register_forward_hook"], [180, 1, 1, "", "register_forward_pre_hook"], [180, 1, 1, "", "register_full_backward_hook"], [180, 1, 1, "", "register_full_backward_pre_hook"], [180, 1, 1, "", "register_gym"], [180, 1, 1, "", "register_load_state_dict_post_hook"], [180, 1, 1, "", "register_load_state_dict_pre_hook"], [180, 1, 1, "", "register_module"], [180, 1, 1, "", "register_parameter"], [180, 1, 1, "", "register_state_dict_post_hook"], [180, 1, 1, "", "register_state_dict_pre_hook"], [180, 1, 1, "", "requires_grad_"], [180, 1, 1, "", "reset"], [180, 2, 1, "", "reset_keys"], [180, 2, 1, "", "reward_key"], [180, 2, 1, "", "reward_keys"], [180, 2, 1, "", "reward_spec"], [180, 2, 1, "", "reward_spec_unbatched"], [180, 1, 1, "", "rollout"], [180, 1, 1, "", "set_extra_state"], [180, 1, 1, "", "set_info_dict_reader"], [180, 1, 1, "", "set_seed"], [180, 1, 1, "", "set_spec_lock_"], [180, 1, 1, "", "set_submodule"], [180, 2, 1, "", "shape"], [180, 1, 1, "", "share_memory"], [180, 2, 1, "", "specs"], [180, 1, 1, "", "state_dict"], [180, 2, 1, "", "state_keys"], [180, 2, 1, "", "state_spec"], [180, 2, 1, "", "state_spec_unbatched"], [180, 1, 1, "", "step"], [180, 1, 1, "", "step_and_maybe_reset"], [180, 1, 1, "", "step_mdp"], [180, 1, 1, "", "to"], [180, 1, 1, "", "to_empty"], [180, 1, 1, "", "train"], [180, 1, 1, "", "type"], [180, 1, 1, "", "xpu"], [180, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms": [[183, 0, 1, "", "AddThinkingPrompt"], [184, 0, 1, "", "BrowserTransform"], [185, 0, 1, "", "DataLoadingPrimer"], [186, 0, 1, "", "ExecuteToolsInOrder"], [187, 0, 1, "", "JSONCallParser"], [188, 0, 1, "", "KLComputation"], [189, 0, 1, "", "KLRewardTransform"], [190, 0, 1, "", "MCPToolTransform"], [191, 0, 1, "", "PolicyVersion"], [192, 0, 1, "", "PythonExecutorService"], [193, 0, 1, "", "PythonInterpreter"], [194, 0, 1, "", "RayDataLoadingPrimer"], [195, 0, 1, "", "RetrieveKL"], [196, 0, 1, "", "RetrieveLogProb"], [197, 0, 1, "", "SimpleToolTransform"], [198, 0, 1, "", "TemplateTransform"], [199, 0, 1, "", "Tokenizer"], [200, 0, 1, "", "ToolCall"], [201, 0, 1, "", "ToolRegistry"], [202, 0, 1, "", "ToolService"], [203, 0, 1, "", "XMLBlockParser"], [204, 0, 1, "", "as_nested_tensor"], [205, 0, 1, "", "as_padded_tensor"]], "torchrl.envs.llm.transforms.AddThinkingPrompt": [[183, 1, 1, "", "add_module"], [183, 1, 1, "", "apply"], [183, 1, 1, "", "bfloat16"], [183, 1, 1, "", "buffers"], [183, 1, 1, "", "children"], [183, 1, 1, "", "close"], [183, 2, 1, "", "collector"], [183, 1, 1, "", "compile"], [183, 2, 1, "", "container"], [183, 1, 1, "", "cpu"], [183, 1, 1, "", "cuda"], [183, 1, 1, "", "double"], [183, 1, 1, "", "eval"], [183, 1, 1, "", "extra_repr"], [183, 1, 1, "", "float"], [183, 1, 1, "", "forward"], [183, 1, 1, "", "get_buffer"], [183, 1, 1, "", "get_extra_state"], [183, 1, 1, "", "get_parameter"], [183, 1, 1, "", "get_submodule"], [183, 1, 1, "", "half"], [183, 1, 1, "", "init"], [183, 1, 1, "", "inv"], [183, 1, 1, "", "ipu"], [183, 1, 1, "", "load_state_dict"], [183, 1, 1, "", "modules"], [183, 1, 1, "", "mtia"], [183, 1, 1, "", "named_buffers"], [183, 1, 1, "", "named_children"], [183, 1, 1, "", "named_modules"], [183, 1, 1, "", "named_parameters"], [183, 1, 1, "", "parameters"], [183, 2, 1, "", "parent"], [183, 1, 1, "", "register_backward_hook"], [183, 1, 1, "", "register_buffer"], [183, 1, 1, "", "register_forward_hook"], [183, 1, 1, "", "register_forward_pre_hook"], [183, 1, 1, "", "register_full_backward_hook"], [183, 1, 1, "", "register_full_backward_pre_hook"], [183, 1, 1, "", "register_load_state_dict_post_hook"], [183, 1, 1, "", "register_load_state_dict_pre_hook"], [183, 1, 1, "", "register_module"], [183, 1, 1, "", "register_parameter"], [183, 1, 1, "", "register_state_dict_post_hook"], [183, 1, 1, "", "register_state_dict_pre_hook"], [183, 1, 1, "", "requires_grad_"], [183, 1, 1, "", "set_extra_state"], [183, 1, 1, "", "set_submodule"], [183, 1, 1, "", "share_memory"], [183, 1, 1, "", "state_dict"], [183, 1, 1, "", "to"], [183, 1, 1, "", "to_empty"], [183, 1, 1, "", "train"], [183, 1, 1, "", "transform_action_spec"], [183, 1, 1, "", "transform_done_spec"], [183, 1, 1, "", "transform_env_batch_size"], [183, 1, 1, "", "transform_env_device"], [183, 1, 1, "", "transform_input_spec"], [183, 1, 1, "", "transform_observation_spec"], [183, 1, 1, "", "transform_output_spec"], [183, 1, 1, "", "transform_reward_spec"], [183, 1, 1, "", "transform_state_spec"], [183, 1, 1, "", "type"], [183, 1, 1, "", "xpu"], [183, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.BrowserTransform": [[184, 1, 1, "", "add_module"], [184, 1, 1, "", "apply"], [184, 1, 1, "", "bfloat16"], [184, 1, 1, "", "buffers"], [184, 1, 1, "", "children"], [184, 1, 1, "", "clone"], [184, 1, 1, "", "close"], [184, 2, 1, "", "collector"], [184, 1, 1, "", "compile"], [184, 2, 1, "", "container"], [184, 1, 1, "", "cpu"], [184, 1, 1, "", "cuda"], [184, 1, 1, "", "double"], [184, 1, 1, "", "eval"], [184, 1, 1, "", "extra_repr"], [184, 1, 1, "", "float"], [184, 1, 1, "", "forward"], [184, 1, 1, "", "get_buffer"], [184, 1, 1, "", "get_extra_state"], [184, 1, 1, "", "get_parameter"], [184, 1, 1, "", "get_submodule"], [184, 1, 1, "", "half"], [184, 1, 1, "", "init"], [184, 1, 1, "", "inv"], [184, 1, 1, "", "ipu"], [184, 1, 1, "", "load_state_dict"], [184, 1, 1, "", "modules"], [184, 1, 1, "", "mtia"], [184, 1, 1, "", "named_buffers"], [184, 1, 1, "", "named_children"], [184, 1, 1, "", "named_modules"], [184, 1, 1, "", "named_parameters"], [184, 1, 1, "", "parameters"], [184, 2, 1, "", "parent"], [184, 1, 1, "", "register_backward_hook"], [184, 1, 1, "", "register_buffer"], [184, 1, 1, "", "register_forward_hook"], [184, 1, 1, "", "register_forward_pre_hook"], [184, 1, 1, "", "register_full_backward_hook"], [184, 1, 1, "", "register_full_backward_pre_hook"], [184, 1, 1, "", "register_load_state_dict_post_hook"], [184, 1, 1, "", "register_load_state_dict_pre_hook"], [184, 1, 1, "", "register_module"], [184, 1, 1, "", "register_parameter"], [184, 1, 1, "", "register_state_dict_post_hook"], [184, 1, 1, "", "register_state_dict_pre_hook"], [184, 1, 1, "", "requires_grad_"], [184, 1, 1, "", "set_extra_state"], [184, 1, 1, "", "set_submodule"], [184, 1, 1, "", "share_memory"], [184, 1, 1, "", "state_dict"], [184, 1, 1, "", "to"], [184, 1, 1, "", "to_empty"], [184, 1, 1, "", "train"], [184, 1, 1, "", "transform_action_spec"], [184, 1, 1, "", "transform_done_spec"], [184, 1, 1, "", "transform_env_batch_size"], [184, 1, 1, "", "transform_env_device"], [184, 1, 1, "", "transform_input_spec"], [184, 1, 1, "", "transform_observation_spec"], [184, 1, 1, "", "transform_output_spec"], [184, 1, 1, "", "transform_reward_spec"], [184, 1, 1, "", "transform_state_spec"], [184, 1, 1, "", "type"], [184, 1, 1, "", "xpu"], [184, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.DataLoadingPrimer": [[185, 1, 1, "", "add_module"], [185, 1, 1, "", "apply"], [185, 1, 1, "", "bfloat16"], [185, 1, 1, "", "buffers"], [185, 1, 1, "", "children"], [185, 1, 1, "", "close"], [185, 2, 1, "", "collector"], [185, 1, 1, "", "compile"], [185, 2, 1, "", "container"], [185, 1, 1, "", "cpu"], [185, 1, 1, "", "cuda"], [185, 1, 1, "", "double"], [185, 1, 1, "", "eval"], [185, 1, 1, "", "extra_repr"], [185, 1, 1, "", "float"], [185, 1, 1, "", "forward"], [185, 1, 1, "", "get_buffer"], [185, 1, 1, "", "get_extra_state"], [185, 1, 1, "", "get_parameter"], [185, 1, 1, "", "get_submodule"], [185, 1, 1, "", "half"], [185, 1, 1, "", "init"], [185, 1, 1, "", "inv"], [185, 1, 1, "", "ipu"], [185, 1, 1, "", "load_state_dict"], [185, 1, 1, "", "modules"], [185, 1, 1, "", "mtia"], [185, 1, 1, "", "named_buffers"], [185, 1, 1, "", "named_children"], [185, 1, 1, "", "named_modules"], [185, 1, 1, "", "named_parameters"], [185, 1, 1, "", "parameters"], [185, 2, 1, "", "parent"], [185, 1, 1, "", "register_backward_hook"], [185, 1, 1, "", "register_buffer"], [185, 1, 1, "", "register_forward_hook"], [185, 1, 1, "", "register_forward_pre_hook"], [185, 1, 1, "", "register_full_backward_hook"], [185, 1, 1, "", "register_full_backward_pre_hook"], [185, 1, 1, "", "register_load_state_dict_post_hook"], [185, 1, 1, "", "register_load_state_dict_pre_hook"], [185, 1, 1, "", "register_module"], [185, 1, 1, "", "register_parameter"], [185, 1, 1, "", "register_state_dict_post_hook"], [185, 1, 1, "", "register_state_dict_pre_hook"], [185, 1, 1, "", "requires_grad_"], [185, 1, 1, "", "reset_dataloader"], [185, 1, 1, "", "set_extra_state"], [185, 1, 1, "", "set_submodule"], [185, 1, 1, "", "share_memory"], [185, 1, 1, "", "state_dict"], [185, 1, 1, "", "to"], [185, 1, 1, "", "to_empty"], [185, 1, 1, "", "train"], [185, 1, 1, "", "transform_action_spec"], [185, 1, 1, "", "transform_done_spec"], [185, 1, 1, "", "transform_env_batch_size"], [185, 1, 1, "", "transform_env_device"], [185, 1, 1, "", "transform_input_spec"], [185, 1, 1, "", "transform_observation_spec"], [185, 1, 1, "", "transform_output_spec"], [185, 1, 1, "", "transform_reward_spec"], [185, 1, 1, "", "transform_state_spec"], [185, 1, 1, "", "type"], [185, 1, 1, "", "xpu"], [185, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.ExecuteToolsInOrder": [[186, 1, 1, "", "add_module"], [186, 1, 1, "", "apply"], [186, 1, 1, "", "bfloat16"], [186, 1, 1, "", "buffers"], [186, 1, 1, "", "children"], [186, 1, 1, "", "close"], [186, 2, 1, "", "collector"], [186, 1, 1, "", "compile"], [186, 2, 1, "", "container"], [186, 1, 1, "", "cpu"], [186, 1, 1, "", "cuda"], [186, 1, 1, "", "double"], [186, 1, 1, "", "eval"], [186, 1, 1, "", "extra_repr"], [186, 1, 1, "", "float"], [186, 1, 1, "", "forward"], [186, 1, 1, "", "get_buffer"], [186, 1, 1, "", "get_extra_state"], [186, 1, 1, "", "get_parameter"], [186, 1, 1, "", "get_submodule"], [186, 1, 1, "", "half"], [186, 1, 1, "", "init"], [186, 1, 1, "", "inv"], [186, 1, 1, "", "ipu"], [186, 1, 1, "", "load_state_dict"], [186, 1, 1, "", "modules"], [186, 1, 1, "", "mtia"], [186, 1, 1, "", "named_buffers"], [186, 1, 1, "", "named_children"], [186, 1, 1, "", "named_modules"], [186, 1, 1, "", "named_parameters"], [186, 1, 1, "", "parameters"], [186, 2, 1, "", "parent"], [186, 1, 1, "", "register_backward_hook"], [186, 1, 1, "", "register_buffer"], [186, 1, 1, "", "register_forward_hook"], [186, 1, 1, "", "register_forward_pre_hook"], [186, 1, 1, "", "register_full_backward_hook"], [186, 1, 1, "", "register_full_backward_pre_hook"], [186, 1, 1, "", "register_load_state_dict_post_hook"], [186, 1, 1, "", "register_load_state_dict_pre_hook"], [186, 1, 1, "", "register_module"], [186, 1, 1, "", "register_parameter"], [186, 1, 1, "", "register_state_dict_post_hook"], [186, 1, 1, "", "register_state_dict_pre_hook"], [186, 1, 1, "", "requires_grad_"], [186, 1, 1, "", "set_extra_state"], [186, 1, 1, "", "set_submodule"], [186, 1, 1, "", "share_memory"], [186, 1, 1, "", "state_dict"], [186, 1, 1, "", "to"], [186, 1, 1, "", "to_empty"], [186, 1, 1, "", "train"], [186, 1, 1, "", "transform_action_spec"], [186, 1, 1, "", "transform_done_spec"], [186, 1, 1, "", "transform_env_batch_size"], [186, 1, 1, "", "transform_env_device"], [186, 1, 1, "", "transform_input_spec"], [186, 1, 1, "", "transform_observation_spec"], [186, 1, 1, "", "transform_output_spec"], [186, 1, 1, "", "transform_reward_spec"], [186, 1, 1, "", "transform_state_spec"], [186, 1, 1, "", "type"], [186, 1, 1, "", "xpu"], [186, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.KLComputation": [[188, 1, 1, "", "add_module"], [188, 1, 1, "", "apply"], [188, 1, 1, "", "bfloat16"], [188, 1, 1, "", "buffers"], [188, 1, 1, "", "children"], [188, 1, 1, "", "close"], [188, 2, 1, "", "collector"], [188, 1, 1, "", "compile"], [188, 2, 1, "", "container"], [188, 1, 1, "", "cpu"], [188, 1, 1, "", "cuda"], [188, 1, 1, "", "double"], [188, 1, 1, "", "eval"], [188, 1, 1, "", "extra_repr"], [188, 1, 1, "", "float"], [188, 1, 1, "", "forward"], [188, 1, 1, "", "get_buffer"], [188, 1, 1, "", "get_extra_state"], [188, 1, 1, "", "get_parameter"], [188, 1, 1, "", "get_submodule"], [188, 1, 1, "", "half"], [188, 1, 1, "", "init"], [188, 1, 1, "", "inv"], [188, 1, 1, "", "ipu"], [188, 1, 1, "", "load_state_dict"], [188, 1, 1, "", "modules"], [188, 1, 1, "", "mtia"], [188, 1, 1, "", "named_buffers"], [188, 1, 1, "", "named_children"], [188, 1, 1, "", "named_modules"], [188, 1, 1, "", "named_parameters"], [188, 1, 1, "", "parameters"], [188, 2, 1, "", "parent"], [188, 1, 1, "", "register_backward_hook"], [188, 1, 1, "", "register_buffer"], [188, 1, 1, "", "register_forward_hook"], [188, 1, 1, "", "register_forward_pre_hook"], [188, 1, 1, "", "register_full_backward_hook"], [188, 1, 1, "", "register_full_backward_pre_hook"], [188, 1, 1, "", "register_load_state_dict_post_hook"], [188, 1, 1, "", "register_load_state_dict_pre_hook"], [188, 1, 1, "", "register_module"], [188, 1, 1, "", "register_parameter"], [188, 1, 1, "", "register_state_dict_post_hook"], [188, 1, 1, "", "register_state_dict_pre_hook"], [188, 1, 1, "", "requires_grad_"], [188, 1, 1, "", "set_extra_state"], [188, 1, 1, "", "set_submodule"], [188, 1, 1, "", "share_memory"], [188, 1, 1, "", "state_dict"], [188, 1, 1, "", "to"], [188, 1, 1, "", "to_empty"], [188, 1, 1, "", "train"], [188, 1, 1, "", "transform_action_spec"], [188, 1, 1, "", "transform_done_spec"], [188, 1, 1, "", "transform_env_batch_size"], [188, 1, 1, "", "transform_env_device"], [188, 1, 1, "", "transform_input_spec"], [188, 1, 1, "", "transform_observation_spec"], [188, 1, 1, "", "transform_output_spec"], [188, 1, 1, "", "transform_reward_spec"], [188, 1, 1, "", "transform_state_spec"], [188, 1, 1, "", "type"], [188, 1, 1, "", "xpu"], [188, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.KLRewardTransform": [[189, 1, 1, "", "add_module"], [189, 1, 1, "", "apply"], [189, 1, 1, "", "bfloat16"], [189, 1, 1, "", "buffers"], [189, 1, 1, "", "children"], [189, 1, 1, "", "close"], [189, 2, 1, "", "collector"], [189, 1, 1, "", "compile"], [189, 2, 1, "", "container"], [189, 1, 1, "", "cpu"], [189, 1, 1, "", "cuda"], [189, 1, 1, "", "double"], [189, 1, 1, "", "eval"], [189, 1, 1, "", "extra_repr"], [189, 1, 1, "", "float"], [189, 1, 1, "", "forward"], [189, 1, 1, "", "get_buffer"], [189, 1, 1, "", "get_extra_state"], [189, 1, 1, "", "get_parameter"], [189, 1, 1, "", "get_submodule"], [189, 1, 1, "", "half"], [189, 1, 1, "", "init"], [189, 1, 1, "", "inv"], [189, 1, 1, "", "ipu"], [189, 1, 1, "", "load_state_dict"], [189, 1, 1, "", "modules"], [189, 1, 1, "", "mtia"], [189, 1, 1, "", "named_buffers"], [189, 1, 1, "", "named_children"], [189, 1, 1, "", "named_modules"], [189, 1, 1, "", "named_parameters"], [189, 1, 1, "", "parameters"], [189, 2, 1, "", "parent"], [189, 1, 1, "", "register_backward_hook"], [189, 1, 1, "", "register_buffer"], [189, 1, 1, "", "register_forward_hook"], [189, 1, 1, "", "register_forward_pre_hook"], [189, 1, 1, "", "register_full_backward_hook"], [189, 1, 1, "", "register_full_backward_pre_hook"], [189, 1, 1, "", "register_load_state_dict_post_hook"], [189, 1, 1, "", "register_load_state_dict_pre_hook"], [189, 1, 1, "", "register_module"], [189, 1, 1, "", "register_parameter"], [189, 1, 1, "", "register_state_dict_post_hook"], [189, 1, 1, "", "register_state_dict_pre_hook"], [189, 1, 1, "", "requires_grad_"], [189, 1, 1, "", "set_extra_state"], [189, 1, 1, "", "set_submodule"], [189, 1, 1, "", "share_memory"], [189, 1, 1, "", "state_dict"], [189, 1, 1, "", "to"], [189, 1, 1, "", "to_empty"], [189, 1, 1, "", "train"], [189, 1, 1, "", "transform_action_spec"], [189, 1, 1, "", "transform_done_spec"], [189, 1, 1, "", "transform_env_batch_size"], [189, 1, 1, "", "transform_env_device"], [189, 1, 1, "", "transform_input_spec"], [189, 1, 1, "", "transform_observation_spec"], [189, 1, 1, "", "transform_output_spec"], [189, 1, 1, "", "transform_reward_spec"], [189, 1, 1, "", "transform_state_spec"], [189, 1, 1, "", "type"], [189, 1, 1, "", "xpu"], [189, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.MCPToolTransform": [[190, 1, 1, "", "add_module"], [190, 1, 1, "", "apply"], [190, 1, 1, "", "bfloat16"], [190, 1, 1, "", "buffers"], [190, 1, 1, "", "children"], [190, 1, 1, "", "close"], [190, 2, 1, "", "collector"], [190, 1, 1, "", "compile"], [190, 2, 1, "", "container"], [190, 1, 1, "", "cpu"], [190, 1, 1, "", "cuda"], [190, 1, 1, "", "double"], [190, 1, 1, "", "eval"], [190, 1, 1, "", "extra_repr"], [190, 1, 1, "", "float"], [190, 1, 1, "", "forward"], [190, 1, 1, "", "get_buffer"], [190, 1, 1, "", "get_extra_state"], [190, 1, 1, "", "get_parameter"], [190, 1, 1, "", "get_submodule"], [190, 1, 1, "", "half"], [190, 1, 1, "", "init"], [190, 1, 1, "", "inv"], [190, 1, 1, "", "ipu"], [190, 1, 1, "", "load_state_dict"], [190, 1, 1, "", "modules"], [190, 1, 1, "", "mtia"], [190, 1, 1, "", "named_buffers"], [190, 1, 1, "", "named_children"], [190, 1, 1, "", "named_modules"], [190, 1, 1, "", "named_parameters"], [190, 1, 1, "", "parameters"], [190, 2, 1, "", "parent"], [190, 1, 1, "", "register_backward_hook"], [190, 1, 1, "", "register_buffer"], [190, 1, 1, "", "register_forward_hook"], [190, 1, 1, "", "register_forward_pre_hook"], [190, 1, 1, "", "register_full_backward_hook"], [190, 1, 1, "", "register_full_backward_pre_hook"], [190, 1, 1, "", "register_load_state_dict_post_hook"], [190, 1, 1, "", "register_load_state_dict_pre_hook"], [190, 1, 1, "", "register_module"], [190, 1, 1, "", "register_parameter"], [190, 1, 1, "", "register_state_dict_post_hook"], [190, 1, 1, "", "register_state_dict_pre_hook"], [190, 1, 1, "", "requires_grad_"], [190, 1, 1, "", "set_extra_state"], [190, 1, 1, "", "set_submodule"], [190, 1, 1, "", "share_memory"], [190, 1, 1, "", "state_dict"], [190, 1, 1, "", "to"], [190, 1, 1, "", "to_empty"], [190, 1, 1, "", "train"], [190, 1, 1, "", "transform_action_spec"], [190, 1, 1, "", "transform_done_spec"], [190, 1, 1, "", "transform_env_batch_size"], [190, 1, 1, "", "transform_env_device"], [190, 1, 1, "", "transform_input_spec"], [190, 1, 1, "", "transform_observation_spec"], [190, 1, 1, "", "transform_output_spec"], [190, 1, 1, "", "transform_reward_spec"], [190, 1, 1, "", "transform_state_spec"], [190, 1, 1, "", "type"], [190, 1, 1, "", "xpu"], [190, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.PolicyVersion": [[191, 1, 1, "", "add_module"], [191, 1, 1, "", "apply"], [191, 1, 1, "", "bfloat16"], [191, 1, 1, "", "buffers"], [191, 1, 1, "", "children"], [191, 1, 1, "", "close"], [191, 2, 1, "", "collector"], [191, 1, 1, "", "compile"], [191, 2, 1, "", "container"], [191, 1, 1, "", "cpu"], [191, 1, 1, "", "cuda"], [191, 1, 1, "", "double"], [191, 1, 1, "", "eval"], [191, 1, 1, "", "extra_repr"], [191, 1, 1, "", "float"], [191, 1, 1, "", "forward"], [191, 1, 1, "", "get_buffer"], [191, 1, 1, "", "get_extra_state"], [191, 1, 1, "", "get_parameter"], [191, 1, 1, "", "get_submodule"], [191, 1, 1, "", "half"], [191, 1, 1, "", "increment_version"], [191, 1, 1, "", "init"], [191, 1, 1, "", "inv"], [191, 1, 1, "", "ipu"], [191, 1, 1, "", "load_state_dict"], [191, 1, 1, "", "modules"], [191, 1, 1, "", "mtia"], [191, 1, 1, "", "named_buffers"], [191, 1, 1, "", "named_children"], [191, 1, 1, "", "named_modules"], [191, 1, 1, "", "named_parameters"], [191, 1, 1, "", "parameters"], [191, 2, 1, "", "parent"], [191, 1, 1, "", "register_backward_hook"], [191, 1, 1, "", "register_buffer"], [191, 1, 1, "", "register_forward_hook"], [191, 1, 1, "", "register_forward_pre_hook"], [191, 1, 1, "", "register_full_backward_hook"], [191, 1, 1, "", "register_full_backward_pre_hook"], [191, 1, 1, "", "register_load_state_dict_post_hook"], [191, 1, 1, "", "register_load_state_dict_pre_hook"], [191, 1, 1, "", "register_module"], [191, 1, 1, "", "register_parameter"], [191, 1, 1, "", "register_state_dict_post_hook"], [191, 1, 1, "", "register_state_dict_pre_hook"], [191, 1, 1, "", "requires_grad_"], [191, 1, 1, "", "set_extra_state"], [191, 1, 1, "", "set_submodule"], [191, 1, 1, "", "share_memory"], [191, 1, 1, "", "state_dict"], [191, 1, 1, "", "to"], [191, 1, 1, "", "to_empty"], [191, 1, 1, "", "train"], [191, 1, 1, "", "transform_action_spec"], [191, 1, 1, "", "transform_done_spec"], [191, 1, 1, "", "transform_env_batch_size"], [191, 1, 1, "", "transform_env_device"], [191, 1, 1, "", "transform_input_spec"], [191, 1, 1, "", "transform_observation_spec"], [191, 1, 1, "", "transform_output_spec"], [191, 1, 1, "", "transform_reward_spec"], [191, 1, 1, "", "transform_state_spec"], [191, 1, 1, "", "type"], [191, 2, 1, "", "version"], [191, 1, 1, "", "xpu"], [191, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.PythonExecutorService": [[192, 1, 1, "", "cleanup"], [192, 1, 1, "", "execute"]], "torchrl.envs.llm.transforms.PythonInterpreter": [[193, 1, 1, "", "add_module"], [193, 1, 1, "", "apply"], [193, 1, 1, "", "bfloat16"], [193, 1, 1, "", "buffers"], [193, 1, 1, "", "children"], [193, 1, 1, "", "clone"], [193, 1, 1, "", "close"], [193, 2, 1, "", "collector"], [193, 1, 1, "", "compile"], [193, 2, 1, "", "container"], [193, 1, 1, "", "cpu"], [193, 1, 1, "", "cuda"], [193, 1, 1, "", "double"], [193, 1, 1, "", "eval"], [193, 1, 1, "", "extra_repr"], [193, 1, 1, "", "float"], [193, 1, 1, "", "forward"], [193, 1, 1, "", "get_buffer"], [193, 1, 1, "", "get_extra_state"], [193, 1, 1, "", "get_parameter"], [193, 1, 1, "", "get_submodule"], [193, 1, 1, "", "half"], [193, 1, 1, "", "init"], [193, 1, 1, "", "inv"], [193, 1, 1, "", "ipu"], [193, 1, 1, "", "load_state_dict"], [193, 1, 1, "", "modules"], [193, 1, 1, "", "mtia"], [193, 1, 1, "", "named_buffers"], [193, 1, 1, "", "named_children"], [193, 1, 1, "", "named_modules"], [193, 1, 1, "", "named_parameters"], [193, 1, 1, "", "parameters"], [193, 2, 1, "", "parent"], [193, 1, 1, "", "register_backward_hook"], [193, 1, 1, "", "register_buffer"], [193, 1, 1, "", "register_forward_hook"], [193, 1, 1, "", "register_forward_pre_hook"], [193, 1, 1, "", "register_full_backward_hook"], [193, 1, 1, "", "register_full_backward_pre_hook"], [193, 1, 1, "", "register_load_state_dict_post_hook"], [193, 1, 1, "", "register_load_state_dict_pre_hook"], [193, 1, 1, "", "register_module"], [193, 1, 1, "", "register_parameter"], [193, 1, 1, "", "register_state_dict_post_hook"], [193, 1, 1, "", "register_state_dict_pre_hook"], [193, 1, 1, "", "requires_grad_"], [193, 1, 1, "", "set_extra_state"], [193, 1, 1, "", "set_submodule"], [193, 1, 1, "", "share_memory"], [193, 1, 1, "", "state_dict"], [193, 1, 1, "", "to"], [193, 1, 1, "", "to_empty"], [193, 1, 1, "", "train"], [193, 1, 1, "", "transform_action_spec"], [193, 1, 1, "", "transform_done_spec"], [193, 1, 1, "", "transform_env_batch_size"], [193, 1, 1, "", "transform_env_device"], [193, 1, 1, "", "transform_input_spec"], [193, 1, 1, "", "transform_observation_spec"], [193, 1, 1, "", "transform_output_spec"], [193, 1, 1, "", "transform_reward_spec"], [193, 1, 1, "", "transform_state_spec"], [193, 1, 1, "", "type"], [193, 1, 1, "", "xpu"], [193, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.RayDataLoadingPrimer": [[194, 1, 1, "", "add_module"], [194, 1, 1, "", "apply"], [194, 2, 1, "", "base_env"], [194, 1, 1, "", "bfloat16"], [194, 1, 1, "", "buffers"], [194, 1, 1, "", "children"], [194, 1, 1, "", "clone"], [194, 1, 1, "", "close"], [194, 2, 1, "", "collector"], [194, 1, 1, "", "compile"], [194, 2, 1, "", "container"], [194, 1, 1, "", "cpu"], [194, 1, 1, "", "cuda"], [194, 2, 1, "", "data_keys"], [194, 2, 1, "", "dataloader"], [194, 2, 1, "", "device"], [194, 1, 1, "", "double"], [194, 1, 1, "", "dump"], [194, 1, 1, "", "empty_cache"], [194, 2, 1, "", "endless_dataloader"], [194, 1, 1, "", "eval"], [194, 1, 1, "", "extra_repr"], [194, 1, 1, "", "float"], [194, 1, 1, "", "forward"], [194, 1, 1, "", "get_buffer"], [194, 1, 1, "", "get_extra_state"], [194, 1, 1, "", "get_parameter"], [194, 1, 1, "", "get_submodule"], [194, 1, 1, "", "half"], [194, 2, 1, "", "in_keys"], [194, 2, 1, "", "in_keys_inv"], [194, 1, 1, "", "init"], [194, 1, 1, "", "inv"], [194, 1, 1, "", "ipu"], [194, 1, 1, "", "load_state_dict"], [194, 2, 1, "", "missing_tolerance"], [194, 1, 1, "", "modules"], [194, 1, 1, "", "mtia"], [194, 1, 1, "", "named_buffers"], [194, 1, 1, "", "named_children"], [194, 1, 1, "", "named_modules"], [194, 1, 1, "", "named_parameters"], [194, 2, 1, "", "out_keys"], [194, 2, 1, "", "out_keys_inv"], [194, 1, 1, "", "parameters"], [194, 2, 1, "", "parent"], [194, 2, 1, "", "primers"], [194, 1, 1, "", "register_backward_hook"], [194, 1, 1, "", "register_buffer"], [194, 1, 1, "", "register_forward_hook"], [194, 1, 1, "", "register_forward_pre_hook"], [194, 1, 1, "", "register_full_backward_hook"], [194, 1, 1, "", "register_full_backward_pre_hook"], [194, 1, 1, "", "register_load_state_dict_post_hook"], [194, 1, 1, "", "register_load_state_dict_pre_hook"], [194, 1, 1, "", "register_module"], [194, 1, 1, "", "register_parameter"], [194, 1, 1, "", "register_state_dict_post_hook"], [194, 1, 1, "", "register_state_dict_pre_hook"], [194, 2, 1, "", "repeats"], [194, 1, 1, "", "requires_grad_"], [194, 1, 1, "", "reset_dataloader"], [194, 1, 1, "", "reset_parent"], [194, 1, 1, "", "set_container"], [194, 1, 1, "", "set_extra_state"], [194, 1, 1, "", "set_missing_tolerance"], [194, 1, 1, "", "set_submodule"], [194, 1, 1, "", "share_memory"], [194, 2, 1, "", "stack_method"], [194, 1, 1, "", "state_dict"], [194, 1, 1, "", "to"], [194, 1, 1, "", "to_empty"], [194, 1, 1, "", "train"], [194, 1, 1, "", "transform_action_spec"], [194, 1, 1, "", "transform_done_spec"], [194, 1, 1, "", "transform_env_batch_size"], [194, 1, 1, "", "transform_env_device"], [194, 1, 1, "", "transform_input_spec"], [194, 1, 1, "", "transform_observation_spec"], [194, 1, 1, "", "transform_output_spec"], [194, 1, 1, "", "transform_reward_spec"], [194, 1, 1, "", "transform_state_spec"], [194, 1, 1, "", "type"], [194, 1, 1, "", "xpu"], [194, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.RetrieveKL": [[195, 1, 1, "", "add_module"], [195, 1, 1, "", "append"], [195, 1, 1, "", "apply"], [195, 1, 1, "", "bfloat16"], [195, 1, 1, "", "buffers"], [195, 1, 1, "", "children"], [195, 1, 1, "", "close"], [195, 2, 1, "", "collector"], [195, 1, 1, "", "compile"], [195, 2, 1, "", "container"], [195, 1, 1, "", "cpu"], [195, 1, 1, "", "cuda"], [195, 1, 1, "", "double"], [195, 1, 1, "", "eval"], [195, 1, 1, "", "extra_repr"], [195, 1, 1, "", "float"], [195, 1, 1, "", "forward"], [195, 1, 1, "", "get_buffer"], [195, 1, 1, "", "get_extra_state"], [195, 1, 1, "", "get_parameter"], [195, 1, 1, "", "get_submodule"], [195, 1, 1, "", "half"], [195, 1, 1, "", "init"], [195, 1, 1, "", "insert"], [195, 1, 1, "", "inv"], [195, 1, 1, "", "ipu"], [195, 1, 1, "", "load_state_dict"], [195, 1, 1, "", "modules"], [195, 1, 1, "", "mtia"], [195, 1, 1, "", "named_buffers"], [195, 1, 1, "", "named_children"], [195, 1, 1, "", "named_modules"], [195, 1, 1, "", "named_parameters"], [195, 1, 1, "", "parameters"], [195, 2, 1, "", "parent"], [195, 1, 1, "", "pop"], [195, 1, 1, "", "register_backward_hook"], [195, 1, 1, "", "register_buffer"], [195, 1, 1, "", "register_forward_hook"], [195, 1, 1, "", "register_forward_pre_hook"], [195, 1, 1, "", "register_full_backward_hook"], [195, 1, 1, "", "register_full_backward_pre_hook"], [195, 1, 1, "", "register_load_state_dict_post_hook"], [195, 1, 1, "", "register_load_state_dict_pre_hook"], [195, 1, 1, "", "register_module"], [195, 1, 1, "", "register_parameter"], [195, 1, 1, "", "register_state_dict_post_hook"], [195, 1, 1, "", "register_state_dict_pre_hook"], [195, 1, 1, "", "requires_grad_"], [195, 1, 1, "", "set_extra_state"], [195, 1, 1, "", "set_submodule"], [195, 1, 1, "", "share_memory"], [195, 1, 1, "", "state_dict"], [195, 1, 1, "", "to"], [195, 1, 1, "", "to_empty"], [195, 1, 1, "", "train"], [195, 1, 1, "", "transform_action_spec"], [195, 1, 1, "", "transform_done_spec"], [195, 1, 1, "", "transform_env_batch_size"], [195, 1, 1, "", "transform_env_device"], [195, 1, 1, "", "transform_input_spec"], [195, 1, 1, "", "transform_observation_spec"], [195, 1, 1, "", "transform_output_spec"], [195, 1, 1, "", "transform_reward_spec"], [195, 1, 1, "", "transform_state_spec"], [195, 1, 1, "", "type"], [195, 1, 1, "", "xpu"], [195, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.RetrieveLogProb": [[196, 1, 1, "", "add_module"], [196, 1, 1, "", "apply"], [196, 1, 1, "", "bfloat16"], [196, 1, 1, "", "buffers"], [196, 1, 1, "", "children"], [196, 1, 1, "", "close"], [196, 2, 1, "", "collector"], [196, 1, 1, "", "compile"], [196, 2, 1, "", "container"], [196, 1, 1, "", "cpu"], [196, 1, 1, "", "cuda"], [196, 1, 1, "", "double"], [196, 1, 1, "", "eval"], [196, 1, 1, "", "extra_repr"], [196, 1, 1, "", "float"], [196, 1, 1, "", "forward"], [196, 1, 1, "", "get_buffer"], [196, 1, 1, "", "get_extra_state"], [196, 1, 1, "", "get_parameter"], [196, 1, 1, "", "get_submodule"], [196, 1, 1, "", "half"], [196, 1, 1, "", "init"], [196, 1, 1, "", "inv"], [196, 1, 1, "", "ipu"], [196, 1, 1, "", "load_state_dict"], [196, 1, 1, "", "modules"], [196, 1, 1, "", "mtia"], [196, 1, 1, "", "named_buffers"], [196, 1, 1, "", "named_children"], [196, 1, 1, "", "named_modules"], [196, 1, 1, "", "named_parameters"], [196, 1, 1, "", "parameters"], [196, 2, 1, "", "parent"], [196, 1, 1, "", "register_backward_hook"], [196, 1, 1, "", "register_buffer"], [196, 1, 1, "", "register_forward_hook"], [196, 1, 1, "", "register_forward_pre_hook"], [196, 1, 1, "", "register_full_backward_hook"], [196, 1, 1, "", "register_full_backward_pre_hook"], [196, 1, 1, "", "register_load_state_dict_post_hook"], [196, 1, 1, "", "register_load_state_dict_pre_hook"], [196, 1, 1, "", "register_module"], [196, 1, 1, "", "register_parameter"], [196, 1, 1, "", "register_state_dict_post_hook"], [196, 1, 1, "", "register_state_dict_pre_hook"], [196, 1, 1, "", "requires_grad_"], [196, 1, 1, "", "set_extra_state"], [196, 1, 1, "", "set_submodule"], [196, 1, 1, "", "share_memory"], [196, 1, 1, "", "state_dict"], [196, 1, 1, "", "to"], [196, 1, 1, "", "to_empty"], [196, 1, 1, "", "train"], [196, 1, 1, "", "transform_action_spec"], [196, 1, 1, "", "transform_done_spec"], [196, 1, 1, "", "transform_env_batch_size"], [196, 1, 1, "", "transform_env_device"], [196, 1, 1, "", "transform_input_spec"], [196, 1, 1, "", "transform_observation_spec"], [196, 1, 1, "", "transform_output_spec"], [196, 1, 1, "", "transform_reward_spec"], [196, 1, 1, "", "transform_state_spec"], [196, 1, 1, "", "type"], [196, 1, 1, "", "xpu"], [196, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.SimpleToolTransform": [[197, 1, 1, "", "add_module"], [197, 1, 1, "", "apply"], [197, 1, 1, "", "bfloat16"], [197, 1, 1, "", "buffers"], [197, 1, 1, "", "children"], [197, 1, 1, "", "close"], [197, 2, 1, "", "collector"], [197, 1, 1, "", "compile"], [197, 2, 1, "", "container"], [197, 1, 1, "", "cpu"], [197, 1, 1, "", "cuda"], [197, 1, 1, "", "double"], [197, 1, 1, "", "eval"], [197, 1, 1, "", "extra_repr"], [197, 1, 1, "", "float"], [197, 1, 1, "", "forward"], [197, 1, 1, "", "get_buffer"], [197, 1, 1, "", "get_extra_state"], [197, 1, 1, "", "get_parameter"], [197, 1, 1, "", "get_submodule"], [197, 1, 1, "", "half"], [197, 1, 1, "", "init"], [197, 1, 1, "", "inv"], [197, 1, 1, "", "ipu"], [197, 1, 1, "", "load_state_dict"], [197, 1, 1, "", "modules"], [197, 1, 1, "", "mtia"], [197, 1, 1, "", "named_buffers"], [197, 1, 1, "", "named_children"], [197, 1, 1, "", "named_modules"], [197, 1, 1, "", "named_parameters"], [197, 1, 1, "", "parameters"], [197, 2, 1, "", "parent"], [197, 1, 1, "", "register_backward_hook"], [197, 1, 1, "", "register_buffer"], [197, 1, 1, "", "register_forward_hook"], [197, 1, 1, "", "register_forward_pre_hook"], [197, 1, 1, "", "register_full_backward_hook"], [197, 1, 1, "", "register_full_backward_pre_hook"], [197, 1, 1, "", "register_load_state_dict_post_hook"], [197, 1, 1, "", "register_load_state_dict_pre_hook"], [197, 1, 1, "", "register_module"], [197, 1, 1, "", "register_parameter"], [197, 1, 1, "", "register_state_dict_post_hook"], [197, 1, 1, "", "register_state_dict_pre_hook"], [197, 1, 1, "", "requires_grad_"], [197, 1, 1, "", "set_extra_state"], [197, 1, 1, "", "set_submodule"], [197, 1, 1, "", "share_memory"], [197, 1, 1, "", "state_dict"], [197, 1, 1, "", "to"], [197, 1, 1, "", "to_empty"], [197, 1, 1, "", "train"], [197, 1, 1, "", "transform_action_spec"], [197, 1, 1, "", "transform_done_spec"], [197, 1, 1, "", "transform_env_batch_size"], [197, 1, 1, "", "transform_env_device"], [197, 1, 1, "", "transform_input_spec"], [197, 1, 1, "", "transform_observation_spec"], [197, 1, 1, "", "transform_output_spec"], [197, 1, 1, "", "transform_reward_spec"], [197, 1, 1, "", "transform_state_spec"], [197, 1, 1, "", "type"], [197, 1, 1, "", "xpu"], [197, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.TemplateTransform": [[198, 1, 1, "", "add_module"], [198, 1, 1, "", "apply"], [198, 1, 1, "", "bfloat16"], [198, 1, 1, "", "buffers"], [198, 1, 1, "", "children"], [198, 1, 1, "", "close"], [198, 2, 1, "", "collector"], [198, 1, 1, "", "compile"], [198, 2, 1, "", "container"], [198, 1, 1, "", "cpu"], [198, 1, 1, "", "cuda"], [198, 1, 1, "", "double"], [198, 1, 1, "", "eval"], [198, 1, 1, "", "extra_repr"], [198, 1, 1, "", "float"], [198, 1, 1, "", "forward"], [198, 1, 1, "", "get_buffer"], [198, 1, 1, "", "get_extra_state"], [198, 1, 1, "", "get_parameter"], [198, 1, 1, "", "get_submodule"], [198, 1, 1, "", "half"], [198, 1, 1, "", "init"], [198, 1, 1, "", "inv"], [198, 1, 1, "", "ipu"], [198, 1, 1, "", "load_state_dict"], [198, 1, 1, "", "modules"], [198, 1, 1, "", "mtia"], [198, 1, 1, "", "named_buffers"], [198, 1, 1, "", "named_children"], [198, 1, 1, "", "named_modules"], [198, 1, 1, "", "named_parameters"], [198, 1, 1, "", "parameters"], [198, 2, 1, "", "parent"], [198, 1, 1, "", "register_backward_hook"], [198, 1, 1, "", "register_buffer"], [198, 1, 1, "", "register_forward_hook"], [198, 1, 1, "", "register_forward_pre_hook"], [198, 1, 1, "", "register_full_backward_hook"], [198, 1, 1, "", "register_full_backward_pre_hook"], [198, 1, 1, "", "register_load_state_dict_post_hook"], [198, 1, 1, "", "register_load_state_dict_pre_hook"], [198, 1, 1, "", "register_module"], [198, 1, 1, "", "register_parameter"], [198, 1, 1, "", "register_state_dict_post_hook"], [198, 1, 1, "", "register_state_dict_pre_hook"], [198, 1, 1, "", "requires_grad_"], [198, 1, 1, "", "set_extra_state"], [198, 1, 1, "", "set_submodule"], [198, 1, 1, "", "share_memory"], [198, 1, 1, "", "state_dict"], [198, 1, 1, "", "to"], [198, 1, 1, "", "to_empty"], [198, 1, 1, "", "train"], [198, 1, 1, "", "transform_action_spec"], [198, 1, 1, "", "transform_done_spec"], [198, 1, 1, "", "transform_env_batch_size"], [198, 1, 1, "", "transform_env_device"], [198, 1, 1, "", "transform_input_spec"], [198, 1, 1, "", "transform_observation_spec"], [198, 1, 1, "", "transform_output_spec"], [198, 1, 1, "", "transform_reward_spec"], [198, 1, 1, "", "transform_state_spec"], [198, 1, 1, "", "type"], [198, 1, 1, "", "xpu"], [198, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.Tokenizer": [[199, 1, 1, "", "add_module"], [199, 1, 1, "", "apply"], [199, 1, 1, "", "bfloat16"], [199, 1, 1, "", "buffers"], [199, 1, 1, "", "children"], [199, 1, 1, "", "close"], [199, 2, 1, "", "collector"], [199, 1, 1, "", "compile"], [199, 2, 1, "", "container"], [199, 1, 1, "", "cpu"], [199, 1, 1, "", "cuda"], [199, 1, 1, "", "double"], [199, 1, 1, "", "eval"], [199, 1, 1, "", "extra_repr"], [199, 1, 1, "", "float"], [199, 1, 1, "", "forward"], [199, 1, 1, "", "get_buffer"], [199, 1, 1, "", "get_extra_state"], [199, 1, 1, "", "get_parameter"], [199, 1, 1, "", "get_submodule"], [199, 1, 1, "", "half"], [199, 1, 1, "", "init"], [199, 1, 1, "", "inv"], [199, 1, 1, "", "ipu"], [199, 1, 1, "", "load_state_dict"], [199, 1, 1, "", "modules"], [199, 1, 1, "", "mtia"], [199, 1, 1, "", "named_buffers"], [199, 1, 1, "", "named_children"], [199, 1, 1, "", "named_modules"], [199, 1, 1, "", "named_parameters"], [199, 1, 1, "", "parameters"], [199, 2, 1, "", "parent"], [199, 1, 1, "", "register_backward_hook"], [199, 1, 1, "", "register_buffer"], [199, 1, 1, "", "register_forward_hook"], [199, 1, 1, "", "register_forward_pre_hook"], [199, 1, 1, "", "register_full_backward_hook"], [199, 1, 1, "", "register_full_backward_pre_hook"], [199, 1, 1, "", "register_load_state_dict_post_hook"], [199, 1, 1, "", "register_load_state_dict_pre_hook"], [199, 1, 1, "", "register_module"], [199, 1, 1, "", "register_parameter"], [199, 1, 1, "", "register_state_dict_post_hook"], [199, 1, 1, "", "register_state_dict_pre_hook"], [199, 1, 1, "", "requires_grad_"], [199, 1, 1, "", "set_extra_state"], [199, 1, 1, "", "set_submodule"], [199, 1, 1, "", "share_memory"], [199, 1, 1, "", "state_dict"], [199, 1, 1, "", "to"], [199, 1, 1, "", "to_empty"], [199, 1, 1, "", "train"], [199, 1, 1, "", "transform_action_spec"], [199, 1, 1, "", "transform_done_spec"], [199, 1, 1, "", "transform_env_batch_size"], [199, 1, 1, "", "transform_env_device"], [199, 1, 1, "", "transform_input_spec"], [199, 1, 1, "", "transform_observation_spec"], [199, 1, 1, "", "transform_output_spec"], [199, 1, 1, "", "transform_reward_spec"], [199, 1, 1, "", "transform_state_spec"], [199, 1, 1, "", "type"], [199, 1, 1, "", "xpu"], [199, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.ToolRegistry": [[201, 1, 1, "", "get"], [201, 1, 1, "", "register"]], "torchrl.envs.model_based.dreamer": [[207, 3, 1, "", "DreamerDecoder"], [208, 3, 1, "", "DreamerEnv"]], "torchrl.envs.transforms": [[214, 0, 1, "", "ActionDiscretizer"], [215, 0, 1, "", "ActionMask"], [216, 0, 1, "", "AutoResetEnv"], [217, 0, 1, "", "AutoResetTransform"], [218, 0, 1, "", "BatchSizeTransform"], [219, 0, 1, "", "BinarizeReward"], [220, 0, 1, "", "BurnInTransform"], [221, 0, 1, "", "CatFrames"], [222, 0, 1, "", "CatTensors"], [223, 0, 1, "", "CenterCrop"], [224, 0, 1, "", "ClipTransform"], [225, 0, 1, "", "Compose"], [226, 0, 1, "", "ConditionalPolicySwitch"], [227, 0, 1, "", "ConditionalSkip"], [228, 0, 1, "", "Crop"], [229, 0, 1, "", "DTypeCastTransform"], [230, 0, 1, "", "DeviceCastTransform"], [231, 0, 1, "", "DiscreteActionProjection"], [232, 0, 1, "", "DoubleToFloat"], [233, 0, 1, "", "EndOfLifeTransform"], [234, 0, 1, "", "ExcludeTransform"], [235, 0, 1, "", "FiniteTensorDictCheck"], [236, 0, 1, "", "FlattenObservation"], [237, 0, 1, "", "FrameSkipTransform"], [238, 0, 1, "", "GrayScale"], [239, 0, 1, "", "Hash"], [240, 0, 1, "", "InitTracker"], [241, 0, 1, "", "KLRewardTransform"], [242, 0, 1, "", "LineariseRewards"], [243, 0, 1, "", "ModuleTransform"], [244, 0, 1, "", "MultiAction"], [245, 0, 1, "", "NoopResetEnv"], [246, 0, 1, "", "ObservationNorm"], [247, 0, 1, "", "ObservationTransform"], [248, 0, 1, "", "PermuteTransform"], [249, 0, 1, "", "PinMemoryTransform"], [250, 0, 1, "", "R3MTransform"], [251, 0, 1, "", "RandomCropTensorDict"], [252, 0, 1, "", "RemoveEmptySpecs"], [253, 0, 1, "", "RenameTransform"], [254, 0, 1, "", "Resize"], [255, 0, 1, "", "Reward2GoTransform"], [256, 0, 1, "", "RewardClipping"], [257, 0, 1, "", "RewardScaling"], [258, 0, 1, "", "RewardSum"], [259, 0, 1, "", "SelectTransform"], [260, 0, 1, "", "SignTransform"], [261, 0, 1, "", "SqueezeTransform"], [262, 0, 1, "", "Stack"], [263, 0, 1, "", "StepCounter"], [264, 0, 1, "", "TargetReturn"], [265, 0, 1, "", "TensorDictPrimer"], [266, 0, 1, "", "TimeMaxPool"], [267, 0, 1, "", "Timer"], [268, 0, 1, "", "ToTensorImage"], [269, 0, 1, "", "Tokenizer"], [270, 0, 1, "", "TrajCounter"], [271, 0, 1, "", "Transform"], [272, 0, 1, "", "TransformedEnv"], [273, 0, 1, "", "UnaryTransform"], [274, 0, 1, "", "UnsqueezeTransform"], [275, 0, 1, "", "VC1Transform"], [276, 0, 1, "", "VIPRewardTransform"], [277, 0, 1, "", "VIPTransform"], [278, 0, 1, "", "VecGymEnvTransform"], [279, 0, 1, "", "VecNorm"], [280, 0, 1, "", "VecNormV2"], [281, 0, 1, "", "gSDENoise"]], "torchrl.envs.transforms.ActionDiscretizer": [[214, 0, 1, "", "SamplingStrategy"], [214, 1, 1, "", "inv"], [214, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.ActionMask": [[215, 1, 1, "", "forward"]], "torchrl.envs.transforms.AutoResetEnv": [[216, 1, 1, "", "insert_transform"]], "torchrl.envs.transforms.AutoResetTransform": [[217, 1, 1, "", "forward"]], "torchrl.envs.transforms.BatchSizeTransform": [[218, 1, 1, "", "forward"], [218, 1, 1, "", "transform_env_batch_size"], [218, 1, 1, "", "transform_input_spec"], [218, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.BinarizeReward": [[219, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.BurnInTransform": [[220, 1, 1, "", "forward"]], "torchrl.envs.transforms.CatFrames": [[221, 1, 1, "", "forward"], [221, 1, 1, "", "make_rb_transform_and_sampler"], [221, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CatTensors": [[222, 1, 1, "", "forward"], [222, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CenterCrop": [[223, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ClipTransform": [[224, 1, 1, "", "transform_observation_spec"], [224, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.Compose": [[225, 1, 1, "", "append"], [225, 1, 1, "", "close"], [225, 1, 1, "", "forward"], [225, 1, 1, "", "init"], [225, 1, 1, "", "insert"], [225, 1, 1, "", "pop"], [225, 1, 1, "", "to"], [225, 1, 1, "", "transform_action_spec"], [225, 1, 1, "", "transform_env_batch_size"], [225, 1, 1, "", "transform_env_device"], [225, 1, 1, "", "transform_input_spec"], [225, 1, 1, "", "transform_observation_spec"], [225, 1, 1, "", "transform_output_spec"], [225, 1, 1, "", "transform_reward_spec"], [225, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.ConditionalPolicySwitch": [[226, 1, 1, "", "forward"]], "torchrl.envs.transforms.ConditionalSkip": [[227, 1, 1, "", "forward"]], "torchrl.envs.transforms.Crop": [[228, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.DTypeCastTransform": [[229, 1, 1, "", "forward"], [229, 1, 1, "", "transform_input_spec"], [229, 1, 1, "", "transform_observation_spec"], [229, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.DeviceCastTransform": [[230, 1, 1, "", "forward"], [230, 1, 1, "", "transform_action_spec"], [230, 1, 1, "", "transform_done_spec"], [230, 1, 1, "", "transform_env_device"], [230, 1, 1, "", "transform_input_spec"], [230, 1, 1, "", "transform_observation_spec"], [230, 1, 1, "", "transform_output_spec"], [230, 1, 1, "", "transform_reward_spec"], [230, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.DiscreteActionProjection": [[231, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.EndOfLifeTransform": [[233, 1, 1, "", "forward"], [233, 1, 1, "", "register_keys"], [233, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ExcludeTransform": [[234, 1, 1, "", "forward"], [234, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.FiniteTensorDictCheck": [[235, 1, 1, "", "forward"]], "torchrl.envs.transforms.FlattenObservation": [[236, 1, 1, "", "forward"], [236, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.FrameSkipTransform": [[237, 1, 1, "", "forward"]], "torchrl.envs.transforms.GrayScale": [[238, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Hash": [[239, 1, 1, "", "get_input_from_hash"], [239, 1, 1, "", "reproducible_hash"], [239, 1, 1, "", "state_dict"]], "torchrl.envs.transforms.InitTracker": [[240, 1, 1, "", "forward"], [240, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.KLRewardTransform": [[241, 1, 1, "", "forward"], [241, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.LineariseRewards": [[242, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.ModuleTransform": [[243, 1, 1, "", "forward"], [243, 1, 1, "", "transform_action_spec"], [243, 1, 1, "", "transform_done_spec"], [243, 1, 1, "", "transform_observation_spec"], [243, 1, 1, "", "transform_reward_spec"], [243, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.MultiAction": [[244, 1, 1, "", "transform_input_spec"], [244, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.ObservationNorm": [[246, 1, 1, "", "init_stats"], [246, 1, 1, "", "transform_action_spec"], [246, 1, 1, "", "transform_observation_spec"], [246, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.PermuteTransform": [[248, 1, 1, "", "transform_input_spec"], [248, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.PinMemoryTransform": [[249, 1, 1, "", "forward"]], "torchrl.envs.transforms.R3MTransform": [[250, 1, 1, "", "to"]], "torchrl.envs.transforms.RandomCropTensorDict": [[251, 1, 1, "", "forward"]], "torchrl.envs.transforms.RemoveEmptySpecs": [[252, 1, 1, "", "forward"], [252, 1, 1, "", "transform_input_spec"], [252, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.RenameTransform": [[253, 1, 1, "", "forward"], [253, 1, 1, "", "transform_input_spec"], [253, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.Resize": [[254, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Reward2GoTransform": [[255, 1, 1, "", "forward"]], "torchrl.envs.transforms.RewardClipping": [[256, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardScaling": [[257, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardSum": [[258, 1, 1, "", "forward"], [258, 1, 1, "", "transform_input_spec"], [258, 1, 1, "", "transform_observation_spec"], [258, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.SelectTransform": [[259, 1, 1, "", "forward"], [259, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.SignTransform": [[260, 1, 1, "", "transform_observation_spec"], [260, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.Stack": [[262, 1, 1, "", "forward"], [262, 1, 1, "", "transform_done_spec"], [262, 1, 1, "", "transform_input_spec"], [262, 1, 1, "", "transform_observation_spec"], [262, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.StepCounter": [[263, 1, 1, "", "forward"], [263, 1, 1, "", "transform_input_spec"], [263, 1, 1, "", "transform_observation_spec"], [263, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.TargetReturn": [[264, 1, 1, "", "forward"], [264, 1, 1, "", "transform_input_spec"], [264, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TensorDictPrimer": [[265, 1, 1, "", "forward"], [265, 1, 1, "", "to"], [265, 1, 1, "", "transform_input_spec"], [265, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TimeMaxPool": [[266, 1, 1, "", "forward"], [266, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Timer": [[267, 1, 1, "", "forward"], [267, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ToTensorImage": [[268, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Tokenizer": [[269, 1, 1, "", "forward"], [269, 1, 1, "", "transform_done_spec"], [269, 1, 1, "", "transform_input_spec"], [269, 1, 1, "", "transform_observation_spec"], [269, 1, 1, "", "transform_output_spec"], [269, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.TrajCounter": [[270, 1, 1, "", "forward"], [270, 1, 1, "", "load_state_dict"], [270, 1, 1, "", "state_dict"], [270, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Transform": [[271, 1, 1, "", "clone"], [271, 1, 1, "", "close"], [271, 2, 1, "", "collector"], [271, 2, 1, "", "container"], [271, 1, 1, "", "forward"], [271, 1, 1, "", "init"], [271, 1, 1, "", "inv"], [271, 2, 1, "", "parent"], [271, 1, 1, "", "reset_parent"], [271, 1, 1, "", "set_container"], [271, 1, 1, "", "to"], [271, 1, 1, "", "transform_action_spec"], [271, 1, 1, "", "transform_done_spec"], [271, 1, 1, "", "transform_env_batch_size"], [271, 1, 1, "", "transform_env_device"], [271, 1, 1, "", "transform_input_spec"], [271, 1, 1, "", "transform_observation_spec"], [271, 1, 1, "", "transform_output_spec"], [271, 1, 1, "", "transform_reward_spec"], [271, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.TransformedEnv": [[272, 1, 1, "", "add_truncated_keys"], [272, 1, 1, "", "append_transform"], [272, 2, 1, "", "batch_locked"], [272, 2, 1, "", "batch_size"], [272, 1, 1, "", "empty_cache"], [272, 1, 1, "", "eval"], [272, 2, 1, "", "input_spec"], [272, 1, 1, "", "insert_transform"], [272, 1, 1, "", "load_state_dict"], [272, 2, 1, "", "output_spec"], [272, 1, 1, "", "rand_action"], [272, 1, 1, "", "set_missing_tolerance"], [272, 1, 1, "", "set_seed"], [272, 1, 1, "", "state_dict"], [272, 1, 1, "", "to"], [272, 1, 1, "", "train"]], "torchrl.envs.transforms.UnaryTransform": [[273, 1, 1, "", "transform_action_spec"], [273, 1, 1, "", "transform_done_spec"], [273, 1, 1, "", "transform_input_spec"], [273, 1, 1, "", "transform_observation_spec"], [273, 1, 1, "", "transform_output_spec"], [273, 1, 1, "", "transform_reward_spec"], [273, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.UnsqueezeTransform": [[274, 1, 1, "", "transform_action_spec"], [274, 1, 1, "", "transform_observation_spec"], [274, 1, 1, "", "transform_reward_spec"], [274, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.VC1Transform": [[275, 1, 1, "", "forward"], [275, 1, 1, "", "make_noload_model"], [275, 1, 1, "", "to"], [275, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VIPRewardTransform": [[276, 1, 1, "", "forward"], [276, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.VIPTransform": [[277, 1, 1, "", "to"]], "torchrl.envs.transforms.VecGymEnvTransform": [[278, 1, 1, "", "forward"], [278, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VecNorm": [[279, 1, 1, "", "build_td_for_shared_vecnorm"], [279, 1, 1, "", "forward"], [279, 1, 1, "", "freeze"], [279, 1, 1, "", "frozen_copy"], [279, 1, 1, "", "get_extra_state"], [279, 2, 1, "", "loc"], [279, 2, 1, "", "scale"], [279, 1, 1, "", "set_extra_state"], [279, 2, 1, "", "standard_normal"], [279, 1, 1, "", "to_observation_norm"], [279, 1, 1, "", "transform_observation_spec"], [279, 1, 1, "", "unfreeze"]], "torchrl.envs.transforms.VecNormV2": [[280, 1, 1, "", "clone"], [280, 1, 1, "id0", "freeze"], [280, 1, 1, "id1", "frozen_copy"], [280, 1, 1, "id2", "get_extra_state"], [280, 2, 1, "id3", "loc"], [280, 2, 1, "id4", "scale"], [280, 1, 1, "id5", "set_extra_state"], [280, 2, 1, "id6", "standard_normal"], [280, 1, 1, "", "to_observation_norm"], [280, 1, 1, "id7", "transform_observation_spec"], [280, 1, 1, "id8", "transform_output_spec"], [280, 1, 1, "id9", "transform_reward_spec"], [280, 1, 1, "id10", "unfreeze"]], "torchrl.implement_for": [[282, 1, 1, "", "get_class_that_defined_method"], [282, 1, 1, "", "import_module"], [282, 1, 1, "", "module_set"], [282, 1, 1, "", "reset"]], "torchrl.modules": [[283, 0, 1, "", "ActorCriticOperator"], [284, 0, 1, "", "ActorCriticWrapper"], [285, 0, 1, "", "ActorValueOperator"], [286, 0, 1, "", "AdditiveGaussianModule"], [287, 0, 1, "", "ConsistentDropoutModule"], [288, 0, 1, "", "ConvNet"], [289, 0, 1, "", "DTActor"], [290, 0, 1, "", "DdpgCnnActor"], [291, 0, 1, "", "DdpgCnnQNet"], [292, 0, 1, "", "DdpgMlpActor"], [293, 0, 1, "", "DdpgMlpQNet"], [294, 0, 1, "", "DecisionTransformer"], [295, 0, 1, "", "Delta"], [296, 0, 1, "", "DistributionalDQNnet"], [297, 0, 1, "", "DistributionalQValueActor"], [298, 0, 1, "", "DistributionalQValueModule"], [299, 0, 1, "", "DreamerActor"], [300, 0, 1, "", "DuelingCnnDQNet"], [301, 0, 1, "", "EGreedyModule"], [302, 0, 1, "", "GRUModule"], [303, 0, 1, "", "IndependentNormal"], [304, 0, 1, "", "LSTMModule"], [305, 0, 1, "", "MLP"], [306, 0, 1, "", "MaskedCategorical"], [307, 0, 1, "", "NormalParamExtractor"], [308, 0, 1, "", "ObsDecoder"], [309, 0, 1, "", "ObsEncoder"], [310, 0, 1, "", "OneHotCategorical"], [311, 0, 1, "", "OnlineDTActor"], [312, 0, 1, "", "OrnsteinUhlenbeckProcessModule"], [313, 0, 1, "", "QValueActor"], [314, 0, 1, "", "QValueModule"], [315, 0, 1, "", "RSSMPosterior"], [316, 0, 1, "", "RSSMPrior"], [317, 0, 1, "", "RSSMRollout"], [318, 0, 1, "", "ReparamGradientStrategy"], [319, 0, 1, "", "TanhDelta"], [320, 0, 1, "", "TanhNormal"], [321, 0, 1, "", "TruncatedNormal"], [322, 0, 1, "", "ValueOperator"], [323, 0, 1, "", "WorldModelWrapper"]], "torchrl.modules.ActorCriticOperator": [[283, 1, 1, "", "get_critic_operator"], [283, 1, 1, "", "get_policy_head"], [283, 1, 1, "", "get_value_head"], [283, 1, 1, "", "get_value_operator"]], "torchrl.modules.ActorCriticWrapper": [[284, 1, 1, "", "get_policy_head"], [284, 1, 1, "", "get_policy_operator"], [284, 1, 1, "", "get_value_head"], [284, 1, 1, "", "get_value_operator"]], "torchrl.modules.ActorValueOperator": [[285, 1, 1, "", "get_policy_head"], [285, 1, 1, "", "get_policy_operator"], [285, 1, 1, "", "get_value_head"], [285, 1, 1, "", "get_value_operator"]], "torchrl.modules.AdditiveGaussianModule": [[286, 1, 1, "", "forward"], [286, 1, 1, "", "step"]], "torchrl.modules.ConsistentDropoutModule": [[287, 1, 1, "", "forward"], [287, 1, 1, "", "make_tensordict_primer"]], "torchrl.modules.ConvNet": [[288, 1, 1, "", "default_atari_dqn"], [288, 1, 1, "", "forward"]], "torchrl.modules.DTActor": [[289, 1, 1, "", "default_config"], [289, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnActor": [[290, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnQNet": [[291, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpActor": [[292, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpQNet": [[293, 1, 1, "", "forward"]], "torchrl.modules.DecisionTransformer": [[294, 0, 1, "", "DTConfig"], [294, 1, 1, "", "forward"]], "torchrl.modules.Delta": [[295, 1, 1, "", "expand"], [295, 1, 1, "", "log_prob"], [295, 2, 1, "", "mean"], [295, 2, 1, "", "mode"], [295, 1, 1, "", "rsample"], [295, 1, 1, "", "sample"]], "torchrl.modules.DistributionalDQNnet": [[296, 1, 1, "", "forward"]], "torchrl.modules.DistributionalQValueModule": [[298, 1, 1, "", "forward"]], "torchrl.modules.DreamerActor": [[299, 1, 1, "", "forward"]], "torchrl.modules.DuelingCnnDQNet": [[300, 1, 1, "", "forward"]], "torchrl.modules.EGreedyModule": [[301, 1, 1, "", "forward"], [301, 1, 1, "", "step"]], "torchrl.modules.GRUModule": [[302, 1, 1, "", "forward"], [302, 1, 1, "", "make_cudnn_based"], [302, 1, 1, "", "make_python_based"], [302, 1, 1, "id0", "make_tensordict_primer"], [302, 1, 1, "", "set_recurrent_mode"]], "torchrl.modules.IndependentNormal": [[303, 2, 1, "", "mode"]], "torchrl.modules.LSTMModule": [[304, 1, 1, "", "forward"], [304, 1, 1, "", "make_cudnn_based"], [304, 1, 1, "", "make_python_based"], [304, 1, 1, "id0", "make_tensordict_primer"], [304, 1, 1, "", "set_recurrent_mode"]], "torchrl.modules.MLP": [[305, 1, 1, "", "forward"]], "torchrl.modules.MaskedCategorical": [[306, 1, 1, "", "entropy"], [306, 1, 1, "", "log_prob"], [306, 2, 1, "", "padding_value"], [306, 1, 1, "", "sample"]], "torchrl.modules.NormalParamExtractor": [[307, 1, 1, "", "forward"]], "torchrl.modules.ObsDecoder": [[308, 1, 1, "", "forward"]], "torchrl.modules.ObsEncoder": [[309, 1, 1, "", "forward"]], "torchrl.modules.OneHotCategorical": [[310, 1, 1, "", "entropy"], [310, 1, 1, "", "log_prob"], [310, 2, 1, "", "mode"], [310, 1, 1, "", "rsample"], [310, 1, 1, "", "sample"]], "torchrl.modules.OnlineDTActor": [[311, 1, 1, "", "default_config"], [311, 1, 1, "", "forward"]], "torchrl.modules.OrnsteinUhlenbeckProcessModule": [[312, 1, 1, "", "forward"], [312, 1, 1, "", "step"]], "torchrl.modules.QValueModule": [[314, 1, 1, "", "forward"]], "torchrl.modules.RSSMPosterior": [[315, 1, 1, "", "forward"]], "torchrl.modules.RSSMPrior": [[316, 1, 1, "", "forward"]], "torchrl.modules.RSSMRollout": [[317, 1, 1, "", "forward"]], "torchrl.modules.TanhDelta": [[319, 2, 1, "", "mean"], [319, 2, 1, "", "mode"]], "torchrl.modules.TanhNormal": [[320, 1, 1, "", "get_mode"], [320, 2, 1, "", "mean"], [320, 2, 1, "", "mode"], [320, 2, 1, "", "support"]], "torchrl.modules.TruncatedNormal": [[321, 1, 1, "", "log_prob"], [321, 2, 1, "", "mode"]], "torchrl.modules.WorldModelWrapper": [[323, 1, 1, "", "get_reward_operator"], [323, 1, 1, "", "get_transition_model_operator"]], "torchrl.modules.llm": [[324, 0, 1, "", "AsyncVLLM"], [325, 0, 1, "", "ChatHistory"], [326, 0, 1, "", "LLMWrapperBase"], [327, 0, 1, "", "LogProbs"], [328, 0, 1, "", "Masks"], [329, 0, 1, "", "RemoteTransformersWrapper"], [330, 0, 1, "", "Text"], [331, 0, 1, "", "Tokens"], [332, 0, 1, "", "TransformersWrapper"], [333, 0, 1, "", "make_async_vllm_engine"], [334, 0, 1, "", "make_vllm_worker"], [335, 0, 1, "", "stateless_init_process_group"], [336, 0, 1, "", "stateless_init_process_group_async"], [337, 0, 1, "", "vLLMWrapper"]], "torchrl.modules.llm.AsyncVLLM": [[324, 1, 1, "", "collective_rpc"], [324, 1, 1, "", "create_load_balancer"], [324, 1, 1, "", "from_pretrained"], [324, 1, 1, "", "generate"], [324, 1, 1, "", "get_cache_usage"], [324, 1, 1, "", "get_master_address"], [324, 1, 1, "", "get_master_port"], [324, 1, 1, "", "get_model_metadata"], [324, 1, 1, "", "get_num_unfinished_requests"], [324, 1, 1, "", "get_random_actor_index"], [324, 1, 1, "", "get_tp_size"], [324, 1, 1, "", "init_weight_update_group"], [324, 1, 1, "", "launch"], [324, 1, 1, "", "shutdown"], [324, 1, 1, "", "update_weights"]], "torchrl.modules.llm.ChatHistory": [[325, 1, 1, "", "cat"], [325, 1, 1, "", "default_spec"], [325, 2, 1, "", "device"], [325, 1, 1, "", "dumps"], [325, 1, 1, "", "fields"], [325, 1, 1, "", "from_any"], [325, 1, 1, "", "from_dataclass"], [325, 1, 1, "", "from_h5"], [325, 1, 1, "", "from_modules"], [325, 1, 1, "", "from_namedtuple"], [325, 1, 1, "", "from_pytree"], [325, 1, 1, "", "from_remote_init"], [325, 1, 1, "", "from_struct_array"], [325, 1, 1, "", "from_tensordict"], [325, 1, 1, "", "from_tuple"], [325, 1, 1, "", "fromkeys"], [325, 1, 1, "", "get"], [325, 1, 1, "", "lazy_stack"], [325, 1, 1, "", "load"], [325, 1, 1, "", "load_"], [325, 1, 1, "", "load_memmap"], [325, 1, 1, "", "load_state_dict"], [325, 1, 1, "", "maybe_dense_stack"], [325, 1, 1, "", "memmap"], [325, 1, 1, "", "memmap_"], [325, 1, 1, "", "memmap_like"], [325, 1, 1, "", "memmap_refresh_"], [325, 1, 1, "", "save"], [325, 1, 1, "", "set"], [325, 1, 1, "", "stack"], [325, 1, 1, "", "state_dict"], [325, 1, 1, "", "to_tensordict"], [325, 1, 1, "", "to_text"], [325, 1, 1, "", "to_tokens"], [325, 1, 1, "", "unbind"]], "torchrl.modules.llm.LLMWrapperBase": [[326, 1, 1, "", "add_module"], [326, 1, 1, "", "apply"], [326, 2, 1, "", "batching"], [326, 1, 1, "", "bfloat16"], [326, 1, 1, "", "buffers"], [326, 1, 1, "", "children"], [326, 1, 1, "", "cleanup_batching"], [326, 2, 1, "", "collector"], [326, 1, 1, "", "compile"], [326, 1, 1, "", "cpu"], [326, 1, 1, "", "cuda"], [326, 1, 1, "", "double"], [326, 1, 1, "", "eval"], [326, 1, 1, "", "extra_repr"], [326, 1, 1, "", "float"], [326, 1, 1, "", "forward"], [326, 1, 1, "", "get_batching_state"], [326, 1, 1, "", "get_buffer"], [326, 1, 1, "", "get_dist"], [326, 1, 1, "", "get_extra_state"], [326, 1, 1, "", "get_new_version"], [326, 1, 1, "", "get_parameter"], [326, 1, 1, "", "get_submodule"], [326, 1, 1, "", "half"], [326, 1, 1, "", "ipu"], [326, 1, 1, "", "is_tdmodule_compatible"], [326, 1, 1, "", "load_state_dict"], [326, 1, 1, "", "modules"], [326, 1, 1, "", "mtia"], [326, 1, 1, "", "named_buffers"], [326, 1, 1, "", "named_children"], [326, 1, 1, "", "named_modules"], [326, 1, 1, "", "named_parameters"], [326, 1, 1, "", "parameters"], [326, 1, 1, "", "register_backward_hook"], [326, 1, 1, "", "register_buffer"], [326, 1, 1, "", "register_collector"], [326, 1, 1, "", "register_forward_hook"], [326, 1, 1, "", "register_forward_pre_hook"], [326, 1, 1, "", "register_full_backward_hook"], [326, 1, 1, "", "register_full_backward_pre_hook"], [326, 1, 1, "", "register_load_state_dict_post_hook"], [326, 1, 1, "", "register_load_state_dict_pre_hook"], [326, 1, 1, "", "register_module"], [326, 1, 1, "", "register_parameter"], [326, 1, 1, "", "register_state_dict_post_hook"], [326, 1, 1, "", "register_state_dict_pre_hook"], [326, 1, 1, "", "requires_grad_"], [326, 1, 1, "", "reset_out_keys"], [326, 1, 1, "", "reset_parameters_recursive"], [326, 1, 1, "", "select_out_keys"], [326, 1, 1, "", "set_extra_state"], [326, 1, 1, "", "set_submodule"], [326, 1, 1, "", "share_memory"], [326, 1, 1, "", "state_dict"], [326, 1, 1, "", "to"], [326, 1, 1, "", "to_empty"], [326, 1, 1, "", "train"], [326, 1, 1, "", "type"], [326, 1, 1, "", "xpu"], [326, 1, 1, "", "zero_grad"]], "torchrl.modules.llm.LogProbs": [[327, 1, 1, "", "cat"], [327, 1, 1, "", "default_spec"], [327, 2, 1, "", "device"], [327, 1, 1, "", "dumps"], [327, 1, 1, "", "fields"], [327, 1, 1, "", "from_any"], [327, 1, 1, "", "from_dataclass"], [327, 1, 1, "", "from_h5"], [327, 1, 1, "", "from_modules"], [327, 1, 1, "", "from_namedtuple"], [327, 1, 1, "", "from_pytree"], [327, 1, 1, "", "from_remote_init"], [327, 1, 1, "", "from_struct_array"], [327, 1, 1, "", "from_tensordict"], [327, 1, 1, "", "from_tuple"], [327, 1, 1, "", "fromkeys"], [327, 1, 1, "", "get"], [327, 1, 1, "", "lazy_stack"], [327, 1, 1, "", "load"], [327, 1, 1, "", "load_"], [327, 1, 1, "", "load_memmap"], [327, 1, 1, "", "load_state_dict"], [327, 1, 1, "", "maybe_dense_stack"], [327, 1, 1, "", "memmap"], [327, 1, 1, "", "memmap_"], [327, 1, 1, "", "memmap_like"], [327, 1, 1, "", "memmap_refresh_"], [327, 1, 1, "", "save"], [327, 1, 1, "", "set"], [327, 1, 1, "", "stack"], [327, 1, 1, "", "state_dict"], [327, 1, 1, "", "to_tensordict"], [327, 1, 1, "", "unbind"]], "torchrl.modules.llm.Masks": [[328, 1, 1, "", "cat"], [328, 1, 1, "", "default_spec"], [328, 2, 1, "", "device"], [328, 1, 1, "", "dumps"], [328, 1, 1, "", "fields"], [328, 1, 1, "", "from_any"], [328, 1, 1, "", "from_dataclass"], [328, 1, 1, "", "from_h5"], [328, 1, 1, "", "from_modules"], [328, 1, 1, "", "from_namedtuple"], [328, 1, 1, "", "from_pytree"], [328, 1, 1, "", "from_remote_init"], [328, 1, 1, "", "from_struct_array"], [328, 1, 1, "", "from_tensordict"], [328, 1, 1, "", "from_tuple"], [328, 1, 1, "", "fromkeys"], [328, 1, 1, "", "get"], [328, 1, 1, "", "lazy_stack"], [328, 1, 1, "", "load"], [328, 1, 1, "", "load_"], [328, 1, 1, "", "load_memmap"], [328, 1, 1, "", "load_state_dict"], [328, 1, 1, "", "maybe_dense_stack"], [328, 1, 1, "", "memmap"], [328, 1, 1, "", "memmap_"], [328, 1, 1, "", "memmap_like"], [328, 1, 1, "", "memmap_refresh_"], [328, 1, 1, "", "save"], [328, 1, 1, "", "set"], [328, 1, 1, "", "stack"], [328, 1, 1, "", "state_dict"], [328, 1, 1, "", "to_tensordict"], [328, 1, 1, "", "unbind"]], "torchrl.modules.llm.RemoteTransformersWrapper": [[329, 2, 1, "", "batching"], [329, 1, 1, "", "cleanup_batching"], [329, 2, 1, "", "collector"], [329, 2, 1, "", "device"], [329, 2, 1, "", "dist_params_keys"], [329, 2, 1, "", "dist_sample_keys"], [329, 2, 1, "", "generate"], [329, 1, 1, "", "get_batching_state"], [329, 1, 1, "", "get_dist"], [329, 1, 1, "", "get_dist_with_prompt_mask"], [329, 1, 1, "", "get_new_version"], [329, 2, 1, "", "in_keys"], [329, 2, 1, "", "inplace"], [329, 2, 1, "", "layout"], [329, 1, 1, "", "log_prob"], [329, 2, 1, "", "log_prob_keys"], [329, 2, 1, "", "log_probs_key"], [329, 2, 1, "", "masks_key"], [329, 2, 1, "", "num_samples"], [329, 2, 1, "", "out_keys"], [329, 2, 1, "", "pad_output"], [329, 2, 1, "", "text_key"], [329, 2, 1, "", "tokens_key"]], "torchrl.modules.llm.Text": [[330, 1, 1, "", "cat"], [330, 1, 1, "", "default_spec"], [330, 2, 1, "", "device"], [330, 1, 1, "", "dumps"], [330, 1, 1, "", "fields"], [330, 1, 1, "", "from_any"], [330, 1, 1, "", "from_dataclass"], [330, 1, 1, "", "from_h5"], [330, 1, 1, "", "from_modules"], [330, 1, 1, "", "from_namedtuple"], [330, 1, 1, "", "from_pytree"], [330, 1, 1, "", "from_remote_init"], [330, 1, 1, "", "from_struct_array"], [330, 1, 1, "", "from_tensordict"], [330, 1, 1, "", "from_tuple"], [330, 1, 1, "", "fromkeys"], [330, 1, 1, "", "get"], [330, 1, 1, "", "lazy_stack"], [330, 1, 1, "", "load"], [330, 1, 1, "", "load_"], [330, 1, 1, "", "load_memmap"], [330, 1, 1, "", "load_state_dict"], [330, 1, 1, "", "maybe_dense_stack"], [330, 1, 1, "", "memmap"], [330, 1, 1, "", "memmap_"], [330, 1, 1, "", "memmap_like"], [330, 1, 1, "", "memmap_refresh_"], [330, 1, 1, "", "save"], [330, 1, 1, "", "set"], [330, 1, 1, "", "stack"], [330, 1, 1, "", "state_dict"], [330, 1, 1, "", "to_history"], [330, 1, 1, "", "to_tensordict"], [330, 1, 1, "", "to_tokens"], [330, 1, 1, "", "unbind"]], "torchrl.modules.llm.Tokens": [[331, 1, 1, "", "cat"], [331, 1, 1, "", "default_spec"], [331, 2, 1, "", "device"], [331, 1, 1, "", "dumps"], [331, 1, 1, "", "fields"], [331, 1, 1, "", "from_any"], [331, 1, 1, "", "from_dataclass"], [331, 1, 1, "", "from_h5"], [331, 1, 1, "", "from_modules"], [331, 1, 1, "", "from_namedtuple"], [331, 1, 1, "", "from_pytree"], [331, 1, 1, "", "from_remote_init"], [331, 1, 1, "", "from_struct_array"], [331, 1, 1, "", "from_tensordict"], [331, 1, 1, "", "from_tuple"], [331, 1, 1, "", "fromkeys"], [331, 1, 1, "", "get"], [331, 1, 1, "", "lazy_stack"], [331, 1, 1, "", "load"], [331, 1, 1, "", "load_"], [331, 1, 1, "", "load_memmap"], [331, 1, 1, "", "load_state_dict"], [331, 1, 1, "", "maybe_dense_stack"], [331, 1, 1, "", "memmap"], [331, 1, 1, "", "memmap_"], [331, 1, 1, "", "memmap_like"], [331, 1, 1, "", "memmap_refresh_"], [331, 1, 1, "", "save"], [331, 1, 1, "", "set"], [331, 1, 1, "", "stack"], [331, 1, 1, "", "state_dict"], [331, 1, 1, "", "to_history"], [331, 1, 1, "", "to_tensordict"], [331, 1, 1, "", "to_text"], [331, 1, 1, "", "unbind"]], "torchrl.modules.llm.TransformersWrapper": [[332, 1, 1, "", "add_module"], [332, 1, 1, "", "apply"], [332, 2, 1, "", "batching"], [332, 1, 1, "", "bfloat16"], [332, 1, 1, "", "buffers"], [332, 1, 1, "", "children"], [332, 1, 1, "", "cleanup_batching"], [332, 2, 1, "", "collector"], [332, 1, 1, "", "compile"], [332, 1, 1, "", "cpu"], [332, 1, 1, "", "cuda"], [332, 1, 1, "", "double"], [332, 1, 1, "", "eval"], [332, 1, 1, "", "extra_repr"], [332, 1, 1, "", "float"], [332, 1, 1, "", "forward"], [332, 1, 1, "", "get_batching_state"], [332, 1, 1, "", "get_buffer"], [332, 1, 1, "", "get_dist"], [332, 1, 1, "", "get_extra_state"], [332, 1, 1, "", "get_new_version"], [332, 1, 1, "", "get_parameter"], [332, 1, 1, "", "get_submodule"], [332, 1, 1, "", "half"], [332, 1, 1, "", "ipu"], [332, 1, 1, "", "is_tdmodule_compatible"], [332, 1, 1, "", "load_state_dict"], [332, 1, 1, "", "modules"], [332, 1, 1, "", "mtia"], [332, 1, 1, "", "named_buffers"], [332, 1, 1, "", "named_children"], [332, 1, 1, "", "named_modules"], [332, 1, 1, "", "named_parameters"], [332, 1, 1, "", "parameters"], [332, 1, 1, "", "register_backward_hook"], [332, 1, 1, "", "register_buffer"], [332, 1, 1, "", "register_collector"], [332, 1, 1, "", "register_forward_hook"], [332, 1, 1, "", "register_forward_pre_hook"], [332, 1, 1, "", "register_full_backward_hook"], [332, 1, 1, "", "register_full_backward_pre_hook"], [332, 1, 1, "", "register_load_state_dict_post_hook"], [332, 1, 1, "", "register_load_state_dict_pre_hook"], [332, 1, 1, "", "register_module"], [332, 1, 1, "", "register_parameter"], [332, 1, 1, "", "register_state_dict_post_hook"], [332, 1, 1, "", "register_state_dict_pre_hook"], [332, 1, 1, "", "repeat_interleave_causal"], [332, 1, 1, "", "requires_grad_"], [332, 1, 1, "", "reset_out_keys"], [332, 1, 1, "", "reset_parameters_recursive"], [332, 1, 1, "", "select_out_keys"], [332, 1, 1, "", "set_extra_state"], [332, 1, 1, "", "set_submodule"], [332, 1, 1, "", "share_memory"], [332, 1, 1, "", "state_dict"], [332, 1, 1, "", "to"], [332, 1, 1, "", "to_empty"], [332, 1, 1, "", "train"], [332, 1, 1, "", "type"], [332, 1, 1, "", "xpu"], [332, 1, 1, "", "zero_grad"]], "torchrl.modules.llm.vLLMWrapper": [[337, 1, 1, "", "add_module"], [337, 1, 1, "", "apply"], [337, 2, 1, "", "batching"], [337, 1, 1, "", "bfloat16"], [337, 1, 1, "", "buffers"], [337, 1, 1, "", "children"], [337, 1, 1, "", "cleanup_batching"], [337, 2, 1, "", "collector"], [337, 1, 1, "", "compile"], [337, 1, 1, "", "cpu"], [337, 1, 1, "", "cuda"], [337, 1, 1, "", "double"], [337, 1, 1, "", "eval"], [337, 1, 1, "", "extra_repr"], [337, 1, 1, "", "float"], [337, 1, 1, "", "forward"], [337, 1, 1, "", "get_batching_state"], [337, 1, 1, "", "get_buffer"], [337, 1, 1, "", "get_dist"], [337, 1, 1, "", "get_dist_with_prompt_mask"], [337, 1, 1, "", "get_extra_state"], [337, 1, 1, "", "get_new_version"], [337, 1, 1, "", "get_parameter"], [337, 1, 1, "", "get_submodule"], [337, 1, 1, "", "half"], [337, 1, 1, "", "ipu"], [337, 1, 1, "", "is_tdmodule_compatible"], [337, 1, 1, "", "load_state_dict"], [337, 1, 1, "", "modules"], [337, 1, 1, "", "mtia"], [337, 1, 1, "", "named_buffers"], [337, 1, 1, "", "named_children"], [337, 1, 1, "", "named_modules"], [337, 1, 1, "", "named_parameters"], [337, 1, 1, "", "parameters"], [337, 1, 1, "", "register_backward_hook"], [337, 1, 1, "", "register_buffer"], [337, 1, 1, "", "register_collector"], [337, 1, 1, "", "register_forward_hook"], [337, 1, 1, "", "register_forward_pre_hook"], [337, 1, 1, "", "register_full_backward_hook"], [337, 1, 1, "", "register_full_backward_pre_hook"], [337, 1, 1, "", "register_load_state_dict_post_hook"], [337, 1, 1, "", "register_load_state_dict_pre_hook"], [337, 1, 1, "", "register_module"], [337, 1, 1, "", "register_parameter"], [337, 1, 1, "", "register_state_dict_post_hook"], [337, 1, 1, "", "register_state_dict_pre_hook"], [337, 1, 1, "", "requires_grad_"], [337, 1, 1, "", "reset_out_keys"], [337, 1, 1, "", "reset_parameters_recursive"], [337, 1, 1, "", "select_out_keys"], [337, 1, 1, "", "set_extra_state"], [337, 1, 1, "", "set_submodule"], [337, 1, 1, "", "set_tokenizer"], [337, 1, 1, "", "share_memory"], [337, 1, 1, "", "state_dict"], [337, 1, 1, "", "to"], [337, 1, 1, "", "to_empty"], [337, 1, 1, "", "train"], [337, 1, 1, "", "type"], [337, 1, 1, "", "xpu"], [337, 1, 1, "", "zero_grad"]], "torchrl.modules.models.utils": [[338, 0, 1, "", "SquashDims"]], "torchrl.modules.models.utils.SquashDims": [[338, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module": [[339, 0, 1, "", "Actor"], [340, 0, 1, "", "MultiStepActorWrapper"], [341, 0, 1, "", "ProbabilisticActor"], [342, 0, 1, "", "RandomPolicy"], [343, 0, 1, "", "SafeModule"], [344, 0, 1, "", "SafeProbabilisticModule"], [345, 0, 1, "", "SafeProbabilisticTensorDictSequential"], [346, 0, 1, "", "SafeSequential"], [347, 0, 1, "", "TanhModule"]], "torchrl.modules.tensordict_module.MultiStepActorWrapper": [[340, 1, 1, "", "forward"], [340, 2, 1, "", "init_key"]], "torchrl.modules.tensordict_module.SafeModule": [[343, 1, 1, "", "random"], [343, 1, 1, "", "random_sample"], [343, 1, 1, "", "to"]], "torchrl.modules.tensordict_module.SafeProbabilisticModule": [[344, 1, 1, "", "random"], [344, 1, 1, "", "random_sample"]], "torchrl.modules.tensordict_module.TanhModule": [[347, 1, 1, "", "forward"]], "torchrl.objectives": [[348, 0, 1, "", "A2CLoss"], [349, 0, 1, "", "CQLLoss"], [350, 0, 1, "", "ClipPPOLoss"], [351, 0, 1, "", "CrossQLoss"], [352, 0, 1, "", "DDPGLoss"], [353, 0, 1, "", "DQNLoss"], [354, 0, 1, "", "DTLoss"], [355, 0, 1, "", "DiscreteCQLLoss"], [356, 0, 1, "", "DiscreteIQLLoss"], [357, 0, 1, "", "DiscreteSACLoss"], [358, 0, 1, "", "DistributionalDQNLoss"], [359, 0, 1, "", "DreamerActorLoss"], [360, 0, 1, "", "DreamerModelLoss"], [361, 0, 1, "", "DreamerValueLoss"], [362, 0, 1, "", "GAILLoss"], [363, 0, 1, "", "IQLLoss"], [364, 0, 1, "", "KLPENPPOLoss"], [365, 0, 1, "", "LossModule"], [366, 0, 1, "", "OnlineDTLoss"], [367, 0, 1, "", "PPOLoss"], [368, 0, 1, "", "REDQLoss"], [369, 0, 1, "", "ReinforceLoss"], [370, 0, 1, "", "SACLoss"], [371, 0, 1, "", "TD3BCLoss"], [372, 0, 1, "", "TD3Loss"], [373, 0, 1, "", "ValueEstimators"], [374, 0, 1, "", "add_random_module"]], "torchrl.objectives.A2CLoss": [[348, 4, 1, "", "default_keys"], [348, 1, 1, "", "forward"], [348, 2, 1, "", "functional"], [348, 1, 1, "", "loss_critic"], [348, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.CQLLoss": [[349, 4, 1, "", "default_keys"], [349, 1, 1, "", "forward"], [349, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ClipPPOLoss": [[350, 1, 1, "", "forward"]], "torchrl.objectives.CrossQLoss": [[351, 1, 1, "", "actor_loss"], [351, 1, 1, "", "alpha_loss"], [351, 4, 1, "", "default_keys"], [351, 1, 1, "", "forward"], [351, 1, 1, "", "load_state_dict"], [351, 1, 1, "", "make_value_estimator"], [351, 1, 1, "", "maybe_init_target_entropy"], [351, 1, 1, "", "qvalue_loss"], [351, 1, 1, "", "set_keys"], [351, 1, 1, "", "state_dict"], [351, 2, 1, "", "target_entropy_buffer"]], "torchrl.objectives.DDPGLoss": [[352, 4, 1, "", "default_keys"], [352, 1, 1, "", "forward"], [352, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DQNLoss": [[353, 4, 1, "", "default_keys"], [353, 1, 1, "", "forward"], [353, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DTLoss": [[354, 4, 1, "", "default_keys"], [354, 1, 1, "", "forward"]], "torchrl.objectives.DiscreteCQLLoss": [[355, 4, 1, "", "default_keys"], [355, 1, 1, "", "forward"], [355, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DiscreteIQLLoss": [[356, 4, 1, "", "default_keys"], [356, 1, 1, "", "forward"]], "torchrl.objectives.DiscreteSACLoss": [[357, 1, 1, "", "alpha_loss"], [357, 4, 1, "", "default_keys"], [357, 1, 1, "", "forward"], [357, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DistributionalDQNLoss": [[358, 4, 1, "", "default_keys"], [358, 1, 1, "", "forward"], [358, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerActorLoss": [[359, 4, 1, "", "default_keys"], [359, 1, 1, "", "forward"], [359, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerModelLoss": [[360, 4, 1, "", "default_keys"], [360, 1, 1, "", "forward"]], "torchrl.objectives.DreamerValueLoss": [[361, 4, 1, "", "default_keys"], [361, 1, 1, "", "forward"]], "torchrl.objectives.GAILLoss": [[362, 4, 1, "", "default_keys"], [362, 1, 1, "", "forward"]], "torchrl.objectives.IQLLoss": [[363, 4, 1, "", "default_keys"], [363, 1, 1, "", "forward"], [363, 1, 1, "", "loss_value_diff"], [363, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.KLPENPPOLoss": [[364, 1, 1, "", "forward"]], "torchrl.objectives.LossModule": [[365, 1, 1, "", "convert_to_functional"], [365, 1, 1, "", "forward"], [365, 1, 1, "", "from_stateful_net"], [365, 2, 1, "", "functional"], [365, 1, 1, "", "get_stateful_net"], [365, 1, 1, "", "make_value_estimator"], [365, 1, 1, "", "named_parameters"], [365, 1, 1, "", "parameters"], [365, 1, 1, "", "reset_parameters_recursive"], [365, 1, 1, "", "set_keys"], [365, 2, 1, "", "value_estimator"], [365, 2, 1, "", "vmap_randomness"]], "torchrl.objectives.OnlineDTLoss": [[366, 4, 1, "", "default_keys"], [366, 1, 1, "", "forward"]], "torchrl.objectives.PPOLoss": [[367, 4, 1, "", "default_keys"], [367, 1, 1, "", "forward"], [367, 2, 1, "", "functional"], [367, 1, 1, "", "loss_critic"], [367, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.REDQLoss": [[368, 4, 1, "", "default_keys"], [368, 1, 1, "", "forward"], [368, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ReinforceLoss": [[369, 4, 1, "", "default_keys"], [369, 1, 1, "", "forward"], [369, 2, 1, "", "functional"], [369, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.SACLoss": [[370, 1, 1, "", "alpha_loss"], [370, 4, 1, "", "default_keys"], [370, 1, 1, "", "forward"], [370, 1, 1, "", "load_state_dict"], [370, 1, 1, "", "make_value_estimator"], [370, 1, 1, "", "state_dict"]], "torchrl.objectives.TD3BCLoss": [[371, 1, 1, "", "actor_loss"], [371, 4, 1, "", "default_keys"], [371, 1, 1, "", "forward"], [371, 1, 1, "", "make_value_estimator"], [371, 1, 1, "", "qvalue_loss"]], "torchrl.objectives.TD3Loss": [[372, 4, 1, "", "default_keys"], [372, 1, 1, "", "forward"], [372, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.llm": [[375, 0, 1, "", "CISPOLoss"], [376, 0, 1, "", "CISPOLossOutput"], [377, 0, 1, "", "DAPO"], [378, 0, 1, "", "DAPOLossOutput"], [379, 0, 1, "", "GRPOLoss"], [380, 0, 1, "", "GRPOLossOutput"], [381, 0, 1, "", "LLMLossOutput"], [382, 0, 1, "", "MCAdvantage"], [383, 0, 1, "", "SFTLoss"], [384, 0, 1, "", "SFTLossOutput"]], "torchrl.objectives.llm.CISPOLoss": [[375, 1, 1, "", "add_module"], [375, 1, 1, "", "apply"], [375, 1, 1, "", "bfloat16"], [375, 1, 1, "", "buffers"], [375, 1, 1, "", "children"], [375, 1, 1, "", "compile"], [375, 1, 1, "", "convert_to_functional"], [375, 1, 1, "", "cpu"], [375, 1, 1, "", "cuda"], [375, 1, 1, "", "double"], [375, 1, 1, "", "eval"], [375, 1, 1, "", "extra_repr"], [375, 1, 1, "", "float"], [375, 1, 1, "", "forward"], [375, 1, 1, "", "from_stateful_net"], [375, 2, 1, "", "functional"], [375, 1, 1, "", "get_buffer"], [375, 1, 1, "", "get_extra_state"], [375, 1, 1, "", "get_parameter"], [375, 1, 1, "", "get_stateful_net"], [375, 1, 1, "", "get_submodule"], [375, 1, 1, "", "half"], [375, 1, 1, "", "ipu"], [375, 1, 1, "", "is_tdmodule_compatible"], [375, 1, 1, "", "load_state_dict"], [375, 1, 1, "", "make_value_estimator"], [375, 1, 1, "", "modules"], [375, 1, 1, "", "mtia"], [375, 1, 1, "", "named_buffers"], [375, 1, 1, "", "named_children"], [375, 1, 1, "", "named_modules"], [375, 1, 1, "", "named_parameters"], [375, 4, 1, "", "output_type"], [375, 1, 1, "", "parameters"], [375, 1, 1, "", "register_backward_hook"], [375, 1, 1, "", "register_buffer"], [375, 1, 1, "", "register_forward_hook"], [375, 1, 1, "", "register_forward_pre_hook"], [375, 1, 1, "", "register_full_backward_hook"], [375, 1, 1, "", "register_full_backward_pre_hook"], [375, 1, 1, "", "register_load_state_dict_post_hook"], [375, 1, 1, "", "register_load_state_dict_pre_hook"], [375, 1, 1, "", "register_module"], [375, 1, 1, "", "register_parameter"], [375, 1, 1, "", "register_state_dict_post_hook"], [375, 1, 1, "", "register_state_dict_pre_hook"], [375, 1, 1, "", "requires_grad_"], [375, 1, 1, "", "reset_out_keys"], [375, 1, 1, "", "reset_parameters_recursive"], [375, 1, 1, "", "select_out_keys"], [375, 1, 1, "", "set_extra_state"], [375, 1, 1, "", "set_keys"], [375, 1, 1, "", "set_submodule"], [375, 1, 1, "", "share_memory"], [375, 1, 1, "", "state_dict"], [375, 2, 1, "", "tensor_keys"], [375, 1, 1, "", "to"], [375, 1, 1, "", "to_empty"], [375, 1, 1, "", "train"], [375, 1, 1, "", "type"], [375, 2, 1, "", "value_estimator"], [375, 2, 1, "", "vmap_randomness"], [375, 1, 1, "", "xpu"], [375, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.CISPOLossOutput": [[376, 1, 1, "", "cat"], [376, 2, 1, "", "device"], [376, 1, 1, "", "dumps"], [376, 1, 1, "", "fields"], [376, 1, 1, "", "from_any"], [376, 1, 1, "", "from_dataclass"], [376, 1, 1, "", "from_h5"], [376, 1, 1, "", "from_modules"], [376, 1, 1, "", "from_namedtuple"], [376, 1, 1, "", "from_pytree"], [376, 1, 1, "", "from_remote_init"], [376, 1, 1, "", "from_struct_array"], [376, 1, 1, "", "from_tensordict"], [376, 1, 1, "", "from_tuple"], [376, 1, 1, "", "fromkeys"], [376, 1, 1, "", "get"], [376, 1, 1, "", "lazy_stack"], [376, 1, 1, "", "load"], [376, 1, 1, "", "load_"], [376, 1, 1, "", "load_memmap"], [376, 1, 1, "", "load_state_dict"], [376, 1, 1, "", "maybe_dense_stack"], [376, 1, 1, "", "memmap"], [376, 1, 1, "", "memmap_"], [376, 1, 1, "", "memmap_like"], [376, 1, 1, "", "memmap_refresh_"], [376, 1, 1, "", "save"], [376, 1, 1, "", "set"], [376, 1, 1, "", "stack"], [376, 1, 1, "", "state_dict"], [376, 1, 1, "", "to_tensordict"], [376, 1, 1, "", "unbind"]], "torchrl.objectives.llm.DAPO": [[377, 1, 1, "", "add_module"], [377, 1, 1, "", "apply"], [377, 1, 1, "", "bfloat16"], [377, 1, 1, "", "buffers"], [377, 1, 1, "", "children"], [377, 1, 1, "", "compile"], [377, 1, 1, "", "convert_to_functional"], [377, 1, 1, "", "cpu"], [377, 1, 1, "", "cuda"], [377, 1, 1, "", "double"], [377, 1, 1, "", "eval"], [377, 1, 1, "", "extra_repr"], [377, 1, 1, "", "float"], [377, 1, 1, "", "forward"], [377, 1, 1, "", "from_stateful_net"], [377, 2, 1, "", "functional"], [377, 1, 1, "", "get_buffer"], [377, 1, 1, "", "get_extra_state"], [377, 1, 1, "", "get_parameter"], [377, 1, 1, "", "get_stateful_net"], [377, 1, 1, "", "get_submodule"], [377, 1, 1, "", "half"], [377, 1, 1, "", "ipu"], [377, 1, 1, "", "is_tdmodule_compatible"], [377, 1, 1, "", "load_state_dict"], [377, 1, 1, "", "make_value_estimator"], [377, 1, 1, "", "modules"], [377, 1, 1, "", "mtia"], [377, 1, 1, "", "named_buffers"], [377, 1, 1, "", "named_children"], [377, 1, 1, "", "named_modules"], [377, 1, 1, "", "named_parameters"], [377, 4, 1, "", "output_type"], [377, 1, 1, "", "parameters"], [377, 1, 1, "", "register_backward_hook"], [377, 1, 1, "", "register_buffer"], [377, 1, 1, "", "register_forward_hook"], [377, 1, 1, "", "register_forward_pre_hook"], [377, 1, 1, "", "register_full_backward_hook"], [377, 1, 1, "", "register_full_backward_pre_hook"], [377, 1, 1, "", "register_load_state_dict_post_hook"], [377, 1, 1, "", "register_load_state_dict_pre_hook"], [377, 1, 1, "", "register_module"], [377, 1, 1, "", "register_parameter"], [377, 1, 1, "", "register_state_dict_post_hook"], [377, 1, 1, "", "register_state_dict_pre_hook"], [377, 1, 1, "", "requires_grad_"], [377, 1, 1, "", "reset_out_keys"], [377, 1, 1, "", "reset_parameters_recursive"], [377, 1, 1, "", "select_out_keys"], [377, 1, 1, "", "set_extra_state"], [377, 1, 1, "", "set_keys"], [377, 1, 1, "", "set_submodule"], [377, 1, 1, "", "share_memory"], [377, 1, 1, "", "state_dict"], [377, 2, 1, "", "tensor_keys"], [377, 1, 1, "", "to"], [377, 1, 1, "", "to_empty"], [377, 1, 1, "", "train"], [377, 1, 1, "", "type"], [377, 2, 1, "", "value_estimator"], [377, 2, 1, "", "vmap_randomness"], [377, 1, 1, "", "xpu"], [377, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.DAPOLossOutput": [[378, 1, 1, "", "cat"], [378, 2, 1, "", "device"], [378, 1, 1, "", "dumps"], [378, 1, 1, "", "fields"], [378, 1, 1, "", "from_any"], [378, 1, 1, "", "from_dataclass"], [378, 1, 1, "", "from_h5"], [378, 1, 1, "", "from_modules"], [378, 1, 1, "", "from_namedtuple"], [378, 1, 1, "", "from_pytree"], [378, 1, 1, "", "from_remote_init"], [378, 1, 1, "", "from_struct_array"], [378, 1, 1, "", "from_tensordict"], [378, 1, 1, "", "from_tuple"], [378, 1, 1, "", "fromkeys"], [378, 1, 1, "", "get"], [378, 1, 1, "", "lazy_stack"], [378, 1, 1, "", "load"], [378, 1, 1, "", "load_"], [378, 1, 1, "", "load_memmap"], [378, 1, 1, "", "load_state_dict"], [378, 1, 1, "", "maybe_dense_stack"], [378, 1, 1, "", "memmap"], [378, 1, 1, "", "memmap_"], [378, 1, 1, "", "memmap_like"], [378, 1, 1, "", "memmap_refresh_"], [378, 1, 1, "", "save"], [378, 1, 1, "", "set"], [378, 1, 1, "", "stack"], [378, 1, 1, "", "state_dict"], [378, 1, 1, "", "to_tensordict"], [378, 1, 1, "", "unbind"]], "torchrl.objectives.llm.GRPOLoss": [[379, 1, 1, "", "add_module"], [379, 1, 1, "", "apply"], [379, 1, 1, "", "bfloat16"], [379, 1, 1, "", "buffers"], [379, 1, 1, "", "children"], [379, 1, 1, "", "compile"], [379, 1, 1, "", "convert_to_functional"], [379, 1, 1, "", "cpu"], [379, 1, 1, "", "cuda"], [379, 1, 1, "", "double"], [379, 1, 1, "", "eval"], [379, 1, 1, "", "extra_repr"], [379, 1, 1, "", "float"], [379, 1, 1, "", "forward"], [379, 1, 1, "", "from_stateful_net"], [379, 2, 1, "", "functional"], [379, 1, 1, "", "get_buffer"], [379, 1, 1, "", "get_extra_state"], [379, 1, 1, "", "get_parameter"], [379, 1, 1, "", "get_stateful_net"], [379, 1, 1, "", "get_submodule"], [379, 1, 1, "", "half"], [379, 1, 1, "", "ipu"], [379, 1, 1, "", "is_tdmodule_compatible"], [379, 1, 1, "", "load_state_dict"], [379, 1, 1, "", "make_value_estimator"], [379, 1, 1, "", "modules"], [379, 1, 1, "", "mtia"], [379, 1, 1, "", "named_buffers"], [379, 1, 1, "", "named_children"], [379, 1, 1, "", "named_modules"], [379, 1, 1, "", "named_parameters"], [379, 4, 1, "", "output_type"], [379, 1, 1, "", "parameters"], [379, 1, 1, "", "register_backward_hook"], [379, 1, 1, "", "register_buffer"], [379, 1, 1, "", "register_forward_hook"], [379, 1, 1, "", "register_forward_pre_hook"], [379, 1, 1, "", "register_full_backward_hook"], [379, 1, 1, "", "register_full_backward_pre_hook"], [379, 1, 1, "", "register_load_state_dict_post_hook"], [379, 1, 1, "", "register_load_state_dict_pre_hook"], [379, 1, 1, "", "register_module"], [379, 1, 1, "", "register_parameter"], [379, 1, 1, "", "register_state_dict_post_hook"], [379, 1, 1, "", "register_state_dict_pre_hook"], [379, 1, 1, "", "requires_grad_"], [379, 1, 1, "", "reset_out_keys"], [379, 1, 1, "", "reset_parameters_recursive"], [379, 1, 1, "", "select_out_keys"], [379, 1, 1, "", "set_extra_state"], [379, 1, 1, "", "set_keys"], [379, 1, 1, "", "set_submodule"], [379, 1, 1, "", "share_memory"], [379, 1, 1, "", "state_dict"], [379, 2, 1, "", "tensor_keys"], [379, 1, 1, "", "to"], [379, 1, 1, "", "to_empty"], [379, 1, 1, "", "train"], [379, 1, 1, "", "type"], [379, 2, 1, "", "value_estimator"], [379, 2, 1, "", "vmap_randomness"], [379, 1, 1, "", "xpu"], [379, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.GRPOLossOutput": [[380, 1, 1, "", "cat"], [380, 2, 1, "", "device"], [380, 1, 1, "", "dumps"], [380, 1, 1, "", "fields"], [380, 1, 1, "", "from_any"], [380, 1, 1, "", "from_dataclass"], [380, 1, 1, "", "from_h5"], [380, 1, 1, "", "from_modules"], [380, 1, 1, "", "from_namedtuple"], [380, 1, 1, "", "from_pytree"], [380, 1, 1, "", "from_remote_init"], [380, 1, 1, "", "from_struct_array"], [380, 1, 1, "", "from_tensordict"], [380, 1, 1, "", "from_tuple"], [380, 1, 1, "", "fromkeys"], [380, 1, 1, "", "get"], [380, 1, 1, "", "lazy_stack"], [380, 1, 1, "", "load"], [380, 1, 1, "", "load_"], [380, 1, 1, "", "load_memmap"], [380, 1, 1, "", "load_state_dict"], [380, 1, 1, "", "maybe_dense_stack"], [380, 1, 1, "", "memmap"], [380, 1, 1, "", "memmap_"], [380, 1, 1, "", "memmap_like"], [380, 1, 1, "", "memmap_refresh_"], [380, 1, 1, "", "save"], [380, 1, 1, "", "set"], [380, 1, 1, "", "stack"], [380, 1, 1, "", "state_dict"], [380, 1, 1, "", "to_tensordict"], [380, 1, 1, "", "unbind"]], "torchrl.objectives.llm.LLMLossOutput": [[381, 1, 1, "", "cat"], [381, 2, 1, "", "device"], [381, 1, 1, "", "dumps"], [381, 1, 1, "", "fields"], [381, 1, 1, "", "from_any"], [381, 1, 1, "", "from_dataclass"], [381, 1, 1, "", "from_h5"], [381, 1, 1, "", "from_modules"], [381, 1, 1, "", "from_namedtuple"], [381, 1, 1, "", "from_pytree"], [381, 1, 1, "", "from_remote_init"], [381, 1, 1, "", "from_struct_array"], [381, 1, 1, "", "from_tensordict"], [381, 1, 1, "", "from_tuple"], [381, 1, 1, "", "fromkeys"], [381, 1, 1, "", "get"], [381, 1, 1, "", "lazy_stack"], [381, 1, 1, "", "load"], [381, 1, 1, "", "load_"], [381, 1, 1, "", "load_memmap"], [381, 1, 1, "", "load_state_dict"], [381, 1, 1, "", "maybe_dense_stack"], [381, 1, 1, "", "memmap"], [381, 1, 1, "", "memmap_"], [381, 1, 1, "", "memmap_like"], [381, 1, 1, "", "memmap_refresh_"], [381, 1, 1, "", "save"], [381, 1, 1, "", "set"], [381, 1, 1, "", "stack"], [381, 1, 1, "", "state_dict"], [381, 1, 1, "", "to_tensordict"], [381, 1, 1, "", "unbind"]], "torchrl.objectives.llm.MCAdvantage": [[382, 1, 1, "", "add_module"], [382, 1, 1, "", "apply"], [382, 1, 1, "", "bfloat16"], [382, 1, 1, "", "buffers"], [382, 1, 1, "", "children"], [382, 1, 1, "", "close"], [382, 2, 1, "", "collector"], [382, 1, 1, "", "compile"], [382, 2, 1, "", "container"], [382, 1, 1, "", "cpu"], [382, 1, 1, "", "cuda"], [382, 1, 1, "", "double"], [382, 1, 1, "", "eval"], [382, 1, 1, "", "extra_repr"], [382, 1, 1, "", "float"], [382, 1, 1, "", "forward"], [382, 1, 1, "", "get_buffer"], [382, 1, 1, "", "get_extra_state"], [382, 1, 1, "", "get_parameter"], [382, 1, 1, "", "get_submodule"], [382, 1, 1, "", "half"], [382, 1, 1, "", "init"], [382, 1, 1, "", "inv"], [382, 1, 1, "", "ipu"], [382, 1, 1, "", "load_state_dict"], [382, 1, 1, "", "modules"], [382, 1, 1, "", "mtia"], [382, 1, 1, "", "named_buffers"], [382, 1, 1, "", "named_children"], [382, 1, 1, "", "named_modules"], [382, 1, 1, "", "named_parameters"], [382, 1, 1, "", "parameters"], [382, 2, 1, "", "parent"], [382, 1, 1, "", "register_backward_hook"], [382, 1, 1, "", "register_buffer"], [382, 1, 1, "", "register_forward_hook"], [382, 1, 1, "", "register_forward_pre_hook"], [382, 1, 1, "", "register_full_backward_hook"], [382, 1, 1, "", "register_full_backward_pre_hook"], [382, 1, 1, "", "register_load_state_dict_post_hook"], [382, 1, 1, "", "register_load_state_dict_pre_hook"], [382, 1, 1, "", "register_module"], [382, 1, 1, "", "register_parameter"], [382, 1, 1, "", "register_state_dict_post_hook"], [382, 1, 1, "", "register_state_dict_pre_hook"], [382, 1, 1, "", "requires_grad_"], [382, 1, 1, "", "set_extra_state"], [382, 1, 1, "", "set_submodule"], [382, 1, 1, "", "share_memory"], [382, 1, 1, "", "state_dict"], [382, 1, 1, "", "to"], [382, 1, 1, "", "to_empty"], [382, 1, 1, "", "train"], [382, 1, 1, "", "transform_action_spec"], [382, 1, 1, "", "transform_done_spec"], [382, 1, 1, "", "transform_env_batch_size"], [382, 1, 1, "", "transform_env_device"], [382, 1, 1, "", "transform_input_spec"], [382, 1, 1, "", "transform_observation_spec"], [382, 1, 1, "", "transform_output_spec"], [382, 1, 1, "", "transform_reward_spec"], [382, 1, 1, "", "transform_state_spec"], [382, 1, 1, "", "type"], [382, 1, 1, "", "xpu"], [382, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.SFTLoss": [[383, 1, 1, "", "add_module"], [383, 1, 1, "", "apply"], [383, 1, 1, "", "bfloat16"], [383, 1, 1, "", "buffers"], [383, 1, 1, "", "children"], [383, 1, 1, "", "compile"], [383, 1, 1, "", "convert_to_functional"], [383, 1, 1, "", "cpu"], [383, 1, 1, "", "cuda"], [383, 4, 1, "", "default_keys"], [383, 1, 1, "", "double"], [383, 1, 1, "", "eval"], [383, 1, 1, "", "extra_repr"], [383, 1, 1, "", "float"], [383, 1, 1, "", "forward"], [383, 1, 1, "", "from_stateful_net"], [383, 2, 1, "", "functional"], [383, 1, 1, "", "get_buffer"], [383, 1, 1, "", "get_extra_state"], [383, 1, 1, "", "get_parameter"], [383, 1, 1, "", "get_stateful_net"], [383, 1, 1, "", "get_submodule"], [383, 1, 1, "", "half"], [383, 1, 1, "", "ipu"], [383, 1, 1, "", "is_tdmodule_compatible"], [383, 1, 1, "", "load_state_dict"], [383, 1, 1, "", "make_value_estimator"], [383, 1, 1, "", "modules"], [383, 1, 1, "", "mtia"], [383, 1, 1, "", "named_buffers"], [383, 1, 1, "", "named_children"], [383, 1, 1, "", "named_modules"], [383, 1, 1, "", "named_parameters"], [383, 1, 1, "", "parameters"], [383, 1, 1, "", "register_backward_hook"], [383, 1, 1, "", "register_buffer"], [383, 1, 1, "", "register_forward_hook"], [383, 1, 1, "", "register_forward_pre_hook"], [383, 1, 1, "", "register_full_backward_hook"], [383, 1, 1, "", "register_full_backward_pre_hook"], [383, 1, 1, "", "register_load_state_dict_post_hook"], [383, 1, 1, "", "register_load_state_dict_pre_hook"], [383, 1, 1, "", "register_module"], [383, 1, 1, "", "register_parameter"], [383, 1, 1, "", "register_state_dict_post_hook"], [383, 1, 1, "", "register_state_dict_pre_hook"], [383, 1, 1, "", "requires_grad_"], [383, 1, 1, "", "reset_out_keys"], [383, 1, 1, "", "reset_parameters_recursive"], [383, 1, 1, "", "select_out_keys"], [383, 1, 1, "", "set_extra_state"], [383, 1, 1, "", "set_keys"], [383, 1, 1, "", "set_submodule"], [383, 1, 1, "", "share_memory"], [383, 1, 1, "", "state_dict"], [383, 1, 1, "", "to"], [383, 1, 1, "", "to_empty"], [383, 1, 1, "", "train"], [383, 1, 1, "", "type"], [383, 2, 1, "", "value_estimator"], [383, 2, 1, "", "vmap_randomness"], [383, 1, 1, "", "xpu"], [383, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.SFTLossOutput": [[384, 1, 1, "", "cat"], [384, 2, 1, "", "device"], [384, 1, 1, "", "dumps"], [384, 1, 1, "", "fields"], [384, 1, 1, "", "from_any"], [384, 1, 1, "", "from_dataclass"], [384, 1, 1, "", "from_h5"], [384, 1, 1, "", "from_modules"], [384, 1, 1, "", "from_namedtuple"], [384, 1, 1, "", "from_pytree"], [384, 1, 1, "", "from_remote_init"], [384, 1, 1, "", "from_struct_array"], [384, 1, 1, "", "from_tensordict"], [384, 1, 1, "", "from_tuple"], [384, 1, 1, "", "fromkeys"], [384, 1, 1, "", "get"], [384, 1, 1, "", "lazy_stack"], [384, 1, 1, "", "load"], [384, 1, 1, "", "load_"], [384, 1, 1, "", "load_memmap"], [384, 1, 1, "", "load_state_dict"], [384, 1, 1, "", "maybe_dense_stack"], [384, 1, 1, "", "memmap"], [384, 1, 1, "", "memmap_"], [384, 1, 1, "", "memmap_like"], [384, 1, 1, "", "memmap_refresh_"], [384, 1, 1, "", "save"], [384, 1, 1, "", "set"], [384, 1, 1, "", "stack"], [384, 1, 1, "", "state_dict"], [384, 1, 1, "", "to_tensordict"], [384, 1, 1, "", "unbind"]], "torchrl.objectives.value": [[385, 0, 1, "", "GAE"], [386, 0, 1, "", "TD0Estimator"], [387, 0, 1, "", "TD1Estimator"], [388, 0, 1, "", "TDLambdaEstimator"], [389, 0, 1, "", "ValueEstimatorBase"]], "torchrl.objectives.value.GAE": [[385, 1, 1, "", "forward"], [385, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD0Estimator": [[386, 1, 1, "", "forward"], [386, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD1Estimator": [[387, 1, 1, "", "forward"], [387, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TDLambdaEstimator": [[388, 1, 1, "", "forward"], [388, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.ValueEstimatorBase": [[389, 4, 1, "", "default_keys"], [389, 1, 1, "", "forward"], [389, 1, 1, "", "set_keys"], [389, 1, 1, "", "value_estimate"]], "torchrl.record": [[390, 3, 1, "", "PixelRenderTransform"], [391, 3, 1, "", "TensorDictRecorder"], [392, 3, 1, "", "VideoRecorder"]], "torchrl.record.loggers": [[393, 3, 1, "", "Logger"], [395, 3, 1, "", "generate_exp_name"], [396, 3, 1, "", "get_logger"]], "torchrl.record.loggers.csv": [[394, 3, 1, "", "CSVLogger"]], "torchrl.record.loggers.mlflow": [[397, 3, 1, "", "MLFlowLogger"]], "torchrl.record.loggers.tensorboard": [[398, 3, 1, "", "TensorboardLogger"]], "torchrl.record.loggers.wandb": [[399, 3, 1, "", "WandbLogger"]], "torchrl.services": [[400, 0, 1, "", "RayService"], [401, 0, 1, "", "ServiceBase"], [402, 0, 1, "", "get_services"]], "torchrl.services.RayService": [[400, 1, 1, "", "get"], [400, 1, 1, "", "list"], [400, 1, 1, "", "register"], [400, 1, 1, "", "register_with_options"], [400, 1, 1, "", "reset"], [400, 1, 1, "", "shutdown"]], "torchrl.services.ServiceBase": [[401, 1, 1, "", "get"], [401, 1, 1, "", "list"], [401, 1, 1, "", "register"], [401, 1, 1, "", "reset"]], "torchrl.trainers": [[404, 0, 1, "", "BatchSubSampler"], [405, 0, 1, "", "ClearCudaCache"], [406, 0, 1, "", "CountFramesLog"], [407, 0, 1, "", "LogScalar"], [408, 0, 1, "", "LogValidationReward"], [409, 0, 1, "", "OptimizerHook"], [410, 0, 1, "", "ReplayBufferTrainer"], [411, 0, 1, "", "RewardNormalizer"], [412, 0, 1, "", "SelectKeys"], [413, 0, 1, "", "TargetNetUpdaterHook"], [414, 0, 1, "", "Trainer"], [415, 0, 1, "", "TrainerHookBase"], [416, 0, 1, "", "UTDRHook"], [417, 0, 1, "", "UpdateWeights"]], "torchrl.trainers.BatchSubSampler": [[404, 1, 1, "", "register"]], "torchrl.trainers.ClearCudaCache": [[405, 1, 1, "", "register"]], "torchrl.trainers.CountFramesLog": [[406, 1, 1, "", "register"]], "torchrl.trainers.LogScalar": [[407, 1, 1, "", "register"]], "torchrl.trainers.LogValidationReward": [[408, 1, 1, "", "register"]], "torchrl.trainers.OptimizerHook": [[409, 1, 1, "", "register"]], "torchrl.trainers.ReplayBufferTrainer": [[410, 1, 1, "", "register"]], "torchrl.trainers.RewardNormalizer": [[411, 1, 1, "", "register"]], "torchrl.trainers.SelectKeys": [[412, 1, 1, "", "register"]], "torchrl.trainers.TargetNetUpdaterHook": [[413, 1, 1, "", "register"]], "torchrl.trainers.Trainer": [[414, 1, 1, "", "load_from_file"]], "torchrl.trainers.TrainerHookBase": [[415, 1, 1, "", "register"]], "torchrl.trainers.UTDRHook": [[416, 1, 1, "", "load_state_dict"], [416, 1, 1, "", "register"], [416, 1, 1, "", "state_dict"]], "torchrl.trainers.UpdateWeights": [[417, 1, 1, "", "register"]], "torchrl.trainers.algorithms": [[418, 0, 1, "", "PPOTrainer"], [419, 0, 1, "", "SACTrainer"]], "torchrl.trainers.algorithms.PPOTrainer": [[418, 1, 1, "", "load_from_file"]], "torchrl.trainers.algorithms.SACTrainer": [[419, 1, 1, "", "load_from_file"]], "torchrl.trainers.algorithms.configs.collectors": [[420, 4, 1, "", "AsyncDataCollectorConfig"], [421, 4, 1, "", "SyncDataCollectorConfig"]], "torchrl.trainers.algorithms.configs.common": [[422, 0, 1, "", "ConfigBase"]], "torchrl.trainers.algorithms.configs.data": [[423, 0, 1, "", "LazyMemmapStorageConfig"], [424, 0, 1, "", "LazyStackStorageConfig"], [425, 0, 1, "", "LazyTensorStorageConfig"], [426, 0, 1, "", "ListStorageConfig"], [427, 0, 1, "", "PrioritizedSamplerConfig"], [428, 0, 1, "", "RandomSamplerConfig"], [429, 0, 1, "", "ReplayBufferConfig"], [430, 0, 1, "", "RoundRobinWriterConfig"], [431, 0, 1, "", "SamplerWithoutReplacementConfig"], [432, 0, 1, "", "SliceSamplerConfig"], [433, 0, 1, "", "SliceSamplerWithoutReplacementConfig"], [434, 0, 1, "", "StorageEnsembleConfig"], [435, 0, 1, "", "StorageEnsembleWriterConfig"], [436, 0, 1, "", "TensorDictReplayBufferConfig"], [437, 0, 1, "", "TensorStorageConfig"]], "torchrl.trainers.algorithms.configs.envs": [[438, 0, 1, "", "BatchedEnvConfig"], [439, 0, 1, "", "EnvConfig"], [440, 0, 1, "", "TransformedEnvConfig"]], "torchrl.trainers.algorithms.configs.envs_libs": [[441, 0, 1, "", "BraxEnvConfig"], [442, 0, 1, "", "DMControlEnvConfig"], [443, 0, 1, "", "EnvLibsConfig"], [444, 0, 1, "", "GymEnvConfig"], [445, 0, 1, "", "HabitatEnvConfig"], [446, 0, 1, "", "IsaacGymEnvConfig"], [447, 0, 1, "", "JumanjiEnvConfig"], [448, 0, 1, "", "MOGymEnvConfig"], [449, 0, 1, "", "MeltingpotEnvConfig"], [450, 0, 1, "", "MultiThreadedEnvConfig"], [451, 0, 1, "", "OpenMLEnvConfig"], [452, 0, 1, "", "OpenSpielEnvConfig"], [453, 0, 1, "", "PettingZooEnvConfig"], [454, 0, 1, "", "RoboHiveEnvConfig"], [455, 0, 1, "", "SMACv2EnvConfig"], [456, 0, 1, "", "UnityMLAgentsEnvConfig"], [457, 0, 1, "", "VmasEnvConfig"]], "torchrl.trainers.algorithms.configs.logging": [[458, 0, 1, "", "CSVLoggerConfig"], [459, 0, 1, "", "LoggerConfig"], [460, 0, 1, "", "TensorboardLoggerConfig"], [461, 0, 1, "", "WandbLoggerConfig"]], "torchrl.trainers.algorithms.configs.modules": [[462, 0, 1, "", "ConvNetConfig"], [463, 0, 1, "", "MLPConfig"], [464, 0, 1, "", "ModelConfig"], [465, 0, 1, "", "NetworkConfig"], [466, 0, 1, "", "TanhNormalModelConfig"], [467, 0, 1, "", "TensorDictModuleConfig"], [468, 0, 1, "", "ValueModelConfig"]], "torchrl.trainers.algorithms.configs.objectives": [[469, 0, 1, "", "LossConfig"], [470, 0, 1, "", "PPOLossConfig"]], "torchrl.trainers.algorithms.configs.trainers": [[471, 0, 1, "", "PPOTrainerConfig"], [472, 0, 1, "", "TrainerConfig"]], "torchrl.trainers.algorithms.configs.transforms": [[473, 0, 1, "", "ActionDiscretizerConfig"], [474, 0, 1, "", "ActionMaskConfig"], [475, 0, 1, "", "AutoResetTransformConfig"], [476, 0, 1, "", "BatchSizeTransformConfig"], [477, 0, 1, "", "BinarizeRewardConfig"], [478, 0, 1, "", "BurnInTransformConfig"], [479, 0, 1, "", "CatFramesConfig"], [480, 0, 1, "", "CatTensorsConfig"], [481, 0, 1, "", "CenterCropConfig"], [482, 0, 1, "", "ClipTransformConfig"], [483, 0, 1, "", "ComposeConfig"], [484, 0, 1, "", "ConditionalPolicySwitchConfig"], [485, 0, 1, "", "ConditionalSkipConfig"], [486, 0, 1, "", "CropConfig"], [487, 0, 1, "", "DTypeCastTransformConfig"], [488, 0, 1, "", "DeviceCastTransformConfig"], [489, 0, 1, "", "DiscreteActionProjectionConfig"], [490, 0, 1, "", "DoubleToFloatConfig"], [491, 0, 1, "", "EndOfLifeTransformConfig"], [492, 0, 1, "", "ExcludeTransformConfig"], [493, 0, 1, "", "FiniteTensorDictCheckConfig"], [494, 0, 1, "", "FlattenObservationConfig"], [495, 0, 1, "", "FrameSkipTransformConfig"], [496, 0, 1, "", "GrayScaleConfig"], [497, 0, 1, "", "HashConfig"], [498, 0, 1, "", "InitTrackerConfig"], [499, 0, 1, "", "KLRewardTransformConfig"], [500, 0, 1, "", "LineariseRewardsConfig"], [501, 0, 1, "", "MultiActionConfig"], [502, 0, 1, "", "MultiStepTransformConfig"], [503, 0, 1, "", "NoopResetEnvConfig"], [504, 0, 1, "", "ObservationNormConfig"], [505, 0, 1, "", "PermuteTransformConfig"], [506, 0, 1, "", "PinMemoryTransformConfig"], [507, 0, 1, "", "R3MTransformConfig"], [508, 0, 1, "", "RandomCropTensorDictConfig"], [509, 0, 1, "", "RemoveEmptySpecsConfig"], [510, 0, 1, "", "RenameTransformConfig"], [511, 0, 1, "", "ResizeConfig"], [512, 0, 1, "", "Reward2GoTransformConfig"], [513, 0, 1, "", "RewardClippingConfig"], [514, 0, 1, "", "RewardScalingConfig"], [515, 0, 1, "", "RewardSumConfig"], [516, 0, 1, "", "SelectTransformConfig"], [517, 0, 1, "", "SignTransformConfig"], [518, 0, 1, "", "SqueezeTransformConfig"], [519, 0, 1, "", "StackConfig"], [520, 0, 1, "", "StepCounterConfig"], [521, 0, 1, "", "TargetReturnConfig"], [522, 0, 1, "", "TensorDictPrimerConfig"], [523, 0, 1, "", "TimeMaxPoolConfig"], [524, 0, 1, "", "TimerConfig"], [525, 0, 1, "", "ToTensorImageConfig"], [526, 0, 1, "", "TokenizerConfig"], [527, 0, 1, "", "TrajCounterConfig"], [528, 0, 1, "", "TransformConfig"], [529, 0, 1, "", "UnaryTransformConfig"], [530, 0, 1, "", "UnsqueezeTransformConfig"], [531, 0, 1, "", "VC1TransformConfig"], [532, 0, 1, "", "VIPRewardTransformConfig"], [533, 0, 1, "", "VIPTransformConfig"], [534, 0, 1, "", "VecGymEnvTransformConfig"], [535, 0, 1, "", "VecNormConfig"], [536, 0, 1, "", "VecNormV2Config"]], "torchrl.trainers.algorithms.configs.utils": [[537, 0, 1, "", "ASGDConfig"], [538, 0, 1, "", "AdadeltaConfig"], [539, 0, 1, "", "AdagradConfig"], [540, 0, 1, "", "AdamConfig"], [541, 0, 1, "", "AdamWConfig"], [542, 0, 1, "", "AdamaxConfig"], [543, 0, 1, "", "LBFGSConfig"], [544, 0, 1, "", "LionConfig"], [545, 0, 1, "", "NAdamConfig"], [546, 0, 1, "", "RAdamConfig"], [547, 0, 1, "", "RMSpropConfig"], [548, 0, 1, "", "RpropConfig"], [549, 0, 1, "", "SGDConfig"], [550, 0, 1, "", "SparseAdamConfig"]], "torchrl.trainers.helpers": [[551, 3, 1, "", "correct_for_frame_skip"], [552, 3, 1, "", "get_stats_random_rollout"], [553, 3, 1, "", "make_collector_offpolicy"], [554, 3, 1, "", "make_collector_onpolicy"], [555, 3, 1, "", "make_dqn_loss"], [556, 3, 1, "", "make_replay_buffer"], [557, 3, 1, "", "make_target_updater"], [558, 3, 1, "", "make_trainer"], [559, 3, 1, "", "parallel_env_constructor"], [560, 3, 1, "", "sync_async_collector"], [561, 3, 1, "", "sync_sync_collector"], [562, 3, 1, "", "transformed_env_constructor"]], "torchrl.weight_update": [[563, 0, 1, "", "DistributedTransport"], [564, 0, 1, "", "DistributedWeightSyncScheme"], [565, 0, 1, "", "MPTransport"], [566, 0, 1, "", "MultiProcessWeightSyncScheme"], [567, 0, 1, "", "NoWeightSyncScheme"], [568, 0, 1, "", "RPCTransport"], [569, 0, 1, "", "RPCWeightSyncScheme"], [570, 0, 1, "", "RayModuleTransformScheme"], [571, 0, 1, "", "RayTransport"], [572, 0, 1, "", "RayWeightSyncScheme"], [573, 0, 1, "", "SharedMemTransport"], [574, 0, 1, "", "SharedMemWeightSyncScheme"], [575, 0, 1, "", "TransportBackend"], [576, 0, 1, "", "WeightStrategy"], [577, 0, 1, "", "WeightSyncScheme"]], "torchrl.weight_update.DistributedTransport": [[563, 1, 1, "", "receive_initial_weights"], [563, 1, 1, "", "receive_weights"], [563, 1, 1, "", "send_initial_weights"], [563, 1, 1, "", "send_weights"], [563, 1, 1, "", "send_weights_async"], [563, 1, 1, "", "setup_connection_and_weights_on_receiver"], [563, 1, 1, "", "setup_connection_and_weights_on_sender"], [563, 1, 1, "", "wait_ack"]], "torchrl.weight_update.DistributedWeightSyncScheme": [[564, 1, 1, "", "apply_weights"], [564, 1, 1, "", "connect"], [564, 2, 1, "", "context"], [564, 1, 1, "", "create_transport"], [564, 1, 1, "", "init_on_receiver"], [564, 1, 1, "", "init_on_sender"], [564, 2, 1, "", "model"], [564, 2, 1, "", "model_id"], [564, 1, 1, "", "prepare_weights"], [564, 1, 1, "", "receive"], [564, 2, 1, "", "receiver_transport"], [564, 1, 1, "", "send"], [564, 2, 1, "", "sender_transports"], [564, 2, 1, "", "shared_transport"], [564, 1, 1, "", "shutdown"], [564, 2, 1, "", "weights"], [564, 2, 1, "", "worker_idx"]], "torchrl.weight_update.MPTransport": [[565, 1, 1, "", "receive_weights"], [565, 1, 1, "", "send_weights_async"], [565, 1, 1, "", "setup_connection_and_weights_on_receiver"], [565, 1, 1, "", "setup_connection_and_weights_on_sender"]], "torchrl.weight_update.MultiProcessWeightSyncScheme": [[566, 1, 1, "", "apply_weights"], [566, 1, 1, "", "connect"], [566, 2, 1, "", "context"], [566, 1, 1, "", "create_transport"], [566, 1, 1, "", "init_on_receiver"], [566, 1, 1, "", "init_on_sender"], [566, 2, 1, "", "model"], [566, 2, 1, "", "model_id"], [566, 1, 1, "", "prepare_weights"], [566, 1, 1, "", "receive"], [566, 2, 1, "", "receiver_transport"], [566, 1, 1, "", "send"], [566, 2, 1, "", "sender_transports"], [566, 2, 1, "", "shared_transport"], [566, 1, 1, "", "shutdown"], [566, 2, 1, "", "weights"], [566, 2, 1, "", "worker_idx"]], "torchrl.weight_update.NoWeightSyncScheme": [[567, 1, 1, "", "apply_weights"], [567, 1, 1, "", "connect"], [567, 2, 1, "", "context"], [567, 1, 1, "", "create_transport"], [567, 1, 1, "", "init_on_receiver"], [567, 1, 1, "", "init_on_sender"], [567, 2, 1, "", "model"], [567, 2, 1, "", "model_id"], [567, 1, 1, "", "prepare_weights"], [567, 1, 1, "", "receive"], [567, 2, 1, "", "receiver_transport"], [567, 1, 1, "", "send"], [567, 2, 1, "", "sender_transports"], [567, 2, 1, "", "shared_transport"], [567, 1, 1, "", "shutdown"], [567, 2, 1, "", "weights"], [567, 2, 1, "", "worker_idx"]], "torchrl.weight_update.RPCTransport": [[568, 1, 1, "", "receive_weights"], [568, 1, 1, "", "send_weights"], [568, 1, 1, "", "send_weights_async"], [568, 1, 1, "", "setup_connection_and_weights_on_receiver"], [568, 1, 1, "", "setup_connection_and_weights_on_sender"], [568, 1, 1, "", "wait_ack"]], "torchrl.weight_update.RPCWeightSyncScheme": [[569, 1, 1, "", "apply_weights"], [569, 1, 1, "", "connect"], [569, 2, 1, "", "context"], [569, 1, 1, "", "create_transport"], [569, 1, 1, "", "init_on_receiver"], [569, 1, 1, "", "init_on_sender"], [569, 2, 1, "", "model"], [569, 2, 1, "", "model_id"], [569, 1, 1, "", "prepare_weights"], [569, 1, 1, "", "receive"], [569, 2, 1, "", "receiver_transport"], [569, 1, 1, "", "send"], [569, 2, 1, "", "sender_transports"], [569, 2, 1, "", "shared_transport"], [569, 1, 1, "", "shutdown"], [569, 2, 1, "", "weights"], [569, 2, 1, "", "worker_idx"]], "torchrl.weight_update.RayModuleTransformScheme": [[570, 1, 1, "", "apply_weights"], [570, 1, 1, "", "connect"], [570, 2, 1, "", "connection_info_name"], [570, 2, 1, "", "context"], [570, 1, 1, "", "create_transport"], [570, 1, 1, "", "init_on_receiver"], [570, 1, 1, "", "init_on_sender"], [570, 2, 1, "", "model"], [570, 2, 1, "", "model_id"], [570, 1, 1, "", "prepare_weights"], [570, 1, 1, "", "receive"], [570, 2, 1, "", "receiver_transport"], [570, 1, 1, "", "send"], [570, 2, 1, "", "sender_transports"], [570, 2, 1, "", "shared_transport"], [570, 1, 1, "", "shutdown"], [570, 2, 1, "", "weights"], [570, 2, 1, "", "worker_idx"]], "torchrl.weight_update.RayTransport": [[571, 1, 1, "", "receive_weights"], [571, 1, 1, "", "send_weights"], [571, 1, 1, "", "send_weights_async"], [571, 1, 1, "", "set_model"], [571, 1, 1, "", "setup_connection_and_weights_on_receiver"], [571, 1, 1, "", "setup_connection_and_weights_on_sender"], [571, 1, 1, "", "wait_ack"]], "torchrl.weight_update.RayWeightSyncScheme": [[572, 1, 1, "", "apply_weights"], [572, 1, 1, "", "connect"], [572, 2, 1, "", "connection_info_name"], [572, 2, 1, "", "context"], [572, 1, 1, "", "create_transport"], [572, 1, 1, "", "init_on_receiver"], [572, 1, 1, "", "init_on_sender"], [572, 2, 1, "", "model"], [572, 2, 1, "", "model_id"], [572, 1, 1, "", "prepare_weights"], [572, 1, 1, "", "receive"], [572, 2, 1, "", "receiver_transport"], [572, 1, 1, "", "send"], [572, 2, 1, "", "sender_transports"], [572, 2, 1, "", "shared_transport"], [572, 1, 1, "", "shutdown"], [572, 2, 1, "", "weights"], [572, 2, 1, "", "worker_idx"]], "torchrl.weight_update.SharedMemTransport": [[573, 1, 1, "", "receive_weights"], [573, 1, 1, "", "register_weights"], [573, 1, 1, "", "send_ack"], [573, 1, 1, "", "send_weights"], [573, 1, 1, "", "setup_connection_and_weights_on_receiver"], [573, 1, 1, "", "setup_connection_and_weights_on_sender"], [573, 2, 1, "", "unique_weights"]], "torchrl.weight_update.SharedMemWeightSyncScheme": [[574, 1, 1, "", "apply_weights"], [574, 1, 1, "", "connect"], [574, 2, 1, "", "context"], [574, 1, 1, "", "create_transport"], [574, 1, 1, "", "init_on_receiver"], [574, 1, 1, "", "init_on_sender"], [574, 2, 1, "", "model"], [574, 2, 1, "", "model_id"], [574, 1, 1, "", "prepare_weights"], [574, 1, 1, "", "receive"], [574, 2, 1, "", "receiver_transport"], [574, 1, 1, "", "send"], [574, 2, 1, "", "sender_transports"], [574, 2, 1, "", "shared_transport"], [574, 1, 1, "", "shutdown"], [574, 2, 1, "", "weights"], [574, 2, 1, "", "worker_idx"]], "torchrl.weight_update.TransportBackend": [[575, 1, 1, "", "receive_weights"], [575, 1, 1, "", "send_weights"], [575, 1, 1, "", "setup_connection_and_weights_on_receiver"], [575, 1, 1, "", "setup_connection_and_weights_on_sender"]], "torchrl.weight_update.WeightStrategy": [[576, 1, 1, "", "apply_weights"], [576, 1, 1, "", "extract_weights"]], "torchrl.weight_update.WeightSyncScheme": [[577, 1, 1, "", "apply_weights"], [577, 1, 1, "", "connect"], [577, 2, 1, "", "context"], [577, 1, 1, "", "create_transport"], [577, 1, 1, "", "init_on_receiver"], [577, 1, 1, "", "init_on_sender"], [577, 2, 1, "", "model"], [577, 2, 1, "", "model_id"], [577, 1, 1, "", "prepare_weights"], [577, 1, 1, "", "receive"], [577, 2, 1, "", "receiver_transport"], [577, 1, 1, "", "send"], [577, 2, 1, "", "sender_transports"], [577, 2, 1, "", "shared_transport"], [577, 1, 1, "", "shutdown"], [577, 2, 1, "", "weights"], [577, 2, 1, "", "worker_idx"]], "torchrl.weight_update.llm": [[578, 0, 1, "", "VLLMCollectiveTransport"], [579, 0, 1, "", "VLLMDoubleBufferSyncScheme"], [580, 0, 1, "", "VLLMDoubleBufferTransport"], [581, 0, 1, "", "VLLMDoubleBufferWeightReceiver"], [582, 0, 1, "", "VLLMDoubleBufferWeightSender"], [583, 0, 1, "", "VLLMWeightReceiver"], [584, 0, 1, "", "VLLMWeightSender"], [585, 0, 1, "", "VLLMWeightSyncScheme"], [586, 0, 1, "", "get_model_metadata"]], "torchrl.weight_update.llm.VLLMCollectiveTransport": [[578, 1, 1, "", "check_connection"], [578, 1, 1, "", "init_all_workers_group"], [578, 1, 1, "", "receive_weights"], [578, 1, 1, "", "send_weights"]], "torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme": [[579, 1, 1, "", "apply_weights"], [579, 1, 1, "", "connect"], [579, 2, 1, "", "context"], [579, 1, 1, "", "create_receiver"], [579, 1, 1, "", "create_sender"], [579, 1, 1, "", "create_transport"], [579, 1, 1, "", "init_on_receiver"], [579, 1, 1, "", "init_on_sender"], [579, 2, 1, "", "model"], [579, 2, 1, "", "model_id"], [579, 1, 1, "", "prepare_weights"], [579, 1, 1, "", "receive"], [579, 2, 1, "", "receiver_transport"], [579, 1, 1, "", "send"], [579, 2, 1, "", "sender_transports"], [579, 2, 1, "", "shared_transport"], [579, 1, 1, "", "shutdown"], [579, 2, 1, "", "weights"], [579, 2, 1, "", "worker_idx"]], "torchrl.weight_update.llm.VLLMDoubleBufferTransport": [[580, 1, 1, "", "check_connection"], [580, 1, 1, "", "receive_weights"], [580, 1, 1, "", "send_weights"]], "torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver": [[581, 1, 1, "", "apply_weights"], [581, 1, 1, "", "poll_and_apply"]], "torchrl.weight_update.llm.VLLMDoubleBufferWeightSender": [[582, 1, 1, "", "register_model"], [582, 1, 1, "", "update_weights"]], "torchrl.weight_update.llm.VLLMWeightReceiver": [[583, 1, 1, "", "apply_weights"], [583, 1, 1, "", "init_all_workers_group"], [583, 1, 1, "", "poll_and_apply"]], "torchrl.weight_update.llm.VLLMWeightSender": [[584, 1, 1, "", "init_all_workers_group"], [584, 1, 1, "", "register_model"], [584, 1, 1, "", "update_weights"]], "torchrl.weight_update.llm.VLLMWeightSyncScheme": [[585, 1, 1, "", "apply_weights"], [585, 1, 1, "", "connect"], [585, 2, 1, "", "context"], [585, 1, 1, "", "create_receiver"], [585, 1, 1, "", "create_sender"], [585, 1, 1, "", "create_transport"], [585, 1, 1, "", "init_on_receiver"], [585, 1, 1, "", "init_on_sender"], [585, 2, 1, "", "model"], [585, 2, 1, "", "model_id"], [585, 1, 1, "", "prepare_weights"], [585, 1, 1, "", "receive"], [585, 2, 1, "", "receiver_transport"], [585, 1, 1, "", "send"], [585, 2, 1, "", "sender_transports"], [585, 2, 1, "", "shared_transport"], [585, 1, 1, "", "shutdown"], [585, 2, 1, "", "weights"], [585, 2, 1, "", "worker_idx"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:property", "3": "py:function", "4": "py:attribute"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "property", "Python property"], "3": ["py", "function", "Python function"], "4": ["py", "attribute", "Python attribute"]}, "titleterms": {"torchrl": [0, 1, 7, 10, 16, 17, 25, 28, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 597, 604, 612, 616, 618, 619, 620, 622, 624, 630, 631, 633, 634, 635, 639, 640], "instal": [0, 25, 26, 630, 639], "get": [0, 7, 611, 623, 624, 625, 626, 627, 628], "start": [0, 7, 611, 623, 624, 625, 626, 627, 628, 630], "tutori": [0, 620, 633, 634], "basic": [0, 2, 7, 611, 613, 630, 637], "intermedi": [0, 27], "advanc": [0, 611], "refer": [0, 588, 611], "knowledg": [0, 589], "base": [0, 7, 17, 26, 589, 590, 602, 610, 622], "indic": 0, "tabl": 0, "collector": [1, 2, 3, 4, 5, 6, 34, 420, 421, 591, 618, 619, 620, 621, 626, 628, 633, 634, 639], "packag": [1, 10, 16, 597, 604, 612, 616], "multicollector": [1, 5, 36], "api": [1, 17, 588, 611], "kei": [1, 10, 16, 21, 590, 597, 604, 611, 612], "featur": [1, 10, 16, 597, 604, 611, 612], "quick": [1, 7, 10, 16, 590, 597, 604, 612], "exampl": [1, 6, 7, 10, 16, 22, 30, 590, 597, 604, 611, 612, 619, 631, 637], "legaci": [1, 3, 6, 590], "name": [1, 3], "document": [1, 10, 16, 28, 590, 597, 604, 612], "section": [1, 10, 16, 590, 597, 604, 612], "batch": [2, 17, 22, 618, 635, 637], "size": [2, 17, 618, 637], "polici": [2, 23, 590, 609, 618, 620, 621, 622, 624, 628, 632, 633, 634, 635], "copi": 2, "distribut": [3, 600], "replai": [4, 7, 12, 21, 618, 619, 620, 621, 626, 628, 633, 634, 637, 639], "buffer": [4, 7, 12, 21, 618, 619, 620, 621, 626, 628, 633, 634, 637, 639], "interoper": 4, "helper": [4, 17, 603, 630], "function": [4, 23, 590, 619, 620, 625, 633, 634, 639], "singl": [5, 23], "node": 5, "data": [5, 7, 10, 12, 23, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 592, 594, 618, 619, 620, 626, 628, 633, 634, 639], "us": [5, 6, 21, 23, 25, 28, 621, 636, 637, 639], "run": [5, 7, 622, 623, 640], "asynchron": 5, "weight": [6, 590, 591], "synchron": [6, 591], "lifecycl": 6, "phase": 6, "1": [6, 26, 630, 631], "initi": 6, "No": 6, "commun": 6, "2": [6, 26, 630, 631], "connect": 6, "rendez": 6, "vou": 6, "3": [6, 630, 631], "ongo": 6, "updat": [6, 590, 618], "scheme": [6, 591], "specif": [6, 17, 590, 613, 632], "behavior": 6, "sharedmemweightsyncschem": [6, 574], "multiprocessweightsyncschem": [6, 566], "distributedweightsyncschem": [6, 564], "rpcweightsyncschem": [6, 569], "rayweightsyncschem": [6, 572], "raymoduletransformschem": [6, 570], "background": 6, "thread": 6, "architectur": [6, 590], "usag": [6, 7, 611], "sync": [6, 639], "standalon": 6, "transport": 6, "interfac": [6, 590], "timeout": 6, "support": [6, 12], "avail": [6, 7, 18, 21], "configur": [7, 611, 630], "system": [7, 14], "simpl": [7, 622, 635], "categori": 7, "group": [7, 633], "more": [7, 637], "complex": [7, 637], "parallel": [7, 22, 618, 632, 640], "environ": [7, 17, 18, 19, 21, 22, 23, 25, 26, 590, 593, 618, 619, 620, 621, 623, 628, 630, 631, 632, 633, 634, 635, 639, 640], "transform": [7, 21, 271, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 590, 596, 618, 620, 623, 631, 633, 634, 635, 637, 639, 640], "option": [7, 26, 611], "complet": 7, "train": [7, 23, 27, 614, 618, 620, 621, 622, 625, 628, 633, 634, 635], "experi": [7, 618, 635], "hyperparamet": [7, 619, 620, 633, 634], "sweep": 7, "custom": [7, 17, 30, 611, 635, 637], "file": 7, "store": [7, 619, 637], "implement": [7, 23], "detail": [7, 22], "class": [7, 12, 17, 22, 592, 594, 600, 635, 639], "librari": [7, 18, 639], "model": [7, 23, 602, 618, 619, 621, 622, 625, 636, 639], "network": [7, 599, 618, 619, 620, 621, 624, 633, 634], "collect": [7, 619, 620, 626], "storag": [7, 12, 15, 110, 618, 626, 637], "optim": [7, 23, 618, 619, 625, 628], "log": [7, 458, 459, 460, 461, 627, 631], "creat": [7, 623], "best": [7, 611], "practic": [7, 611], "futur": 7, "extens": 7, "dataset": 11, "core": [12, 590], "compos": [12, 225], "type": 12, "choos": 12, "sampl": [12, 13, 637], "index": 12, "strategi": [13, 601], "writer": [13, 118], "tensorspec": [14, 74], "backend": 15, "perform": [15, 611, 630], "env": [16, 17, 438, 439, 440, 635, 639, 640], "spec": [17, 18, 21, 635, 640], "lock": [17, 22], "method": [17, 605, 607, 609, 610, 618], "nativ": 17, "domain": 17, "wrapper": [18, 590, 594, 624, 631], "auto": 18, "reset": [18, 22, 635, 640], "dynam": [18, 23, 637], "multi": [19, 632, 633, 634], "agent": [19, 23, 633, 634], "record": [20, 615, 618, 627], "video": [20, 30, 627], "forward": [21, 23, 618], "invers": 21, "understand": 21, "tensor": [21, 637], "expos": 21, "outsid": 21, "world": [21, 602], "design": [21, 590, 628], "your": [21, 23, 25, 618, 622, 628, 635], "own": [21, 628], "tip": 21, "subclass": 21, "clone": [21, 26], "mask": [21, 328], "action": [21, 23, 621, 635], "vector": [22, 639], "partial": 22, "step": [22, 618, 620, 623, 626, 630, 633, 634, 637, 640], "async": [22, 639], "thing": [23, 618, 635], "consid": 23, "when": [23, 26], "debug": 23, "rl": [23, 28, 602, 607, 623, 625, 631, 639], "gener": [23, 30], "have": 23, "you": 23, "valid": [23, 631], "algorithm": [23, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 613], "few": 23, "small": 23, "toi": 23, "problem": 23, "known": 23, "return": 23, "e": 23, "g": 23, "gridworld": 23, "mountaincar": 23, "visual": 23, "Be": 23, "veri": 23, "care": 23, "ani": 23, "augment": 23, "doe": 23, "entropi": 23, "converg": 23, "too": [23, 27], "quickli": 23, "slowli": 23, "chang": [23, 639], "drastic": 23, "reward": [23, 590, 592], "beyond": 23, "go": 23, "up": [23, 25], "Is": 23, "favor": 23, "compon": [23, 590, 606], "i": 23, "veloc": 23, "vs": 23, "l2": 23, "magnitud": 23, "task": [23, 590, 632], "horizon": 23, "extrem": 23, "long": 23, "ar": 23, "normal": [23, 618, 619, 620], "standard": 23, "explor": [23, 601, 618, 619, 624, 631], "valu": [23, 598, 599, 606, 610, 618, 620, 621, 624], "loss": [23, 608, 618, 619, 620, 621, 628, 633, 634], "earli": 23, "roughli": 23, "uniformli": 23, "random": [23, 633, 634], "intrins": 23, "decai": 23, "learn": [23, 620, 633, 634], "progress": 23, "singleton": 23, "episod": 23, "remain": 23, "constant": [23, 619], "increas": 23, "an": [23, 620, 621, 623, 635], "can": 23, "low": 23, "also": [23, 611], "offlin": [23, 607], "observ": [23, 618], "space": 23, "effect": [23, 635], "dramat": 23, "dure": [23, 26], "high": 23, "dimension": 23, "work": [24, 25, 26, 611, 622], "gym": [24, 639, 640], "what": 24, "openai": 24, "version": [24, 26, 29, 590], "habitat": 25, "lab": 25, "set": [25, 30], "from": [25, 26], "pip": [25, 26], "common": [25, 26, 27, 422, 606], "issu": [25, 26, 29], "mujoco": 26, "prerequisit": [26, 618], "render": [26, 30, 628, 633, 634, 640], "all": 26, "new": 26, "bindindg": 26, "old": 26, "bind": 26, "py": 26, "repo": [26, 28], "import": [26, 618, 631], "pytorch": [27, 28, 29, 622], "error": [27, 631], "solut": 27, "gradient": [27, 609], "relat": 27, "newcom": 27, "my": 27, "slow": 27, "bug": 27, "resourc": 28, "paper": 28, "functorch": 28, "blog": 28, "websit": 28, "educ": 28, "forum": 28, "how": [29, 611], "reproduc": [29, 635], "workaround": 29, "customis": 30, "tweak": 30, "principl": 30, "auto_unwrap_transformed_env": 31, "asynccollector": 32, "basecollector": 33, "multiasynccollector": 35, "multiprocessedweightupdat": 37, "multisynccollector": 38, "rayweightupdat": 39, "vanillaweightupdat": 40, "weightupdaterbas": 41, "distributedcollector": 42, "distributeddatacollector": 43, "distributedsynccollector": 44, "distributedsyncdatacollector": 45, "distributedweightupdat": 46, "rpccollector": 47, "rpcdatacollector": 48, "rpcweightupdat": 49, "raycollector": 50, "submitit_delayed_launch": 51, "llmcollector": 52, "rayllmcollector": 53, "vllmupdat": 54, "vllmupdaterv2": 55, "split_trajectori": 56, "binari": [57, 622], "bound": 58, "categor": 59, "composit": 60, "multicategor": 61, "multionehot": 62, "nontensor": 63, "onehot": 64, "prioritizedreplaybuff": 65, "rayreplaybuff": 66, "remotetensordictreplaybuff": 67, "replaybuff": 68, "replaybufferensembl": 69, "stack": [70, 262], "stackedcomposit": 71, "tensordictprioritizedreplaybuff": 72, "tensordictreplaybuff": 73, "unbound": 75, "unboundedcontinu": 76, "unboundeddiscret": 77, "ataridqnexperiencereplai": 78, "d4rlexperiencereplai": 79, "gendgrlexperiencereplai": 80, "minariexperiencereplai": 81, "openmlexperiencereplai": 82, "openxexperiencereplai": 83, "robosetexperiencereplai": 84, "vd4rlexperiencereplai": 85, "contentbas": 86, "histori": [87, 592, 631], "topkrewardselector": 88, "add_chat_templ": 89, "compressedliststorag": 90, "compressedliststoragecheckpoint": 91, "flatstoragecheckpoint": 92, "h5storagecheckpoint": 93, "immutabledatasetwrit": 94, "lazymemmapstorag": 95, "lazystackstorag": 96, "lazytensorstorag": 97, "liststorag": 98, "liststoragecheckpoint": 99, "nestedstoragecheckpoint": 100, "prioritizedsampl": 101, "prioritizedslicesampl": 102, "randomsampl": 103, "roundrobinwrit": 104, "sampler": 105, "samplerensembl": 106, "samplerwithoutreplac": 107, "slicesampl": 108, "slicesamplerwithoutreplac": 109, "storagecheckpointerbas": 111, "storageensembl": 112, "storageensemblecheckpoint": 113, "tensordictmaxvaluewrit": 114, "tensordictroundrobinwrit": 115, "tensorstorag": 116, "tensorstoragecheckpoint": 117, "writerensembl": 119, "asyncenvpool": 120, "braxenv": 121, "braxwrapp": 122, "chessenv": 123, "dmcontrolenv": 124, "dmcontrolwrapp": 125, "envbas": [126, 635], "envcreat": 127, "envmetadata": 128, "gymenv": 129, "gymlikeenv": 130, "gymwrapp": 131, "habitatenv": 132, "isaacgymenv": 133, "isaacgymwrapp": 134, "isaaclabwrapp": 135, "jumanjienv": 136, "jumanjiwrapp": 137, "llmhashingenv": [138, 179], "mogymenv": 139, "mogymwrapp": 140, "marlgroupmaptyp": 141, "meltingpotenv": 142, "meltingpotwrapp": 143, "modelbasedenvbas": 144, "multithreadedenv": 145, "multithreadedenvwrapp": 146, "openmlenv": 147, "openspielenv": 148, "openspielwrapp": 149, "parallelenv": 150, "pendulumenv": 151, "pettingzooenv": 152, "pettingzoowrapp": 153, "processorasyncenvpool": 154, "robohiveenv": 155, "smacv2env": 156, "smacv2wrapp": 157, "serialenv": 158, "threadingasyncenvpool": 159, "tictactoeenv": 160, "unitymlagentsenv": 161, "unitymlagentswrapp": 162, "vmasenv": 163, "vmaswrapp": 164, "check_env_spec": 165, "check_marl_group": 166, "exploration_typ": 167, "get_available_librari": 168, "gym_backend": 169, "chatenv": [170, 590], "datasetchatenv": 171, "gsm8kenv": 172, "gsm8kpreparequest": 173, "gsm8krewardpars": 174, "ifevalenv": 175, "ifevalscoredata": 176, "ifevalscor": 177, "llmenv": 178, "mlgymwrapp": 180, "make_gsm8k_env": 181, "make_mlgym": 182, "addthinkingprompt": 183, "browsertransform": 184, "dataloadingprim": 185, "executetoolsinord": 186, "jsoncallpars": 187, "klcomput": 188, "klrewardtransform": [189, 241], "mcptooltransform": 190, "policyvers": 191, "pythonexecutorservic": 192, "pythoninterpret": 193, "raydataloadingprim": 194, "retrievekl": 195, "retrievelogprob": 196, "simpletooltransform": 197, "templatetransform": 198, "token": [199, 269, 331], "toolcal": 200, "toolregistri": 201, "toolservic": 202, "xmlblockpars": 203, "as_nested_tensor": 204, "as_padded_tensor": 205, "make_composite_from_td": 206, "dreamerdecod": 207, "dreamerenv": 208, "register_gym_spec_convers": 209, "set_exploration_typ": 210, "set_gym_backend": 211, "step_mdp": 212, "terminated_or_trunc": 213, "actiondiscret": 214, "actionmask": 215, "autoresetenv": 216, "autoresettransform": 217, "batchsizetransform": 218, "binarizereward": 219, "burnintransform": 220, "catfram": [221, 637], "cattensor": 222, "centercrop": 223, "cliptransform": 224, "conditionalpolicyswitch": 226, "conditionalskip": 227, "crop": 228, "dtypecasttransform": 229, "devicecasttransform": 230, "discreteactionproject": 231, "doubletofloat": 232, "endoflifetransform": 233, "excludetransform": 234, "finitetensordictcheck": 235, "flattenobserv": 236, "frameskiptransform": 237, "grayscal": 238, "hash": 239, "inittrack": 240, "linearisereward": 242, "moduletransform": 243, "multiact": 244, "noopresetenv": 245, "observationnorm": 246, "observationtransform": 247, "permutetransform": 248, "pinmemorytransform": 249, "r3mtransform": 250, "randomcroptensordict": 251, "removeemptyspec": 252, "renametransform": 253, "resiz": 254, "reward2gotransform": 255, "rewardclip": 256, "rewardsc": 257, "rewardsum": 258, "selecttransform": 259, "signtransform": 260, "squeezetransform": 261, "stepcount": 263, "targetreturn": 264, "tensordictprim": 265, "timemaxpool": 266, "timer": 267, "totensorimag": 268, "trajcount": 270, "transformedenv": 272, "unarytransform": 273, "unsqueezetransform": 274, "vc1transform": 275, "viprewardtransform": 276, "viptransform": 277, "vecgymenvtransform": 278, "vecnorm": [279, 640], "vecnormv2": 280, "gsdenois": 281, "implement_for": 282, "actorcriticoper": 283, "actorcriticwrapp": 284, "actorvalueoper": 285, "additivegaussianmodul": 286, "consistentdropoutmodul": 287, "convnet": 288, "dtactor": 289, "ddpgcnnactor": 290, "ddpgcnnqnet": 291, "ddpgmlpactor": 292, "ddpgmlpqnet": 293, "decisiontransform": 294, "delta": 295, "distributionaldqnnet": 296, "distributionalqvalueactor": 297, "distributionalqvaluemodul": 298, "dreameractor": 299, "duelingcnndqnet": 300, "egreedymodul": 301, "grumodul": 302, "independentnorm": 303, "lstmmodul": 304, "mlp": [305, 621], "maskedcategor": 306, "normalparamextractor": 307, "obsdecod": 308, "obsencod": 309, "onehotcategor": 310, "onlinedtactor": 311, "ornsteinuhlenbeckprocessmodul": 312, "qvalueactor": 313, "qvaluemodul": 314, "rssmposterior": 315, "rssmprior": 316, "rssmrollout": 317, "reparamgradientstrategi": 318, "tanhdelta": 319, "tanhnorm": 320, "truncatednorm": 321, "valueoper": 322, "worldmodelwrapp": 323, "asyncvllm": 324, "chathistori": 325, "llmwrapperbas": 326, "logprob": 327, "remotetransformerswrapp": 329, "text": [330, 631], "transformerswrapp": 332, "make_async_vllm_engin": 333, "make_vllm_work": 334, "stateless_init_process_group": 335, "stateless_init_process_group_async": 336, "vllmwrapper": 337, "squashdim": 338, "actor": [339, 598, 605, 618, 624], "multistepactorwrapp": 340, "probabilisticactor": 341, "randompolici": 342, "safemodul": [343, 598], "safeprobabilisticmodul": 344, "safeprobabilistictensordictsequenti": 345, "safesequenti": 346, "tanhmodul": 347, "a2closs": 348, "cqlloss": 349, "clipppoloss": 350, "crossqloss": 351, "ddpgloss": 352, "dqnloss": 353, "dtloss": 354, "discretecqlloss": 355, "discreteiqlloss": 356, "discretesacloss": 357, "distributionaldqnloss": 358, "dreameractorloss": 359, "dreamermodelloss": 360, "dreamervalueloss": 361, "gailloss": 362, "iqlloss": 363, "klpenppoloss": 364, "lossmodul": [365, 618, 625], "onlinedtloss": 366, "ppoloss": 367, "redqloss": 368, "reinforceloss": 369, "sacloss": 370, "td3bcloss": 371, "td3loss": 372, "valueestim": 373, "add_random_modul": 374, "cispoloss": 375, "cispolossoutput": 376, "dapo": 377, "dapolossoutput": 378, "grpoloss": 379, "grpolossoutput": 380, "llmlossoutput": 381, "mcadvantag": 382, "sftloss": 383, "sftlossoutput": 384, "gae": 385, "td0estim": 386, "td1estim": 387, "tdlambdaestim": 388, "valueestimatorbas": 389, "pixelrendertransform": 390, "tensordictrecord": 391, "videorecord": 392, "logger": [393, 615, 627, 628], "csvlogger": 394, "generate_exp_nam": 395, "get_logg": 396, "mlflowlogg": 397, "tensorboardlogg": 398, "wandblogg": 399, "rayservic": 400, "servicebas": 401, "get_servic": 402, "set_auto_unwrap_transformed_env": 403, "batchsubsampl": 404, "clearcudacach": 405, "countframeslog": 406, "logscalar": 407, "logvalidationreward": 408, "optimizerhook": 409, "replaybuffertrain": 410, "rewardnorm": 411, "selectkei": 412, "targetnetupdaterhook": 413, "trainer": [414, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 612, 613, 619], "trainerhookbas": 415, "utdrhook": 416, "updateweight": 417, "ppotrain": 418, "sactrain": 419, "config": [420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 639], "asyncdatacollectorconfig": 420, "syncdatacollectorconfig": 421, "configbas": 422, "lazymemmapstorageconfig": 423, "lazystackstorageconfig": 424, "lazytensorstorageconfig": 425, "liststorageconfig": 426, "prioritizedsamplerconfig": 427, "randomsamplerconfig": 428, "replaybufferconfig": 429, "roundrobinwriterconfig": 430, "samplerwithoutreplacementconfig": 431, "slicesamplerconfig": 432, "slicesamplerwithoutreplacementconfig": 433, "storageensembleconfig": 434, "storageensemblewriterconfig": 435, "tensordictreplaybufferconfig": 436, "tensorstorageconfig": 437, "batchedenvconfig": 438, "envconfig": 439, "transformedenvconfig": 440, "envs_lib": [441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457], "braxenvconfig": 441, "dmcontrolenvconfig": 442, "envlibsconfig": 443, "gymenvconfig": 444, "habitatenvconfig": 445, "isaacgymenvconfig": 446, "jumanjienvconfig": 447, "mogymenvconfig": 448, "meltingpotenvconfig": 449, "multithreadedenvconfig": 450, "openmlenvconfig": 451, "openspielenvconfig": 452, "pettingzooenvconfig": 453, "robohiveenvconfig": 454, "smacv2envconfig": 455, "unitymlagentsenvconfig": 456, "vmasenvconfig": 457, "csvloggerconfig": 458, "loggerconfig": 459, "tensorboardloggerconfig": 460, "wandbloggerconfig": 461, "modul": [462, 463, 464, 465, 466, 467, 468, 597, 598, 608, 618, 621, 622, 624, 628, 639], "convnetconfig": 462, "mlpconfig": 463, "modelconfig": 464, "networkconfig": 465, "tanhnormalmodelconfig": 466, "tensordictmoduleconfig": 467, "valuemodelconfig": 468, "object": [469, 470, 590, 595, 604, 618, 625, 639], "lossconfig": 469, "ppolossconfig": 470, "ppotrainerconfig": 471, "trainerconfig": 472, "actiondiscretizerconfig": 473, "actionmaskconfig": 474, "autoresettransformconfig": 475, "batchsizetransformconfig": 476, "binarizerewardconfig": 477, "burnintransformconfig": 478, "catframesconfig": 479, "cattensorsconfig": 480, "centercropconfig": 481, "cliptransformconfig": 482, "composeconfig": 483, "conditionalpolicyswitchconfig": 484, "conditionalskipconfig": 485, "cropconfig": 486, "dtypecasttransformconfig": 487, "devicecasttransformconfig": 488, "discreteactionprojectionconfig": 489, "doubletofloatconfig": 490, "endoflifetransformconfig": 491, "excludetransformconfig": 492, "finitetensordictcheckconfig": 493, "flattenobservationconfig": 494, "frameskiptransformconfig": 495, "grayscaleconfig": 496, "hashconfig": 497, "inittrackerconfig": 498, "klrewardtransformconfig": 499, "lineariserewardsconfig": 500, "multiactionconfig": 501, "multisteptransformconfig": 502, "noopresetenvconfig": 503, "observationnormconfig": 504, "permutetransformconfig": 505, "pinmemorytransformconfig": 506, "r3mtransformconfig": 507, "randomcroptensordictconfig": 508, "removeemptyspecsconfig": 509, "renametransformconfig": 510, "resizeconfig": 511, "reward2gotransformconfig": 512, "rewardclippingconfig": 513, "rewardscalingconfig": 514, "rewardsumconfig": 515, "selecttransformconfig": 516, "signtransformconfig": 517, "squeezetransformconfig": 518, "stackconfig": 519, "stepcounterconfig": 520, "targetreturnconfig": 521, "tensordictprimerconfig": 522, "timemaxpoolconfig": 523, "timerconfig": 524, "totensorimageconfig": 525, "tokenizerconfig": 526, "trajcounterconfig": 527, "transformconfig": 528, "unarytransformconfig": 529, "unsqueezetransformconfig": 530, "vc1transformconfig": 531, "viprewardtransformconfig": 532, "viptransformconfig": 533, "vecgymenvtransformconfig": 534, "vecnormconfig": 535, "vecnormv2config": 536, "util": [537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 594, 603, 613, 615, 633], "asgdconfig": 537, "adadeltaconfig": 538, "adagradconfig": 539, "adamconfig": 540, "adamwconfig": 541, "adamaxconfig": 542, "lbfgsconfig": 543, "lionconfig": 544, "nadamconfig": 545, "radamconfig": 546, "rmspropconfig": 547, "rpropconfig": 548, "sgdconfig": 549, "sparseadamconfig": 550, "correct_for_frame_skip": 551, "get_stats_random_rollout": 552, "make_collector_offpolici": 553, "make_collector_onpolici": 554, "make_dqn_loss": 555, "make_replay_buff": 556, "make_target_updat": 557, "make_train": 558, "parallel_env_constructor": 559, "sync_async_collector": 560, "sync_sync_collector": 561, "transformed_env_constructor": 562, "distributedtransport": 563, "mptransport": 565, "noweightsyncschem": 567, "rpctransport": 568, "raytransport": 571, "sharedmemtransport": 573, "transportbackend": 575, "weightstrategi": 576, "weightsyncschem": 577, "vllmcollectivetransport": 578, "vllmdoublebuffersyncschem": 579, "vllmdoublebuffertransport": 580, "vllmdoublebufferweightreceiv": 581, "vllmdoublebufferweightsend": 582, "vllmweightreceiv": 583, "vllmweightsend": 584, "vllmweightsyncschem": 585, "get_model_metadata": 586, "readm": [587, 629], "tuto": [587, 629], "contribut": [589, 639], "content": 589, "llm": [590, 591, 593, 594, 595, 596, 630, 631], "track": 590, "deprec": 590, "integr": [590, 631, 637], "structur": [592, 594, 631, 637], "topk": 592, "selector": 592, "grpo": 595, "sft": 595, "tensordictmodul": [598, 622, 624, 639], "probabilist": [598, 624], "q": [598, 619, 621, 624], "critic": [599, 605, 633, 634], "estim": [606, 618], "other": [608, 637], "servic": 611, "registri": 611, "overview": [611, 618, 621], "registr": 611, "access": [611, 640], "cross": 611, "worker": 611, "visibl": 611, "namespac": 611, "isol": 611, "cleanup": 611, "python": 611, "executor": 611, "condit": 611, "pattern": 611, "It": 611, "consider": [611, 625], "multipl": 611, "see": 611, "hook": [613, 614, 619], "builder": 613, "_util": 616, "comput": [617, 619, 635, 638], "time": [617, 618, 638], "code": [618, 635], "ddpg": [618, 633], "setup": [618, 621, 630, 631], "The": 618, "__init__": 618, "put": 618, "togeth": [618, 635], "call": 618, "execut": [618, 630, 632, 635], "stat": 618, "build": [618, 619, 628, 630, 637], "evalu": 618, "construct": 618, "target": [618, 619, 625], "result": [618, 620, 630, 633, 634], "conclus": [618, 619, 620, 621, 622, 630, 631, 633, 634, 635, 637], "next": [618, 620, 623, 626, 633, 634, 637], "A": [619, 637], "dqn": [619, 621], "deep": 619, "paramet": [619, 620, 625], "regist": 619, "possibl": 619, "improv": 619, "reinforc": [620, 633, 634], "ppo": [620, 634], "defin": [620, 633, 634], "loop": [620, 621, 622, 628, 633, 634, 635], "recurr": [621, 622], "convolut": 621, "lstm": 621, "select": 621, "further": [621, 625], "read": 621, "export": 622, "introduct": [622, 639], "fast": 622, "recap": 622, "stochast": 622, "aotinductor": 622, "free": 622, "c": 622, "onnx": 622, "rollout": [622, 623, 632, 633, 634, 635, 640], "ted": 623, "s": [624, 625], "special": [624, 639], "output": 625, "first": 628, "tool": 630, "enabl": 630, "interact": 630, "4": [630, 631], "search": 630, "5": [630, 631], "extract": 630, "vllm": 631, "input": 631, "mode": 631, "probabl": 631, "onli": 631, "tensorclass": [631, 637], "6": 631, "handl": 631, "7": 631, "divers": 632, "competit": 633, "map": 633, "pendulum": 635, "write": 635, "_step": 635, "simul": 635, "_reset": 635, "metadata": 635, "_spec": 635, "shape": 635, "seed": [635, 640], "wrap": 635, "test": 635, "our": 635, "pretrain": 636, "vanilla": 637, "tensordict": [637, 639], "pytre": 637, "iter": 637, "over": 637, "fix": 637, "priorit": 637, "save": 637, "raw": 637, "imag": 637, "trajectori": 637, "sequenc": 639, "program": 639, "ensembl": 639, "meta": 639, "vmap": 639, "multiprocess": 639, "frame_skip": 640, "deepmind": 640, "control": 640, "devic": 640, "close": 640, "attribut": 640, "kwarg": 640}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 56}})
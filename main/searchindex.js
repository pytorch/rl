Search.setIndex({"docnames": ["index", "reference/collectors", "reference/collectors_basics", "reference/collectors_distributed", "reference/collectors_replay", "reference/collectors_single", "reference/collectors_weightsync", "reference/config", "reference/cudnn_persistent_rnn", "reference/cudnn_rnn_determinism", "reference/data", "reference/data_datasets", "reference/data_replaybuffers", "reference/data_samplers", "reference/data_specs", "reference/data_storage", "reference/envs", "reference/envs_api", "reference/envs_libraries", "reference/envs_multiagent", "reference/envs_recorders", "reference/envs_transforms", "reference/envs_vectorized", "reference/generated/knowledge_base/DEBUGGING_RL", "reference/generated/knowledge_base/GYM", "reference/generated/knowledge_base/HABITAT", "reference/generated/knowledge_base/MUJOCO_INSTALLATION", "reference/generated/knowledge_base/PRO-TIPS", "reference/generated/knowledge_base/RESOURCES", "reference/generated/knowledge_base/VERSIONING_ISSUES", "reference/generated/knowledge_base/VIDEO_CUSTOMISATION", "reference/generated/torchrl.auto_unwrap_transformed_env", "reference/generated/torchrl.collectors.AsyncCollector", "reference/generated/torchrl.collectors.BaseCollector", "reference/generated/torchrl.collectors.Collector", "reference/generated/torchrl.collectors.MultiAsyncCollector", "reference/generated/torchrl.collectors.MultiCollector", "reference/generated/torchrl.collectors.MultiProcessedWeightUpdater", "reference/generated/torchrl.collectors.MultiSyncCollector", "reference/generated/torchrl.collectors.RayWeightUpdater", "reference/generated/torchrl.collectors.VanillaWeightUpdater", "reference/generated/torchrl.collectors.WeightUpdaterBase", "reference/generated/torchrl.collectors.distributed.DistributedCollector", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedSyncCollector", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedWeightUpdater", "reference/generated/torchrl.collectors.distributed.RPCCollector", "reference/generated/torchrl.collectors.distributed.RPCDataCollector", "reference/generated/torchrl.collectors.distributed.RPCWeightUpdater", "reference/generated/torchrl.collectors.distributed.RayCollector", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher", "reference/generated/torchrl.collectors.llm.LLMCollector", "reference/generated/torchrl.collectors.llm.RayLLMCollector", "reference/generated/torchrl.collectors.llm.vLLMUpdater", "reference/generated/torchrl.collectors.llm.vLLMUpdaterV2", "reference/generated/torchrl.collectors.utils.split_trajectories", "reference/generated/torchrl.data.Binary", "reference/generated/torchrl.data.Bounded", "reference/generated/torchrl.data.Categorical", "reference/generated/torchrl.data.Composite", "reference/generated/torchrl.data.MultiCategorical", "reference/generated/torchrl.data.MultiOneHot", "reference/generated/torchrl.data.NonTensor", "reference/generated/torchrl.data.OneHot", "reference/generated/torchrl.data.PrioritizedReplayBuffer", "reference/generated/torchrl.data.RayReplayBuffer", "reference/generated/torchrl.data.RemoteTensorDictReplayBuffer", "reference/generated/torchrl.data.ReplayBuffer", "reference/generated/torchrl.data.ReplayBufferEnsemble", "reference/generated/torchrl.data.Stacked", "reference/generated/torchrl.data.StackedComposite", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer", "reference/generated/torchrl.data.TensorDictReplayBuffer", "reference/generated/torchrl.data.TensorSpec", "reference/generated/torchrl.data.Unbounded", "reference/generated/torchrl.data.UnboundedContinuous", "reference/generated/torchrl.data.UnboundedDiscrete", "reference/generated/torchrl.data.datasets.AtariDQNExperienceReplay", "reference/generated/torchrl.data.datasets.D4RLExperienceReplay", "reference/generated/torchrl.data.datasets.GenDGRLExperienceReplay", "reference/generated/torchrl.data.datasets.MinariExperienceReplay", "reference/generated/torchrl.data.datasets.OpenMLExperienceReplay", "reference/generated/torchrl.data.datasets.OpenXExperienceReplay", "reference/generated/torchrl.data.datasets.RobosetExperienceReplay", "reference/generated/torchrl.data.datasets.VD4RLExperienceReplay", "reference/generated/torchrl.data.llm.ContentBase", "reference/generated/torchrl.data.llm.History", "reference/generated/torchrl.data.llm.TopKRewardSelector", "reference/generated/torchrl.data.llm.add_chat_template", "reference/generated/torchrl.data.replay_buffers.CompressedListStorage", "reference/generated/torchrl.data.replay_buffers.CompressedListStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.FlatStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.H5StorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.ImmutableDatasetWriter", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage", "reference/generated/torchrl.data.replay_buffers.LazyStackStorage", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage", "reference/generated/torchrl.data.replay_buffers.ListStorage", "reference/generated/torchrl.data.replay_buffers.ListStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.NestedStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler", "reference/generated/torchrl.data.replay_buffers.PrioritizedSliceSampler", "reference/generated/torchrl.data.replay_buffers.RandomSampler", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.Sampler", "reference/generated/torchrl.data.replay_buffers.SamplerEnsemble", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.SliceSampler", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.Storage", "reference/generated/torchrl.data.replay_buffers.StorageCheckpointerBase", "reference/generated/torchrl.data.replay_buffers.StorageEnsemble", "reference/generated/torchrl.data.replay_buffers.StorageEnsembleCheckpointer", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.TensorStorage", "reference/generated/torchrl.data.replay_buffers.TensorStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.Writer", "reference/generated/torchrl.data.replay_buffers.WriterEnsemble", "reference/generated/torchrl.envs.AsyncEnvPool", "reference/generated/torchrl.envs.BraxEnv", "reference/generated/torchrl.envs.BraxWrapper", "reference/generated/torchrl.envs.ChessEnv", "reference/generated/torchrl.envs.DMControlEnv", "reference/generated/torchrl.envs.DMControlWrapper", "reference/generated/torchrl.envs.EnvBase", "reference/generated/torchrl.envs.EnvCreator", "reference/generated/torchrl.envs.EnvMetaData", "reference/generated/torchrl.envs.GymEnv", "reference/generated/torchrl.envs.GymLikeEnv", "reference/generated/torchrl.envs.GymWrapper", "reference/generated/torchrl.envs.HabitatEnv", "reference/generated/torchrl.envs.IsaacGymEnv", "reference/generated/torchrl.envs.IsaacGymWrapper", "reference/generated/torchrl.envs.IsaacLabWrapper", "reference/generated/torchrl.envs.JumanjiEnv", "reference/generated/torchrl.envs.JumanjiWrapper", "reference/generated/torchrl.envs.LLMHashingEnv", "reference/generated/torchrl.envs.MOGymEnv", "reference/generated/torchrl.envs.MOGymWrapper", "reference/generated/torchrl.envs.MarlGroupMapType", "reference/generated/torchrl.envs.MeltingpotEnv", "reference/generated/torchrl.envs.MeltingpotWrapper", "reference/generated/torchrl.envs.ModelBasedEnvBase", "reference/generated/torchrl.envs.MultiThreadedEnv", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper", "reference/generated/torchrl.envs.OpenMLEnv", "reference/generated/torchrl.envs.OpenSpielEnv", "reference/generated/torchrl.envs.OpenSpielWrapper", "reference/generated/torchrl.envs.ParallelEnv", "reference/generated/torchrl.envs.PendulumEnv", "reference/generated/torchrl.envs.PettingZooEnv", "reference/generated/torchrl.envs.PettingZooWrapper", "reference/generated/torchrl.envs.ProcessorAsyncEnvPool", "reference/generated/torchrl.envs.RoboHiveEnv", "reference/generated/torchrl.envs.SMACv2Env", "reference/generated/torchrl.envs.SMACv2Wrapper", "reference/generated/torchrl.envs.SerialEnv", "reference/generated/torchrl.envs.ThreadingAsyncEnvPool", "reference/generated/torchrl.envs.TicTacToeEnv", "reference/generated/torchrl.envs.UnityMLAgentsEnv", "reference/generated/torchrl.envs.UnityMLAgentsWrapper", "reference/generated/torchrl.envs.VmasEnv", "reference/generated/torchrl.envs.VmasWrapper", "reference/generated/torchrl.envs.check_env_specs", "reference/generated/torchrl.envs.check_marl_grouping", "reference/generated/torchrl.envs.exploration_type", "reference/generated/torchrl.envs.get_available_libraries", "reference/generated/torchrl.envs.gym_backend", "reference/generated/torchrl.envs.llm.ChatEnv", "reference/generated/torchrl.envs.llm.DatasetChatEnv", "reference/generated/torchrl.envs.llm.GSM8KEnv", "reference/generated/torchrl.envs.llm.GSM8KPrepareQuestion", "reference/generated/torchrl.envs.llm.GSM8KRewardParser", "reference/generated/torchrl.envs.llm.IFEvalEnv", "reference/generated/torchrl.envs.llm.IFEvalScoreData", "reference/generated/torchrl.envs.llm.IfEvalScorer", "reference/generated/torchrl.envs.llm.LLMEnv", "reference/generated/torchrl.envs.llm.LLMHashingEnv", "reference/generated/torchrl.envs.llm.MLGymWrapper", "reference/generated/torchrl.envs.llm.make_gsm8k_env", "reference/generated/torchrl.envs.llm.make_mlgym", "reference/generated/torchrl.envs.llm.transforms.AddThinkingPrompt", "reference/generated/torchrl.envs.llm.transforms.BrowserTransform", "reference/generated/torchrl.envs.llm.transforms.DataLoadingPrimer", "reference/generated/torchrl.envs.llm.transforms.ExecuteToolsInOrder", "reference/generated/torchrl.envs.llm.transforms.JSONCallParser", "reference/generated/torchrl.envs.llm.transforms.KLComputation", "reference/generated/torchrl.envs.llm.transforms.KLRewardTransform", "reference/generated/torchrl.envs.llm.transforms.MCPToolTransform", "reference/generated/torchrl.envs.llm.transforms.PolicyVersion", "reference/generated/torchrl.envs.llm.transforms.PythonExecutorService", "reference/generated/torchrl.envs.llm.transforms.PythonInterpreter", "reference/generated/torchrl.envs.llm.transforms.RayDataLoadingPrimer", "reference/generated/torchrl.envs.llm.transforms.RetrieveKL", "reference/generated/torchrl.envs.llm.transforms.RetrieveLogProb", "reference/generated/torchrl.envs.llm.transforms.SimpleToolTransform", "reference/generated/torchrl.envs.llm.transforms.TemplateTransform", "reference/generated/torchrl.envs.llm.transforms.Tokenizer", "reference/generated/torchrl.envs.llm.transforms.ToolCall", "reference/generated/torchrl.envs.llm.transforms.ToolRegistry", "reference/generated/torchrl.envs.llm.transforms.ToolService", "reference/generated/torchrl.envs.llm.transforms.XMLBlockParser", "reference/generated/torchrl.envs.llm.transforms.as_nested_tensor", "reference/generated/torchrl.envs.llm.transforms.as_padded_tensor", "reference/generated/torchrl.envs.make_composite_from_td", "reference/generated/torchrl.envs.model_based.dreamer.DreamerDecoder", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv", "reference/generated/torchrl.envs.register_gym_spec_conversion", "reference/generated/torchrl.envs.set_exploration_type", "reference/generated/torchrl.envs.set_gym_backend", "reference/generated/torchrl.envs.step_mdp", "reference/generated/torchrl.envs.terminated_or_truncated", "reference/generated/torchrl.envs.transforms.ActionDiscretizer", "reference/generated/torchrl.envs.transforms.ActionMask", "reference/generated/torchrl.envs.transforms.AutoResetEnv", "reference/generated/torchrl.envs.transforms.AutoResetTransform", "reference/generated/torchrl.envs.transforms.BatchSizeTransform", "reference/generated/torchrl.envs.transforms.BinarizeReward", "reference/generated/torchrl.envs.transforms.BurnInTransform", "reference/generated/torchrl.envs.transforms.CatFrames", "reference/generated/torchrl.envs.transforms.CatTensors", "reference/generated/torchrl.envs.transforms.CenterCrop", "reference/generated/torchrl.envs.transforms.ClipTransform", "reference/generated/torchrl.envs.transforms.Compose", "reference/generated/torchrl.envs.transforms.ConditionalPolicySwitch", "reference/generated/torchrl.envs.transforms.ConditionalSkip", "reference/generated/torchrl.envs.transforms.Crop", "reference/generated/torchrl.envs.transforms.DTypeCastTransform", "reference/generated/torchrl.envs.transforms.DeviceCastTransform", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection", "reference/generated/torchrl.envs.transforms.DoubleToFloat", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform", "reference/generated/torchrl.envs.transforms.ExcludeTransform", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck", "reference/generated/torchrl.envs.transforms.FlattenObservation", "reference/generated/torchrl.envs.transforms.FrameSkipTransform", "reference/generated/torchrl.envs.transforms.GrayScale", "reference/generated/torchrl.envs.transforms.Hash", "reference/generated/torchrl.envs.transforms.InitTracker", "reference/generated/torchrl.envs.transforms.KLRewardTransform", "reference/generated/torchrl.envs.transforms.LineariseRewards", "reference/generated/torchrl.envs.transforms.ModuleTransform", "reference/generated/torchrl.envs.transforms.MultiAction", "reference/generated/torchrl.envs.transforms.NoopResetEnv", "reference/generated/torchrl.envs.transforms.ObservationNorm", "reference/generated/torchrl.envs.transforms.ObservationTransform", "reference/generated/torchrl.envs.transforms.PermuteTransform", "reference/generated/torchrl.envs.transforms.PinMemoryTransform", "reference/generated/torchrl.envs.transforms.R3MTransform", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict", "reference/generated/torchrl.envs.transforms.RemoveEmptySpecs", "reference/generated/torchrl.envs.transforms.RenameTransform", "reference/generated/torchrl.envs.transforms.Resize", "reference/generated/torchrl.envs.transforms.Reward2GoTransform", "reference/generated/torchrl.envs.transforms.RewardClipping", "reference/generated/torchrl.envs.transforms.RewardScaling", "reference/generated/torchrl.envs.transforms.RewardSum", "reference/generated/torchrl.envs.transforms.SelectTransform", "reference/generated/torchrl.envs.transforms.SignTransform", "reference/generated/torchrl.envs.transforms.SqueezeTransform", "reference/generated/torchrl.envs.transforms.Stack", "reference/generated/torchrl.envs.transforms.StepCounter", "reference/generated/torchrl.envs.transforms.TargetReturn", "reference/generated/torchrl.envs.transforms.TensorDictPrimer", "reference/generated/torchrl.envs.transforms.TimeMaxPool", "reference/generated/torchrl.envs.transforms.Timer", "reference/generated/torchrl.envs.transforms.ToTensorImage", "reference/generated/torchrl.envs.transforms.Tokenizer", "reference/generated/torchrl.envs.transforms.TrajCounter", "reference/generated/torchrl.envs.transforms.Transform", "reference/generated/torchrl.envs.transforms.TransformedEnv", "reference/generated/torchrl.envs.transforms.UnaryTransform", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform", "reference/generated/torchrl.envs.transforms.VC1Transform", "reference/generated/torchrl.envs.transforms.VIPRewardTransform", "reference/generated/torchrl.envs.transforms.VIPTransform", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform", "reference/generated/torchrl.envs.transforms.VecNorm", "reference/generated/torchrl.envs.transforms.VecNormV2", "reference/generated/torchrl.envs.transforms.gSDENoise", "reference/generated/torchrl.implement_for", "reference/generated/torchrl.modules.ActorCriticOperator", "reference/generated/torchrl.modules.ActorCriticWrapper", "reference/generated/torchrl.modules.ActorValueOperator", "reference/generated/torchrl.modules.AdditiveGaussianModule", "reference/generated/torchrl.modules.ConsistentDropoutModule", "reference/generated/torchrl.modules.ConvNet", "reference/generated/torchrl.modules.DTActor", "reference/generated/torchrl.modules.DdpgCnnActor", "reference/generated/torchrl.modules.DdpgCnnQNet", "reference/generated/torchrl.modules.DdpgMlpActor", "reference/generated/torchrl.modules.DdpgMlpQNet", "reference/generated/torchrl.modules.DecisionTransformer", "reference/generated/torchrl.modules.Delta", "reference/generated/torchrl.modules.DistributionalDQNnet", "reference/generated/torchrl.modules.DistributionalQValueActor", "reference/generated/torchrl.modules.DistributionalQValueModule", "reference/generated/torchrl.modules.DreamerActor", "reference/generated/torchrl.modules.DuelingCnnDQNet", "reference/generated/torchrl.modules.EGreedyModule", "reference/generated/torchrl.modules.GRUModule", "reference/generated/torchrl.modules.IndependentNormal", "reference/generated/torchrl.modules.LSTMModule", "reference/generated/torchrl.modules.MLP", "reference/generated/torchrl.modules.MaskedCategorical", "reference/generated/torchrl.modules.NormalParamExtractor", "reference/generated/torchrl.modules.ObsDecoder", "reference/generated/torchrl.modules.ObsEncoder", "reference/generated/torchrl.modules.OneHotCategorical", "reference/generated/torchrl.modules.OnlineDTActor", "reference/generated/torchrl.modules.OrnsteinUhlenbeckProcessModule", "reference/generated/torchrl.modules.QValueActor", "reference/generated/torchrl.modules.QValueModule", "reference/generated/torchrl.modules.RSSMPosterior", "reference/generated/torchrl.modules.RSSMPrior", "reference/generated/torchrl.modules.RSSMRollout", "reference/generated/torchrl.modules.ReparamGradientStrategy", "reference/generated/torchrl.modules.TanhDelta", "reference/generated/torchrl.modules.TanhNormal", "reference/generated/torchrl.modules.TruncatedNormal", "reference/generated/torchrl.modules.ValueOperator", "reference/generated/torchrl.modules.WorldModelWrapper", "reference/generated/torchrl.modules.llm.AsyncVLLM", "reference/generated/torchrl.modules.llm.ChatHistory", "reference/generated/torchrl.modules.llm.LLMWrapperBase", "reference/generated/torchrl.modules.llm.LogProbs", "reference/generated/torchrl.modules.llm.Masks", "reference/generated/torchrl.modules.llm.RemoteTransformersWrapper", "reference/generated/torchrl.modules.llm.Text", "reference/generated/torchrl.modules.llm.Tokens", "reference/generated/torchrl.modules.llm.TransformersWrapper", "reference/generated/torchrl.modules.llm.make_async_vllm_engine", "reference/generated/torchrl.modules.llm.make_vllm_worker", "reference/generated/torchrl.modules.llm.stateless_init_process_group", "reference/generated/torchrl.modules.llm.stateless_init_process_group_async", "reference/generated/torchrl.modules.llm.vLLMWrapper", "reference/generated/torchrl.modules.models.utils.SquashDims", "reference/generated/torchrl.modules.tensordict_module.Actor", "reference/generated/torchrl.modules.tensordict_module.MultiStepActorWrapper", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor", "reference/generated/torchrl.modules.tensordict_module.RandomPolicy", "reference/generated/torchrl.modules.tensordict_module.SafeModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential", "reference/generated/torchrl.modules.tensordict_module.SafeSequential", "reference/generated/torchrl.modules.tensordict_module.TanhModule", "reference/generated/torchrl.objectives.A2CLoss", "reference/generated/torchrl.objectives.CQLLoss", "reference/generated/torchrl.objectives.ClipPPOLoss", "reference/generated/torchrl.objectives.CrossQLoss", "reference/generated/torchrl.objectives.DDPGLoss", "reference/generated/torchrl.objectives.DQNLoss", "reference/generated/torchrl.objectives.DTLoss", "reference/generated/torchrl.objectives.DiscreteCQLLoss", "reference/generated/torchrl.objectives.DiscreteIQLLoss", "reference/generated/torchrl.objectives.DiscreteSACLoss", "reference/generated/torchrl.objectives.DistributionalDQNLoss", "reference/generated/torchrl.objectives.DreamerActorLoss", "reference/generated/torchrl.objectives.DreamerModelLoss", "reference/generated/torchrl.objectives.DreamerValueLoss", "reference/generated/torchrl.objectives.GAILLoss", "reference/generated/torchrl.objectives.IQLLoss", "reference/generated/torchrl.objectives.KLPENPPOLoss", "reference/generated/torchrl.objectives.LossModule", "reference/generated/torchrl.objectives.OnlineDTLoss", "reference/generated/torchrl.objectives.PPOLoss", "reference/generated/torchrl.objectives.REDQLoss", "reference/generated/torchrl.objectives.ReinforceLoss", "reference/generated/torchrl.objectives.SACLoss", "reference/generated/torchrl.objectives.TD3BCLoss", "reference/generated/torchrl.objectives.TD3Loss", "reference/generated/torchrl.objectives.ValueEstimators", "reference/generated/torchrl.objectives.add_random_module", "reference/generated/torchrl.objectives.llm.CISPOLoss", "reference/generated/torchrl.objectives.llm.CISPOLossOutput", "reference/generated/torchrl.objectives.llm.DAPO", "reference/generated/torchrl.objectives.llm.DAPOLossOutput", "reference/generated/torchrl.objectives.llm.GRPOLoss", "reference/generated/torchrl.objectives.llm.GRPOLossOutput", "reference/generated/torchrl.objectives.llm.LLMLossOutput", "reference/generated/torchrl.objectives.llm.MCAdvantage", "reference/generated/torchrl.objectives.llm.SFTLoss", "reference/generated/torchrl.objectives.llm.SFTLossOutput", "reference/generated/torchrl.objectives.value.GAE", "reference/generated/torchrl.objectives.value.TD0Estimator", "reference/generated/torchrl.objectives.value.TD1Estimator", "reference/generated/torchrl.objectives.value.TDLambdaEstimator", "reference/generated/torchrl.objectives.value.ValueEstimatorBase", "reference/generated/torchrl.record.PixelRenderTransform", "reference/generated/torchrl.record.TensorDictRecorder", "reference/generated/torchrl.record.VideoRecorder", "reference/generated/torchrl.record.loggers.Logger", "reference/generated/torchrl.record.loggers.csv.CSVLogger", "reference/generated/torchrl.record.loggers.generate_exp_name", "reference/generated/torchrl.record.loggers.get_logger", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger", "reference/generated/torchrl.record.loggers.trackio.TrackioLogger", "reference/generated/torchrl.record.loggers.wandb.WandbLogger", "reference/generated/torchrl.services.RayService", "reference/generated/torchrl.services.ServiceBase", "reference/generated/torchrl.services.get_services", "reference/generated/torchrl.set_auto_unwrap_transformed_env", "reference/generated/torchrl.trainers.BatchSubSampler", "reference/generated/torchrl.trainers.ClearCudaCache", "reference/generated/torchrl.trainers.CountFramesLog", "reference/generated/torchrl.trainers.LogScalar", "reference/generated/torchrl.trainers.LogValidationReward", "reference/generated/torchrl.trainers.OptimizerHook", "reference/generated/torchrl.trainers.ReplayBufferTrainer", "reference/generated/torchrl.trainers.RewardNormalizer", "reference/generated/torchrl.trainers.SelectKeys", "reference/generated/torchrl.trainers.TargetNetUpdaterHook", "reference/generated/torchrl.trainers.Trainer", "reference/generated/torchrl.trainers.TrainerHookBase", "reference/generated/torchrl.trainers.UTDRHook", "reference/generated/torchrl.trainers.UpdateWeights", "reference/generated/torchrl.trainers.algorithms.PPOTrainer", "reference/generated/torchrl.trainers.algorithms.SACTrainer", "reference/generated/torchrl.trainers.algorithms.configs.collectors.AsyncDataCollectorConfig", "reference/generated/torchrl.trainers.algorithms.configs.collectors.SyncDataCollectorConfig", "reference/generated/torchrl.trainers.algorithms.configs.common.ConfigBase", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyMemmapStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyStackStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyTensorStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.ListStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.PrioritizedSamplerConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.RandomSamplerConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.ReplayBufferConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.RoundRobinWriterConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.SamplerWithoutReplacementConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerWithoutReplacementConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleWriterConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorDictReplayBufferConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs.BatchedEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs.EnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs.TransformedEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.BraxEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.DMControlEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.EnvLibsConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.GymEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.HabitatEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.IsaacGymEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.JumanjiEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MOGymEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MeltingpotEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MultiThreadedEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenMLEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenSpielEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.PettingZooEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.RoboHiveEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.SMACv2EnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.UnityMLAgentsEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.VmasEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.CSVLoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.LoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.TensorboardLoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.WandbLoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.ConvNetConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.MLPConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.ModelConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.NetworkConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.TanhNormalModelConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.TensorDictModuleConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.ValueModelConfig", "reference/generated/torchrl.trainers.algorithms.configs.objectives.LossConfig", "reference/generated/torchrl.trainers.algorithms.configs.objectives.PPOLossConfig", "reference/generated/torchrl.trainers.algorithms.configs.trainers.PPOTrainerConfig", "reference/generated/torchrl.trainers.algorithms.configs.trainers.TrainerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionDiscretizerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionMaskConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.AutoResetTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BatchSizeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BinarizeRewardConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BurnInTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatFramesConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatTensorsConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CenterCropConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ClipTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ComposeConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalPolicySwitchConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalSkipConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CropConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DTypeCastTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DeviceCastTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DiscreteActionProjectionConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DoubleToFloatConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.EndOfLifeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ExcludeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FiniteTensorDictCheckConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FlattenObservationConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FrameSkipTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.GrayScaleConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.HashConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.InitTrackerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.KLRewardTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.LineariseRewardsConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiActionConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiStepTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.NoopResetEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ObservationNormConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PermuteTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PinMemoryTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.R3MTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RandomCropTensorDictConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RemoveEmptySpecsConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RenameTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ResizeConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.Reward2GoTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardClippingConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardScalingConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardSumConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SelectTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SignTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SqueezeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StackConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StepCounterConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TargetReturnConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TensorDictPrimerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimeMaxPoolConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ToTensorImageConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TokenizerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TrajCounterConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnaryTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnsqueezeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VC1TransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPRewardTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecGymEnvTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormV2Config", "reference/generated/torchrl.trainers.algorithms.configs.utils.ASGDConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdadeltaConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdagradConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamWConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamaxConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.LBFGSConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.LionConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.NAdamConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.RAdamConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.RMSpropConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.RpropConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.SGDConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.SparseAdamConfig", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy", "reference/generated/torchrl.trainers.helpers.make_dqn_loss", "reference/generated/torchrl.trainers.helpers.make_replay_buffer", "reference/generated/torchrl.trainers.helpers.make_target_updater", "reference/generated/torchrl.trainers.helpers.make_trainer", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor", "reference/generated/torchrl.trainers.helpers.sync_async_collector", "reference/generated/torchrl.trainers.helpers.sync_sync_collector", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor", "reference/generated/torchrl.weight_update.DistributedTransport", "reference/generated/torchrl.weight_update.DistributedWeightSyncScheme", "reference/generated/torchrl.weight_update.MPTransport", "reference/generated/torchrl.weight_update.MultiProcessWeightSyncScheme", "reference/generated/torchrl.weight_update.NoWeightSyncScheme", "reference/generated/torchrl.weight_update.RPCTransport", "reference/generated/torchrl.weight_update.RPCWeightSyncScheme", "reference/generated/torchrl.weight_update.RayModuleTransformScheme", "reference/generated/torchrl.weight_update.RayTransport", "reference/generated/torchrl.weight_update.RayWeightSyncScheme", "reference/generated/torchrl.weight_update.SharedMemTransport", "reference/generated/torchrl.weight_update.SharedMemWeightSyncScheme", "reference/generated/torchrl.weight_update.TransportBackend", "reference/generated/torchrl.weight_update.WeightStrategy", "reference/generated/torchrl.weight_update.WeightSyncScheme", "reference/generated/torchrl.weight_update.llm.VLLMCollectiveTransport", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferTransport", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightSender", "reference/generated/torchrl.weight_update.llm.VLLMWeightReceiver", "reference/generated/torchrl.weight_update.llm.VLLMWeightSender", "reference/generated/torchrl.weight_update.llm.VLLMWeightSyncScheme", "reference/generated/torchrl.weight_update.llm.get_model_metadata", "reference/generated/tutorials/README", "reference/index", "reference/knowledge_base", "reference/llms", "reference/llms_collectors", "reference/llms_data", "reference/llms_envs", "reference/llms_modules", "reference/llms_objectives", "reference/llms_transforms", "reference/modules", "reference/modules_actors", "reference/modules_critics", "reference/modules_distributions", "reference/modules_exploration", "reference/modules_models", "reference/modules_utils", "reference/objectives", "reference/objectives_actorcritic", "reference/objectives_common", "reference/objectives_offline", "reference/objectives_other", "reference/objectives_policy", "reference/objectives_value", "reference/services", "reference/trainers", "reference/trainers_basics", "reference/trainers_hooks", "reference/trainers_loggers", "reference/utils", "sg_execution_times", "tutorials/coding_ddpg", "tutorials/coding_dqn", "tutorials/coding_ppo", "tutorials/dqn_with_rnn", "tutorials/export", "tutorials/getting-started-0", "tutorials/getting-started-1", "tutorials/getting-started-2", "tutorials/getting-started-3", "tutorials/getting-started-4", "tutorials/getting-started-5", "tutorials/index", "tutorials/llm_browser", "tutorials/llm_wrappers", "tutorials/multi_task", "tutorials/multiagent_competitive_ddpg", "tutorials/multiagent_ppo", "tutorials/pendulum", "tutorials/pretrained_models", "tutorials/rb_tutorial", "tutorials/sg_execution_times", "tutorials/torchrl_demo", "tutorials/torchrl_envs"], "filenames": ["index.rst", "reference/collectors.rst", "reference/collectors_basics.rst", "reference/collectors_distributed.rst", "reference/collectors_replay.rst", "reference/collectors_single.rst", "reference/collectors_weightsync.rst", "reference/config.rst", "reference/cudnn_persistent_rnn.rst", "reference/cudnn_rnn_determinism.rst", "reference/data.rst", "reference/data_datasets.rst", "reference/data_replaybuffers.rst", "reference/data_samplers.rst", "reference/data_specs.rst", "reference/data_storage.rst", "reference/envs.rst", "reference/envs_api.rst", "reference/envs_libraries.rst", "reference/envs_multiagent.rst", "reference/envs_recorders.rst", "reference/envs_transforms.rst", "reference/envs_vectorized.rst", "reference/generated/knowledge_base/DEBUGGING_RL.rst", "reference/generated/knowledge_base/GYM.rst", "reference/generated/knowledge_base/HABITAT.rst", "reference/generated/knowledge_base/MUJOCO_INSTALLATION.rst", "reference/generated/knowledge_base/PRO-TIPS.rst", "reference/generated/knowledge_base/RESOURCES.rst", "reference/generated/knowledge_base/VERSIONING_ISSUES.rst", "reference/generated/knowledge_base/VIDEO_CUSTOMISATION.rst", "reference/generated/torchrl.auto_unwrap_transformed_env.rst", "reference/generated/torchrl.collectors.AsyncCollector.rst", "reference/generated/torchrl.collectors.BaseCollector.rst", "reference/generated/torchrl.collectors.Collector.rst", "reference/generated/torchrl.collectors.MultiAsyncCollector.rst", "reference/generated/torchrl.collectors.MultiCollector.rst", "reference/generated/torchrl.collectors.MultiProcessedWeightUpdater.rst", "reference/generated/torchrl.collectors.MultiSyncCollector.rst", "reference/generated/torchrl.collectors.RayWeightUpdater.rst", "reference/generated/torchrl.collectors.VanillaWeightUpdater.rst", "reference/generated/torchrl.collectors.WeightUpdaterBase.rst", "reference/generated/torchrl.collectors.distributed.DistributedCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedSyncCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedWeightUpdater.rst", "reference/generated/torchrl.collectors.distributed.RPCCollector.rst", "reference/generated/torchrl.collectors.distributed.RPCDataCollector.rst", "reference/generated/torchrl.collectors.distributed.RPCWeightUpdater.rst", "reference/generated/torchrl.collectors.distributed.RayCollector.rst", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher.rst", "reference/generated/torchrl.collectors.llm.LLMCollector.rst", "reference/generated/torchrl.collectors.llm.RayLLMCollector.rst", "reference/generated/torchrl.collectors.llm.vLLMUpdater.rst", "reference/generated/torchrl.collectors.llm.vLLMUpdaterV2.rst", "reference/generated/torchrl.collectors.utils.split_trajectories.rst", "reference/generated/torchrl.data.Binary.rst", "reference/generated/torchrl.data.Bounded.rst", "reference/generated/torchrl.data.Categorical.rst", "reference/generated/torchrl.data.Composite.rst", "reference/generated/torchrl.data.MultiCategorical.rst", "reference/generated/torchrl.data.MultiOneHot.rst", "reference/generated/torchrl.data.NonTensor.rst", "reference/generated/torchrl.data.OneHot.rst", "reference/generated/torchrl.data.PrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.RayReplayBuffer.rst", "reference/generated/torchrl.data.RemoteTensorDictReplayBuffer.rst", "reference/generated/torchrl.data.ReplayBuffer.rst", "reference/generated/torchrl.data.ReplayBufferEnsemble.rst", "reference/generated/torchrl.data.Stacked.rst", "reference/generated/torchrl.data.StackedComposite.rst", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.TensorDictReplayBuffer.rst", "reference/generated/torchrl.data.TensorSpec.rst", "reference/generated/torchrl.data.Unbounded.rst", "reference/generated/torchrl.data.UnboundedContinuous.rst", "reference/generated/torchrl.data.UnboundedDiscrete.rst", "reference/generated/torchrl.data.datasets.AtariDQNExperienceReplay.rst", "reference/generated/torchrl.data.datasets.D4RLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.GenDGRLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.MinariExperienceReplay.rst", "reference/generated/torchrl.data.datasets.OpenMLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.OpenXExperienceReplay.rst", "reference/generated/torchrl.data.datasets.RobosetExperienceReplay.rst", "reference/generated/torchrl.data.datasets.VD4RLExperienceReplay.rst", "reference/generated/torchrl.data.llm.ContentBase.rst", "reference/generated/torchrl.data.llm.History.rst", "reference/generated/torchrl.data.llm.TopKRewardSelector.rst", "reference/generated/torchrl.data.llm.add_chat_template.rst", "reference/generated/torchrl.data.replay_buffers.CompressedListStorage.rst", "reference/generated/torchrl.data.replay_buffers.CompressedListStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.FlatStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.H5StorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.ImmutableDatasetWriter.rst", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage.rst", "reference/generated/torchrl.data.replay_buffers.LazyStackStorage.rst", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.ListStorage.rst", "reference/generated/torchrl.data.replay_buffers.ListStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.NestedStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler.rst", "reference/generated/torchrl.data.replay_buffers.PrioritizedSliceSampler.rst", "reference/generated/torchrl.data.replay_buffers.RandomSampler.rst", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.Sampler.rst", "reference/generated/torchrl.data.replay_buffers.SamplerEnsemble.rst", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.SliceSampler.rst", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.Storage.rst", "reference/generated/torchrl.data.replay_buffers.StorageCheckpointerBase.rst", "reference/generated/torchrl.data.replay_buffers.StorageEnsemble.rst", "reference/generated/torchrl.data.replay_buffers.StorageEnsembleCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.TensorStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.Writer.rst", "reference/generated/torchrl.data.replay_buffers.WriterEnsemble.rst", "reference/generated/torchrl.envs.AsyncEnvPool.rst", "reference/generated/torchrl.envs.BraxEnv.rst", "reference/generated/torchrl.envs.BraxWrapper.rst", "reference/generated/torchrl.envs.ChessEnv.rst", "reference/generated/torchrl.envs.DMControlEnv.rst", "reference/generated/torchrl.envs.DMControlWrapper.rst", "reference/generated/torchrl.envs.EnvBase.rst", "reference/generated/torchrl.envs.EnvCreator.rst", "reference/generated/torchrl.envs.EnvMetaData.rst", "reference/generated/torchrl.envs.GymEnv.rst", "reference/generated/torchrl.envs.GymLikeEnv.rst", "reference/generated/torchrl.envs.GymWrapper.rst", "reference/generated/torchrl.envs.HabitatEnv.rst", "reference/generated/torchrl.envs.IsaacGymEnv.rst", "reference/generated/torchrl.envs.IsaacGymWrapper.rst", "reference/generated/torchrl.envs.IsaacLabWrapper.rst", "reference/generated/torchrl.envs.JumanjiEnv.rst", "reference/generated/torchrl.envs.JumanjiWrapper.rst", "reference/generated/torchrl.envs.LLMHashingEnv.rst", "reference/generated/torchrl.envs.MOGymEnv.rst", "reference/generated/torchrl.envs.MOGymWrapper.rst", "reference/generated/torchrl.envs.MarlGroupMapType.rst", "reference/generated/torchrl.envs.MeltingpotEnv.rst", "reference/generated/torchrl.envs.MeltingpotWrapper.rst", "reference/generated/torchrl.envs.ModelBasedEnvBase.rst", "reference/generated/torchrl.envs.MultiThreadedEnv.rst", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper.rst", "reference/generated/torchrl.envs.OpenMLEnv.rst", "reference/generated/torchrl.envs.OpenSpielEnv.rst", "reference/generated/torchrl.envs.OpenSpielWrapper.rst", "reference/generated/torchrl.envs.ParallelEnv.rst", "reference/generated/torchrl.envs.PendulumEnv.rst", "reference/generated/torchrl.envs.PettingZooEnv.rst", "reference/generated/torchrl.envs.PettingZooWrapper.rst", "reference/generated/torchrl.envs.ProcessorAsyncEnvPool.rst", "reference/generated/torchrl.envs.RoboHiveEnv.rst", "reference/generated/torchrl.envs.SMACv2Env.rst", "reference/generated/torchrl.envs.SMACv2Wrapper.rst", "reference/generated/torchrl.envs.SerialEnv.rst", "reference/generated/torchrl.envs.ThreadingAsyncEnvPool.rst", "reference/generated/torchrl.envs.TicTacToeEnv.rst", "reference/generated/torchrl.envs.UnityMLAgentsEnv.rst", "reference/generated/torchrl.envs.UnityMLAgentsWrapper.rst", "reference/generated/torchrl.envs.VmasEnv.rst", "reference/generated/torchrl.envs.VmasWrapper.rst", "reference/generated/torchrl.envs.check_env_specs.rst", "reference/generated/torchrl.envs.check_marl_grouping.rst", "reference/generated/torchrl.envs.exploration_type.rst", "reference/generated/torchrl.envs.get_available_libraries.rst", "reference/generated/torchrl.envs.gym_backend.rst", "reference/generated/torchrl.envs.llm.ChatEnv.rst", "reference/generated/torchrl.envs.llm.DatasetChatEnv.rst", "reference/generated/torchrl.envs.llm.GSM8KEnv.rst", "reference/generated/torchrl.envs.llm.GSM8KPrepareQuestion.rst", "reference/generated/torchrl.envs.llm.GSM8KRewardParser.rst", "reference/generated/torchrl.envs.llm.IFEvalEnv.rst", "reference/generated/torchrl.envs.llm.IFEvalScoreData.rst", "reference/generated/torchrl.envs.llm.IfEvalScorer.rst", "reference/generated/torchrl.envs.llm.LLMEnv.rst", "reference/generated/torchrl.envs.llm.LLMHashingEnv.rst", "reference/generated/torchrl.envs.llm.MLGymWrapper.rst", "reference/generated/torchrl.envs.llm.make_gsm8k_env.rst", "reference/generated/torchrl.envs.llm.make_mlgym.rst", "reference/generated/torchrl.envs.llm.transforms.AddThinkingPrompt.rst", "reference/generated/torchrl.envs.llm.transforms.BrowserTransform.rst", "reference/generated/torchrl.envs.llm.transforms.DataLoadingPrimer.rst", "reference/generated/torchrl.envs.llm.transforms.ExecuteToolsInOrder.rst", "reference/generated/torchrl.envs.llm.transforms.JSONCallParser.rst", "reference/generated/torchrl.envs.llm.transforms.KLComputation.rst", "reference/generated/torchrl.envs.llm.transforms.KLRewardTransform.rst", "reference/generated/torchrl.envs.llm.transforms.MCPToolTransform.rst", "reference/generated/torchrl.envs.llm.transforms.PolicyVersion.rst", "reference/generated/torchrl.envs.llm.transforms.PythonExecutorService.rst", "reference/generated/torchrl.envs.llm.transforms.PythonInterpreter.rst", "reference/generated/torchrl.envs.llm.transforms.RayDataLoadingPrimer.rst", "reference/generated/torchrl.envs.llm.transforms.RetrieveKL.rst", "reference/generated/torchrl.envs.llm.transforms.RetrieveLogProb.rst", "reference/generated/torchrl.envs.llm.transforms.SimpleToolTransform.rst", "reference/generated/torchrl.envs.llm.transforms.TemplateTransform.rst", "reference/generated/torchrl.envs.llm.transforms.Tokenizer.rst", "reference/generated/torchrl.envs.llm.transforms.ToolCall.rst", "reference/generated/torchrl.envs.llm.transforms.ToolRegistry.rst", "reference/generated/torchrl.envs.llm.transforms.ToolService.rst", "reference/generated/torchrl.envs.llm.transforms.XMLBlockParser.rst", "reference/generated/torchrl.envs.llm.transforms.as_nested_tensor.rst", "reference/generated/torchrl.envs.llm.transforms.as_padded_tensor.rst", "reference/generated/torchrl.envs.make_composite_from_td.rst", "reference/generated/torchrl.envs.model_based.dreamer.DreamerDecoder.rst", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv.rst", "reference/generated/torchrl.envs.register_gym_spec_conversion.rst", "reference/generated/torchrl.envs.set_exploration_type.rst", "reference/generated/torchrl.envs.set_gym_backend.rst", "reference/generated/torchrl.envs.step_mdp.rst", "reference/generated/torchrl.envs.terminated_or_truncated.rst", "reference/generated/torchrl.envs.transforms.ActionDiscretizer.rst", "reference/generated/torchrl.envs.transforms.ActionMask.rst", "reference/generated/torchrl.envs.transforms.AutoResetEnv.rst", "reference/generated/torchrl.envs.transforms.AutoResetTransform.rst", "reference/generated/torchrl.envs.transforms.BatchSizeTransform.rst", "reference/generated/torchrl.envs.transforms.BinarizeReward.rst", "reference/generated/torchrl.envs.transforms.BurnInTransform.rst", "reference/generated/torchrl.envs.transforms.CatFrames.rst", "reference/generated/torchrl.envs.transforms.CatTensors.rst", "reference/generated/torchrl.envs.transforms.CenterCrop.rst", "reference/generated/torchrl.envs.transforms.ClipTransform.rst", "reference/generated/torchrl.envs.transforms.Compose.rst", "reference/generated/torchrl.envs.transforms.ConditionalPolicySwitch.rst", "reference/generated/torchrl.envs.transforms.ConditionalSkip.rst", "reference/generated/torchrl.envs.transforms.Crop.rst", "reference/generated/torchrl.envs.transforms.DTypeCastTransform.rst", "reference/generated/torchrl.envs.transforms.DeviceCastTransform.rst", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection.rst", "reference/generated/torchrl.envs.transforms.DoubleToFloat.rst", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform.rst", "reference/generated/torchrl.envs.transforms.ExcludeTransform.rst", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck.rst", "reference/generated/torchrl.envs.transforms.FlattenObservation.rst", "reference/generated/torchrl.envs.transforms.FrameSkipTransform.rst", "reference/generated/torchrl.envs.transforms.GrayScale.rst", "reference/generated/torchrl.envs.transforms.Hash.rst", "reference/generated/torchrl.envs.transforms.InitTracker.rst", "reference/generated/torchrl.envs.transforms.KLRewardTransform.rst", "reference/generated/torchrl.envs.transforms.LineariseRewards.rst", "reference/generated/torchrl.envs.transforms.ModuleTransform.rst", "reference/generated/torchrl.envs.transforms.MultiAction.rst", "reference/generated/torchrl.envs.transforms.NoopResetEnv.rst", "reference/generated/torchrl.envs.transforms.ObservationNorm.rst", "reference/generated/torchrl.envs.transforms.ObservationTransform.rst", "reference/generated/torchrl.envs.transforms.PermuteTransform.rst", "reference/generated/torchrl.envs.transforms.PinMemoryTransform.rst", "reference/generated/torchrl.envs.transforms.R3MTransform.rst", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict.rst", "reference/generated/torchrl.envs.transforms.RemoveEmptySpecs.rst", "reference/generated/torchrl.envs.transforms.RenameTransform.rst", "reference/generated/torchrl.envs.transforms.Resize.rst", "reference/generated/torchrl.envs.transforms.Reward2GoTransform.rst", "reference/generated/torchrl.envs.transforms.RewardClipping.rst", "reference/generated/torchrl.envs.transforms.RewardScaling.rst", "reference/generated/torchrl.envs.transforms.RewardSum.rst", "reference/generated/torchrl.envs.transforms.SelectTransform.rst", "reference/generated/torchrl.envs.transforms.SignTransform.rst", "reference/generated/torchrl.envs.transforms.SqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.Stack.rst", "reference/generated/torchrl.envs.transforms.StepCounter.rst", "reference/generated/torchrl.envs.transforms.TargetReturn.rst", "reference/generated/torchrl.envs.transforms.TensorDictPrimer.rst", "reference/generated/torchrl.envs.transforms.TimeMaxPool.rst", "reference/generated/torchrl.envs.transforms.Timer.rst", "reference/generated/torchrl.envs.transforms.ToTensorImage.rst", "reference/generated/torchrl.envs.transforms.Tokenizer.rst", "reference/generated/torchrl.envs.transforms.TrajCounter.rst", "reference/generated/torchrl.envs.transforms.Transform.rst", "reference/generated/torchrl.envs.transforms.TransformedEnv.rst", "reference/generated/torchrl.envs.transforms.UnaryTransform.rst", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.VC1Transform.rst", "reference/generated/torchrl.envs.transforms.VIPRewardTransform.rst", "reference/generated/torchrl.envs.transforms.VIPTransform.rst", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform.rst", "reference/generated/torchrl.envs.transforms.VecNorm.rst", "reference/generated/torchrl.envs.transforms.VecNormV2.rst", "reference/generated/torchrl.envs.transforms.gSDENoise.rst", "reference/generated/torchrl.implement_for.rst", "reference/generated/torchrl.modules.ActorCriticOperator.rst", "reference/generated/torchrl.modules.ActorCriticWrapper.rst", "reference/generated/torchrl.modules.ActorValueOperator.rst", "reference/generated/torchrl.modules.AdditiveGaussianModule.rst", "reference/generated/torchrl.modules.ConsistentDropoutModule.rst", "reference/generated/torchrl.modules.ConvNet.rst", "reference/generated/torchrl.modules.DTActor.rst", "reference/generated/torchrl.modules.DdpgCnnActor.rst", "reference/generated/torchrl.modules.DdpgCnnQNet.rst", "reference/generated/torchrl.modules.DdpgMlpActor.rst", "reference/generated/torchrl.modules.DdpgMlpQNet.rst", "reference/generated/torchrl.modules.DecisionTransformer.rst", "reference/generated/torchrl.modules.Delta.rst", "reference/generated/torchrl.modules.DistributionalDQNnet.rst", "reference/generated/torchrl.modules.DistributionalQValueActor.rst", "reference/generated/torchrl.modules.DistributionalQValueModule.rst", "reference/generated/torchrl.modules.DreamerActor.rst", "reference/generated/torchrl.modules.DuelingCnnDQNet.rst", "reference/generated/torchrl.modules.EGreedyModule.rst", "reference/generated/torchrl.modules.GRUModule.rst", "reference/generated/torchrl.modules.IndependentNormal.rst", "reference/generated/torchrl.modules.LSTMModule.rst", "reference/generated/torchrl.modules.MLP.rst", "reference/generated/torchrl.modules.MaskedCategorical.rst", "reference/generated/torchrl.modules.NormalParamExtractor.rst", "reference/generated/torchrl.modules.ObsDecoder.rst", "reference/generated/torchrl.modules.ObsEncoder.rst", "reference/generated/torchrl.modules.OneHotCategorical.rst", "reference/generated/torchrl.modules.OnlineDTActor.rst", "reference/generated/torchrl.modules.OrnsteinUhlenbeckProcessModule.rst", "reference/generated/torchrl.modules.QValueActor.rst", "reference/generated/torchrl.modules.QValueModule.rst", "reference/generated/torchrl.modules.RSSMPosterior.rst", "reference/generated/torchrl.modules.RSSMPrior.rst", "reference/generated/torchrl.modules.RSSMRollout.rst", "reference/generated/torchrl.modules.ReparamGradientStrategy.rst", "reference/generated/torchrl.modules.TanhDelta.rst", "reference/generated/torchrl.modules.TanhNormal.rst", "reference/generated/torchrl.modules.TruncatedNormal.rst", "reference/generated/torchrl.modules.ValueOperator.rst", "reference/generated/torchrl.modules.WorldModelWrapper.rst", "reference/generated/torchrl.modules.llm.AsyncVLLM.rst", "reference/generated/torchrl.modules.llm.ChatHistory.rst", "reference/generated/torchrl.modules.llm.LLMWrapperBase.rst", "reference/generated/torchrl.modules.llm.LogProbs.rst", "reference/generated/torchrl.modules.llm.Masks.rst", "reference/generated/torchrl.modules.llm.RemoteTransformersWrapper.rst", "reference/generated/torchrl.modules.llm.Text.rst", "reference/generated/torchrl.modules.llm.Tokens.rst", "reference/generated/torchrl.modules.llm.TransformersWrapper.rst", "reference/generated/torchrl.modules.llm.make_async_vllm_engine.rst", "reference/generated/torchrl.modules.llm.make_vllm_worker.rst", "reference/generated/torchrl.modules.llm.stateless_init_process_group.rst", "reference/generated/torchrl.modules.llm.stateless_init_process_group_async.rst", "reference/generated/torchrl.modules.llm.vLLMWrapper.rst", "reference/generated/torchrl.modules.models.utils.SquashDims.rst", "reference/generated/torchrl.modules.tensordict_module.Actor.rst", "reference/generated/torchrl.modules.tensordict_module.MultiStepActorWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor.rst", "reference/generated/torchrl.modules.tensordict_module.RandomPolicy.rst", "reference/generated/torchrl.modules.tensordict_module.SafeModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential.rst", "reference/generated/torchrl.modules.tensordict_module.SafeSequential.rst", "reference/generated/torchrl.modules.tensordict_module.TanhModule.rst", "reference/generated/torchrl.objectives.A2CLoss.rst", "reference/generated/torchrl.objectives.CQLLoss.rst", "reference/generated/torchrl.objectives.ClipPPOLoss.rst", "reference/generated/torchrl.objectives.CrossQLoss.rst", "reference/generated/torchrl.objectives.DDPGLoss.rst", "reference/generated/torchrl.objectives.DQNLoss.rst", "reference/generated/torchrl.objectives.DTLoss.rst", "reference/generated/torchrl.objectives.DiscreteCQLLoss.rst", "reference/generated/torchrl.objectives.DiscreteIQLLoss.rst", "reference/generated/torchrl.objectives.DiscreteSACLoss.rst", "reference/generated/torchrl.objectives.DistributionalDQNLoss.rst", "reference/generated/torchrl.objectives.DreamerActorLoss.rst", "reference/generated/torchrl.objectives.DreamerModelLoss.rst", "reference/generated/torchrl.objectives.DreamerValueLoss.rst", "reference/generated/torchrl.objectives.GAILLoss.rst", "reference/generated/torchrl.objectives.IQLLoss.rst", "reference/generated/torchrl.objectives.KLPENPPOLoss.rst", "reference/generated/torchrl.objectives.LossModule.rst", "reference/generated/torchrl.objectives.OnlineDTLoss.rst", "reference/generated/torchrl.objectives.PPOLoss.rst", "reference/generated/torchrl.objectives.REDQLoss.rst", "reference/generated/torchrl.objectives.ReinforceLoss.rst", "reference/generated/torchrl.objectives.SACLoss.rst", "reference/generated/torchrl.objectives.TD3BCLoss.rst", "reference/generated/torchrl.objectives.TD3Loss.rst", "reference/generated/torchrl.objectives.ValueEstimators.rst", "reference/generated/torchrl.objectives.add_random_module.rst", "reference/generated/torchrl.objectives.llm.CISPOLoss.rst", "reference/generated/torchrl.objectives.llm.CISPOLossOutput.rst", "reference/generated/torchrl.objectives.llm.DAPO.rst", "reference/generated/torchrl.objectives.llm.DAPOLossOutput.rst", "reference/generated/torchrl.objectives.llm.GRPOLoss.rst", "reference/generated/torchrl.objectives.llm.GRPOLossOutput.rst", "reference/generated/torchrl.objectives.llm.LLMLossOutput.rst", "reference/generated/torchrl.objectives.llm.MCAdvantage.rst", "reference/generated/torchrl.objectives.llm.SFTLoss.rst", "reference/generated/torchrl.objectives.llm.SFTLossOutput.rst", "reference/generated/torchrl.objectives.value.GAE.rst", "reference/generated/torchrl.objectives.value.TD0Estimator.rst", "reference/generated/torchrl.objectives.value.TD1Estimator.rst", "reference/generated/torchrl.objectives.value.TDLambdaEstimator.rst", "reference/generated/torchrl.objectives.value.ValueEstimatorBase.rst", "reference/generated/torchrl.record.PixelRenderTransform.rst", "reference/generated/torchrl.record.TensorDictRecorder.rst", "reference/generated/torchrl.record.VideoRecorder.rst", "reference/generated/torchrl.record.loggers.Logger.rst", "reference/generated/torchrl.record.loggers.csv.CSVLogger.rst", "reference/generated/torchrl.record.loggers.generate_exp_name.rst", "reference/generated/torchrl.record.loggers.get_logger.rst", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger.rst", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger.rst", "reference/generated/torchrl.record.loggers.trackio.TrackioLogger.rst", "reference/generated/torchrl.record.loggers.wandb.WandbLogger.rst", "reference/generated/torchrl.services.RayService.rst", "reference/generated/torchrl.services.ServiceBase.rst", "reference/generated/torchrl.services.get_services.rst", "reference/generated/torchrl.set_auto_unwrap_transformed_env.rst", "reference/generated/torchrl.trainers.BatchSubSampler.rst", "reference/generated/torchrl.trainers.ClearCudaCache.rst", "reference/generated/torchrl.trainers.CountFramesLog.rst", "reference/generated/torchrl.trainers.LogScalar.rst", "reference/generated/torchrl.trainers.LogValidationReward.rst", "reference/generated/torchrl.trainers.OptimizerHook.rst", "reference/generated/torchrl.trainers.ReplayBufferTrainer.rst", "reference/generated/torchrl.trainers.RewardNormalizer.rst", "reference/generated/torchrl.trainers.SelectKeys.rst", "reference/generated/torchrl.trainers.TargetNetUpdaterHook.rst", "reference/generated/torchrl.trainers.Trainer.rst", "reference/generated/torchrl.trainers.TrainerHookBase.rst", "reference/generated/torchrl.trainers.UTDRHook.rst", "reference/generated/torchrl.trainers.UpdateWeights.rst", "reference/generated/torchrl.trainers.algorithms.PPOTrainer.rst", "reference/generated/torchrl.trainers.algorithms.SACTrainer.rst", "reference/generated/torchrl.trainers.algorithms.configs.collectors.AsyncDataCollectorConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.collectors.SyncDataCollectorConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.common.ConfigBase.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyMemmapStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyStackStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyTensorStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.ListStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.PrioritizedSamplerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.RandomSamplerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.ReplayBufferConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.RoundRobinWriterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.SamplerWithoutReplacementConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerWithoutReplacementConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleWriterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorDictReplayBufferConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs.BatchedEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs.EnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs.TransformedEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.BraxEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.DMControlEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.EnvLibsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.GymEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.HabitatEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.IsaacGymEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.JumanjiEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MOGymEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MeltingpotEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MultiThreadedEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenMLEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenSpielEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.PettingZooEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.RoboHiveEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.SMACv2EnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.UnityMLAgentsEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.VmasEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.CSVLoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.LoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.TensorboardLoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.WandbLoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.ConvNetConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.MLPConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.ModelConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.NetworkConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.TanhNormalModelConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.TensorDictModuleConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.ValueModelConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.objectives.LossConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.objectives.PPOLossConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.trainers.PPOTrainerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.trainers.TrainerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionDiscretizerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionMaskConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.AutoResetTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BatchSizeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BinarizeRewardConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BurnInTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatFramesConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatTensorsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CenterCropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ClipTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ComposeConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalPolicySwitchConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalSkipConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DTypeCastTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DeviceCastTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DiscreteActionProjectionConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DoubleToFloatConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.EndOfLifeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ExcludeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FiniteTensorDictCheckConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FlattenObservationConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FrameSkipTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.GrayScaleConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.HashConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.InitTrackerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.KLRewardTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.LineariseRewardsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiActionConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiStepTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.NoopResetEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ObservationNormConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PermuteTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PinMemoryTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.R3MTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RandomCropTensorDictConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RemoveEmptySpecsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RenameTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ResizeConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.Reward2GoTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardClippingConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardScalingConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardSumConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SelectTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SignTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SqueezeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StackConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StepCounterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TargetReturnConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TensorDictPrimerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimeMaxPoolConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ToTensorImageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TokenizerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TrajCounterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnaryTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnsqueezeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VC1TransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPRewardTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecGymEnvTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormV2Config.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.ASGDConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdadeltaConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdagradConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamWConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamaxConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.LBFGSConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.LionConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.NAdamConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.RAdamConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.RMSpropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.RpropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.SGDConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.SparseAdamConfig.rst", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip.rst", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout.rst", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_dqn_loss.rst", "reference/generated/torchrl.trainers.helpers.make_replay_buffer.rst", "reference/generated/torchrl.trainers.helpers.make_target_updater.rst", "reference/generated/torchrl.trainers.helpers.make_trainer.rst", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor.rst", "reference/generated/torchrl.trainers.helpers.sync_async_collector.rst", "reference/generated/torchrl.trainers.helpers.sync_sync_collector.rst", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor.rst", "reference/generated/torchrl.weight_update.DistributedTransport.rst", "reference/generated/torchrl.weight_update.DistributedWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.MPTransport.rst", "reference/generated/torchrl.weight_update.MultiProcessWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.NoWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.RPCTransport.rst", "reference/generated/torchrl.weight_update.RPCWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.RayModuleTransformScheme.rst", "reference/generated/torchrl.weight_update.RayTransport.rst", "reference/generated/torchrl.weight_update.RayWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.SharedMemTransport.rst", "reference/generated/torchrl.weight_update.SharedMemWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.TransportBackend.rst", "reference/generated/torchrl.weight_update.WeightStrategy.rst", "reference/generated/torchrl.weight_update.WeightSyncScheme.rst", "reference/generated/torchrl.weight_update.llm.VLLMCollectiveTransport.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferTransport.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightSender.rst", "reference/generated/torchrl.weight_update.llm.VLLMWeightReceiver.rst", "reference/generated/torchrl.weight_update.llm.VLLMWeightSender.rst", "reference/generated/torchrl.weight_update.llm.VLLMWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.llm.get_model_metadata.rst", "reference/generated/tutorials/README.rst", "reference/index.rst", "reference/knowledge_base.rst", "reference/llms.rst", "reference/llms_collectors.rst", "reference/llms_data.rst", "reference/llms_envs.rst", "reference/llms_modules.rst", "reference/llms_objectives.rst", "reference/llms_transforms.rst", "reference/modules.rst", "reference/modules_actors.rst", "reference/modules_critics.rst", "reference/modules_distributions.rst", "reference/modules_exploration.rst", "reference/modules_models.rst", "reference/modules_utils.rst", "reference/objectives.rst", "reference/objectives_actorcritic.rst", "reference/objectives_common.rst", "reference/objectives_offline.rst", "reference/objectives_other.rst", "reference/objectives_policy.rst", "reference/objectives_value.rst", "reference/services.rst", "reference/trainers.rst", "reference/trainers_basics.rst", "reference/trainers_hooks.rst", "reference/trainers_loggers.rst", "reference/utils.rst", "sg_execution_times.rst", "tutorials/coding_ddpg.rst", "tutorials/coding_dqn.rst", "tutorials/coding_ppo.rst", "tutorials/dqn_with_rnn.rst", "tutorials/export.rst", "tutorials/getting-started-0.rst", "tutorials/getting-started-1.rst", "tutorials/getting-started-2.rst", "tutorials/getting-started-3.rst", "tutorials/getting-started-4.rst", "tutorials/getting-started-5.rst", "tutorials/index.rst", "tutorials/llm_browser.rst", "tutorials/llm_wrappers.rst", "tutorials/multi_task.rst", "tutorials/multiagent_competitive_ddpg.rst", "tutorials/multiagent_ppo.rst", "tutorials/pendulum.rst", "tutorials/pretrained_models.rst", "tutorials/rb_tutorial.rst", "tutorials/sg_execution_times.rst", "tutorials/torchrl_demo.rst", "tutorials/torchrl_envs.rst"], "titles": ["TorchRL", "torchrl.collectors package", "Collector Basics", "Distributed Collectors", "Collectors and Replay Buffers", "Single Node Collectors", "Weight Synchronization", "TorchRL Configuration System", "&lt;no title&gt;", "&lt;no title&gt;", "torchrl.data package", "Datasets", "Replay Buffers", "Sampling Strategies", "TensorSpec System", "Storage Backends", "torchrl.envs package", "Environment API", "Library Wrappers", "Multi-agent Environments", "Recorders", "Transforms", "Vectorized and Parallel Environments", "Things to consider when debugging RL", "Working with gym", "Working with <code class=\"docutils literal notranslate\"><span class=\"pre\">habitat-lab</span></code>", "Working with MuJoCo-based environments", "Common PyTorch errors and solutions", "Useful resources", "Versioning Issues", "Customising Video Renders", "auto_unwrap_transformed_env", "AsyncCollector", "BaseCollector", "Collector", "MultiAsyncCollector", "MultiCollector", "MultiProcessedWeightUpdater", "MultiSyncCollector", "RayWeightUpdater", "VanillaWeightUpdater", "WeightUpdaterBase", "DistributedCollector", "DistributedDataCollector", "DistributedSyncCollector", "DistributedSyncDataCollector", "DistributedWeightUpdater", "RPCCollector", "RPCDataCollector", "RPCWeightUpdater", "RayCollector", "submitit_delayed_launcher", "LLMCollector", "RayLLMCollector", "vLLMUpdater", "vLLMUpdaterV2", "split_trajectories", "Binary", "Bounded", "Categorical", "Composite", "MultiCategorical", "MultiOneHot", "NonTensor", "OneHot", "PrioritizedReplayBuffer", "RayReplayBuffer", "RemoteTensorDictReplayBuffer", "ReplayBuffer", "ReplayBufferEnsemble", "Stacked", "StackedComposite", "TensorDictPrioritizedReplayBuffer", "TensorDictReplayBuffer", "TensorSpec", "Unbounded", "UnboundedContinuous", "UnboundedDiscrete", "AtariDQNExperienceReplay", "D4RLExperienceReplay", "GenDGRLExperienceReplay", "MinariExperienceReplay", "OpenMLExperienceReplay", "OpenXExperienceReplay", "RobosetExperienceReplay", "VD4RLExperienceReplay", "ContentBase", "History", "TopKRewardSelector", "add_chat_template", "CompressedListStorage", "CompressedListStorageCheckpointer", "FlatStorageCheckpointer", "H5StorageCheckpointer", "ImmutableDatasetWriter", "LazyMemmapStorage", "LazyStackStorage", "LazyTensorStorage", "ListStorage", "ListStorageCheckpointer", "NestedStorageCheckpointer", "PrioritizedSampler", "PrioritizedSliceSampler", "RandomSampler", "RoundRobinWriter", "Sampler", "SamplerEnsemble", "SamplerWithoutReplacement", "SliceSampler", "SliceSamplerWithoutReplacement", "Storage", "StorageCheckpointerBase", "StorageEnsemble", "StorageEnsembleCheckpointer", "TensorDictMaxValueWriter", "TensorDictRoundRobinWriter", "TensorStorage", "TensorStorageCheckpointer", "Writer", "WriterEnsemble", "AsyncEnvPool", "BraxEnv", "BraxWrapper", "ChessEnv", "DMControlEnv", "DMControlWrapper", "EnvBase", "EnvCreator", "EnvMetaData", "GymEnv", "GymLikeEnv", "GymWrapper", "HabitatEnv", "IsaacGymEnv", "IsaacGymWrapper", "IsaacLabWrapper", "JumanjiEnv", "JumanjiWrapper", "LLMHashingEnv", "MOGymEnv", "MOGymWrapper", "MarlGroupMapType", "MeltingpotEnv", "MeltingpotWrapper", "ModelBasedEnvBase", "MultiThreadedEnv", "MultiThreadedEnvWrapper", "OpenMLEnv", "OpenSpielEnv", "OpenSpielWrapper", "ParallelEnv", "PendulumEnv", "PettingZooEnv", "PettingZooWrapper", "ProcessorAsyncEnvPool", "RoboHiveEnv", "SMACv2Env", "SMACv2Wrapper", "SerialEnv", "ThreadingAsyncEnvPool", "TicTacToeEnv", "UnityMLAgentsEnv", "UnityMLAgentsWrapper", "VmasEnv", "VmasWrapper", "check_env_specs", "check_marl_grouping", "exploration_type", "get_available_libraries", "gym_backend", "ChatEnv", "DatasetChatEnv", "GSM8KEnv", "GSM8KPrepareQuestion", "GSM8KRewardParser", "IFEvalEnv", "IFEvalScoreData", "IfEvalScorer", "LLMEnv", "LLMHashingEnv", "MLGymWrapper", "make_gsm8k_env", "make_mlgym", "AddThinkingPrompt", "BrowserTransform", "DataLoadingPrimer", "ExecuteToolsInOrder", "JSONCallParser", "KLComputation", "KLRewardTransform", "MCPToolTransform", "PolicyVersion", "PythonExecutorService", "PythonInterpreter", "RayDataLoadingPrimer", "RetrieveKL", "RetrieveLogProb", "SimpleToolTransform", "TemplateTransform", "Tokenizer", "ToolCall", "ToolRegistry", "ToolService", "XMLBlockParser", "as_nested_tensor", "as_padded_tensor", "make_composite_from_td", "DreamerDecoder", "DreamerEnv", "register_gym_spec_conversion", "set_exploration_type", "set_gym_backend", "step_mdp", "terminated_or_truncated", "ActionDiscretizer", "ActionMask", "AutoResetEnv", "AutoResetTransform", "BatchSizeTransform", "BinarizeReward", "BurnInTransform", "CatFrames", "CatTensors", "CenterCrop", "ClipTransform", "Compose", "ConditionalPolicySwitch", "ConditionalSkip", "Crop", "DTypeCastTransform", "DeviceCastTransform", "DiscreteActionProjection", "DoubleToFloat", "EndOfLifeTransform", "ExcludeTransform", "FiniteTensorDictCheck", "FlattenObservation", "FrameSkipTransform", "GrayScale", "Hash", "InitTracker", "KLRewardTransform", "LineariseRewards", "ModuleTransform", "MultiAction", "NoopResetEnv", "ObservationNorm", "ObservationTransform", "PermuteTransform", "PinMemoryTransform", "R3MTransform", "RandomCropTensorDict", "RemoveEmptySpecs", "RenameTransform", "Resize", "Reward2GoTransform", "RewardClipping", "RewardScaling", "RewardSum", "SelectTransform", "SignTransform", "SqueezeTransform", "Stack", "StepCounter", "TargetReturn", "TensorDictPrimer", "TimeMaxPool", "Timer", "ToTensorImage", "Tokenizer", "TrajCounter", "Transform", "TransformedEnv", "UnaryTransform", "UnsqueezeTransform", "VC1Transform", "VIPRewardTransform", "VIPTransform", "VecGymEnvTransform", "VecNorm", "VecNormV2", "gSDENoise", "implement_for", "ActorCriticOperator", "ActorCriticWrapper", "ActorValueOperator", "AdditiveGaussianModule", "ConsistentDropoutModule", "ConvNet", "DTActor", "DdpgCnnActor", "DdpgCnnQNet", "DdpgMlpActor", "DdpgMlpQNet", "DecisionTransformer", "Delta", "DistributionalDQNnet", "DistributionalQValueActor", "DistributionalQValueModule", "DreamerActor", "DuelingCnnDQNet", "EGreedyModule", "GRUModule", "IndependentNormal", "LSTMModule", "MLP", "MaskedCategorical", "NormalParamExtractor", "ObsDecoder", "ObsEncoder", "OneHotCategorical", "OnlineDTActor", "OrnsteinUhlenbeckProcessModule", "QValueActor", "QValueModule", "RSSMPosterior", "RSSMPrior", "RSSMRollout", "ReparamGradientStrategy", "TanhDelta", "TanhNormal", "TruncatedNormal", "ValueOperator", "WorldModelWrapper", "AsyncVLLM", "ChatHistory", "LLMWrapperBase", "LogProbs", "Masks", "RemoteTransformersWrapper", "Text", "Tokens", "TransformersWrapper", "make_async_vllm_engine", "make_vllm_worker", "stateless_init_process_group", "stateless_init_process_group_async", "vLLMWrapper", "SquashDims", "Actor", "MultiStepActorWrapper", "ProbabilisticActor", "RandomPolicy", "SafeModule", "SafeProbabilisticModule", "SafeProbabilisticTensorDictSequential", "SafeSequential", "TanhModule", "A2CLoss", "CQLLoss", "ClipPPOLoss", "CrossQLoss", "DDPGLoss", "DQNLoss", "DTLoss", "DiscreteCQLLoss", "DiscreteIQLLoss", "DiscreteSACLoss", "DistributionalDQNLoss", "DreamerActorLoss", "DreamerModelLoss", "DreamerValueLoss", "GAILLoss", "IQLLoss", "KLPENPPOLoss", "LossModule", "OnlineDTLoss", "PPOLoss", "REDQLoss", "ReinforceLoss", "SACLoss", "TD3BCLoss", "TD3Loss", "ValueEstimators", "add_random_module", "CISPOLoss", "CISPOLossOutput", "DAPO", "DAPOLossOutput", "GRPOLoss", "GRPOLossOutput", "LLMLossOutput", "MCAdvantage", "SFTLoss", "SFTLossOutput", "GAE", "TD0Estimator", "TD1Estimator", "TDLambdaEstimator", "ValueEstimatorBase", "PixelRenderTransform", "TensorDictRecorder", "VideoRecorder", "Logger", "CSVLogger", "generate_exp_name", "get_logger", "MLFlowLogger", "TensorboardLogger", "TrackioLogger", "WandbLogger", "RayService", "ServiceBase", "get_services", "set_auto_unwrap_transformed_env", "BatchSubSampler", "ClearCudaCache", "CountFramesLog", "LogScalar", "LogValidationReward", "OptimizerHook", "ReplayBufferTrainer", "RewardNormalizer", "SelectKeys", "TargetNetUpdaterHook", "Trainer", "TrainerHookBase", "UTDRHook", "UpdateWeights", "PPOTrainer", "SACTrainer", "torchrl.trainers.algorithms.configs.collectors.AsyncDataCollectorConfig", "torchrl.trainers.algorithms.configs.collectors.SyncDataCollectorConfig", "torchrl.trainers.algorithms.configs.common.ConfigBase", "torchrl.trainers.algorithms.configs.data.LazyMemmapStorageConfig", "torchrl.trainers.algorithms.configs.data.LazyStackStorageConfig", "torchrl.trainers.algorithms.configs.data.LazyTensorStorageConfig", "torchrl.trainers.algorithms.configs.data.ListStorageConfig", "torchrl.trainers.algorithms.configs.data.PrioritizedSamplerConfig", "torchrl.trainers.algorithms.configs.data.RandomSamplerConfig", "torchrl.trainers.algorithms.configs.data.ReplayBufferConfig", "torchrl.trainers.algorithms.configs.data.RoundRobinWriterConfig", "torchrl.trainers.algorithms.configs.data.SamplerWithoutReplacementConfig", "torchrl.trainers.algorithms.configs.data.SliceSamplerConfig", "torchrl.trainers.algorithms.configs.data.SliceSamplerWithoutReplacementConfig", "torchrl.trainers.algorithms.configs.data.StorageEnsembleConfig", "torchrl.trainers.algorithms.configs.data.StorageEnsembleWriterConfig", "torchrl.trainers.algorithms.configs.data.TensorDictReplayBufferConfig", "torchrl.trainers.algorithms.configs.data.TensorStorageConfig", "torchrl.trainers.algorithms.configs.envs.BatchedEnvConfig", "torchrl.trainers.algorithms.configs.envs.EnvConfig", "torchrl.trainers.algorithms.configs.envs.TransformedEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.BraxEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.DMControlEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.EnvLibsConfig", "torchrl.trainers.algorithms.configs.envs_libs.GymEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.HabitatEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.IsaacGymEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.JumanjiEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.MOGymEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.MeltingpotEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.MultiThreadedEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.OpenMLEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.OpenSpielEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.PettingZooEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.RoboHiveEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.SMACv2EnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.UnityMLAgentsEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.VmasEnvConfig", "torchrl.trainers.algorithms.configs.logging.CSVLoggerConfig", "torchrl.trainers.algorithms.configs.logging.LoggerConfig", "torchrl.trainers.algorithms.configs.logging.TensorboardLoggerConfig", "torchrl.trainers.algorithms.configs.logging.WandbLoggerConfig", "torchrl.trainers.algorithms.configs.modules.ConvNetConfig", "torchrl.trainers.algorithms.configs.modules.MLPConfig", "torchrl.trainers.algorithms.configs.modules.ModelConfig", "torchrl.trainers.algorithms.configs.modules.NetworkConfig", "torchrl.trainers.algorithms.configs.modules.TanhNormalModelConfig", "torchrl.trainers.algorithms.configs.modules.TensorDictModuleConfig", "torchrl.trainers.algorithms.configs.modules.ValueModelConfig", "torchrl.trainers.algorithms.configs.objectives.LossConfig", "torchrl.trainers.algorithms.configs.objectives.PPOLossConfig", "torchrl.trainers.algorithms.configs.trainers.PPOTrainerConfig", "torchrl.trainers.algorithms.configs.trainers.TrainerConfig", "torchrl.trainers.algorithms.configs.transforms.ActionDiscretizerConfig", "torchrl.trainers.algorithms.configs.transforms.ActionMaskConfig", "torchrl.trainers.algorithms.configs.transforms.AutoResetTransformConfig", "torchrl.trainers.algorithms.configs.transforms.BatchSizeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.BinarizeRewardConfig", "torchrl.trainers.algorithms.configs.transforms.BurnInTransformConfig", "torchrl.trainers.algorithms.configs.transforms.CatFramesConfig", "torchrl.trainers.algorithms.configs.transforms.CatTensorsConfig", "torchrl.trainers.algorithms.configs.transforms.CenterCropConfig", "torchrl.trainers.algorithms.configs.transforms.ClipTransformConfig", "torchrl.trainers.algorithms.configs.transforms.ComposeConfig", "torchrl.trainers.algorithms.configs.transforms.ConditionalPolicySwitchConfig", "torchrl.trainers.algorithms.configs.transforms.ConditionalSkipConfig", "torchrl.trainers.algorithms.configs.transforms.CropConfig", "torchrl.trainers.algorithms.configs.transforms.DTypeCastTransformConfig", "torchrl.trainers.algorithms.configs.transforms.DeviceCastTransformConfig", "torchrl.trainers.algorithms.configs.transforms.DiscreteActionProjectionConfig", "torchrl.trainers.algorithms.configs.transforms.DoubleToFloatConfig", "torchrl.trainers.algorithms.configs.transforms.EndOfLifeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.ExcludeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.FiniteTensorDictCheckConfig", "torchrl.trainers.algorithms.configs.transforms.FlattenObservationConfig", "torchrl.trainers.algorithms.configs.transforms.FrameSkipTransformConfig", "torchrl.trainers.algorithms.configs.transforms.GrayScaleConfig", "torchrl.trainers.algorithms.configs.transforms.HashConfig", "torchrl.trainers.algorithms.configs.transforms.InitTrackerConfig", "torchrl.trainers.algorithms.configs.transforms.KLRewardTransformConfig", "torchrl.trainers.algorithms.configs.transforms.LineariseRewardsConfig", "torchrl.trainers.algorithms.configs.transforms.MultiActionConfig", "torchrl.trainers.algorithms.configs.transforms.MultiStepTransformConfig", "torchrl.trainers.algorithms.configs.transforms.NoopResetEnvConfig", "torchrl.trainers.algorithms.configs.transforms.ObservationNormConfig", "torchrl.trainers.algorithms.configs.transforms.PermuteTransformConfig", "torchrl.trainers.algorithms.configs.transforms.PinMemoryTransformConfig", "torchrl.trainers.algorithms.configs.transforms.R3MTransformConfig", "torchrl.trainers.algorithms.configs.transforms.RandomCropTensorDictConfig", "torchrl.trainers.algorithms.configs.transforms.RemoveEmptySpecsConfig", "torchrl.trainers.algorithms.configs.transforms.RenameTransformConfig", "torchrl.trainers.algorithms.configs.transforms.ResizeConfig", "torchrl.trainers.algorithms.configs.transforms.Reward2GoTransformConfig", "torchrl.trainers.algorithms.configs.transforms.RewardClippingConfig", "torchrl.trainers.algorithms.configs.transforms.RewardScalingConfig", "torchrl.trainers.algorithms.configs.transforms.RewardSumConfig", "torchrl.trainers.algorithms.configs.transforms.SelectTransformConfig", "torchrl.trainers.algorithms.configs.transforms.SignTransformConfig", "torchrl.trainers.algorithms.configs.transforms.SqueezeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.StackConfig", "torchrl.trainers.algorithms.configs.transforms.StepCounterConfig", "torchrl.trainers.algorithms.configs.transforms.TargetReturnConfig", "torchrl.trainers.algorithms.configs.transforms.TensorDictPrimerConfig", "torchrl.trainers.algorithms.configs.transforms.TimeMaxPoolConfig", "torchrl.trainers.algorithms.configs.transforms.TimerConfig", "torchrl.trainers.algorithms.configs.transforms.ToTensorImageConfig", "torchrl.trainers.algorithms.configs.transforms.TokenizerConfig", "torchrl.trainers.algorithms.configs.transforms.TrajCounterConfig", "torchrl.trainers.algorithms.configs.transforms.TransformConfig", "torchrl.trainers.algorithms.configs.transforms.UnaryTransformConfig", "torchrl.trainers.algorithms.configs.transforms.UnsqueezeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VC1TransformConfig", "torchrl.trainers.algorithms.configs.transforms.VIPRewardTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VIPTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VecGymEnvTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VecNormConfig", "torchrl.trainers.algorithms.configs.transforms.VecNormV2Config", "torchrl.trainers.algorithms.configs.utils.ASGDConfig", "torchrl.trainers.algorithms.configs.utils.AdadeltaConfig", "torchrl.trainers.algorithms.configs.utils.AdagradConfig", "torchrl.trainers.algorithms.configs.utils.AdamConfig", "torchrl.trainers.algorithms.configs.utils.AdamWConfig", "torchrl.trainers.algorithms.configs.utils.AdamaxConfig", "torchrl.trainers.algorithms.configs.utils.LBFGSConfig", "torchrl.trainers.algorithms.configs.utils.LionConfig", "torchrl.trainers.algorithms.configs.utils.NAdamConfig", "torchrl.trainers.algorithms.configs.utils.RAdamConfig", "torchrl.trainers.algorithms.configs.utils.RMSpropConfig", "torchrl.trainers.algorithms.configs.utils.RpropConfig", "torchrl.trainers.algorithms.configs.utils.SGDConfig", "torchrl.trainers.algorithms.configs.utils.SparseAdamConfig", "correct_for_frame_skip", "get_stats_random_rollout", "make_collector_offpolicy", "make_collector_onpolicy", "make_dqn_loss", "make_replay_buffer", "make_target_updater", "make_trainer", "parallel_env_constructor", "sync_async_collector", "sync_sync_collector", "transformed_env_constructor", "DistributedTransport", "DistributedWeightSyncScheme", "MPTransport", "MultiProcessWeightSyncScheme", "NoWeightSyncScheme", "RPCTransport", "RPCWeightSyncScheme", "RayModuleTransformScheme", "RayTransport", "RayWeightSyncScheme", "SharedMemTransport", "SharedMemWeightSyncScheme", "TransportBackend", "WeightStrategy", "WeightSyncScheme", "VLLMCollectiveTransport", "VLLMDoubleBufferSyncScheme", "VLLMDoubleBufferTransport", "VLLMDoubleBufferWeightReceiver", "VLLMDoubleBufferWeightSender", "VLLMWeightReceiver", "VLLMWeightSender", "VLLMWeightSyncScheme", "get_model_metadata", "README Tutos", "API Reference", "Knowledge Base", "LLM Interface", "LLM Collectors", "Data Structures", "LLM Environments", "LLM Wrappers", "LLM Objectives", "LLM Transforms", "torchrl.modules package", "Actor Modules", "Value Networks and Critics", "Distribution Classes", "Exploration Strategies", "World Models and Model-Based RL", "Utilities and Helpers", "torchrl.objectives package", "Actor-Critic Methods", "Common Components", "Offline RL Methods", "Other Loss Modules", "Policy Gradient Methods", "Value-Based Methods", "Service Registry", "torchrl.trainers package", "Trainer Basics", "Training Hooks", "Loggers", "torchrl._utils package", "Computation times", "TorchRL objectives: Coding a DDPG loss", "TorchRL trainer: A DQN example", "Reinforcement Learning (PPO) with TorchRL Tutorial", "Recurrent DQN: Training recurrent policies", "Exporting TorchRL modules", "Get started with Environments, TED and transforms", "Get started with TorchRL\u2019s modules", "Getting started with model optimization", "Get started with data collection and storage", "Get started with logging", "Get started with your own first training loop", "README Tutos", "TorchRL LLM: Building Tool-Enabled Environments", "LLM Wrappers in TorchRL", "Task-specific policy in multi-task environments", "Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial", "Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial", "Pendulum: Writing your environment and transforms with TorchRL", "Using pretrained models", "Using Replay Buffers", "Computation times", "Introduction to TorchRL", "TorchRL envs"], "terms": {"an": [0, 2, 6, 12, 16, 17, 18, 19, 20, 21, 22, 24, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 94, 95, 96, 97, 98, 102, 104, 106, 108, 109, 110, 112, 114, 115, 116, 118, 119, 120, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 137, 138, 144, 145, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 165, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 214, 215, 217, 218, 220, 221, 223, 229, 231, 232, 235, 239, 243, 245, 246, 250, 251, 252, 253, 255, 264, 265, 266, 267, 268, 270, 271, 272, 275, 278, 279, 280, 283, 284, 285, 288, 290, 291, 292, 293, 295, 297, 298, 301, 302, 304, 305, 312, 313, 320, 323, 324, 325, 326, 327, 328, 330, 331, 332, 333, 335, 336, 337, 338, 340, 341, 344, 345, 348, 349, 350, 351, 353, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 395, 400, 403, 409, 410, 415, 416, 419, 420, 553, 560, 561, 562, 563, 567, 575, 590, 591, 619, 620, 623, 625, 626, 627, 628, 629, 631, 632, 633, 634, 635, 637, 638, 640, 641], "open": [0, 24, 26, 83, 86, 87, 95, 176, 282, 325, 327, 328, 330, 331, 335, 336, 376, 378, 380, 381, 384, 620, 631, 634, 635, 640], "sourc": [0, 2, 4, 23, 26, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "reinforc": [0, 7, 15, 22, 28, 80, 142, 143, 170, 171, 221, 280, 290, 291, 292, 293, 298, 312, 348, 349, 351, 354, 355, 356, 358, 363, 369, 370, 371, 419, 591, 603, 605, 608, 618, 620, 624, 625, 630, 632, 636, 639, 640], "learn": [0, 7, 15, 19, 22, 26, 27, 28, 42, 80, 81, 82, 84, 85, 86, 87, 101, 102, 126, 142, 143, 147, 150, 158, 170, 171, 176, 177, 221, 280, 290, 291, 292, 293, 298, 312, 325, 327, 328, 330, 331, 348, 349, 350, 351, 354, 355, 356, 358, 362, 363, 367, 368, 369, 370, 371, 376, 378, 379, 380, 381, 384, 419, 420, 591, 603, 605, 608, 618, 619, 620, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 636, 638, 639, 640, 641], "rl": [0, 2, 6, 10, 11, 12, 16, 18, 22, 24, 27, 29, 32, 34, 35, 38, 78, 135, 144, 170, 221, 264, 322, 332, 337, 339, 341, 348, 350, 364, 365, 367, 369, 379, 405, 588, 589, 590, 598, 599, 601, 604, 605, 611, 619, 620, 621, 627, 630, 634, 635, 637, 638, 641], "librari": [0, 2, 3, 6, 10, 16, 17, 20, 22, 24, 25, 26, 27, 28, 29, 30, 35, 36, 38, 42, 44, 47, 123, 124, 125, 134, 145, 168, 177, 190, 324, 403, 589, 590, 617, 619, 620, 621, 623, 624, 625, 627, 634, 635, 636, 641], "pytorch": [0, 2, 3, 6, 19, 20, 56, 81, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 175, 178, 179, 180, 221, 267, 268, 415, 577, 579, 588, 590, 601, 619, 621, 622, 626, 630, 634, 635, 636, 640, 641], "you": [0, 2, 5, 6, 7, 12, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 54, 80, 87, 88, 89, 120, 123, 126, 130, 134, 138, 141, 142, 143, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 221, 242, 271, 279, 280, 326, 332, 337, 344, 367, 375, 377, 379, 382, 383, 400, 404, 586, 590, 591, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "can": [0, 2, 3, 4, 6, 7, 8, 12, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 101, 102, 107, 108, 109, 114, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 134, 136, 137, 138, 141, 142, 143, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 202, 209, 211, 213, 214, 215, 217, 218, 220, 221, 224, 225, 227, 229, 231, 232, 233, 236, 239, 244, 245, 246, 250, 251, 255, 258, 262, 263, 264, 265, 269, 270, 271, 272, 273, 275, 277, 279, 280, 282, 287, 288, 290, 297, 298, 301, 302, 303, 304, 306, 307, 312, 313, 314, 321, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 337, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 400, 401, 402, 404, 408, 409, 419, 465, 561, 562, 563, 565, 567, 568, 570, 571, 573, 574, 575, 576, 577, 578, 580, 585, 586, 590, 591, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "directli": [0, 6, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 69, 78, 81, 88, 120, 121, 122, 123, 126, 129, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 246, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 273, 275, 276, 278, 279, 280, 324, 329, 344, 365, 371, 375, 377, 379, 382, 383, 563, 565, 567, 570, 571, 573, 574, 578, 580, 586, 591, 620, 621, 622, 623, 624, 634, 635, 636, 638], "from": [0, 1, 2, 4, 5, 6, 7, 10, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 96, 97, 98, 101, 102, 106, 107, 108, 109, 110, 112, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 206, 211, 212, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 239, 240, 241, 242, 246, 248, 250, 251, 252, 253, 254, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 277, 278, 279, 280, 282, 283, 284, 285, 287, 290, 291, 292, 293, 294, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 317, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 401, 405, 408, 411, 415, 417, 418, 419, 420, 428, 429, 433, 472, 552, 553, 557, 559, 560, 563, 564, 565, 566, 567, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 590, 591, 598, 605, 612, 613, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641], "pypi": [0, 640], "see": [0, 1, 3, 17, 18, 19, 21, 22, 25, 26, 27, 28, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 96, 102, 108, 109, 120, 123, 126, 130, 133, 135, 137, 138, 142, 143, 145, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 225, 227, 244, 250, 265, 268, 270, 271, 272, 275, 277, 279, 280, 281, 283, 285, 287, 288, 302, 303, 304, 305, 307, 317, 321, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 344, 350, 351, 362, 364, 365, 367, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 400, 401, 411, 419, 565, 567, 570, 571, 573, 574, 575, 578, 580, 586, 589, 591, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 631, 634, 635, 636, 638, 640, 641], "more": [0, 2, 6, 9, 17, 21, 22, 23, 25, 27, 28, 32, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 49, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 101, 102, 114, 120, 123, 126, 129, 130, 131, 133, 134, 137, 138, 142, 143, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 268, 271, 275, 280, 281, 282, 286, 287, 297, 298, 305, 307, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 339, 343, 344, 348, 358, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 400, 401, 410, 586, 589, 590, 591, 605, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 631, 632, 633, 634, 635, 636, 637, 640, 641], "about": [0, 21, 24, 26, 28, 42, 44, 47, 49, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 81, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 183, 195, 326, 332, 337, 619, 620, 621, 623, 624, 625, 626, 627, 628, 629, 634, 635, 636, 638, 640, 641], "instruct": [0, 6, 25, 26, 29, 51, 79, 87, 135, 172, 177, 231, 233, 564, 567, 575, 591, 619, 620, 621, 622, 631, 634, 635, 638], "dedic": [0, 3, 6, 19, 42, 44, 47, 50, 68, 69, 72, 73, 150, 158, 283, 284, 285, 324, 574, 591, 619, 624, 626, 627, 629, 633, 635], "section": [0, 7, 17, 23, 126, 589, 620, 623, 624, 629, 634, 635], "below": [0, 1, 6, 17, 22, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 68, 72, 73, 75, 86, 87, 88, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 227, 244, 250, 265, 270, 271, 272, 275, 277, 288, 303, 305, 317, 321, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 350, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 411, 619, 620, 621, 622, 623, 624, 634, 636], "pip": [0, 29, 82, 190, 623, 624, 625, 626, 627, 628, 629, 631, 635, 640, 641], "provid": [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 15, 16, 17, 18, 19, 21, 22, 24, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 98, 101, 102, 103, 106, 108, 109, 117, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 218, 220, 221, 222, 223, 224, 228, 229, 232, 236, 239, 243, 245, 246, 248, 250, 251, 254, 255, 258, 259, 264, 265, 266, 269, 270, 272, 274, 275, 277, 278, 279, 280, 282, 288, 294, 295, 298, 301, 302, 304, 305, 306, 313, 314, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 337, 339, 340, 341, 344, 347, 348, 349, 350, 351, 352, 353, 355, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 396, 401, 402, 405, 411, 417, 418, 423, 553, 559, 565, 567, 585, 590, 591, 593, 595, 605, 612, 613, 619, 620, 621, 622, 623, 624, 625, 627, 628, 632, 633, 634, 635, 636, 637, 638, 640, 641], "python": [0, 5, 7, 22, 24, 25, 26, 29, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 146, 161, 162, 170, 190, 192, 193, 211, 302, 304, 306, 589, 591, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "first": [0, 1, 2, 5, 6, 9, 17, 18, 19, 20, 22, 23, 24, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 95, 97, 102, 108, 109, 114, 116, 120, 123, 126, 129, 130, 131, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 186, 217, 218, 221, 222, 226, 227, 236, 244, 246, 250, 251, 267, 268, 272, 275, 280, 282, 288, 295, 297, 298, 302, 304, 305, 306, 309, 313, 324, 331, 339, 341, 343, 344, 350, 360, 364, 365, 367, 375, 377, 379, 383, 391, 392, 413, 573, 618, 619, 620, 621, 622, 623, 624, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641], "low": [0, 6, 18, 58, 60, 74, 75, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 183, 206, 214, 224, 231, 239, 242, 265, 273, 298, 319, 320, 321, 341, 344, 347, 367, 483, 619, 620, 621, 623, 634, 635, 636, 640], "high": [0, 1, 18, 22, 28, 58, 60, 72, 75, 86, 87, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 183, 206, 214, 224, 231, 239, 242, 245, 265, 273, 298, 319, 320, 321, 325, 327, 328, 330, 331, 341, 344, 347, 367, 376, 378, 380, 381, 384, 385, 483, 585, 613, 619, 620, 621, 632, 634, 635, 636, 638, 640], "level": [0, 6, 19, 21, 22, 23, 35, 36, 38, 51, 60, 65, 66, 68, 69, 71, 86, 87, 90, 129, 131, 176, 188, 196, 221, 263, 271, 302, 304, 325, 327, 328, 330, 331, 357, 364, 370, 376, 378, 380, 381, 384, 613, 619, 620, 623, 627, 640], "abstract": [0, 19, 27, 41, 74, 78, 82, 118, 126, 247, 389, 402, 406, 416, 423, 576, 578, 621, 623, 636, 640], "ar": [0, 1, 2, 3, 5, 6, 7, 9, 10, 12, 17, 18, 19, 20, 21, 22, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 96, 97, 98, 100, 101, 102, 106, 107, 108, 109, 110, 112, 114, 116, 120, 123, 126, 127, 129, 130, 131, 137, 138, 141, 142, 143, 144, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 213, 214, 216, 217, 218, 220, 221, 224, 225, 227, 229, 230, 231, 232, 233, 235, 236, 239, 241, 242, 244, 245, 248, 250, 255, 258, 262, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 278, 279, 280, 286, 293, 295, 297, 301, 302, 304, 306, 307, 310, 313, 316, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 337, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 400, 401, 402, 403, 404, 411, 415, 417, 418, 419, 420, 559, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 580, 584, 586, 591, 598, 605, 612, 617, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "intend": [0, 6, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 220, 231, 365, 640], "effici": [0, 1, 3, 6, 9, 10, 12, 23, 27, 39, 91, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 192, 332, 351, 417, 567, 572, 591, 593, 605, 612, 619, 620, 621, 622, 623, 626, 627, 629, 633, 634, 635, 637, 638, 640], "modular": [0, 7, 78, 189, 346, 598, 613, 623, 638, 640], "document": [0, 6, 24, 26, 30, 42, 44, 47, 50, 83, 88, 120, 123, 126, 130, 135, 138, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 326, 332, 337, 375, 377, 379, 382, 383, 588, 589, 612, 620, 622, 623, 624, 627, 630, 640], "properli": [0, 4, 5, 21, 22, 52, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 195, 196, 212, 227, 302, 304, 385, 591, 621, 622, 628, 634, 635, 636, 640], "test": [0, 7, 20, 22, 24, 52, 120, 121, 122, 123, 126, 130, 136, 137, 138, 142, 143, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 183, 185, 270, 275, 409, 559, 580, 581, 584, 585, 591, 612, 621, 622, 623, 637, 640], "The": [0, 1, 2, 3, 5, 6, 7, 9, 10, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 93, 101, 102, 106, 108, 109, 110, 114, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 136, 137, 138, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 205, 209, 212, 213, 214, 217, 218, 220, 221, 225, 226, 227, 229, 232, 233, 234, 239, 242, 243, 244, 246, 248, 250, 255, 257, 258, 259, 262, 263, 264, 265, 267, 270, 271, 272, 275, 277, 278, 279, 280, 283, 286, 290, 291, 292, 293, 294, 297, 298, 302, 304, 306, 307, 312, 313, 314, 315, 316, 317, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 343, 344, 346, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 394, 397, 398, 399, 400, 401, 402, 404, 405, 410, 417, 418, 419, 420, 460, 470, 472, 559, 561, 562, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 583, 584, 586, 591, 593, 594, 595, 612, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 634, 635, 636, 637, 638, 640, 641], "code": [0, 6, 17, 18, 22, 24, 26, 27, 35, 38, 60, 71, 83, 120, 123, 126, 130, 135, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 189, 190, 192, 193, 250, 272, 275, 326, 341, 344, 346, 591, 612, 618, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 637, 638, 639, 640, 641], "aim": [0, 21, 26, 70, 71, 250, 275, 277, 305, 552, 590, 619, 620, 640], "support": [0, 2, 3, 4, 7, 10, 16, 18, 19, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 82, 85, 86, 87, 89, 95, 97, 110, 112, 116, 117, 119, 120, 121, 122, 123, 129, 131, 136, 145, 147, 150, 152, 155, 168, 176, 178, 184, 189, 199, 218, 221, 233, 239, 246, 265, 266, 269, 272, 273, 280, 297, 298, 320, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 341, 343, 346, 358, 365, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 397, 403, 565, 567, 570, 571, 573, 575, 576, 577, 578, 580, 586, 591, 593, 598, 605, 612, 613, 621, 622, 624, 625, 631, 632, 635, 636, 638, 640], "research": [0, 26, 28, 142, 143, 632, 640], "most": [0, 4, 6, 12, 17, 21, 26, 27, 35, 36, 38, 63, 101, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 231, 278, 612, 619, 621, 623, 624, 625, 626, 627, 628, 629, 636, 640, 641], "written": [0, 4, 13, 17, 22, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 93, 95, 102, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 183, 212, 213, 214, 221, 233, 236, 241, 242, 258, 263, 266, 267, 272, 278, 282, 287, 312, 322, 325, 327, 328, 330, 331, 339, 341, 343, 344, 348, 350, 364, 367, 369, 376, 378, 379, 380, 381, 384, 390, 391, 392, 417, 591, 619, 622, 623, 625, 633, 636, 640], "highli": [0, 15, 332, 350, 367, 624, 640, 641], "wai": [0, 1, 2, 4, 5, 19, 21, 22, 23, 50, 60, 69, 71, 78, 81, 114, 134, 171, 172, 175, 195, 221, 225, 250, 253, 270, 271, 277, 278, 302, 304, 367, 385, 386, 387, 388, 420, 591, 612, 619, 620, 621, 623, 624, 626, 627, 633, 634, 635, 636, 637, 638, 640, 641], "easili": [0, 2, 7, 17, 18, 22, 26, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 612, 619, 620, 621, 624, 625, 626, 629, 634, 635, 640, 641], "swap": [0, 2, 16, 17, 129, 278, 621, 623, 637, 640], "compon": [0, 2, 6, 7, 10, 12, 19, 21, 22, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 95, 96, 97, 98, 110, 112, 116, 171, 297, 298, 314, 324, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 410, 415, 589, 605, 619, 620, 621, 622, 623, 625, 626, 629, 631, 633, 634, 635, 636, 637, 640], "transform": [0, 3, 4, 6, 10, 12, 16, 17, 18, 20, 22, 23, 27, 32, 34, 35, 36, 38, 40, 41, 42, 44, 47, 50, 52, 53, 54, 55, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 93, 100, 112, 117, 120, 123, 126, 127, 130, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 207, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 287, 289, 290, 294, 299, 302, 304, 311, 317, 320, 325, 327, 328, 329, 330, 331, 332, 337, 340, 347, 354, 366, 376, 378, 380, 381, 382, 383, 384, 390, 392, 411, 418, 419, 430, 435, 436, 437, 441, 472, 563, 571, 572, 573, 589, 593, 612, 618, 620, 622, 623, 625, 627, 628, 629, 630, 631, 637, 639], "them": [0, 6, 12, 19, 26, 28, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 114, 119, 120, 123, 126, 127, 130, 134, 138, 141, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 199, 229, 232, 239, 242, 265, 269, 272, 273, 279, 280, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 338, 340, 347, 349, 351, 357, 363, 364, 368, 370, 371, 372, 386, 387, 388, 392, 564, 567, 574, 576, 581, 582, 583, 612, 619, 620, 622, 623, 624, 625, 627, 628, 632, 633, 634, 635, 636, 637, 638, 640, 641], "write": [0, 17, 27, 32, 34, 35, 36, 38, 52, 56, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 112, 119, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 213, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 248, 249, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 274, 275, 276, 278, 279, 322, 325, 327, 328, 330, 331, 339, 343, 344, 346, 351, 352, 353, 355, 356, 357, 363, 368, 370, 371, 372, 376, 378, 380, 381, 382, 384, 389, 392, 580, 581, 583, 591, 612, 613, 618, 619, 620, 621, 622, 623, 624, 625, 627, 628, 629, 630, 631, 633, 634, 635, 637, 638, 639, 640, 641], "new": [0, 2, 6, 7, 18, 21, 23, 27, 32, 34, 35, 36, 38, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 101, 102, 107, 120, 123, 126, 130, 138, 145, 150, 151, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 212, 213, 218, 243, 258, 262, 271, 272, 279, 280, 295, 302, 304, 312, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 343, 344, 348, 349, 350, 353, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 418, 565, 567, 570, 571, 573, 574, 575, 578, 580, 582, 586, 591, 619, 621, 624, 626, 632, 634, 635, 636, 640, 641], "ones": [0, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 86, 87, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 222, 225, 226, 229, 230, 232, 246, 250, 255, 262, 265, 271, 272, 275, 277, 280, 306, 325, 326, 327, 328, 330, 331, 332, 337, 342, 343, 348, 349, 350, 351, 352, 363, 364, 367, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 591, 619, 621, 623, 632, 634, 635, 636, 638, 640, 641], "littl": [0, 4, 5, 17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272, 348, 350, 364, 367, 369, 621, 622, 623, 627, 638, 640, 641], "effort": [0, 16, 17, 18, 324, 636, 638, 640], "thi": [0, 2, 3, 4, 5, 6, 7, 8, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 100, 101, 102, 106, 107, 108, 109, 110, 112, 114, 116, 117, 119, 120, 121, 122, 123, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 147, 150, 151, 152, 153, 154, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 209, 211, 212, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 243, 244, 246, 249, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 320, 321, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 400, 401, 402, 403, 404, 405, 407, 408, 409, 411, 415, 417, 418, 419, 420, 423, 472, 552, 553, 559, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 590, 591, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "repo": [0, 25, 79, 221, 266, 275, 590, 635, 640], "attempt": [0, 32, 34, 35, 36, 38, 42, 44, 47, 50, 86, 87, 88, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 325, 326, 327, 328, 330, 331, 332, 337, 344, 353, 356, 363, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 626, 640], "align": [0, 640], "exist": [0, 19, 23, 32, 34, 35, 36, 38, 42, 50, 52, 53, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 222, 230, 243, 270, 271, 272, 282, 295, 325, 326, 327, 328, 330, 331, 332, 337, 344, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 401, 402, 403, 553, 563, 572, 612, 634, 635, 640, 641], "ecosystem": [0, 623, 627, 640], "ha": [0, 2, 4, 6, 7, 18, 21, 22, 23, 24, 26, 27, 29, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 97, 101, 102, 106, 108, 114, 116, 120, 123, 126, 127, 130, 134, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 218, 221, 243, 244, 263, 264, 265, 266, 267, 269, 270, 271, 272, 286, 298, 302, 304, 320, 325, 326, 327, 328, 330, 331, 332, 337, 340, 344, 348, 351, 364, 365, 367, 369, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 392, 419, 472, 564, 572, 591, 619, 620, 621, 622, 623, 624, 627, 628, 631, 633, 634, 635, 636, 637, 638, 640, 641], "dataset": [0, 10, 65, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 94, 102, 106, 108, 109, 147, 170, 171, 172, 175, 176, 177, 178, 181, 185, 194, 279, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 392, 589, 591, 619, 620, 624, 637, 638, 640, 641], "pillar": [0, 640], "environ": [0, 1, 2, 3, 4, 6, 16, 20, 24, 27, 29, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 66, 70, 71, 74, 75, 76, 77, 88, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 208, 214, 215, 217, 218, 220, 221, 222, 226, 227, 229, 230, 231, 232, 237, 244, 245, 246, 250, 251, 252, 255, 258, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 278, 279, 280, 287, 302, 304, 317, 332, 337, 340, 355, 359, 382, 385, 386, 387, 388, 389, 390, 392, 404, 405, 407, 409, 419, 420, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 472, 552, 553, 554, 555, 559, 560, 561, 562, 563, 589, 590, 597, 612, 618, 623, 625, 626, 627, 628, 630, 637, 638, 639], "model": [0, 2, 3, 6, 17, 19, 27, 28, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 55, 86, 87, 88, 89, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 229, 250, 265, 275, 277, 281, 283, 284, 285, 288, 289, 294, 296, 305, 311, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 343, 348, 349, 350, 351, 353, 354, 355, 356, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 401, 402, 415, 465, 467, 469, 554, 555, 556, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 583, 585, 586, 587, 589, 590, 591, 593, 598, 618, 621, 624, 627, 630, 632, 634, 635, 636, 638, 639, 641], "data": [0, 1, 2, 3, 4, 6, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 27, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 135, 136, 137, 138, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 165, 170, 171, 172, 175, 176, 177, 178, 179, 180, 182, 185, 188, 189, 190, 191, 194, 195, 196, 199, 202, 206, 213, 215, 218, 220, 221, 226, 229, 230, 232, 234, 236, 239, 241, 246, 252, 255, 262, 263, 265, 269, 271, 272, 273, 278, 280, 297, 301, 302, 304, 312, 313, 322, 325, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336, 337, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 376, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 390, 392, 400, 405, 408, 411, 415, 417, 418, 419, 420, 472, 554, 559, 561, 562, 563, 566, 572, 579, 584, 589, 591, 594, 598, 612, 613, 618, 622, 623, 624, 625, 626, 630, 631, 632, 636, 637, 638, 639, 641], "util": [0, 11, 17, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 56, 68, 86, 87, 88, 108, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 143, 150, 151, 152, 153, 154, 158, 159, 160, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 265, 277, 287, 288, 294, 302, 304, 325, 326, 327, 328, 330, 331, 332, 337, 338, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 556, 559, 589, 597, 598, 607, 613, 617, 619, 621, 623, 625, 626, 635, 636, 638, 640, 641], "e": [0, 2, 6, 7, 17, 19, 20, 21, 22, 26, 27, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 89, 90, 95, 97, 101, 102, 114, 116, 120, 123, 126, 127, 130, 131, 138, 150, 151, 154, 158, 159, 160, 163, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 220, 222, 225, 226, 227, 228, 236, 239, 242, 244, 246, 250, 258, 265, 267, 270, 271, 272, 275, 277, 282, 298, 302, 303, 304, 307, 314, 320, 321, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 340, 341, 343, 344, 348, 350, 351, 352, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 402, 405, 415, 419, 472, 552, 562, 565, 566, 567, 568, 570, 571, 572, 573, 575, 578, 579, 580, 583, 586, 591, 612, 620, 621, 623, 625, 626, 628, 632, 634, 635, 637, 638, 640, 641], "g": [0, 2, 6, 7, 17, 19, 20, 21, 22, 26, 27, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 89, 114, 120, 123, 126, 127, 130, 131, 138, 150, 151, 154, 158, 159, 160, 163, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 220, 222, 225, 226, 236, 239, 242, 246, 250, 258, 265, 267, 270, 271, 272, 275, 277, 282, 302, 303, 304, 320, 321, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 341, 343, 344, 351, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 402, 415, 419, 472, 562, 565, 566, 567, 568, 570, 571, 573, 575, 578, 579, 580, 583, 586, 591, 612, 620, 621, 623, 625, 628, 634, 635, 636, 637, 638, 640, 641], "collector": [0, 7, 17, 18, 22, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 255, 263, 271, 302, 304, 312, 326, 329, 332, 337, 342, 350, 364, 367, 379, 382, 411, 415, 418, 419, 420, 472, 554, 555, 559, 561, 562, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 575, 578, 580, 586, 589, 591, 605, 612, 613, 623, 638, 641], "contain": [0, 17, 21, 22, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 94, 102, 104, 106, 108, 109, 110, 115, 118, 119, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 221, 225, 229, 232, 239, 250, 262, 265, 270, 271, 272, 275, 277, 278, 279, 280, 288, 297, 298, 305, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 343, 344, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 396, 405, 552, 559, 560, 561, 562, 563, 574, 581, 582, 591, 605, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 634, 635, 636, 637, 638, 640, 641], "etc": [0, 6, 7, 12, 17, 21, 22, 26, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 262, 272, 282, 305, 320, 326, 332, 337, 375, 377, 379, 382, 383, 401, 565, 566, 567, 568, 570, 571, 573, 575, 578, 580, 586, 598, 620, 621, 627, 638, 640, 641], "have": [0, 2, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 32, 35, 36, 38, 42, 46, 47, 50, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 107, 110, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 209, 213, 214, 217, 221, 226, 229, 232, 233, 241, 245, 246, 262, 263, 265, 269, 270, 271, 272, 279, 280, 286, 288, 305, 306, 312, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 345, 346, 348, 350, 364, 367, 369, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 392, 401, 405, 415, 417, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586, 591, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 633, 634, 635, 636, 637, 638, 640, 641], "few": [0, 12, 27, 86, 87, 109, 130, 176, 180, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 392, 405, 591, 612, 621, 622, 625, 634, 635, 638, 640, 641], "depend": [0, 2, 3, 5, 6, 18, 21, 22, 23, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 58, 75, 120, 123, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 175, 177, 178, 179, 180, 190, 229, 232, 322, 332, 337, 344, 367, 394, 612, 619, 621, 622, 631, 634, 635, 636, 640, 641], "possibl": [0, 19, 20, 22, 23, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 80, 83, 85, 86, 87, 88, 96, 102, 108, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 225, 250, 265, 270, 271, 272, 275, 277, 288, 324, 325, 326, 327, 328, 330, 331, 332, 337, 343, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 409, 415, 591, 619, 621, 622, 623, 625, 627, 628, 634, 635, 636, 638, 640, 641], "standard": [0, 19, 21, 63, 123, 246, 257, 279, 280, 286, 299, 311, 324, 326, 332, 337, 350, 364, 367, 371, 372, 385, 386, 387, 388, 408, 619, 620, 624, 625, 635, 638, 640], "numpi": [0, 20, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 239, 268, 273, 282, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 415, 623, 636, 638, 640, 641], "common": [0, 22, 23, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 74, 88, 120, 130, 136, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 233, 271, 283, 284, 285, 326, 348, 349, 350, 351, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 379, 382, 401, 402, 419, 559, 589, 590, 591, 605, 612, 619, 621, 625, 628, 633, 634, 635, 636, 637, 640, 641], "openai": [0, 26, 129, 131, 138, 155, 179, 621, 636, 640, 641], "gym": [0, 3, 7, 16, 17, 18, 22, 23, 27, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 88, 120, 123, 126, 127, 129, 130, 131, 132, 134, 135, 138, 142, 143, 145, 146, 150, 151, 154, 155, 158, 159, 160, 163, 164, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 209, 211, 217, 221, 224, 233, 240, 241, 246, 248, 253, 255, 258, 265, 271, 278, 279, 282, 382, 449, 559, 590, 619, 620, 621, 622, 624, 628, 629, 636, 637, 638], "onli": [0, 2, 6, 7, 17, 19, 20, 22, 23, 26, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 95, 97, 101, 102, 108, 109, 116, 120, 123, 124, 125, 126, 129, 130, 131, 132, 134, 137, 138, 145, 146, 150, 151, 152, 153, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 217, 221, 222, 224, 225, 226, 227, 229, 231, 232, 236, 239, 244, 246, 250, 251, 255, 262, 263, 264, 265, 266, 270, 271, 272, 275, 277, 279, 280, 282, 297, 304, 306, 313, 326, 329, 332, 337, 339, 341, 343, 344, 345, 346, 348, 350, 351, 352, 356, 357, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 392, 400, 401, 403, 415, 417, 553, 566, 575, 579, 586, 612, 619, 620, 621, 622, 623, 625, 626, 627, 628, 629, 631, 633, 634, 635, 636, 638, 640, 641], "option": [0, 3, 6, 10, 18, 22, 23, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 101, 102, 103, 104, 106, 107, 108, 109, 112, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 205, 206, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 228, 229, 231, 232, 233, 234, 236, 237, 239, 240, 241, 242, 243, 244, 245, 246, 250, 251, 253, 254, 257, 258, 259, 262, 263, 264, 265, 266, 268, 269, 270, 272, 273, 274, 275, 277, 278, 279, 280, 282, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 339, 340, 341, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 394, 397, 399, 400, 401, 402, 403, 405, 407, 408, 409, 410, 411, 412, 415, 418, 419, 420, 472, 553, 559, 561, 562, 563, 565, 567, 568, 570, 571, 572, 573, 575, 578, 579, 580, 583, 585, 586, 589, 591, 622, 624, 627, 634, 635, 638, 640], "On": [0, 5, 19, 21, 26, 42, 44, 47, 50, 60, 80, 567, 575, 580, 591, 620, 634, 635], "end": [0, 6, 17, 32, 35, 36, 38, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 93, 102, 107, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 233, 239, 248, 263, 264, 270, 272, 288, 326, 332, 337, 340, 351, 370, 375, 377, 379, 382, 383, 433, 434, 492, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "come": [0, 1, 2, 4, 5, 6, 18, 20, 21, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 114, 120, 123, 126, 130, 137, 138, 141, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 229, 232, 283, 284, 285, 322, 339, 341, 348, 350, 364, 367, 369, 392, 566, 574, 619, 620, 621, 622, 626, 627, 628, 629, 634, 635, 638, 640, 641], "set": [0, 2, 3, 6, 7, 15, 17, 18, 21, 22, 26, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 98, 107, 110, 116, 120, 123, 126, 128, 130, 131, 137, 138, 142, 143, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 211, 213, 215, 217, 218, 221, 222, 225, 229, 232, 239, 240, 241, 242, 250, 255, 263, 264, 265, 266, 270, 271, 272, 275, 277, 279, 280, 282, 302, 304, 306, 312, 317, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 343, 344, 350, 351, 357, 362, 364, 365, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 389, 392, 404, 405, 409, 411, 420, 555, 563, 565, 567, 568, 570, 571, 572, 573, 575, 578, 580, 586, 590, 591, 617, 619, 620, 621, 622, 623, 625, 626, 627, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "re": [0, 21, 27, 33, 42, 43, 44, 45, 47, 48, 50, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 107, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 236, 304, 306, 326, 332, 337, 341, 344, 375, 377, 379, 382, 383, 400, 613, 619, 621, 622, 624, 626, 631, 633, 634, 636, 640, 641], "usabl": [0, 613, 622, 640], "function": [0, 1, 7, 12, 17, 18, 19, 20, 21, 22, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 126, 127, 130, 131, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 211, 212, 213, 217, 218, 229, 232, 239, 241, 243, 269, 270, 272, 273, 279, 280, 282, 283, 284, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 304, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 321, 322, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 341, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 401, 403, 415, 419, 420, 471, 472, 559, 567, 578, 587, 593, 596, 604, 619, 622, 623, 624, 625, 628, 631, 633, 636, 638, 641], "cost": [0, 15, 59, 83, 96, 98, 348, 350, 364, 367, 369, 619, 620, 623, 634, 635, 636, 638], "return": [0, 1, 5, 6, 10, 16, 17, 18, 19, 20, 21, 22, 26, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 94, 96, 102, 104, 106, 108, 109, 112, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 204, 205, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 288, 289, 290, 291, 292, 293, 295, 302, 303, 304, 305, 306, 307, 310, 311, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 343, 344, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 396, 401, 402, 403, 404, 415, 417, 418, 552, 554, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 584, 586, 587, 591, 605, 612, 619, 620, 621, 623, 625, 626, 628, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "process": [0, 1, 2, 3, 5, 6, 7, 12, 18, 21, 22, 23, 24, 27, 32, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 49, 50, 52, 53, 65, 68, 72, 73, 78, 80, 84, 85, 86, 87, 88, 90, 95, 97, 101, 102, 104, 108, 116, 120, 123, 126, 127, 130, 134, 138, 141, 145, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 220, 221, 229, 232, 239, 265, 268, 270, 271, 279, 280, 298, 302, 304, 312, 314, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 350, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 565, 566, 567, 568, 570, 571, 572, 573, 575, 578, 579, 580, 586, 591, 612, 619, 620, 622, 623, 624, 631, 632, 634, 635, 636, 637, 638, 640, 641], "good": [0, 2, 23, 28, 101, 102, 150, 191, 591, 612, 619, 621, 622, 623, 625, 635, 640, 641], "runtim": [0, 22, 56, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 612, 636], "perform": [0, 5, 6, 7, 10, 18, 20, 22, 23, 27, 32, 33, 35, 36, 38, 42, 43, 44, 45, 47, 48, 54, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 123, 124, 125, 126, 129, 130, 131, 132, 137, 138, 150, 151, 154, 155, 158, 159, 160, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 239, 245, 267, 270, 272, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 338, 340, 347, 350, 351, 360, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 409, 415, 417, 564, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586, 589, 591, 619, 620, 621, 622, 623, 624, 627, 629, 632, 633, 634, 635, 636, 641], "To": [0, 7, 18, 19, 20, 21, 23, 25, 26, 27, 28, 41, 42, 44, 47, 65, 66, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 93, 102, 108, 109, 112, 119, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 141, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 227, 263, 265, 279, 283, 284, 285, 287, 302, 304, 312, 326, 332, 337, 344, 351, 357, 362, 365, 371, 375, 377, 379, 382, 383, 392, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 418, 584, 585, 591, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 634, 635, 636, 637, 638, 640, 641], "read": [0, 6, 17, 26, 56, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 110, 112, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 233, 234, 235, 236, 237, 240, 241, 243, 248, 249, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 269, 270, 271, 274, 275, 276, 278, 279, 283, 284, 285, 287, 297, 310, 322, 323, 325, 327, 328, 330, 331, 339, 340, 341, 343, 344, 346, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 392, 409, 415, 567, 574, 580, 581, 582, 619, 620, 621, 623, 624, 625, 633, 634, 635, 636, 637, 640, 641], "philosophi": [0, 28], "capabl": [0, 3, 18, 20, 26, 28, 30, 39, 50, 56, 170, 184, 419, 581, 591, 619, 624, 627, 631, 633, 637, 641], "beyond": [0, 6, 7, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 612, 623], "api": [0, 6, 16, 18, 22, 24, 46, 56, 60, 71, 74, 86, 87, 123, 126, 152, 153, 155, 176, 180, 182, 190, 250, 277, 279, 280, 324, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 383, 384, 419, 420, 580, 582, 584, 586, 591, 593, 595, 623, 624, 625, 626, 627, 628, 632, 634, 635, 636, 638, 640, 641], "check": [0, 17, 22, 23, 24, 25, 26, 28, 32, 34, 35, 36, 38, 42, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 86, 87, 88, 92, 93, 100, 108, 120, 123, 126, 127, 129, 130, 131, 138, 144, 150, 151, 154, 158, 159, 160, 165, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 222, 227, 235, 241, 251, 265, 268, 272, 282, 295, 297, 298, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 343, 344, 351, 362, 367, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 401, 403, 564, 565, 567, 570, 571, 573, 575, 578, 579, 580, 581, 586, 588, 612, 620, 621, 622, 623, 624, 625, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 640, 641], "paper": [0, 80, 83, 121, 122, 124, 125, 132, 136, 137, 142, 143, 145, 146, 155, 163, 164, 250, 275, 277, 288, 355, 371, 375, 377, 379, 619, 621, 634, 635], "releas": [0, 6, 23, 26, 29, 54, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383, 568, 570, 571, 573, 578, 580, 586, 591, 612], "sync": [0, 1, 2, 5, 7, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 120, 191, 324, 418, 559, 564, 565, 567, 575, 619], "so": [0, 5, 21, 22, 23, 25, 26, 29, 30, 50, 60, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 265, 270, 279, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 345, 346, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 392, 567, 575, 591, 619, 621, 622, 626, 629, 634, 635, 636, 641], "make": [0, 1, 5, 6, 7, 16, 17, 18, 19, 21, 23, 26, 30, 60, 65, 66, 68, 69, 74, 78, 79, 82, 84, 85, 86, 87, 88, 106, 110, 112, 119, 120, 123, 126, 130, 131, 134, 135, 137, 138, 140, 146, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 227, 234, 242, 246, 250, 251, 255, 259, 263, 267, 271, 275, 287, 297, 302, 304, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 348, 350, 364, 367, 369, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 401, 411, 555, 563, 598, 619, 620, 621, 622, 623, 624, 625, 626, 628, 629, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "sure": [0, 5, 19, 23, 26, 50, 82, 88, 110, 123, 130, 134, 173, 174, 175, 177, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 255, 271, 297, 382, 563, 619, 621, 622, 623, 626, 634, 635, 636, 638, 640, 641], "alwai": [0, 19, 21, 22, 35, 36, 38, 47, 52, 58, 74, 75, 78, 88, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 245, 267, 279, 280, 326, 332, 337, 358, 365, 375, 377, 379, 382, 383, 465, 565, 567, 568, 570, 571, 573, 575, 578, 580, 581, 586, 612, 620, 621, 622, 623, 634, 635, 636, 638], "enjoi": [0, 22, 83, 627], "latest": [0, 21, 29, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 145, 148, 149, 152, 153, 190, 411, 621, 634, 635, 636, 640], "featur": [0, 5, 6, 18, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 54, 56, 63, 64, 74, 81, 86, 87, 102, 108, 109, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 197, 218, 221, 236, 239, 241, 248, 265, 266, 274, 279, 288, 299, 300, 302, 304, 305, 325, 326, 327, 328, 330, 331, 332, 337, 344, 348, 350, 364, 367, 369, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 401, 419, 420, 563, 589, 593, 619, 620, 621, 622, 623, 625, 626, 627, 629, 632, 636, 638, 640, 641], "recent": [0, 26, 189, 278, 280, 282, 641], "version": [0, 2, 5, 6, 7, 18, 25, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 48, 49, 52, 53, 54, 55, 76, 77, 80, 85, 86, 87, 88, 108, 120, 123, 126, 129, 130, 131, 132, 138, 145, 146, 150, 151, 152, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 221, 269, 278, 279, 280, 282, 285, 302, 304, 325, 326, 327, 328, 329, 330, 331, 332, 336, 337, 348, 350, 364, 365, 367, 369, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 388, 419, 420, 589, 590, 593, 619, 621, 622, 623, 624, 626, 629, 634, 635, 636, 637, 641], "although": [0, 2, 5, 21, 27, 50, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 338, 340, 347, 619, 620, 627, 638], "core": [0, 7, 10, 19, 27, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 170, 612, 613, 614, 622, 625, 640], "guarante": [0, 12, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 344, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 627], "backward": [0, 1, 3, 5, 7, 8, 9, 27, 35, 36, 38, 54, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 344, 348, 349, 351, 352, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 418, 619, 621, 622, 623, 626, 627, 629, 634, 635, 636], "compat": [0, 1, 3, 5, 6, 7, 17, 18, 26, 34, 35, 36, 38, 50, 54, 56, 60, 69, 71, 79, 86, 87, 88, 96, 98, 106, 108, 109, 110, 114, 120, 123, 126, 130, 132, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 263, 272, 275, 279, 280, 282, 302, 304, 313, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 351, 352, 353, 355, 356, 357, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 418, 572, 580, 582, 586, 591, 619, 622, 631, 638], "2": [0, 2, 4, 7, 8, 10, 18, 19, 21, 22, 27, 28, 29, 34, 35, 38, 50, 51, 52, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 95, 97, 101, 102, 108, 109, 114, 116, 120, 121, 122, 123, 126, 127, 130, 136, 137, 138, 141, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 206, 213, 217, 218, 220, 222, 225, 226, 227, 229, 230, 231, 232, 241, 242, 246, 248, 250, 252, 255, 258, 262, 263, 264, 265, 270, 271, 272, 275, 277, 279, 280, 282, 287, 288, 289, 290, 291, 292, 293, 294, 297, 298, 300, 301, 302, 304, 305, 306, 307, 311, 312, 320, 322, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 337, 338, 340, 343, 347, 348, 349, 350, 351, 352, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 392, 401, 405, 463, 464, 467, 468, 469, 549, 565, 566, 567, 569, 570, 571, 572, 573, 575, 578, 580, 586, 591, 598, 612, 618, 619, 620, 621, 622, 623, 625, 626, 633, 634, 635, 636, 638, 639, 640, 641], "0": [0, 2, 6, 7, 9, 10, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 101, 102, 108, 109, 116, 120, 121, 122, 123, 126, 129, 130, 132, 133, 136, 137, 138, 144, 145, 146, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 203, 205, 214, 215, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 230, 231, 233, 234, 235, 237, 240, 241, 242, 243, 244, 245, 246, 249, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 275, 276, 277, 278, 279, 280, 282, 286, 287, 288, 290, 291, 292, 293, 294, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 310, 312, 314, 315, 316, 319, 320, 321, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 339, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 401, 405, 412, 418, 419, 425, 445, 449, 463, 467, 471, 472, 487, 503, 505, 513, 515, 519, 520, 522, 531, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 559, 563, 565, 566, 571, 572, 573, 574, 579, 582, 584, 585, 586, 591, 605, 612, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641], "nightli": [0, 25], "via": [0, 3, 6, 17, 18, 22, 23, 26, 27, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 79, 81, 82, 83, 84, 85, 87, 89, 96, 130, 150, 158, 178, 180, 186, 190, 242, 250, 253, 277, 326, 332, 337, 351, 354, 365, 375, 377, 379, 383, 419, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 579, 580, 584, 586, 605, 619, 620, 621, 622, 625, 627, 638, 640, 641], "tensordict": [0, 1, 2, 6, 10, 16, 17, 18, 19, 20, 21, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 96, 97, 98, 100, 101, 102, 106, 108, 109, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 206, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 283, 284, 285, 286, 287, 296, 297, 298, 301, 302, 304, 307, 312, 313, 314, 317, 322, 325, 326, 327, 328, 329, 330, 331, 332, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 405, 409, 410, 411, 413, 415, 418, 437, 468, 564, 565, 567, 568, 570, 571, 572, 573, 574, 575, 577, 578, 579, 580, 581, 582, 583, 586, 591, 598, 605, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 633, 634, 635, 636, 637, 641], "git": [0, 25, 26, 29], "clone": [0, 23, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 95, 172, 184, 193, 194, 241, 252, 270, 271, 280, 283, 284, 285, 326, 332, 337, 343, 356, 363, 371, 619, 634, 636, 640], "willing": 0, "contribut": [0, 306, 419], "cd": [0, 26], "path": [0, 18, 25, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 93, 95, 111, 117, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 250, 277, 325, 326, 327, 328, 329, 330, 331, 332, 337, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 394, 400, 401, 415, 418, 419, 420, 472, 580, 581, 620, 623, 629, 634], "root": [0, 19, 21, 22, 60, 65, 66, 68, 69, 71, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 221, 244, 266, 267, 302, 303, 304, 320, 321, 385, 622, 624, 634, 635, 636, 638, 641], "http": [0, 24, 25, 26, 29, 35, 38, 42, 44, 47, 65, 78, 80, 81, 82, 83, 84, 85, 101, 102, 121, 122, 124, 125, 132, 134, 136, 137, 142, 143, 145, 146, 147, 148, 149, 152, 153, 155, 161, 162, 163, 164, 177, 186, 190, 221, 250, 275, 289, 290, 291, 292, 293, 294, 298, 299, 300, 306, 308, 309, 312, 315, 316, 317, 348, 349, 351, 353, 354, 355, 356, 358, 359, 360, 361, 362, 363, 366, 367, 368, 369, 370, 371, 385, 588, 630, 631, 637, 640], "github": [0, 24, 25, 26, 29, 42, 44, 47, 78, 80, 81, 83, 121, 122, 124, 125, 129, 132, 136, 137, 142, 143, 145, 146, 148, 149, 152, 153, 155, 161, 162, 163, 164, 218, 221, 275, 625, 629, 631, 634, 635, 640], "com": [0, 24, 25, 26, 29, 42, 44, 47, 80, 83, 84, 121, 122, 124, 125, 132, 134, 136, 137, 142, 143, 145, 146, 148, 149, 152, 153, 155, 161, 162, 163, 164, 221, 631, 640], "setup": [0, 1, 6, 26, 42, 47, 50, 121, 122, 134, 136, 137, 161, 195, 196, 383, 419, 580, 585, 586], "py": [0, 6, 7, 18, 22, 129, 131, 211, 221, 295, 612, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641], "develop": [0, 6, 22, 23, 26, 134, 332, 337, 591, 619, 632, 640], "If": [0, 2, 3, 4, 5, 6, 9, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 102, 104, 106, 107, 108, 109, 114, 116, 120, 123, 124, 125, 126, 127, 129, 130, 131, 132, 134, 137, 138, 142, 143, 144, 145, 146, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 209, 212, 213, 214, 217, 218, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 236, 239, 241, 242, 243, 244, 245, 246, 250, 251, 254, 255, 258, 259, 264, 265, 266, 267, 268, 269, 270, 272, 273, 275, 277, 279, 280, 282, 287, 288, 297, 298, 301, 302, 304, 305, 306, 312, 313, 314, 322, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 339, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 357, 358, 359, 360, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 396, 400, 401, 402, 403, 404, 408, 410, 411, 415, 418, 419, 420, 472, 553, 559, 563, 564, 565, 567, 569, 570, 571, 572, 573, 574, 575, 578, 580, 581, 583, 585, 586, 590, 619, 620, 621, 622, 623, 624, 626, 628, 629, 631, 633, 634, 635, 636, 638, 640, 641], "us": [0, 1, 2, 3, 4, 7, 8, 9, 12, 15, 16, 17, 18, 19, 20, 22, 24, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 98, 100, 101, 102, 103, 108, 109, 114, 116, 120, 121, 122, 123, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 210, 211, 212, 213, 214, 215, 217, 218, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 244, 246, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 282, 286, 287, 288, 289, 290, 291, 294, 296, 297, 298, 299, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 317, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 343, 344, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 395, 396, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 460, 470, 472, 553, 554, 555, 557, 559, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 578, 579, 580, 581, 582, 583, 584, 585, 586, 590, 591, 592, 605, 612, 613, 617, 618, 619, 620, 621, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 639, 641], "uv": 0, "specif": [0, 1, 2, 7, 16, 18, 22, 24, 27, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 72, 73, 74, 75, 76, 77, 120, 123, 126, 130, 138, 148, 149, 150, 151, 154, 158, 159, 160, 163, 170, 171, 172, 175, 178, 179, 180, 185, 190, 209, 244, 265, 280, 294, 302, 304, 324, 326, 332, 333, 334, 337, 348, 350, 365, 367, 369, 375, 377, 379, 383, 392, 401, 402, 403, 415, 419, 564, 565, 567, 568, 569, 570, 571, 572, 573, 578, 580, 586, 589, 598, 612, 613, 618, 621, 622, 624, 625, 626, 627, 628, 629, 630, 631, 634, 635, 638, 639, 640], "build": [0, 3, 7, 21, 26, 56, 60, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 121, 122, 123, 126, 130, 131, 132, 136, 137, 138, 142, 143, 145, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 255, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 415, 556, 557, 558, 593, 598, 604, 618, 621, 622, 623, 625, 626, 627, 628, 630, 634, 635, 636, 637, 639, 640, 641], "beforehand": 0, "wheel": [0, 621], "dep": 0, "edit": [0, 21, 183, 271, 627], "prevent": [0, 23, 57, 59, 60, 61, 62, 64, 66, 71, 93, 101, 102, 121, 122, 279, 280, 303, 320, 321, 324, 332, 337, 348, 350, 364, 367, 369, 379, 412, 591, 628, 638], "resolut": [0, 326, 332, 337, 347, 565, 568, 570, 571, 573, 578, 580, 586], "potenti": [0, 2, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 636, 638], "downgrad": 0, "A": [0, 2, 6, 21, 22, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 107, 108, 110, 114, 115, 116, 117, 118, 120, 123, 126, 128, 130, 132, 133, 135, 138, 150, 151, 154, 155, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 203, 204, 205, 207, 212, 214, 216, 217, 218, 220, 221, 224, 225, 226, 227, 231, 237, 241, 243, 244, 250, 251, 253, 260, 265, 267, 270, 271, 272, 275, 276, 278, 279, 280, 281, 282, 286, 287, 288, 297, 298, 301, 302, 304, 305, 306, 307, 313, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 338, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 393, 394, 397, 400, 402, 403, 404, 407, 414, 415, 418, 420, 459, 460, 461, 462, 463, 464, 465, 467, 468, 469, 470, 471, 559, 567, 575, 578, 580, 586, 587, 612, 618, 619, 621, 623, 625, 626, 627, 630, 631, 636, 639, 641], "seri": [0, 12, 17, 26, 27, 64, 94, 104, 114, 115, 118, 119, 158, 245, 271, 392, 619, 620, 621, 628, 629, 634, 635, 638, 641], "quick": [0, 78, 589, 623], "ramp": 0, "up": [0, 1, 2, 5, 6, 7, 8, 21, 22, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 201, 217, 220, 239, 242, 266, 271, 324, 329, 367, 382, 402, 420, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586, 590, 612, 619, 620, 621, 622, 625, 629, 631, 632, 634, 635, 636, 638, 640, 641], "hurri": [0, 624], "last": [0, 2, 17, 18, 23, 32, 34, 35, 36, 38, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 107, 108, 109, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 183, 195, 206, 214, 217, 220, 225, 226, 236, 244, 246, 251, 264, 266, 268, 278, 282, 286, 288, 301, 302, 304, 305, 306, 308, 320, 326, 332, 337, 338, 340, 344, 351, 385, 387, 388, 591, 620, 621, 622, 623, 624, 625, 631, 634, 635, 636, 637, 638, 640, 641], "item": [0, 21, 27, 34, 38, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 96, 102, 107, 114, 214, 235, 271, 280, 306, 352, 353, 355, 383, 405, 605, 619, 621, 622, 626, 627, 631, 634, 635, 636, 638], "navig": [0, 184, 631, 635], "previou": [0, 22, 23, 29, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 236, 265, 316, 317, 621, 622, 623, 624, 625, 629, 636, 641], "whenev": [0, 2, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 83, 88, 101, 102, 108, 109, 124, 125, 129, 131, 132, 142, 143, 155, 163, 164, 171, 172, 173, 174, 175, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 236, 240, 271, 272, 278, 326, 332, 337, 365, 375, 377, 379, 382, 383, 385, 386, 387, 388, 390, 418, 628, 631, 638], "want": [0, 5, 6, 21, 22, 25, 26, 27, 34, 50, 52, 109, 171, 172, 175, 185, 221, 246, 326, 332, 337, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 612, 619, 620, 621, 622, 623, 624, 626, 627, 628, 634, 635, 636, 637, 638, 640, 641], "ted": [0, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 100, 618, 630, 639], "s": [0, 1, 2, 3, 5, 6, 7, 17, 18, 19, 21, 22, 25, 26, 27, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 55, 60, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 108, 109, 114, 120, 121, 122, 123, 126, 130, 134, 136, 137, 138, 142, 143, 145, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 225, 226, 239, 244, 250, 263, 265, 268, 269, 270, 271, 272, 275, 277, 279, 280, 283, 285, 286, 288, 295, 298, 301, 302, 304, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 343, 344, 347, 349, 350, 351, 356, 362, 363, 364, 365, 367, 370, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 401, 417, 418, 419, 564, 565, 566, 567, 568, 570, 571, 572, 573, 575, 578, 579, 580, 581, 582, 586, 591, 612, 618, 619, 620, 621, 622, 623, 624, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641], "modul": [0, 6, 7, 17, 18, 21, 22, 23, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 65, 68, 69, 72, 73, 86, 87, 88, 114, 120, 121, 122, 123, 126, 130, 138, 144, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 214, 220, 221, 225, 231, 233, 239, 241, 243, 250, 251, 255, 264, 265, 270, 271, 272, 275, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 414, 415, 417, 419, 420, 472, 556, 559, 565, 567, 568, 570, 571, 572, 573, 577, 578, 580, 586, 589, 591, 602, 603, 604, 605, 606, 607, 608, 610, 611, 618, 620, 621, 624, 626, 627, 628, 630, 632, 633, 634, 635, 636, 637, 638, 639], "optim": [0, 1, 2, 15, 27, 55, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 349, 351, 365, 366, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 409, 410, 415, 417, 419, 420, 472, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 559, 589, 612, 613, 618, 621, 622, 623, 624, 625, 627, 630, 632, 634, 635, 636, 639], "collect": [0, 1, 2, 3, 4, 5, 6, 12, 20, 22, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 60, 61, 65, 66, 67, 68, 69, 71, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 107, 120, 123, 126, 130, 138, 150, 151, 154, 155, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 218, 219, 220, 221, 222, 223, 225, 228, 229, 232, 236, 238, 242, 246, 247, 250, 252, 254, 255, 256, 257, 258, 262, 264, 265, 266, 268, 271, 272, 273, 277, 279, 280, 282, 288, 295, 305, 306, 310, 312, 325, 326, 327, 328, 330, 331, 332, 337, 340, 349, 352, 355, 357, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 405, 408, 410, 411, 415, 417, 418, 419, 420, 472, 552, 553, 559, 561, 562, 564, 567, 572, 576, 579, 584, 585, 586, 589, 591, 598, 605, 613, 618, 619, 622, 623, 624, 625, 626, 629, 630, 634, 635, 636, 637, 638, 639, 640, 641], "storag": [0, 2, 4, 10, 13, 27, 32, 34, 35, 36, 38, 50, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 107, 108, 109, 111, 112, 113, 114, 116, 117, 120, 123, 126, 128, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 220, 221, 229, 232, 255, 325, 326, 327, 328, 330, 331, 332, 337, 350, 364, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 402, 420, 424, 425, 426, 427, 430, 431, 435, 436, 437, 438, 580, 581, 582, 583, 589, 618, 620, 621, 622, 623, 624, 626, 629, 630, 634, 635, 637, 639], "log": [0, 20, 23, 27, 30, 188, 189, 195, 196, 295, 296, 297, 298, 306, 310, 320, 321, 324, 326, 329, 332, 333, 337, 341, 344, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 400, 407, 408, 409, 415, 417, 419, 420, 472, 559, 566, 579, 581, 589, 618, 619, 620, 621, 624, 625, 629, 630, 634, 635, 636, 639, 640], "your": [0, 1, 5, 7, 16, 22, 26, 27, 29, 30, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 52, 88, 120, 123, 126, 130, 134, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 344, 350, 367, 375, 377, 379, 382, 383, 404, 563, 590, 591, 612, 618, 620, 621, 622, 624, 625, 626, 627, 628, 630, 632, 634, 635, 638, 639, 640], "own": [0, 2, 5, 7, 16, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 55, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 392, 565, 570, 573, 574, 612, 618, 620, 621, 624, 630, 634, 635, 636, 639], "train": [0, 1, 2, 5, 6, 9, 18, 20, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 54, 59, 78, 80, 86, 87, 88, 101, 102, 120, 123, 126, 130, 135, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 237, 250, 264, 269, 272, 275, 277, 286, 290, 292, 301, 312, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 348, 349, 350, 351, 352, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 402, 408, 415, 417, 418, 419, 420, 472, 559, 571, 583, 589, 591, 595, 596, 602, 612, 613, 618, 620, 624, 627, 628, 630, 637, 638, 639, 640, 641], "loop": [0, 1, 5, 6, 7, 27, 34, 42, 47, 50, 52, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 286, 301, 312, 325, 327, 328, 330, 331, 349, 351, 357, 363, 367, 368, 370, 371, 372, 376, 378, 380, 381, 384, 385, 386, 387, 388, 411, 415, 564, 565, 566, 567, 570, 571, 573, 575, 578, 580, 583, 586, 613, 615, 618, 619, 620, 624, 626, 627, 628, 630, 633, 638, 639, 640], "ppo": [0, 1, 5, 7, 23, 27, 35, 36, 38, 341, 344, 350, 364, 367, 375, 419, 471, 472, 613, 618, 619, 620, 623, 625, 626, 630, 634, 639], "pendulum": [0, 1, 7, 16, 18, 21, 22, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 88, 114, 120, 123, 124, 125, 126, 127, 129, 130, 131, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 221, 224, 225, 227, 234, 240, 241, 246, 253, 255, 259, 260, 263, 265, 266, 267, 270, 271, 272, 273, 279, 280, 287, 302, 304, 382, 559, 598, 618, 620, 621, 624, 625, 626, 630, 639, 640, 641], "introduct": [0, 618, 624, 630, 634, 635, 639, 641], "multi": [0, 1, 4, 5, 16, 17, 26, 28, 32, 35, 36, 38, 65, 68, 70, 71, 72, 73, 88, 92, 93, 100, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 242, 272, 302, 304, 305, 324, 326, 332, 337, 340, 344, 375, 377, 379, 382, 383, 385, 386, 387, 388, 464, 589, 591, 593, 612, 618, 619, 620, 621, 622, 624, 625, 630, 636, 639, 640], "agent": [0, 16, 21, 22, 28, 67, 70, 71, 135, 141, 142, 143, 148, 149, 152, 153, 156, 157, 161, 162, 163, 164, 166, 184, 242, 262, 263, 264, 306, 350, 364, 367, 419, 589, 618, 624, 630, 636, 639], "env": [0, 1, 2, 4, 5, 6, 7, 18, 19, 20, 21, 22, 24, 25, 26, 27, 30, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 53, 60, 65, 66, 69, 72, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 114, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 287, 302, 304, 325, 326, 327, 328, 330, 331, 332, 337, 340, 343, 365, 375, 377, 379, 382, 383, 390, 391, 392, 404, 420, 442, 443, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 531, 532, 533, 534, 535, 536, 537, 553, 554, 555, 559, 561, 562, 563, 571, 589, 591, 598, 612, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 635, 637, 638, 639], "pretrain": [0, 324, 618, 630, 639], "recurr": [0, 220, 302, 304, 316, 385, 618, 620, 625, 630, 638, 639], "dqn": [0, 1, 5, 7, 78, 214, 233, 288, 297, 298, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 556, 618, 623, 625, 626, 629, 630, 639], "polici": [0, 1, 3, 4, 5, 6, 7, 10, 12, 17, 21, 22, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 66, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 226, 231, 241, 244, 264, 267, 271, 283, 284, 285, 286, 287, 297, 298, 301, 302, 304, 312, 313, 314, 326, 329, 332, 337, 339, 340, 341, 342, 343, 344, 347, 348, 349, 350, 351, 352, 356, 357, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 409, 417, 418, 419, 420, 472, 485, 554, 555, 559, 561, 562, 565, 566, 567, 568, 570, 571, 573, 578, 580, 586, 589, 598, 599, 605, 618, 620, 624, 626, 627, 630, 632, 637, 638, 639, 640, 641], "replai": [0, 1, 5, 10, 13, 15, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 101, 102, 103, 104, 105, 107, 109, 110, 112, 114, 115, 119, 220, 221, 231, 251, 255, 265, 271, 351, 352, 353, 355, 356, 357, 363, 368, 370, 371, 372, 382, 402, 411, 415, 417, 419, 420, 427, 428, 429, 430, 433, 437, 438, 472, 557, 559, 589, 591, 612, 613, 618, 623, 630, 636, 637, 639], "buffer": [0, 1, 3, 5, 6, 10, 13, 15, 18, 22, 23, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 114, 115, 116, 119, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 220, 221, 225, 230, 231, 239, 250, 251, 255, 265, 270, 271, 272, 275, 277, 286, 312, 325, 326, 327, 328, 330, 331, 332, 337, 343, 346, 350, 351, 352, 353, 355, 356, 357, 363, 364, 367, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 401, 402, 411, 415, 417, 419, 420, 427, 428, 429, 430, 433, 437, 438, 472, 557, 559, 564, 566, 567, 569, 572, 574, 575, 576, 580, 581, 582, 583, 589, 591, 612, 613, 618, 623, 628, 630, 636, 637, 639, 641], "export": [0, 25, 26, 618, 630, 639], "llm": [0, 6, 52, 53, 54, 55, 86, 87, 88, 89, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 500, 579, 580, 581, 582, 583, 584, 585, 586, 587, 589, 593, 612, 618, 630, 639], "tool": [0, 3, 18, 20, 24, 87, 170, 184, 186, 187, 190, 193, 197, 200, 201, 202, 203, 591, 593, 594, 597, 618, 622, 624, 630, 634, 636, 638, 639, 641], "enabl": [0, 7, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 79, 89, 95, 97, 107, 116, 170, 184, 218, 302, 304, 312, 324, 326, 329, 332, 333, 334, 337, 340, 379, 390, 392, 409, 417, 419, 420, 571, 591, 602, 612, 618, 621, 624, 630, 634, 635, 636, 638, 639], "competit": [0, 22, 142, 143, 618, 630, 635, 639], "ddpg": [0, 290, 291, 292, 293, 352, 420, 618, 620, 626, 630, 635, 639], "task": [0, 7, 19, 22, 28, 70, 71, 80, 83, 120, 123, 124, 125, 126, 130, 133, 138, 142, 143, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 175, 177, 178, 179, 180, 182, 250, 263, 272, 275, 277, 356, 363, 420, 589, 618, 619, 620, 621, 622, 624, 625, 630, 631, 634, 635, 636, 639, 641], "object": [0, 6, 17, 21, 23, 25, 26, 32, 34, 35, 36, 38, 39, 42, 44, 47, 50, 52, 53, 60, 63, 69, 74, 86, 87, 88, 89, 90, 95, 96, 97, 98, 106, 110, 112, 116, 119, 120, 123, 126, 130, 136, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 229, 232, 233, 239, 242, 246, 250, 270, 271, 272, 275, 279, 280, 283, 302, 304, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 342, 343, 344, 345, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 392, 420, 553, 554, 555, 556, 558, 559, 563, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586, 589, 618, 620, 621, 622, 623, 627, 629, 630, 632, 634, 635, 636, 638, 639, 641], "loss": [0, 6, 7, 19, 21, 27, 233, 306, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375, 377, 379, 383, 385, 410, 414, 415, 419, 420, 470, 471, 472, 556, 559, 589, 591, 596, 605, 606, 607, 608, 610, 611, 613, 618, 623, 624, 626, 627, 628, 630, 636, 638, 639], "trainer": [0, 6, 7, 324, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 416, 417, 418, 419, 420, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 571, 579, 580, 584, 585, 586, 589, 618, 619, 630, 639], "exampl": [0, 2, 3, 5, 18, 19, 21, 23, 28, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 101, 102, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 203, 206, 207, 211, 212, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 246, 248, 249, 250, 251, 252, 253, 254, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 300, 301, 302, 304, 305, 306, 307, 310, 311, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 392, 401, 403, 404, 405, 406, 407, 408, 410, 411, 412, 413, 414, 418, 419, 420, 463, 464, 467, 468, 469, 472, 559, 567, 571, 575, 580, 582, 583, 586, 589, 618, 619, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 639, 640, 641], "packag": [0, 18, 25, 26, 29, 190, 211, 589, 590, 631, 641], "multicollector": [0, 2, 6, 35, 38, 589], "kei": [0, 2, 6, 7, 17, 18, 19, 22, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 86, 87, 88, 92, 101, 102, 106, 108, 109, 114, 120, 123, 126, 130, 136, 137, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 243, 246, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 286, 287, 296, 297, 298, 301, 302, 304, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 408, 409, 410, 412, 413, 415, 418, 419, 553, 581, 582, 587, 589, 619, 621, 622, 623, 624, 626, 631, 632, 633, 634, 635, 636, 638, 640, 641], "legaci": [0, 5, 26, 35, 36, 38, 56, 86, 87, 176, 188, 189, 195, 196, 325, 326, 327, 328, 330, 331, 332, 337, 376, 378, 380, 381, 384, 418, 571, 573, 589], "name": [0, 5, 6, 7, 17, 18, 21, 25, 26, 32, 34, 35, 36, 38, 54, 55, 60, 71, 78, 80, 82, 85, 86, 87, 88, 89, 120, 121, 123, 124, 126, 130, 136, 138, 142, 143, 145, 148, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 209, 213, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 231, 233, 234, 235, 237, 239, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 282, 297, 302, 304, 313, 318, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 389, 390, 394, 396, 397, 398, 399, 400, 401, 402, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 416, 417, 418, 571, 572, 573, 579, 584, 585, 587, 589, 605, 612, 619, 620, 621, 622, 623, 626, 627, 628, 631, 634, 635, 636, 637, 641], "interfac": [0, 1, 16, 22, 55, 120, 133, 147, 305, 324, 326, 329, 332, 337, 402, 423, 572, 576, 582, 586, 589, 595, 619, 621, 623, 628, 631, 632, 636, 638], "servic": [0, 50, 186, 189, 192, 193, 195, 201, 202, 243, 324, 333, 401, 402, 403, 589, 591], "registri": [0, 129, 161, 186, 193, 201, 401, 402, 403, 589, 591], "overview": [0, 589, 621, 623, 626, 634, 635, 640], "usag": [0, 1, 12, 18, 24, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 79, 85, 91, 93, 114, 171, 189, 191, 192, 218, 221, 233, 302, 304, 324, 326, 332, 337, 350, 351, 356, 363, 364, 367, 370, 373, 375, 377, 379, 383, 401, 403, 418, 419, 567, 575, 589, 591, 619, 621, 622, 625, 626, 628, 634, 635, 638], "executor": [0, 22, 42, 44, 47, 159, 193, 589], "best": [0, 5, 24, 28, 134, 302, 304, 324, 367, 589, 634, 635, 638, 640], "practic": [0, 3, 4, 18, 21, 22, 23, 24, 27, 52, 63, 78, 271, 303, 320, 321, 589, 590, 619, 620, 621, 622, 623, 626, 631, 634, 635, 637, 641], "also": [0, 2, 5, 6, 7, 12, 17, 18, 19, 21, 22, 27, 28, 30, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 57, 59, 61, 62, 64, 68, 69, 72, 73, 74, 78, 80, 81, 83, 84, 85, 86, 87, 88, 95, 96, 97, 102, 108, 109, 114, 116, 120, 123, 126, 130, 137, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 211, 212, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 231, 233, 234, 235, 237, 239, 240, 241, 243, 246, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 282, 288, 305, 316, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 345, 346, 347, 348, 349, 351, 352, 353, 355, 356, 357, 362, 363, 367, 370, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 392, 408, 589, 591, 619, 620, 621, 622, 623, 624, 625, 626, 627, 631, 633, 634, 635, 636, 638, 640, 641], "_util": [0, 18, 150, 589, 623, 629], "implement_for": [0, 18, 589], "set_auto_unwrap_transformed_env": [0, 31, 272, 589], "auto_unwrap_transformed_env": [0, 404, 589], "configur": [0, 2, 4, 27, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 45, 47, 48, 50, 51, 52, 55, 123, 171, 190, 241, 289, 294, 311, 324, 326, 333, 350, 365, 367, 375, 377, 379, 383, 401, 402, 419, 420, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 567, 570, 571, 573, 578, 589, 598, 613, 619, 620, 621, 626, 632, 634, 635, 636], "system": [0, 10, 16, 23, 24, 87, 93, 170, 171, 172, 175, 177, 191, 193, 195, 196, 379, 383, 423, 589, 591, 612, 613, 621, 632, 634, 635, 636], "simpl": [0, 19, 21, 28, 40, 41, 64, 74, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 290, 324, 326, 332, 337, 340, 344, 353, 355, 365, 367, 369, 375, 377, 379, 382, 383, 385, 408, 589, 591, 612, 619, 620, 621, 624, 625, 626, 632, 634, 635, 638, 641], "categori": [0, 60, 80, 589], "group": [0, 6, 18, 19, 22, 54, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 86, 87, 88, 120, 123, 126, 130, 138, 141, 142, 143, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 166, 170, 171, 172, 175, 176, 178, 179, 180, 185, 242, 262, 324, 325, 327, 328, 330, 331, 332, 333, 335, 336, 376, 378, 380, 381, 384, 572, 573, 579, 580, 584, 585, 589, 591, 620, 625, 627, 635, 638], "complex": [0, 6, 12, 22, 37, 39, 40, 41, 46, 49, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383, 401, 586, 589, 591, 612, 619, 620, 624, 625], "parallel": [0, 1, 2, 3, 4, 5, 16, 18, 19, 21, 27, 35, 36, 38, 54, 55, 120, 123, 126, 129, 130, 131, 138, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 272, 278, 302, 304, 324, 333, 334, 348, 439, 560, 561, 562, 563, 586, 589, 612, 620, 621, 634, 635, 640], "avail": [0, 2, 3, 5, 16, 20, 23, 25, 32, 35, 36, 38, 50, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 102, 107, 108, 109, 121, 122, 124, 125, 134, 136, 137, 142, 143, 148, 149, 150, 152, 153, 155, 161, 162, 163, 164, 182, 186, 192, 194, 195, 201, 214, 217, 220, 239, 241, 333, 341, 344, 365, 375, 377, 379, 383, 392, 561, 562, 565, 566, 567, 568, 570, 571, 573, 574, 575, 576, 578, 580, 586, 589, 591, 612, 619, 620, 621, 622, 623, 624, 625, 632, 634, 635, 636, 638, 641], "complet": [0, 1, 5, 6, 26, 28, 35, 36, 38, 46, 52, 53, 102, 107, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 184, 221, 263, 324, 382, 419, 569, 572, 579, 586, 589, 590, 591, 612, 619, 621, 624, 631, 632, 633], "run": [0, 1, 2, 6, 16, 18, 19, 22, 23, 24, 25, 26, 27, 29, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 66, 78, 80, 88, 102, 108, 109, 120, 121, 122, 123, 124, 125, 126, 129, 130, 136, 137, 138, 144, 145, 146, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 239, 245, 246, 262, 270, 271, 272, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 317, 324, 326, 332, 337, 338, 340, 344, 345, 346, 347, 351, 357, 370, 375, 377, 379, 382, 383, 392, 400, 409, 420, 561, 562, 563, 571, 589, 590, 612, 613, 619, 620, 621, 622, 625, 626, 627, 628, 629, 631, 634, 635, 636, 640], "experi": [0, 1, 16, 17, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 394, 395, 396, 397, 398, 399, 400, 401, 420, 589, 590, 616, 620, 621, 623, 627, 628, 634, 635, 638], "store": [0, 2, 6, 12, 17, 27, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 60, 63, 65, 66, 68, 69, 72, 73, 80, 81, 83, 84, 86, 87, 88, 90, 93, 95, 96, 97, 98, 101, 102, 108, 114, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 267, 278, 279, 280, 286, 312, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 419, 420, 472, 564, 565, 567, 571, 572, 573, 575, 589, 619, 621, 622, 625, 627, 629, 634, 635, 637, 641], "implement": [0, 1, 6, 9, 10, 12, 17, 21, 22, 28, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 70, 71, 74, 75, 76, 77, 88, 99, 101, 110, 111, 120, 123, 126, 130, 138, 144, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 237, 241, 244, 252, 253, 259, 263, 269, 271, 272, 273, 279, 280, 282, 302, 303, 304, 319, 320, 321, 324, 326, 332, 334, 337, 348, 349, 351, 354, 355, 356, 362, 363, 365, 366, 367, 369, 370, 371, 375, 377, 379, 382, 383, 390, 405, 419, 420, 554, 584, 585, 586, 589, 591, 612, 613, 619, 620, 621, 622, 623, 634, 635, 636, 640], "detail": [0, 6, 21, 24, 25, 26, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 268, 272, 298, 307, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 350, 358, 364, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 565, 589, 590, 591, 620, 623, 627, 633, 638], "class": [0, 1, 2, 4, 5, 6, 10, 14, 16, 18, 19, 20, 21, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 126, 127, 128, 129, 130, 131, 132, 137, 138, 141, 144, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 211, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 589, 591, 592, 598, 607, 612, 614, 616, 619, 620, 621, 622, 624, 625, 626, 627, 628, 631, 634, 635, 638, 641], "creat": [0, 1, 4, 6, 10, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 29, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 98, 114, 120, 123, 126, 127, 130, 134, 138, 150, 151, 152, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 218, 221, 226, 239, 243, 250, 270, 271, 272, 275, 278, 279, 280, 288, 290, 291, 292, 293, 294, 295, 300, 302, 304, 305, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 343, 344, 351, 353, 358, 367, 368, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 401, 402, 403, 411, 419, 420, 472, 553, 554, 555, 559, 561, 562, 564, 565, 567, 568, 569, 570, 571, 572, 573, 574, 575, 578, 580, 586, 589, 591, 598, 605, 612, 613, 619, 620, 621, 622, 623, 625, 628, 631, 632, 634, 635, 636, 637, 638, 640, 641], "custom": [0, 6, 10, 16, 21, 22, 24, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 81, 86, 87, 88, 89, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 275, 324, 325, 326, 327, 328, 330, 331, 332, 337, 347, 358, 367, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 401, 403, 419, 472, 563, 568, 570, 571, 573, 578, 580, 584, 585, 586, 589, 601, 613, 615, 619, 620, 621, 622, 625, 626, 628, 631, 634, 635], "futur": [0, 23, 34, 41, 54, 56, 86, 87, 88, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 250, 270, 272, 277, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 419, 420, 572, 589, 590, 591, 612], "extens": [0, 65, 68, 72, 73, 109, 589, 638], "thing": [0, 5, 19, 21, 22, 26, 27, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 271, 325, 327, 328, 330, 331, 357, 370, 376, 378, 380, 381, 384, 590, 621, 622, 623, 624, 625, 626, 627, 628, 634, 635, 638, 641], "consid": [0, 2, 18, 21, 27, 34, 35, 36, 37, 38, 39, 42, 46, 47, 49, 50, 52, 54, 60, 65, 68, 71, 72, 73, 88, 95, 97, 108, 109, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 231, 279, 295, 306, 319, 326, 332, 337, 349, 351, 363, 368, 370, 371, 372, 375, 377, 379, 382, 383, 385, 387, 388, 590, 591, 612, 619, 624, 625, 626, 636, 638], "when": [0, 1, 2, 3, 6, 7, 8, 17, 18, 20, 21, 22, 24, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 96, 97, 98, 100, 101, 102, 103, 107, 108, 109, 110, 112, 116, 120, 121, 122, 123, 126, 127, 129, 130, 131, 137, 138, 141, 142, 143, 145, 147, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 212, 215, 217, 220, 221, 225, 226, 229, 231, 232, 241, 242, 245, 246, 250, 251, 258, 265, 267, 270, 271, 272, 275, 277, 278, 279, 280, 282, 295, 302, 304, 305, 306, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 343, 344, 346, 349, 350, 351, 353, 357, 358, 363, 364, 365, 367, 368, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 394, 397, 399, 400, 401, 411, 417, 418, 563, 564, 565, 567, 570, 571, 573, 574, 575, 578, 579, 580, 586, 590, 591, 612, 619, 620, 621, 622, 623, 625, 627, 628, 634, 635, 636, 637, 638, 640, 641], "debug": [0, 6, 25, 27, 78, 79, 80, 81, 82, 83, 84, 85, 191, 267, 326, 332, 337, 566, 590, 641], "work": [0, 4, 6, 18, 20, 21, 22, 23, 27, 46, 49, 54, 55, 60, 68, 71, 78, 79, 80, 81, 82, 83, 84, 85, 88, 95, 101, 102, 106, 108, 109, 112, 119, 120, 123, 126, 129, 130, 131, 134, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 212, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 280, 282, 288, 298, 305, 314, 324, 326, 332, 337, 347, 350, 364, 367, 375, 377, 379, 382, 383, 401, 402, 415, 572, 586, 589, 590, 591, 598, 619, 620, 621, 622, 624, 627, 632, 633, 634, 635, 636, 637, 638, 640, 641], "habitat": [0, 18, 132, 446, 590, 637], "lab": [0, 17, 124, 125, 132, 135, 590], "mujoco": [0, 25, 27, 155, 590, 619, 621, 622], "error": [0, 2, 22, 26, 29, 32, 34, 35, 36, 38, 52, 57, 59, 61, 62, 64, 70, 86, 87, 88, 95, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 165, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 251, 270, 282, 324, 325, 326, 327, 328, 330, 331, 332, 337, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 590, 591, 612, 619, 621, 634, 635, 641], "solut": [0, 12, 18, 25, 26, 28, 50, 108, 590, 623, 640], "resourc": [0, 3, 33, 42, 43, 44, 45, 47, 48, 50, 132, 171, 172, 175, 184, 185, 192, 194, 195, 324, 329, 337, 401, 402, 568, 570, 571, 573, 578, 580, 586, 590, 591, 612, 619, 621, 623, 634, 635], "issu": [0, 6, 20, 22, 23, 24, 27, 66, 78, 81, 93, 95, 97, 101, 102, 108, 116, 120, 123, 126, 129, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 194, 195, 212, 221, 251, 266, 297, 298, 313, 314, 324, 339, 341, 343, 344, 350, 367, 419, 590, 591, 632, 640], "customis": [0, 590, 620, 628], "video": [0, 16, 23, 28, 86, 392, 394, 397, 399, 400, 409, 563, 590, 629, 634, 635], "render": [0, 20, 27, 137, 163, 390, 392, 409, 590, 619, 620, 621, 623, 624, 628], "index": [0, 21, 26, 27, 29, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 94, 95, 96, 97, 101, 102, 104, 106, 108, 112, 114, 115, 116, 118, 119, 120, 123, 126, 130, 138, 142, 143, 148, 149, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 195, 212, 216, 221, 225, 231, 272, 306, 324, 325, 327, 328, 330, 331, 340, 376, 378, 380, 381, 384, 565, 566, 567, 568, 570, 571, 572, 573, 574, 575, 576, 578, 580, 586, 624, 631, 633, 634, 635, 638, 640], "search": [0, 60, 71, 147, 186, 187, 203, 213, 326, 332, 337, 620], "page": [0, 26, 184, 400, 626, 631], "bridg": [1, 420], "between": [1, 2, 6, 19, 21, 23, 24, 32, 34, 35, 36, 38, 39, 46, 50, 52, 53, 54, 65, 66, 68, 69, 72, 73, 83, 86, 87, 88, 90, 97, 101, 102, 104, 107, 108, 109, 116, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 231, 245, 256, 267, 270, 272, 279, 280, 288, 296, 298, 302, 304, 305, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 341, 344, 348, 350, 351, 352, 355, 356, 357, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 409, 415, 420, 567, 571, 587, 593, 612, 619, 620, 622, 623, 627, 631, 632, 634, 635, 636, 638, 641], "manag": [1, 2, 6, 10, 11, 22, 27, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 190, 192, 201, 302, 304, 324, 337, 367, 385, 386, 387, 388, 402, 403, 404, 409, 420, 578, 591, 593, 612, 622, 623, 626, 631, 640], "gather": [1, 2, 17, 18, 42, 47, 50, 95, 97, 102, 108, 116, 195, 244, 251, 310, 326, 332, 337, 365, 375, 377, 379, 383, 419, 420, 472, 553, 590, 620, 621, 622, 627, 634, 635, 636, 638, 640, 641], "thei": [1, 2, 3, 6, 7, 17, 20, 21, 22, 23, 27, 28, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 120, 123, 126, 129, 130, 131, 138, 141, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 220, 235, 241, 250, 259, 267, 271, 272, 277, 304, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 411, 415, 565, 567, 570, 571, 573, 575, 578, 580, 586, 599, 612, 619, 620, 621, 622, 623, 626, 633, 634, 635, 636, 637, 638, 640, 641], "handl": [1, 5, 6, 7, 16, 17, 18, 20, 22, 35, 36, 37, 38, 39, 40, 41, 42, 46, 47, 49, 50, 54, 55, 63, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 278, 279, 280, 304, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 401, 402, 408, 415, 420, 561, 562, 564, 565, 566, 568, 569, 570, 571, 572, 573, 577, 578, 579, 580, 586, 591, 593, 612, 619, 620, 621, 622, 624, 626, 631, 635, 638], "reset": [1, 2, 7, 16, 17, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 109, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 216, 217, 218, 221, 233, 236, 240, 245, 250, 258, 263, 264, 265, 266, 267, 270, 271, 272, 275, 278, 279, 282, 287, 302, 304, 312, 326, 332, 337, 340, 365, 375, 377, 379, 382, 383, 391, 401, 402, 591, 612, 619, 620, 621, 622, 624, 627, 631, 633, 634, 635, 640], "execut": [1, 2, 3, 5, 17, 18, 20, 21, 22, 25, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 95, 96, 98, 108, 109, 120, 121, 122, 123, 126, 127, 130, 131, 132, 134, 136, 137, 138, 144, 145, 150, 151, 154, 155, 158, 159, 160, 161, 170, 171, 172, 175, 176, 178, 179, 180, 186, 190, 192, 193, 197, 201, 215, 226, 227, 244, 267, 272, 301, 302, 304, 324, 325, 327, 328, 329, 330, 331, 334, 340, 345, 346, 365, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 553, 563, 591, 594, 612, 618, 620, 621, 622, 623, 624, 625, 626, 627, 628, 634, 635, 638, 639, 640, 641], "aggreg": [1, 2, 22, 78, 102, 114, 152, 153, 177, 213, 242, 280, 288, 290, 291, 346, 379, 402, 591, 635], "easi": [1, 7, 16, 17, 18, 21, 24, 30, 78, 82, 120, 123, 124, 125, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 301, 312, 598, 619, 620, 621, 632, 635, 637, 638, 640, 641], "qualiti": [1, 30, 177, 285, 367], "sever": [1, 2, 5, 6, 7, 12, 20, 27, 55, 61, 80, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 222, 224, 225, 242, 272, 325, 326, 327, 328, 330, 331, 332, 337, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 465, 591, 619, 621, 623, 628, 629, 638, 641], "differ": [1, 2, 5, 6, 7, 15, 16, 17, 19, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 83, 86, 87, 88, 101, 106, 120, 121, 122, 123, 126, 127, 130, 136, 137, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 221, 226, 230, 231, 242, 246, 253, 262, 270, 272, 274, 282, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 363, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 401, 409, 415, 418, 561, 562, 567, 571, 573, 576, 580, 584, 585, 591, 595, 612, 613, 619, 620, 621, 623, 624, 626, 628, 632, 633, 634, 635, 636, 637, 638, 640, 641], "scenario": [1, 4, 6, 40, 46, 49, 142, 143, 150, 163, 164, 226, 270, 379, 390, 612, 619, 625, 634, 635, 636], "singl": [1, 2, 3, 4, 7, 16, 17, 18, 19, 20, 21, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 60, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 96, 109, 114, 120, 123, 126, 129, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 214, 221, 222, 242, 250, 255, 265, 270, 272, 277, 288, 302, 304, 305, 314, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 346, 349, 350, 351, 353, 355, 357, 358, 363, 364, 367, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 563, 564, 565, 567, 569, 570, 571, 572, 573, 578, 580, 586, 589, 591, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 631, 633, 634, 635, 636, 637, 638, 640], "worker": [1, 2, 4, 5, 6, 7, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 65, 68, 69, 72, 73, 74, 80, 85, 86, 87, 88, 127, 145, 150, 158, 173, 174, 176, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 271, 279, 280, 324, 325, 327, 328, 330, 331, 334, 335, 336, 376, 378, 380, 381, 382, 384, 401, 402, 403, 415, 561, 562, 563, 564, 565, 566, 567, 568, 570, 571, 572, 573, 574, 575, 576, 578, 579, 580, 582, 583, 584, 585, 586, 589, 619, 620, 621, 640, 641], "across": [1, 2, 3, 16, 19, 27, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 87, 102, 108, 109, 121, 122, 124, 125, 129, 131, 132, 134, 136, 137, 145, 146, 150, 155, 160, 171, 172, 175, 185, 194, 195, 270, 279, 280, 302, 304, 312, 324, 326, 365, 367, 375, 377, 379, 382, 383, 402, 403, 418, 431, 565, 570, 573, 578, 591, 595, 612, 619, 624, 628, 634, 635, 636], "multipl": [1, 2, 3, 6, 7, 17, 18, 21, 22, 24, 27, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 62, 68, 69, 72, 73, 87, 90, 97, 104, 116, 120, 121, 122, 136, 137, 150, 158, 160, 171, 172, 175, 177, 178, 185, 192, 194, 195, 222, 224, 231, 240, 244, 245, 255, 258, 262, 263, 270, 279, 297, 304, 313, 324, 337, 339, 341, 343, 344, 347, 350, 357, 364, 367, 402, 419, 431, 563, 564, 567, 568, 569, 570, 571, 572, 573, 578, 580, 586, 589, 591, 593, 619, 620, 621, 624, 626, 627, 632, 634, 635, 636, 638, 640], "distribut": [1, 6, 10, 15, 21, 22, 23, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 123, 152, 153, 191, 241, 246, 280, 286, 295, 296, 297, 298, 299, 303, 306, 307, 310, 311, 315, 316, 317, 319, 320, 321, 324, 326, 329, 332, 335, 336, 337, 341, 344, 345, 348, 349, 350, 351, 356, 357, 358, 363, 364, 367, 368, 369, 370, 371, 372, 379, 401, 402, 403, 431, 564, 565, 566, 569, 570, 571, 572, 573, 574, 579, 580, 584, 585, 589, 598, 612, 620, 621, 623, 625, 627, 634, 635, 636, 640, 641], "For": [1, 2, 5, 6, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 32, 34, 35, 36, 38, 42, 44, 47, 50, 53, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69, 72, 73, 74, 75, 76, 77, 79, 83, 85, 86, 87, 88, 89, 95, 97, 102, 108, 116, 120, 123, 126, 129, 130, 131, 135, 137, 138, 150, 151, 152, 153, 154, 158, 159, 160, 161, 163, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 229, 232, 236, 246, 264, 271, 272, 278, 283, 285, 298, 302, 304, 306, 313, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 356, 358, 363, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 403, 409, 565, 567, 570, 571, 573, 574, 575, 578, 579, 580, 581, 584, 586, 591, 612, 619, 620, 621, 622, 624, 625, 627, 628, 631, 634, 635, 636, 637, 638, 641], "node": [1, 3, 7, 15, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 60, 71, 85, 86, 87, 138, 176, 179, 270, 324, 325, 327, 328, 330, 331, 335, 336, 376, 378, 380, 381, 384, 579, 580, 586, 589, 612, 627, 640], "rai": [1, 3, 6, 10, 32, 34, 35, 36, 38, 39, 50, 52, 53, 54, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 171, 172, 175, 185, 189, 192, 193, 194, 195, 243, 324, 329, 334, 337, 401, 402, 403, 571, 572, 573, 579, 584, 585, 586, 612], "rpc": [1, 3, 6, 32, 34, 35, 36, 38, 47, 49, 51, 52, 53, 67, 324, 569, 570, 579, 582, 584, 585], "backend": [1, 3, 6, 7, 8, 10, 16, 17, 18, 20, 22, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 175, 178, 179, 180, 192, 193, 211, 282, 326, 332, 333, 334, 337, 402, 403, 445, 449, 565, 571, 572, 573, 578, 584, 585, 589, 595, 612, 619, 621, 622, 623, 624, 627, 628, 632, 636], "distributedcollector": [1, 3, 43], "rpccollector": [1, 3, 48], "unifi": [1, 16, 324, 337, 577, 591, 595, 632, 641], "paramet": [1, 2, 5, 6, 7, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 96, 97, 98, 101, 102, 103, 104, 106, 107, 110, 112, 114, 116, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 204, 205, 206, 210, 211, 212, 213, 214, 215, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 394, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 460, 470, 472, 552, 553, 554, 555, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 605, 612, 619, 622, 623, 625, 629, 634, 635, 636, 637, 640], "choos": [1, 2, 3, 6, 22, 30, 63, 120, 123, 141, 302, 304, 367, 619, 620, 621, 623, 634, 635, 638, 640], "synchron": [1, 3, 5, 22, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 86, 87, 145, 176, 190, 324, 325, 327, 328, 330, 331, 337, 376, 378, 380, 381, 384, 401, 561, 562, 565, 566, 567, 568, 570, 571, 572, 573, 575, 576, 578, 579, 580, 586, 589, 591, 620, 621, 634], "asynchron": [1, 2, 3, 22, 28, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 324, 325, 326, 327, 328, 330, 331, 332, 337, 343, 348, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 415, 417, 561, 569, 619, 620, 621], "import": [1, 5, 6, 7, 10, 16, 18, 19, 20, 21, 22, 23, 25, 29, 30, 32, 34, 35, 36, 38, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 101, 102, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 140, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 206, 211, 212, 213, 214, 215, 217, 218, 220, 221, 224, 226, 227, 233, 234, 239, 240, 241, 242, 246, 248, 250, 252, 253, 254, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 270, 271, 273, 277, 279, 280, 282, 283, 284, 285, 287, 290, 291, 292, 293, 296, 297, 298, 300, 301, 302, 304, 305, 307, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 392, 407, 409, 419, 420, 559, 586, 591, 598, 605, 612, 613, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 633, 634, 635, 636, 637, 638, 640, 641], "all": [1, 2, 3, 5, 6, 7, 17, 18, 19, 21, 22, 23, 27, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 124, 125, 126, 127, 129, 130, 131, 132, 137, 138, 142, 143, 144, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 166, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 206, 210, 212, 214, 220, 221, 224, 225, 229, 230, 232, 235, 241, 245, 246, 250, 258, 260, 262, 265, 266, 271, 272, 275, 277, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 340, 343, 344, 346, 347, 348, 349, 350, 351, 360, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 401, 402, 403, 410, 415, 419, 423, 472, 552, 561, 562, 563, 564, 565, 566, 567, 570, 571, 572, 573, 575, 578, 579, 580, 582, 584, 586, 590, 607, 612, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 633, 634, 635, 636, 638, 640, 641], "befor": [1, 2, 4, 5, 6, 17, 21, 22, 23, 25, 26, 29, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 59, 61, 82, 88, 107, 109, 114, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 278, 279, 280, 302, 304, 305, 324, 326, 332, 337, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 386, 387, 388, 411, 565, 567, 570, 571, 572, 573, 576, 578, 579, 580, 584, 586, 591, 612, 619, 621, 622, 623, 627, 628, 634, 635, 636, 638, 641], "deliv": [1, 2, 5, 18, 34, 35, 36, 38, 83, 185, 619, 620, 624, 627, 640], "batch": [1, 4, 5, 6, 7, 9, 16, 18, 19, 20, 32, 34, 35, 36, 38, 39, 42, 44, 47, 50, 52, 53, 55, 56, 60, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 98, 102, 103, 107, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 144, 145, 147, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 218, 221, 225, 227, 236, 244, 246, 248, 251, 255, 262, 265, 267, 271, 272, 274, 278, 279, 280, 295, 302, 304, 306, 310, 312, 319, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 340, 343, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 405, 408, 411, 412, 413, 415, 417, 418, 419, 420, 439, 472, 561, 562, 563, 591, 593, 605, 620, 621, 622, 623, 624, 627, 629, 631, 633, 634, 635, 637, 640, 641], "create_env_fn": [1, 5, 6, 7, 32, 34, 35, 36, 38, 42, 44, 47, 50, 127, 150, 158, 439, 472, 567, 619, 640], "make_env": [1, 4, 5, 16, 20, 22, 35, 36, 38, 150, 158, 164, 270, 279, 280, 390, 554, 555, 591, 619, 620, 640, 641], "4": [1, 4, 5, 6, 7, 10, 16, 17, 22, 26, 35, 36, 38, 57, 60, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 101, 102, 108, 109, 116, 120, 121, 122, 123, 124, 125, 126, 130, 136, 137, 138, 139, 140, 141, 144, 146, 150, 151, 154, 156, 157, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 194, 214, 215, 217, 218, 221, 226, 227, 233, 255, 262, 263, 264, 270, 279, 280, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 297, 298, 299, 300, 301, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 322, 325, 327, 328, 330, 331, 338, 339, 340, 341, 343, 346, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 390, 391, 401, 419, 420, 472, 480, 490, 496, 565, 567, 570, 571, 573, 578, 580, 586, 591, 612, 618, 619, 620, 621, 622, 628, 634, 635, 636, 638, 639, 640, 641], "my_polici": [1, 5, 35, 36, 38], "frames_per_batch": [1, 2, 4, 5, 6, 7, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 66, 218, 221, 255, 302, 304, 420, 552, 567, 619, 620, 621, 622, 623, 627, 629, 634, 635, 638, 640], "200": [1, 7, 16, 34, 35, 38, 50, 66, 78, 88, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 255, 290, 291, 299, 315, 316, 326, 332, 337, 375, 377, 379, 382, 383, 390, 392, 619, 622, 623, 627, 629, 638], "total_fram": [1, 4, 5, 6, 7, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 66, 218, 221, 255, 415, 419, 420, 472, 552, 559, 567, 613, 619, 620, 621, 622, 623, 627, 629, 634, 635, 638, 640], "10000": [1, 6, 32, 35, 36, 38, 50, 150, 415, 419, 420, 472, 622], "true": [1, 2, 5, 6, 7, 9, 18, 21, 22, 23, 27, 30, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 95, 96, 97, 98, 101, 102, 104, 106, 107, 108, 109, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 213, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 231, 234, 236, 239, 240, 241, 242, 244, 245, 246, 250, 251, 253, 254, 257, 258, 259, 262, 263, 265, 268, 269, 270, 271, 272, 273, 274, 275, 277, 279, 280, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 297, 298, 300, 302, 304, 305, 306, 312, 313, 314, 319, 320, 321, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 339, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 400, 401, 404, 407, 408, 409, 411, 415, 417, 419, 420, 432, 433, 434, 441, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 463, 464, 467, 471, 472, 474, 502, 504, 521, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 563, 564, 565, 567, 568, 570, 571, 573, 575, 577, 578, 580, 581, 582, 584, 586, 591, 612, 619, 620, 621, 622, 623, 625, 628, 629, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "deliveri": [1, 5, 17, 35, 36, 38], "serv": [1, 2, 5, 16, 22, 35, 36, 38, 42, 47, 50, 86, 87, 132, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 423, 591, 638, 640, 641], "fals": [1, 2, 3, 5, 18, 22, 30, 31, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 106, 107, 108, 109, 110, 115, 116, 118, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 213, 214, 215, 217, 218, 221, 222, 225, 227, 229, 232, 233, 234, 236, 239, 240, 241, 243, 244, 245, 246, 248, 250, 251, 252, 253, 255, 257, 258, 259, 262, 263, 265, 268, 269, 270, 271, 272, 273, 274, 275, 277, 279, 280, 282, 283, 284, 285, 286, 287, 288, 290, 296, 297, 298, 301, 302, 303, 304, 305, 306, 312, 313, 314, 320, 321, 322, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 337, 339, 340, 341, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 392, 400, 404, 407, 408, 409, 411, 412, 415, 419, 420, 424, 425, 426, 427, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 476, 477, 502, 505, 515, 526, 538, 539, 540, 541, 542, 548, 549, 550, 563, 565, 567, 575, 582, 584, 612, 619, 620, 621, 622, 623, 628, 629, 631, 632, 633, 634, 635, 636, 637, 640, 641], "async": [1, 7, 16, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 66, 120, 154, 159, 190, 278, 324, 333, 336, 337, 417, 419, 472], "faster": [1, 3, 23, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 84, 85, 101, 145, 306, 385, 386, 387, 388, 622, 623, 634, 635], "mai": [1, 2, 3, 5, 6, 17, 18, 19, 21, 22, 23, 24, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 54, 56, 60, 70, 71, 74, 79, 85, 86, 87, 88, 93, 96, 101, 102, 108, 120, 123, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 246, 259, 270, 272, 274, 279, 280, 302, 304, 305, 325, 326, 327, 328, 330, 331, 332, 337, 344, 350, 357, 364, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 419, 420, 565, 567, 570, 571, 573, 575, 576, 578, 580, 586, 591, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 634, 635, 636, 637, 638, 641], "lag": [1, 2, 619, 620, 621], "vs": [1, 6, 280, 282, 326, 332, 337, 401], "algorithm": [1, 5, 7, 10, 12, 18, 20, 27, 28, 33, 35, 36, 38, 42, 43, 44, 45, 47, 48, 144, 214, 262, 348, 367, 368, 370, 417, 419, 420, 605, 606, 609, 610, 611, 613, 619, 620, 621, 622, 623, 625, 626, 627, 628, 634, 635, 637, 638, 640], "a2c": [1, 5, 348], "where": [1, 2, 4, 6, 7, 17, 18, 19, 20, 21, 22, 23, 26, 27, 32, 34, 35, 36, 37, 38, 39, 40, 42, 44, 46, 47, 49, 50, 52, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 95, 97, 102, 108, 109, 114, 116, 117, 120, 123, 126, 130, 138, 141, 144, 147, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 212, 213, 214, 215, 218, 221, 226, 233, 241, 250, 255, 258, 263, 264, 265, 266, 267, 271, 272, 274, 277, 278, 286, 301, 302, 304, 306, 312, 317, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 344, 348, 349, 350, 351, 356, 357, 358, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 394, 400, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 420, 580, 581, 613, 619, 620, 621, 623, 624, 631, 633, 634, 635, 636, 638, 641], "must": [1, 4, 6, 18, 21, 22, 26, 30, 32, 34, 35, 36, 38, 40, 41, 42, 44, 47, 50, 51, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 95, 96, 97, 98, 102, 108, 109, 110, 111, 112, 114, 116, 120, 121, 123, 126, 127, 130, 136, 138, 148, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 163, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 214, 217, 218, 221, 224, 226, 227, 233, 237, 239, 241, 243, 244, 246, 248, 259, 262, 264, 265, 266, 269, 270, 272, 273, 274, 279, 288, 297, 298, 302, 304, 305, 306, 313, 314, 322, 324, 326, 329, 332, 337, 339, 340, 341, 343, 344, 347, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 394, 400, 401, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 420, 579, 580, 586, 587, 591, 619, 620, 621, 622, 625, 631, 633, 636, 638], "match": [1, 10, 19, 21, 22, 25, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 112, 120, 123, 124, 125, 126, 127, 129, 130, 131, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 238, 240, 241, 242, 243, 244, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 288, 295, 297, 302, 304, 305, 313, 319, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 343, 344, 347, 349, 350, 351, 357, 364, 366, 367, 368, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 411, 418, 574, 619, 621, 623, 633, 635, 636, 638, 641], "current": [1, 4, 18, 22, 31, 32, 34, 35, 36, 37, 38, 39, 46, 49, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 99, 102, 109, 120, 123, 126, 130, 132, 138, 145, 148, 149, 150, 151, 154, 158, 159, 160, 167, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 217, 218, 221, 239, 251, 264, 265, 266, 270, 271, 272, 280, 299, 312, 316, 317, 320, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 340, 348, 350, 351, 358, 364, 367, 369, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 395, 401, 402, 403, 565, 567, 568, 570, 571, 573, 574, 575, 578, 580, 583, 584, 585, 586, 612, 619, 620, 621, 622, 626, 634, 635, 636, 638, 641], "off": [1, 2, 5, 10, 12, 23, 35, 36, 38, 297, 303, 321, 370, 390, 409, 417, 420, 554, 619, 620, 621, 625, 626, 634, 635, 637, 640, 641], "sac": [1, 5, 7, 35, 36, 38, 357, 368, 370, 420, 613], "slight": [1, 150, 158, 620], "accept": [1, 2, 6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 68, 75, 80, 81, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 216, 221, 225, 236, 239, 250, 258, 262, 265, 270, 271, 272, 273, 274, 275, 277, 305, 325, 326, 327, 328, 330, 331, 332, 337, 343, 344, 345, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 612, 621, 624, 628, 638, 640, 641], "flexibl": [1, 6, 10, 16, 22, 28, 145, 170, 373, 591, 612, 619, 623, 632, 638, 641], "devic": [1, 2, 3, 6, 12, 17, 18, 19, 21, 22, 26, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 108, 109, 116, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 209, 212, 214, 218, 225, 229, 230, 232, 233, 234, 239, 241, 242, 243, 248, 249, 250, 252, 253, 255, 259, 262, 263, 265, 268, 271, 272, 273, 275, 277, 279, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 300, 301, 302, 304, 305, 311, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 343, 344, 346, 348, 349, 350, 351, 352, 353, 355, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 411, 418, 424, 426, 438, 439, 442, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 463, 464, 471, 489, 508, 532, 533, 534, 557, 567, 578, 579, 586, 619, 620, 621, 622, 623, 634, 635, 636, 637, 640], "control": [1, 2, 7, 13, 17, 18, 22, 24, 27, 34, 56, 60, 68, 69, 71, 72, 73, 101, 102, 108, 120, 123, 124, 125, 126, 130, 137, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 194, 195, 196, 212, 231, 290, 291, 292, 293, 302, 304, 312, 316, 324, 343, 344, 345, 348, 350, 351, 364, 365, 367, 375, 377, 379, 383, 385, 390, 404, 420, 591, 612, 619, 620, 621, 622, 623, 624, 625, 626, 634, 635, 636, 638, 640], "weight": [1, 2, 23, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 65, 69, 86, 87, 88, 101, 102, 106, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 239, 242, 250, 265, 270, 271, 272, 275, 277, 302, 304, 324, 325, 326, 327, 328, 330, 331, 332, 337, 343, 348, 349, 350, 351, 357, 360, 367, 370, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 418, 420, 501, 558, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 589, 619, 620, 621, 633, 636, 638, 640], "keep": [1, 2, 7, 20, 21, 22, 23, 26, 27, 35, 65, 68, 69, 72, 73, 86, 87, 88, 107, 114, 123, 150, 158, 176, 189, 191, 195, 212, 246, 250, 277, 279, 280, 312, 325, 327, 328, 330, 331, 340, 350, 367, 376, 378, 379, 380, 381, 382, 384, 392, 407, 415, 619, 620, 621, 622, 627, 628, 629, 635, 636, 638, 641], "infer": [1, 2, 6, 21, 34, 35, 36, 37, 38, 39, 41, 42, 46, 47, 49, 50, 52, 53, 54, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 194, 195, 196, 221, 279, 306, 324, 334, 337, 341, 344, 355, 379, 383, 390, 402, 580, 586, 591, 595, 619, 621, 623, 627, 629, 632, 638, 640], "date": [1, 37, 39, 123, 220, 395], "integr": [1, 6, 7, 16, 54, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 293, 302, 304, 324, 326, 332, 337, 343, 375, 377, 379, 382, 383, 624, 625, 627, 631, 634, 635, 636, 637], "seamless": [1, 305, 324, 591, 632], "strategi": [1, 2, 5, 6, 7, 10, 12, 22, 34, 83, 86, 87, 106, 141, 176, 188, 214, 301, 310, 324, 325, 327, 328, 330, 331, 337, 376, 378, 379, 380, 381, 384, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 586, 589, 591, 598, 612, 619, 620, 623, 625, 634, 635, 638, 640], "organ": [1, 2, 7, 16, 631, 636, 638], "gymenv": [1, 5, 6, 16, 18, 20, 21, 22, 24, 30, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 88, 114, 120, 123, 126, 127, 130, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 217, 218, 221, 224, 225, 226, 227, 233, 239, 240, 241, 246, 248, 253, 254, 255, 258, 260, 264, 265, 266, 267, 270, 271, 272, 273, 279, 280, 287, 302, 304, 340, 382, 390, 392, 445, 559, 567, 598, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 637, 638, 640, 641], "parallelenv": [1, 3, 4, 16, 18, 20, 22, 32, 34, 35, 36, 38, 47, 52, 53, 88, 114, 120, 123, 126, 130, 138, 145, 151, 152, 153, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 271, 280, 302, 304, 382, 390, 560, 619, 620, 621, 624, 633, 640, 641], "def": [1, 5, 6, 7, 16, 18, 20, 21, 22, 35, 36, 38, 51, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 120, 123, 126, 127, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 209, 211, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 280, 282, 322, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 349, 351, 352, 357, 363, 365, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 404, 584, 585, 591, 612, 619, 620, 623, 631, 633, 634, 635, 636, 638, 640, 641], "v1": [1, 5, 6, 7, 16, 18, 20, 21, 22, 30, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 79, 81, 86, 87, 88, 114, 120, 123, 126, 127, 129, 130, 131, 136, 137, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 217, 218, 221, 224, 226, 227, 234, 240, 241, 246, 253, 255, 258, 259, 260, 263, 264, 265, 266, 267, 270, 271, 273, 279, 280, 287, 302, 304, 325, 327, 328, 330, 331, 340, 376, 378, 380, 381, 382, 384, 390, 567, 598, 620, 622, 624, 625, 626, 627, 628, 629, 636, 638, 640, 641], "shape": [1, 4, 6, 14, 17, 18, 19, 22, 34, 35, 38, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 95, 96, 97, 101, 108, 114, 116, 120, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 175, 176, 177, 178, 179, 180, 183, 185, 188, 195, 196, 206, 212, 214, 218, 220, 222, 229, 232, 233, 234, 239, 241, 242, 246, 248, 252, 253, 255, 259, 262, 263, 265, 268, 273, 279, 281, 283, 284, 285, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 302, 304, 305, 306, 307, 310, 311, 312, 313, 314, 319, 320, 322, 325, 326, 327, 328, 330, 331, 332, 337, 338, 339, 340, 341, 343, 344, 346, 347, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 390, 392, 405, 411, 415, 463, 464, 467, 468, 469, 559, 579, 584, 585, 587, 591, 619, 620, 621, 622, 623, 625, 626, 629, 631, 632, 633, 634, 635, 637, 638, 640, 641], "50": [1, 34, 35, 38, 50, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 85, 88, 108, 109, 142, 143, 183, 324, 329, 332, 337, 549, 612, 622, 632, 638], "step": [1, 2, 3, 4, 6, 7, 16, 17, 18, 19, 21, 23, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 78, 86, 87, 88, 92, 93, 100, 102, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 212, 213, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 236, 237, 240, 241, 243, 244, 246, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 286, 299, 301, 302, 304, 312, 317, 325, 327, 328, 330, 331, 340, 341, 344, 348, 359, 367, 376, 378, 380, 381, 382, 384, 385, 386, 387, 388, 391, 394, 405, 409, 415, 417, 419, 420, 472, 591, 613, 620, 622, 623, 625, 626, 628, 629, 632, 633, 636, 637, 640], "each": [1, 2, 3, 5, 6, 7, 12, 15, 17, 19, 20, 21, 22, 23, 26, 27, 32, 34, 35, 36, 37, 38, 39, 42, 44, 46, 47, 49, 50, 52, 53, 55, 56, 60, 61, 62, 68, 69, 71, 72, 78, 79, 80, 83, 86, 87, 88, 101, 102, 106, 108, 109, 111, 114, 120, 123, 126, 127, 130, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 240, 242, 244, 250, 255, 258, 263, 264, 265, 266, 270, 271, 277, 279, 280, 282, 286, 297, 298, 301, 302, 304, 308, 314, 317, 324, 325, 326, 327, 328, 330, 331, 332, 337, 344, 346, 350, 364, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 392, 401, 409, 411, 561, 562, 565, 567, 568, 570, 571, 573, 574, 575, 576, 578, 579, 580, 586, 591, 612, 619, 620, 621, 622, 625, 626, 627, 629, 634, 635, 636, 637, 638, 640, 641], "updat": [1, 17, 18, 21, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 144, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 215, 217, 218, 229, 231, 232, 239, 252, 263, 264, 270, 272, 276, 279, 280, 286, 301, 312, 313, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 344, 348, 349, 350, 351, 352, 353, 355, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 409, 414, 415, 417, 418, 420, 554, 555, 558, 559, 564, 565, 566, 567, 569, 570, 571, 572, 573, 574, 575, 578, 580, 582, 584, 586, 589, 620, 621, 622, 623, 626, 629, 634, 635, 636, 638, 641], "period": [1, 191, 579], "should_upd": 1, "update_policy_weights_": [1, 2, 6, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 191, 565, 567, 570, 571, 573, 575, 578, 580, 586, 619, 635, 640], "shutdown": [1, 5, 6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 154, 159, 190, 218, 324, 401, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586, 612, 619, 620, 638, 640], "follow": [1, 2, 3, 4, 5, 6, 9, 17, 18, 19, 21, 22, 25, 26, 27, 30, 41, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 109, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 144, 147, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 217, 221, 241, 250, 275, 279, 280, 288, 298, 302, 304, 305, 313, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 348, 349, 350, 351, 352, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 415, 564, 565, 566, 567, 569, 570, 572, 573, 579, 591, 605, 619, 620, 621, 622, 623, 626, 627, 633, 634, 635, 636, 638, 640, 641], "kept": [1, 3, 19, 22, 46, 49, 56, 107, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 212, 231, 259, 303, 320, 321, 580, 582, 584, 586, 626, 634], "syncdatacollector": [1, 4, 5, 18, 619, 620, 621, 622, 623, 627, 629, 634, 635, 638], "multisyncdatacollector": [1, 2, 4, 5, 621, 627, 640], "multiasyncdatacollector": [1, 2, 5, 53, 619, 620, 621, 627, 640], "datacollectorbas": [1, 5], "basecollector": [1, 5, 37, 39, 40, 41, 44, 46, 49, 54, 55, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 271, 341, 344, 382, 418, 419, 420, 554, 555, 559], "basic": [1, 6, 21, 40, 89, 144, 170, 401, 403, 419, 567, 575, 589, 591, 613, 621, 626, 627, 629, 634, 640, 641], "size": [1, 16, 18, 19, 22, 34, 35, 38, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 103, 107, 108, 109, 110, 116, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 214, 218, 220, 221, 222, 225, 228, 229, 232, 233, 234, 236, 239, 242, 244, 248, 250, 252, 253, 255, 259, 261, 262, 263, 265, 267, 268, 271, 272, 273, 274, 277, 279, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 304, 305, 306, 307, 310, 311, 312, 313, 314, 315, 316, 319, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 339, 340, 341, 343, 346, 348, 349, 350, 351, 352, 353, 355, 356, 357, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 392, 401, 405, 411, 417, 419, 420, 579, 584, 585, 591, 620, 621, 622, 623, 624, 625, 627, 631, 634, 635, 636, 641], "copi": [1, 6, 18, 35, 36, 37, 38, 39, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 74, 75, 76, 77, 83, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 217, 221, 239, 253, 264, 270, 271, 272, 279, 280, 282, 302, 304, 325, 326, 327, 328, 330, 331, 332, 337, 351, 365, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 565, 567, 570, 571, 573, 574, 575, 578, 580, 586, 591, 619, 620, 622, 624, 634, 638, 640], "distributedsynccollector": [1, 3, 45], "distributeddatacollector": [1, 3, 42, 46, 51, 569], "rpcdatacollector": [1, 3, 34, 35, 36, 38, 47, 49, 51], "distributedsyncdatacollector": [1, 3], "submitit_delayed_launch": 1, "raycollector": [1, 39, 66], "lifecycl": [1, 22, 324], "scheme": [1, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 564, 565, 566, 567, 568, 570, 571, 572, 573, 575, 578, 580, 582, 583, 584, 585, 586, 591, 641], "behavior": [1, 2, 18, 21, 22, 23, 35, 36, 38, 50, 74, 83, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 222, 229, 232, 246, 251, 264, 272, 280, 302, 303, 304, 321, 324, 325, 326, 327, 328, 330, 331, 332, 337, 350, 356, 363, 367, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 404, 409, 578, 612, 620, 622, 634, 635, 636, 638], "transport": [1, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 579, 580, 581, 582, 586], "interoper": [1, 35, 36, 38], "helper": [1, 16, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 589, 598, 613, 619, 620, 622, 634, 636], "somewhat": [2, 185, 625, 641], "equival": [2, 7, 17, 50, 53, 54, 57, 59, 60, 61, 62, 64, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 230, 233, 265, 267, 272, 297, 298, 305, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 401, 411, 627, 640, 641], "dataload": [2, 6, 52, 107, 109, 170, 171, 172, 175, 178, 185, 194, 620, 627, 638], "except": [2, 17, 21, 32, 34, 35, 36, 38, 42, 44, 47, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 235, 255, 264, 265, 266, 270, 272, 286, 301, 302, 304, 310, 312, 325, 326, 327, 328, 330, 331, 332, 337, 348, 351, 365, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 591, 619, 620, 624, 632, 634, 638, 640, 641], "1": [2, 4, 7, 8, 10, 18, 19, 21, 22, 23, 27, 29, 32, 34, 35, 36, 38, 42, 44, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 95, 96, 97, 101, 102, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 206, 212, 214, 215, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 237, 239, 241, 242, 244, 246, 248, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 270, 271, 272, 273, 275, 277, 279, 280, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 298, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 360, 363, 364, 366, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 392, 401, 403, 405, 409, 411, 412, 420, 424, 426, 439, 445, 463, 464, 467, 469, 471, 472, 476, 481, 502, 505, 515, 524, 539, 544, 549, 559, 563, 565, 566, 567, 569, 570, 571, 572, 573, 575, 578, 579, 580, 581, 584, 585, 586, 590, 591, 612, 618, 619, 620, 621, 622, 623, 625, 626, 627, 629, 633, 634, 635, 636, 637, 638, 639, 640, 641], "over": [2, 5, 7, 18, 20, 21, 22, 23, 27, 35, 36, 38, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 101, 102, 107, 108, 109, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 231, 246, 258, 266, 280, 306, 310, 317, 320, 326, 332, 337, 346, 358, 360, 365, 375, 377, 379, 382, 383, 385, 390, 411, 552, 619, 620, 621, 623, 624, 625, 626, 627, 634, 635, 636, 641], "non": [2, 6, 12, 17, 22, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 53, 55, 57, 58, 60, 63, 65, 70, 71, 74, 75, 76, 77, 83, 86, 87, 88, 96, 98, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 218, 219, 221, 225, 236, 250, 262, 265, 271, 272, 273, 274, 275, 277, 280, 287, 302, 304, 307, 325, 326, 327, 328, 330, 331, 332, 337, 343, 344, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 360, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 565, 567, 569, 570, 571, 573, 575, 578, 580, 586, 619, 622, 623, 634, 635, 636, 638, 641], "static": [2, 60, 71, 102, 108, 109, 132, 151, 174, 180, 279, 282, 326, 332, 337, 363, 375, 377, 379, 383, 624, 636, 638], "like": [2, 4, 6, 7, 17, 19, 21, 22, 23, 26, 30, 34, 35, 36, 38, 46, 50, 60, 63, 65, 68, 69, 71, 72, 73, 86, 87, 88, 90, 98, 109, 120, 123, 126, 127, 130, 132, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 233, 265, 268, 325, 326, 327, 328, 329, 330, 331, 332, 337, 344, 348, 350, 364, 367, 368, 369, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 402, 566, 612, 619, 621, 622, 623, 624, 625, 626, 627, 628, 629, 634, 635, 636, 637, 638, 640, 641], "being": [2, 3, 17, 18, 21, 22, 26, 27, 32, 34, 35, 36, 38, 41, 42, 44, 47, 49, 50, 70, 86, 87, 88, 96, 98, 101, 102, 114, 117, 120, 123, 126, 129, 130, 131, 132, 137, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 220, 229, 231, 232, 239, 245, 253, 265, 270, 271, 272, 301, 302, 304, 312, 325, 326, 327, 328, 330, 331, 332, 337, 350, 351, 364, 365, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 411, 418, 561, 562, 563, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586, 612, 619, 620, 621, 622, 627, 634, 635, 636, 638], "torchrl": [2, 3, 5, 6, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 591, 612, 618, 622, 624, 626, 627, 628, 629, 630, 633, 637, 638, 639], "two": [2, 6, 7, 18, 22, 23, 27, 29, 61, 62, 65, 68, 69, 72, 73, 83, 86, 87, 88, 107, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 226, 246, 250, 270, 277, 293, 302, 304, 317, 320, 325, 326, 327, 328, 330, 331, 332, 337, 344, 364, 367, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 409, 415, 567, 591, 619, 620, 621, 622, 623, 624, 625, 627, 628, 632, 633, 634, 635, 636, 638, 640, 641], "main": [2, 6, 7, 19, 24, 35, 36, 38, 41, 42, 47, 50, 51, 56, 66, 85, 127, 170, 193, 221, 226, 324, 344, 415, 564, 565, 566, 567, 568, 570, 571, 573, 575, 578, 580, 586, 591, 619, 620, 631, 632, 633, 640, 641], "argument": [2, 3, 6, 18, 19, 20, 21, 22, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 95, 96, 97, 98, 101, 102, 106, 107, 108, 109, 112, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 152, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 206, 212, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 244, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 286, 287, 288, 297, 298, 301, 302, 304, 305, 306, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 339, 340, 341, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 397, 399, 400, 401, 402, 403, 407, 415, 419, 420, 552, 559, 560, 563, 577, 612, 619, 620, 621, 622, 623, 624, 625, 627, 634, 635, 636, 638, 640, 641], "list": [2, 21, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 96, 98, 106, 107, 108, 109, 110, 112, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 212, 219, 220, 224, 225, 229, 230, 232, 241, 242, 246, 248, 250, 258, 260, 268, 269, 270, 271, 272, 274, 275, 277, 279, 287, 288, 290, 296, 298, 300, 302, 304, 305, 306, 308, 313, 314, 322, 324, 325, 326, 327, 328, 330, 331, 332, 334, 337, 340, 344, 346, 347, 349, 351, 363, 365, 368, 370, 371, 372, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 388, 390, 391, 401, 402, 403, 409, 411, 427, 435, 436, 442, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 475, 477, 478, 479, 480, 481, 482, 483, 484, 487, 488, 489, 490, 491, 493, 494, 495, 496, 497, 498, 500, 501, 503, 505, 506, 507, 508, 509, 512, 513, 514, 515, 516, 517, 518, 519, 520, 522, 523, 524, 525, 526, 527, 530, 531, 532, 533, 534, 535, 536, 537, 561, 562, 565, 567, 568, 570, 571, 573, 574, 575, 578, 580, 586, 612, 619, 621, 624, 625, 626, 627, 631, 632, 633, 634, 636, 637, 638, 640, 641], "constructor": [2, 17, 21, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 66, 68, 72, 73, 83, 86, 87, 101, 114, 120, 123, 126, 130, 138, 145, 150, 151, 154, 158, 159, 160, 163, 170, 171, 172, 175, 176, 177, 178, 179, 180, 195, 196, 217, 221, 270, 288, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 401, 402, 419, 560, 563, 577, 591, 612, 619, 620, 621, 624, 627, 634, 635, 638, 640], "iter": [2, 5, 18, 20, 34, 35, 36, 38, 50, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 98, 107, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 234, 246, 259, 282, 287, 288, 297, 305, 313, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 343, 345, 346, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 409, 411, 413, 415, 619, 621, 622, 627, 629, 634, 635, 636], "queri": [2, 18, 38, 86, 87, 88, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 203, 250, 275, 279, 325, 326, 327, 328, 330, 331, 332, 337, 346, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 619, 626, 631, 636, 640], "defin": [2, 7, 14, 21, 32, 34, 35, 36, 38, 41, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 251, 264, 282, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 347, 353, 355, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 414, 472, 560, 612, 619, 620, 622, 626, 629, 636, 638, 641], "number": [2, 16, 17, 18, 19, 27, 32, 34, 35, 36, 38, 39, 42, 44, 46, 47, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 106, 108, 109, 116, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 144, 145, 146, 147, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 231, 233, 234, 235, 237, 240, 241, 243, 245, 246, 249, 251, 252, 253, 255, 257, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 286, 288, 295, 299, 300, 301, 302, 303, 304, 305, 307, 308, 309, 312, 315, 316, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 397, 399, 400, 401, 405, 407, 409, 415, 417, 418, 419, 420, 472, 552, 553, 561, 562, 563, 579, 580, 581, 586, 591, 619, 620, 621, 622, 624, 625, 627, 629, 634, 635, 636, 637, 638, 641], "stack": [2, 4, 10, 17, 18, 19, 22, 26, 27, 34, 35, 36, 38, 42, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 74, 75, 76, 77, 86, 87, 96, 101, 120, 123, 126, 129, 130, 131, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 186, 195, 196, 204, 205, 221, 226, 244, 279, 302, 304, 317, 325, 327, 328, 330, 331, 340, 345, 346, 349, 351, 363, 368, 370, 371, 372, 376, 378, 380, 381, 384, 385, 391, 405, 425, 520, 591, 620, 623, 624, 631, 632, 633, 634, 636, 640], "user": [2, 6, 12, 18, 20, 21, 22, 24, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 56, 78, 79, 83, 85, 87, 88, 89, 102, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 222, 239, 264, 270, 272, 294, 326, 332, 337, 351, 367, 370, 371, 375, 377, 379, 382, 383, 392, 560, 591, 619, 620, 624, 626, 627, 632, 636, 640, 641], "reach": [2, 18, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 107, 120, 123, 126, 130, 137, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 244, 263, 286, 301, 312, 619, 621, 629, 631, 634, 635, 640, 641], "done": [2, 17, 18, 19, 21, 22, 23, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 92, 93, 100, 102, 108, 109, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 215, 217, 218, 221, 229, 230, 232, 233, 234, 239, 243, 244, 245, 246, 248, 252, 253, 255, 257, 259, 262, 263, 265, 266, 269, 270, 271, 272, 273, 279, 302, 304, 320, 329, 340, 348, 349, 350, 351, 352, 353, 355, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 379, 382, 383, 385, 386, 387, 388, 389, 408, 492, 591, 612, 619, 621, 622, 623, 624, 626, 627, 629, 632, 633, 634, 635, 636, 638, 640, 641], "state": [2, 6, 17, 18, 21, 22, 23, 32, 34, 35, 36, 38, 40, 41, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 100, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 144, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 217, 220, 221, 222, 224, 225, 227, 230, 233, 236, 239, 243, 244, 246, 253, 263, 264, 269, 270, 271, 272, 273, 274, 279, 280, 283, 289, 294, 299, 302, 304, 305, 308, 311, 315, 316, 317, 323, 325, 326, 327, 328, 329, 330, 331, 332, 337, 340, 343, 348, 350, 351, 355, 357, 364, 365, 367, 368, 369, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 401, 408, 415, 417, 419, 420, 472, 563, 572, 577, 591, 600, 605, 613, 619, 620, 621, 622, 623, 624, 625, 626, 627, 631, 632, 634, 635, 636, 641], "after": [2, 4, 6, 19, 20, 22, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 66, 69, 78, 86, 87, 88, 97, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 135, 136, 137, 138, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 286, 297, 301, 302, 304, 313, 325, 326, 327, 328, 330, 331, 332, 337, 351, 360, 370, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 401, 402, 564, 565, 566, 567, 568, 570, 571, 572, 573, 575, 576, 578, 580, 586, 591, 612, 620, 621, 622, 623, 624, 625, 627, 629, 631, 634, 635, 636, 637, 638, 641], "predefin": [2, 7, 183, 392, 620, 622, 627, 638, 640], "becaus": [2, 18, 21, 22, 23, 26, 53, 60, 71, 78, 86, 87, 88, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 233, 241, 263, 278, 293, 297, 298, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 344, 348, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 619, 620, 622, 623, 625, 626, 627, 631, 633, 634, 635, 636, 638, 641], "comput": [2, 6, 17, 18, 21, 22, 23, 27, 34, 38, 39, 50, 52, 59, 86, 87, 88, 101, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 243, 246, 260, 272, 276, 280, 283, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 320, 321, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 340, 341, 344, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 408, 419, 420, 472, 553, 567, 573, 591, 594, 605, 612, 619, 621, 622, 623, 624, 625, 631, 632, 633, 634, 635, 637, 638], "heavi": [2, 6, 27, 78, 612, 638], "crucial": [2, 20, 86, 87, 176, 286, 301, 312, 325, 327, 328, 330, 331, 356, 363, 365, 376, 378, 379, 380, 381, 384, 420, 591, 619, 620, 621, 622, 624, 626, 628, 634, 635, 636, 640, 641], "hyperparamet": [2, 106, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 589, 619, 628, 636, 638], "appropri": [2, 6, 7, 17, 23, 26, 87, 94, 104, 114, 115, 118, 119, 138, 150, 158, 179, 180, 233, 560, 563, 591, 612, 619, 628, 638], "take": [2, 17, 20, 21, 22, 27, 41, 56, 80, 86, 87, 90, 111, 117, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 183, 224, 226, 263, 266, 267, 271, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 325, 327, 328, 330, 331, 338, 340, 341, 344, 347, 367, 376, 378, 380, 381, 384, 392, 405, 418, 591, 619, 620, 621, 623, 624, 625, 626, 634, 635, 636, 638, 641], "consider": [2, 21, 22, 27, 129, 131, 271, 324, 589, 591, 620, 634, 635, 638], "whether": [2, 18, 22, 32, 34, 35, 36, 38, 39, 42, 44, 47, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 97, 104, 116, 120, 123, 126, 130, 137, 138, 142, 143, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 217, 226, 227, 229, 232, 243, 264, 270, 272, 279, 280, 288, 302, 304, 305, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 340, 344, 348, 349, 350, 351, 352, 353, 355, 357, 358, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 404, 415, 419, 420, 472, 563, 565, 567, 568, 570, 571, 573, 575, 577, 578, 580, 582, 584, 586, 612, 619, 620, 621, 623, 624, 634, 635, 636, 640, 641], "should": [2, 5, 6, 7, 17, 18, 20, 21, 22, 23, 24, 26, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 95, 98, 102, 108, 109, 110, 114, 117, 120, 123, 124, 125, 126, 129, 130, 131, 132, 137, 138, 141, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 214, 217, 218, 221, 224, 225, 226, 229, 230, 233, 234, 236, 241, 242, 244, 246, 251, 252, 253, 255, 258, 259, 263, 264, 266, 269, 271, 272, 273, 278, 279, 280, 282, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 341, 343, 344, 347, 348, 350, 351, 357, 364, 365, 367, 368, 369, 370, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 392, 394, 404, 409, 410, 411, 415, 559, 561, 562, 563, 566, 568, 570, 571, 573, 578, 579, 580, 586, 612, 619, 620, 621, 622, 623, 625, 627, 628, 631, 633, 634, 635, 636, 637, 638, 640, 641], "occur": [2, 6, 27, 35, 70, 71, 78, 120, 123, 126, 130, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 222, 234, 246, 251, 278, 297, 298, 313, 314, 326, 332, 337, 339, 341, 343, 344, 360, 375, 377, 379, 383, 591, 623, 638, 641], "serial": [2, 6, 15, 18, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 279, 280, 326, 332, 337, 375, 377, 379, 382, 383], "multisynccollector": [2, 3, 5, 34, 35, 36, 42, 44, 47, 50, 53, 562, 567], "split": [2, 6, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 71, 78, 79, 80, 81, 82, 83, 84, 85, 102, 108, 109, 141, 152, 153, 171, 307, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 621, 625, 638, 640], "workload": [2, 324], "result": [2, 3, 7, 17, 18, 20, 21, 22, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 56, 58, 65, 66, 67, 68, 69, 72, 73, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 102, 107, 108, 109, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 212, 213, 214, 217, 218, 219, 221, 222, 223, 224, 225, 227, 228, 229, 230, 231, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 286, 298, 301, 302, 304, 305, 314, 320, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 337, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 391, 401, 417, 418, 591, 612, 620, 622, 624, 625, 628, 629, 632, 636, 637, 640, 641], "final": [2, 7, 21, 22, 23, 50, 86, 87, 172, 175, 176, 177, 183, 265, 278, 286, 301, 302, 304, 312, 324, 325, 327, 328, 330, 331, 333, 334, 345, 376, 378, 380, 381, 384, 385, 409, 619, 620, 621, 623, 628, 629, 631, 634, 635, 636, 641], "multiasynccollector": [2, 5, 32, 36, 38, 42, 44, 47, 50, 561], "continu": [2, 21, 28, 58, 60, 75, 76, 87, 109, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 206, 214, 239, 265, 273, 290, 291, 292, 293, 312, 326, 346, 349, 385, 420, 566, 619, 621, 622, 625, 634, 635, 638], "concomitantli": [2, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180], "network": [2, 6, 23, 27, 81, 88, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 283, 284, 285, 288, 290, 291, 292, 293, 296, 299, 300, 305, 308, 309, 315, 316, 317, 326, 332, 337, 343, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 414, 420, 463, 465, 466, 467, 469, 472, 558, 559, 589, 598, 604, 623, 626, 629, 633, 636, 641], "impli": [2, 641], "slightli": [2, 56, 78, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 622, 623, 634, 636, 637, 638, 641], "therefor": [2, 19, 21, 22, 26, 65, 68, 72, 73, 84, 85, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 183, 255, 325, 327, 328, 330, 331, 367, 376, 378, 380, 381, 382, 384, 623, 626, 634, 641], "fastest": 2, "price": 2, "suitabl": [2, 6, 221, 379], "curriculum": [2, 23], "remot": [2, 6, 10, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 150, 158, 176, 189, 194, 195, 280, 325, 327, 328, 329, 330, 331, 337, 376, 378, 380, 381, 384, 401, 402, 569, 570, 571, 572, 573, 579, 584, 585, 586, 612, 641], "rollout": [2, 16, 17, 18, 20, 22, 30, 32, 34, 35, 36, 38, 50, 52, 53, 56, 114, 120, 121, 122, 123, 126, 130, 132, 133, 136, 137, 138, 142, 143, 144, 145, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 165, 170, 171, 172, 175, 178, 179, 180, 185, 214, 215, 217, 218, 221, 224, 226, 227, 229, 232, 233, 234, 239, 241, 242, 248, 252, 253, 258, 259, 260, 263, 264, 266, 267, 270, 273, 279, 280, 287, 302, 304, 312, 317, 340, 348, 390, 392, 553, 605, 619, 621, 622, 625, 626, 627, 628, 629, 637, 638, 640], "necessari": [2, 6, 23, 25, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 78, 80, 81, 83, 84, 85, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 259, 368, 385, 386, 387, 388, 389, 619, 621, 625, 626, 627, 631, 632], "synchronis": [2, 127, 634, 635], "either": [2, 5, 24, 51, 55, 57, 65, 66, 68, 69, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 243, 244, 263, 264, 280, 323, 326, 332, 334, 337, 365, 371, 372, 375, 377, 379, 382, 383, 396, 591, 599, 619, 620, 622, 634, 637, 638, 640, 641], "update_at_each_batch": [2, 32, 35, 36, 38], "second": [2, 6, 22, 27, 32, 34, 35, 36, 38, 52, 56, 61, 62, 78, 80, 114, 150, 184, 190, 192, 197, 218, 267, 298, 302, 304, 324, 350, 364, 367, 370, 392, 394, 397, 399, 400, 413, 564, 565, 566, 567, 569, 570, 571, 572, 573, 575, 576, 578, 580, 586, 612, 619, 621, 627, 634, 635, 636, 638, 640, 641], "oper": [2, 3, 6, 17, 21, 22, 23, 26, 27, 32, 34, 35, 36, 38, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 96, 97, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 236, 241, 267, 269, 273, 280, 283, 284, 285, 296, 297, 298, 323, 325, 326, 327, 328, 329, 330, 331, 332, 337, 343, 348, 350, 352, 353, 358, 364, 367, 369, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 401, 402, 415, 565, 567, 572, 579, 580, 581, 584, 591, 593, 605, 619, 620, 621, 622, 623, 624, 625, 633, 634, 635, 636, 641], "instanc": [2, 6, 7, 17, 20, 21, 22, 23, 26, 27, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 58, 60, 65, 66, 67, 68, 69, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 95, 96, 97, 100, 102, 108, 109, 116, 120, 123, 125, 126, 127, 129, 130, 131, 135, 138, 144, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 213, 246, 265, 272, 279, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341, 343, 344, 345, 346, 347, 349, 351, 353, 356, 357, 363, 365, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 392, 396, 403, 404, 409, 417, 418, 465, 553, 554, 555, 559, 561, 562, 575, 578, 580, 586, 591, 612, 619, 621, 622, 623, 624, 625, 631, 636, 638, 641], "cpu": [2, 3, 6, 18, 22, 27, 29, 32, 34, 35, 36, 38, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 101, 108, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 214, 218, 225, 229, 230, 232, 233, 234, 239, 242, 243, 248, 250, 252, 253, 255, 259, 262, 263, 265, 271, 272, 273, 275, 277, 283, 284, 285, 287, 296, 297, 298, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 329, 330, 331, 332, 337, 339, 340, 341, 343, 346, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 401, 442, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 489, 508, 532, 533, 534, 574, 612, 619, 620, 621, 622, 634, 635, 636, 637, 640], "slower": [2, 3, 8, 9, 567, 634], "than": [2, 3, 6, 22, 23, 27, 32, 34, 35, 36, 38, 42, 44, 46, 47, 50, 52, 53, 57, 65, 68, 69, 72, 73, 78, 79, 83, 86, 87, 88, 102, 108, 109, 112, 114, 120, 123, 126, 130, 134, 138, 148, 149, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 189, 195, 226, 242, 244, 253, 280, 286, 293, 297, 302, 304, 305, 307, 322, 325, 327, 328, 330, 331, 332, 339, 343, 344, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 416, 418, 567, 580, 590, 591, 612, 619, 620, 621, 622, 623, 624, 626, 634, 635, 636, 638, 640, 641], "one": [2, 3, 6, 7, 17, 18, 20, 21, 22, 23, 24, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 83, 86, 87, 88, 92, 93, 94, 95, 100, 101, 102, 104, 108, 109, 110, 112, 114, 115, 118, 119, 120, 121, 122, 123, 126, 127, 129, 130, 131, 132, 134, 135, 136, 137, 138, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 221, 224, 226, 227, 229, 230, 231, 232, 239, 242, 243, 245, 246, 250, 255, 258, 261, 262, 264, 265, 266, 271, 272, 274, 277, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 339, 340, 341, 343, 344, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 392, 394, 403, 407, 409, 410, 415, 553, 563, 565, 575, 586, 590, 591, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 633, 634, 635, 636, 637, 638, 641], "cuda": [2, 3, 21, 22, 26, 34, 35, 36, 38, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 121, 122, 123, 126, 130, 132, 133, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 241, 249, 250, 265, 271, 272, 275, 277, 326, 332, 333, 337, 343, 375, 377, 379, 382, 383, 406, 574, 579, 619, 620, 621, 622, 634, 635, 637, 641], "dispatch": [2, 5, 22, 42, 44, 47, 50, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 326, 332, 337, 340, 375, 377, 379, 382, 383, 392, 565, 567, 570, 571, 573, 575, 578, 580, 586, 619, 641], "speed": [2, 5, 22, 23, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 612, 619, 620, 621, 622, 634, 635, 636, 638, 640], "avoid": [2, 7, 17, 20, 81, 88, 95, 97, 108, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 221, 239, 270, 272, 279, 280, 320, 322, 326, 332, 337, 339, 343, 350, 351, 364, 367, 370, 375, 377, 379, 382, 383, 552, 564, 567, 569, 571, 573, 574, 591, 612, 621, 623, 632, 635], "oom": [2, 20, 86, 87, 95, 97, 116, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "choic": [2, 15, 63, 79, 85, 86, 87, 150, 176, 185, 307, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 419, 619, 620, 626, 634, 635], "pass": [2, 4, 5, 6, 9, 12, 17, 18, 19, 20, 21, 22, 23, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 57, 60, 63, 65, 66, 68, 69, 71, 72, 73, 74, 78, 80, 81, 83, 84, 85, 86, 87, 88, 93, 95, 97, 102, 108, 109, 114, 116, 120, 123, 126, 127, 128, 130, 131, 138, 141, 145, 150, 151, 152, 153, 154, 158, 159, 160, 163, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 215, 217, 218, 221, 225, 227, 229, 232, 242, 244, 252, 253, 270, 271, 274, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 313, 314, 315, 316, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 339, 340, 341, 343, 344, 346, 347, 349, 350, 351, 363, 364, 365, 367, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 401, 402, 403, 411, 415, 419, 420, 561, 562, 563, 571, 574, 575, 591, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 633, 634, 635, 636, 638, 640, 641], "ie": [2, 17, 42, 47, 51, 57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 72, 74, 75, 76, 77, 83, 101, 109, 120, 123, 126, 130, 134, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 214, 221, 236, 262, 265, 274, 279, 302, 304, 326, 332, 337, 343, 375, 377, 379, 383, 620, 635], "while": [2, 6, 7, 17, 21, 22, 26, 27, 32, 34, 35, 36, 38, 52, 56, 66, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 255, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 340, 347, 350, 356, 363, 364, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 572, 591, 612, 619, 621, 622, 625, 627, 628, 634, 635, 636, 637, 638, 640], "wait": [2, 6, 32, 33, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 66, 95, 97, 161, 183, 324, 564, 565, 566, 567, 569, 570, 571, 572, 573, 575, 576, 578, 579, 580, 586, 622, 636], "impact": [2, 18, 33, 42, 43, 44, 45, 47, 48, 83, 137, 229, 232, 332, 348, 350, 364, 367, 369, 379, 620, 622, 634, 635], "memori": [2, 3, 4, 6, 9, 10, 12, 18, 21, 27, 32, 35, 36, 38, 50, 55, 59, 66, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 90, 91, 93, 95, 96, 100, 120, 121, 122, 123, 126, 127, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 221, 225, 250, 265, 271, 272, 275, 277, 279, 280, 295, 325, 326, 327, 328, 330, 331, 332, 337, 343, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 401, 424, 563, 565, 566, 567, 570, 571, 573, 574, 575, 578, 580, 581, 586, 591, 612, 619, 620, 622, 634, 638, 640], "which": [2, 3, 5, 6, 7, 10, 17, 18, 19, 21, 22, 23, 26, 27, 32, 34, 35, 36, 37, 38, 41, 42, 44, 47, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 92, 96, 106, 107, 114, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 205, 221, 222, 226, 229, 232, 237, 239, 241, 242, 245, 246, 250, 251, 253, 263, 265, 266, 269, 270, 271, 272, 273, 275, 279, 282, 283, 284, 285, 296, 302, 303, 304, 306, 317, 321, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 343, 344, 345, 346, 348, 349, 350, 351, 353, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 392, 401, 405, 410, 419, 565, 566, 567, 570, 571, 573, 575, 578, 580, 586, 591, 593, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 631, 633, 634, 635, 636, 637, 638, 641], "storing_devic": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 620, 622, 635], "dure": [2, 6, 10, 18, 20, 21, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 93, 95, 97, 98, 101, 102, 106, 108, 120, 123, 126, 127, 130, 137, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 182, 185, 191, 198, 199, 217, 218, 221, 224, 229, 232, 234, 236, 237, 239, 244, 248, 260, 262, 265, 267, 269, 270, 272, 273, 274, 279, 280, 287, 302, 304, 324, 332, 340, 350, 367, 379, 383, 385, 387, 388, 409, 415, 417, 420, 564, 566, 567, 573, 575, 583, 584, 587, 591, 602, 619, 620, 621, 622, 625, 626, 627, 629, 634, 635, 636, 638, 641], "heurist": [2, 23, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 176, 286, 325, 327, 328, 330, 331, 340, 344, 376, 378, 380, 381, 384, 619, 623, 627, 641], "usual": [2, 17, 18, 21, 23, 25, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 79, 106, 114, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 270, 367, 371, 379, 383, 385, 386, 387, 388, 389, 391, 590, 591, 593, 619, 620, 621, 622, 625, 627, 628, 635, 638, 641], "same": [2, 4, 5, 6, 7, 18, 19, 21, 22, 23, 34, 41, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 83, 86, 87, 88, 107, 108, 109, 112, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 141, 145, 146, 150, 151, 152, 153, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 221, 229, 231, 232, 237, 239, 242, 244, 245, 246, 262, 270, 271, 272, 279, 282, 288, 305, 306, 312, 320, 324, 325, 326, 327, 328, 330, 331, 332, 337, 347, 349, 351, 363, 365, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 401, 419, 564, 565, 567, 569, 570, 572, 573, 580, 581, 586, 587, 591, 612, 619, 620, 621, 624, 625, 627, 631, 632, 633, 634, 635, 637, 638, 641], "default": [2, 3, 6, 7, 17, 19, 21, 22, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 95, 96, 97, 98, 101, 102, 104, 106, 107, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 205, 206, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 245, 246, 248, 249, 250, 251, 252, 253, 255, 257, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311, 312, 313, 314, 315, 316, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 394, 397, 398, 399, 400, 401, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 418, 419, 420, 463, 472, 559, 563, 565, 566, 567, 568, 570, 571, 572, 573, 575, 577, 578, 580, 582, 584, 586, 619, 620, 621, 622, 625, 634, 637, 638, 640, 641], "besid": 2, "those": [2, 22, 24, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 199, 221, 226, 229, 232, 239, 246, 265, 266, 269, 273, 304, 341, 344, 345, 346, 418, 561, 562, 565, 567, 570, 571, 573, 578, 580, 586, 619, 620, 624, 625, 635, 636, 641], "max_frames_per_traj": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 552, 619, 621, 640], "frame": [2, 30, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 78, 90, 221, 237, 286, 301, 312, 340, 391, 392, 394, 397, 399, 400, 407, 409, 415, 419, 420, 472, 552, 553, 619, 620, 621, 622, 625, 634, 635, 638, 640, 641], "call": [2, 6, 7, 8, 17, 18, 20, 21, 22, 26, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 102, 103, 107, 108, 110, 112, 116, 117, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 135, 136, 137, 138, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 203, 210, 213, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 230, 231, 233, 234, 235, 236, 237, 239, 240, 241, 243, 244, 246, 248, 249, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 340, 343, 344, 346, 347, 349, 350, 351, 357, 363, 364, 365, 367, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 394, 401, 402, 409, 411, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 575, 576, 578, 579, 580, 584, 585, 586, 591, 593, 612, 620, 621, 622, 623, 624, 625, 627, 628, 634, 635, 636, 638, 640, 641], "init_random_fram": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 552, 619, 620, 623, 629], "random": [2, 7, 19, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 85, 103, 114, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 185, 214, 231, 245, 246, 265, 272, 287, 301, 302, 324, 326, 332, 337, 341, 342, 343, 344, 349, 365, 368, 374, 375, 377, 379, 383, 409, 419, 420, 429, 467, 472, 504, 553, 605, 619, 620, 621, 623, 624, 625, 627, 636, 637, 638, 640, 641], "rand_step": [2, 19, 22, 120, 123, 124, 125, 126, 127, 129, 130, 131, 138, 139, 140, 144, 145, 146, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 240, 265, 279, 636, 640, 641], "reset_at_each_it": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 619], "split_traj": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 79, 81, 83, 84, 85, 619, 620, 621], "trajectori": [2, 4, 17, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 56, 72, 78, 79, 80, 81, 83, 84, 85, 101, 102, 108, 109, 114, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 251, 263, 270, 304, 312, 367, 382, 385, 388, 405, 433, 434, 619, 620, 621, 622, 624, 627, 629, 636, 640, 641], "pad": [2, 22, 56, 79, 81, 83, 84, 85, 87, 185, 188, 189, 195, 196, 199, 205, 221, 269, 288, 290, 291, 304, 306, 326, 327, 328, 329, 330, 331, 332, 337, 379, 411, 463, 591, 632], "along": [2, 18, 22, 35, 36, 38, 56, 57, 58, 59, 60, 61, 62, 63, 64, 69, 70, 71, 74, 75, 76, 77, 79, 81, 83, 84, 85, 86, 87, 88, 97, 102, 108, 109, 114, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 205, 206, 220, 221, 222, 244, 246, 248, 251, 258, 262, 268, 297, 304, 305, 306, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 344, 351, 365, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 619, 620, 622, 624, 626, 634, 635, 636, 638, 640], "mask": [2, 16, 18, 22, 23, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 87, 89, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 195, 196, 215, 251, 287, 297, 298, 301, 306, 313, 314, 326, 329, 332, 337, 357, 370, 375, 379, 383, 408, 411, 591, 593, 620, 622, 623, 632, 641], "point": [2, 19, 22, 51, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 70, 71, 74, 75, 76, 77, 82, 88, 94, 101, 102, 104, 114, 115, 118, 119, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 275, 276, 277, 278, 279, 324, 326, 332, 337, 343, 358, 375, 377, 379, 382, 383, 415, 590, 613, 615, 620, 621, 633, 634, 635, 636, 638, 640, 641], "boolean": [2, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 108, 109, 130, 180, 213, 217, 226, 251, 263, 306, 312, 591, 622], "repres": [2, 17, 19, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 60, 63, 71, 72, 81, 86, 87, 96, 120, 123, 124, 125, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 237, 251, 267, 279, 297, 298, 306, 313, 314, 320, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 385, 411, 599, 619, 621, 622, 623, 624, 625, 626, 634, 635], "valid": [2, 7, 19, 56, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 166, 170, 171, 172, 175, 178, 179, 180, 217, 251, 270, 272, 286, 288, 305, 306, 312, 326, 329, 350, 357, 364, 367, 370, 377, 379, 385, 386, 387, 388, 411, 623, 641], "valu": [2, 7, 17, 18, 19, 21, 22, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 101, 102, 108, 109, 114, 120, 123, 126, 130, 131, 138, 141, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 203, 206, 211, 212, 213, 214, 217, 219, 221, 222, 224, 227, 229, 230, 231, 232, 233, 239, 245, 246, 250, 251, 254, 255, 256, 258, 260, 262, 265, 266, 270, 271, 272, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 290, 291, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 310, 312, 313, 314, 318, 319, 320, 321, 322, 325, 326, 327, 328, 330, 331, 332, 337, 338, 339, 341, 343, 344, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 392, 404, 405, 407, 408, 409, 410, 411, 415, 419, 469, 472, 559, 589, 598, 605, 620, 623, 626, 627, 628, 633, 634, 635, 636, 638, 640, 641], "exploration_typ": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 409, 467, 619, 620], "explor": [2, 7, 281, 286, 297, 298, 301, 312, 313, 314, 339, 341, 343, 344, 348, 365, 367, 409, 420, 554, 555, 559, 589, 598, 621, 622, 623, 624, 626, 627, 629, 634, 635, 636], "reset_when_don": [2, 32, 34, 35, 36, 38], "its": [2, 6, 17, 18, 19, 21, 22, 23, 24, 26, 28, 30, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 72, 74, 75, 76, 77, 86, 87, 88, 97, 101, 102, 108, 109, 120, 123, 126, 130, 137, 138, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 220, 221, 227, 233, 241, 263, 264, 265, 270, 272, 278, 279, 280, 282, 286, 288, 297, 302, 304, 306, 307, 313, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 347, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 370, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 415, 419, 420, 559, 565, 570, 573, 574, 586, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 634, 635, 636, 637, 638, 640, 641], "within": [2, 20, 21, 22, 32, 35, 36, 38, 41, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 96, 101, 102, 109, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 280, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 344, 347, 353, 358, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 392, 401, 415, 612, 620, 623, 624, 625, 626, 627, 628, 629, 634, 636, 640], "how": [2, 5, 6, 13, 17, 19, 21, 30, 41, 42, 44, 47, 65, 72, 83, 86, 87, 88, 101, 102, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 242, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 348, 350, 364, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 394, 415, 417, 578, 582, 589, 590, 619, 620, 621, 622, 623, 624, 625, 627, 628, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "tabl": [2, 379, 620, 625], "summar": [2, 17, 187, 636], "what": [2, 7, 18, 19, 21, 22, 27, 30, 35, 36, 38, 65, 74, 78, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 195, 196, 212, 233, 265, 270, 313, 351, 362, 365, 371, 375, 377, 379, 383, 590, 619, 620, 621, 622, 623, 624, 625, 626, 627, 629, 631, 632, 634, 635, 636, 637, 638, 640, 641], "expect": [2, 5, 6, 8, 17, 18, 21, 22, 23, 26, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 81, 86, 87, 88, 102, 107, 108, 120, 123, 126, 130, 138, 144, 147, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 214, 218, 219, 220, 221, 222, 223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 238, 240, 241, 242, 243, 244, 246, 248, 250, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 298, 302, 304, 312, 324, 325, 326, 327, 328, 330, 331, 332, 337, 343, 346, 348, 349, 350, 351, 352, 353, 355, 356, 357, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 553, 590, 612, 619, 621, 622, 624, 625, 626, 627, 631, 632, 634, 635, 636, 638, 641], "n": [2, 4, 6, 17, 19, 25, 26, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 101, 102, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 231, 236, 274, 312, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 344, 348, 349, 357, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 411, 480, 591, 620, 622, 623, 632, 638, 640, 641], "b": [2, 22, 26, 27, 52, 56, 60, 68, 71, 72, 73, 86, 87, 95, 96, 114, 123, 176, 197, 201, 239, 273, 325, 326, 327, 328, 330, 331, 332, 337, 347, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 392, 620, 631, 638], "cat_result": [2, 4, 35, 36, 38], "na": [2, 172, 175, 193], "t": [2, 4, 12, 21, 22, 23, 25, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 92, 101, 102, 107, 108, 109, 114, 120, 123, 126, 127, 129, 130, 138, 145, 146, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 239, 240, 241, 243, 249, 250, 251, 252, 253, 254, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 277, 278, 279, 282, 297, 302, 304, 306, 312, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 343, 348, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 392, 400, 415, 418, 563, 580, 590, 591, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 633, 634, 635, 636, 637, 638, 640, 641], "p": [2, 23, 69, 101, 102, 106, 127, 156, 157, 287, 317], "In": [2, 3, 4, 6, 7, 8, 12, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 51, 52, 78, 79, 81, 83, 84, 85, 86, 87, 88, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 229, 230, 232, 240, 250, 255, 259, 264, 265, 268, 270, 271, 272, 275, 277, 278, 280, 282, 303, 305, 316, 320, 321, 325, 326, 327, 328, 330, 331, 332, 337, 343, 344, 346, 348, 349, 351, 352, 353, 355, 356, 357, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 418, 561, 562, 563, 585, 586, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 634, 635, 636, 637, 638, 641], "case": [2, 4, 6, 7, 15, 18, 19, 20, 21, 22, 23, 24, 26, 27, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 92, 93, 100, 114, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 195, 197, 229, 230, 232, 240, 246, 265, 268, 272, 273, 282, 304, 305, 325, 327, 328, 330, 331, 341, 343, 344, 346, 347, 348, 349, 351, 352, 353, 355, 356, 357, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 392, 402, 405, 418, 561, 562, 563, 591, 592, 619, 620, 621, 622, 623, 624, 625, 627, 628, 632, 634, 635, 636, 638, 640, 641], "dimens": [2, 4, 17, 18, 19, 22, 34, 35, 36, 38, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 79, 81, 83, 84, 85, 86, 87, 95, 96, 97, 102, 108, 109, 114, 116, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 177, 178, 179, 180, 185, 205, 206, 214, 220, 221, 222, 236, 244, 246, 248, 251, 258, 261, 262, 265, 268, 274, 279, 280, 288, 289, 294, 295, 297, 302, 304, 305, 306, 311, 319, 320, 325, 327, 328, 330, 331, 332, 337, 338, 340, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 563, 591, 619, 620, 621, 622, 624, 631, 634, 635, 636, 638], "time": [2, 4, 5, 7, 17, 22, 23, 26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 56, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 92, 95, 114, 120, 121, 122, 123, 126, 127, 130, 136, 137, 138, 141, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 212, 220, 221, 222, 244, 251, 258, 265, 266, 267, 270, 272, 279, 287, 299, 304, 312, 317, 325, 326, 327, 328, 330, 331, 332, 337, 340, 344, 349, 350, 351, 357, 360, 363, 364, 365, 367, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 415, 419, 472, 525, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 575, 576, 578, 580, 586, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 634, 635, 636, 638, 640, 641], "adapt": [2, 4, 215, 244, 263, 279, 324, 357, 364, 370, 591, 619, 623, 636], "equal": [2, 32, 35, 36, 38, 78, 88, 102, 108, 109, 123, 145, 148, 149, 150, 158, 178, 245, 246, 288, 302, 304, 305, 306, 350, 367, 379, 405, 561, 562, 619, 621, 637], "i": [2, 5, 6, 17, 19, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 60, 65, 68, 71, 73, 86, 87, 88, 90, 91, 95, 97, 101, 102, 108, 109, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 228, 244, 250, 255, 258, 270, 272, 277, 298, 302, 304, 307, 314, 325, 326, 327, 328, 330, 331, 332, 337, 340, 341, 343, 344, 348, 350, 351, 352, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 405, 552, 572, 591, 619, 620, 621, 622, 623, 625, 626, 627, 628, 629, 634, 635, 636, 638, 640, 641], "introduc": [2, 101, 102, 150, 158, 302, 304, 312, 619, 634], "some": [2, 6, 8, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 51, 57, 58, 59, 60, 61, 62, 63, 64, 66, 68, 69, 70, 71, 74, 75, 76, 77, 79, 85, 86, 87, 88, 90, 95, 97, 114, 116, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 203, 217, 250, 265, 272, 275, 290, 302, 325, 326, 327, 328, 330, 331, 332, 337, 344, 345, 346, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 405, 552, 565, 567, 570, 571, 573, 575, 576, 578, 580, 586, 591, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 634, 635, 636, 638, 640, 641], "confus": [2, 57, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 326, 332, 337, 375, 377, 379, 382, 383], "other": [2, 3, 5, 6, 7, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 30, 32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 74, 75, 76, 77, 78, 79, 81, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 106, 107, 108, 109, 110, 112, 116, 120, 123, 126, 129, 130, 131, 135, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 224, 226, 230, 231, 252, 259, 265, 268, 275, 279, 280, 298, 301, 302, 304, 307, 314, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 344, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 401, 403, 408, 411, 561, 562, 566, 574, 585, 586, 589, 591, 605, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 634, 635, 636, 637, 640, 641], "better": [2, 6, 19, 22, 27, 28, 34, 35, 36, 38, 54, 55, 56, 137, 170, 171, 172, 175, 177, 189, 302, 304, 324, 333, 337, 591, 621, 624, 636, 640], "consist": [2, 5, 16, 17, 18, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 80, 83, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 278, 288, 305, 326, 332, 337, 375, 377, 379, 382, 383, 584, 587, 595, 612, 619, 620, 621, 632, 636, 637, 641], "interact": [2, 20, 21, 23, 24, 26, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 83, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 181, 184, 272, 341, 344, 420, 591, 619, 621, 623, 624, 625, 627, 634, 635, 636, 641], "separ": [2, 4, 6, 7, 23, 27, 32, 34, 35, 36, 38, 42, 47, 50, 52, 56, 60, 68, 71, 72, 73, 78, 80, 86, 87, 176, 183, 221, 250, 277, 324, 325, 327, 328, 330, 331, 349, 352, 355, 357, 368, 370, 371, 372, 376, 378, 380, 381, 384, 385, 401, 579, 591, 612, 619, 620, 625, 626, 634, 635, 638, 641], "interchang": [2, 621, 624, 628, 632, 637, 638], "wherea": [2, 51, 52, 63, 83, 88, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 231, 270, 272, 326, 332, 337, 351, 365, 370, 375, 377, 379, 382, 383, 628], "correspond": [2, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 72, 74, 75, 76, 77, 80, 83, 85, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 250, 265, 270, 272, 277, 279, 280, 301, 302, 304, 306, 312, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 351, 353, 356, 357, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 402, 564, 619, 620, 621, 623, 624, 626, 627, 628, 634, 635, 636, 637], "sub": [2, 3, 6, 21, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 71, 78, 83, 88, 108, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 251, 270, 271, 280, 326, 332, 337, 345, 346, 375, 377, 379, 382, 383, 405, 415, 565, 567, 570, 571, 573, 575, 578, 580, 586, 619, 620, 621, 627, 633, 640, 641], "doesn": [2, 23, 32, 35, 36, 38, 88, 114, 120, 123, 126, 130, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 282, 326, 329, 332, 337, 375, 377, 379, 382, 383, 580, 623, 624], "understood": [2, 619], "basi": [2, 114, 638, 640], "we": [2, 6, 12, 17, 18, 19, 21, 22, 24, 26, 28, 30, 53, 54, 56, 60, 65, 68, 72, 73, 78, 79, 83, 85, 88, 95, 107, 109, 114, 120, 121, 122, 123, 126, 127, 130, 134, 136, 137, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 226, 241, 250, 253, 259, 270, 275, 278, 279, 280, 282, 304, 306, 324, 326, 332, 337, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 392, 419, 564, 567, 575, 590, 591, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 633, 634, 635, 636, 637, 638, 640, 641], "anoth": [2, 18, 21, 22, 27, 37, 39, 40, 41, 46, 49, 54, 74, 83, 87, 96, 102, 108, 120, 123, 126, 129, 130, 131, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 196, 218, 227, 229, 230, 232, 265, 271, 305, 341, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 402, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 416, 418, 619, 621, 622, 623, 625, 626, 633, 634, 635, 636, 641], "wise": [2, 244, 379], "requir": [2, 4, 6, 17, 18, 22, 23, 26, 27, 32, 34, 35, 36, 37, 38, 39, 40, 42, 44, 46, 47, 49, 50, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 81, 83, 86, 87, 88, 96, 101, 102, 108, 109, 120, 123, 126, 130, 134, 138, 145, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 225, 226, 239, 250, 262, 265, 270, 271, 272, 275, 277, 280, 302, 304, 305, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 343, 344, 345, 346, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 392, 394, 403, 418, 419, 472, 580, 585, 586, 591, 619, 620, 621, 622, 624, 625, 626, 628, 631, 632, 634, 635, 636, 638, 640, 641], "method": [2, 6, 16, 20, 21, 22, 23, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 108, 109, 110, 111, 112, 114, 116, 120, 123, 126, 129, 130, 131, 132, 137, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 233, 234, 235, 236, 237, 240, 241, 243, 244, 246, 249, 250, 251, 252, 253, 254, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 295, 297, 298, 301, 302, 304, 313, 314, 317, 324, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 342, 343, 344, 345, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 362, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 389, 390, 391, 401, 402, 408, 420, 560, 564, 565, 566, 567, 568, 570, 571, 572, 573, 574, 575, 578, 579, 580, 582, 584, 586, 589, 605, 612, 617, 620, 621, 622, 623, 624, 625, 626, 627, 628, 631, 634, 636, 638, 641], "op": [2, 6, 7, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 57, 58, 59, 61, 62, 63, 64, 74, 75, 76, 77, 186, 245, 278, 286, 301, 392, 418, 564, 566, 568, 569, 574, 576, 584], "sinc": [2, 3, 6, 19, 21, 23, 24, 26, 30, 32, 34, 35, 36, 38, 41, 52, 53, 54, 56, 65, 68, 72, 73, 78, 85, 86, 87, 88, 101, 102, 109, 114, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 155, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 227, 286, 287, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 347, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 392, 565, 567, 570, 571, 572, 573, 575, 578, 580, 586, 591, 619, 620, 621, 622, 624, 625, 626, 631, 634, 636, 637, 638, 640, 641], "goal": [2, 17, 23, 78, 79, 80, 81, 82, 83, 84, 85, 138, 179, 264, 619, 620, 621, 622, 631, 635, 636], "policy_devic": [2, 32, 34, 35, 36, 38, 42, 44, 47, 50, 620], "explicitli": [2, 22, 23, 59, 69, 89, 92, 93, 100, 217, 341, 404, 612, 620, 622, 627, 634, 635, 638], "do": [2, 5, 6, 17, 21, 22, 23, 26, 63, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 177, 178, 179, 180, 193, 195, 196, 212, 214, 226, 251, 265, 270, 278, 279, 284, 302, 304, 344, 365, 375, 377, 379, 383, 385, 392, 585, 586, 591, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 633, 634, 635, 636, 638, 640, 641], "deepcopi": [2, 365, 375, 377, 379, 383, 634], "structur": [2, 6, 7, 12, 16, 17, 22, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 63, 65, 68, 72, 73, 74, 86, 87, 96, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 185, 195, 196, 202, 213, 229, 232, 265, 312, 325, 326, 327, 328, 330, 331, 332, 337, 348, 357, 367, 370, 376, 378, 380, 381, 384, 385, 386, 387, 388, 389, 423, 591, 598, 605, 612, 619, 621, 622, 624, 627, 634, 635, 636, 637], "place": [2, 7, 21, 22, 40, 60, 69, 71, 86, 87, 88, 95, 97, 106, 108, 116, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 217, 225, 233, 250, 265, 271, 272, 275, 277, 278, 279, 325, 326, 327, 328, 329, 330, 331, 332, 337, 340, 343, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 411, 418, 552, 565, 567, 568, 570, 571, 573, 574, 575, 577, 578, 580, 582, 584, 586, 591, 620, 621, 625, 628, 634, 635, 636, 638], "instanti": [2, 6, 7, 17, 22, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 101, 102, 134, 137, 176, 180, 217, 225, 239, 265, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 385, 386, 387, 388, 389, 390, 401, 402, 419, 463, 464, 467, 468, 469, 612, 619, 620, 625, 626, 628, 634, 635, 636, 638, 641], "graph": [2, 21, 23, 27, 86, 87, 121, 122, 136, 137, 176, 189, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 383, 384, 619, 623, 636], "reli": [2, 6, 17, 30, 56, 265, 302, 304, 335, 336, 348, 367, 385, 417, 619, 621, 623, 625, 627, 636, 641], "third": [2, 246, 267, 298, 634, 635], "parti": 2, "try": [2, 23, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 60, 71, 86, 87, 176, 325, 326, 327, 328, 330, 331, 332, 337, 376, 378, 380, 381, 384, 591, 619, 620, 621, 623, 626, 627, 632, 634, 635, 636, 640, 641], "limit": [2, 5, 7, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 189, 195, 196, 221, 241, 348, 350, 364, 365, 367, 369, 375, 377, 379, 383, 591, 612, 619, 620, 622, 634, 635, 636], "chart": 2, "show": [2, 7, 30, 35, 36, 38, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 324, 326, 332, 337, 375, 377, 379, 382, 383, 392, 419, 420, 472, 619, 621, 622, 623, 631, 634, 635, 636, 638, 640], "decis": [2, 18, 19, 289, 294, 311, 354, 366, 622, 624, 625, 634, 635, 638, 641], "tree": [2, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 221, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 634, 638], "These": [3, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 80, 85, 117, 163, 250, 277, 280, 375, 377, 379, 383, 591, 598, 605, 612, 619, 621, 634, 635, 636, 638, 641], "gloo": [3, 42, 44, 47, 51, 565, 571, 572, 573], "nccl": [3, 42, 44, 47, 324, 335, 336, 565, 571, 572, 573, 579, 580, 584, 585, 586], "mpi": [3, 42, 44, 47], "launcher": [3, 42, 44, 47, 51], "submitit": [3, 42, 44, 47, 51], "torch": [3, 6, 10, 17, 18, 19, 21, 22, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 101, 102, 104, 107, 108, 109, 114, 115, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 213, 214, 215, 217, 218, 219, 220, 222, 225, 226, 227, 229, 230, 231, 232, 233, 234, 239, 241, 242, 243, 246, 248, 250, 252, 253, 255, 257, 258, 259, 260, 262, 263, 264, 265, 266, 268, 271, 272, 273, 275, 277, 279, 280, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 319, 320, 321, 322, 324, 325, 326, 327, 328, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 394, 405, 412, 413, 420, 463, 464, 467, 468, 469, 488, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 559, 564, 565, 569, 570, 571, 572, 573, 578, 579, 584, 585, 586, 591, 598, 613, 619, 620, 621, 622, 623, 625, 626, 627, 629, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "multiprocess": [3, 5, 6, 22, 35, 36, 37, 38, 42, 44, 47, 50, 68, 69, 72, 73, 78, 85, 95, 96, 97, 98, 120, 127, 128, 150, 154, 158, 279, 280, 564, 565, 566, 567, 570, 572, 573, 574, 612, 619, 620, 621, 622, 627, 634, 635, 636, 637, 641], "mode": [3, 21, 25, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 123, 126, 130, 135, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 264, 272, 279, 280, 295, 302, 303, 304, 310, 319, 320, 321, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 350, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 404, 409, 522, 591, 605, 612, 619, 620, 634, 635, 640, 641], "find": [3, 23, 25, 26, 42, 44, 47, 65, 108, 109, 183, 286, 312, 402, 408, 412, 584, 619, 620, 623, 625, 626, 631, 634, 635], "folder": [3, 86, 87, 163, 176, 221, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 620], "variou": [3, 10, 15, 19, 21, 22, 37, 123, 271, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 373, 375, 377, 379, 383, 392, 561, 562, 593, 615, 619, 620, 621, 623, 624, 625, 626, 628, 634, 635, 638, 641], "machin": [3, 26, 42, 44, 47, 82, 134, 580, 634, 635, 640], "One": [3, 4, 6, 22, 23, 27, 57, 59, 60, 62, 64, 71, 114, 120, 121, 122, 150, 154, 158, 159, 221, 255, 275, 286, 310, 343, 347, 396, 612, 619, 620, 638, 641], "wonder": 3, "why": [3, 22, 212, 634, 636, 641], "instead": [3, 21, 22, 23, 26, 27, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 52, 53, 54, 57, 59, 66, 83, 86, 87, 88, 101, 102, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 236, 282, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 343, 347, 348, 350, 351, 353, 356, 357, 358, 363, 364, 367, 368, 369, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 389, 563, 622, 623, 624, 625, 629, 636, 638, 641], "gener": [3, 5, 6, 16, 17, 21, 22, 26, 27, 28, 32, 34, 35, 36, 38, 42, 44, 47, 50, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 105, 107, 120, 123, 126, 127, 130, 138, 142, 143, 144, 147, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 213, 215, 218, 225, 227, 229, 230, 234, 239, 241, 244, 246, 252, 253, 258, 259, 263, 265, 269, 271, 273, 278, 280, 287, 295, 302, 304, 306, 310, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 337, 339, 341, 344, 362, 368, 376, 378, 379, 380, 381, 382, 383, 384, 385, 395, 408, 415, 430, 591, 593, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "lower": [3, 15, 22, 50, 58, 101, 102, 224, 279, 280, 315, 316, 347, 367, 621, 634, 636], "io": [3, 30, 78, 83, 136, 137, 145, 148, 149, 161, 162, 202, 623], "footprint": [3, 638], "need": [3, 4, 6, 7, 17, 18, 19, 20, 21, 22, 23, 26, 27, 29, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 65, 68, 69, 72, 73, 74, 86, 87, 88, 110, 114, 120, 123, 126, 130, 134, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 224, 226, 227, 236, 242, 250, 253, 266, 270, 271, 272, 277, 279, 280, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 340, 341, 343, 347, 357, 369, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 389, 392, 401, 415, 563, 572, 574, 586, 591, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 634, 635, 636, 638, 640, 641], "commun": [3, 18, 22, 46, 49, 86, 87, 138, 150, 154, 158, 176, 179, 324, 325, 327, 328, 330, 331, 335, 336, 376, 378, 380, 381, 384, 564, 567, 569, 572, 574, 576, 578, 579, 584, 585, 586, 590, 612, 621, 641], "yet": [3, 6, 121, 122, 136, 330, 331, 382, 637], "spec": [3, 16, 19, 22, 34, 35, 36, 38, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 87, 88, 120, 121, 122, 123, 126, 128, 129, 130, 131, 132, 135, 136, 137, 138, 144, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 209, 212, 213, 214, 215, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 232, 233, 234, 236, 238, 240, 241, 242, 243, 244, 246, 248, 250, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 286, 297, 298, 301, 302, 304, 312, 313, 314, 316, 325, 327, 328, 330, 331, 339, 341, 342, 343, 344, 346, 347, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 382, 591, 598, 619, 620, 621, 622, 623, 624, 625, 629, 631, 633, 634, 635, 640], "plai": [3, 19, 152, 153, 160, 170, 221, 620, 621, 626, 638, 641], "role": [3, 19, 87, 89, 143, 170, 172, 175, 183, 190, 195, 196, 197, 332, 337, 383, 620, 626, 632, 641], "opposit": [3, 634], "direct": [3, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 365, 375, 377, 379, 382, 383, 620, 626, 632], "vector": [3, 16, 21, 27, 57, 64, 121, 122, 131, 136, 137, 141, 152, 153, 155, 163, 164, 231, 278, 280, 290, 292, 305, 385, 388, 589, 619, 620, 622, 633, 634, 635, 636, 637, 641], "share": [3, 6, 7, 15, 19, 21, 25, 27, 32, 34, 35, 36, 38, 50, 52, 56, 68, 69, 72, 73, 74, 86, 87, 90, 93, 95, 96, 97, 98, 102, 104, 108, 110, 112, 116, 127, 150, 158, 171, 172, 175, 176, 185, 192, 193, 194, 195, 262, 270, 279, 280, 283, 284, 285, 302, 304, 325, 327, 328, 330, 331, 348, 349, 350, 351, 352, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 376, 378, 380, 381, 384, 402, 430, 465, 467, 468, 469, 563, 565, 566, 567, 568, 570, 571, 572, 573, 574, 575, 578, 580, 581, 582, 583, 586, 591, 612, 621, 623, 629, 631, 632, 633, 634, 635, 640, 641], "among": [3, 18, 63, 152, 153, 270, 357, 370, 634, 635], "achiev": [3, 4, 21, 23, 88, 120, 123, 126, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 264, 287, 326, 332, 337, 341, 375, 377, 379, 382, 383, 411, 619, 620, 621, 622, 623, 631, 634, 635, 636, 638, 640, 641], "prohibit": [3, 21, 114], "slow": [3, 22, 23, 30, 86, 87, 96, 108, 109, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "compar": [3, 21, 22, 83, 114, 349, 351, 363, 368, 370, 371, 372, 409, 612, 619, 621, 623, 625, 626, 634, 635, 638, 641], "gpu": [3, 26, 27, 53, 55, 88, 95, 97, 116, 120, 123, 126, 130, 131, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 243, 324, 326, 329, 332, 333, 334, 337, 375, 377, 379, 382, 383, 401, 579, 585, 586, 619, 621, 622, 634, 635, 641], "nativ": [3, 6, 16, 26, 28, 81, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 324, 337, 392, 622, 638], "driver": [3, 26], "mean": [3, 5, 6, 7, 17, 19, 21, 22, 23, 26, 32, 34, 35, 36, 38, 39, 42, 44, 47, 50, 52, 72, 74, 78, 86, 87, 96, 101, 102, 108, 109, 114, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 183, 217, 246, 270, 279, 280, 286, 295, 299, 302, 304, 311, 319, 320, 325, 327, 328, 330, 331, 341, 344, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 376, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 408, 419, 565, 566, 567, 570, 571, 573, 575, 576, 578, 580, 586, 619, 620, 621, 623, 625, 634, 635, 636, 638, 641], "keyword": [3, 6, 21, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 93, 95, 96, 97, 98, 101, 102, 106, 108, 109, 112, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 206, 214, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 244, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 286, 287, 297, 301, 302, 304, 306, 312, 313, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 339, 340, 341, 343, 344, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 397, 399, 400, 402, 415, 419, 420, 560, 619, 620, 621, 623, 625, 628, 634, 635, 638, 640, 641], "given": [3, 4, 12, 22, 35, 36, 38, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 109, 120, 123, 126, 130, 138, 144, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 225, 231, 239, 246, 250, 265, 269, 271, 272, 273, 275, 277, 279, 280, 286, 287, 297, 298, 299, 301, 302, 304, 314, 317, 318, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 343, 344, 345, 346, 352, 353, 355, 365, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 402, 406, 409, 559, 619, 620, 621, 624, 625, 626, 627, 628, 635, 636, 641], "mani": [3, 7, 16, 18, 19, 22, 23, 68, 86, 87, 121, 122, 124, 125, 126, 129, 131, 132, 136, 137, 145, 146, 155, 176, 178, 183, 185, 265, 325, 327, 328, 330, 331, 348, 350, 357, 364, 367, 376, 378, 379, 380, 381, 384, 417, 567, 612, 619, 620, 621, 623, 624, 625, 627, 629, 634, 635, 636, 638, 640, 641], "eg": [3, 17, 22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 124, 125, 126, 129, 130, 131, 132, 134, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 231, 263, 272, 282, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 392], "gymnasium": [3, 17, 18, 22, 24, 32, 34, 35, 36, 38, 52, 120, 123, 126, 129, 130, 131, 135, 138, 139, 140, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 175, 178, 179, 180, 211, 234, 259, 263, 278, 282, 445, 620, 621, 623, 636, 640], "warn": [3, 22, 35, 36, 38, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 272, 279, 286, 301, 312, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 404, 620, 631, 632], "quickli": [3, 22, 620, 634, 635, 641], "becom": [3, 22, 23, 50, 401, 402, 612, 634, 635, 641], "quit": [3, 22, 30, 78, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 619, 620, 621, 623, 625, 634, 635, 641], "annoi": [3, 22], "By": [3, 17, 21, 22, 34, 37, 39, 40, 41, 46, 49, 60, 64, 71, 88, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 142, 143, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 244, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 344, 365, 375, 377, 379, 382, 383, 404, 409, 563, 591, 619, 622, 634, 637, 638, 641], "filter": [3, 21, 22, 23, 102, 108, 109, 348, 349, 351, 352, 356, 357, 363, 367, 368, 370, 379, 401, 624], "out": [3, 17, 19, 21, 22, 23, 24, 28, 37, 39, 40, 41, 46, 49, 50, 54, 55, 79, 83, 86, 87, 88, 93, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 262, 265, 286, 297, 298, 306, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 343, 344, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 401, 619, 620, 621, 622, 623, 624, 625, 627, 634, 635, 636, 638, 640, 641], "still": [3, 17, 22, 28, 75, 83, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 270, 272, 312, 326, 332, 337, 364, 365, 375, 377, 379, 383, 591, 619, 620, 622, 633, 636, 638, 641], "wish": [3, 22, 30, 32, 35, 36, 38, 83, 211, 626, 638], "displai": [3, 22, 26, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 415, 619, 620, 631, 635, 636], "filter_warnings_subprocess": [3, 22], "simplest": [4, 114, 326, 332, 337, 347, 375, 377, 379, 383, 619, 621, 625, 634, 635, 638, 641], "transit": [4, 35, 36, 38, 79, 83, 88, 102, 109, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 317, 323, 326, 332, 337, 375, 377, 379, 382, 383, 619, 622, 624, 625, 627, 634, 636, 638], "sampl": [4, 5, 7, 10, 15, 23, 27, 28, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 95, 96, 97, 101, 102, 103, 106, 107, 108, 109, 112, 114, 116, 120, 123, 126, 130, 138, 144, 147, 150, 151, 154, 158, 159, 160, 167, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 210, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 280, 286, 295, 297, 298, 301, 303, 306, 310, 311, 312, 313, 314, 315, 317, 320, 321, 326, 329, 332, 337, 339, 341, 343, 344, 348, 349, 350, 351, 352, 353, 355, 364, 366, 367, 371, 372, 375, 379, 382, 405, 411, 415, 417, 420, 428, 429, 432, 433, 434, 474, 552, 589, 619, 620, 621, 622, 623, 624, 625, 627, 629, 634, 635, 637, 640, 641], "attent": [4, 27, 178, 221, 326, 332, 337, 379, 619, 622, 632, 641], "built": [4, 7, 10, 16, 17, 21, 24, 26, 69, 86, 87, 121, 122, 129, 136, 137, 147, 148, 176, 317, 325, 327, 328, 330, 331, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 383, 384, 557, 559, 560, 563, 591, 598, 612, 619, 620, 621, 622, 623, 626, 628, 631, 636, 638, 641], "flatten": [4, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 114, 176, 218, 236, 325, 327, 328, 330, 331, 338, 376, 378, 380, 381, 382, 384, 385, 411, 581, 582, 591, 635], "suffici": [4, 18, 23, 619], "preprocess": [4, 10, 16, 78, 79, 80, 81, 82, 83, 84, 85, 271, 620, 623], "popul": [4, 17, 34, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 178, 240, 265, 295, 365, 375, 377, 379, 383, 619, 621, 622, 625, 627, 636, 638], "replaybuff": [4, 10, 12, 21, 32, 34, 35, 36, 38, 50, 52, 53, 65, 66, 67, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 95, 96, 101, 102, 103, 108, 109, 118, 221, 251, 255, 353, 358, 401, 419, 420, 430, 557, 559, 621, 623, 627, 629, 634, 635, 637, 638, 640], "lazytensorstorag": [4, 10, 12, 32, 34, 35, 36, 38, 52, 65, 68, 72, 73, 101, 108, 109, 114, 255, 420, 426, 621, 623, 629, 634, 635, 638], "lambda": [4, 6, 32, 34, 35, 36, 38, 50, 51, 52, 53, 68, 114, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 183, 211, 218, 226, 227, 239, 241, 265, 273, 280, 282, 287, 297, 313, 326, 332, 337, 340, 341, 359, 361, 362, 371, 375, 377, 379, 383, 385, 388, 390, 418, 419, 559, 567, 584, 591, 619, 620, 622, 623, 634, 635, 637, 638, 640, 641], "reshap": [4, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 108, 114, 218, 302, 304, 305, 390, 591, 621, 634, 635], "extend": [4, 7, 10, 27, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 94, 95, 98, 101, 102, 104, 108, 109, 112, 114, 115, 118, 119, 170, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 220, 255, 271, 365, 375, 377, 379, 382, 383, 411, 419, 584, 585, 591, 593, 601, 619, 620, 621, 623, 627, 629, 634, 635, 637, 638, 640], "slice": [4, 10, 17, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 83, 102, 108, 109, 214, 220, 221, 325, 433, 434, 622, 638], "recommend": [4, 5, 23, 26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 68, 72, 73, 86, 87, 108, 114, 134, 170, 171, 172, 175, 176, 189, 221, 324, 325, 327, 328, 330, 331, 332, 335, 336, 337, 350, 367, 376, 377, 378, 379, 380, 381, 384, 591, 612, 627, 632, 634, 635], "multidimension": [4, 72, 101, 102, 638], "slicesampl": [4, 10, 78, 102, 109, 221, 433, 622, 638], "sampler": [4, 7, 10, 13, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 95, 96, 97, 98, 101, 102, 103, 106, 107, 108, 109, 110, 112, 114, 116, 221, 251, 353, 358, 430, 437, 619, 621, 622, 634, 635, 638], "ensur": [4, 7, 17, 21, 33, 42, 43, 44, 45, 46, 47, 48, 49, 65, 72, 88, 101, 102, 107, 120, 123, 126, 130, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 221, 250, 263, 272, 275, 279, 280, 297, 302, 304, 324, 326, 332, 337, 350, 364, 367, 375, 377, 379, 382, 383, 401, 565, 567, 568, 570, 571, 573, 578, 579, 580, 584, 586, 587, 591, 595, 612, 620, 621, 622, 636, 638], "clearli": 4, "dimension": [4, 65, 68, 72, 73, 178, 231, 302, 304, 385, 635], "num_slic": [4, 78, 83, 102, 108, 109, 433, 434, 638], "trajectory_kei": [4, 56, 108, 109], "traj_id": [4, 17, 34, 35, 38, 52, 56, 218, 255, 627, 638], "dim": [4, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 108, 176, 190, 205, 221, 222, 244, 248, 261, 262, 265, 274, 279, 325, 327, 328, 330, 331, 340, 376, 378, 380, 381, 384, 480, 481, 502, 506, 519, 520, 524, 531, 563, 591, 620, 621, 623, 634, 636, 638], "ndim": [4, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 95, 97, 101, 102, 114, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 244, 340, 424, 426, 438], "regular": [4, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 86, 87, 88, 101, 106, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 296, 298, 302, 304, 313, 314, 325, 327, 328, 329, 330, 331, 343, 344, 358, 367, 376, 378, 380, 381, 382, 383, 384, 418, 419, 420, 619, 620, 623, 624, 625, 629, 631, 638, 641], "behav": [4, 22, 132, 144, 310, 356, 363, 365, 375, 377, 379, 383, 623, 637], "accordingli": [4, 22, 86, 87, 102, 174, 176, 227, 244, 263, 264, 313, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 622], "3": [4, 18, 19, 20, 22, 25, 26, 29, 30, 32, 34, 35, 36, 38, 50, 52, 53, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 97, 101, 102, 108, 109, 114, 116, 120, 123, 124, 125, 126, 129, 130, 131, 132, 133, 138, 141, 142, 143, 145, 147, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 206, 215, 217, 218, 221, 225, 226, 227, 231, 233, 234, 239, 241, 246, 248, 250, 252, 253, 255, 258, 259, 262, 263, 264, 265, 268, 270, 271, 272, 273, 275, 277, 280, 282, 283, 284, 285, 287, 288, 290, 291, 292, 294, 297, 298, 300, 302, 304, 305, 306, 307, 310, 314, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 338, 339, 341, 342, 343, 346, 347, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 360, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 392, 401, 413, 463, 480, 503, 565, 566, 567, 569, 570, 571, 572, 573, 575, 578, 580, 586, 598, 612, 618, 619, 620, 621, 622, 624, 625, 627, 628, 634, 635, 636, 638, 639, 640, 641], "isn": [4, 22, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 83, 86, 87, 101, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 217, 233, 239, 297, 325, 327, 328, 330, 331, 343, 376, 378, 380, 381, 384, 385, 625, 626, 628, 634, 635], "fulli": [4, 6, 27, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 620, 623, 626, 636, 638], "ani": [4, 6, 7, 12, 17, 18, 19, 21, 22, 24, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 94, 95, 96, 97, 98, 104, 107, 109, 110, 112, 114, 115, 116, 118, 119, 120, 123, 126, 127, 130, 131, 138, 145, 150, 151, 152, 153, 154, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 213, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 236, 237, 239, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 280, 282, 287, 288, 294, 295, 305, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 343, 344, 345, 346, 348, 349, 350, 351, 352, 353, 355, 356, 357, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 390, 392, 397, 401, 402, 408, 415, 417, 418, 419, 424, 426, 430, 433, 434, 435, 436, 437, 438, 439, 441, 445, 449, 463, 464, 465, 467, 468, 469, 471, 472, 477, 484, 485, 486, 523, 530, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 583, 584, 585, 586, 590, 612, 619, 620, 621, 622, 623, 625, 626, 631, 634, 635, 636, 638, 640, 641], "consecut": [4, 17, 78, 107, 134, 304, 312, 392, 622, 624, 627, 635, 638, 641], "won": [4, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 83, 86, 87, 88, 120, 123, 126, 127, 129, 130, 138, 145, 146, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 277, 325, 326, 327, 328, 330, 331, 332, 337, 348, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 415, 563, 620, 621, 624, 625], "therebi": [4, 390, 619, 620], "interrupt": [4, 130, 180, 340, 401, 402], "asyncdatacollector": 5, "asynccollector": 5, "_multidatacollector": 5, "It": [5, 7, 17, 20, 21, 22, 23, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 96, 106, 114, 119, 120, 123, 126, 130, 132, 138, 144, 145, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 212, 215, 218, 220, 221, 233, 239, 241, 246, 251, 264, 270, 272, 278, 280, 286, 290, 292, 298, 299, 301, 312, 314, 315, 316, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 344, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 400, 401, 408, 409, 419, 465, 567, 568, 570, 571, 573, 578, 580, 586, 589, 590, 591, 593, 619, 620, 622, 623, 624, 634, 635, 636, 637, 638, 640, 641], "cartpol": [5, 6, 7, 18, 20, 22, 30, 35, 36, 38, 120, 123, 124, 125, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 218, 221, 226, 258, 264, 279, 340, 390, 567, 620, 622, 625, 627, 628, 629, 638, 641], "sync_collector": [5, 35, 36, 38], "1000": [5, 23, 34, 35, 36, 38, 52, 68, 90, 95, 96, 101, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 279, 286, 301, 312, 341, 344, 420, 527, 567, 619, 620, 621, 622, 623, 625, 627, 629, 632, 636, 637, 638], "100000": [5, 7, 35, 36, 38, 420, 620], "async_collector": [5, 35, 36, 38], "comparison": [5, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 326, 332, 337, 365, 375, 377, 379, 382, 383, 619, 620], "older": [5, 26, 282], "throughput": [5, 28, 137, 324, 333, 337, 619], "slowest": 5, "higher": [5, 22, 23, 101, 102, 177, 188, 196, 224, 324, 326, 332, 337, 347, 377, 379, 383, 619, 620, 621, 634, 638, 641], "allow": [5, 6, 7, 12, 16, 17, 18, 20, 21, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 63, 64, 68, 69, 70, 71, 72, 73, 78, 83, 86, 87, 88, 89, 96, 102, 106, 108, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 212, 217, 218, 253, 280, 305, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 567, 591, 612, 619, 621, 622, 623, 624, 625, 626, 632, 634, 635, 636, 638, 640, 641], "start": [5, 6, 20, 21, 22, 23, 24, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 66, 74, 78, 85, 101, 102, 108, 109, 120, 123, 126, 127, 130, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 214, 228, 318, 373, 410, 565, 567, 568, 569, 570, 571, 572, 573, 575, 576, 578, 579, 580, 584, 586, 589, 618, 619, 620, 622, 623, 630, 635, 636, 638, 639, 641], "get": [5, 6, 18, 19, 21, 22, 23, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 60, 65, 68, 71, 78, 79, 83, 86, 87, 88, 95, 97, 102, 108, 109, 110, 112, 114, 116, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 188, 190, 194, 195, 196, 201, 215, 220, 222, 226, 229, 231, 232, 241, 246, 251, 264, 265, 268, 272, 279, 280, 301, 313, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 339, 341, 344, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 392, 396, 401, 402, 403, 565, 567, 568, 570, 571, 573, 574, 575, 578, 580, 584, 586, 589, 591, 605, 618, 619, 620, 621, 622, 623, 630, 632, 634, 635, 636, 638, 639, 640, 641], "rid": [5, 326, 332, 337, 375, 377, 379, 383], "natur": [5, 18, 33, 42, 43, 44, 45, 47, 48, 170, 186, 619, 625, 626, 627, 638], "background": [5, 32, 33, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 53, 190, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586, 638], "simpli": [5, 6, 7, 20, 22, 25, 86, 87, 112, 114, 119, 176, 182, 234, 259, 278, 325, 327, 328, 330, 331, 365, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 619, 621, 626, 631, 634, 635, 641], "replay_buff": [5, 7, 27, 32, 34, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 221, 411, 418, 419, 420, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 472, 559, 619, 620, 621, 622, 627, 634, 635, 638], "rb": [5, 32, 34, 35, 36, 38, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 96, 101, 102, 108, 109, 114, 221, 255, 620, 622, 623, 627, 629, 635, 637, 638, 640], "paus": [5, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "sleep": [5, 32, 34, 35, 36, 38, 52, 66, 127, 641], "10": [5, 6, 18, 20, 26, 51, 56, 57, 59, 61, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 101, 108, 109, 114, 116, 120, 121, 122, 123, 126, 127, 130, 136, 137, 138, 144, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 183, 185, 188, 190, 192, 193, 197, 214, 215, 218, 220, 221, 226, 227, 264, 266, 267, 268, 279, 280, 287, 289, 290, 292, 294, 296, 301, 302, 304, 306, 311, 312, 325, 327, 328, 330, 331, 341, 344, 347, 349, 353, 355, 362, 367, 368, 369, 372, 376, 377, 378, 379, 380, 381, 384, 385, 386, 387, 388, 392, 401, 405, 464, 467, 468, 469, 474, 479, 522, 540, 566, 574, 612, 613, 619, 620, 621, 622, 623, 624, 625, 629, 634, 636, 638, 640, 641], "rang": [5, 6, 17, 19, 23, 27, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 97, 114, 120, 123, 126, 127, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 185, 255, 268, 279, 282, 325, 327, 328, 330, 331, 364, 371, 372, 376, 378, 380, 381, 384, 619, 621, 622, 623, 626, 627, 629, 634, 635, 636, 638, 640], "optim_step": [5, 623, 629], "rest": [5, 7, 32, 35, 36, 38, 621, 622, 634, 636, 640], "multithread": [5, 22, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 145, 146, 627, 638], "mind": [5, 21, 22, 78, 83, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 634, 635], "gil": 5, "relat": [5, 19, 22, 23, 29, 60, 65, 150, 175, 236, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 620, 629, 636], "restrict": [5, 22, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 620, 631, 637, 638, 641], "hand": [5, 19, 26, 50, 60, 634, 635, 636], "let": [5, 6, 7, 19, 25, 26, 30, 56, 65, 68, 72, 73, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 297, 326, 332, 337, 375, 377, 379, 382, 383, 409, 591, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "child": [5, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 620], "fill": [5, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 130, 180, 217, 265, 278, 304, 385, 622, 636, 637], "truli": [5, 278, 401, 640], "decoupl": [5, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 52, 619, 626, 640], "been": [5, 18, 24, 26, 27, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 107, 120, 123, 126, 130, 134, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 241, 243, 263, 264, 271, 272, 302, 304, 340, 348, 365, 367, 369, 375, 377, 379, 383, 401, 564, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586, 619, 620, 621, 622, 633, 634, 635, 636, 638, 640, 641], "shut": [5, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 154, 159, 401], "down": [5, 23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 154, 159, 401, 622, 624], "async_shutdown": [5, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 66], "drastic": [5, 6, 137, 150, 638], "hardwar": [5, 17, 623], "load": [5, 6, 25, 26, 32, 34, 35, 36, 38, 52, 53, 54, 55, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 95, 96, 97, 98, 110, 111, 112, 116, 117, 120, 123, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 279, 280, 324, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 415, 417, 419, 420, 563, 582, 591, 594, 619, 621, 623, 631, 632, 638], "factor": [5, 27, 30, 255, 286, 301, 303, 312, 320, 321, 349, 355, 358, 359, 361, 419, 619, 620, 623, 625, 629, 634, 635, 638, 641], "signific": [5, 21, 24, 27, 612, 621, 640, 641], "understand": [5, 6, 19, 27, 33, 42, 43, 44, 45, 47, 48, 612, 619, 620, 623, 624, 625, 631, 634, 635], "affect": [5, 22, 27, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 272, 280, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 401, 634], "legitim": [5, 641], "unless": [5, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 86, 87, 88, 92, 107, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 280, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 351, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 621], "benchmark": [5, 18, 22, 28, 121, 122, 130, 136, 137, 180], "pipelin": [6, 19, 26, 130, 180, 333, 375, 591, 595, 621], "typic": [6, 17, 22, 23, 27, 33, 34, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 81, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 233, 264, 326, 332, 337, 341, 349, 351, 365, 367, 370, 375, 377, 379, 382, 383, 419, 572, 579, 586, 591, 621, 623, 624, 626, 627, 632, 634, 635, 636], "big": [6, 621, 627, 638, 641], "bucket": [6, 171], "send": [6, 22, 27, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 86, 87, 154, 159, 176, 324, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 400, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 580, 583, 585, 586, 640], "occasion": 6, "tradit": [6, 626, 634], "neural": [6, 7, 141, 152, 153, 288, 343, 385, 598, 620, 621, 622, 625, 634, 635, 636, 641], "both": [6, 7, 18, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 54, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 127, 129, 130, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 161, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 214, 221, 239, 253, 269, 270, 272, 283, 284, 285, 288, 298, 302, 304, 305, 314, 324, 326, 332, 334, 337, 348, 350, 351, 352, 356, 357, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 401, 402, 408, 409, 418, 472, 569, 572, 574, 577, 578, 584, 585, 586, 591, 612, 619, 621, 623, 624, 626, 631, 632, 634, 635, 636, 637, 638, 641], "anyth": [6, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50], "happen": [6, 7, 18, 21, 22, 46, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 282, 312, 417, 566, 572, 620, 623, 626, 627, 628, 637, 641], "held": 6, "datacollector": [6, 32, 34, 35, 36, 38, 50, 52, 53, 367, 621, 627, 638], "receiv": [6, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 271, 272, 280, 305, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 584, 586, 619, 621, 626, 633, 636], "postprocess": [6, 34], "hook": [6, 37, 39, 40, 41, 46, 49, 54, 55, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 117, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 347, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 472, 589, 613], "itself": [6, 21, 34, 42, 47, 50, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 325, 326, 327, 328, 330, 331, 332, 337, 365, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 621, 624], "transfer": [6, 55, 86, 87, 176, 325, 327, 328, 330, 331, 344, 376, 378, 380, 381, 384, 569, 572, 579, 580, 584, 585], "think": [6, 21, 87, 170, 172, 174, 175, 177, 183, 590, 591, 621, 634, 635, 641], "world": [6, 19, 24, 144, 323, 324, 333, 360, 401, 589, 598, 612, 623, 628, 634, 635, 636, 641], "engin": [6, 26, 54, 55, 155, 324, 333, 334, 337, 382, 579, 580, 582, 584, 585, 586, 591, 631, 636], "veri": [6, 12, 15, 18, 19, 22, 86, 87, 136, 137, 175, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 620, 624, 627, 631, 634, 636, 638, 640, 641], "kernel": [6, 288], "forward": [6, 16, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 240, 241, 243, 246, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 317, 322, 324, 326, 332, 337, 338, 340, 341, 343, 344, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 622, 636, 640], "format": [6, 20, 62, 64, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 92, 93, 100, 106, 114, 120, 123, 126, 130, 138, 150, 151, 152, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 203, 221, 225, 250, 265, 271, 272, 275, 277, 326, 330, 332, 337, 343, 375, 377, 379, 382, 383, 392, 577, 587, 591, 593, 594, 595, 605, 619, 620, 623, 624, 626, 628, 631, 640, 641], "quantiz": 6, "much": [6, 22, 27, 32, 35, 36, 38, 65, 72, 83, 86, 87, 101, 102, 150, 158, 176, 325, 327, 328, 330, 331, 364, 367, 376, 378, 380, 381, 384, 621, 623, 624, 628, 634, 635, 636, 638, 641], "cannot": [6, 18, 22, 23, 26, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 60, 62, 64, 68, 72, 73, 90, 97, 98, 102, 104, 108, 109, 116, 120, 123, 126, 129, 130, 131, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 229, 232, 251, 258, 270, 313, 348, 351, 367, 620, 621, 622, 623, 634, 635, 636], "dump": [6, 20, 30, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 93, 95, 96, 97, 98, 110, 112, 116, 176, 190, 194, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 390, 391, 392, 628, 629, 634], "dict": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 102, 108, 109, 120, 123, 126, 127, 128, 129, 130, 131, 138, 142, 143, 145, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 239, 241, 265, 270, 272, 278, 279, 280, 282, 288, 289, 290, 291, 292, 293, 294, 300, 305, 311, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 351, 370, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 396, 397, 401, 402, 403, 409, 415, 417, 418, 419, 420, 439, 463, 464, 472, 511, 554, 555, 561, 562, 563, 565, 567, 568, 570, 571, 573, 574, 575, 577, 578, 579, 580, 581, 584, 585, 586, 587, 612, 619, 620, 621, 638, 640, 641], "who": 6, "activ": [6, 25, 26, 28, 288, 294, 299, 305, 350, 364, 367, 636, 640], "ask": [6, 22, 27, 78, 83, 102, 108, 109, 332, 392, 621, 622, 624, 625, 634, 635, 637, 641], "push": [6, 55, 383, 584], "intermedi": [6, 23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 220, 287, 298, 302, 304, 317, 326, 332, 337, 375, 377, 379, 383, 619, 623, 637], "approach": [6, 21, 34, 65, 68, 72, 73, 86, 87, 176, 189, 221, 246, 325, 327, 328, 330, 331, 335, 336, 337, 371, 376, 378, 380, 381, 384, 420, 566, 567, 580, 591, 619, 621, 626, 627, 634, 641], "intermediari": 6, "server": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 190], "fetch": [6, 40, 86, 87, 121, 122, 124, 125, 176, 241, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 584, 625, 637, 638], "tri": [6, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 324, 326, 332, 337, 343, 375, 377, 379, 382, 383, 628], "account": [6, 95, 97, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 227, 306, 620, 622, 638, 641], "problem": [6, 18, 26, 27, 28, 34, 175, 379, 620, 621, 622, 627, 634, 635, 636, 638, 641], "manner": [6, 130, 180, 250, 275, 619, 620, 621, 627, 633, 636, 638], "identifi": [6, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 195, 196, 401, 402, 565, 567, 568, 570, 571, 572, 573, 575, 578, 580, 581, 586, 593, 612, 631], "three": [6, 57, 59, 61, 62, 64, 170, 351, 591, 621, 623, 624, 625, 634, 635, 636, 638, 641], "orchestr": [6, 591, 594, 620, 626, 628], "entir": [6, 23, 34, 35, 36, 38, 50, 60, 83, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 280, 568, 591, 621, 624, 636, 638], "includ": [6, 7, 12, 16, 19, 21, 23, 26, 28, 50, 63, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 95, 96, 97, 98, 100, 110, 112, 116, 120, 123, 126, 130, 138, 144, 148, 149, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 236, 239, 264, 270, 272, 279, 280, 302, 304, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 348, 351, 365, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 401, 402, 408, 419, 472, 552, 591, 593, 597, 603, 619, 620, 621, 622, 623, 631, 632, 634, 635, 636, 638, 641], "coordin": [6, 35, 36, 38, 50, 95, 97, 228, 564, 565, 572, 579, 580, 582, 584, 585, 612], "actual": [6, 17, 18, 21, 23, 26, 35, 36, 37, 38, 39, 40, 41, 46, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 278, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 552, 566, 567, 569, 572, 584, 587, 591, 619, 621, 623, 634, 635, 636], "through": [6, 12, 17, 18, 21, 22, 23, 24, 27, 32, 34, 35, 36, 38, 41, 42, 47, 50, 52, 53, 55, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 120, 121, 122, 123, 126, 129, 130, 131, 134, 136, 137, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 184, 185, 190, 217, 227, 229, 232, 251, 282, 287, 305, 324, 325, 327, 328, 330, 331, 337, 340, 341, 344, 345, 346, 365, 376, 378, 380, 381, 384, 385, 386, 387, 388, 404, 566, 567, 574, 579, 612, 619, 620, 621, 622, 624, 626, 633, 634, 635, 636, 637, 638, 641], "queue": [6, 52, 154, 279, 326, 332, 337, 382, 566, 567, 574, 612, 638, 640], "determin": [6, 22, 35, 36, 38, 39, 65, 72, 79, 86, 87, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 174, 175, 176, 178, 179, 180, 183, 186, 250, 277, 312, 325, 326, 327, 328, 330, 331, 332, 337, 351, 376, 378, 379, 380, 381, 384, 578, 620, 625, 634, 635], "state_dict": [6, 32, 34, 35, 36, 38, 50, 52, 53, 54, 55, 86, 87, 88, 90, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 417, 563, 567, 568, 570, 571, 573, 577, 578, 580, 586, 587, 619, 620, 641], "extract": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 60, 71, 80, 102, 170, 184, 186, 190, 193, 197, 199, 217, 239, 269, 273, 565, 566, 567, 568, 570, 571, 573, 575, 577, 578, 580, 583, 585, 586, 587, 591, 619, 621, 640], "appli": [6, 7, 10, 21, 22, 23, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 231, 233, 234, 235, 236, 237, 240, 241, 242, 243, 245, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 297, 320, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 408, 410, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 580, 582, 584, 586, 591, 619, 620, 621, 627, 631, 634, 636, 640, 641], "automat": [6, 7, 18, 19, 20, 22, 24, 31, 35, 36, 38, 41, 55, 58, 69, 74, 75, 85, 86, 87, 89, 95, 97, 109, 116, 120, 121, 122, 123, 126, 129, 130, 131, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 174, 175, 176, 178, 179, 180, 191, 217, 229, 232, 246, 265, 278, 280, 302, 304, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 339, 340, 341, 344, 376, 378, 380, 381, 384, 390, 404, 408, 415, 419, 472, 565, 567, 570, 571, 573, 574, 575, 577, 578, 580, 584, 586, 593, 598, 612, 619, 621, 622, 624, 625, 634, 635, 636, 638, 640], "weight_sync_schem": [6, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 418, 419, 472, 564, 565, 567, 568, 569, 570, 571, 572, 573, 575, 576, 578, 580, 586, 591], "intern": [6, 20, 22, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 280, 324, 326, 332, 337, 401, 567, 568, 575, 578, 579, 584, 617], "propag": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 71, 348, 350, 351, 352, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 385, 386, 387, 388, 621, 622, 634, 635], "convent": [6, 22, 78, 79, 80, 81, 82, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 326, 605, 619, 622, 634, 635, 636], "regist": [6, 7, 20, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 209, 212, 229, 232, 233, 258, 270, 272, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 347, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 392, 401, 402, 403, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 565, 567, 570, 571, 573, 575, 578, 580, 583, 585, 586, 591, 612, 613, 619, 621, 624, 638], "posit": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 102, 120, 123, 124, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 226, 236, 237, 239, 261, 262, 263, 266, 270, 272, 274, 307, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383, 401, 402, 621, 634, 635, 636, 638], "policy_modul": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 621, 634, 635], "weights_tensordict": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "clariti": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 272], "actor_modul": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 640], "weights_td": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "model_id": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 565, 566, 567, 568, 570, 571, 572, 573, 575, 578, 579, 580, 581, 586], "actor": [6, 21, 23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 66, 171, 172, 175, 185, 189, 192, 193, 194, 195, 241, 243, 283, 284, 285, 289, 290, 292, 297, 298, 299, 301, 311, 312, 313, 314, 324, 329, 334, 337, 340, 341, 342, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375, 377, 379, 383, 401, 402, 403, 420, 471, 472, 571, 572, 573, 585, 586, 589, 598, 605, 612, 620, 622, 624, 626, 629, 634, 637, 640], "atom": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "weights_dict": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "actor_td": 6, "critic": [6, 23, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 177, 283, 348, 350, 351, 352, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 379, 420, 471, 472, 569, 589, 598, 605, 612, 619, 626], "critic_td": 6, "primarili": [6, 74, 251, 625], "special": [6, 7, 18, 60, 71, 76, 77, 86, 87, 176, 180, 325, 326, 327, 328, 330, 331, 332, 337, 376, 378, 380, 381, 384, 591, 592, 596, 609, 612, 619, 622, 623, 641], "outsid": [6, 22, 34, 230, 270, 628, 634, 635, 636], "pattern": [6, 89, 190, 197, 564, 565, 567, 569, 570, 572, 573, 574, 579, 589, 591], "clear": [6, 20, 30, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 80, 88, 120, 121, 122, 123, 126, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 401, 406, 612, 624, 627, 632], "local": [6, 23, 26, 29, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 67, 81, 86, 88, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 280, 326, 332, 334, 337, 375, 377, 379, 382, 383, 397, 400, 580, 581, 612, 623, 628, 629, 634, 635], "inter": [6, 22, 150, 154], "base": [6, 10, 12, 16, 19, 21, 22, 23, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 83, 86, 87, 101, 102, 105, 111, 114, 115, 117, 118, 120, 121, 122, 123, 126, 130, 134, 136, 137, 138, 144, 145, 146, 150, 151, 154, 158, 159, 160, 163, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 185, 188, 189, 191, 194, 195, 199, 204, 205, 212, 218, 225, 226, 230, 255, 269, 271, 272, 273, 275, 276, 280, 283, 302, 304, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 351, 352, 353, 355, 356, 357, 359, 363, 367, 368, 369, 370, 371, 372, 376, 378, 380, 381, 384, 385, 386, 387, 388, 389, 400, 401, 402, 415, 419, 423, 427, 437, 438, 440, 444, 473, 529, 564, 565, 566, 567, 568, 570, 571, 573, 574, 575, 577, 578, 580, 581, 582, 584, 586, 589, 598, 605, 607, 612, 619, 620, 622, 624, 625, 626, 628, 631, 632, 634, 635, 636, 638, 641], "tcpstore": [6, 564, 565], "small": [6, 101, 102, 109, 275, 280, 619, 621, 623, 634, 635, 641], "logic": [6, 21, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 89, 568, 570, 571, 573, 578, 580, 586, 634], "sender": [6, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 579, 580, 581, 583, 586, 591], "trigger": [6, 26, 178, 280, 326, 332, 337, 375, 377, 379, 383, 565, 567, 570, 571, 573, 575, 578, 580, 586, 622], "_receive_weights_schem": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "side": [6, 18, 23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 188, 189, 195, 196, 202, 306, 326, 565, 567, 568, 570, 571, 572, 573, 575, 576, 578, 579, 580, 586, 641], "init_on_send": [6, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586], "context": [6, 17, 19, 21, 24, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 109, 120, 123, 126, 127, 130, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 265, 274, 302, 304, 326, 332, 337, 375, 377, 379, 382, 383, 385, 386, 387, 388, 392, 404, 409, 565, 566, 567, 568, 570, 571, 573, 574, 575, 578, 580, 586, 591, 612, 619, 620, 621, 622, 623, 634, 635, 636, 637, 638, 640], "NO": 6, "pickl": [6, 32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 68, 69, 72, 73, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 375, 377, 379, 382, 383], "init": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 66, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 271, 279, 324, 326, 329, 332, 337, 375, 377, 379, 382, 383, 385, 399, 400, 401, 403, 579, 584, 586, 612, 620, 621], "block": [6, 53, 55, 89, 94, 119, 135, 175, 177, 186, 193, 203, 324, 564, 565, 566, 567, 569, 570, 571, 572, 573, 575, 576, 578, 580, 586, 591, 619, 622, 623, 626, 627, 634, 638], "readi": [6, 42, 47, 50, 52, 53, 170, 324, 565, 567, 568, 570, 571, 573, 575, 578, 580, 581, 584, 586, 590, 620, 621, 623, 625, 628, 638, 640], "init_on_receiv": [6, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586], "resolv": [6, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 418], "handler": 6, "prepar": [6, 25, 80, 170, 173, 195, 196, 383, 565, 567, 568, 570, 571, 573, 575, 578, 580, 585, 586, 591, 621], "without": [6, 17, 18, 19, 22, 26, 28, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 83, 86, 87, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 217, 229, 232, 268, 271, 284, 285, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 401, 432, 434, 559, 564, 566, 567, 572, 574, 575, 590, 612, 619, 620, 621, 623, 624, 625, 626, 627, 631, 632, 634, 635, 636, 638, 641], "attribut": [6, 17, 19, 21, 22, 23, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 129, 130, 131, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 233, 244, 250, 272, 275, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 344, 348, 349, 351, 352, 353, 355, 357, 358, 359, 362, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 580, 619, 622, 636], "refer": [6, 7, 17, 18, 21, 26, 27, 28, 30, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 123, 126, 129, 130, 131, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 270, 271, 272, 279, 285, 298, 299, 306, 308, 309, 315, 316, 317, 325, 326, 327, 328, 330, 331, 332, 337, 348, 351, 358, 359, 360, 361, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 565, 566, 567, 568, 570, 571, 573, 574, 578, 579, 580, 586, 618, 619, 621, 623, 625, 626, 627, 628, 634, 635, 638], "indic": [6, 12, 17, 18, 20, 22, 27, 32, 34, 35, 36, 38, 39, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 94, 101, 102, 104, 106, 107, 108, 109, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 213, 214, 221, 222, 226, 263, 264, 265, 266, 272, 280, 282, 288, 305, 306, 312, 313, 314, 325, 327, 328, 330, 331, 340, 348, 349, 350, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 553, 563, 590, 612, 621, 622, 623, 627, 628, 629, 636, 638, 641], "primit": [6, 21, 23, 83, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 565, 569], "NOT": [6, 22, 35, 36, 38, 92, 93, 100, 109, 251, 586], "sent": [6, 35, 36, 38, 65, 68, 69, 72, 73, 86, 87, 90, 95, 97, 116, 176, 279, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 565, 566, 567, 569, 570, 571, 573, 574, 575, 576, 578, 580, 586], "explicit": [6, 23, 34, 35, 36, 38, 171, 172, 175, 185, 194, 195, 282, 329, 401, 574, 575, 612, 638], "param": [6, 27, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 273, 280, 295, 319, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 346, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 579, 584, 585, 619, 623, 629, 634, 635, 636, 637, 640], "num_work": [6, 7, 35, 36, 38, 46, 49, 78, 79, 80, 81, 82, 83, 84, 85, 145, 150, 158, 194, 439, 578, 619, 620], "inner_collector": 6, "worker_idx": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 580, 586], "simultan": [6, 22, 47, 137, 145, 146, 150, 158, 567, 579, 586, 612, 636], "order": [6, 21, 30, 34, 41, 52, 53, 64, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 107, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 222, 229, 232, 239, 248, 262, 270, 272, 297, 322, 324, 326, 332, 337, 339, 343, 345, 346, 348, 349, 351, 352, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 569, 620, 634, 635], "driven": 6, "exchang": 6, "notabl": [6, 22], "until": [6, 20, 26, 50, 52, 88, 137, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 266, 271, 382, 404, 564, 567, 569, 572, 575, 621, 622, 629, 634, 635], "exact": [6, 22, 56, 150, 612], "sharedmem": 6, "put": [6, 65, 66, 68, 69, 130, 142, 143, 160, 163, 164, 279, 400, 563, 620, 621, 622, 624, 631, 634, 636], "recv": [6, 564, 565, 569, 572], "send_async": [6, 567, 575], "train_step": 6, "new_weight": [6, 191], "zero": [6, 18, 22, 23, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 97, 101, 102, 108, 109, 114, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 218, 220, 222, 226, 229, 231, 232, 246, 252, 255, 262, 280, 291, 292, 293, 300, 301, 302, 304, 306, 312, 314, 325, 326, 327, 328, 330, 331, 332, 337, 344, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 574, 622, 623, 632, 638, 640, 641], "instantan": 6, "none": [6, 18, 21, 22, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 95, 96, 97, 98, 100, 101, 102, 106, 108, 109, 110, 112, 114, 116, 120, 123, 126, 127, 129, 130, 138, 142, 143, 144, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 206, 207, 209, 210, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 228, 229, 230, 232, 236, 238, 239, 241, 242, 243, 246, 247, 248, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 318, 320, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 396, 397, 398, 401, 402, 408, 409, 410, 411, 412, 413, 415, 417, 418, 419, 420, 424, 425, 426, 427, 428, 430, 433, 434, 437, 438, 439, 441, 442, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 462, 463, 464, 465, 467, 468, 469, 471, 472, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 493, 494, 495, 496, 497, 498, 499, 500, 501, 503, 505, 506, 507, 508, 509, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 542, 544, 546, 548, 549, 550, 553, 554, 555, 556, 558, 559, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 612, 619, 620, 622, 623, 632, 636, 638, 640], "mp": [6, 42, 44, 47, 78, 79, 80, 81, 82, 83, 84, 85, 127, 279, 280, 566, 574], "signal": [6, 17, 32, 34, 35, 36, 38, 56, 78, 79, 81, 83, 84, 85, 102, 108, 109, 114, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 177, 178, 179, 180, 213, 221, 227, 233, 242, 263, 266, 564, 569, 572, 584, 585, 619, 621, 634, 635, 638, 641], "alreadi": [6, 20, 21, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 243, 265, 282, 325, 326, 327, 328, 329, 330, 331, 332, 337, 344, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 401, 402, 564, 574, 612, 619, 621, 628, 634, 635], "part": [6, 7, 12, 20, 21, 22, 23, 27, 78, 80, 81, 83, 84, 85, 88, 102, 120, 121, 123, 126, 130, 136, 138, 148, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 220, 246, 255, 258, 322, 326, 332, 337, 375, 377, 379, 382, 383, 405, 563, 612, 619, 621, 622, 623, 629, 634, 636, 641], "irecv": 6, "return_prematur": 6, "rank": [6, 46, 86, 87, 114, 176, 324, 325, 327, 328, 330, 331, 335, 336, 376, 378, 380, 381, 384, 564, 570, 571, 572, 573, 579, 584, 585, 586], "flag": [6, 7, 17, 19, 27, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 174, 175, 177, 178, 179, 180, 183, 240, 312, 634, 635, 636, 637], "poll": [6, 582, 584], "ref": [6, 324], "connectioninfo": 6, "init_process_group": [6, 572], "isend": [6, 569, 572], "insid": [6, 7, 21, 86, 87, 150, 176, 230, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 571, 612, 641], "raymoduletransform": [6, 571], "join": [6, 127, 185, 572, 620, 621, 623, 634], "uniqu": [6, 64, 108, 109, 138, 142, 143, 177, 179, 221, 233, 264, 265, 266, 270, 340, 400, 401, 402, 571, 573, 574, 591, 612, 627, 638], "even": [6, 17, 21, 23, 27, 30, 35, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 90, 95, 96, 97, 98, 102, 108, 110, 112, 116, 120, 123, 126, 127, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 217, 619, 621, 624, 631, 634, 635, 636, 641], "invok": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 67, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 326, 332, 337, 375, 377, 379, 382, 383], "mechan": [6, 23, 32, 34, 35, 36, 37, 38, 39, 40, 46, 49, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 324, 326, 332, 337, 375, 377, 379, 382, 383, 576, 584, 585, 591, 612, 620, 626, 636], "benefit": [6, 101, 102, 590, 624, 632, 634, 635, 638], "cascad": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 565, 567, 570, 571, 573, 575, 578, 580, 586], "grace": [6, 324], "runnabl": 6, "repositori": [6, 26, 80, 81, 82, 85, 163, 164, 634, 635], "weight_sync_standalon": 6, "weight_sync_collector": 6, "seamlessli": [6, 19, 170, 191, 591, 598, 632, 636], "nn": [6, 17, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 66, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 167, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 226, 231, 233, 241, 250, 265, 271, 272, 275, 277, 283, 284, 285, 287, 288, 290, 291, 292, 293, 297, 299, 300, 301, 302, 304, 305, 307, 312, 313, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 344, 345, 346, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 468, 559, 565, 567, 568, 570, 571, 572, 573, 577, 578, 580, 586, 598, 619, 620, 621, 622, 623, 625, 626, 629, 633, 634, 635, 636, 637, 640], "tensordictmodul": [6, 17, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 66, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 220, 226, 241, 283, 284, 285, 287, 297, 302, 304, 313, 314, 317, 323, 326, 332, 337, 340, 341, 343, 345, 346, 347, 349, 351, 352, 356, 357, 359, 360, 361, 362, 363, 365, 368, 370, 371, 372, 375, 377, 379, 383, 385, 386, 387, 388, 409, 468, 559, 598, 619, 621, 622, 626, 629, 633, 634, 635, 636, 637, 641], "weight_upd": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 591], "linear": [6, 21, 32, 34, 35, 36, 38, 50, 52, 53, 66, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 241, 250, 265, 271, 272, 275, 277, 283, 284, 285, 287, 288, 290, 291, 292, 293, 300, 301, 305, 307, 312, 313, 315, 316, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 346, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 559, 598, 620, 633, 637, 640], "observation_spec": [6, 17, 18, 19, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 193, 194, 195, 196, 197, 198, 199, 215, 218, 221, 222, 223, 224, 225, 228, 229, 230, 232, 233, 236, 238, 239, 240, 241, 243, 246, 248, 250, 252, 254, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 278, 279, 280, 302, 304, 382, 553, 559, 619, 621, 626, 633, 634, 635, 636, 641], "observ": [6, 7, 10, 16, 17, 18, 19, 21, 22, 27, 32, 34, 35, 36, 38, 50, 52, 53, 66, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 92, 93, 100, 102, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 193, 194, 195, 196, 197, 198, 199, 207, 212, 214, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 233, 234, 236, 238, 239, 240, 241, 243, 244, 246, 247, 248, 252, 253, 254, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 278, 279, 280, 283, 284, 285, 287, 289, 290, 291, 292, 293, 294, 297, 301, 302, 304, 308, 309, 311, 312, 313, 315, 317, 322, 323, 339, 340, 341, 348, 349, 350, 351, 352, 353, 355, 356, 357, 360, 363, 364, 367, 368, 369, 370, 371, 372, 382, 385, 386, 387, 388, 389, 390, 392, 419, 420, 468, 559, 591, 598, 599, 620, 621, 622, 623, 624, 625, 626, 628, 629, 633, 634, 635, 636, 638, 640, 641], "action_spec": [6, 17, 18, 19, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 88, 120, 121, 122, 123, 126, 130, 136, 137, 138, 144, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 218, 221, 225, 229, 230, 232, 241, 243, 246, 252, 255, 271, 272, 273, 274, 297, 313, 316, 339, 341, 342, 349, 351, 353, 355, 368, 370, 371, 372, 382, 559, 598, 619, 620, 621, 622, 623, 625, 626, 627, 629, 633, 634, 635, 636, 637, 638, 640, 641], "in_kei": [6, 7, 20, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 66, 69, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 207, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 283, 284, 285, 287, 296, 297, 302, 304, 313, 322, 326, 329, 332, 337, 339, 340, 341, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 362, 363, 364, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 391, 392, 465, 467, 468, 469, 475, 478, 479, 480, 481, 482, 483, 487, 488, 489, 490, 491, 494, 495, 496, 497, 498, 500, 501, 503, 505, 506, 507, 508, 509, 512, 513, 514, 515, 516, 518, 519, 520, 522, 523, 524, 526, 527, 530, 531, 532, 533, 534, 535, 536, 537, 559, 598, 619, 620, 621, 622, 623, 625, 626, 629, 632, 633, 634, 635, 636, 637, 638, 640, 641], "out_kei": [6, 7, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 66, 69, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 121, 122, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 207, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 277, 278, 279, 280, 283, 284, 285, 287, 296, 298, 302, 304, 313, 314, 322, 326, 329, 332, 337, 339, 340, 341, 343, 344, 346, 347, 348, 349, 350, 351, 356, 357, 362, 363, 364, 367, 368, 369, 370, 371, 375, 377, 379, 382, 383, 385, 386, 387, 388, 390, 392, 409, 465, 467, 468, 469, 475, 478, 479, 480, 481, 482, 483, 487, 488, 489, 490, 491, 494, 495, 496, 497, 498, 500, 501, 503, 505, 506, 507, 508, 509, 512, 513, 514, 515, 516, 518, 519, 520, 522, 523, 524, 525, 526, 527, 528, 530, 531, 532, 533, 534, 535, 536, 537, 559, 598, 619, 620, 621, 622, 623, 625, 629, 632, 633, 634, 635, 636, 637, 638, 640, 641], "action": [6, 7, 10, 16, 17, 18, 19, 22, 27, 28, 32, 34, 35, 36, 38, 50, 52, 53, 64, 66, 78, 79, 80, 81, 82, 83, 84, 85, 88, 101, 102, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 214, 215, 218, 224, 225, 226, 229, 230, 231, 232, 233, 234, 236, 237, 239, 241, 243, 244, 245, 246, 248, 252, 253, 255, 259, 263, 265, 269, 271, 272, 273, 274, 278, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 301, 302, 304, 305, 306, 311, 312, 313, 314, 316, 317, 319, 320, 322, 326, 332, 337, 339, 340, 341, 342, 344, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 408, 419, 420, 468, 474, 559, 563, 591, 598, 599, 600, 602, 619, 620, 621, 623, 624, 625, 626, 631, 632, 633, 634, 635, 637, 640, 641], "192": [6, 142, 143], "enumer": [6, 34, 35, 38, 50, 52, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 73, 74, 75, 76, 77, 88, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 373, 375, 377, 379, 382, 383, 619, 620, 621, 622, 629, 634, 638, 640], "worker_fn": 6, "overwritten": [6, 42, 44, 47, 50, 78, 80, 81, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 236], "now": [6, 18, 21, 26, 65, 68, 69, 72, 73, 89, 148, 149, 150, 185, 189, 221, 259, 324, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 631, 633, 634, 635, 637, 638, 641], "from_modul": [6, 35, 36, 38, 86, 87, 176, 325, 326, 327, 328, 330, 331, 332, 337, 343, 346, 376, 378, 380, 381, 384, 418, 640], "spawn": [6, 22, 23, 42, 51, 134, 145, 150, 158, 270, 620, 634, 635], "target": [6, 7, 23, 27, 50, 88, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 264, 324, 326, 332, 337, 343, 344, 348, 349, 350, 351, 352, 353, 355, 357, 358, 361, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 414, 420, 552, 558, 559, 622, 623, 629, 634, 636], "arg": [6, 17, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 58, 60, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 98, 102, 108, 109, 110, 112, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 208, 214, 215, 216, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 244, 249, 250, 251, 252, 253, 255, 258, 259, 261, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 274, 275, 276, 277, 278, 279, 283, 284, 285, 286, 287, 288, 295, 296, 297, 298, 301, 302, 304, 305, 312, 313, 314, 317, 322, 323, 324, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 399, 400, 401, 402, 407, 411, 415, 419, 420, 563, 565, 567, 568, 570, 571, 573, 574, 575, 576, 580, 586, 612, 620, 623, 631], "w": [6, 23, 69, 123, 148, 149, 190, 221, 223, 228, 254, 268, 312, 367, 392, 512, 620, 638], "epoch": [6, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 415, 419, 472, 621, 634, 635], "stop": [6, 17, 32, 34, 35, 36, 38, 50, 52, 85, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 186, 326, 332, 337, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586, 621, 627, 634, 635, 640, 641], "With": [6, 17, 86, 87, 136, 137, 141, 176, 264, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 401, 403, 586, 620, 631, 633, 634, 635, 638, 641], "dictionari": [6, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 60, 86, 87, 88, 89, 102, 106, 108, 109, 120, 123, 126, 129, 130, 131, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 239, 265, 270, 272, 280, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 351, 370, 371, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 401, 409, 417, 561, 562, 563, 577, 620, 621, 624, 626, 634, 636, 641], "map": [6, 17, 21, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 93, 95, 100, 101, 102, 120, 123, 126, 130, 138, 141, 142, 143, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 214, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 232, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 278, 279, 280, 283, 284, 285, 297, 307, 313, 322, 323, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 343, 344, 346, 347, 350, 351, 364, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 409, 418, 419, 424, 472, 567, 579, 580, 581, 584, 585, 587, 599, 619, 620, 621, 622, 625, 626, 637], "transportbackend": [6, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586], "protocol": [6, 190, 197, 202], "stateless": [6, 17, 22, 53, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 218, 227, 280, 335, 336, 365, 375, 377, 379, 383, 390, 619, 624, 636, 641], "design": [6, 7, 10, 16, 17, 18, 22, 37, 46, 49, 63, 64, 86, 87, 88, 106, 112, 119, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 221, 239, 251, 270, 272, 280, 324, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 598, 605, 612, 619, 620, 621, 624, 625, 626, 631, 632, 633, 634, 635, 636, 638, 640, 641], "rather": [6, 23, 65, 68, 69, 72, 73, 112, 148, 149, 178, 185, 253, 280, 619, 620, 621, 622, 624, 626, 634, 635, 638], "kwarg": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 58, 60, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 95, 96, 97, 98, 100, 101, 102, 108, 109, 110, 112, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 202, 208, 209, 215, 216, 218, 225, 243, 250, 252, 261, 265, 270, 271, 272, 274, 276, 277, 279, 281, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 296, 297, 298, 300, 301, 302, 303, 304, 305, 310, 312, 313, 314, 317, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 396, 397, 399, 400, 401, 402, 407, 415, 419, 420, 554, 555, 560, 561, 562, 565, 567, 568, 570, 571, 573, 575, 576, 578, 580, 586, 612, 621, 623, 635], "receive_weight": [6, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 564, 566, 569, 572, 574, 576, 579, 581], "pre": [6, 26, 51, 55, 83, 88, 97, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 269, 275, 277, 326, 332, 337, 375, 377, 379, 382, 383, 564, 567, 569, 572, 576, 641], "alloc": [6, 86, 87, 97, 176, 194, 295, 306, 324, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 564, 569, 572, 576, 591, 612, 619], "weightstrategi": [6, 564, 565, 567, 568, 569, 570, 571, 572, 573, 575, 576, 578, 580, 586, 587], "applic": [6, 86, 87, 150, 158, 170, 176, 325, 327, 328, 330, 331, 370, 376, 378, 380, 381, 384, 577, 579, 612, 624, 625, 636], "setup_connection_and_weights_on_receiv": [6, 564, 566, 569, 572, 574, 576], "recept": [6, 38], "note": [6, 18, 19, 20, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 213, 229, 232, 270, 279, 280, 302, 304, 312, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 350, 358, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 565, 567, 570, 571, 573, 575, 578, 580, 584, 586, 612, 620, 623, 625, 631, 633, 634, 635, 641], "mptransport": [6, 567], "ye": 6, "rpctransport": [6, 570], "raytransport": [6, 571, 573], "distributedtransport": 6, "sharedmemtransport": [6, 566, 576], "instant": [6, 574, 581], "arriv": [6, 567, 575], "specifi": [6, 7, 15, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 228, 229, 230, 232, 258, 261, 264, 269, 273, 274, 282, 307, 324, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 343, 344, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 403, 565, 567, 570, 571, 573, 575, 576, 577, 578, 580, 586, 612, 619, 621, 622, 623, 627, 631, 634], "expir": [6, 564, 569, 572], "weightupdat": 6, "deprec": [6, 34, 35, 36, 38, 41, 43, 45, 46, 48, 50, 56, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 279, 325, 326, 327, 328, 330, 331, 332, 337, 348, 350, 351, 353, 356, 357, 358, 363, 364, 367, 368, 369, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 589, 641], "11": [6, 29, 56, 64, 95, 96, 97, 101, 109, 116, 127, 214, 226, 268, 591], "prefer": [6, 18, 22, 32, 35, 36, 38, 47, 56, 65, 68, 72, 73, 108, 109, 120, 154, 159, 181, 251, 259, 367, 371, 411, 621, 634, 635, 638, 640], "power": [7, 16, 30, 620], "top": [7, 21, 23, 88, 114, 121, 122, 136, 137, 228, 271, 326, 332, 337, 487, 598, 625], "hydra": [7, 419, 613], "dataclass": [7, 74, 86, 87, 176, 325, 327, 328, 330, 331, 365, 376, 378, 380, 381, 384], "compos": [7, 10, 21, 65, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 103, 104, 105, 114, 115, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 226, 227, 239, 254, 270, 271, 272, 279, 326, 332, 337, 340, 351, 360, 370, 375, 377, 379, 382, 383, 392, 484, 598, 619, 620, 621, 622, 623, 627, 631, 633, 635, 637, 638, 640, 641], "overridden": [7, 22, 37, 39, 40, 41, 46, 49, 78, 80, 81, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 338, 340, 347, 385, 387, 388, 622, 634], "advantag": [7, 21, 22, 27, 178, 185, 300, 348, 350, 364, 367, 369, 375, 377, 379, 382, 385, 386, 387, 388, 389, 619, 620, 621, 622, 635, 636, 641], "glimps": 7, "go": [7, 19, 21, 26, 96, 141, 150, 227, 251, 255, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "sota": [7, 35, 38, 144, 237, 369, 405, 554, 619, 620, 640], "ppo_train": 7, "help": [7, 17, 23, 74, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 233, 326, 332, 333, 334, 337, 348, 350, 364, 367, 369, 375, 377, 379, 382, 383, 419, 590, 619, 620, 621, 622, 631, 632, 634, 635], "overrid": [7, 22, 37, 39, 40, 41, 46, 49, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 78, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 295, 326, 332, 337, 375, 377, 379, 382, 383, 392, 563, 568, 570, 571, 573, 578, 580, 585, 586, 631], "reproduc": [7, 17, 21, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 221, 239, 419, 420, 472, 619, 621, 623, 635], "command": [7, 25, 26, 29, 154, 159, 160, 190, 621, 631, 634, 635, 636, 641], "here": [7, 18, 19, 21, 23, 26, 27, 28, 29, 35, 38, 50, 84, 85, 114, 120, 123, 124, 125, 126, 130, 134, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 193, 221, 270, 400, 591, 619, 620, 621, 622, 623, 624, 625, 627, 629, 634, 635, 636, 638, 640, 641], "minim": [7, 16, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 394, 567, 591, 638], "config": [7, 25, 26, 190, 250, 277, 289, 294, 311, 419, 553, 554, 555, 557, 560, 612], "yaml": 7, "training_env": 7, "env_nam": [7, 25, 120, 121, 123, 124, 126, 127, 129, 130, 132, 136, 138, 139, 145, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 442, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 619, 621, 641], "tell": [7, 18, 23, 26, 120, 152, 153, 270, 575, 582, 619, 622, 627, 634, 635], "proper": [7, 22, 23, 25, 26, 189, 324, 385, 386, 387, 388, 591, 620, 621, 631, 634, 635, 636, 638], "select": [7, 23, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 123, 142, 143, 152, 153, 163, 164, 170, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 236, 237, 240, 241, 243, 244, 245, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 297, 313, 324, 326, 332, 337, 342, 375, 377, 379, 382, 383, 413, 619, 623, 624, 632, 634, 638], "syntax": [7, 612, 619], "dmcontrol": [7, 16, 18, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "brax": [7, 16, 27, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 253, 442, 624, 641], "well": [7, 15, 16, 17, 20, 21, 22, 27, 50, 56, 65, 68, 72, 73, 74, 88, 102, 106, 110, 117, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 271, 272, 290, 315, 316, 326, 332, 337, 344, 365, 367, 371, 375, 377, 379, 382, 383, 385, 389, 619, 620, 622, 623, 624, 625, 626, 628, 637, 638, 640, 641], "reward": [7, 10, 17, 18, 19, 22, 34, 35, 38, 78, 79, 80, 81, 82, 83, 84, 85, 88, 101, 102, 114, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 214, 215, 218, 219, 224, 225, 229, 230, 232, 233, 234, 239, 241, 242, 243, 244, 248, 252, 253, 255, 256, 257, 258, 259, 260, 262, 263, 264, 269, 271, 272, 273, 274, 276, 277, 279, 280, 302, 323, 340, 348, 349, 351, 352, 353, 355, 356, 357, 360, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 407, 408, 409, 412, 419, 420, 563, 594, 613, 619, 620, 621, 622, 623, 624, 628, 631, 632, 634, 635, 636, 640, 641], "mlp": [7, 144, 283, 288, 290, 291, 292, 293, 297, 300, 302, 304, 353, 355, 464, 598, 620, 623, 625, 626, 629, 633, 637, 640], "convnet": [7, 290, 291, 300, 463, 598, 622, 623, 625, 640], "writer": [7, 10, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 94, 97, 102, 104, 108, 114, 115, 116, 119, 430, 431, 436, 437, 621, 638], "logger": [7, 20, 30, 390, 392, 394, 395, 396, 397, 398, 399, 400, 408, 415, 419, 420, 459, 460, 461, 462, 472, 559, 563, 589, 613, 620, 634], "assign": [7, 17, 23, 32, 35, 36, 38, 54, 58, 75, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 325, 326, 327, 328, 330, 331, 332, 335, 336, 337, 351, 352, 353, 355, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 586, 612, 621, 625, 631, 634, 635, 638], "locat": [7, 15, 26, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 209, 228, 233, 246, 257, 280, 303, 320, 321, 324, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 416, 418, 612, 619, 620, 621, 628, 634, 635, 638], "batched_env": 7, "transformed_env": [7, 225, 272, 624], "base_env": [7, 21, 22, 120, 122, 123, 126, 130, 131, 137, 138, 149, 150, 151, 154, 158, 159, 160, 162, 170, 171, 172, 175, 178, 179, 180, 194, 214, 215, 218, 224, 226, 227, 229, 231, 232, 241, 248, 252, 254, 260, 263, 265, 266, 270, 272, 392, 404, 441, 571, 591, 619, 620, 621, 623, 634, 637, 640, 641], "transform0": 7, "noop_reset": 7, "transform1": [7, 21], "step_count": [7, 34, 35, 38, 120, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 227, 263, 521, 621, 622, 623, 624, 629], "noop": [7, 245, 504], "30": [7, 18, 20, 68, 81, 88, 108, 109, 184, 217, 245, 315, 316, 390, 394, 397, 399, 400, 459, 504, 612, 627, 632, 635, 636, 638], "max_step": [7, 16, 17, 30, 114, 120, 123, 126, 130, 138, 142, 143, 144, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 183, 263, 270, 390, 521, 624, 625, 626, 628, 629, 634, 635, 640, 641], "step_count_kei": [7, 226, 227, 263, 521], "_partial_": [7, 424, 425, 426, 427, 430, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 463, 464, 465, 466, 467, 468, 469, 470, 471, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551], "individu": [7, 23, 34, 42, 44, 47, 50, 69, 88, 102, 114, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 280, 326, 332, 337, 350, 364, 367, 375, 377, 379, 382, 383, 619, 622, 635], "construct": [7, 18, 24, 56, 65, 68, 69, 72, 73, 74, 78, 88, 120, 123, 126, 127, 129, 130, 138, 150, 151, 152, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 280, 302, 304, 316, 326, 332, 337, 344, 375, 377, 379, 382, 383, 415, 598, 613, 620, 621, 622, 625, 634, 636, 638, 641], "repeat": [7, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 181, 185, 194, 270, 295, 324, 326, 332, 337, 528, 621, 634, 635, 636], "layer": [7, 246, 279, 288, 290, 291, 296, 299, 302, 304, 305, 308, 309, 324, 333, 334, 338, 347, 464, 579, 584, 585, 591, 593, 594, 598, 620, 621, 622, 623, 625, 634, 637], "episod": [7, 18, 78, 79, 80, 81, 82, 83, 84, 85, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 217, 255, 258, 264, 385, 419, 620, 624, 629, 634, 635, 638], "track": [7, 20, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 73, 86, 87, 101, 102, 107, 123, 176, 178, 191, 258, 267, 279, 280, 312, 325, 327, 328, 330, 331, 340, 376, 378, 380, 381, 382, 384, 397, 407, 417, 419, 472, 589, 616, 620, 622, 624, 627, 635, 636, 638], "count": [7, 18, 20, 22, 32, 34, 35, 36, 38, 52, 126, 127, 226, 263, 270, 280, 312, 324, 409, 415, 552, 591, 619, 620, 621, 622, 638, 641], "composit": [7, 10, 17, 18, 19, 21, 57, 58, 59, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 87, 88, 106, 112, 119, 120, 123, 126, 128, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 206, 213, 215, 218, 229, 230, 231, 232, 234, 239, 241, 244, 252, 253, 259, 263, 265, 269, 270, 271, 273, 280, 286, 339, 341, 344, 346, 347, 348, 367, 382, 591, 619, 621, 625, 631, 636, 641], "combin": [7, 23, 102, 188, 195, 196, 324, 371, 620, 623, 628, 638, 640], "maximum": [7, 17, 23, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 47, 48, 50, 57, 75, 90, 95, 96, 97, 98, 101, 102, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 231, 256, 263, 264, 266, 319, 320, 321, 326, 329, 332, 337, 347, 349, 351, 356, 357, 363, 365, 366, 370, 375, 377, 379, 383, 392, 411, 419, 420, 472, 564, 565, 566, 567, 569, 570, 571, 572, 573, 575, 576, 578, 580, 586, 591, 612, 619, 620, 621, 622, 625, 634, 635, 638], "length": [7, 35, 36, 38, 47, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 83, 87, 102, 108, 109, 112, 120, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 196, 214, 221, 242, 251, 279, 288, 290, 292, 294, 305, 322, 325, 326, 332, 337, 339, 343, 382, 383, 405, 411, 591, 619, 621, 622, 627, 629, 631, 636, 638, 641], "concept": [7, 21, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 591, 620, 631, 638], "nest": [7, 16, 17, 19, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 56, 60, 68, 69, 71, 86, 87, 88, 95, 96, 97, 100, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 213, 221, 263, 266, 270, 271, 325, 326, 327, 328, 330, 331, 332, 337, 340, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 404, 408, 613, 620, 621, 623, 635, 636, 638, 640], "deep": [7, 22, 28, 221, 242, 290, 291, 292, 293, 296, 312, 348, 351, 370, 619, 634], "factori": [7, 28, 32, 34, 35, 36, 38, 42, 44, 47, 50, 66, 68, 72, 73, 74, 194, 243, 402, 439, 463, 464, 619], "onc": [7, 22, 26, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 54, 69, 83, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 244, 255, 265, 272, 286, 312, 325, 326, 327, 328, 330, 331, 332, 337, 340, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 412, 565, 567, 568, 570, 571, 573, 575, 576, 578, 580, 586, 612, 620, 621, 622, 625, 628, 636, 638, 641], "per": [7, 19, 20, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 53, 80, 88, 101, 102, 108, 114, 134, 136, 137, 150, 152, 153, 196, 224, 244, 258, 288, 299, 301, 324, 333, 340, 367, 379, 392, 394, 397, 399, 400, 415, 417, 419, 420, 472, 561, 562, 574, 586, 591, 619, 620, 621, 622, 623, 625, 626, 629, 634, 635, 638, 640], "variabl": [7, 18, 20, 22, 23, 26, 27, 41, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 80, 81, 84, 85, 87, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 142, 143, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 175, 178, 179, 180, 185, 196, 200, 202, 225, 267, 271, 280, 283, 284, 285, 302, 304, 326, 332, 337, 365, 368, 404, 591, 620, 632], "interpol": [7, 69, 254, 512, 620, 623], "script": [7, 26, 80, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 404, 559, 563, 613, 619, 620, 623, 628, 634, 635, 636, 638], "discov": [7, 23], "print": [7, 18, 22, 25, 26, 34, 35, 38, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 101, 102, 108, 109, 114, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 136, 137, 138, 139, 140, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 164, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 203, 206, 211, 212, 213, 214, 217, 218, 221, 222, 226, 227, 229, 230, 231, 232, 240, 246, 252, 253, 255, 258, 263, 265, 266, 267, 268, 279, 280, 283, 284, 285, 288, 290, 291, 292, 293, 294, 297, 300, 301, 302, 304, 305, 306, 307, 310, 312, 313, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 339, 340, 341, 343, 344, 346, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 401, 559, 582, 591, 612, 620, 621, 622, 623, 624, 625, 626, 627, 628, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "someth": [7, 88, 120, 123, 126, 130, 138, 141, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 590, 620, 621, 636, 641], "policy_model": [7, 583], "tanh_norm": 7, "value_model": [7, 359, 361], "policy_network": 7, "value_network": [7, 352, 353, 355, 356, 358, 363, 370, 385, 386, 387, 388, 605, 619, 621, 623, 626, 629, 634], "tensor": [7, 10, 12, 14, 17, 18, 19, 22, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 106, 108, 109, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 206, 212, 213, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 231, 232, 233, 234, 236, 239, 240, 242, 246, 248, 250, 251, 252, 253, 255, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 270, 271, 272, 273, 274, 275, 277, 279, 280, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 338, 339, 340, 341, 343, 344, 346, 347, 348, 349, 351, 352, 353, 355, 356, 357, 360, 361, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 408, 426, 438, 574, 591, 593, 619, 620, 621, 622, 623, 624, 625, 634, 635, 636, 640, 641], "without_replac": 7, "round_robin": 7, "adam": [7, 172, 320, 420, 541, 619, 620, 621, 622, 623, 626, 629, 634, 635, 636], "wandb": [7, 392, 396, 400, 415, 419, 462, 472, 628, 640], "out_featur": [7, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 283, 288, 290, 291, 292, 293, 297, 299, 300, 302, 304, 305, 326, 332, 337, 343, 353, 355, 375, 377, 379, 382, 383, 464, 467, 468, 469, 619, 622, 623, 625, 626, 629, 640], "in_featur": [7, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 283, 288, 290, 291, 292, 293, 300, 305, 326, 332, 337, 343, 353, 355, 375, 377, 379, 382, 383, 463, 464, 467, 468, 469, 623, 625, 626], "num_cel": [7, 283, 288, 290, 291, 292, 293, 299, 300, 302, 304, 305, 463, 464, 467, 468, 469, 620, 621, 622, 623, 625, 626, 629, 634, 635, 640], "128": [7, 78, 79, 83, 109, 121, 122, 136, 137, 193, 291, 294, 612, 620, 622, 623, 629, 634, 637, 638], "num_cal": 7, "state_valu": [7, 284, 285, 322, 350, 356, 363, 364, 367, 368, 370, 385, 386, 387, 388, 619, 635], "loss_modul": [7, 350, 364, 365, 367, 375, 377, 379, 383, 414, 415, 418, 419, 420, 472, 558, 559, 605, 613, 619, 620, 621, 634, 635, 638], "1024": [7, 50, 66, 294, 401, 638], "lr": [7, 420, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 619, 620, 621, 622, 629, 634, 635, 636], "001": [7, 541, 542, 547, 550, 551, 619, 636], "actor_network": [7, 348, 349, 350, 351, 352, 354, 356, 357, 363, 364, 366, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 414, 418, 419, 420, 471, 472, 605, 619, 621, 626, 634, 635], "critic_network": [7, 348, 350, 364, 367, 369, 418, 419, 471, 472, 621, 635], "exp_nam": [7, 30, 392, 393, 394, 397, 398, 399, 400, 459, 461, 462, 559, 620, 628, 629], "my_experi": [7, 403], "0001": [7, 280, 299, 307, 467, 538, 541, 545], "chang": [7, 18, 21, 24, 26, 30, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 86, 87, 88, 90, 95, 96, 97, 98, 102, 107, 108, 110, 112, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 232, 234, 241, 244, 252, 253, 259, 263, 269, 271, 272, 273, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 419, 420, 567, 575, 591, 612, 619, 622, 632, 634, 635, 636, 637, 638, 641], "rate": [7, 23, 30, 78, 279, 280, 419, 620, 621, 634, 635], "multirun": 7, "01": [7, 217, 246, 280, 312, 348, 350, 364, 367, 379, 538, 540, 542, 548, 549], "8": [7, 25, 26, 60, 68, 71, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 108, 109, 120, 121, 122, 123, 124, 125, 126, 130, 138, 148, 149, 150, 151, 154, 158, 159, 160, 161, 170, 171, 172, 175, 178, 179, 180, 214, 217, 226, 227, 264, 267, 273, 280, 283, 284, 285, 288, 290, 291, 300, 305, 341, 343, 346, 363, 619, 620, 636, 638, 640], "my_custom_config": 7, "under": [7, 17, 18, 21, 23, 50, 60, 71, 78, 79, 80, 81, 83, 84, 85, 88, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 242, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 297, 298, 313, 314, 326, 332, 337, 339, 341, 343, 344, 365, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 392, 415, 591, 619, 620, 625, 634, 636, 641], "hood": [7, 17, 50, 78, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 636], "configstor": 7, "type": [7, 10, 21, 22, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 85, 86, 87, 88, 120, 123, 126, 130, 138, 141, 144, 147, 150, 151, 152, 153, 154, 158, 159, 160, 167, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 204, 205, 209, 210, 212, 214, 218, 221, 225, 229, 230, 233, 234, 239, 241, 244, 250, 252, 253, 259, 263, 265, 269, 270, 271, 272, 273, 275, 277, 279, 280, 286, 288, 297, 305, 318, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 335, 336, 337, 341, 343, 344, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 390, 401, 402, 403, 439, 463, 464, 470, 561, 574, 577, 612, 619, 620, 621, 623, 627, 631, 634, 635, 636, 638, 641], "safeti": [7, 32, 35, 36, 38, 144, 150, 158, 280, 612, 631], "id": [7, 26, 32, 34, 35, 36, 37, 38, 39, 40, 41, 46, 49, 52, 53, 55, 56, 69, 102, 108, 109, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 175, 177, 178, 179, 180, 200, 312, 324, 332, 351, 368, 395, 400, 462, 565, 567, 568, 570, 571, 573, 575, 578, 579, 580, 586, 627, 638], "registr": [7, 41, 401, 589, 620], "config_stor": 7, "cs": 7, "gymenvconfig": 7, "batchedenvconfig": 7, "tanhnormalmodelconfig": [7, 465], "inherit": [7, 21, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 193, 365, 375, 621, 634, 635], "envs_lib": 7, "envlibsconfig": 7, "mycustomenvconfig": 7, "_target_": [7, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 441, 442, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 462, 463, 464, 467, 468, 469, 471, 472, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551], "str": [7, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 95, 96, 97, 98, 101, 102, 114, 116, 120, 121, 123, 124, 125, 126, 128, 129, 130, 131, 132, 136, 138, 142, 143, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 210, 213, 217, 221, 233, 239, 240, 241, 243, 250, 254, 263, 264, 267, 269, 270, 272, 273, 275, 277, 278, 279, 282, 288, 289, 290, 291, 292, 293, 296, 297, 298, 300, 302, 304, 305, 306, 307, 311, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 341, 343, 344, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 441, 442, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 462, 463, 464, 467, 468, 469, 471, 472, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 553, 563, 565, 566, 567, 568, 570, 571, 572, 573, 574, 575, 577, 578, 579, 580, 581, 584, 585, 586, 612, 620, 621, 623, 631], "my_modul": [7, 571], "mycustomenv": 7, "myenv": [7, 150, 218, 229, 232], "custom_param": 7, "float": [7, 18, 21, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 58, 60, 64, 65, 69, 72, 75, 83, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 214, 217, 221, 225, 229, 232, 241, 242, 246, 250, 255, 256, 257, 264, 265, 268, 271, 272, 275, 277, 280, 286, 287, 295, 299, 303, 305, 306, 315, 316, 319, 321, 324, 325, 326, 327, 328, 330, 331, 332, 337, 343, 347, 348, 349, 350, 351, 355, 356, 357, 360, 361, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 412, 419, 420, 428, 464, 467, 471, 472, 483, 501, 503, 505, 513, 514, 515, 522, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 579, 580, 581, 582, 584, 586, 591, 619, 620, 638, 641], "__post_init__": 7, "self": [7, 18, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 71, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 277, 278, 279, 282, 286, 301, 302, 304, 322, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 584, 585, 591, 612, 619, 631, 636, 640], "super": [7, 18, 21, 88, 144, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 322, 349, 351, 352, 357, 363, 368, 370, 371, 372, 382, 568, 570, 571, 573, 578, 580, 585, 586, 619, 636, 640], "my_custom": 7, "begin": [7, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 102, 108, 217, 404, 623, 624, 625, 626, 627, 628, 629, 631], "gradual": 7, "add": [7, 10, 16, 21, 23, 25, 50, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 94, 96, 101, 104, 114, 115, 118, 119, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 221, 239, 241, 269, 272, 302, 304, 326, 332, 337, 348, 374, 375, 377, 379, 382, 383, 410, 419, 472, 568, 570, 571, 573, 578, 580, 586, 591, 602, 612, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 634, 635, 636, 638, 640], "leverag": [7, 39, 50, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 324, 591, 619, 635, 641], "sparingli": 7, "correctli": [7, 22, 26, 88, 90, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 591], "duplic": [7, 88, 107, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 349, 351, 353, 358, 363, 365, 368, 370, 371, 372, 375, 377, 379, 382, 383], "As": [7, 19, 22, 23, 68, 69, 72, 73, 74, 78, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 255, 295, 344, 385, 619, 620, 621, 622, 623, 624, 626, 627, 634, 635, 636, 637, 638, 640, 641], "td3": [7, 371, 372], "expand": [7, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 95, 108, 109, 176, 218, 265, 295, 325, 327, 328, 330, 331, 343, 346, 349, 351, 363, 365, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 634, 635, 636, 638, 640], "sactrainerconfig": 7, "td3trainerconfig": 7, "addit": [7, 16, 19, 22, 23, 37, 39, 46, 49, 63, 79, 86, 87, 88, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 163, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 225, 250, 265, 269, 271, 272, 275, 277, 286, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 337, 340, 343, 350, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 390, 392, 570, 571, 573, 586, 609, 612, 619, 620, 623, 624, 634, 635, 638], "maintain": [7, 18, 24, 28, 35, 36, 38, 63, 189, 192, 201, 221, 280, 357, 370, 574, 578, 591, 612, 636], "circumst": 8, "cudnn": [8, 302, 304, 622, 623], "7": [8, 10, 25, 29, 64, 65, 68, 72, 101, 102, 109, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 214, 217, 226, 227, 264, 267, 280, 287, 288, 291, 305, 324, 332, 337, 586, 619, 638, 640], "5x": 8, "batch_first": [8, 622], "input": [8, 9, 16, 17, 18, 20, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 96, 98, 111, 117, 120, 123, 126, 130, 138, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 243, 244, 248, 249, 250, 251, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 287, 288, 290, 291, 292, 293, 296, 297, 298, 301, 302, 304, 305, 307, 312, 313, 314, 315, 316, 320, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 408, 412, 552, 559, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586, 591, 595, 605, 619, 620, 621, 622, 623, 624, 631, 634, 635, 636, 640, 641], "fix": [8, 27, 150, 265, 349, 351, 366, 370, 612, 620, 629, 636, 641], "5": [8, 10, 18, 19, 32, 34, 35, 36, 38, 52, 56, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 72, 73, 78, 87, 88, 90, 108, 109, 114, 120, 123, 126, 127, 130, 136, 137, 138, 142, 143, 145, 150, 151, 154, 156, 157, 158, 159, 160, 163, 164, 170, 172, 175, 177, 178, 179, 180, 183, 193, 214, 217, 218, 220, 226, 227, 242, 255, 262, 263, 264, 270, 280, 287, 288, 290, 291, 296, 297, 299, 300, 303, 305, 308, 313, 320, 321, 324, 333, 334, 337, 340, 347, 364, 367, 369, 371, 372, 379, 390, 463, 464, 467, 469, 549, 591, 612, 618, 619, 620, 623, 625, 629, 634, 635, 636, 638, 639, 640, 641], "condit": [9, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 178, 183, 226, 227, 264, 279, 297, 298, 313, 314, 340, 485, 574, 589, 591, 619, 634, 636, 638], "met": [9, 226, 227, 634, 636], "packedsequ": 9, "dropout": [9, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 287, 302, 304, 305, 326, 332, 337, 375, 377, 379, 382, 383, 464, 622], "comprehens": [10, 16, 419, 420, 591, 593, 598, 605, 612], "around": [10, 24, 26, 32, 72, 73, 89, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 340, 342, 344, 385, 591, 619, 620, 631, 635, 641], "central": [10, 12, 37, 41, 46, 49, 50, 324, 402, 612, 619, 620, 624, 634, 635, 638], "offer": [10, 16, 17, 20, 22, 26, 120, 121, 122, 123, 126, 130, 136, 137, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 270, 390, 598, 619, 620, 623, 624, 626, 627, 634, 636, 638, 641], "memmap": [10, 86, 87, 95, 97, 150, 158, 176, 279, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 392, 394, 411, 580, 581, 583], "compress": [10, 90, 91], "advanc": [10, 22, 50, 65, 68, 72, 73, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 324, 401, 589, 624, 627, 638], "priorit": [10, 27, 65, 72, 101, 102, 351, 352, 353, 355, 356, 357, 363, 368, 370, 371, 372, 428, 619, 620, 627, 640], "mix": [10, 251, 612, 619, 634, 635], "arbitrari": [10, 16, 17, 22, 57, 64, 68, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 619, 620, 636, 638], "lazymemmapstorag": [10, 12, 15, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 102, 108, 109, 220, 221, 424, 619, 620, 622, 627, 634, 637, 638], "prioritizedsampl": [10, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 102, 353, 358, 428, 619, 638], "max_siz": [10, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 95, 96, 97, 98, 108, 109, 110, 114, 116, 424, 425, 426, 427, 438, 621, 627], "1000000": [10, 78, 79, 80, 81, 82, 83, 84, 85, 401, 420, 538, 613], "max_capac": [10, 101, 102, 428, 619, 638], "alpha": [10, 65, 72, 101, 102, 288, 290, 291, 292, 293, 300, 349, 351, 357, 366, 368, 370, 371, 428, 538, 548, 619, 638, 640], "beta": [10, 23, 65, 72, 101, 102, 356, 363, 364, 383, 428, 541, 542, 543, 545, 546, 547, 551, 619, 620, 638, 640], "batch_siz": [10, 17, 18, 19, 22, 27, 34, 35, 38, 52, 55, 56, 60, 63, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 95, 96, 97, 101, 102, 103, 108, 109, 114, 116, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 133, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 212, 213, 214, 218, 220, 221, 225, 229, 232, 233, 234, 239, 248, 252, 253, 255, 259, 262, 263, 265, 271, 272, 273, 283, 284, 285, 287, 294, 295, 296, 297, 298, 301, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 344, 346, 347, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 401, 405, 411, 417, 419, 420, 430, 437, 442, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 477, 591, 612, 619, 620, 621, 622, 627, 631, 632, 634, 635, 636, 638, 640, 641], "256": [10, 34, 52, 142, 143, 239, 294, 591, 620, 621, 623, 634, 635], "randn": [10, 22, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 95, 96, 97, 102, 108, 109, 116, 120, 176, 188, 206, 220, 246, 283, 284, 285, 287, 289, 290, 294, 296, 297, 306, 307, 310, 311, 313, 322, 325, 327, 328, 330, 331, 338, 339, 341, 343, 346, 347, 348, 349, 351, 352, 353, 355, 356, 357, 363, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 413, 463, 464, 467, 468, 469, 623, 638, 640, 641], "32": [10, 51, 60, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 109, 130, 137, 156, 157, 163, 164, 180, 185, 192, 193, 194, 221, 239, 288, 289, 290, 291, 293, 294, 300, 305, 308, 309, 311, 390, 401, 462, 463, 464, 467, 468, 469, 612, 620, 622, 623, 625, 626, 636, 637, 638, 640, 641], "compressedliststorag": [10, 91], "compressedliststoragecheckpoint": 10, "flatstoragecheckpoint": 10, "h5storagecheckpoint": 10, "immutabledatasetwrit": [10, 78, 79, 80, 81, 82, 83, 84, 85], "liststorag": [10, 12, 65, 66, 68, 69, 72, 73, 96, 427, 638], "lazystackstorag": [10, 88, 425], "liststoragecheckpoint": 10, "nestedstoragecheckpoint": 10, "storagecheckpointerbas": [10, 68, 110], "storageensembl": [10, 69, 106, 435], "storageensemblecheckpoint": 10, "tensorstorag": [10, 12, 68, 78, 79, 80, 81, 82, 83, 84, 85, 95, 101, 102, 114, 117, 438, 627, 638], "tensorstoragecheckpoint": [10, 95], "prioritizedslicesampl": [10, 638], "randomsampl": [10, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 429, 619, 634], "samplerensembl": [10, 69], "samplerwithoutreplac": [10, 88, 114, 432, 621, 635, 638], "slicesamplerwithoutreplac": [10, 108, 434, 638], "ataridqnexperiencereplai": 10, "d4rlexperiencereplai": 10, "gendgrlexperiencereplai": 10, "minariexperiencereplai": [10, 78, 79, 80, 82, 83, 84, 85], "openmlexperiencereplai": 10, "openxexperiencereplai": [10, 392], "robosetexperiencereplai": [10, 108, 109], "vd4rlexperiencereplai": 10, "tensorspec": [10, 17, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 75, 76, 77, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 213, 214, 218, 219, 221, 222, 223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 238, 240, 241, 242, 243, 244, 246, 248, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 278, 279, 280, 286, 297, 298, 301, 312, 313, 314, 316, 339, 341, 342, 343, 344, 345, 347, 349, 351, 353, 356, 357, 368, 370, 371, 372, 382, 589, 636], "binari": [10, 18, 26, 64, 161, 215, 219, 297, 298, 313, 314, 353, 356, 357, 631], "bound": [10, 18, 23, 50, 60, 75, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 224, 245, 279, 286, 297, 298, 301, 312, 313, 314, 315, 316, 326, 332, 337, 339, 341, 342, 343, 344, 347, 348, 349, 351, 352, 363, 367, 368, 370, 371, 372, 375, 377, 379, 382, 383, 619, 620, 621, 623, 634, 636, 640, 641], "categor": [10, 19, 21, 57, 58, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 175, 178, 179, 180, 213, 214, 215, 233, 252, 297, 298, 310, 313, 314, 326, 341, 353, 356, 357, 474, 622], "multicategor": [10, 62], "multionehot": [10, 61, 353, 356, 357], "nontensor": [10, 17, 87, 175, 180, 239, 273], "onehot": [10, 57, 58, 59, 60, 61, 62, 63, 70, 71, 74, 75, 76, 77, 121, 122, 129, 131, 132, 135, 136, 137, 145, 146, 148, 149, 155, 161, 162, 297, 313, 353, 355, 356, 357], "stackedcomposit": 10, "unbound": [10, 18, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 76, 77, 86, 87, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 206, 215, 218, 229, 232, 252, 265, 322, 325, 327, 328, 330, 331, 339, 343, 346, 369, 376, 378, 380, 381, 384, 591, 631, 636, 638], "unboundedcontinu": [10, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 252, 265, 346], "unboundeddiscret": [10, 75, 151, 239], "offlin": [11, 27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 78, 80, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 349, 355, 356, 363, 371, 382, 400, 462, 589, 605, 624, 637, 638], "wide": [12, 22, 24, 640], "give": [12, 22, 26, 60, 71, 72, 80, 87, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 350, 364, 367, 590, 612, 619, 620, 623, 634, 635, 636, 637, 640], "abil": [12, 15, 365, 636, 638], "panel": [12, 621], "almost": [12, 280, 306, 622], "physic": [12, 25, 26, 93, 150, 151, 155, 619, 634, 635, 636], "theori": 12, "crude": 12, "made": [12, 18, 22, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 78, 88, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 265, 271, 312, 326, 332, 337, 353, 365, 375, 377, 379, 382, 383, 465, 619, 620, 622, 634, 635, 637, 638, 640], "ineffici": [12, 23], "contigu": [12, 18, 27, 58, 60, 75, 80, 83, 84, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 239, 242, 265, 273, 636, 638, 640], "collate_fn": [12, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 170, 171, 172, 175, 638, 640], "__init__": [12, 18, 21, 26, 88, 126, 144, 161, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 211, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 295, 322, 334, 349, 351, 352, 357, 363, 368, 370, 371, 372, 382, 612, 636, 641], "retriev": [13, 17, 22, 32, 35, 36, 37, 38, 39, 41, 46, 49, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 106, 108, 109, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 188, 189, 195, 196, 201, 212, 222, 230, 233, 246, 325, 327, 328, 330, 331, 337, 340, 341, 344, 347, 348, 349, 350, 351, 353, 364, 367, 368, 370, 371, 372, 376, 378, 379, 380, 381, 384, 385, 386, 387, 388, 401, 402, 403, 563, 572, 620, 621, 625, 636, 641], "dtype": [14, 18, 19, 22, 34, 35, 38, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 101, 102, 108, 109, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 209, 212, 213, 214, 215, 218, 219, 225, 226, 229, 230, 231, 232, 233, 234, 239, 241, 242, 246, 248, 250, 252, 253, 255, 259, 262, 263, 265, 267, 268, 271, 272, 273, 275, 277, 283, 284, 285, 287, 296, 297, 298, 302, 304, 312, 313, 314, 322, 324, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 344, 346, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 488, 526, 579, 584, 585, 587, 591, 623, 631, 632, 633, 636, 638, 640, 641], "domain": [14, 16, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 184, 206, 231, 239, 265, 273, 297, 298, 313, 314, 339, 341, 343, 344, 345, 346, 621, 626, 631, 634, 635, 636, 640, 641], "influenti": 15, "latenc": [15, 22, 612], "especi": [15, 17, 26, 27, 222, 326, 332, 337, 567], "larger": [15, 23, 42, 47, 50, 302, 304, 356, 363, 640], "volum": 15, "advis": [15, 30, 80, 628, 641], "due": [15, 22, 24, 33, 42, 43, 44, 45, 47, 48, 56, 350, 367, 420, 586, 626, 637, 638, 641], "memorymappedtensor": [15, 78, 79, 80, 81, 82, 83, 84, 85, 95, 394, 627], "file": [15, 25, 26, 27, 78, 79, 80, 81, 83, 84, 85, 86, 87, 93, 163, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 391, 392, 394, 415, 419, 420, 472, 580, 581, 582, 589, 612, 618, 620, 634, 638, 639], "improv": [15, 23, 30, 54, 177, 192, 237, 348, 419, 623, 634, 635, 638], "failur": [15, 23, 177, 324, 350, 367, 379, 591], "recoveri": 15, "wrapper": [16, 17, 21, 32, 55, 72, 73, 86, 87, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 169, 170, 171, 172, 175, 176, 178, 179, 180, 185, 189, 278, 282, 287, 323, 325, 326, 327, 328, 329, 330, 331, 332, 334, 337, 340, 342, 344, 376, 378, 380, 381, 384, 385, 397, 398, 399, 400, 563, 587, 589, 598, 618, 621, 622, 624, 630, 631, 634, 635, 637, 639, 640, 641], "popular": [16, 22, 622, 626, 635], "framework": [16, 18, 23, 28, 51, 120, 121, 122, 123, 126, 130, 136, 137, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 591, 612, 631, 632, 640, 641], "jumanji": [16, 18, 120, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 448], "envbas": [16, 17, 18, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 88, 120, 123, 127, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 215, 218, 229, 232, 245, 252, 253, 271, 272, 279, 302, 304, 340, 382, 409, 553, 554, 555, 559, 561, 562, 563, 624], "foundat": [16, 18, 24, 152, 153, 423, 593, 621, 635], "output": [16, 17, 18, 19, 20, 21, 22, 23, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 65, 68, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 137, 138, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 213, 218, 219, 221, 224, 225, 227, 228, 229, 230, 232, 234, 236, 239, 241, 244, 246, 250, 252, 253, 258, 259, 262, 263, 266, 267, 269, 271, 272, 273, 275, 277, 278, 280, 283, 286, 288, 289, 290, 291, 294, 296, 297, 298, 299, 302, 304, 305, 312, 313, 314, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 405, 591, 593, 595, 598, 605, 619, 620, 621, 622, 623, 624, 625, 628, 631, 632, 633, 634, 635, 636, 637, 640, 641], "infrastructur": [16, 19, 197, 634, 635], "transformedenv": [16, 21, 22, 30, 31, 88, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 215, 218, 221, 224, 225, 227, 229, 232, 233, 234, 240, 241, 242, 245, 246, 248, 252, 253, 254, 255, 258, 259, 260, 263, 264, 265, 266, 270, 271, 279, 302, 304, 340, 382, 392, 404, 441, 571, 591, 619, 620, 621, 622, 623, 624, 628, 629, 633, 634, 635, 636, 637, 638, 640, 641], "rewardsum": [16, 21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 212, 271, 382, 516, 634, 635], "stepcount": [16, 88, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 226, 227, 270, 271, 272, 287, 382, 521, 591, 619, 620, 621, 622, 623, 624, 629, 634, 635, 640], "parallel_env": [16, 153, 619, 640, 641], "100": [16, 32, 34, 35, 36, 38, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 95, 97, 108, 109, 114, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 224, 226, 233, 246, 255, 260, 263, 298, 306, 324, 326, 332, 337, 340, 375, 377, 379, 382, 383, 392, 406, 420, 544, 559, 567, 612, 620, 621, 623, 624, 626, 629, 633, 634, 635, 636, 638, 640, 641], "lock": [16, 60, 71, 86, 87, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 218, 227, 265, 279, 280, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 636], "partial": [16, 17, 32, 34, 35, 36, 38, 52, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 220, 221, 264, 265, 266, 341, 415, 622], "invers": [16, 23, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 221, 229, 232, 234, 239, 243, 246, 253, 255, 267, 269, 271, 273, 350, 356, 363, 367, 379, 382, 636], "marlgroupmaptyp": [16, 142, 143, 148, 149, 152, 153, 161, 162, 163, 164, 166, 634], "check_marl_group": 16, "auto": [16, 54, 89, 97, 116, 126, 131, 216, 217, 272, 278, 312, 349, 351, 357, 366, 368, 370, 371, 372, 401, 403, 586, 634, 635], "dynam": [16, 26, 34, 35, 36, 38, 80, 83, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 206, 356, 363, 401, 593, 598, 603, 621, 624, 636], "record": [16, 30, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 207, 214, 241, 326, 332, 337, 367, 375, 377, 379, 382, 383, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 409, 420, 459, 461, 462, 559, 589, 613, 620, 621, 625, 629, 634], "dm": [17, 619, 641], "abl": [17, 21, 22, 120, 141, 152, 153, 154, 159, 302, 304, 619, 621, 622, 625, 633, 634, 635, 636, 638], "simul": [17, 18, 19, 20, 24, 26, 27, 74, 121, 122, 123, 132, 136, 137, 155, 163, 164, 170, 208, 317, 591, 619, 621, 623, 624, 628, 632, 634, 635], "box": [17, 19, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 129, 131, 365, 375, 377, 379, 383, 631], "lib": [17, 18, 19, 24, 25, 26, 28, 29, 32, 34, 35, 36, 38, 50, 51, 52, 53, 66, 88, 120, 123, 126, 127, 130, 135, 138, 142, 143, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 221, 224, 233, 240, 241, 246, 248, 253, 255, 258, 265, 271, 278, 279, 382, 390, 442, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 559, 619, 620, 621, 622, 633, 635, 637, 638, 640, 641], "hope": [17, 30], "imit": [17, 362], "parent": [17, 20, 21, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 63, 69, 74, 88, 112, 119, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 221, 222, 225, 226, 227, 230, 233, 236, 237, 244, 246, 250, 258, 263, 264, 265, 266, 270, 271, 274, 275, 283, 302, 304, 326, 332, 337, 365, 367, 375, 377, 379, 382, 383, 389, 390, 392, 465, 466, 567, 571, 619, 627, 636, 640, 641], "subclass": [17, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 58, 60, 69, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 216, 217, 271, 278, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 337, 338, 340, 343, 344, 345, 347, 365, 367, 568, 570, 571, 573, 578, 580, 585, 586, 612, 620, 622, 627, 636, 638], "organis": [17, 84, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272, 620], "togeth": [17, 21, 30, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 70, 71, 96, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 251, 262, 271, 283, 284, 285, 302, 304, 323, 586, 591, 620, 622, 624, 634], "live": [17, 22, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 233, 326, 332, 337, 375, 377, 379, 382, 383, 492], "doe": [17, 18, 21, 22, 40, 42, 65, 72, 78, 79, 83, 86, 87, 88, 92, 93, 100, 102, 108, 110, 112, 119, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 280, 294, 295, 302, 304, 325, 326, 327, 328, 330, 331, 332, 337, 345, 346, 348, 350, 358, 364, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 415, 568, 619, 620, 621, 622, 624, 627, 634, 636, 638, 641], "respons": [17, 20, 22, 27, 34, 35, 36, 38, 41, 42, 47, 50, 52, 53, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 174, 175, 177, 178, 179, 180, 183, 186, 187, 190, 193, 203, 325, 327, 329, 330, 331, 332, 337, 379, 383, 415, 564, 591, 593, 626, 627, 631, 632, 641], "just": [17, 22, 23, 86, 87, 112, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 135, 136, 137, 138, 141, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 175, 176, 178, 179, 180, 213, 217, 224, 265, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 405, 591, 612, 619, 620, 621, 622, 623, 624, 625, 627, 631, 634, 635, 636, 638, 640, 641], "care": [17, 20, 21, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 338, 340, 347, 392, 619, 621, 623, 634, 635, 636, 638], "desir": [17, 18, 30, 32, 34, 35, 36, 38, 52, 59, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 210, 216, 218, 225, 227, 246, 248, 250, 251, 265, 271, 272, 275, 277, 288, 295, 297, 298, 305, 313, 314, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 343, 344, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 619, 623, 631, 634, 635, 636, 638], "parametr": [17, 307, 344, 349, 351, 356, 363, 370, 619, 621], "pair": [17, 22, 55, 79, 86, 87, 120, 123, 124, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 255, 265, 270, 283, 302, 325, 327, 328, 330, 331, 341, 344, 365, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 578, 600, 619, 620, 621, 625, 626, 633, 636, 641], "state_spec": [17, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 225, 230, 243, 246, 271, 273, 274, 382, 636, 641], "empti": [17, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 98, 120, 123, 126, 130, 137, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 206, 229, 232, 250, 252, 266, 272, 275, 277, 280, 324, 325, 326, 327, 328, 330, 331, 332, 337, 343, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 396, 402, 612, 619, 636], "reward_spec": [17, 18, 19, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 218, 219, 224, 225, 229, 230, 232, 242, 243, 252, 256, 257, 258, 260, 262, 269, 271, 273, 274, 280, 382, 591, 621, 631, 634, 635, 636, 641], "done_spec": [17, 18, 19, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 229, 230, 232, 233, 243, 252, 262, 269, 271, 273, 382, 634, 635, 636, 641], "termin": [17, 18, 19, 22, 26, 32, 34, 35, 36, 38, 52, 66, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 100, 108, 120, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 142, 143, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 178, 179, 180, 185, 213, 214, 217, 218, 233, 239, 252, 265, 273, 302, 304, 340, 345, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 385, 386, 387, 388, 389, 401, 402, 591, 612, 619, 620, 621, 631, 634, 635, 636, 640, 641], "input_spec": [17, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 225, 229, 230, 231, 244, 248, 252, 253, 258, 259, 262, 263, 264, 265, 269, 271, 272, 273, 276, 382, 621, 636], "full_action_spec": [17, 120, 123, 126, 130, 138, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 175, 178, 179, 180, 214, 230, 634, 635], "full_state_spec": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 214, 230], "output_spec": [17, 19, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 272, 273, 280, 382, 636], "full_observation_spec": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180], "full_reward_spec": [17, 18, 19, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 218, 230, 252, 634, 635], "full_done_spec": [17, 18, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 218, 230, 252, 634, 635], "carri": [17, 19, 50, 62, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 265, 280, 365, 375, 377, 379, 383, 620, 622, 634, 635, 636, 638], "spec_lock": [17, 126], "modif": [17, 19, 22, 24, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 213, 236, 239, 326, 332, 337, 365, 375, 377, 379, 382, 383, 591, 621, 636], "children": [17, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "unlock": [17, 22, 60, 71, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "set_spec_lock_": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "reason": [17, 21, 22, 23, 27, 83, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 275, 304, 326, 332, 337, 375, 377, 379, 382, 383, 591, 619, 620, 621, 626, 627, 634, 636, 638], "cach": [17, 20, 32, 35, 36, 38, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 102, 108, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 194, 212, 217, 229, 232, 250, 271, 272, 277, 324, 406, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586, 591], "modifi": [17, 18, 22, 26, 27, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 225, 227, 236, 239, 241, 243, 250, 265, 271, 272, 275, 277, 280, 312, 325, 326, 327, 328, 330, 331, 332, 337, 343, 344, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 552, 591, 619, 620, 621, 623, 624, 634, 635, 636], "often": [17, 22, 27, 350, 365, 367, 375, 377, 379, 383, 415, 619, 620, 624, 626, 636, 638, 641], "principl": [17, 591], "new_spec": 17, "eras": [17, 21, 22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272], "relock": 17, "wa": [17, 22, 24, 26, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 91, 102, 107, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 185, 213, 221, 239, 272, 325, 326, 327, 328, 330, 331, 332, 337, 348, 350, 364, 367, 369, 376, 378, 379, 380, 381, 384, 402, 565, 567, 570, 571, 572, 573, 575, 578, 580, 586, 620, 621, 624, 625, 633, 634, 638, 640], "previous": [17, 23, 81, 402, 621, 641], "importantli": [17, 341, 344], "action_s": 17, "prealloc": [17, 22, 150, 158, 636], "necessarili": [17, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 641], "present": [17, 18, 19, 22, 52, 65, 66, 68, 69, 74, 78, 79, 83, 86, 87, 88, 101, 102, 107, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 234, 255, 259, 265, 270, 272, 288, 289, 290, 291, 292, 293, 300, 302, 304, 311, 312, 325, 326, 327, 328, 330, 331, 332, 337, 340, 343, 344, 345, 346, 348, 349, 350, 351, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 563, 619, 629, 633, 634, 635, 638, 640], "0s": [17, 78, 83, 265, 622], "step_and_maybe_reset": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 591, 624, 631], "next": [17, 18, 19, 23, 27, 34, 35, 38, 53, 56, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 92, 93, 100, 102, 108, 109, 114, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 136, 137, 138, 142, 143, 144, 148, 149, 150, 151, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 178, 179, 180, 183, 185, 188, 190, 192, 193, 195, 206, 212, 214, 217, 218, 220, 221, 226, 227, 229, 232, 233, 234, 239, 240, 241, 242, 244, 248, 252, 253, 255, 258, 259, 263, 265, 267, 270, 273, 278, 279, 280, 302, 304, 316, 317, 323, 340, 348, 349, 351, 352, 353, 355, 356, 357, 358, 363, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 389, 392, 408, 409, 412, 433, 434, 591, 612, 620, 622, 623, 625, 629, 631, 636, 637, 640, 641], "step_mdp": [17, 60, 71, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 302, 304, 622, 624, 636, 640, 641], "done_kei": [17, 18, 19, 56, 88, 92, 93, 100, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 217, 221, 233, 255, 263, 382, 492, 634, 635], "_reset": [17, 18, 22, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 215, 217, 218, 221, 229, 232, 240, 252, 267, 634], "data_": [17, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "append": [17, 19, 20, 21, 27, 30, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 182, 185, 195, 217, 224, 225, 244, 255, 265, 272, 278, 297, 302, 304, 313, 591, 593, 619, 620, 621, 622, 623, 631, 634, 635, 636, 637, 638, 640], "set_se": [17, 18, 32, 34, 35, 36, 38, 50, 52, 53, 120, 121, 122, 123, 126, 130, 136, 137, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 226, 227, 246, 253, 258, 264, 266, 272, 591, 623, 627, 629, 636, 640, 641], "seed": [17, 18, 32, 34, 35, 36, 38, 50, 52, 53, 68, 69, 72, 73, 84, 120, 123, 126, 130, 138, 144, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 165, 170, 171, 172, 175, 178, 179, 180, 181, 215, 218, 229, 232, 239, 252, 272, 390, 415, 419, 420, 472, 634], "determinist": [17, 32, 34, 35, 36, 38, 42, 44, 47, 50, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 210, 225, 250, 265, 271, 272, 275, 277, 289, 299, 308, 316, 317, 326, 332, 337, 339, 341, 343, 344, 347, 349, 350, 365, 367, 375, 377, 379, 382, 383, 409, 599, 619, 620, 621, 622, 623, 625, 626, 629, 634, 636, 640, 641], "preced": [17, 123, 221, 418, 622], "risk": [17, 251], "overlap": [17, 72, 114], "mark": [17, 34, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 267, 302, 304, 385, 387, 388, 627, 638], "trail": [17, 63, 177, 279, 631], "treat": [17, 21, 625, 626], "figur": [17, 21, 619, 621, 622, 635, 636, 641], "brief": [17, 621, 624, 626, 638], "entri": [17, 19, 21, 22, 32, 35, 36, 38, 56, 60, 71, 79, 80, 81, 82, 84, 85, 86, 87, 88, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 142, 143, 150, 151, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 213, 217, 221, 223, 224, 227, 228, 229, 230, 232, 233, 236, 240, 242, 244, 246, 248, 250, 253, 255, 258, 260, 262, 263, 264, 265, 267, 270, 272, 274, 277, 279, 297, 302, 306, 313, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 340, 349, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 619, 621, 622, 624, 625, 626, 628, 634, 635, 636, 637, 638, 640, 641], "metaclass": [17, 126, 131], "everi": [17, 27, 32, 34, 35, 36, 38, 39, 52, 53, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 110, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 263, 264, 279, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 305, 307, 308, 309, 311, 312, 314, 315, 316, 326, 332, 337, 338, 340, 347, 350, 364, 365, 367, 375, 377, 379, 382, 383, 415, 619, 620, 621, 622, 624, 625, 634, 635, 636], "flank": [17, 622], "dual": 17, "strictli": [17, 27, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 242, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383, 619, 621], "union": [17, 34, 47, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 250, 275, 277, 288, 289, 290, 291, 292, 293, 300, 305, 311, 324, 326, 332, 337, 343, 355, 357, 368, 375, 377, 379, 382, 383, 411, 560, 563], "interpret": [17, 65, 66, 68, 69, 192, 193, 591, 612, 620], "truncat": [17, 18, 19, 22, 32, 34, 35, 36, 38, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 93, 100, 102, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 178, 179, 180, 185, 213, 214, 233, 234, 239, 245, 252, 255, 259, 263, 265, 272, 273, 302, 304, 321, 330, 340, 385, 433, 434, 521, 619, 621, 624, 634, 641], "look": [17, 19, 22, 24, 26, 27, 86, 87, 88, 102, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 226, 239, 250, 251, 275, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 345, 346, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 621, 622, 623, 624, 625, 626, 627, 628, 629, 634, 635, 636, 637, 638, 640, 641], "assess": [17, 22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 71, 142, 143, 166, 175, 619], "split_trajectori": [17, 32, 34, 35, 36, 38, 42, 44, 47, 50, 78, 83, 102, 108, 109], "adjac": [17, 56, 236, 340], "junction": 17, "miss": [17, 22, 23, 25, 26, 60, 88, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 239, 270, 272, 278, 282, 326, 332, 337, 345, 346, 348, 351, 367, 370, 375, 377, 379, 382, 383, 590, 612, 619, 622, 632], "inittrack": [17, 302, 304, 340, 499, 619, 622], "our": [17, 18, 21, 26, 27, 30, 42, 68, 221, 226, 392, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 633, 634, 635, 637, 638, 640], "tutori": [17, 21, 151, 184, 588, 618, 619, 620, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 636, 637, 638, 639, 641], "inform": [17, 18, 19, 21, 23, 32, 34, 35, 36, 38, 42, 44, 47, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 83, 86, 87, 88, 101, 102, 120, 123, 126, 127, 130, 133, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 287, 288, 305, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 415, 419, 472, 619, 620, 621, 622, 623, 624, 631, 634, 635, 636, 638, 640], "scratch": [17, 27, 620, 636], "mission": 18, "irrespect": [18, 343, 344], "statu": [18, 46, 126, 189, 190], "mostli": [18, 22, 32, 392, 628, 638, 641], "Its": [18, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 279, 326, 332, 337, 343, 375, 377, 379, 382, 383, 389], "success": [18, 78, 79, 80, 81, 82, 83, 84, 85, 172, 174, 177, 178, 185, 190, 192, 221, 267, 301, 351, 371, 591, 620, 627, 629, 632, 636, 638, 640], "inspir": [18, 623, 636], "howev": [18, 24, 26, 54, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 278, 279, 326, 332, 337, 348, 350, 351, 364, 367, 369, 370, 375, 377, 379, 382, 383, 591, 619, 620, 622, 623, 626, 636, 638, 641], "gone": [18, 23, 24, 340], "sometim": [18, 74, 622, 641], "hard": [18, 26, 35, 36, 38, 114, 124, 125, 150, 620, 641], "accommod": [18, 19, 612, 624, 625], "extern": [18, 229, 232, 280, 324, 335, 336, 612, 631, 634, 641], "adopt": [18, 24, 619, 641], "moreov": 18, "facilit": [18, 26, 249, 250, 265, 275, 277, 283, 284, 285, 619, 622, 625, 636], "instal": [18, 24, 29, 42, 44, 47, 79, 82, 120, 123, 126, 130, 135, 138, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 170, 171, 172, 175, 177, 178, 179, 180, 190, 394, 403, 415, 590, 619, 621, 622, 623, 624, 625, 626, 627, 628, 629, 634, 635, 641], "virtual": [18, 129], "concomittantli": 18, "fortun": [18, 21, 622, 623, 624, 625, 628], "decor": [18, 27, 209, 211, 282, 302, 304, 365, 385, 386, 387, 388, 404, 591, 622, 640], "set_gym_backend": [18, 32, 34, 35, 36, 38, 52, 120, 123, 126, 129, 130, 138, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 175, 178, 179, 180, 217, 624, 640], "relev": [18, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 385, 386, 387, 388, 389, 400, 623, 636], "gym_backend": [18, 211], "env1": [18, 287, 633], "venv": 18, "python3": [18, 25, 26, 29], "site": [18, 25, 26, 84, 123, 211], "env2": [18, 633], "_env": [18, 25, 129, 641], "classic_control": 18, "pendulumenv": [18, 636], "0x15147e190": 18, "0x1629916a0": 18, "further": [18, 22, 24, 383, 619, 621, 623, 624], "mo_gymnasium": [18, 140, 169, 242], "handi": [18, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 628], "v0": [18, 35, 36, 38, 60, 71, 86, 87, 120, 123, 126, 130, 132, 135, 136, 137, 138, 139, 140, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 225, 242, 272, 279, 280, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 404, 559], "26": [18, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 195, 196, 226], "fun": [18, 211, 282, 621, 634, 635], "effect": [18, 22, 34, 52, 53, 60, 65, 66, 68, 69, 72, 73, 78, 83, 86, 87, 88, 101, 102, 106, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 217, 221, 227, 272, 325, 326, 327, 328, 330, 331, 332, 337, 350, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 415, 420, 591, 619, 625, 634, 638, 641], "autoresettransform": [18, 476], "skip": [18, 20, 22, 39, 78, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 237, 239, 244, 270, 272, 326, 331, 332, 337, 341, 344, 351, 365, 370, 375, 377, 379, 382, 383, 385, 386, 387, 388, 391, 392, 407, 409, 419, 420, 472, 619, 620, 632, 636], "fine": [18, 68, 69, 72, 73, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 218, 241, 383, 591, 623, 627, 637], "grain": [18, 68, 69, 72, 73, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 218], "invalid": [18, 88, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 166, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 306, 326, 332, 333, 337, 375, 377, 379, 382, 383, 632], "nan": [18, 217, 278, 476], "auto_reset": [18, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 217, 636], "auto_reset_replac": [18, 217], "replac": [18, 21, 25, 26, 78, 83, 88, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 217, 231, 233, 240, 279, 280, 301, 324, 326, 332, 337, 349, 351, 357, 363, 368, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 432, 434, 476, 634, 638, 640], "placehold": [18, 131, 132, 175, 233, 272, 278], "manual_se": [18, 57, 61, 65, 68, 72, 73, 80, 84, 85, 86, 87, 96, 108, 109, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 215, 217, 226, 227, 231, 246, 255, 258, 264, 266, 280, 298, 301, 306, 310, 312, 325, 327, 328, 330, 331, 339, 344, 347, 348, 349, 351, 352, 356, 363, 370, 376, 378, 380, 381, 384, 623, 627, 629, 634, 635, 636, 640, 641], "autoresettinggymenv": [18, 217], "_step": [18, 21, 22, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 236, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 382], "td_reset": [18, 217], "exclud": [18, 27, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 79, 84, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 195, 196, 212, 217, 221, 234, 329, 337, 350, 364, 367, 379, 634, 635, 638], "r": [18, 20, 23, 86, 87, 89, 123, 172, 175, 176, 190, 193, 197, 214, 215, 217, 224, 226, 227, 246, 260, 267, 270, 279, 280, 287, 325, 327, 328, 330, 331, 344, 367, 376, 378, 380, 381, 384, 390, 591, 620, 636, 641], "break_when_any_don": [18, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 217, 270, 287, 340, 635], "squeez": [18, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 217, 218, 221, 226, 261, 264, 288, 619, 623, 636, 638], "creation": [18, 19, 150, 158, 196, 332, 379, 472, 567, 586, 641], "imposs": [18, 20, 68, 72, 73, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 348, 350, 364, 367, 369], "forecast": 18, "awar": [18, 26, 60, 71, 88, 90, 95, 96, 97, 98, 110, 112, 116, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 271, 302, 304, 324, 382, 620, 622], "detect": [18, 20, 85, 87, 89, 174, 178, 365, 374, 375, 377, 379, 383, 401, 577, 591, 593], "return_contigu": [18, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 633], "tensordictbas": [18, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 114, 120, 123, 126, 128, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 204, 205, 212, 213, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 233, 234, 235, 236, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 280, 286, 298, 301, 302, 304, 312, 314, 325, 326, 327, 328, 330, 331, 332, 337, 340, 343, 344, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 415, 564, 565, 567, 568, 570, 571, 573, 574, 575, 577, 578, 580, 586, 619, 634, 636], "envwithdynamicspec": 18, "max_count": 18, "bool": [18, 19, 22, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 94, 95, 96, 97, 98, 101, 102, 104, 106, 107, 108, 109, 110, 115, 116, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 206, 212, 213, 214, 215, 217, 218, 221, 222, 226, 227, 229, 231, 232, 233, 234, 236, 239, 241, 243, 244, 245, 246, 248, 250, 252, 253, 255, 257, 258, 259, 262, 263, 265, 268, 269, 270, 272, 273, 274, 275, 277, 279, 280, 282, 286, 287, 288, 290, 291, 297, 298, 302, 303, 304, 305, 306, 313, 314, 319, 320, 321, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 339, 340, 341, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 400, 401, 404, 407, 408, 409, 411, 412, 415, 419, 420, 424, 425, 426, 427, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 474, 476, 477, 502, 504, 505, 515, 521, 526, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 563, 564, 565, 567, 568, 570, 571, 573, 575, 577, 578, 579, 580, 581, 582, 584, 586, 591, 620, 621, 623, 631, 632, 636, 640, 641], "full": [18, 19, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 188, 190, 195, 196, 197, 298, 302, 304, 325, 327, 328, 330, 331, 332, 337, 344, 367, 375, 376, 377, 378, 379, 380, 381, 384, 405, 591, 612, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "_set_se": [18, 215, 218, 229, 232, 252, 636], "int": [18, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 94, 95, 96, 97, 98, 101, 102, 103, 104, 106, 108, 109, 110, 114, 115, 116, 118, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 142, 143, 144, 145, 146, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 205, 206, 214, 216, 217, 218, 220, 221, 222, 223, 225, 228, 231, 236, 237, 239, 243, 244, 245, 246, 248, 250, 251, 254, 261, 262, 263, 266, 269, 270, 272, 274, 275, 277, 286, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 301, 303, 305, 306, 308, 309, 311, 312, 314, 315, 316, 319, 320, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341, 343, 344, 348, 349, 350, 357, 359, 360, 364, 365, 366, 367, 368, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 391, 392, 394, 397, 399, 400, 401, 405, 406, 407, 409, 411, 415, 418, 419, 420, 424, 425, 426, 427, 428, 430, 433, 434, 437, 438, 439, 442, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 462, 463, 464, 471, 472, 474, 476, 477, 479, 480, 481, 482, 487, 490, 496, 502, 503, 504, 506, 509, 512, 519, 520, 521, 524, 527, 528, 531, 544, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 579, 580, 581, 586, 623, 636, 638], "lazystackedtensordict": [18, 52, 71, 78, 86, 87, 96, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 633], "field": [18, 19, 22, 32, 34, 35, 36, 38, 52, 53, 56, 60, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 96, 97, 101, 108, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 218, 229, 232, 233, 234, 239, 248, 252, 253, 255, 259, 262, 263, 265, 270, 272, 273, 283, 284, 285, 287, 296, 297, 298, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 346, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 472, 553, 590, 591, 620, 632, 636], "float32": [18, 21, 34, 35, 38, 58, 60, 65, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 95, 96, 97, 101, 102, 108, 116, 120, 121, 122, 123, 126, 129, 130, 131, 136, 137, 138, 144, 147, 148, 149, 150, 151, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 206, 212, 214, 218, 229, 232, 233, 234, 239, 242, 246, 248, 252, 253, 255, 259, 262, 263, 265, 268, 273, 283, 284, 285, 287, 296, 297, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 346, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 488, 631, 636], "is_shar": [18, 22, 34, 35, 38, 52, 56, 60, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 95, 96, 97, 101, 108, 116, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 185, 212, 214, 218, 229, 232, 233, 234, 239, 248, 252, 253, 255, 259, 262, 263, 265, 273, 279, 283, 284, 285, 287, 296, 297, 298, 302, 304, 312, 313, 314, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 340, 341, 343, 346, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 636], "exclusive_field": [18, 52, 78, 86, 87, 96, 120, 172, 175, 176, 185, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "stack_dim": [18, 52, 78, 86, 87, 96, 120, 172, 175, 176, 185, 205, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 425], "absenc": [18, 22], "dramat": 18, "carefulli": [18, 183, 634, 635, 641], "against": [18, 24, 26, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 297, 298, 313, 314, 326, 332, 337, 339, 341, 343, 344, 349, 351, 363, 368, 370, 371, 372, 375, 377, 379, 382, 383, 621, 634, 635], "plain": [18, 27, 349, 351, 357, 363, 368, 370, 371, 372, 386, 387, 388, 624], "deseri": 18, "larg": [18, 23, 59, 86, 87, 101, 102, 108, 109, 176, 229, 232, 275, 324, 325, 327, 328, 330, 331, 332, 348, 350, 364, 367, 369, 376, 378, 379, 380, 381, 384, 567, 620, 621, 632, 634, 635, 638], "expens": [18, 20, 53, 102, 108, 109, 390, 638], "check_env_spec": [18, 20, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 214, 239, 252, 273, 390, 621, 634, 635, 636], "vari": [18, 19, 129, 131, 132, 152, 153, 155, 163, 251, 623, 635], "absent": [18, 60, 71, 79, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 259, 272], "view": [19, 27, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 83, 84, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 305, 326, 332, 337, 375, 377, 379, 382, 383, 591, 624, 636, 638, 640, 641], "act": [19, 22, 23, 108, 109, 152, 153, 272, 296, 349, 351, 352, 363, 368, 370, 371, 372, 622, 623, 634, 635, 638, 640], "paradigm": [19, 32, 635], "decpodp": 19, "markov": [19, 624, 641], "game": [19, 20, 23, 24, 78, 123, 142, 143, 148, 149, 226, 288, 392, 623, 628], "thank": [19, 170, 195, 196, 383, 619, 623, 624, 640], "carrier": [19, 621, 622, 624, 638], "particular": [19, 79, 80, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 272, 326, 332, 337, 375, 377, 379, 382, 383, 620, 622, 624, 633, 635, 638], "thu": [19, 364, 635], "vma": [19, 163, 164, 390, 458, 634, 635], "robot": [19, 24, 26, 83, 250, 275, 277, 367, 623, 635], "vmasenv": [19, 390, 458, 634, 635], "balanc": [19, 101, 102, 124, 125, 324, 619, 620], "num_env": [19, 32, 35, 36, 38, 50, 120, 129, 133, 146, 163, 164, 171, 172, 175, 181, 390, 445, 449, 612, 634, 635], "n_agent": [19, 163, 164, 390, 634, 635], "td": [19, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 101, 102, 114, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 139, 140, 148, 149, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 175, 176, 178, 179, 180, 183, 185, 186, 190, 212, 215, 218, 220, 222, 226, 227, 229, 230, 231, 232, 240, 241, 242, 244, 246, 255, 258, 262, 265, 268, 272, 279, 283, 284, 285, 287, 296, 297, 301, 312, 313, 322, 325, 326, 327, 328, 330, 331, 332, 337, 339, 341, 342, 343, 346, 375, 376, 377, 378, 379, 380, 381, 383, 384, 386, 387, 388, 391, 405, 413, 591, 605, 619, 620, 622, 635, 636, 637, 640], "info": [19, 35, 38, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 106, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 142, 143, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 175, 178, 179, 180, 190, 239, 273, 275, 278, 281, 400, 570, 571, 572, 573, 624, 629, 631, 634, 635, 638, 640], "ground_rew": 19, "pos_rew": 19, "16": [19, 20, 32, 35, 36, 38, 52, 84, 88, 102, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 324, 326, 329, 332, 337, 375, 377, 379, 382, 383, 612, 622, 638], "style": [19, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 187, 197, 203, 375, 420], "info_spec": [19, 150], "agent_i_action_spec": 19, "agent_i_reward_spec": 19, "agent_i_observation_spec": 19, "prefix": [19, 56, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 267, 270, 272, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 351, 365, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 391, 401, 415, 419, 472, 622, 626, 631, 641], "exactli": [19, 88, 120, 123, 126, 130, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 310, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383, 619, 622, 627, 634, 635], "action_kei": [19, 21, 32, 34, 35, 36, 38, 42, 44, 47, 50, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 214, 215, 231, 241, 244, 286, 301, 312, 340, 342, 474, 634, 635], "reward_kei": [19, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 408, 412, 634, 635], "right": [19, 22, 25, 26, 56, 102, 108, 180, 226, 332, 337, 620, 621, 623, 635, 636, 641], "set_kei": [19, 233, 348, 350, 351, 353, 356, 357, 358, 363, 364, 365, 367, 368, 369, 370, 375, 377, 379, 383, 389, 619, 634, 635], "awai": [19, 621, 624, 634, 635, 640], "eas": [19, 634, 635], "access": [19, 21, 26, 27, 30, 32, 34, 35, 36, 38, 52, 53, 65, 80, 81, 82, 88, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 221, 250, 271, 275, 324, 326, 332, 337, 375, 377, 379, 382, 383, 401, 402, 403, 563, 574, 589, 590, 605, 619, 624, 634, 635, 636, 638, 640], "leaf": [19, 21, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 240, 263, 265, 271, 344], "abov": [19, 21, 22, 26, 54, 75, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 271, 303, 320, 321, 326, 332, 337, 375, 377, 379, 382, 383, 591, 619, 621, 623, 624, 625, 634, 635, 636, 641], "would": [19, 21, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 302, 304, 305, 326, 332, 337, 344, 375, 377, 379, 382, 383, 620, 621, 622, 624, 626, 627, 636, 638, 640, 641], "ey": 20, "report": [20, 121, 122, 136, 137, 419, 628], "foremost": 20, "callback": [20, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 635], "callabl": [20, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 120, 123, 126, 127, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 211, 216, 218, 225, 226, 227, 233, 239, 243, 265, 272, 273, 282, 288, 305, 326, 332, 337, 344, 365, 375, 377, 379, 382, 383, 390, 418, 419, 420, 554, 555, 561, 562, 563, 578, 620, 638], "upon": [20, 27, 41, 634, 636], "ad": [20, 23, 32, 34, 35, 36, 38, 52, 56, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 258, 270, 272, 312, 325, 326, 327, 328, 330, 331, 332, 337, 348, 350, 351, 353, 358, 364, 367, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 591, 620, 622, 623, 625, 631, 634, 638, 640, 641], "save": [20, 27, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 98, 100, 110, 111, 112, 116, 117, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 278, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 391, 392, 394, 400, 415, 419, 420, 472, 612, 613, 623, 627, 628, 629, 634, 635], "disk": [20, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 91, 95, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 415, 619, 620, 622, 623, 627, 628, 634, 638], "tensordictrecord": 20, "imag": [20, 23, 26, 30, 83, 86, 90, 221, 223, 226, 228, 250, 268, 277, 305, 390, 392, 619, 620, 623, 624, 628, 635, 637, 641], "pixel": [20, 21, 22, 26, 60, 69, 85, 123, 124, 125, 129, 131, 132, 155, 221, 223, 228, 233, 236, 238, 246, 248, 250, 254, 268, 275, 277, 290, 308, 309, 390, 392, 619, 620, 622, 623, 628, 634, 637, 638, 640, 641], "atari": [20, 22, 23, 78, 79, 80, 81, 83, 84, 85, 90, 221, 288, 392, 623, 628, 641], "videorecord": [20, 30, 390, 621, 628, 629, 634], "csvlogger": [20, 30, 390, 392, 459, 613, 620, 628, 629, 634], "wandblogg": [20, 462, 613, 628], "tensorboardlogg": [20, 461, 559, 613, 628], "tag": [20, 26, 30, 174, 175, 177, 187, 200, 203, 390, 392, 394, 397, 563, 591, 628, 629, 631, 634], "mp4": [20, 390, 392, 394, 629, 634], "video_format": [20, 390, 392, 394, 459, 629, 634], "whc": 20, "cwh": 20, "dummi": [20, 160, 185, 390, 619, 623, 627, 641], "exp": [20, 307], "al": [20, 32, 34, 35, 36, 38, 52, 129, 131, 233, 248, 492, 623, 641], "pong": [20, 32, 34, 35, 36, 38, 52, 78, 146, 248, 623, 641], "v5": [20, 32, 34, 35, 36, 38, 52, 129, 131, 146, 233, 248, 623, 641], "append_transform": [20, 21, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 207, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 239, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276, 278, 279, 280, 287, 302, 304, 382, 390, 591, 612, 619, 622, 631, 634, 636, 638, 640, 641], "grow": [20, 96], "tediou": [20, 624], "workspac": [20, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 239], "assum": [20, 22, 25, 34, 35, 36, 37, 38, 39, 46, 49, 50, 54, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 72, 73, 74, 75, 76, 77, 79, 81, 83, 84, 85, 92, 93, 100, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 206, 220, 223, 228, 236, 250, 251, 258, 265, 272, 275, 277, 287, 302, 304, 347, 353, 357, 358, 370, 382, 392, 564, 619, 621, 633, 636], "pixelrendertransform": [20, 634], "stream": [20, 83, 90], "alik": [20, 390], "envcreat": [20, 34, 50, 51, 150, 158, 270, 280, 390, 559, 560, 563, 619, 620, 640, 641], "render_mod": [20, 390, 445, 449, 636], "rgb_arrai": [20, 390, 634, 635, 636], "uncom": [20, 628], "line": [20, 26, 78, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 620, 628, 634, 635], "__name__": [20, 32, 34, 35, 36, 38, 51, 52, 66, 127, 280, 390, 620, 640], "__main__": [20, 32, 34, 35, 36, 38, 51, 52, 66, 127, 280, 390, 640], "comment": [20, 620, 640], "pixels_record": [20, 390], "close": [20, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 52, 66, 88, 120, 130, 145, 173, 174, 177, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 241, 271, 280, 348, 350, 364, 367, 379, 382, 390, 566, 619, 620, 624, 631, 633, 634, 636, 640], "purpos": [20, 21, 22, 26, 30, 35, 36, 38, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 197, 221, 325, 327, 328, 330, 331, 348, 350, 362, 364, 367, 369, 376, 378, 379, 380, 381, 384, 559, 612, 619, 621, 622, 623, 626, 628, 634, 635, 637, 641], "raw": [21, 23, 90, 199, 239, 269, 273, 303, 320, 321, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586, 620, 623, 627, 636], "torchvis": [21, 30, 250, 277, 394, 634, 640, 641], "from_pixel": [21, 22, 30, 121, 122, 124, 125, 129, 131, 132, 136, 137, 155, 221, 254, 390, 392, 442, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 619, 620, 622, 624, 628, 629, 637, 638, 640, 641], "totensorimag": [21, 69, 85, 221, 254, 526, 620, 622, 623, 638, 640, 641], "resiz": [21, 69, 85, 221, 512, 620, 622, 623, 624, 638, 641], "64": [21, 69, 78, 83, 86, 87, 176, 221, 254, 290, 291, 300, 302, 304, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 463, 598, 612, 619, 620, 621, 622, 623, 625, 629, 633, 636, 638, 640, 641], "appar": [21, 407], "bring": [21, 621, 624, 641], "speedup": [21, 22, 27, 634, 641], "kind": [21, 68, 74, 626, 634, 638], "great": [21, 22, 26, 27, 623, 632, 634, 640], "consult": 21, "interest": [21, 22, 341, 344, 620, 621, 624, 635, 636, 641], "resize_par": 21, "inv": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 224, 231, 234, 239, 248, 255, 260, 262, 267, 271, 274, 382, 636], "revers": 21, "chain": [21, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 138, 170, 176, 178, 179, 194, 195, 225, 231, 288, 317, 325, 327, 328, 330, 331, 346, 376, 378, 380, 381, 384, 591, 641], "taken": [21, 53, 57, 59, 61, 62, 64, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 214, 254, 306, 619, 621, 622, 625, 634, 635, 636], "in_keys_inv": [21, 194, 199, 207, 224, 229, 230, 232, 239, 246, 247, 248, 252, 253, 255, 260, 269, 271, 273, 274, 483, 488, 489, 491, 619, 633, 636, 641], "doubletofloat": [21, 491, 619, 621, 633], "float64": [21, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 124, 125, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 225, 229, 232, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "paragraph": [21, 22], "in_": 21, "out_": 21, "perspect": [21, 183, 298, 358, 621, 623], "inner": [21, 22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 231, 272, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586, 613, 620, 621, 635, 641], "outer": [21, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272, 613, 619, 620, 641], "ob": [21, 23, 27, 56, 60, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 101, 108, 109, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 212, 215, 217, 226, 229, 230, 232, 246, 260, 262, 268, 290, 291, 292, 293, 313, 322, 349, 351, 352, 357, 363, 368, 370, 371, 372, 385, 386, 387, 388, 620, 623, 633, 634, 636, 638, 640, 641], "obs_standard": 21, "similarli": [21, 50, 88, 107, 112, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 244, 326, 332, 337, 345, 346, 356, 363, 375, 377, 379, 382, 383, 385, 591, 641], "seen": [21, 42, 44, 47, 50, 60, 71, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 230, 619, 620, 622, 626, 634, 635, 638], "out_keys_inv": [21, 194, 199, 207, 224, 229, 230, 232, 239, 246, 247, 248, 252, 253, 260, 262, 269, 271, 273, 274, 483, 488, 489, 491, 636], "produc": [21, 34, 60, 71, 108, 214, 217, 218, 283, 285, 288, 305, 310, 344, 385, 392, 621, 622, 623, 624, 625, 627, 638, 641], "illustr": [21, 619, 620, 625, 638], "renametransform": [21, 69, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 511], "renam": [21, 60, 69, 71, 86, 87, 171, 176, 212, 253, 255, 272, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 619], "schemat": 21, "outermost": 21, "innermost": 21, "similar": [21, 63, 68, 83, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 276, 277, 279, 280, 283, 285, 324, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 344, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 566, 582, 619, 620, 621, 622, 623, 625, 626, 627, 628, 636, 638, 640, 641], "transform_action_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 230, 243, 246, 271, 273, 274, 382], "pseudocod": 21, "could": [21, 22, 23, 25, 56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 344, 375, 377, 379, 382, 383, 612, 620, 621, 628, 634, 635, 637, 641], "spec_from_random_valu": 21, "_apply_transform": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 382, 636, 641], "rand": [21, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 96, 121, 122, 136, 137, 144, 148, 149, 161, 162, 215, 218, 229, 232, 252, 262, 341, 342, 348, 349, 351, 352, 353, 355, 356, 357, 363, 365, 367, 368, 370, 371, 372, 375, 377, 379, 383, 636, 640, 641], "did": [21, 68, 278, 620, 621, 627, 638, 641], "_inv_apply_transform": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 271, 382, 636, 641], "actiondiscret": [21, 474], "rand_act": [21, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 185, 218, 272, 624], "action_discret": 21, "counterpart": [21, 221], "obtain": [21, 26, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 196, 220, 250, 264, 277, 287, 411, 619, 621, 624, 625, 626, 634, 635], "addonetoob": 21, "There": [21, 29, 69, 86, 87, 172, 176, 271, 302, 304, 325, 327, 328, 330, 331, 348, 367, 376, 378, 380, 381, 384, 621, 622, 623, 625, 627, 634, 635, 636, 638, 640, 641], "Is": [21, 271], "ident": [21, 34, 35, 38, 68, 69, 72, 73, 86, 87, 95, 108, 120, 123, 126, 129, 130, 131, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 233, 262, 271, 280, 325, 327, 328, 330, 331, 349, 351, 363, 368, 370, 371, 372, 376, 378, 380, 381, 384, 385, 386, 387, 388, 561, 562, 620, 624, 634, 635], "rewrit": [21, 271], "otherwis": [21, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 108, 109, 120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 222, 226, 227, 231, 239, 246, 264, 265, 266, 270, 271, 272, 279, 282, 297, 303, 313, 320, 321, 325, 326, 327, 328, 330, 331, 332, 337, 344, 347, 349, 351, 360, 365, 366, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 409, 411, 565, 566, 567, 568, 570, 571, 572, 573, 575, 578, 580, 582, 586, 619, 620, 621, 622, 631, 636, 641], "_call": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 231, 233, 234, 235, 236, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 382, 631, 636], "_inv_cal": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 214, 271, 382], "overwrit": [21, 271], "till": [21, 271, 278], "encapsul": [21, 271, 624, 625, 626], "don": [21, 22, 23, 25, 26, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 170, 197, 221, 271, 306, 324, 612, 620, 621, 623, 627, 638, 640, 641], "forget": [21, 271], "transform_output_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 273, 280, 382], "transform_input_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 218, 225, 229, 230, 231, 244, 248, 252, 253, 258, 262, 263, 264, 265, 269, 271, 273, 276, 382], "transform_observation_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 222, 223, 224, 225, 228, 229, 230, 233, 234, 236, 238, 240, 241, 243, 244, 246, 248, 252, 253, 254, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 278, 279, 280, 382, 636], "transform_state_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 230, 243, 246, 271, 273, 274, 382], "transform_reward_spec": [21, 88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 219, 224, 225, 229, 230, 234, 241, 242, 243, 244, 252, 253, 256, 257, 258, 259, 260, 262, 263, 269, 271, 273, 274, 280, 382, 591, 631], "undo": [21, 183], "addonetoact": 21, "subtract": [21, 188, 264], "properti": [21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 120, 123, 126, 130, 138, 144, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 270, 271, 272, 279, 280, 295, 303, 306, 310, 319, 320, 321, 325, 326, 327, 328, 329, 330, 331, 332, 337, 340, 348, 351, 365, 367, 369, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 565, 567, 568, 570, 571, 573, 574, 575, 578, 580, 586, 625, 627, 636, 638], "manipul": [21, 23, 27, 124, 125, 250, 271, 275], "third_transform": 21, "assert": [21, 22, 25, 34, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 114, 120, 123, 126, 130, 133, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 183, 206, 211, 214, 218, 221, 224, 229, 232, 241, 253, 260, 272, 279, 287, 307, 325, 327, 328, 330, 331, 376, 378, 380, 381, 383, 384, 385, 386, 387, 388, 404, 405, 413, 463, 464, 467, 468, 469, 612, 627, 633, 638, 641], "lead": [21, 23, 27, 29, 52, 56, 60, 65, 68, 71, 79, 101, 107, 120, 123, 124, 125, 126, 129, 130, 131, 132, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 265, 282, 303, 320, 321, 619, 622, 623, 634, 635, 636, 638, 640], "unexpect": [21, 34, 35, 36, 38, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 641], "behviour": 21, "rais": [21, 22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 81, 83, 86, 87, 88, 95, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 165, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 221, 235, 245, 255, 264, 265, 266, 270, 272, 279, 286, 301, 312, 325, 326, 327, 328, 330, 331, 332, 333, 337, 351, 365, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 401, 402, 403, 404, 565, 567, 570, 571, 572, 573, 574, 575, 576, 578, 580, 586, 612, 619, 621, 634, 635, 638], "catfram": [21, 340, 480, 620], "hold": [21, 22, 271, 382, 567, 636, 638], "notic": [21, 114, 221, 621, 629, 636], "parenthood": 21, "henc": [21, 53, 65, 213, 251, 619, 621, 634, 635, 636], "transform2": 21, "transform3": 21, "last_two": 21, "isinst": [21, 150, 158, 272, 390, 404, 468, 636], "discret": [21, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 129, 130, 131, 138, 142, 143, 150, 151, 152, 153, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180, 214, 231, 239, 310, 355, 356, 357, 358, 620, 625, 635], "might": [21, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 396, 590, 619, 624, 641], "throughout": [21, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 621, 634, 641], "action_mask": [21, 123, 136, 137, 152, 153, 156, 157, 215, 475, 632], "unavail": [21, 152, 153], "probabl": [21, 23, 27, 69, 101, 102, 106, 188, 189, 195, 196, 287, 295, 301, 302, 304, 305, 306, 310, 317, 320, 321, 326, 329, 332, 337, 341, 344, 351, 357, 367, 370, 375, 377, 379, 383, 620, 623, 625, 640], "probabilistictensordictmodul": [21, 241, 344, 345, 640], "tensordictsequenti": [21, 287, 297, 301, 302, 304, 312, 326, 332, 337, 340, 345, 346, 375, 377, 379, 383, 619, 620, 622, 623, 625, 629, 633, 634, 637, 640], "maskedcategor": [21, 598], "in_feat": 21, "out_feat": 21, "logit": [21, 296, 298, 306, 310, 326, 329, 332, 337, 341, 356, 357, 591], "dist": [21, 29, 306, 310, 344, 625], "distribution_class": [21, 241, 283, 284, 285, 341, 344, 346, 348, 349, 351, 356, 357, 363, 367, 368, 369, 370, 598, 619, 621, 625, 634, 635, 640], "wrap": [21, 24, 32, 34, 35, 36, 38, 42, 44, 47, 50, 81, 88, 120, 121, 122, 123, 126, 130, 131, 135, 136, 137, 138, 143, 146, 148, 149, 150, 151, 152, 153, 154, 158, 159, 160, 162, 164, 165, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 227, 243, 270, 272, 282, 283, 284, 285, 302, 304, 313, 323, 326, 329, 332, 337, 340, 344, 365, 375, 377, 379, 382, 383, 591, 619, 620, 621, 622, 626, 629, 631, 634, 635, 641], "actionmask": [21, 123, 475], "know": [21, 22, 23, 28, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 68, 72, 73, 129, 131, 286, 365, 368, 375, 377, 379, 383, 409, 619, 620, 621, 622, 623, 624, 625, 626, 627, 634, 635, 638], "your_base_env": 21, "mask_kei": [21, 56, 215, 251, 326, 332, 337, 475], "intens": [22, 27], "gym3": 22, "envpool": [22, 145, 146, 451], "scale": [22, 23, 79, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 177, 178, 179, 180, 221, 241, 246, 257, 264, 268, 279, 280, 283, 284, 285, 299, 303, 307, 315, 316, 320, 321, 341, 344, 346, 348, 349, 351, 363, 367, 368, 369, 370, 412, 505, 515, 553, 563, 598, 619, 620, 621, 622, 625, 635, 640], "varieti": [22, 30], "serialenv": [22, 120, 123, 126, 130, 138, 150, 151, 154, 159, 160, 170, 171, 172, 175, 178, 179, 180, 265, 280, 287, 340, 640, 641], "Of": [22, 26, 590, 636, 641], "cours": [22, 23, 590, 636, 641], "saniti": [22, 26, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 621], "9": [22, 26, 56, 65, 68, 72, 84, 85, 86, 87, 102, 109, 114, 124, 125, 141, 152, 153, 160, 176, 214, 217, 226, 227, 264, 267, 272, 279, 280, 306, 325, 327, 328, 330, 331, 332, 337, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 383, 384, 404, 419, 539, 541, 542, 543, 545, 546, 547, 551, 619, 620, 634, 635], "81": [22, 86, 87, 108, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "c": [22, 25, 26, 32, 34, 35, 36, 38, 52, 60, 68, 72, 73, 82, 86, 87, 96, 176, 246, 268, 273, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 383, 384, 620, 638], "d": [22, 60, 65, 68, 71, 72, 73, 80, 82, 84, 85, 101, 102, 326, 332, 337, 341, 344, 375, 377, 379, 383, 640], "forc": [22, 25, 26, 32, 35, 36, 38, 42, 44, 47, 50, 78, 80, 81, 83, 84, 85, 151, 332, 620, 634, 635, 636], "launch": [22, 32, 35, 36, 38, 42, 44, 47, 51, 78, 80, 150, 158, 190, 324, 333], "bottleneck": [22, 27, 102, 108, 109], "precis": [22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 212, 229, 232, 619, 621], "misspecifi": 22, "caus": [22, 26, 27, 34, 35, 36, 38, 95, 97, 101, 102, 116, 120, 123, 126, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 251, 379, 641], "breakag": 22, "mismatch": [22, 350, 367, 379, 620], "subprocess": [22, 32, 35, 36, 38, 127, 150, 158], "multithreadedenv": [22, 451], "underneath": 22, "cover": [22, 129, 131, 590, 621, 624, 627, 628, 636, 640], "classic": [22, 135, 144, 153, 620], "benchmark_batched_env": 22, "distinguish": [22, 68, 72, 73, 142, 143, 163, 164], "mere": [22, 32, 623], "element": [22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 56, 57, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 95, 96, 97, 98, 101, 102, 108, 109, 114, 116, 120, 123, 126, 130, 138, 147, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 177, 178, 179, 180, 185, 214, 221, 226, 227, 251, 260, 264, 265, 280, 286, 288, 297, 322, 325, 327, 328, 330, 331, 339, 340, 343, 344, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 405, 619, 621, 625, 627, 631, 638, 641], "batch_lock": [22, 120, 123, 126, 128, 130, 138, 150, 154, 158, 159, 170, 171, 172, 175, 178, 179, 180, 218, 265, 272, 636], "contrast": [22, 638], "braxenv": [22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 253, 442, 624], "jumanjienv": [22, 448], "straightforward": [22, 40, 619, 620, 624, 625, 626, 627, 638], "merg": [22, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 636], "deal": [22, 65, 66, 68, 69, 365, 375, 377, 379, 383, 619, 621, 635, 638], "silent": [22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 326, 338, 340, 347], "temporari": [22, 95, 97, 612, 619], "arm": 22, "unbatch": 22, "captur": [22, 190, 197, 286, 301, 312, 542, 591, 623], "content": [22, 27, 34, 60, 65, 68, 71, 72, 73, 86, 87, 89, 107, 108, 109, 120, 123, 126, 129, 130, 131, 138, 145, 150, 151, 154, 158, 159, 160, 170, 171, 172, 174, 175, 176, 178, 179, 180, 184, 190, 195, 196, 252, 288, 305, 325, 327, 328, 330, 331, 332, 337, 341, 365, 375, 376, 377, 378, 379, 380, 381, 383, 384, 591, 621, 631, 632, 636, 640], "found": [22, 25, 26, 29, 32, 34, 35, 36, 38, 50, 56, 60, 71, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 108, 109, 120, 123, 124, 125, 126, 129, 130, 131, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 213, 215, 221, 242, 255, 258, 266, 279, 280, 301, 325, 326, 327, 328, 330, 331, 332, 337, 341, 344, 364, 365, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 401, 402, 593, 612, 619, 620, 622, 623, 624, 626, 628, 631, 636, 638, 640], "essenti": [22, 33, 42, 43, 44, 45, 47, 48, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 591, 620, 624, 634, 636, 638], "break_when_all_don": [22, 120, 123, 126, 130, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "conditionalskip": [22, 486], "programmat": 22, "pretti": [22, 619, 624, 628, 638], "likewis": 22, "te": 22, "dive": 22, "privat": [22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 278, 636, 641], "distinct": [22, 65, 66, 68, 69, 86, 87, 176, 218, 221, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 626, 633], "total": [22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 57, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 109, 114, 172, 176, 183, 226, 325, 327, 328, 330, 331, 335, 336, 350, 364, 367, 376, 378, 379, 380, 381, 384, 405, 407, 409, 415, 417, 419, 420, 472, 552, 553, 579, 605, 618, 619, 620, 621, 622, 626, 634, 635, 637, 638, 639, 640], "accord": [22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 60, 69, 71, 86, 87, 106, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 161, 162, 170, 171, 172, 175, 176, 178, 179, 180, 246, 257, 303, 315, 317, 320, 321, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 625, 626, 634, 636, 638], "nevertheless": [22, 621, 624, 638], "wherev": 22, "expos": [22, 155, 229, 232, 345, 350, 367, 620], "lost": [22, 27, 278], "face": [22, 24, 27, 28, 329, 332, 624, 632, 641], "word": [22, 30, 78, 79, 81, 83, 84, 85, 365, 375, 377, 379, 383, 619, 627, 636, 641], "preliminari": 22, "warranti": 22, "long": [22, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 95, 102, 148, 149, 231, 270, 324, 356, 379, 622, 623, 627, 638], "assumpt": [22, 74, 636, 638], "preclud": 22, "presenc": [22, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 326, 332, 337, 375, 377, 379, 383, 626], "annihil": 22, "known": [22, 24, 26, 27, 130, 180, 265, 619, 620, 624], "supersed": [22, 56], "pettingzoowrapp": 22, "associ": [22, 60, 66, 71, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 271, 315, 325, 326, 327, 328, 329, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 402, 563, 565, 571, 573, 619, 638], "__not__": [22, 341, 349, 351, 363, 368, 370, 371, 372], "constrain": [22, 241, 302, 304, 367, 641], "li": 22, "fact": [22, 26, 27, 591, 619, 621, 624, 634, 635, 636, 637, 638, 641], "predict": [22, 296, 299, 323, 348, 350, 355, 358, 360, 361, 364, 367, 369, 379, 619, 620, 626], "meaning": [22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 177, 417], "perfectli": [22, 619, 623, 636], "meaningless": 22, "discard": [22, 79, 81, 130, 212, 275, 391, 638, 641], "val": [22, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 171, 280, 404, 626, 640], "agent0": [22, 367, 623], "agent1": [22, 367], "elimin": [22, 624], "500": [22, 619, 620], "uint8": [22, 60, 78, 83, 86, 87, 124, 125, 142, 143, 176, 233, 239, 248, 268, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 620, 638], "significantli": [22, 33, 42, 43, 44, 45, 47, 48, 90, 108, 109, 221, 350, 367, 379, 567, 619, 620, 626, 635], "asyncenvpool": [22, 52, 154, 159], "thread": [22, 32, 34, 35, 36, 38, 50, 52, 53, 86, 87, 120, 121, 122, 136, 137, 150, 158, 159, 176, 190, 280, 324, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 565, 567, 568, 570, 571, 573, 575, 578, 580, 581, 586], "pool": [22, 78, 79, 80, 81, 82, 83, 84, 85, 120, 154, 159, 192, 266, 612], "concurr": [22, 120, 324, 329, 417, 612, 634, 635], "contrari": 22, "permit": [22, 224, 236, 262, 274, 348, 350, 364, 367, 369], "job": [22, 26, 42, 44, 47, 51, 68, 69, 72, 73, 638, 640], "famili": [22, 87, 89, 593], "particularli": [22, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 68, 69, 72, 73, 86, 87, 90, 176, 191, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 417, 420, 612, 623, 640, 641], "pleas": [22, 41, 81, 88, 120, 123, 126, 129, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 239, 266, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383, 419, 590, 591], "processorasyncenvpool": 22, "threadingasyncenvpool": 22, "functool": [22, 32, 34, 35, 36, 38, 52, 120], "lazi": [22, 70, 71, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 176, 178, 179, 180, 250, 275, 325, 327, 328, 330, 331, 345, 346, 376, 378, 380, 381, 384, 424, 425, 426, 619, 620, 625, 627, 633, 638, 641], "s0": [22, 120], "clamp": [22, 120, 344, 347, 360, 415, 634, 636], "env_index": [22, 120], "async_step_send": [22, 120, 154, 159], "s0_result": [22, 120], "async_step_recv": [22, 120, 154, 159], "reveal": 23, "bug": 23, "curv": 23, "exploit": [23, 625], "cv": 23, "flip": [23, 137], "correspondingli": 23, "prescript": 23, "tune": [23, 241, 383, 591, 634, 635, 637], "coeffici": [23, 188, 195, 241, 350, 357, 364, 367, 370, 379, 383, 635], "bonu": [23, 177, 348, 350, 364, 367, 379, 591], "altern": [23, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 59, 86, 87, 145, 170, 176, 197, 226, 270, 294, 306, 324, 325, 327, 328, 330, 331, 351, 376, 378, 380, 381, 384, 390, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586, 612, 619, 621, 623, 634, 635], "reduc": [23, 25, 59, 101, 102, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 192, 212, 221, 227, 264, 280, 320, 383, 522, 567, 620, 634], "downstream": [23, 379, 619], "formul": [23, 634, 635], "gradient": [23, 65, 68, 69, 72, 73, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 243, 272, 303, 310, 320, 321, 326, 332, 337, 344, 348, 350, 351, 352, 356, 357, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 415, 419, 420, 472, 589, 605, 619, 621, 634, 635, 636], "norm": [23, 27, 86, 87, 121, 122, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 408, 415, 419, 420, 472, 619, 620, 621, 634, 635, 636], "easier": [23, 619, 640], "optima": 23, "sens": [23, 86, 87, 176, 185, 221, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 627, 636], "product": [23, 28, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 561, 562, 612, 632], "sum": [23, 35, 36, 38, 50, 62, 64, 86, 87, 114, 121, 122, 124, 125, 129, 131, 132, 136, 137, 145, 146, 155, 176, 177, 220, 242, 258, 306, 320, 325, 327, 328, 330, 331, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 376, 378, 379, 380, 381, 383, 384, 408, 591, 605, 619, 620, 621, 623, 626, 629, 634, 635, 636, 641], "stat": [23, 246, 279, 280, 553, 563, 620, 621], "yield": [23, 34, 35, 36, 38, 50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 324, 326, 332, 337, 365, 375, 377, 379, 382, 383, 619, 622, 626], "insight": [23, 171, 417, 612, 623], "auxiliari": [23, 626], "credit": 23, "past": [23, 221, 340, 620, 638], "difficult": [23, 150, 628], "spars": [23, 591, 622], "instrument": 23, "greatli": 23, "soccer": 23, "kick": 23, "ball": [23, 172], "likelihood": [23, 619], "score": [23, 177, 332, 367, 591], "undesir": 23, "though": [23, 30, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 305, 332, 612, 621, 634, 635], "unintention": 23, "valuabl": 23, "idiosyncrat": 23, "subtask": 23, "hierarch": 23, "fall": [23, 37, 39, 41, 46, 49, 54, 55, 79, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "curios": 23, "magnitudin": 23, "domin": 23, "smaller": [23, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 356, 363, 621, 635], "addition": [23, 295], "timestep": [23, 79, 255, 634, 635], "realli": 23, "huge": [23, 622], "std": [23, 246, 279, 286, 307, 311, 419, 619, 641], "initi": [23, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 59, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 95, 97, 114, 120, 123, 126, 130, 138, 148, 149, 150, 151, 154, 158, 159, 160, 161, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 220, 239, 246, 250, 265, 272, 275, 280, 281, 282, 286, 301, 312, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 340, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 401, 403, 563, 564, 565, 566, 567, 568, 570, 571, 572, 573, 574, 575, 576, 578, 579, 580, 584, 585, 586, 591, 612, 619, 620, 622, 624, 625, 627, 631, 634, 636, 641], "estim": [23, 78, 102, 108, 109, 170, 171, 172, 175, 178, 185, 233, 241, 283, 284, 285, 290, 320, 348, 349, 350, 351, 352, 353, 355, 357, 358, 359, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375, 377, 379, 383, 385, 386, 387, 388, 389, 600, 605, 620, 621, 625, 626, 634, 635], "encount": [23, 83, 244, 340, 590, 620, 625, 636], "unseen": 23, "extrins": 23, "wrong": [23, 102, 108, 183], "goe": [23, 152, 153, 619, 621, 634, 635, 641], "bonus": 23, "denser": 23, "prior": [23, 316, 317, 360, 635], "freshli": 23, "drop": [23, 107, 109, 212, 280, 324, 350, 367, 379], "meant": [23, 144, 178], "encourag": [23, 150, 183, 367, 420, 619, 620, 638], "measur": [23, 88, 95, 97, 101, 116, 121, 122, 136, 137, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 350, 367, 379, 382, 417, 420, 621, 627], "novelti": 23, "revisit": 23, "diminish": 23, "decreas": [23, 625], "ideal": [23, 170, 226, 246, 379, 632, 636], "distil": 23, "nois": [23, 281, 312, 368, 371, 372, 409, 563, 602, 619, 634], "exploratori": [23, 348, 350, 364, 367, 379], "misalign": 23, "trade": [23, 625], "unavoid": 23, "prioriti": [23, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 90, 95, 96, 97, 98, 101, 102, 110, 112, 116, 351, 352, 353, 355, 356, 357, 358, 363, 368, 370, 371, 372, 619, 620, 638], "schedul": [23, 26, 324, 409, 621, 636], "divers": [23, 150, 158, 332], "bootstrap": [23, 358, 385, 386, 619, 622], "noisi": 23, "unstabl": [23, 101, 102, 303, 320, 321], "inher": [23, 348, 367], "stochast": [23, 241, 299, 308, 316, 349, 351, 354, 356, 357, 362, 363, 366, 368, 370, 420, 598, 599, 621, 625, 635], "enemi": 23, "pomdp": [23, 638], "loos": [23, 344, 584, 620, 621], "nonexist": 23, "architectur": [23, 189, 294, 324, 332, 598, 612, 626, 634, 635, 640], "sequenc": [23, 32, 34, 35, 36, 38, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 74, 75, 76, 77, 83, 86, 87, 94, 104, 106, 112, 115, 118, 119, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 199, 201, 207, 219, 220, 221, 222, 223, 228, 229, 231, 232, 236, 238, 239, 242, 246, 247, 251, 252, 253, 254, 255, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 273, 279, 280, 288, 295, 305, 306, 310, 317, 324, 325, 326, 327, 328, 329, 330, 331, 332, 337, 345, 346, 354, 375, 376, 377, 378, 379, 380, 381, 383, 384, 391, 392, 409, 410, 411, 413, 415, 591, 619, 621, 622, 623, 633, 634, 635, 641], "lstm": [23, 265, 304, 307, 623], "rel": [23, 69, 265, 295, 319, 619, 620, 634, 635, 638], "tend": 23, "stabl": [23, 28, 29, 101, 102, 147], "compens": 23, "descent": 23, "minimum": [23, 75, 120, 150, 158, 256, 299, 307, 319, 320, 321, 326, 332, 337, 347, 349, 351, 357, 365, 366, 370, 375, 377, 379, 383, 405, 619, 621, 629, 634, 635], "manual": [23, 30, 42, 47, 50, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 130, 131, 180, 191, 419, 619, 622, 638], "deviat": [23, 246, 279, 280, 286, 299, 311, 367, 371, 372, 383, 408, 619, 625, 635], "radic": 23, "stabil": [23, 101, 102, 237, 324, 333, 334, 348, 350, 364, 367, 369, 379], "stage": [23, 619, 636], "never": [23, 32, 35, 36, 38, 52, 58, 75, 101, 102, 267, 627, 640], "solv": [23, 26, 28, 29, 65, 66, 68, 69, 183, 590, 619, 620, 621, 627, 629, 634, 635, 636, 638], "submit": [23, 129, 218, 590, 640], "adequ": [23, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 621, 634, 635], "infeas": 23, "allevi": 23, "prune": [23, 138, 179], "fire": [23, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "certain": [23, 42, 44, 47, 50, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 226, 227, 237, 263, 272, 301, 326, 332, 333, 334, 337, 364, 375, 377, 379, 382, 383, 619, 620, 621, 623, 629, 634, 635, 641], "illeg": 23, "move": [23, 74, 85, 88, 96, 98, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 214, 225, 230, 250, 265, 271, 272, 275, 277, 279, 280, 305, 326, 332, 337, 343, 375, 377, 379, 382, 383, 412, 619, 620, 622, 624, 641], "chess": [23, 123, 148, 149], "grasp": 23, "wherein": 23, "cumul": [23, 258, 264, 621], "q": [23, 28, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 285, 290, 291, 292, 293, 296, 298, 300, 313, 314, 317, 349, 351, 352, 353, 355, 356, 357, 358, 363, 368, 370, 371, 372, 598, 619, 626, 631], "flow": [23, 385, 566, 567, 574, 619, 621, 634, 635, 636, 638], "reparameter": [23, 295, 310], "soft": [23, 370, 420, 634], "clip": [23, 183, 224, 256, 348, 350, 364, 367, 369, 371, 372, 375, 377, 379, 415, 419, 420, 471, 472, 621, 635, 636], "oppos": 23, "incorrect": [23, 108, 183, 367], "thought": [23, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 591], "region": [23, 102, 379], "squash": [23, 338, 622, 640], "tanh": [23, 288, 303, 305, 319, 320, 321, 347, 621, 625, 634, 635, 636, 637], "correct": [23, 86, 87, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 182, 183, 188, 221, 241, 325, 327, 328, 330, 331, 376, 378, 379, 380, 381, 384, 552, 612, 621, 622, 631], "prob": [23, 188, 189, 195, 196, 306, 310, 324, 326, 329, 332, 337, 621, 632, 635], "rememb": [23, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 634], "remap": 23, "origin": [23, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 90, 134, 170, 176, 230, 231, 241, 250, 272, 277, 325, 326, 327, 328, 330, 331, 332, 337, 341, 343, 344, 349, 351, 363, 365, 367, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 591, 619, 623, 631, 633, 636, 641], "real": [24, 35, 36, 38, 83, 326, 332, 337, 344, 572, 622, 623, 636, 637], "histor": 24, "ceas": 24, "fork": [24, 78, 79, 80, 81, 82, 83, 84, 85, 619, 620, 621, 622, 634, 635, 637, 640], "farama": [24, 81, 139, 140, 152, 153, 621, 636], "bc": [24, 371], "break": [24, 32, 34, 35, 36, 38, 50, 52, 54, 66, 68, 73, 78, 80, 81, 83, 84, 85, 88, 102, 108, 109, 114, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 221, 255, 279, 280, 302, 304, 320, 326, 332, 337, 375, 377, 379, 382, 383, 392, 620, 623, 627, 629, 638, 640], "13": [24, 108, 109, 155, 226, 278, 280, 282], "gymwrapp": [24, 120, 123, 126, 130, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 234, 259, 263, 278, 621, 640], "feel": [24, 590, 629, 640], "free": [24, 26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 176, 212, 229, 232, 325, 327, 328, 330, 331, 348, 360, 367, 376, 378, 380, 381, 384, 612, 621, 629, 635, 640], "gladli": 24, "conda": [25, 26, 590], "cmake": 25, "14": [25, 78, 79, 80, 81, 82, 83, 84, 85, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 226, 246, 282, 367], "sim": 25, "bullet": 25, "headless": [25, 26, 135, 184, 631], "cluster": [25, 26, 27, 42, 50, 80, 401, 402, 403, 590], "withbullet": 25, "forg": [25, 26], "aihabitat": [25, 132], "y": [25, 26, 68, 86, 87, 147, 176, 300, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 383, 384, 463, 464, 467, 469, 619, 635, 638], "facebookresearch": [25, 80, 132], "subdirectori": 25, "verbos": [25, 52, 53, 88, 177, 324, 333, 382, 629, 631], "magnum_log": 25, "quiet": 25, "habitat_sim_log": 25, "remov": [25, 34, 35, 36, 38, 41, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 252, 261, 272, 325, 326, 327, 328, 330, 331, 332, 337, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 401, 402, 591, 634, 635, 640, 641], "readm": [25, 26, 163, 640], "md": [25, 26], "habitatenv": [25, 446], "_has_habitat": 25, "available_env": [25, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 136, 137, 138, 139, 142, 143, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 172, 175, 178, 179, 180, 641], "startswith": [25, 287, 605, 619, 626], "oserror": 25, "libllvmlit": 25, "ionstal": 25, "pointer": [25, 127, 365, 619], "llvmlite": 25, "var": [25, 26, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 280, 326, 332, 337, 351, 365, 370, 375, 377, 379, 382, 383], "ld_preload": [25, 26], "bind": 25, "deactiv": [25, 26, 121, 122, 297, 349, 351, 357, 363, 365, 368, 370, 371, 372, 386, 387, 388], "importerror": [25, 26, 29, 403, 632], "usr": [25, 26, 29], "x86_64": [25, 26], "linux": [25, 26], "gnu": [25, 26], "libopengl": [25, 26], "undefin": [25, 26, 29, 59, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 351, 365, 370, 375, 377, 379, 382, 383, 623, 638], "symbol": [25, 26, 29], "_glapi_tls_curr": [25, 26], "link": [25, 26, 126, 620, 629], "mujoco_env": [25, 26], "libglvnd": [25, 26], "glx": [25, 26], "cos7": [25, 26], "reinstal": [25, 26], "xvfbwrapper": [25, 26], "sysroot": [25, 26], "lib64": [25, 26], "libgldispatch": [25, 26], "offici": [26, 79, 190, 623], "stand": [26, 124, 125, 150, 158, 633, 636], "joint": [26, 620], "contact": [26, 634], "biomechan": 26, "graphic": 26, "anim": [26, 635], "area": 26, "demand": [26, 567, 628, 641], "fast": [26, 28, 96, 121, 122, 212, 253, 368, 612, 619, 620, 621, 640], "accur": [26, 79, 85, 591, 620, 636, 638], "articul": 26, "acquir": [26, 621], "deepmind": [26, 27, 28, 83, 120, 123, 124, 125, 126, 130, 138, 142, 143, 148, 149, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 233, 621, 624], "whomev": 26, "licenc": 26, "were": [26, 32, 34, 35, 36, 38, 41, 42, 44, 47, 50, 67, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 150, 158, 239, 350, 367, 567, 582, 591, 593, 621, 634, 638], "incorpor": [26, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 301, 312, 371, 420, 622, 625, 636], "relianc": 26, "obsolet": 26, "pro": [26, 590], "tip": [26, 590], "glfw": [26, 619], "osmesa": 26, "egl": 26, "advic": [26, 83, 641], "sudo": [26, 590], "apt": [26, 635], "libglfw3": 26, "libglew2": 26, "libgl1": 26, "mesa": 26, "libosmesa6": 26, "workflow": [26, 283, 284, 285, 324, 591, 632], "glew": 26, "mesalib": 26, "anaconda": 26, "libgl": 26, "cos6": 26, "menpo": 26, "glfw3": 26, "mujoco_gl": 26, "pyopengl_platform": 26, "mkdir": 26, "earlier": [26, 619, 621, 622, 634, 635, 638], "roboti": 26, "download": [26, 29, 78, 79, 80, 81, 83, 84, 85, 134, 250, 277, 392, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "html": [26, 35, 38, 145, 147, 148, 149, 631], "wget": 26, "mujoco210": 26, "tar": [26, 80], "gz": 26, "xf": 26, "charg": [26, 32, 35, 36, 38, 150, 158], "mjkei": 26, "txt": [26, 383], "mjlib_path": 26, "home": 26, "bin": [26, 190, 298], "libmujoco210": 26, "ld_library_path": 26, "mujoco_py_mujoco_path": 26, "too": [26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 245, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 303, 320, 321, 326, 332, 337, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 385, 386, 387, 388, 620, 625, 628, 636, 638, 641], "mujoco_py_mjkey_path": 26, "reload": 26, "later": [26, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 101, 102, 293, 341, 344, 402, 566, 619, 621, 623, 638], "nvidia": [26, 134, 623], "hack": [26, 619], "adatp": 26, "unnot": [26, 251], "mujoco_pi": 26, "cymj": 26, "linuxgpuextensionbuild": 26, "filenam": [26, 86, 87, 93, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 620, 638], "troubleshoot": [26, 350, 364, 367], "gl": 26, "h": [26, 69, 221, 223, 228, 254, 268, 302, 304, 392, 512, 620, 638], "eglshim": 26, "fatal": 26, "No": [26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 54, 57, 59, 62, 64, 177, 401, 564, 566, 568, 569, 574], "directori": [26, 78, 79, 80, 81, 83, 84, 85, 86, 87, 91, 95, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 397, 400, 580, 581, 582, 583, 619, 625, 628, 634], "devel": 26, "ubuntu": [26, 134], "libglew": 26, "dev": 26, "cento": 26, "yum": 26, "glu": 26, "38": 26, "disappear": [26, 620, 622, 633], "libstdc": 26, "6": [26, 32, 34, 35, 36, 38, 52, 53, 56, 60, 68, 71, 78, 84, 85, 101, 102, 109, 124, 125, 130, 150, 156, 157, 172, 180, 214, 217, 226, 227, 246, 248, 264, 270, 280, 287, 288, 290, 291, 292, 295, 300, 305, 308, 319, 322, 340, 341, 620, 623, 640], "glibcxx_3": 26, "29": [26, 108, 109], "compil": [26, 34, 35, 36, 38, 56, 68, 72, 73, 86, 87, 88, 90, 94, 95, 96, 97, 98, 102, 104, 108, 109, 110, 115, 116, 118, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 282, 320, 324, 325, 326, 327, 328, 330, 331, 332, 333, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 424, 425, 426, 427, 431, 433, 434, 438], "libosmesa": 26, "libgcc": 26, "Then": [26, 32, 34, 35, 36, 38, 42, 44, 47, 50, 175, 183, 278, 584, 585, 621, 633], "filenotfounderror": [26, 81], "errno": 26, "patchelf": 26, "fatalerror": 26, "gladloadgl": 26, "mj_env": 26, "912": 26, "glfwerror": 26, "65537": 26, "myscript": 26, "runtimeerror": [26, 27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 59, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 245, 270, 272, 326, 332, 333, 337, 351, 370, 375, 377, 379, 382, 383, 572, 641], "slurm": 26, "mjrendercontext": 26, "pyx": 26, "46": [26, 108, 121, 122], "114": 26, "_setup_opengl_context": 26, "opengl_context": 26, "130": 26, "offscreenopenglcontext": 26, "fail": [26, 32, 34, 35, 36, 38, 51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 195, 215, 326, 332, 337], "opengl": [26, 634, 635], "global": [26, 68, 69, 72, 73, 88, 89, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 270, 326, 332, 335, 336, 337, 341, 344, 375, 377, 379, 382, 383, 401, 402, 619, 634, 635], "cuda_visible_devic": [26, 586], "slurm_step_gpu": 26, "black": [26, 123, 634], "onscreen": 26, "101": 26, "lgl": 26, "libegl": 26, "x11": [26, 635], "xlib": 26, "libx11": 26, "xorg": 26, "attributeerror": [26, 32, 35, 36, 38, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "nonetyp": 26, "glgeterror": 26, "this_dir": 26, "pwd": 26, "ln": 26, "libglut": 26, "12": [26, 29, 35, 36, 38, 84, 86, 87, 95, 97, 109, 116, 136, 137, 150, 156, 157, 158, 172, 176, 190, 226, 272, 280, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 392, 638], "sketch": 27, "_": [27, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 96, 123, 127, 134, 163, 164, 176, 185, 222, 229, 231, 232, 241, 246, 253, 268, 279, 322, 325, 327, 328, 330, 331, 339, 343, 344, 348, 349, 351, 352, 356, 357, 363, 367, 368, 370, 371, 372, 376, 378, 380, 381, 384, 385, 386, 387, 388, 394, 619, 620, 621, 622, 623, 629, 634, 635, 636, 638, 640], "n_training_step": 27, "datapoint": [27, 638], "onlin": [27, 32, 38, 221, 294, 311, 348, 354, 366, 367, 405, 563, 621, 622, 635, 638], "n_data_per_train": 27, "no_grad": [27, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 243, 326, 332, 337, 375, 377, 379, 382, 383, 385, 386, 387, 388, 621, 622, 623, 635], "loss_fn": [27, 622, 626, 627, 640], "zero_grad": [27, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 619, 621, 622, 623, 626, 629, 634, 635, 636], "backpropag": [27, 121, 122, 136, 137, 150, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 626, 635, 636], "differenti": [27, 121, 122, 241, 351, 371, 385, 386, 387, 388, 538, 539, 540, 542, 548, 549, 550, 622, 625, 626, 634, 635, 636], "pai": [27, 221, 619, 622], "denomin": 27, "artifact": 27, "numer": [27, 68, 101, 102, 130, 180, 279, 297, 298, 303, 313, 314, 320, 321, 324, 333, 334, 339, 341, 343, 344, 412, 621, 638, 641], "misconcept": 27, "freed": 27, "appear": [27, 30, 58, 64, 75, 78, 83, 102, 108, 109, 126, 178, 185, 186, 636, 638], "compuat": 27, "twice": [27, 109], "retain_graph": [27, 121, 122], "discuss": [27, 28, 627, 634, 635], "inplac": [27, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 329, 330, 331, 332, 337, 343, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 565, 567, 568, 570, 571, 573, 575, 577, 578, 580, 582, 584, 586, 619], "accumul": [27, 317], "onto": [27, 64, 86, 87, 176, 189, 195, 206, 230, 286, 297, 298, 307, 312, 313, 314, 325, 327, 328, 330, 331, 339, 341, 343, 344, 376, 378, 380, 381, 384, 385, 622, 636], "submodul": [27, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 265, 302, 304, 326, 332, 337, 365, 375, 377, 379, 382, 383], "grad": [27, 86, 87, 88, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 330, 331, 332, 337, 344, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 619, 621], "whose": [27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 88, 120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "neg": [27, 32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 72, 74, 101, 102, 182, 221, 236, 251, 262, 274, 326, 350, 359, 364, 367, 385, 387, 388, 621, 634, 635, 636], "fit": [27, 246, 265, 282, 324, 619], "jax": [27, 121, 122, 136, 137, 282], "improperli": 27, "underli": [27, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 326, 332, 365, 612, 622, 624, 626, 628, 636], "tedeiou": 27, "amount": [27, 150, 312, 385, 620, 638], "costli": [27, 636], "concaten": [27, 35, 36, 38, 50, 61, 62, 83, 86, 87, 176, 178, 221, 222, 246, 262, 305, 325, 327, 328, 330, 331, 346, 376, 378, 380, 381, 384, 619, 620, 625, 634, 635, 636, 638, 641], "constitut": [27, 620, 635, 636], "profil": 27, "frequent": [27, 612, 638], "techniqu": [27, 150, 158, 620, 623, 627, 638], "program": [27, 356, 363, 623, 641], "functorch": [27, 29], "incl": 27, "suit": [27, 125, 612, 621, 624, 640, 641], "mujoco_instal": 27, "valueerror": [27, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 330, 331, 332, 333, 337, 375, 377, 379, 382, 383, 401, 402, 403, 565, 567, 570, 571, 573, 574, 575, 576, 578, 580, 586, 632], "bad": 27, "fds_to_keep": 27, "new_shap": 27, "permut": [27, 107, 248, 268, 623, 640, 641], "idea": [28, 101, 102, 368, 613, 622, 625, 634, 635], "introductori": 28, "intro": [28, 621, 622], "dai": [28, 640], "2022": [28, 29, 640], "spin": [28, 124, 125], "hug": [28, 329, 332, 632], "syllabu": 28, "lectur": 28, "awesom": 28, "curat": 28, "succinct": [28, 625], "summari": [28, 246, 279, 280, 619, 620, 621, 622], "reddit": 28, "reagent": 28, "orient": [28, 85, 641], "baselines3": 28, "tf": 28, "bandit": [28, 147], "tensorflow": [28, 306], "kera": 28, "acm": 28, "dopamin": 28, "prototyp": [28, 419, 420, 623, 629], "salina": 28, "sequenti": [28, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 220, 241, 283, 284, 285, 326, 332, 337, 341, 345, 346, 348, 349, 351, 357, 363, 367, 368, 369, 370, 371, 375, 377, 379, 382, 383, 567, 598, 621, 622, 625, 635, 636, 637, 640, 641], "tianshou": 28, "eleg": 28, "rlpyt": 28, "rllib": 28, "industri": [28, 640], "grade": 28, "cherri": 28, "jaxrl": 28, "space": [28, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 87, 92, 93, 100, 120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 209, 214, 224, 231, 239, 242, 265, 273, 286, 288, 294, 297, 298, 309, 312, 313, 314, 317, 322, 337, 339, 341, 343, 344, 346, 347, 348, 353, 355, 356, 357, 367, 371, 372, 620, 621, 622, 623, 624, 625, 626, 634, 635, 636, 641], "mbrl": [28, 144], "rlmeta": 28, "light": 28, "elegantrl": 28, "cloud": 28, "mtrl": 28, "baselin": 28, "689": 29, "_torchrl": 29, "_zn8pybind116detail11type_casterin2at6tensoreve4loadens_6handleeb": 29, "colab": [29, 621, 622, 634, 635], "notebook": [29, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "24": [29, 84, 109, 129, 145, 146, 172, 183, 338, 340, 392, 634], "pip3": [29, 619, 621, 622, 634, 635], "extra": [29, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 221, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 399, 400, 621, 622, 638], "url": [29, 86, 132, 186, 631], "org": [29, 35, 38, 65, 80, 81, 83, 85, 101, 102, 121, 122, 124, 125, 132, 136, 137, 142, 143, 145, 146, 147, 155, 163, 164, 221, 250, 275, 289, 290, 291, 292, 293, 294, 298, 299, 300, 306, 308, 309, 312, 315, 316, 317, 348, 349, 353, 354, 355, 356, 358, 359, 360, 361, 362, 363, 366, 367, 369, 370, 371, 385, 588, 630, 637], "whl": 29, "u": [29, 82, 636], "upgrad": 29, "lib_version_her": 29, "heavili": 30, "pyav": 30, "conveni": [30, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 221, 324, 401, 621, 634, 635, 636, 638], "knob": 30, "dispos": 30, "guid": [30, 152, 153, 156, 157, 264, 324, 590, 619, 635, 640], "clarifi": 30, "behind": [30, 259], "adjust": [30, 265, 619, 634, 635, 636], "ultim": [30, 303, 320, 321], "ffmpeg": 30, "whatev": [30, 326, 332, 337, 619], "fed": [30, 635, 638], "feed": [30, 250, 277, 365, 375, 377, 379, 383, 619, 634, 635, 638], "suppos": [30, 150, 409, 641], "snippet": [30, 250, 275, 619], "gave": 30, "extrem": [30, 150, 158, 348, 350, 364, 367, 369, 379], "blurri": [30, 623], "stitch": 30, "my_exp": [30, 628], "pixels_onli": [30, 124, 125, 129, 131, 132, 155, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 619, 620, 628, 629, 640, 641], "my_video": [30, 628], "record_env": [30, 628, 629], "codec": 30, "h264": 30, "constant": [30, 101, 102, 221, 246, 264, 619, 621, 622, 641], "crf": 30, "17": [30, 84, 108, 109, 130, 150, 180, 214, 226], "preset": 30, "allow_non": 31, "unwrap": [31, 233, 272, 404, 492], "seealso": 31, "randompolici": [32, 34, 35, 36, 38, 42, 44, 47, 50, 51, 52, 221, 255, 627, 638], "tensordictmodulebas": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 220, 243, 297, 313, 326, 332, 337, 340, 375, 377, 379, 383, 465, 622], "signatur": [32, 34, 35, 36, 38, 42, 44, 47, 50, 65, 66, 68, 69, 88, 89, 112, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 209, 218, 225, 239, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383, 619, 623, 624, 636], "undergon": [32, 34, 35, 36, 38, 42, 44, 47, 50], "env_obs_kei": [32, 34, 35, 36, 38, 42, 44, 47, 50], "mustn": [32, 34, 35, 36, 38, 42, 44, 47, 50], "policy_factori": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53], "exclus": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 63, 68, 72, 73, 78, 83, 86, 87, 102, 108, 109, 176, 182, 218, 234, 236, 243, 297, 298, 302, 304, 306, 313, 314, 325, 327, 328, 330, 331, 334, 371, 372, 376, 378, 380, 381, 384, 385, 386, 387, 388, 389, 400, 563], "lifespan": [32, 34, 35, 36, 38, 42, 44, 47, 52, 53, 620], "divis": [32, 34, 35, 36, 38, 42, 44, 47, 78, 83, 102, 108, 109, 280, 635], "endless": [32, 34, 35, 36, 38, 42, 44, 47, 185, 591], "env_devic": [32, 34, 35, 36, 38, 42, 44, 47, 50, 620], "sit": [32, 34, 35, 36, 38, 42, 44, 47, 50, 418, 620], "cast": [32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 214, 215, 217, 218, 220, 221, 222, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 243, 249, 250, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 275, 276, 277, 278, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 343, 350, 364, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 634, 641], "create_env_kwarg": [32, 34, 35, 36, 38, 50, 120, 127, 145, 150, 158, 270, 439, 619, 641], "span": [32, 34, 35, 36, 38, 42, 44, 47, 50, 83, 102, 108, 109, 433, 434], "n_step": [32, 34, 35, 36, 38, 42, 44, 47, 50, 340, 503, 620, 621, 634, 635], "independ": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 80, 150, 158, 186, 236, 244, 265, 274, 324, 348, 367, 401, 584, 612, 619, 620, 622, 635, 638, 640], "ignor": [32, 34, 35, 36, 38, 42, 44, 47, 50, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 93, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 231, 234, 259, 268, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 306, 307, 308, 309, 311, 312, 314, 315, 316, 325, 326, 327, 328, 330, 331, 332, 337, 338, 340, 347, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 566, 574, 579, 581, 631, 632, 638], "mainli": [32, 34, 35, 36, 38, 42, 44, 47, 50, 170, 171, 172, 175, 400, 634, 635, 636], "round": [32, 34, 35, 36, 38, 42, 44, 47, 50, 78, 123, 192, 324, 431, 612], "closest": [32, 34, 35, 36, 38, 42, 44, 47, 50], "postproc": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 53, 255, 620, 638], "post": [32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 81, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 591], "multistep": [32, 34, 35, 36, 38, 42, 44, 47, 50, 52, 620], "explorationtyp": [32, 34, 35, 36, 38, 42, 44, 47, 50, 341, 365, 409, 619, 620, 621, 622, 625, 634, 640], "boolm": [32, 35, 36, 38], "preemptive_threshold": [32, 35, 36, 38], "ratio": [32, 35, 36, 38, 350, 367, 415, 417, 619, 621], "finish": [32, 34, 35, 36, 38, 50, 52, 130, 180, 255, 572, 641], "earli": [32, 35, 36, 38, 101, 102, 130, 180, 263, 326, 332, 337, 640], "num_thread": [32, 35, 36, 38, 86, 87, 130, 150, 158, 176, 180, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 580, 581], "num_sub_thread": [32, 35, 36, 38, 150, 158], "plu": [32, 35, 36, 38, 150, 158, 591, 636], "harm": [32, 35, 36, 38, 150, 158], "set_trunc": [32, 34, 35, 36, 38, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "add_truncated_kei": [32, 34, 35, 36, 38, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272], "track_policy_vers": [32, 34, 35, 36, 38, 52, 53, 191, 591], "policyvers": [32, 34, 35, 36, 38, 52, 53, 591], "mediat": [32, 34, 35, 36, 38, 52], "timeout": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 150, 184, 190, 192, 193, 197, 324, 326, 332, 337, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 579, 580, 581, 582, 584, 586, 612], "close_env": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 52], "cascade_execut": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "attr_path": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "caller": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 324, 326, 332, 337, 375, 377, 379, 382, 383, 579], "_receiver_schem": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "_set_dist_connection_info": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "connection_info_ref": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "get_cached_weight": [32, 35, 36, 38], "get_model": [32, 34, 35, 36, 38, 52, 53, 565, 567, 570, 571, 573, 578, 580, 586], "value_net": [32, 34, 35, 36, 38, 52, 53, 353, 355, 369, 385, 386, 387, 388, 621, 623, 625, 626, 629], "recogn": [32, 34, 35, 36, 38, 52, 53, 401], "get_policy_vers": [32, 34, 35, 36, 38, 52, 53], "uuid": [32, 34, 35, 36, 38, 52, 53, 191, 395, 620, 641], "disabl": [32, 34, 35, 36, 38, 52, 53, 57, 59, 61, 62, 64, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 303, 321, 326, 332, 337, 375, 377, 379, 382, 383, 390, 419, 568, 619, 634, 635], "getattr_env": [32, 34, 35, 36, 38, 52, 53], "attr": [32, 34, 35, 36, 38, 52, 53], "getattr_polici": [32, 34, 35, 36, 38, 52, 53], "getattr_rb": [32, 34, 35, 36, 38, 52, 53], "increment_vers": [32, 34, 35, 36, 37, 38, 39, 40, 41, 46, 49, 52, 53, 54, 55, 191], "increment": [32, 34, 35, 36, 37, 38, 39, 40, 41, 46, 49, 52, 53, 54, 55, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180, 191, 246, 364, 591], "init_updat": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "load_state_dict": [32, 34, 35, 36, 38, 50, 52, 53, 86, 87, 88, 90, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 417, 619], "ordereddict": [32, 34, 35, 36, 38, 50, 52, 53, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 279, 280, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383], "form": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 92, 93, 100, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 302, 304, 317, 326, 332, 337, 344, 348, 350, 364, 367, 375, 377, 379, 382, 383, 415, 420, 625], "worker0": [32, 35, 36, 38], "state_dict0": [32, 35, 36, 38], "worker1": [32, 35, 36, 38, 612], "state_dict1": [32, 35, 36, 38], "policy_vers": [32, 34, 35, 36, 38, 52, 53, 191, 591], "policy_or_weight": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54], "deleg": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 86, 87, 176, 194, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 636], "trained_polici": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "mirror": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "conflict": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 171, 326, 332, 337], "register_scheme_receiv": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "weight_recv_schem": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53], "weightsyncschem": [32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53], "synchronize_weight": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 566, 567, 573], "hierarchi": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 324], "immedi": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 401, 402, 403, 565, 567, 570, 571, 573, 575, 578, 580, 586, 612, 634, 635], "reset_idx": [32, 35, 36, 38], "abc": [32, 34, 35, 36, 37, 38, 39, 40, 41, 46, 49, 50, 52, 53, 54, 55, 60, 61, 65, 67, 68, 69, 71, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 219, 220, 221, 222, 223, 225, 228, 229, 232, 236, 238, 242, 246, 247, 252, 254, 255, 256, 257, 258, 262, 264, 265, 266, 268, 271, 272, 273, 279, 280, 282, 288, 295, 305, 306, 310, 326, 332, 337, 375, 377, 379, 382, 383, 410, 411, 418, 561, 562], "static_se": [32, 34, 35, 36, 38, 50, 52, 53, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 272], "integ": [32, 34, 35, 36, 38, 52, 53, 56, 61, 62, 64, 102, 108, 109, 110, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180, 191, 214, 217, 233, 237, 246, 263, 280, 288, 305, 351, 356, 363, 370, 623, 638], "env_fn": [32, 34, 35, 36, 38, 52, 53, 127, 561, 562], "env_fn_parallel": [32, 34, 35, 36, 38, 52, 53], "300": [32, 34, 35, 36, 38, 52, 53, 108, 109, 292, 293], "out_se": [32, 34, 35, 36, 38, 52, 53, 641], "raise_on_error": [32, 34, 35, 36, 38, 52, 401], "irrevers": [32, 35, 36, 38], "pipe": [32, 34, 35, 36, 38, 52, 150], "tqdm": [32, 34, 35, 36, 38, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 415, 619, 621, 622, 634, 635, 636], "ale_pi": [32, 34, 35, 36, 38, 52, 623], "progress": [32, 34, 35, 36, 38, 52, 53, 324, 407, 408, 409, 415, 417, 419, 420, 472, 620, 622, 641], "bar": [32, 34, 35, 36, 38, 52, 95, 97, 116, 324, 407, 408, 409, 415, 419, 420, 472, 620], "pbar": [32, 34, 35, 36, 38, 52, 78, 79, 80, 81, 82, 83, 84, 85, 619, 621, 622, 634, 635, 636], "100_000": [32, 34, 35, 36, 38, 52, 623, 629], "prec_wc": [32, 34, 35, 36, 38, 52], "wc": [32, 34, 35, 36, 38, 52], "write_count": [32, 34, 35, 36, 38, 52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 417], "set_descript": [32, 34, 35, 36, 38, 52, 619, 621, 622, 634, 635, 636], "f": [32, 34, 35, 36, 38, 52, 84, 88, 121, 122, 130, 136, 137, 180, 188, 190, 193, 195, 196, 267, 282, 383, 385, 386, 387, 388, 389, 612, 619, 620, 621, 622, 629, 632, 634, 635, 636, 638, 641], "worker_id": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586], "actor_weight": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "critic_weight": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "Will": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 86, 87, 102, 108, 145, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 392, 612], "_get_server_weight": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54], "typeerror": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "weight_updat": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52, 53, 620], "weightupdaterbas": [32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55], "localweightsupdaterbas": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "remoteweightsupdaterbas": [32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 47, 48, 50, 52], "implic": [33, 42, 43, 44, 45, 47, 48], "notimplementederror": [33, 42, 43, 44, 45, 47, 48, 619], "env_creat": [34, 127, 619], "interactiontyp": [34, 42, 44, 47, 50, 167, 210, 341, 344, 409], "return_same_td": 34, "interruptor": 34, "use_buff": [34, 35, 36, 38, 150, 158], "extend_buff": [34, 35, 36, 38], "local_init_rb": [34, 35, 36, 38], "trust_polici": [34, 35, 36, 38, 50, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "compile_polici": [34, 35, 36, 38], "cudagraph_polici": [34, 35, 36, 38], "no_cuda_sync": [34, 35, 36, 38, 50], "cautious": [34, 367], "whole": [34, 60, 71, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 341, 351, 370, 375, 377, 379, 382, 383, 405, 619, 621], "_interruptor": 34, "start_collect": 34, "stop_collect": 34, "preeptiv": 34, "trust": [34, 35, 36, 38, 50, 120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 227, 304, 379], "cudagraphmodul": [34, 35, 36, 38, 50, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "behaviour": [34, 35, 36, 38, 326, 332, 337, 375, 377, 379, 383, 622, 623, 640], "bypass": [34, 35, 36, 38, 81, 625], "isaaclab": [34, 35, 36, 38, 131, 135], "maniskil": [34, 35, 36, 38], "crash": [34, 35, 36, 38, 255], "Not": [34, 54, 61, 68, 121, 122, 136, 270, 302, 304, 332, 580, 582, 586], "env_mak": [34, 35, 38, 50, 66, 120, 559, 641], "2000": [34, 35, 38, 133, 392, 638], "int64": [34, 35, 38, 52, 56, 57, 59, 61, 62, 64, 72, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 101, 108, 120, 123, 126, 130, 138, 141, 142, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 214, 218, 226, 233, 248, 255, 263, 297, 298, 312, 313, 314, 325, 327, 328, 330, 331, 341, 376, 378, 380, 381, 384, 636], "del": [34, 35, 38, 52, 619, 620, 621, 633, 634, 638, 640, 641], "chunk": [34, 52, 53, 88, 625], "policy_state_dict": [34, 52, 53], "env_state_dict": [34, 52, 53], "safe": [35, 38, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 102, 108, 176, 286, 297, 298, 312, 313, 314, 319, 320, 325, 327, 328, 330, 331, 339, 341, 343, 344, 346, 376, 378, 380, 381, 384, 568, 570, 571, 573, 578, 580, 586, 598, 640], "guard": [35, 38], "doc": [35, 38, 132, 135, 136, 137, 147, 155, 186, 400, 620, 634, 635, 638], "depopul": [35, 36, 38], "mutual": [35, 36, 38], "collector_class": [35, 36, 38, 42, 44, 47, 49, 50, 569, 570], "deriv": [35, 36, 38, 42, 44, 47, 50, 86, 87, 176, 295, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 415], "fake": [35, 36, 38, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 619, 620, 623], "multiprocessedweightupdat": [35, 36, 38], "multiprocessweightsyncschem": [35, 36, 38, 566], "get_server_weight": 37, "policy_weight": [37, 39, 40, 46, 49], "all_worker_id": [37, 39, 40, 41, 46, 49, 54, 55], "scope": [37, 39, 40, 41, 46, 49, 54, 55, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 623, 641], "classmethod": [37, 39, 40, 41, 46, 49, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 239, 275, 282, 288, 289, 311, 324, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_polici": [37, 39, 40, 41, 46, 49, 54, 55], "back": [37, 39, 41, 46, 49, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 74, 75, 76, 77, 79, 86, 87, 89, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 199, 269, 278, 297, 298, 313, 314, 325, 327, 328, 330, 331, 339, 341, 343, 344, 376, 378, 380, 381, 384, 581, 621, 623, 634, 635, 636, 638], "post_hook": [37, 39, 40, 41, 46, 49, 54, 55], "push_weight": [37, 39, 40, 41, 46, 49, 54, 55], "noth": [37, 39, 40, 41, 46, 49, 54, 138, 179, 568, 619, 621], "register_collector": [37, 39, 40, 41, 46, 49, 54, 55, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 326, 332, 337], "register_post_hook": [37, 39, 40, 41, 46, 49, 54, 55], "remote_collector": [39, 50, 571, 573], "max_interv": 39, "_maybe_map_weight": [39, 41, 46, 49, 54], "_sync_weights_with_work": [39, 41, 46, 49, 54], "_skip_upd": 39, "interv": [39, 214, 267, 391, 392, 406, 418, 419, 420, 472, 620, 636], "weight_gett": 40, "vanillaweightsend": 40, "update_weight": [40, 46, 49, 324, 418, 564, 583, 585, 586, 591], "piec": [41, 94, 104, 115, 118, 119, 619, 620, 621, 628, 634, 635, 636, 638], "_push_weight": 41, "unchang": [41, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 231, 243, 250, 265, 271, 272, 275, 277, 301, 326, 332, 337, 343, 375, 377, 379, 382, 383, 392, 411, 584, 585, 619, 638], "__call__": [41, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 201, 326, 332, 337, 344, 375, 377, 379, 382, 383], "proxi": [41, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 176, 310, 325, 327, 328, 330, 331, 341, 376, 378, 380, 381, 384], "weakref": 41, "exporationtyp": [42, 44, 47], "_singl": [42, 44, 47, 50, 562], "collector_kwarg": [42, 44, 47, 50], "num_workers_per_collector": [42, 44, 47, 50], "slurm_kwarg": [42, 44, 47], "update_after_each_batch": [42, 44, 47, 50], "max_weight_update_interv": [42, 44, 47, 50], "update_interv": [42, 44], "tcp_port": [42, 44, 47, 51], "string": [42, 44, 47, 63, 88, 89, 96, 120, 123, 126, 130, 138, 142, 148, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 211, 239, 250, 263, 269, 277, 297, 302, 304, 313, 324, 325, 326, 329, 332, 337, 340, 341, 375, 377, 379, 382, 383, 391, 408, 413, 591, 619, 621, 622, 631, 638], "respect": [42, 44, 47, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 215, 219, 225, 229, 232, 244, 250, 251, 260, 265, 271, 272, 275, 277, 316, 322, 326, 332, 337, 343, 348, 350, 364, 367, 369, 375, 377, 379, 382, 383, 385, 387, 388, 410, 621, 622, 634, 635], "subnod": [42, 44, 47, 50], "fashion": [42, 47, 50, 86, 87, 109, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "distributed_back": [42, 44], "ucc": [42, 44, 47], "turn": [42, 44, 47, 50, 53, 60, 71, 86, 87, 88, 123, 137, 150, 160, 170, 176, 226, 238, 271, 274, 278, 297, 325, 327, 328, 330, 331, 376, 378, 379, 380, 381, 384, 385, 390, 409, 591, 619, 620, 622, 625, 636, 637], "submitit_delai": [42, 51], "former": [42, 44, 47, 56, 65, 68, 72, 73, 79, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 338, 340, 347, 619], "whilst": [42, 44, 47, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "latter": [42, 44, 47, 79, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 326, 332, 337, 338, 340, 347, 367, 375, 377, 379, 382, 383, 561, 562], "homonym": [42, 44, 47, 636], "visit": [42, 44, 47, 175], "facebookincub": [42, 44, 47], "tcp": [42, 44, 47, 51], "port": [42, 44, 47, 51, 54, 161, 324, 335, 336, 579, 586], "10003": [42, 44, 47, 51], "distributedweightupdat": 42, "distributedweightsyncschem": [42, 46], "liter": [44, 86, 120, 165, 170, 171, 172, 174, 175, 178, 182, 183, 185, 191, 324, 325, 327, 328, 330, 331, 332, 337, 379, 383, 568, 570, 571, 573, 577, 578, 580, 586], "frequenc": [44, 337, 420, 619], "favor": [46, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 326, 332, 337, 375, 377, 379, 382, 383, 591, 621], "restart": 46, "less": [46, 86, 87, 101, 102, 145, 176, 325, 327, 328, 330, 331, 332, 376, 378, 380, 381, 384, 561, 562, 621, 622, 638, 640], "visible_devic": 47, "tensorpipe_opt": 47, "experiment": [47, 54, 56, 64, 78, 341, 344, 419, 420], "tensorpiperpcbackendopt": 47, "rpcweightupdat": 47, "rpcweightsyncschem": 47, "collector_info": [49, 569, 570], "collector_rref": [49, 569, 570], "_td": [50, 88, 127, 359, 367], "ray_init_config": [50, 53, 66, 401, 403], "remote_config": [50, 52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "num_collector": [50, 561, 562, 619, 620], "use_env_cr": [50, 563], "autodetect": 50, "num_cpu": [50, 53, 66, 192, 193, 194, 243, 329, 401, 402, 403, 612], "num_gpu": [50, 53, 66, 194, 243, 329, 401, 402, 612], "equat": [50, 83, 130, 180, 279, 280, 312, 350, 621, 624, 636], "exce": [50, 638], "indefinit": 50, "rayreplaybuff": [50, 65, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "enfoc": 50, "rayweightupdat": 50, "rayweightsyncschem": 50, "lazili": [50, 86, 87, 96, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 636], "defer": [50, 337], "distributed_collector": [50, 66], "add_collector": 50, "shutdown_rai": [50, 66], "kill": [50, 401], "local_polici": 50, "stop_remote_collector": 50, "num_job": 51, "tcpport": 51, "submitit_main_conf": 51, "slurm_cpus_per_task": 51, "slurm_gpus_per_nod": 51, "slurm_partit": 51, "timeout_min": 51, "submitit_collection_conf": 51, "delai": [51, 371, 626], "jump": [51, 624], "host": [51, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "satellit": 51, "rendezv": 51, "hang": 51, "forev": 51, "default_config": [51, 289, 294, 311], "default_slurm_conf_main": 51, "default_slurm_conf": 51, "randompolicyfrom": 51, "boundedcontinu": [51, 58, 60, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 239, 242, 273], "dialog_turns_per_batch": [52, 53, 591], "yield_only_last_step": [52, 53], "yield_completed_trajectori": [52, 53], "total_dialog_turn": [52, 53, 88], "async_env": [52, 53], "flatten_data": [52, 53], "simplifi": [52, 55, 65, 209, 329, 625, 636, 638], "vllm": [52, 54, 55, 178, 324, 333, 334, 335, 336, 337, 579, 580, 581, 582, 583, 584, 585, 586, 591, 631], "vllmwrapper": [52, 170, 178, 326, 332, 591, 632], "mocking_class": [52, 270], "dummystrdataload": 52, "llmenv": [52, 173, 181, 185], "llm_model": 52, "gpt2": [52, 138, 179, 289, 294, 311, 329, 332, 337, 612], "token": [52, 87, 88, 89, 138, 170, 171, 172, 174, 175, 177, 178, 179, 181, 182, 183, 184, 188, 189, 193, 195, 196, 198, 324, 325, 326, 329, 330, 332, 337, 375, 377, 379, 383, 401, 402, 403, 527, 591, 593, 612, 631, 632], "get_token": 52, "pad_token": [52, 195, 196, 383], "eos_token": [52, 174, 195, 196, 383], "from_dataload": [52, 170, 171, 172, 175, 178, 185], "from_text": [52, 87, 89, 178, 185, 383], "group_repeat": [52, 170, 171, 172, 175, 178, 181, 185], "attention_mask": [52, 178, 332, 337], "22": [52, 83, 90, 108, 109, 278], "text": [52, 81, 86, 87, 88, 89, 138, 170, 171, 172, 174, 175, 177, 178, 179, 187, 189, 190, 193, 195, 196, 203, 312, 324, 325, 326, 329, 331, 332, 333, 337, 382, 383, 591, 593, 621, 631], "nontensorstack": [52, 63, 87, 96, 120, 123, 138, 172, 175, 179, 185, 199, 239, 269, 273], "plsgqejeyd": 52, "text_respons": [52, 172, 175, 177, 178, 180, 183, 193, 383, 591, 631], "ec": 52, "tjbjz3perwhz": 52, "tokens_respons": [52, 178], "as_remot": [52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "cl": [52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 620], "quantiti": [52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "reserv": [52, 53, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "alia": [52, 65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 95, 96, 97, 98, 110, 112, 116, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 348, 349, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 366, 367, 368, 369, 370, 371, 372, 375, 377, 379, 382, 383, 389, 421, 422, 571, 573], "get_policy_model": [52, 53], "rayllmcollector": [52, 591], "is_initi": [52, 53, 329, 612], "sync_it": 53, "lightweight": [53, 197, 623, 628], "dialog": [53, 88], "yeild": 53, "idl": [53, 150], "somehwat": 53, "serializ": [53, 329], "v2": [54, 55, 86, 87, 136, 137, 156, 157, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 622], "master_address": [54, 324, 335, 336, 579, 586], "master": [54, 324, 335, 336, 579, 586, 634, 635], "address": [54, 324, 335, 336, 401, 403, 579, 586, 591, 638], "localhost": [54, 161, 335, 336, 586], "master_port": [54, 324, 335, 336, 579, 586, 591], "model_metadata": [54, 55, 579, 584, 585], "tupl": [54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 98, 102, 108, 112, 114, 120, 123, 124, 125, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 221, 239, 241, 246, 287, 290, 296, 297, 298, 302, 304, 305, 307, 311, 313, 314, 324, 325, 326, 327, 328, 330, 331, 332, 337, 347, 348, 349, 350, 351, 352, 356, 357, 359, 363, 364, 365, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 408, 409, 412, 471, 541, 542, 543, 545, 546, 547, 549, 551, 556, 579, 584, 585, 587, 631, 638, 640], "metadata": [54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 79, 86, 87, 91, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 324, 325, 327, 328, 330, 331, 351, 371, 376, 378, 380, 381, 384, 584, 586, 587, 591, 621, 624, 626, 627, 634, 635, 641], "vllm_tp_size": 54, "vllmupdaterv2": [54, 591], "asyncvllm": [54, 333, 337, 579, 582, 591], "vllm_engin": [54, 55, 579, 580, 582, 584, 585, 586, 591], "reliabl": [54, 591], "get_model_metadata": [54, 55, 324, 591], "transformerswrapp": [54, 55, 170, 195, 196, 326, 329, 337, 383, 583, 591, 632], "rlvllmengin": [55, 334, 586], "vllmupdat": [55, 591], "get_tp_siz": [55, 324], "push_weights_from_transform": 55, "transformers_model": [55, 632], "pretrainedmodel": 55, "push_weights_from_transformers_optim": 55, "rollout_tensordict": 56, "_nestedkei": [56, 70, 71, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 178, 179, 180, 212, 219, 220, 221, 222, 223, 228, 229, 232, 236, 238, 241, 242, 246, 247, 251, 252, 254, 255, 256, 257, 258, 262, 264, 265, 266, 268, 271, 273, 280, 326, 332, 337], "nestedkei": [56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 102, 108, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 188, 195, 196, 199, 207, 212, 213, 214, 215, 219, 220, 221, 222, 223, 224, 228, 229, 230, 231, 232, 233, 234, 236, 238, 239, 240, 241, 242, 246, 247, 248, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 279, 280, 286, 287, 301, 312, 325, 326, 327, 328, 330, 331, 332, 337, 340, 342, 344, 350, 353, 364, 367, 376, 378, 380, 381, 382, 384, 390, 392, 408], "as_nest": 56, "x": [56, 68, 83, 86, 87, 109, 138, 176, 179, 239, 241, 268, 273, 282, 287, 288, 297, 300, 302, 304, 305, 313, 325, 326, 327, 328, 330, 331, 332, 337, 338, 341, 375, 376, 377, 378, 379, 380, 381, 383, 384, 390, 392, 415, 591, 619, 623, 634, 636, 638, 640], "max": [56, 64, 72, 101, 102, 114, 137, 177, 231, 266, 312, 349, 350, 351, 357, 366, 368, 370, 379, 408, 419, 591, 619, 621, 622, 623, 629], "durat": [56, 635], "meta": [56, 74, 79, 86, 87, 89, 128, 132, 176, 190, 325, 327, 328, 330, 331, 348, 350, 364, 367, 369, 376, 378, 380, 381, 384, 621, 634, 635, 638], "aren": [56, 264, 622], "eventu": [56, 622, 636], "recov": [56, 79, 81, 83, 84, 85, 86, 87, 108, 109, 176, 325, 327, 328, 330, 331, 345, 356, 363, 376, 378, 380, 381, 384, 633], "layout": [56, 326, 329, 332, 337], "to_padded_tensor": 56, "nested_tensor": [56, 129, 131], "stride": [56, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 290, 291, 300, 326, 332, 337, 375, 377, 379, 382, 383, 463, 620, 634, 640], "jag": 56, "focu": [56, 619, 620, 621, 623, 625, 626, 627, 634], "team": [56, 634, 635, 640], "cat": [56, 86, 87, 176, 185, 322, 325, 327, 328, 330, 331, 349, 351, 352, 363, 368, 370, 371, 372, 376, 378, 380, 381, 384, 634, 638, 640], "arang": [56, 57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 108, 109, 214, 297, 306, 405, 638], "obs_": 56, "15": [56, 78, 79, 80, 81, 82, 83, 84, 85, 109, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 190, 226, 312, 359, 638], "trajectory_id": 56, "int32": [56, 58, 73, 75, 78, 83, 108, 136, 137, 148, 149, 160, 206, 340], "data_split": 56, "got": [56, 627], "int8": [57, 126, 141, 152, 153, 219], "encod": [57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 74, 75, 76, 77, 86, 87, 121, 122, 126, 129, 130, 131, 132, 135, 136, 137, 145, 146, 148, 149, 155, 161, 162, 176, 180, 214, 231, 309, 310, 315, 317, 325, 326, 327, 328, 330, 331, 332, 337, 376, 378, 380, 381, 384, 401, 612, 620, 621, 622, 625, 636, 638], "unlik": [57, 68, 72, 73, 107, 130, 142, 143, 163, 164, 180, 340, 358, 367, 392, 567, 620, 623, 625, 627, 640], "null": [57, 58, 60, 63, 65, 70, 71, 72, 74, 75, 76, 77, 170, 178, 219, 239], "denot": [57, 635], "assert_is_in": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "belong": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 83, 278, 279, 344, 619, 627, 635], "cardin": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 297, 298, 314, 621], "outcom": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 295, 306, 319, 365, 375, 377, 379, 383, 634], "cartesian": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "clear_device_": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "is_in": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 641], "ndarrai": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 130, 176, 180, 312, 325, 327, 328, 330, 331, 347, 376, 378, 380, 381, 384, 390, 623, 634], "ignore_devic": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "arrai": [57, 58, 59, 60, 61, 62, 63, 64, 65, 70, 71, 74, 75, 76, 77, 86, 87, 90, 101, 120, 123, 126, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 185, 233, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 619, 634], "np": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 90, 130, 176, 180, 278, 325, 327, 328, 330, 331, 347, 376, 378, 380, 381, 384, 390, 623, 634, 636], "use_mask": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 152, 153], "erase_memoize_cach": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "memoiz": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 130, 180], "memoize_encod": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "broadcast": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 295, 324, 357, 370, 579, 584, 585, 586, 587, 591], "least": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 108, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 224, 243, 628, 641], "compliant": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "singleton": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 177, 288, 305, 631], "start_dim": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "end_dim": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "implements_for_spec": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "torch_funct": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "tensor_to_index": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "represent": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 96, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 250, 275, 277, 325, 326, 327, 328, 330, 331, 332, 337, 348, 367, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 593, 619, 636, 637, 641], "exanpl": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "one_hot": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "categ": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 341], "to_categorical_spec": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "idx_one_hot": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "idx_categ": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "to_categor": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "make_neg_dim": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "convert": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 88, 90, 120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 145, 146, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 229, 232, 250, 265, 271, 272, 275, 277, 279, 280, 325, 326, 327, 328, 330, 331, 332, 337, 343, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586, 593, 619, 620, 621, 636, 638], "shortcut": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 636, 641], "len": [57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 95, 97, 116, 185, 248, 288, 305, 383, 619, 622, 623, 627, 629, 634, 636, 637, 638, 640], "ndimens": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 619], "violat": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "primari": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 138, 179, 612, 627], "project": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 231, 286, 297, 298, 312, 313, 314, 339, 341, 343, 344, 399, 400, 462, 598, 640, 641], "uniformli": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 101, 102, 103, 365, 375, 377, 379, 383, 641], "normal": [57, 58, 59, 60, 61, 62, 63, 64, 67, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 246, 279, 280, 286, 288, 303, 305, 306, 320, 321, 341, 344, 350, 351, 364, 367, 382, 383, 409, 412, 563, 586, 622, 625, 635, 641], "drawn": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 265, 301, 341, 344, 621, 634, 635], "set_provisional_n": [57, 59, 61], "temporarili": [57, 59, 61, 93, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 627, 638], "dest": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 250, 275, 277, 343], "to_numpi": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "transformed_in": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 319, 563], "check_spec_encod": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "to_one_hot": [57, 59, 61, 62, 64], "hot": [57, 59, 61, 62, 64, 121, 122, 129, 131, 132, 135, 136, 137, 142, 143, 145, 146, 148, 149, 152, 153, 155, 161, 162, 163, 164, 214, 231, 297, 298, 310, 313, 314, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 622], "categ_sampl": [57, 59, 62, 64], "onehot_sampl": [57, 59, 62], "to_one_hot_spec": [57, 59, 61, 62, 64], "categoricalbox": [57, 59, 62, 64, 151], "type_check": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77], "unflatten": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 86, 87, 176, 218, 325, 327, 328, 330, 331, 340, 376, 378, 380, 381, 384], "unsqueez": [57, 58, 59, 60, 61, 62, 63, 64, 70, 71, 74, 75, 76, 77, 102, 190, 206, 215, 218, 221, 222, 268, 274, 526, 591, 619, 623, 634, 635, 636], "update_mask": [57, 59, 61, 62, 64], "leav": [57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 74, 75, 76, 77, 86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 176, 178, 179, 180, 213, 259, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 619, 627, 638], "unmask": [57, 59, 61, 62, 64, 306], "ts": [57, 59, 61, 62, 64], "boundeddiscret": [58, 60], "upper": [58, 106, 245], "continuousbox": [58, 60, 75, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 206, 239, 242, 265, 273], "provision": [59, 337], "descript": [60, 135, 163, 217, 379, 612, 620, 621], "akin": 60, "unnam": [60, 71], "constraint": [60, 144, 320, 598, 621, 634, 635], "data_cl": 60, "tensorclass": [60, 86, 87, 95, 97, 116, 176, 325, 326, 327, 328, 330, 331, 337, 376, 378, 380, 381, 384, 593], "enforc": [60, 88, 107, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 334, 337, 345, 350, 351, 367, 370, 375, 377, 379, 382, 383, 636], "step_mdp_stat": 60, "pixels_spec": 60, "observation_vector_spec": 60, "33": [60, 69, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 305, 326, 332, 337, 375, 377, 379, 382, 383], "composite_spec": 60, "observation_vector": [60, 222, 619], "_nodefault": [60, 71], "is_empti": [60, 71, 636], "recurs": [60, 71, 86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 330, 331, 332, 337, 365, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 623], "include_nest": [60, 71], "leaves_onli": [60, 71], "is_leaf": [60, 71], "step_mdp_static_onli": [60, 71], "_compositespecitemsview": [60, 71], "_compositespeckeysview": [60, 71], "reflect": [60, 71, 131, 152, 153, 212, 239, 278, 365, 375, 377, 379, 383, 552, 620, 621, 622, 635], "lock_": [60, 71], "succeed": [60, 71, 239, 273], "ones_upd": [60, 71], "pop": [60, 71, 195, 225], "keyerror": [60, 71, 171, 172, 175, 201, 272, 367, 401, 402, 612], "rand_upd": [60, 71], "refine_nam": [60, 71], "refin": [60, 71, 83, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 591], "lift": [60, 71, 83], "coexist": [60, 71], "nice": [60, 71, 621, 624, 627], "ellipsi": [60, 71], "greedili": [60, 71, 625], "spec_refin": [60, 71], "selected_kei": [60, 71, 259, 619], "unlock_": [60, 71], "_compositespecvaluesview": [60, 71], "zeros_upd": [60, 71], "nvec": [61, 62], "remove_singleton": 61, "ax": [61, 634], "m": [61, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 231, 287, 326, 332, 337, 344, 375, 377, 379, 382, 383, 620, 636], "tensor_spec": [61, 64, 74, 213, 215, 265, 342, 356, 357, 367, 369], "neither": [61, 62, 83, 161, 636], "use_regist": [62, 64], "mone_hot": 62, "boxlist": 62, "example_data": [63, 87, 175, 178, 185], "feature_dim": 63, "conform": 63, "nontensordata": [63, 78, 83, 86, 87, 123, 148, 149, 176, 185, 199, 239, 269, 273, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 390], "left": [63, 78, 79, 83, 88, 102, 108, 173, 174, 177, 178, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 218, 225, 226, 228, 229, 230, 234, 241, 244, 250, 252, 253, 259, 263, 266, 269, 271, 273, 275, 277, 280, 301, 306, 326, 332, 337, 382, 487, 620, 621, 623, 627, 628], "device_typ": [63, 557], "templat": [63, 87, 89, 170, 171, 172, 175, 195, 196, 198, 325, 330, 331, 332, 337, 393, 591, 593], "randomli": [63, 83, 107, 160, 183, 215, 245, 246, 265, 301, 341, 344, 625, 634, 635, 636, 638], "unidimension": 64, "action_valu": [64, 296, 297, 298, 313, 314, 351, 357, 365, 375, 377, 379, 383, 622, 623, 625, 629], "keepdim": [64, 591], "chosen_action_valu": [64, 313, 314, 622, 625], "priori": 64, "definit": [64, 110, 631], "one_hot_sampl": 64, "ep": [65, 72, 101, 102, 246, 279, 280, 312, 350, 379, 412, 428, 505, 515, 536, 537, 539, 540, 541, 542, 543, 546, 547, 548, 551, 619, 620, 622, 623, 626, 629], "1e": [65, 72, 101, 102, 246, 279, 280, 295, 299, 307, 319, 505, 515, 536, 537, 539, 540, 542, 543, 544, 546, 547, 548, 549, 551, 619, 620, 621, 635], "08": [65, 72, 101, 102, 505, 515, 536, 537, 542, 543, 546, 547, 548, 551], "pin_memori": [65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 249, 619, 640], "prefetch": [65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 619, 620, 622, 638], "dim_extend": [65, 68, 72, 73], "delayed_init": [65, 66, 68, 69, 72, 73], "schaul": [65, 101, 102], "quan": [65, 101, 102], "j": [65, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383, 622, 626], "antonogl": [65, 101, 102], "silver": [65, 101, 102], "2015": [65, 101, 102, 226], "arxiv": [65, 80, 83, 85, 101, 102, 121, 122, 124, 125, 136, 137, 142, 143, 145, 146, 155, 163, 164, 221, 250, 275, 289, 290, 291, 292, 293, 294, 298, 299, 300, 308, 309, 312, 315, 316, 317, 348, 349, 353, 354, 355, 356, 358, 359, 360, 361, 362, 363, 366, 367, 370, 371, 385, 637], "ab": [65, 80, 83, 85, 101, 102, 121, 122, 124, 125, 136, 137, 142, 143, 145, 146, 155, 163, 164, 220, 250, 275, 279, 289, 294, 299, 300, 308, 309, 315, 316, 317, 348, 349, 353, 354, 355, 356, 359, 360, 361, 363, 366, 367, 370, 637], "1511": [65, 101, 102, 300], "05952": [65, 101, 102], "expon": [65, 72, 101, 102], "\u03b1": [65, 72], "uniform": [65, 72, 101, 102, 326, 332, 337, 634], "delta": [65, 72, 319, 341, 344, 598, 634], "1_000": [65, 68, 72, 73, 634, 638], "mini": [65, 68, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 635], "decid": [65, 68, 72, 73, 612, 634, 640], "incompat": [65, 68, 72, 73, 369, 638], "drop_last": [65, 68, 72, 73, 107, 109, 432], "notion": [65, 68, 72, 73], "capac": [65, 68, 72, 73, 95, 97, 101, 102, 108, 116, 621, 627], "caution": [65, 68, 72, 73, 107, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 401, 641], "codebas": [65, 68, 72, 73, 636], "unbind": [65, 68, 72, 73, 86, 87, 176, 244, 325, 327, 328, 330, 331, 340, 376, 378, 380, 381, 383, 384, 591], "transform_factori": [65, 66, 68, 69, 72, 73], "return_info": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 638], "tensordictprioritizedreplaybuff": [65, 640], "priority_weight": [65, 72, 101, 102], "update_prior": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 411, 620, 638, 640], "36278465": 65, "invert": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 621], "default_remote_class_config": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "overriden": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "tempfil": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 95, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 559, 619, 620, 622, 623, 627, 634, 637, 638], "tensordictreplaybuff": [65, 66, 67, 68, 69, 72, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 108, 109, 114, 220, 221, 411, 437, 559, 619, 620, 622, 638], "1_000_000": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 108, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 619, 622, 634], "td_error": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 351, 352, 353, 355, 356, 357, 358, 363, 365, 368, 370, 371, 372, 375, 377, 379, 383, 619, 638, 640], "update_tensordict_prior": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 619, 638, 640], "temporarydirectori": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 619, 620, 622, 623, 627, 634, 637, 638], "tmpdir": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 619, 620, 623, 634], "rb_load": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "empty_write_count": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "cursor": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "ambigu": [65, 66, 68, 69], "pytre": [65, 66, 68, 69, 72, 73, 86, 87, 98, 117, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "cut": [65, 66, 68, 69], "insert_transform": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 171, 172, 175, 216, 272], "insert": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 94, 104, 114, 115, 118, 119, 171, 172, 175, 195, 216, 221, 225, 262, 272, 274, 591], "__iter__": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 185], "register_load_hook": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "register_save_hook": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "set_sampl": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "set_storag": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "set_writ": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "far": [65, 66, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 175, 303, 320, 321, 379, 591, 629, 636, 641], "replay_buffer_cl": 66, "optiona": 66, "asyncio": [66, 120], "ray_buff": 66, "object_store_memori": 66, "600": 66, "await": 66, "invoc": 67, "friendli": [67, 619], "public": [67, 82, 111, 250, 277], "include_info": [67, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85], "checkpoint": [68, 91, 93, 95, 99, 110, 111, 113, 117, 401, 417, 613, 638], "roundrobinwrit": [68, 78, 79, 80, 81, 82, 83, 84, 85, 431], "depth": [68, 74, 120, 123, 126, 130, 138, 144, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 288, 290, 291, 292, 293, 297, 299, 300, 305, 308, 309, 463, 464, 467, 468, 469, 620, 624, 626, 627, 633, 634, 635, 638], "_pytre": [68, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 638], "tree_map": [68, 86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 638], "assert0": [68, 638], "writerensembl": [69, 112], "sample_from_al": [69, 78, 106], "num_buffer_sampl": [69, 106], "_c": [69, 72], "ensembl": [69, 106, 112, 113, 119, 343, 368, 435, 436], "forbidden": 69, "collat": [69, 171, 172, 175], "rb0": 69, "rb1": 69, "another_kei": 69, "pixels33": 69, "0x13a2ef430": 69, "0x13a2f9310": 69, "interpolationmod": 69, "bilinear": [69, 254, 512], "0x13a2f9220": 69, "0x13a2f9f70": 69, "tensordictroundrobinwrit": [69, 73], "0x13a2d9b50": 69, "0x13a2f95b0": 69, "0x128648260": 69, "data0": [69, 96], "randint": [69, 86, 87, 176, 185, 268, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 638], "255": [69, 268, 638], "244": [69, 250, 277], "data1": [69, 96, 640], "thrown": [70, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 638], "heterogen": [70, 71, 96, 120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 619, 620], "semant": [70, 71, 129, 131, 637], "priority_kei": [72, 73, 101, 351, 353, 356, 357, 358, 363, 365, 368, 370, 371, 372, 375, 377, 379, 383, 638, 640], "reduct": [72, 101, 102, 114, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 379, 383, 408, 428, 471], "prioritizedreplaybuff": [72, 640], "min": [72, 101, 102, 114, 312, 349, 350, 351, 357, 366, 368, 370, 375, 379, 408, 620, 621], "median": [72, 101, 102, 114, 130, 136, 137, 180, 214, 341, 344], "_encode_memo_dict": 74, "possess": [74, 79], "describ": [74, 86, 87, 176, 202, 222, 319, 320, 325, 327, 328, 330, 331, 342, 353, 376, 378, 380, 381, 384, 395, 619, 621, 634, 635, 636, 641], "make_composite_from_td": [74, 636], "educ": 74, "guess": 74, "knowledg": [74, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 626, 628], "dataset_id": [78, 79, 80, 81, 83, 84, 85], "num_proc": 78, "slice_len": [78, 83, 102, 108, 109, 392, 433, 434, 622], "strict_len": 78, "mp_start_method": [78, 79, 80, 81, 82, 83, 84, 85, 150, 158, 270, 620, 640], "arari": 78, "2600": 78, "million": 78, "consequ": [78, 93, 627], "50x10": 78, "available_dataset": [78, 79, 80, 81, 82, 83, 84, 85, 108, 109], "ataridqn": 78, "greater": [78, 102, 108, 109, 226, 242, 244, 302, 304, 351, 619, 620], "strict_length": [78, 83, 102, 108, 109, 392, 433, 434, 622], "shorter": [78, 83, 102, 108, 109], "Be": [78, 83, 102, 108, 109], "game_nam": 78, "krull": 78, "1d": [78, 101, 102, 108, 109, 114], "1m": [78, 83, 552, 619, 621, 622], "cheapli": 78, "invalid_rang": 78, "999998": 78, "999999": 78, "add_count": 78, "84": [78, 90, 108, 254, 482, 487, 512, 622, 623], "valueestim": [78, 348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 619, 634, 635], "convolut": [78, 288, 290, 291, 463, 623, 625], "2657628": 78, "2657629": 78, "2657630": 78, "2657631": 78, "2657632": 78, "2657633": 78, "2657634": 78, "2657635": 78, "2657636": 78, "2657637": 78, "2657638": 78, "2657639": 78, "2657640": 78, "2657641": 78, "2657642": 78, "2657643": 78, "2657644": 78, "2657645": 78, "2657646": 78, "2657647": 78, "2657648": 78, "2657649": 78, "2657650": 78, "2657651": 78, "2657652": 78, "2657653": 78, "2657654": 78, "2657655": 78, "2657656": 78, "2657657": 78, "2657658": 78, "2657659": 78, "2657660": 78, "2657661": 78, "2657662": 78, "2657663": 78, "2657664": 78, "2657665": 78, "2657666": 78, "2657667": 78, "2657668": 78, "2657669": 78, "2657670": 78, "2657671": 78, "2657672": 78, "2657673": 78, "2657674": 78, "2657675": 78, "2657676": 78, "2657677": 78, "2657678": 78, "2657679": 78, "2657680": 78, "2657681": 78, "2657682": 78, "2657683": 78, "2657684": 78, "2657685": 78, "2657686": 78, "2657687": 78, "2657688": 78, "2657689": 78, "2657690": 78, "2657691": 78, "1995687": 78, "1995688": 78, "1995689": 78, "1995690": 78, "1995691": 78, "1995692": 78, "1995693": 78, "1995694": 78, "1995695": 78, "1995696": 78, "1995697": 78, "1995698": 78, "1995699": 78, "1995700": 78, "1995701": 78, "1995702": 78, "1995703": 78, "1995704": 78, "1995705": 78, "1995706": 78, "1995707": 78, "1995708": 78, "1995709": 78, "1995710": 78, "1995711": 78, "1995712": 78, "1995713": 78, "1995714": 78, "1995715": 78, "1995716": 78, "1995717": 78, "1995718": 78, "1995719": 78, "1995720": 78, "1995721": 78, "1995722": 78, "1995723": 78, "1995724": 78, "1995725": 78, "1995726": 78, "1995727": 78, "1995728": 78, "1995729": 78, "1995730": 78, "1995731": 78, "1995732": 78, "1995733": 78, "1995734": 78, "1995735": 78, "1995736": 78, "1995737": 78, "1995738": 78, "1995739": 78, "1995740": 78, "1995741": 78, "1995742": 78, "1995743": 78, "1995744": 78, "1995745": 78, "1995746": 78, "1995747": 78, "1995748": 78, "1995749": 78, "1995750": 78, "replaybufferensembl": [78, 106, 112, 119], "untouch": [78, 83, 86, 87, 88, 173, 174, 176, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 273, 280, 325, 327, 328, 330, 331, 376, 378, 380, 381, 382, 384], "_max_run": 78, "dataset_asterix": 78, "asterix": 78, "dataset_pong": 78, "buffer_id": [78, 106, 112], "hidden": [78, 150, 158, 220, 283, 284, 285, 290, 299, 302, 304, 308, 309, 315, 316, 343, 346, 350, 364, 367, 622, 633, 640], "data_path": [78, 79, 80, 81, 82, 83, 84, 85], "data_path_root": [78, 79, 80, 81, 82, 83, 84, 85], "delet": [78, 79, 80, 81, 82, 83, 84, 85, 97, 222, 262, 400], "fn": [78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 273, 307, 326, 332, 337, 375, 377, 379, 382, 383, 530, 561, 562], "chunksiz": [78, 79, 80, 81, 82, 83, 84, 85], "num_chunk": [78, 79, 80, 81, 82, 83, 84, 85], "max_tasks_per_child": [78, 79, 80, 81, 82, 83, 84, 85], "worker_thread": [78, 79, 80, 81, 82, 83, 84, 85], "index_with_gener": [78, 79, 80, 81, 82, 83, 84, 85], "num_fram": [78, 79, 80, 81, 82, 83, 84, 85], "unitari": [78, 79, 80, 81, 82, 83, 84, 85, 636], "subsequ": [78, 79, 80, 81, 82, 83, 84, 85, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 217, 326, 332, 337, 375, 377, 379, 382, 383, 566, 574, 622, 634], "distance_from_origin": [78, 79, 80, 81, 82, 83, 84, 85], "forward_reward": [78, 79, 80, 81, 82, 83, 84, 85], "qpo": [78, 79, 80, 81, 82, 83, 84, 85], "qvel": [78, 79, 80, 81, 82, 83, 84, 85], "reward_ctrl": [78, 79, 80, 81, 82, 83, 84, 85, 130, 150, 180], "reward_forward": [78, 79, 80, 81, 82, 83, 84, 85], "reward_surv": [78, 79, 80, 81, 82, 83, 84, 85], "x_posit": [78, 79, 80, 81, 82, 83, 84, 85, 130, 150, 180], "x_veloc": [78, 79, 80, 81, 82, 83, 84, 85, 130, 150, 180], "y_posit": [78, 79, 80, 81, 82, 83, 84, 85], "y_veloc": [78, 79, 80, 81, 82, 83, 84, 85], "achieved_go": [78, 79, 80, 81, 82, 83, 84, 85], "desired_go": [78, 79, 80, 81, 82, 83, 84, 85], "27": [78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 108, 109, 121, 122, 150, 158, 176, 226, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "_collate_id": [78, 79, 80, 81, 82, 83, 84, 85], "0x120e21dc0": [78, 79, 80, 81, 82, 83, 84, 85], "cattensor": [78, 79, 80, 81, 82, 83, 84, 85, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 481, 619, 633, 636, 641], "cat_tensor": [78, 79, 80, 81, 82, 83, 84, 85], "cat_next_tensor": [78, 79, 80, 81, 82, 83, 84, 85], "func": [78, 79, 80, 81, 82, 83, 84, 85, 281], "new_storag": [78, 79, 80, 81, 82, 83, 84, 85], "31": [78, 79, 80, 81, 82, 83, 84, 85, 108, 136, 137], "full_storag": [78, 79, 80, 81, 82, 83, 84, 85], "0x168406fc0": [78, 79, 80, 81, 82, 83, 84, 85], "from_env": 79, "use_truncated_as_don": 79, "direct_download": 79, "terminate_on_end": 79, "env_kwarg": [79, 84, 85, 218, 477, 561, 562, 619], "d4rl": [79, 85], "reconstruct": [79, 108, 109, 360, 619, 641], "regard": [79, 85, 298, 348, 358, 367, 619, 621, 636], "get_dataset": 79, "qlearning_dataset": 79, "fewer": [79, 102, 108], "unexpectedli": 79, "traj_split": 79, "observationnorm": [79, 279, 280, 505, 563, 619, 620, 621, 622, 640], "maze2d": 79, "umaz": 79, "loc": [79, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180, 241, 246, 257, 279, 280, 283, 284, 285, 303, 307, 320, 321, 341, 344, 346, 348, 349, 351, 363, 367, 368, 369, 370, 505, 515, 553, 563, 598, 619, 620, 621, 622, 625, 635, 640], "gen": 80, "dgrl": 80, "accompani": [80, 218, 263], "gap": 80, "2312": 80, "05742": 80, "gen_dgrl": 80, "procgen": 80, "bigfish": 80, "bossfight": 80, "1m_e": 80, "1m_": 80, "comma": [80, 623], "npy": 80, "mmap": [80, 84, 85], "minut": 80, "huggingfac": [80, 85, 177, 332], "internet": [80, 85], "connect": [80, 85, 161, 190, 564, 565, 567, 568, 570, 571, 572, 573, 575, 578, 580, 586], "load_from_local_minari": 81, "minari": 81, "websit": [81, 83, 631], "currenrtli": 81, "minari_data": 81, "door": 81, "human": [81, 171, 636], "torchrl_logg": [81, 629, 631], "28": [81, 108, 109, 377, 379], "39": [81, 136, 137], "door_body_po": 81, "openml": [82, 147, 452], "dua": 82, "graff": 82, "2017": 82, "uci": [82, 123], "archiv": 82, "ic": 82, "edu": 82, "ml": [82, 161, 162, 324], "scikit": [82, 147], "sklearn": [82, 147], "panda": 82, "adult_num": [82, 147], "adult_onehot": [82, 147], "mushroom_num": [82, 147], "mushroom_onehot": [82, 147], "covertyp": [82, 147], "shuttl": [82, 147], "magic": [82, 147, 623, 624], "shuffl": [83, 107, 109, 171, 172, 175, 432, 635], "embodi": [83, 637], "collabor": 83, "21": [83, 84, 108, 109, 150, 152, 153, 158, 226, 618, 639], "institut": 83, "demonstr": [83, 591, 621, 623, 627, 631, 632, 634, 635, 636, 638, 641], "527": 83, "skill": 83, "160266": 83, "googl": [83, 84, 121, 122, 142, 143, 148, 149, 175, 177, 621, 622, 631, 634, 635], "open_x_embodi": 83, "2310": [83, 155], "08864": 83, "language_instruct": 83, "get_non_tensor": 83, "nor": [83, 161], "insuffici": 83, "chosen": [83, 163, 164, 264, 265, 314, 392, 612, 628], "openx": 83, "__will": 83, "change__": 83, "crop": [83, 223, 251, 392, 487], "compli": 83, "modal": [83, 326, 332, 337, 619], "cmu_stretch": [83, 392], "discount": [83, 127, 255, 349, 355, 358, 359, 361, 385, 386, 387, 388, 419, 620, 621, 634, 635], "is_init": [83, 85, 220, 240, 302, 304, 312, 340, 385, 622, 623], "language_embed": 83, "512": [83, 300], "green": [83, 634], "garbag": [83, 567], "lid": 83, "roboset": 84, "h5": [84, 85, 86, 87, 93, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "roboh": [84, 155, 455], "excludetransform": [84, 259, 493, 638], "fk1": 84, "v4": [84, 130, 150, 180, 214, 254, 619, 621, 637, 640], "expert": 84, "fk1_microopenrandom_v2d": 84, "concis": [84, 626], "20": [84, 108, 109, 114, 120, 123, 126, 130, 134, 138, 148, 149, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 264, 300, 377, 379, 401, 405, 544, 632, 638, 641], "18": [84, 108, 109, 156, 157, 163, 164, 270], "23": [84, 109, 226, 282], "19": [84, 108, 109, 114, 226], "75": [84, 108, 538], "totensor": 85, "image_s": 85, "v": [85, 279, 283, 356, 363, 370, 605, 619, 620], "npz": 85, "2206": [85, 145, 146], "04779": [85, 349, 355], "vd4rl": 85, "squar": [85, 223, 228, 303, 320, 321, 350, 367, 379, 392, 591], "rectangular": [85, 288], "walker_walk": 85, "64px": 85, "height": [85, 223, 228, 254, 482, 487], "veloc": [85, 120, 123, 124, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 634, 635, 636, 641], "audio": 86, "function_cal": 86, "_wrap_td_method": 86, "wrapped_func": 86, "0x7f7cc561fe20": 86, "mime_typ": 86, "function_nam": 86, "function_arg": 86, "copy_exist": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "return_earli": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "share_non_tensor": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "robust_kei": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_ani": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "auto_batch_s": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "batch_dim": [86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 563], "incur": [86, 87, 121, 122, 136, 137, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "overhead": [86, 87, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 212, 325, 327, 328, 330, 331, 344, 376, 378, 380, 381, 384], "involv": [86, 87, 129, 131, 132, 142, 143, 155, 176, 218, 221, 270, 302, 304, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 624, 626], "opinion": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "term": [86, 87, 96, 176, 188, 195, 241, 325, 327, 328, 330, 331, 348, 357, 367, 376, 378, 380, 381, 384, 418, 620, 621, 624, 625, 635], "obj": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_dataclass": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "namedtupl": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 325, 326, 327, 328, 330, 331, 332, 337, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384], "from_namedtupl": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_dict": [86, 87, 176, 185, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_tupl": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_struct_arrai": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "hdf5": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_h5": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "dest_cl": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "as_tensorclass": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "convers": [86, 87, 121, 122, 136, 137, 170, 172, 175, 176, 186, 195, 196, 209, 325, 327, 328, 330, 331, 376, 378, 379, 380, 381, 384, 565, 568, 570, 571, 573, 578, 580, 586, 591, 593, 631, 632], "persistenttensordict": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "key1": [86, 87, 176, 222, 262, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 405, 413, 640], "key2": [86, 87, 176, 222, 262, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 405, 413, 640], "as_modul": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "use_state_dict": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "lazy_stack": [86, 87, 88, 89, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 383, 384, 591, 633], "expand_ident": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "ensebml": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "vmap": [86, 87, 176, 325, 327, 328, 330, 331, 343, 346, 349, 351, 357, 363, 365, 368, 370, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 605], "tensordictparam": [86, 87, 176, 325, 327, 328, 330, 331, 344, 376, 378, 380, 381, 384], "densli": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "dens": [86, 87, 120, 176, 306, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 591], "reinstanti": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "tempt": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "orign": [86, 87, 176, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 383, 384], "longer": [86, 87, 176, 189, 282, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 591, 620, 622, 629, 634, 635, 638], "empty_modul": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "n_model": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "bia": [86, 87, 88, 101, 102, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 239, 250, 265, 270, 271, 272, 275, 277, 288, 290, 291, 292, 293, 299, 300, 301, 302, 304, 305, 307, 312, 325, 326, 327, 328, 330, 331, 332, 337, 343, 351, 365, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 619, 620, 621, 622, 635], "exec_modul": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "to_modul": [86, 87, 176, 325, 327, 328, 330, 331, 343, 346, 376, 378, 380, 381, 384, 619, 640], "backprop": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "named_tupl": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "a_tensor": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "a_str": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "nt": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "to_namedtupl": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "genericdict": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_pytre": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "biject": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "castabl": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "surject": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "weird": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "weirdlookingclass": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "weird_kei": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "pytree_recon": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "to_pytre": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_remote_init": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "processgroup": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "init_remot": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "src": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "struct_arrai": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "rex": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "fido": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "u10": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "ag": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "i4": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "f4": [86, 87, 123, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "x_recon": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "to_struct_arrai": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "from_tensordict": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "non_tensordict": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "my_tupl": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "fromkei": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "getattr": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "load_memmap": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "load_": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "pathlib": [86, 87, 95, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 415, 419, 420, 623], "load_memmap_": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "non_block": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 325, 326, 327, 328, 330, 331, 332, 337, 343, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384], "robust": [86, 87, 176, 251, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 591], "decod": [86, 87, 138, 176, 179, 207, 308, 324, 325, 326, 327, 328, 330, 331, 332, 337, 376, 378, 380, 381, 384, 591], "emit": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "saved_td": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "td_load": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "_subclass": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "faketensormod": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "faketensor": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "strict": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 325, 326, 327, 328, 330, 331, 332, 337, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 612, 623], "from_flatten": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "attemptedli": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "destin": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 212, 220, 229, 230, 232, 239, 270, 272, 275, 279, 325, 326, 327, 328, 330, 331, 332, 337, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 392, 418, 419, 472, 577], "maybe_dense_stack": [86, 87, 176, 185, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "existsok": [86, 87, 95, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "mimic": [86, 87, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 176, 178, 179, 180, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "non_tensor": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "charact": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 621, 623], "throw": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 325, 326, 327, 328, 330, 331, 332, 337, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 641], "cross": [86, 87, 176, 325, 326, 327, 328, 330, 331, 332, 337, 376, 378, 380, 381, 384, 589], "anymor": [86, 87, 176, 272, 325, 327, 328, 330, 331, 343, 376, 378, 380, 381, 384], "tensordictfutur": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "serialis": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "deepli": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "memmap_": [86, 87, 176, 279, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "memmap_lik": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "contentless": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "memmap_refresh_": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "refresh": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384, 629, 634, 635], "saved_path": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "setattr": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "tent": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "keep_var": [86, 87, 88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 325, 326, 327, 328, 330, 331, 332, 337, 351, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384], "to_tensordict": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "retain_non": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "discrard": [86, 87, 176, 325, 327, 328, 330, 331, 376, 378, 380, 381, 384], "contentbas": 87, "is_complet": 87, "tool_cal": 87, "tool_respons": [87, 193, 591], "apply_chat_templ": [87, 89, 170, 193, 383, 591, 631], "autotoken": [87, 89, 170, 171, 172, 174, 175, 182, 183, 189, 193, 195, 196, 325, 330, 331, 332, 337, 383, 591, 631, 632], "autoprocessor": 87, "add_generation_prompt": [87, 89, 195, 196, 325, 383], "chat_templ": [87, 198, 325, 332, 337, 383], "chat_template_nam": [87, 89, 325, 330, 331, 332, 337, 383], "continue_final_messag": 87, "return_tensor": [87, 195, 330], "return_dict": [87, 89, 196], "return_assistant_tokens_mask": [87, 89, 195, 196], "chat": [87, 89, 170, 171, 172, 175, 184, 193, 195, 196, 198, 325, 330, 331, 332, 337, 383, 591, 593, 632], "pretrainedtoken": [87, 170, 181, 332, 337], "prompt": [87, 88, 170, 171, 172, 173, 175, 177, 178, 183, 185, 190, 193, 324, 325, 327, 329, 330, 331, 332, 337, 379, 382, 591, 632], "im_start": [87, 172, 175, 193, 591], "assist": [87, 89, 170, 172, 175, 183, 189, 190, 193, 195, 196, 332, 337, 379, 383, 591, 593, 622, 631, 632], "preval": 87, "messag": [87, 89, 170, 183, 187, 565, 566, 567, 568, 570, 571, 573, 574, 575, 578, 580, 586, 591, 632], "pt": [87, 195, 330, 394, 459], "assistant_mask": 87, "qwen": [87, 172, 175, 183, 193, 324, 332, 333, 334, 337, 383, 591, 631, 632], "dialogpt": 87, "falcon": 87, "deepseek": 87, "chatml_format": [87, 332, 337, 383], "default_spec": [87, 325, 327, 328, 330, 331], "set_list_to_stack": [87, 175, 190, 193, 195, 196, 197, 591, 631], "foo": [87, 95, 97, 116, 638, 641], "from_chat": [87, 89, 170, 195, 196, 332, 337, 383, 632], "from_pretrain": [87, 89, 138, 172, 175, 179, 183, 193, 195, 196, 324, 329, 332, 337, 383, 591, 631, 632], "qwen2": [87, 172, 175, 183, 193, 324, 333, 334, 337, 591, 631, 632], "7b": [87, 89, 324, 591, 631], "nyou": [87, 175], "im_end": [87, 172, 183, 193, 591, 631], "nwrite": 87, "capit": [87, 631, 632], "franc": [87, 631, 632], "germani": 87, "pari": [87, 175, 631], "berlin": 87, "answer": [87, 172, 174, 175, 177, 183, 591, 631], "topk_siz": 88, "prompt_kei": [88, 177, 382], "rewards_kei": [88, 382], "k": [88, 287, 326, 332, 337, 605], "topk": 88, "selector": [88, 631], "25": [88, 226, 471, 612, 619], "wrote": 88, "top3": 88, "r3": 88, "as_padded_tensor": [88, 178, 185, 196, 326, 332, 337], "add_modul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "init_weight": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "fill_": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 620, 622], "net": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 291, 293, 296, 300, 326, 332, 337, 348, 349, 351, 357, 363, 367, 368, 369, 370, 375, 377, 379, 382, 383, 463, 464, 467, 469, 559, 620, 636, 637, 640], "requires_grad": [88, 120, 121, 122, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 270, 272, 326, 332, 337, 344, 351, 370, 375, 377, 379, 382, 383, 442], "bfloat16": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "datatyp": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 638], "member": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 365, 375, 377, 379, 382, 383, 392], "xdoctest": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 239, 250, 265, 270, 271, 272, 275, 277, 326, 332, 337, 343, 351, 365, 370, 375, 377, 379, 382, 383], "buf": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "20l": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 365, 375, 377, 379, 382, 383], "1l": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 365, 375, 377, 379, 382, 383], "5l": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 365, 375, 377, 379, 382, 383], "doubl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 229, 230, 232, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 353, 358, 368, 375, 377, 379, 382, 383, 580, 581, 582, 583, 619, 620, 621, 622, 641], "eval": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 279, 326, 332, 337, 350, 367, 375, 377, 379, 382, 383, 619, 620, 621], "evalu": [88, 120, 123, 126, 130, 131, 138, 142, 143, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 226, 272, 295, 306, 310, 321, 326, 332, 337, 368, 375, 377, 379, 382, 383, 554, 555, 612, 620, 621, 629], "batchnorm": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 272, 326, 332, 337, 375, 377, 379, 382, 383], "extra_repr": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "transformthatmeasuresbyt": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 382], "byte": [88, 90, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 382], "bytes_in_td": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 215, 217, 218, 220, 221, 222, 225, 226, 227, 230, 233, 234, 235, 237, 240, 241, 243, 249, 251, 252, 253, 255, 258, 259, 262, 263, 264, 265, 266, 267, 269, 270, 271, 275, 276, 278, 279, 382], "get_buff": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "docstr": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 624, 625], "get_submodul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "explan": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "qualifi": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "referenc": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "get_extra_st": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 375, 377, 379, 382, 383], "set_extra_st": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 375, 377, 379, 382, 383], "picklabl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 375, 377, 379, 382, 383], "get_paramet": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "sai": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 634, 637, 641], "net_b": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "net_c": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "conv": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 326, 332, 337, 375, 377, 379, 382, 383, 620], "conv2d": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 290, 291, 300, 326, 332, 337, 375, 377, 379, 382, 383], "kernel_s": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 288, 290, 291, 300, 308, 326, 332, 337, 375, 377, 379, 382, 383, 463, 620, 640], "diagram": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "degre": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 227, 326, 332, 337, 375, 377, 379, 382, 383], "named_modul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "o": [88, 91, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "half": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383, 619], "ipu": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "descend": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383], "get_swap_module_params_on_convers": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383], "persist": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 212, 239, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383, 401, 612], "preserv": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 343, 351, 370, 375, 377, 379, 382, 383], "missing_kei": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383], "unexpected_kei": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383], "l": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 621, 636], "idx": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "mtia": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "named_buff": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "remove_dupl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 365, 375, 377, 379, 382, 383], "prepend": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 365, 375, 377, 379, 382, 383, 623], "running_var": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "named_children": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "conv4": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "conv5": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "memo": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "named_paramet": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 241, 326, 332, 337, 365, 375, 377, 379, 382, 383], "register_backward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "removablehandl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_full_backward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_buff": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "running_mean": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "alongsid": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 591, 612, 628], "num_featur": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_forward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "with_kwarg": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "always_cal": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_module_forward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "regardless": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 350, 364, 367, 375, 377, 379, 382, 383], "register_forward_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "And": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 626], "forward_pr": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_module_forward_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "rule": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 229, 232, 326, 332, 337, 344, 375, 377, 379, 382, 383, 621], "ordinarili": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "grad_input": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "grad_output": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "technic": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 620, 622, 623, 625], "register_module_full_backward_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_full_backward_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "backward_pr": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_module_full_backward_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_load_state_dict_post_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "incompatible_kei": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_load_state_dict_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "local_metadata": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "error_msg": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "noqa": [88, 120, 123, 126, 130, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 623], "b950": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_modul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_paramet": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_state_dict_post_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "register_state_dict_pre_hook": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "requires_grad_": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 623], "autograd": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383], "freez": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 279, 280, 326, 332, 337, 375, 377, 379, 382, 383], "finetun": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "gan": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "set_submodul": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "share_memori": [88, 120, 123, 126, 127, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 619], "share_memory_": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383, 640], "averag": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 279, 280, 312, 326, 332, 337, 351, 359, 360, 370, 375, 377, 379, 382, 383, 412, 591, 619, 621], "shallow": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 351, 370, 375, 377, 379, 382, 383, 622], "detach": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 239, 270, 272, 326, 332, 337, 351, 362, 365, 370, 371, 375, 377, 379, 382, 383, 385, 386, 387, 388, 619], "memory_format": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "channels_last": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "pin": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "4d": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "ignore_w": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "1913": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "3420": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "5113": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "2325": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "torch_doctest_cuda1": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "gpu1": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "1914": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "5112": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "2324": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "float16": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "cdoubl": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "3741": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "2382": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "5593": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "4443": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "complex128": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "6122": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "1150": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 225, 250, 265, 271, 272, 275, 277, 326, 332, 337, 343, 375, 377, 379, 382, 383], "to_empti": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "transform_done_spec": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 230, 243, 262, 269, 271, 273, 382], "transform_env_batch_s": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 218, 225, 271, 382], "transform_env_devic": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 225, 230, 271, 382], "transform_full_done_spec": [88, 173, 174, 177, 183, 184, 185, 186, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 218, 225, 229, 230, 234, 241, 244, 252, 253, 259, 263, 269, 271, 273, 280, 382], "dst_type": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "xpu": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "set_to_non": [88, 120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 326, 332, 337, 375, 377, 379, 382, 383], "template_nam": 89, "inverse_pars": 89, "model_family_keyword": 89, "llama": 89, "mistral": 89, "histori": [89, 170, 171, 172, 174, 175, 178, 183, 184, 186, 189, 190, 193, 195, 196, 197, 325, 326, 329, 330, 331, 332, 337, 383, 591, 631], "jinja2": 89, "pars": [89, 174, 186, 198, 200, 203, 330, 331, 591, 593, 631, 638], "parser": [89, 135, 174, 186, 187, 197, 203, 560, 563, 591], "llama_templ": 89, "inst": 89, "elif": [89, 591, 619, 620, 631], "endgener": 89, "endif": 89, "endfor": 89, "parse_llama_text": 89, "findal": 89, "dotal": 89, "user_cont": 89, "assistant_cont": 89, "strip": [89, 620], "hf": 89, "hello": [89, 170, 195, 196, 324, 332, 333, 337, 383, 401, 612], "hi": [89, 332, 337], "Or": [89, 156, 157], "compression_fn": 90, "decompression_fn": 90, "compression_level": 90, "decompress": 90, "sensori": 90, "zstd": 90, "verifi": [90, 171, 367], "attach": [90, 95, 96, 97, 98, 110, 112, 116, 620], "entiti": [90, 95, 96, 97, 98, 110, 112, 116], "to_bytestream": 90, "data_to_bytestream": 90, "compact": [92, 93, 100], "shift": [92, 93, 100, 385, 386, 387, 388, 621], "checkpoint_fil": 93, "h5_kwarg": 93, "iff": 93, "suffix": [93, 409], "h5py": 93, "create_dataset": 93, "increas": [93, 221, 266, 312, 350, 367, 379, 383, 634, 635], "immut": [94, 120, 123, 126, 130, 138, 150, 154, 158, 159, 170, 171, 172, 175, 178, 179, 180, 253, 272], "scratch_dir": [95, 619, 620, 622, 627, 634, 637, 638], "shared_init": [95, 97, 424, 426], "mistak": [95, 97, 116], "overewritten": 95, "main_ckpt_dir": 95, "rb_memmap": 95, "10_000_000": 95, "myclass": [95, 97, 116], "lazystacktensordict": 96, "heterougen": 96, "linearli": 96, "densifi": 96, "unlimit": [96, 98], "st": 96, "consolid": 97, "cleanup_memmap": 97, "expans": [97, 365, 375, 377, 379, 383], "ram": [97, 129, 131, 628, 638], "zero_": [97, 116, 206], "liststoag": 99, "max_priority_within_buff": [101, 102], "proport": [101, 638], "magnitud": [101, 102, 619, 634], "tempor": [101, 302, 304, 386, 387], "focus": [101, 102, 612, 619, 626], "p_i": [101, 102], "delta_i": [101, 102], "epsilon": [101, 102, 246, 286, 301, 312, 412, 620, 621, 622, 625], "frac": [101, 102, 621], "sum_j": [101, 102], "p_j": [101, 102], "w_i": [101, 102], "cdot": [101, 102, 383], "aggress": [101, 102, 383], "bias": [101, 102, 619], "toward": [101, 102, 277], "unbias": [101, 102], "anneal": [101, 102, 312, 620, 625, 634], "guidelin": [101, 102], "math": [101, 102, 190], "data_0": 101, "data_1": 101, "smoothen": 101, "tdrb": 101, "pack": [101, 332, 621, 624, 641], "nd": [101, 102], "sum_tre": [101, 102], "min_tre": [101, 102], "end_kei": [102, 108, 109, 433, 434, 622], "traj_kei": [102, 108, 109, 433, 434, 638], "cache_valu": [102, 108, 109, 433, 434, 622], "truncated_kei": [102, 108, 109, 255, 263, 433, 434, 521], "closer": [102, 640], "commonli": [102, 108, 109, 641], "readili": [102, 108, 109, 344], "conjunct": [102, 108, 109, 620], "buffer0": [102, 108], "immutablewrit": [102, 108], "buffer1": [102, 108], "other_sampl": [102, 108], "short": [102, 108, 109, 120, 121, 122, 123, 126, 130, 136, 137, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 332, 620, 621, 624, 625, 635, 638], "tolist": [102, 591], "120110917137936e": 102, "06": [102, 295, 319, 539, 549], "roundrobin": [104, 115], "consum": [107, 109, 340, 620, 621, 627, 635, 638], "incomplet": [107, 109, 183], "fresh": [107, 185, 567, 575], "haven": [107, 637], "remain": [107, 183, 191, 220, 230, 231, 241, 243, 264, 591, 612, 626], "draw": [107, 301], "use_gpu": [108, 109, 433, 434], "acceler": [108, 109, 130, 180, 634, 635], "ep_1": [108, 109], "ep_2": [108, 109], "73": 108, "74": 108, "76": 108, "77": 108, "41": 108, "42": [108, 305, 348, 349, 351, 352, 356, 363, 370], "43": 108, "44": 108, "45": 108, "67": [108, 633], "68": 108, "69": 108, "70": 108, "71": 108, "80": [108, 121, 122], "82": 108, "83": 108, "78": 108, "79": 108, "320": [108, 109, 124, 125], "550": [108, 109], "700": [108, 109], "dataid": [108, 109], "counter": [109, 191, 226, 270, 340, 407, 623], "request": [109, 201, 218, 251, 324, 330, 564, 612], "51": 109, "__len__": 110, "rank_kei": 114, "flat": [114, 385], "get_insert_index": 114, "themselv": [120, 620], "maybe_dens": 120, "maker": [120, 563, 620], "min_get": [120, 154, 159], "sort": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 222, 312], "another_act": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "discretebox": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "mutabl": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "action_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 621, 635], "had": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 625, 627], "all_act": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "any_don": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "_callabletransform": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 178, 179, 180], "auto_specs_": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "observation_kei": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "action_spac": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 233, 297, 298, 313, 314, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 622, 623, 625, 629], "discrep": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 348, 350, 352, 353, 364, 367, 369], "broken": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180], "check_dtyp": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180], "rng": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 636], "revert": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 326, 332, 337, 375, 377, 379, 383, 625, 638], "accomplish": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 165, 170, 171, 172, 175, 178, 179, 180, 624, 631], "done_keys_group": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "another_don": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "done_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "empty_cach": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 194, 272], "env_batch_s": [120, 154, 159], "fake_tensordict": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 620, 623], "recip": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 338, 340, 347, 567], "afterward": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 286, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 307, 308, 309, 311, 312, 314, 315, 316, 338, 340, 347, 634, 641], "envnam": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "full_action_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 634, 635], "full_done_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "full_observation_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "full_reward_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "pipeline_st": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "full_state_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "input_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "is_spec_lock": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "maybe_reset": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "speak": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 227, 344, 619], "observation_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "output_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "register_gym": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 624], "entry_point": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "info_kei": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "reward_threshold": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "nondeterminist": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "max_episode_step": [120, 123, 126, 129, 130, 131, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "order_enforc": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "autoreset": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "disable_env_check": [120, 123, 126, 129, 130, 138, 145, 146, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 445, 449], "apply_api_compat": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "nasium": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 209], "dmcontrolenv": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 392, 443, 619, 624, 633, 641], "dmc": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "cheetah": [120, 123, 124, 125, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 392, 619], "removeemptyspec": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 510], "threshold": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 301, 349, 350, 377, 379, 591, 621], "learnt": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 559], "checker": [120, 123, 126, 129, 130, 138, 145, 146, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "stepapicompat": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "deem": [120, 123, 126, 130, 138, 142, 143, 150, 151, 154, 158, 159, 160, 163, 164, 170, 171, 172, 175, 178, 179, 180], "task_nam": [120, 123, 124, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 443], "envgym": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0855": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0215": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0881": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0412": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "1101": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0080": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0254": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0424": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "9609e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "02": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 280, 620, 629], "9776e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "04": [120, 123, 126, 130, 134, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 267, 280], "6347e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "03": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 217, 246, 267], "3842e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5338e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "3064e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0381e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "6656e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "05": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 267, 367, 636], "0204e": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0833": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0275": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0612": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0770": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "1256": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0082": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0186": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0476": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "2221": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "2256": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5930": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "6937": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5865": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5479": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0187": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "6825": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "5224": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0018": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "1005": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0335": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 227], "0268": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0133": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0627": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0074": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0488": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0353": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0075": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0069": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0098": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0058": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0033": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0157": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0004": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 267], "0381": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0452": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "11355747": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "04257728": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "00408397": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "04155852": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0389733": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "01409826": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0978704": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "08808327": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "03970837": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "00535434": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "02353762": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "05116226": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "02788907": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "06848346": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "05154399": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "0371798": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "05128025": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "selecttransform": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 517], "dydact": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "ant": [120, 121, 122, 123, 126, 130, 133, 135, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 637], "gym_env": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 640], "reset_kei": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 221, 258, 264, 265, 266, 522, 634], "multitask": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "multiag": [120, 123, 126, 130, 138, 141, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 350, 364, 367], "another_reward": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "reward_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "auto_cast_to_devic": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 635], "soon": [120, 123, 126, 130, 138, 150, 151, 152, 153, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "__sort": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "as__": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "categorical_action_encod": [120, 121, 122, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 145, 146, 150, 151, 154, 155, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 209, 226, 442, 445, 449, 623], "argmaxmodul": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "argmax": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 298, 314, 623, 625], "n_ob": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 241, 340, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 626], "n_act": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 241, 348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 626], "ourselv": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 621, 641], "emul": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "input_td": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "rollout_td": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "state_kei": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "state_spec_unbatch": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "prevail": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 213, 222, 258, 326], "newli": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "next_tensordict": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212, 218, 222, 234, 235, 236, 249, 252, 253, 259, 262, 275, 279, 591], "precomput": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "_stepmdp": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212], "exclude_act": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 212], "retain": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "next_data": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180], "reset_data": [120, 123, 126, 130, 138, 150, 151, 154, 158, 159, 160, 170, 171, 172, 175, 178, 179, 180, 190, 591, 641], "2106": [121, 122, 354, 371], "13281": [121, 122], "cache_clear_frequ": [121, 122, 442], "leak": [121, 122, 324], "frame_skip": [121, 122, 124, 125, 129, 130, 131, 132, 136, 137, 139, 140, 145, 146, 155, 180, 237, 407, 409, 419, 420, 442, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 472, 496, 552, 619, 620, 621, 640], "allow_done_after_reset": [121, 122, 124, 125, 126, 129, 131, 132, 135, 136, 137, 145, 146, 148, 149, 155, 161, 162, 442, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458], "toler": [121, 122, 124, 125, 129, 131, 132, 135, 136, 137, 145, 146, 148, 149, 155, 161, 162, 194, 295, 319, 324], "is_avail": [121, 122, 619, 620, 621, 622, 634, 635, 637], "els": [121, 122, 185, 218, 308, 612, 619, 620, 621, 622, 631, 632, 634, 635, 636, 637], "87": [121, 122], "acrobot": [121, 122, 124, 125, 641], "advant": [121, 122, 136, 137], "timer": [121, 122, 130, 136, 137, 180, 525], "timeit": [121, 122, 136, 137, 623], "310": [121, 122], "00": [121, 122, 217, 618, 639], "ms": [121, 122, 136, 137], "268": [121, 122], "433": [121, 122], "213": [121, 122], "8605": [121, 122], "pipelineenv": 122, "get_environ": 122, "san": 123, "fen": [123, 148, 149], "pgn": 123, "legal": [123, 215], "board": [123, 160], "include_san": 123, "algebra": [123, 636], "notat": 123, "include_fen": 123, "forsyth": 123, "edward": 123, "include_pgn": 123, "portabl": [123, 612, 628], "include_legal_mov": 123, "include_hash": 123, "hash": [123, 138, 179, 498], "mask_act": 123, "subset": [123, 636, 637], "29275": 123, "rnbqkbnr": [123, 148, 149], "pppppppp": [123, 148, 149], "kqkq": [123, 148, 149], "legal_mov": 123, "219": 123, "5p2": 123, "ppppp1pp": 123, "event": [123, 306, 310, 317, 638], "white": 123, "96": 123, "kq": 123, "5n2": 123, "rnbqkb1r": 123, "nf3": 123, "na6": 123, "c4": 123, "f6": 123, "h4": 123, "rb8": 123, "na3": 123, "ra": 123, "get_legal_mov": 123, "dm_control": [124, 125, 443, 619, 633, 641], "2006": [124, 125, 226, 349, 355], "12983": [124, 125], "240": [124, 125, 640], "swingup": [124, 125, 641], "swingup_spars": [124, 125], "ball_in_cup": [124, 125], "catch": [124, 125, 623], "balance_spars": [124, 125], "three_pol": [124, 125], "two_pol": [124, 125], "finger": [124, 125], "turn_easi": [124, 125], "turn_hard": [124, 125], "fish": [124, 125], "upright": [124, 125, 620], "swim": [124, 125], "hopper": [124, 125], "hop": [124, 125], "humanoid": [124, 125, 150, 158, 633], "walk": [124, 125, 150, 158, 620, 633], "run_pure_st": [124, 125], "bring_bal": [124, 125], "bring_peg": [124, 125], "insert_bal": [124, 125], "insert_peg": [124, 125], "point_mass": [124, 125], "reacher": [124, 125], "swimmer": [124, 125], "swimmer6": [124, 125], "swimmer15": [124, 125], "walker": [124, 125], "dog": [124, 125], "trot": [124, 125], "humanoid_cmu": [124, 125], "lqr": [124, 125], "lqr_2_1": [124, 125], "lqr_6_2": [124, 125], "quadrup": [124, 125], "escap": [124, 125], "stacker": [124, 125], "stack_2": [124, 125], "stack_4": [124, 125], "deviceless": 126, "run_type_check": [126, 144], "hint": 126, "counterenv": 126, "creator": [127, 554, 555, 561, 562, 563], "substitut": [127, 264, 279, 625], "vecnorm": [127, 280, 536, 537, 563], "test_env1": 127, "observation_count": [127, 641], "test_env2": 127, "ps": 127, "p1": 127, "p2": 127, "9934": 127, "make_vari": [127, 270], "variant": [127, 270], "trajcount": [127, 528], "env_creator_pendulum": 127, "env_creator_cartpol": 127, "env_str": 128, "device_map": 128, "asyncvectorenv": 129, "pixel_observ": [129, 131, 132, 155], "pixelobservationwrapp": [129, 131, 132, 155], "adventur": [129, 131], "airraid": [129, 131, 641], "alien": [129, 131], "time_limit": 129, "timelimit": [129, 142, 143, 163, 164], "default_info_dict_read": [129, 130, 131, 150, 180], "reader": [129, 130, 131, 150, 180, 620], "set_info_dict_read": [129, 130, 131, 150, 180, 624], "info_dict": [129, 130, 131, 150, 180], "gymlikeenv": [129, 131, 180], "auto_register_info_dict": [129, 130, 131, 150, 180], "multibinari": [129, 131], "multidiscret": [129, 131], "rag": [129, 131], "gym_conversion_exampl": [129, 131], "info_dict_read": [130, 150, 180], "ignore_priv": [130, 180], "baseinfodictread": [130, 180], "tensordictprim": [130, 150, 180, 287, 302, 304, 523, 622], "succe": [130, 150, 180, 586], "underscor": [130, 180], "primer": [130, 170, 171, 172, 175, 178, 180, 185, 194, 265, 287, 302, 304, 317, 622], "halfcheetah": [130, 150, 180, 214, 254, 619, 640], "reward_run": [130, 150, 180], "raise_if_clos": [130, 180], "fast_encod": [130, 180], "memoize_cach": [130, 180], "adaptive_autorang": [130, 180], "4f": [130, 180, 383, 621, 622, 636], "fp": [130, 180, 392, 397, 399, 400], "10141": [130, 180], "5742fp": [130, 180], "10576": [130, 180], "8388fp": [130, 180], "read_act": [130, 180], "read_don": [130, 180], "nonsens": [130, 180], "fallback": [130, 180, 324], "read_ob": [130, 180], "dictat": [130, 180, 242, 341, 344, 367, 619, 636], "read_reward": [130, 180], "gym_lik": [130, 180], "hoc": [130, 150, 180, 625], "dict_read": [130, 180], "my_info_kei": [130, 180], "some_env": [130, 180], "vecenv": 131, "vectorenv": 131, "convert_actions_to_numpi": [131, 445, 449], "missing_obs_valu": [131, 278, 445, 449], "vecgymenvtransform": [131, 535], "secur": [132, 631], "habitat3": 132, "ai": [132, 637], "habitatrenderpick": 132, "isaacgym": [133, 134, 447], "isaacgymwrapp": 133, "isaacgymenv": [134, 447], "webpag": 134, "isaac": [134, 135], "essenc": [134, 624], "scripts_isaaclab": 135, "managerbasedrlenv": 135, "app": 135, "applaunch": 135, "argpars": [135, 560, 563], "argumentpars": 135, "add_app_launcher_arg": 135, "args_cli": 135, "hydra_arg": 135, "parse_known_arg": 135, "app_launch": 135, "isaaclab_task": 135, "f401": 135, "manager_bas": 135, "ant_env_cfg": 135, "antenvcfg": 135, "isaac_lab": 135, "cfg": [135, 463, 464, 467, 468, 469, 552, 553, 554, 555, 556, 557, 558, 559, 560, 563], "instadeepai": [136, 137], "2306": [136, 137, 280], "09884": [136, 137], "snake": [136, 137, 172], "grid": [136, 137, 392], "bodi": [136, 137], "body_st": [136, 137], "fruit_posit": [136, 137], "col": [136, 137], "row": [136, 137, 242], "head_posit": [136, 137], "tail": [136, 137], "game2048": [136, 137], "maze": [136, 137], "cleaner": [136, 137, 591, 632], "cvrp": [136, 137], "multicvrp": [136, 137], "minesweep": [136, 137], "rubikscub": [136, 137], "knapsack": [136, 137], "sudoku": [136, 137], "tsp": [136, 137], "connector": [136, 137], "mmst": [136, 137], "graphcolor": [136, 137], "partli": [136, 137], "scrambl": [136, 137], "robotwarehous": [136, 137], "tetri": [136, 137], "binpack": [136, 137], "jobshop": [136, 137], "0x1fca91910": 136, "122": [136, 137, 641], "40": [136, 137], "0x1ff9baee0": 136, "134": [136, 137], "0x1ff9ba7c0": 136, "172": [136, 137], "jit": 137, "eager": [137, 334], "tdreset": [137, 633], "whichev": 137, "mctsforest": [138, 179], "vocab_s": [138, 178, 179, 527, 612], "vocabulari": [138, 178, 179, 199, 269], "omit": [138, 179, 185, 286, 301, 312, 410, 621, 626, 636, 638], "hashing_modul": [138, 179], "siphash": [138, 179], "text_output": [138, 179], "batch_decod": [138, 179], "text_kei": [138, 179, 326, 329, 332, 337], "gpt2token": [138, 179], "input_id": [138, 178, 179], "make_tensordict": [138, 179], "mo": [139, 140], "minecart": [139, 140], "mo_gym": [140, 242], "marl": [141, 166, 221, 262, 266, 357, 370, 624, 634, 635], "group_map": [141, 142, 143, 148, 149, 152, 153, 161, 162, 163, 164, 166, 634], "constructiuon": [141, 152, 153], "premad": [141, 142, 143, 152, 153, 163, 164], "all_in_one_group": [141, 148, 149, 166], "agent_0": [141, 152, 153, 161, 166, 262], "agent_1": [141, 152, 153, 161, 166, 262], "agent_2": [141, 152, 153, 161, 166], "agent_3": [141, 161], "one_group_per_ag": [141, 152, 153], "meltingpot": [142, 143, 450], "2211": [142, 143], "13746": [142, 143], "melt": [142, 143], "pot": [142, 143], "novel": [142, 143, 626], "social": [142, 143], "situat": [142, 143, 178, 185], "familiar": [142, 143, 620, 631, 635, 641], "unfamiliar": [142, 143], "broad": [142, 143], "cooper": [142, 143, 634, 635], "decept": [142, 143], "reciproc": [142, 143], "stubborn": [142, 143], "substrat": [142, 143], "ml_collect": 142, "config_dict": 142, "configdict": 142, "horizon": [142, 143, 163, 164, 621], "infinit": [142, 143, 163, 164, 171, 172, 175, 185, 280, 627, 638], "categorical_act": [142, 143, 148, 149, 152, 153, 156, 157, 161, 162, 163, 164], "agent_nam": [142, 143, 163, 164, 166], "agent_names_to_indices_map": [142, 143, 163, 164], "env_torchrl": [142, 143], "commons_harvest__open": [142, 143], "rgb": [142, 143], "144": [142, 143, 190], "collective_reward": [142, 143], "ready_to_shoot": [142, 143], "88": [142, 143, 156, 157], "substrate_config": 143, "get_config": 143, "mp_env": 143, "build_from_config": 143, "default_player_rol": 143, "mymbenv": 144, "world_model": [144, 360], "hidden_observ": 144, "worldmodelwrapp": [144, 598], "activation_class": [144, 288, 290, 291, 292, 293, 299, 300, 305, 463, 464, 620, 625, 634, 635, 640], "relu": [144, 294, 307, 326, 332, 337, 598], "activate_last_lay": [144, 293, 305, 464], "sail": [145, 146], "sg": [145, 146], "10558": [145, 146], "readthedoc": [145, 148, 149], "en": [145, 148, 149], "python_interfac": 145, "envpoolmixin": 146, "env_bas": 146, "task_id": 146, "env_typ": 146, "gym_reset_return_info": 146, "envpool_env": 146, "www": [147, 306], "fetch_openml": 147, "dataset_nam": 147, "106": 147, "openspiel": [148, 149, 453], "open_spiel": [148, 149], "game_str": 148, "return_st": [148, 149, 152, 153], "4672": [148, 149], "current_play": [148, 149], "674": 148, "2048": [148, 149], "add_nois": [148, 149], "amazon": [148, 149], "backgammon": [148, 149], "restor": [148, 149, 591, 613], "td_restor": [148, 149], "pyspiel": 149, "load_gam": 149, "new_initial_st": 149, "3009": 149, "my_env_fun": [150, 158], "custom_attribute_list": [150, 158], "custom_attribut": [150, 158], "custom_method_list": [150, 158], "custom_method": [150, 158], "deploi": [150, 158, 218, 623], "share_individual_td": [150, 158], "shared_memori": [150, 158], "policy_proof": [150, 158], "ll": [150, 158, 226, 619, 620, 621, 622, 624, 625, 626, 627, 629, 631, 635, 641], "serial_for_singl": [150, 158, 620], "circular": [150, 158, 619], "daemon": [150, 158], "list_of_kwarg": [150, 158], "sharabl": [150, 158], "com_veloc": [150, 158], "head_height": [150, 158], "joint_angl": [150, 158], "torso_vert": [150, 158], "batched_pipe_timeout": 150, "stringent": [150, 621, 634, 635], "penv": [150, 270], "env_fix": 150, "influenc": 150, "thumb": [150, 621], "update_kwarg": [150, 158], "th": [151, 236, 274, 636], "thdot": [151, 636], "max_spe": [151, 636], "max_torqu": [151, 636], "dt": [151, 312, 636], "gen_param": [151, 636], "gravit": [151, 636], "torqu": [151, 636], "pettingzoo": [152, 153, 454, 634, 635], "pet": [152, 153], "zoo": [152, 153], "__": [152, 153], "aecenv": [152, 153], "dead": [152, 153], "done_on_ani": [152, 153, 634], "compulsori": [152, 153], "adversary_0": [152, 153], "adversari": [152, 153, 362, 634], "sisl": 152, "multiwalker_v9": 152, "aec": [152, 153], "n_piston": [152, 153], "pistonball_v6": [152, 153], "piston": [152, 153], "piston_0": [152, 153], "piston_1": [152, 153], "piston_20": [152, 153], "tictactoe_v3": [152, 153], "player": [152, 153, 160], "player_1": [152, 153], "player_2": [152, 153], "butterfli": 153, "_setup": [154, 159], "async_reset_send": [154, 159], "async_reset_recv": [154, 159], "vikashplu": 155, "wiki": 155, "06828": 155, "from_depth": 155, "smacv2": [156, 157, 456], "starcraft": [156, 157], "challeng": [156, 157, 624, 636, 637], "10gen_terran": [156, 157], "10gen_zerg": [156, 157], "10gen_protoss": [156, 157], "3m": [156, 157], "8m": [156, 157], "25m": [156, 157], "5m_vs_6m": [156, 157], "8m_vs_9m": [156, 157], "10m_vs_11m": [156, 157], "27m_vs_30m": [156, 157], "mmm": [156, 157], "mmm2": [156, 157], "2s3z": [156, 157], "3s5z": [156, 157], "3s5z_vs_3s6z": [156, 157], "3s_vs_3z": [156, 157], "3s_vs_4z": [156, 157], "3s_vs_5z": [156, 157], "1c3s5z": [156, 157], "2m_vs_1z": [156, 157], "corridor": [156, 157], "6h_vs_8z": [156, 157], "2s_vs_1sc": [156, 157], "so_many_banel": [156, 157], "bane_vs_ban": [156, 157], "2c_vs_64zg": [156, 157], "old": [156, 157, 272, 280, 364, 641], "smac": [156, 157], "map_nam": [156, 157], "176": [156, 157], "battle_won": [156, 157], "dead_al": [156, 157], "dead_enemi": [156, 157], "episode_limit": [156, 157], "322": [156, 157, 183], "procedur": [156, 157, 324], "distribution_config": [156, 157], "n_unit": [156, 157], "n_enemi": [156, 157], "team_gen": [156, 157], "dist_typ": [156, 157], "weighted_team": [156, 157], "unit_typ": [156, 157], "marin": [156, 157], "maraud": [156, 157], "medivac": [156, 157], "exception_unit_typ": [156, 157], "start_posit": [156, 157], "surrounded_and_reflect": [156, 157], "map_x": [156, 157], "map_i": [156, 157], "capability_config": [156, 157], "131": [156, 157], "starcraft2env": 157, "tic": 160, "tac": 160, "toe": 160, "single_play": 160, "player1": 160, "desired_batch_s": 160, "player0": 160, "uniti": [161, 162], "technolog": [161, 162], "llapi": [161, 162], "mlagents_env": [161, 162], "unityenviron": [161, 162], "file_nam": 161, "registered_nam": 161, "3dball": 161, "group_0": 161, "vectorsensor_size8": 161, "continuous_act": [161, 163, 164, 390, 634, 635], "agent_10": 161, "agent_11": 161, "agent_4": 161, "agent_5": 161, "agent_6": 161, "agent_7": 161, "agent_8": 161, "agent_9": 161, "group_reward": 161, "proroklab": [163, 164], "vectorizedmultiagentsimul": [163, 164], "2207": [163, 164], "03530": [163, 164], "basescenario": 163, "defaultt": 163, "sparsiti": 163, "unbatched_action_spec": [163, 164], "unbatched_observation_spec": [163, 164], "unbatched_reward_spec": [163, 164], "het_spec": [163, 164], "het_specs_map": [163, 164], "flock": [163, 164, 390], "agent_collision_rew": [163, 164], "agent_distance_rew": [163, 164], "ca": 166, "environment4": 166, "get_group_map": 166, "probabilist": [167, 241, 341, 348, 367, 598, 621, 640], "sumbodul": 169, "blank": [170, 591], "canva": [170, 591], "fundament": [170, 591, 627], "intention": [170, 591], "data_kei": [170, 171, 172, 175, 178, 194], "dialogu": 170, "klrewardtransform": [170, 188, 195, 196, 500, 591], "kl": [170, 188, 189, 195, 196, 241, 360, 364, 375, 379, 383, 591], "diverg": [170, 188, 189, 195, 196, 241, 341, 344, 360, 364, 379, 383, 591], "pythoninterpret": [170, 192, 591, 612], "dataloadingprim": [170, 171, 178, 194, 265, 591], "addthinkingprompt": [170, 591], "input_mod": [170, 171, 172, 174, 175, 195, 196, 326, 329, 332, 337, 591, 632], "system_prompt": [170, 171, 172, 175, 193, 591, 612, 631], "template_kwarg": [170, 171, 172, 175], "system_rol": [170, 591], "user_rol": [170, 591], "policy_rol": 170, "response_kei": 170, "datasetchatenv": 170, "gsm8kenv": [170, 171, 174, 181, 183, 591], "ifevalenv": [170, 171, 591], "response_data": 170, "next_ob": [170, 246, 385, 386, 387, 388, 640], "mont": [170, 171, 172, 175, 178, 185, 348, 350, 364, 367, 379, 382, 619], "carlo": [170, 171, 172, 175, 178, 185, 348, 350, 364, 367, 379, 382, 619], "pull": [171, 638], "rlhf": [171, 241, 379], "feedback": [171, 419, 591, 629, 640], "rlvr": 171, "batch_size_dl": [171, 172, 175, 181], "apply_templ": [171, 172, 175, 193, 631], "ray_backend": [171, 172, 175], "dataloader_actor_nam": [171, 172, 175], "thin": [171, 180], "chatenv": [171, 172, 175, 180, 186, 190, 193, 197, 589, 612, 631], "reset_dataload": [171, 172, 175, 185, 194], "set_missing_toler": [171, 172, 175, 194, 272], "gsm8k": [172, 173, 181, 591], "compute_reward": [172, 175], "gsm8k_dataload": 172, "3b": [172, 175, 183, 193, 324, 333, 334, 337], "question": [172, 175, 631, 638, 640], "bought": 172, "sandwich": 172, "he": 172, "paid": 172, "calcul": [172, 190, 197, 255, 348, 350, 355, 364, 367, 369, 371, 379, 385, 417], "breed": 172, "36": 172, "mari": 172, "saw": [172, 628, 636, 638], "reward_answ": [172, 174, 591], "reward_contain": [172, 174, 591], "reward_right": [172, 174, 591], "reward_think": [172, 174, 591], "snak": 172, "set_done_if_answ": [174, 177, 591], "make_gsm8k_env": 174, "sentenc": 174, "extract_tag": [174, 591], "xml": [174, 197, 203, 591], "ifev": [175, 177, 591], "ifeval_dataload": 175, "pprint": [175, 591], "instruction_id_list": [175, 177], "detectable_cont": 175, "number_placehold": 175, "num_highlight": 175, "num_": 175, "respond": 175, "plan": [175, 612], "week": 175, "europ": 175, "trip": 175, "london": 175, "rome": 175, "cap": [175, 621, 638], "restaur": 175, "prompt_level_strict_acc": [176, 177], "inst_level_strict_acc": [176, 177], "prompt_level_loose_acc": [176, 177], "inst_level_loose_acc": [176, 177], "instruction_ids_kei": 177, "keyword_args_kei": 177, "id_kei": 177, "response_column": 177, "score_kei": 177, "ifeval_scor": 177, "aggregate_reward": 177, "_scorer": 177, "ifevalscoredata": [177, 591], "format_weight": 177, "scorer": 177, "IF": 177, "co": [177, 233, 324, 636], "column": 177, "builder": [177, 181, 613, 620, 641], "think_block": 177, "answer_block": [177, 591], "langdetect": 177, "nltk": 177, "immutabledict": 177, "default_reward_aggreg": [177, 591], "tier": 177, "eo": [177, 337], "metric": [177, 350, 367, 379, 402, 408, 415, 417, 419, 420, 472, 619], "multipli": [177, 178, 185, 348, 349, 350, 351, 357, 364, 366, 367, 368, 370, 379, 412, 619, 634], "penalti": [177, 182, 188, 326, 332, 337, 362, 364, 375], "formula": [177, 241, 303, 320, 321, 348, 350, 364, 367, 379, 621], "format_scor": [177, 591], "quality_bonu": 177, "structure_multipli": 177, "complexity_scal": 177, "everyth": [177, 620, 621, 622, 628, 629], "incent": 177, "languag": [178, 591, 632], "tailor": [178, 640], "cot": [178, 591], "token_kei": 178, "str_kei": 178, "attention_kei": 178, "assign_reward": 178, "has_attent": 178, "assign_don": 178, "batchless": 178, "eos_token_id": [178, 332], "pretrainedtokenizerbas": [178, 199, 269], "stack_method": [178, 185, 194], "as_nested_tensor": [178, 185, 326, 332, 337], "bert": [178, 199, 269], "uncas": [178, 199, 269], "tokens_in": 178, "tokens_out": 178, "grpo": [178, 185, 375, 377, 379], "mlgym": [180, 182, 591], "get_library_nam": 180, "prisonersdilemma": 182, "reward_wrong_format": 182, "mlgymenv": [182, 591], "wrongli": 182, "cond": [183, 226, 227, 486], "random_prompt": 183, "edit_last_turn": 183, "zero_reward": 183, "undo_don": 183, "egocentr": 183, "reconsid": 183, "But": [183, 612, 633], "me": [183, 187, 190, 631], "wrong_answ": 183, "natalia": 183, "sold": 183, "48": 183, "friend": 183, "april": 183, "she": [183, 638], "72": 183, "altogeth": [183, 227], "undon": 183, "correct_answ": 183, "allowed_domain": [184, 631], "tool_nam": [184, 190, 193, 197, 203], "web": [184, 623, 631], "brows": [184, 631], "browser": [184, 190, 631], "click": [184, 631], "llm_tool": 184, "clean": [184, 324, 329, 402, 565, 567, 568, 570, 571, 573, 575, 578, 580, 586, 591, 612], "use_ray_servic": [185, 189, 195, 243], "mappabl": 185, "dataloader_factori": [185, 194], "unrel": 185, "dl": 185, "raydataloadingprim": 185, "endless_dataload": [185, 194], "set_capture_non_tensor_stack": 185, "dummydataload": 185, "generate_random_str": 185, "ascii_lowercas": 185, "__next__": 185, "zxwvupirska": 185, "stringa": 185, "zxwvupirsk": 185, "roll": 185, "init_st": 185, "nngcmflsana": 185, "vrrbnhzpmga": 185, "nngcmflsan": 185, "vrrb": 185, "dummytensordataload": 185, "max_length": [185, 199, 269, 623, 629], "generate_random_tensor": 185, "pad_tensor": 185, "padding_length": 185, "data_spec": 185, "toolregistri": 186, "llmtoolpars": [186, 197], "stop_on_error": 186, "pass_state_to_tool": 186, "pluggabl": 186, "xmlblockpars": [186, 197], "websearch": 186, "schema_in": [186, 201, 202], "schema_out": [186, 201, 202], "titl": [186, 621, 622, 623, 635, 636], "json": [187, 190, 631], "gen_log_probs_full_kei": [188, 195], "log_prob": [188, 195, 295, 306, 310, 321, 326, 329, 332, 337, 344, 351, 357, 370, 375, 377, 379, 383, 632], "ref_log_probs_full_kei": [188, 195], "ref_log_prob": [188, 195, 196, 375, 377, 379, 383], "kl_kei": [188, 195], "kl_penalti": [188, 195], "add_to_reward": [188, 195], "coeff": [188, 195, 350, 364, 367], "padding_sid": [188, 189, 195, 196, 306, 326, 332, 337], "retrievelogprob": [188, 189, 195, 383], "retrievekl": [188, 189, 196], "pad_output": [188, 195, 196, 326, 329, 332, 337, 632], "gen_log_prob": [188, 195], "pad_sequ": [188, 189, 195, 196], "next_td": [188, 195], "kl_transform": 188, "gen_log_probs_kei": 188, "ref_log_probs_kei": 188, "coef": [188, 241], "chathistori": [189, 195, 196, 330, 331, 332, 337], "ref_model": [189, 195, 196], "llmwrapperbas": [189, 195, 196, 332, 337, 379], "ref_model_factori": [189, 195], "assistant_onli": [189, 195, 196, 383], "upcom": [189, 195, 365, 375, 377, 379, 383, 619], "actor_nam": [189, 194, 195, 243, 329], "gen_model": [189, 195], "klcomput": [189, 195, 196], "tool_call_pattern": [190, 197], "mcp": 190, "npx": 190, "uvx": 190, "browsermcp": 190, "regex": [190, 197, 591], "tool_name_with_serv": 190, "args_json": [190, 197], "os": [190, 620, 632], "deno": 190, "deno_path": 190, "expandus": 190, "stdio": 190, "sqrt": [190, 312], "pi": [190, 623, 634, 635, 636], "run_python_cod": 190, "python_cod": 190, "linkedlist": 190, "successfulli": [190, 193, 582, 591, 631, 632], "textcont": 190, "nresult": 190, "141592653589793": 190, "return_valu": 190, "n15": 190, "annot": [190, 631], "curl": 190, "fssl": 190, "land": 190, "sh": 190, "version_typ": 191, "llmcollector": [191, 195, 326, 332, 337, 591], "tracker": [191, 240], "current_vers": 191, "uuid4": 191, "pool_siz": [192, 193, 612], "get_servic": [192, 193, 612], "python_executor": [192, 193, 612], "max_concurr": [192, 193, 329, 401, 612], "cleanup": [192, 324, 337, 568, 570, 571, 573, 578, 580, 586, 589], "robin": [192, 324, 431, 612], "stdout": 192, "stderr": 192, "returncod": 192, "service_nam": [193, 403, 612], "namespac": [193, 401, 403, 560, 563, 589], "tooltransformbas": 193, "boilerpl": 193, "inject": 193, "nprint": 193, "pythonexecutorservic": [193, 591, 612], "reus": [194, 290, 400, 591], "create_dataload": 194, "primer1": 194, "primer2": 194, "travers": 194, "missing_toler": [194, 199, 269], "reset_par": [194, 271], "set_contain": [194, 271], "ahead": [195, 641], "from_collector": 195, "get_new_vers": [195, 326, 329, 332, 337], "gen_model_factori": 195, "consciou": [195, 196], "identif": [195, 196], "history_kei": [195, 332, 337], "tokenizer_kwarg": [195, 196, 326, 332, 337, 383], "assit": [195, 196, 383], "rayretrievekl": 195, "optconfig": [195, 196, 383], "optforcausallm": [195, 196, 383], "weather": [195, 196, 383], "facebook": [195, 196, 383], "opt": [195, 196, 383], "125m": [195, 196, 383], "return_log_prob": [195, 196, 241, 283, 284, 285, 332, 337, 341, 344, 346, 369, 383, 467, 621, 625, 632, 634, 635, 640], "log_probs_kei": [195, 196, 326, 329, 332, 337], "chat_histori": [195, 196, 332, 337], "log_probs_full_kei": 196, "batchabl": 196, "tool_schema": 197, "mcptooltransform": [197, 591], "schema": [197, 202], "unknown": [197, 619], "use_raw_nontensor": [199, 239, 269, 273], "additional_token": [199, 269], "skip_special_token": [199, 269, 326, 331, 332, 337], "add_special_token": [199, 269], "return_attention_mask": [199, 269], "call_before_reset": [199, 269], "test_input_spec": [199, 273], "visibl": [200, 401, 402, 403, 589, 635], "label": [200, 619, 634, 638], "correl": [200, 312], "toolservic": 201, "addservic": 201, "optional_tag": 203, "nsome": 203, "list_of_tensordict": [204, 205], "unsqueeze_null_shap": 206, "dynamic_shap": 206, "model_bas": [207, 208], "dreamer": [207, 208, 299, 359, 360, 361], "model_based_env": [207, 359], "dreamerenv": [207, 359], "model_based_env_ev": 207, "spec_typ": 209, "convert_specnam": 209, "remap_state_to_observ": 209, "spectyp": 209, "unus": 209, "probabilistictdmodul": [210, 305, 341, 344, 409], "keep_oth": [212, 636], "exclude_reward": 212, "exclude_don": 212, "next_": 212, "mdp": [212, 624, 636], "write_full_fals": 213, "_terminated_or_trunc": 213, "num_interv": [214, 474], "out_action_kei": [214, 474], "samplingstrategi": 214, "optino": 214, "intenum": 214, "action_disc": 214, "qualnam": [214, 318, 373], "boundari": [214, 318, 347, 373, 621, 623, 634, 635], "masker": 215, "finit": [215, 235, 625, 638], "maskedenv": 215, "ones_lik": [215, 306], "scatter": 215, "fill_float": [217, 476], "fill_int": [217, 476], "fill_bool": [217, 476], "someenvclass": 217, "autoresetenv": 217, "fooenv": 217, "sign": [217, 260, 385, 634], "envtyp": 217, "3633e": 217, "4877e": 217, "2849e": 217, "7584e": 217, "6609e": 217, "6166e": 217, "8366e": 217, "2761e": 217, "5685e": 217, "4102e": 217, "8111e": 217, "9959e": 217, "0865e": 217, "5644e": 217, "2119e": 217, "2542e": 217, "9952e": 217, "4059e": 217, "2094e": 217, "9009e": 217, "5140e": 217, "3554e": 217, "2920e": 217, "7893e": 217, "6429e": 217, "3057e": 217, "2867e": 217, "6963e": 217, "3818e": 217, "2576e": 217, "2679e": 217, "1640e": 217, "6972e": 217, "0212e": 217, "5959e": 217, "4637e": 217, "3121e": 217, "2168e": 217, "5232e": 217, "7704e": 217, "7457e": 217, "4127e": 217, "1064e": 217, "0854e": 217, "5712e": 217, "2189e": 217, "5235e": 217, "8289e": 217, "0009e": 217, "0257e": 217, "8893e": 217, "5872e": 217, "9405e": 217, "7766e": 217, "0403e": 217, "0626e": 217, "2959e": 217, "7263e": 217, "2775e": 217, "9564e": 217, "0411e": 217, "6769e": 217, "6354e": 217, "8698e": 217, "1765e": 217, "6292e": 217, "5375e": 217, "1820e": 217, "7023e": 217, "5836e": 217, "9016e": 217, "4826e": 217, "6191e": 217, "6387e": 217, "8667e": 217, "2056e": 217, "1147e": 217, "5991e": 217, "0278e": 217, "5219e": 217, "3067e": 217, "6617e": 217, "3322e": 217, "2629e": 217, "4599e": 217, "7298e": 217, "5848e": 217, "0148e": 217, "5745e": 217, "6982e": 217, "7877e": 217, "3527e": 217, "7285e": 217, "6668e": 217, "0583e": 217, "6956e": 217, "3962e": 217, "9845e": 217, "5015e": 217, "5903e": 217, "9993e": 217, "9418e": 217, "0196e": 217, "6557e": 217, "2109e": 217, "8997e": 217, "1507e": 217, "7363e": 217, "0310e": 217, "9574e": 217, "8980e": 217, "0090e": 217, "reshape_fn": [218, 477, 623], "reset_func": [218, 477], "tensordict_batch_s": 218, "tensordict_reset": [218, 636], "biner": 219, "burn_in": [220, 479], "burn": 220, "burnt": 220, "grumodul": [220, 265, 598, 622], "gru_modul": [220, 302], "input_s": [220, 265, 302, 304, 622, 623], "hidden_s": [220, 265, 302, 304, 622, 623], "default_recurrent_mod": [220, 302, 304], "burn_in_transform": 220, "gru": [220, 265, 302, 623], "num_lay": [220, 302, 304, 308, 309, 623], "86": 220, "3008": 220, "37": 220, "0344": 220, "padding_valu": [221, 306, 326, 332, 337], "as_invers": 221, "movement": [221, 367], "propos": [221, 233, 622, 638], "pdf": [221, 289, 290, 291, 292, 293, 298, 312, 351, 358, 362, 368, 371, 385], "1312": 221, "5602": 221, "unsqueezetransform": [221, 531, 636, 638], "consumpt": 221, "pictur": 221, "pixels_trsf": [221, 638], "grayscal": [221, 497, 620, 622, 623, 638, 641], "data_exclud": [221, 638], "mitig": 221, "make_rb_transform_and_sampl": 221, "sampler_kwarg": 221, "redund": [221, 591, 622], "fly": [221, 279, 364, 591, 621, 636, 638, 641], "del_kei": [222, 262, 275, 633, 636], "unsqueeze_if_oor": 222, "observation_posit": 222, "observation_veloc": 222, "center": [223, 392, 548], "width": [223, 228, 254, 482, 487], "scalar": [224, 256, 286, 291, 293, 301, 312, 348, 349, 350, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 372, 375, 377, 379, 383, 385, 386, 387, 388, 408, 620, 626, 636], "rewardsc": [225, 272, 515, 619, 620, 622], "rewardclip": [225, 514], "transform_list": 225, "condition": 226, "switch": [226, 272, 280, 303, 321, 390, 612, 632], "unalt": 226, "criteria": [226, 332], "mod": [226, 241, 287, 302, 304, 326, 332, 337, 340, 344, 347, 375, 377, 379, 383, 622, 623, 629], "policy_switch": 226, "step_count_tot": 226, "step_count_main": 226, "0322": 226, "1540": 226, "0111": 226, "3190": 226, "0299": 226, "1544": 226, "0181": 226, "3280": 226, "0276": 226, "1550": 226, "0255": 226, "3414": 226, "0253": 226, "1558": 226, "0334": 226, "3596": 226, "0230": 226, "1569": 226, "0422": 226, "3828": 226, "0206": 226, "1582": 226, "0519": 226, "4117": 226, "1598": 226, "0629": 226, "4469": 226, "0156": 226, "1617": 226, "0753": 226, "4891": 226, "0130": 226, "1639": 226, "0895": 226, "5394": 226, "0104": 226, "1665": 226, "1058": 226, "5987": 226, "0076": 226, "1696": 226, "1246": 226, "6685": 226, "0047": 226, "1732": 226, "1463": 226, "7504": 226, "0016": 226, "1774": 226, "1715": 226, "8459": 226, "0020": 226, "0150": 226, "1884": 226, "6117": 226, "0017": 226, "2071": 226, "3838": 226, "0105": 226, "2115": 226, "5110": 226, "exectu": 227, "palliat": [227, 625], "inner_count": 227, "middle_env": 227, "middle_count": 227, "auto_unwrap": [227, 272, 404, 441], "9670": 227, "2546": 227, "9669": 227, "9802": 227, "1981": 227, "1601": 227, "9926": 227, "1214": 227, "5556": 227, "9994": 227, "7622": 227, "9984": 227, "0561": 227, "7933": 227, "9895": 227, "1445": 227, "7779": 227, "dtype_in": 229, "dtype_out": 229, "scan": [229, 232, 345, 346], "resp": [229, 232], "anticip": [229, 232], "not_transform": [229, 232], "orig_devic": 230, "unspecifi": 230, "num_actions_effect": 231, "max_act": 231, "include_forward": 231, "num_act": [231, 288, 357, 490, 623, 625], "action_out": 231, "inde": [231, 621, 623, 636], "eol_kei": [233, 492], "life": [233, 492, 637], "lives_kei": [233, 492], "eol_attribut": [233, 492], "breakout": 233, "210": [233, 248], "160": [233, 248], "eol_transform": 233, "eol": 233, "dqnloss": [233, 348, 349, 351, 352, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 373, 375, 377, 379, 383, 556, 605, 620, 622, 623, 629], "register_kei": 233, "loss_or_advantag": 233, "lossmodul": [233, 415, 419, 420, 558, 559, 605], "valueestimatorbas": [233, 365, 375, 377, 379, 383], "excluded_kei": 234, "first_dim": 236, "last_dim": 236, "allow_positive_dim": [236, 262, 274], "frameskip": 236, "repeatedli": [237, 621, 635], "hash_fn": 239, "repertoir": 239, "reproducible_hash": 239, "unarytransform": [239, 530], "observation_str": 239, "tobyt": [239, 273], "observation_hash": 239, "x08": 239, "x8b": 239, "xbexav": 239, "xbf": 239, "x00": 239, "xee": 239, "xb5": 239, "x17": 239, "x8f": 239, "xbe": [239, 273], "x88": 239, "xccu": 239, "xc0vr": 239, "get_input_from_hash": 239, "hash_tensor": 239, "bit": [239, 621, 622, 624, 634, 635, 638], "init_kei": [240, 340, 499], "log_prob_kei": [241, 329, 344], "sample_log_prob": [241, 283, 284, 285, 341, 344, 346, 367, 375, 377, 379], "pi_curr": 241, "pi_0": 241, "overfit": 241, "get_dist": [241, 326, 329, 332, 337, 344, 345], "frozen": [241, 279, 280], "normalparamextractor": [241, 283, 284, 285, 341, 346, 348, 349, 351, 357, 363, 367, 368, 369, 370, 371, 372, 598, 621, 625, 635, 640], "probabilisticactor": [241, 283, 284, 285, 348, 349, 351, 354, 356, 357, 363, 366, 367, 368, 369, 370, 371, 372, 598, 619, 621, 625, 634, 635], "tanhnorm": [241, 283, 284, 285, 341, 346, 348, 349, 351, 363, 367, 368, 369, 370, 371, 372, 467, 598, 621, 635, 640], "reward_kl": 241, "apply_": 241, "copy_": [241, 619], "mogymwrapp": 242, "mo_env": 242, "sea": 242, "treasur": 242, "so_env": 242, "module_factori": 243, "At": [243, 267, 301, 317, 620, 621, 622, 627, 633, 636, 637], "observation_spec_transform": 243, "done_spec_transform": 243, "reward_spec_transform": 243, "state_spec_transform": 243, "action_spec_transform": 243, "stack_reward": [244, 502], "stack_observ": [244, 502], "auto_batch_size_": 244, "macro": [244, 340], "trial": 245, "standard_norm": [246, 257, 279, 280, 505, 515, 619, 620, 622], "affin": [246, 257, 279, 280], "recover": 246, "set_default_tensor_typ": 246, "doubletensor": 246, "isclos": 246, "rubric": [246, 326, 332, 337, 346, 375, 377, 379, 383], "init_stat": [246, 619, 620, 621, 622], "3752e": 246, "5087e": 246, "9294e": 246, "9636": 246, "5608": 246, "6408": 246, "num_it": [246, 620, 621], "reduce_dim": [246, 619, 620, 621, 622], "cat_dim": [246, 619, 620, 621, 622], "keep_dim": [246, 340, 620, 622], "statist": [246, 279, 280, 324, 333, 369, 419, 420, 563, 619, 620, 621, 641], "gaussian": [246, 265, 286, 311, 621, 623, 634], "empir": [246, 341, 344, 619, 621, 635], "3d": 246, "reorder": 248, "in_keys_in": [248, 274], "channel": [248, 268, 308, 309, 620], "r3m": [250, 508, 637], "resnet": [250, 275, 277], "visual": [250, 275, 277, 392, 616, 621, 634, 636], "embed": [250, 275, 276, 277, 283, 284, 285, 290, 322, 339, 343, 344, 637], "ego4d": [250, 275, 277], "univers": [250, 275, 277, 332, 624], "suraj": [250, 275], "nair": [250, 275], "aravind": [250, 275], "rajeswaran": [250, 275], "vikash": [250, 275, 277], "kumar": [250, 275, 277], "chelsea": [250, 275], "finn": [250, 275], "abhinav": [250, 275], "gupta": [250, 275], "2203": [250, 275, 637], "12601": [250, 275, 637], "_init": [250, 275, 619], "resnet50": [250, 277, 637], "model_nam": [250, 275, 277, 324, 333, 334, 395, 508, 612], "resnet34": 250, "resnet18": [250, 508], "r3m_vec": [250, 637], "stack_imag": [250, 277], "tread": [250, 277], "hub": [250, 277, 624], "resnet50_weight": [250, 277], "imagenet1k_v1": [250, 277], "download_path": [250, 277], "tensor_pixels_kei": [250, 277], "sub_seq_len": 251, "sample_dim": [251, 619], "hesit": 251, "improp": 251, "dummyenv": 252, "another_oth": 252, "other_reward": 252, "create_copi": 253, "stuff": [253, 627], "newnam": 253, "gamma": [255, 348, 349, 351, 352, 353, 355, 357, 358, 359, 361, 363, 365, 367, 368, 369, 370, 371, 372, 373, 375, 377, 379, 383, 385, 386, 387, 388, 419, 471, 503, 513, 559, 605, 619, 620, 621, 634, 635, 640], "r2g": 255, "99": [255, 279, 361, 419, 503, 513, 536, 537, 545, 548, 559, 605, 619, 620, 621, 623, 626, 629, 634, 635, 640], "reward_to_go": 255, "bernoulli_": 255, "9010": 255, "9404": 255, "9701": 255, "9900": 255, "0000": [255, 266, 267, 301, 347], "clamp_min": [256, 514], "clamp_max": [256, 514], "clip_min": 256, "clip_max": 256, "episode_": 258, "reward1": 258, "reward2": 258, "episode_reward": [258, 634, 635], "keep_reward": 259, "keep_don": 259, "logical_or": 260, "in_key_inv": 262, "unstack": 262, "update_don": [263, 521], "disjunct": 263, "recognis": 263, "target_return": [264, 522], "default_valu": 265, "expand_spec": 265, "single_default_valu": 265, "call_before_env_reset": 265, "unit": [265, 299, 308, 309, 315, 316, 621], "scala": 265, "mykei": 265, "__unless": 265, "exists__": 265, "get_primers_from_modul": [265, 287, 302, 304], "recurrent_st": [265, 302, 304, 622], "10th": 266, "0216": 266, "1149": 266, "1990": 266, "2749": 266, "3281": 266, "9290": 266, "3702": 266, "8978": 266, "time_kei": [267, 525], "elaps": [267, 628], "monitor": [267, 324, 326, 332, 337, 350, 367, 417, 419, 565, 624], "expend": 267, "_polici": 267, "time_reset": 267, "time_polici": 267, "time_step": [267, 340], "0882": 267, "0002": 267, "5797e": 267, "6289e": 267, "7990e": 267, "0824e": 267, "0837e": 267, "6056e": 267, "2016e": 267, "1062e": 267, "7009e": 267, "from_int": [268, 526], "shape_toler": [268, 526], "ri": 268, "traj_count": [270, 528], "traj": 270, "countingenv": 270, "make_env_c0": 270, "make_env_c1": 270, "smoothli": 272, "add_1": 272, "cache_spec": [272, 441], "shown": [272, 591, 623, 631, 633, 634, 635, 638], "inv_fn": 273, "unari": 273, "durin": 273, "ommit": 273, "observation_trsf": 273, "xbc": 273, "x7f": 273, "x859": 273, "x81": 273, "x9a": 273, "xbd": 273, "xb8t8": 273, "test_output_spec": 273, "danger": 274, "vc1": [275, 532], "vc1_vec": 275, "untrain": 275, "make_noload_model": 275, "naiv": [275, 624], "vip": [276, 277, 533, 534, 637], "implicit": [277, 356, 363, 585, 638], "jason": 277, "ma": 277, "shagun": 277, "sodhani": 277, "dinesh": 277, "jayaraman": 277, "osbert": 277, "bastani": 277, "ami": 277, "zhang": 277, "vip_vec": 277, "final_nam": 278, "sb3": 278, "terminal_obs_read": 278, "vecnormv2": [279, 537], "new_api": [279, 280], "to_observation_norm": [279, 280], "frozen_copi": [279, 280], "shared_td": 279, "race": [279, 574], "decai": [279, 280, 286, 301, 412, 536, 537, 619, 620, 622, 641], "underflow": [279, 412], "build_td_for_shared_vecnorm": 279, "memmori": 279, "td_share": 279, "unfreez": [279, 280], "train_env": 279, "eval_env": 279, "9999": 280, "shared_data": 280, "reduce_batch_dim": 280, "varianc": [280, 303, 307, 320, 321, 367, 619, 621, 635], "weigh": 280, "_cast_int_to_float": 280, "env_trsf": 280, "observation_norm": 280, "reward_norm": [280, 412], "unnorm": [280, 306, 310], "7967": 280, "1238": 280, "5911": 280, "5275": 280, "8585": 280, "5028": 280, "2505": 280, "3169": [280, 347], "1332": 280, "1235": 280, "6596e": 280, "3072e": 280, "9170e": 280, "9255e": 280, "9131e": 280, "4671e": 280, "3760e": 280, "2058e": 280, "3484e": 280, "6185e": 280, "1456": 280, "1862": 280, "2053": 280, "2605": 280, "4046": 280, "5185": 280, "8023": 280, "1364": 280, "6183": 280, "5406": 280, "0920": 280, "1492": 280, "2702": 280, "3917": 280, "5001": 280, "7947": 280, "0160": 280, "3347": 280, "9082": 280, "9679": 280, "2199": 280, "2918": 280, "1668": 280, "2083": 280, "4981": 280, "5046": 280, "7950": 280, "9791": 280, "1484": 280, "4182": 280, "2201": 280, "0403": 280, "5206": 280, "7791": 280, "8282": 280, "2279": 280, "2907": 280, "4929": 280, "7793": 280, "8626": 280, "1832": 280, "local_env": 280, "testifi": 280, "4307": 280, "9613": 280, "state_dim": [281, 289, 294, 311, 315, 316], "action_dim": [281, 289, 290, 292, 294, 311, 619, 633], "gsde": [281, 368, 563], "gsdemodul": 281, "module_nam": [282, 365, 375, 377, 379, 383], "from_vers": 282, "to_vers": 282, "class_method": 282, "intersect": 282, "import_modul": 282, "get_class_that_defined_method": 282, "module_set": 282, "setters_dict": 282, "pyver": 282, "setter": 282, "setter_dict": 282, "actorvalueoper": [283, 350, 364, 367, 598, 625], "get_policy_oper": [283, 284, 285, 350, 364, 367], "standalon": [283, 284, 285, 623, 625], "tdmodul": [283, 284, 285, 559], "get_critic_oper": 283, "common_oper": [283, 285], "policy_oper": [283, 284, 285], "value_oper": [283, 284, 285], "valueoper": [283, 284, 285, 348, 349, 350, 351, 352, 357, 363, 364, 367, 368, 369, 370, 371, 372, 469, 559, 598, 605, 619, 621, 626], "module_hidden": [283, 285], "td_module_hidden": [283, 285], "safemodul": [283, 285, 344, 348, 349, 351, 356, 357, 363, 367, 368, 369, 370, 371, 372, 554, 555, 559, 598, 640], "module_act": [283, 285], "td_module_act": [283, 284, 285], "module_valu": [283, 284, 285], "td_module_valu": [283, 284, 285], "state_action_valu": [283, 322, 349, 351, 356, 363, 370, 559, 619, 634, 640], "td_modul": [283, 284, 285, 322, 339, 341, 343, 344, 346, 625, 640], "td_clone": [283, 284, 285], "tensordictmodulewrapp": [283, 554, 555, 559], "get_policy_head": [283, 284, 285], "safesequenti": [283, 284, 285], "head": [283, 285, 344, 350, 364, 367], "get_value_head": [283, 284, 285], "get_value_oper": [283, 284, 285, 350, 364, 367], "action_modul": 284, "actorcriticoper": [285, 598, 625], "actorcriticwrapp": [285, 598, 619], "po": 286, "sigma_init": [286, 634], "sigma_end": [286, 634], "annealing_num_step": [286, 301, 312, 619, 620, 622, 623, 625, 629, 634], "sigma": [286, 303, 312, 320, 321, 383, 621, 634], "omiss": [286, 301, 312], "consistentdropout": 287, "input_shap": 287, "batcht": 287, "make_tensordict_prim": [287, 302, 304, 622], "input_dtyp": 287, "get_default_dtyp": [287, 412], "mask_6127171760": 287, "seq": [287, 302, 304, 326, 332, 337, 340, 375, 377, 379, 383, 622, 623, 629, 633], "env0": [287, 641], "elu": [288, 290, 291, 292, 293, 299, 300, 620, 640], "activation_kwarg": [288, 305, 463, 464], "norm_class": [288, 290, 291, 305, 463, 464], "norm_kwarg": [288, 305, 463, 464], "bias_last_lay": [288, 290, 291, 292, 293, 300, 305, 463, 464], "aggregator_class": [288, 290, 291, 463, 620, 622, 640], "squashdim": [288, 290, 300, 598, 640], "aggregator_kwarg": [288, 290, 291, 463, 620, 622], "squeeze_output": [288, 290, 291, 463, 620, 622], "lazyconv2d": [288, 290, 291, 300], "cell": [288, 302, 304, 305, 621, 623, 624, 625, 626, 627, 628, 629], "cnet": 288, "34": [288, 305, 367], "35": [288, 305, 632], "default_atari_dqn": [288, 623], "semin": 288, "transformer_config": [289, 311], "decision_transform": [289, 311], "decisiontransform": [289, 311, 598], "dtconfig": [289, 294, 311], "2202": [289, 294, 366], "05607": [289, 294, 366], "return_to_go": [289, 294, 311], "conv_net_kwarg": [290, 291], "mlp_net_kwarg": [290, 291, 292], "use_avg_pool": [290, 291], "WITH": [290, 291, 292, 293, 312], "1509": [290, 291, 292, 293, 312, 353], "02971": [290, 291, 292, 293, 312], "maximis": [290, 292, 620, 621, 635], "ndims_in": [290, 338], "avgpool": [290, 291], "lazylinear": [290, 291, 292, 293, 300, 305, 621, 625, 636, 637], "2304": 290, "adaptiveavgpool2d": [291, 620, 622], "output_s": [291, 620, 622], "squeeze2dlay": 291, "400": [292, 293, 635], "mlp_net_kwargs_net1": 293, "mlp_net_kwargs_net2": 293, "mlp1": 293, "mlp2": 293, "desdescrib": 294, "n_embd": 294, "n_layer": 294, "n_head": 294, "n_inner": 294, "n_posit": 294, "resid_pdrop": 294, "attn_pdrop": 294, "gpt2config": 294, "atol": [295, 319], "rtol": [295, 319], "batch_shap": [295, 310, 319], "event_shap": [295, 319], "absolut": [295, 319, 619], "_instanc": 295, "densiti": [295, 306, 310, 321], "mass": [295, 306, 310, 321, 636], "rsampl": [295, 310, 344], "sample_shap": [295, 306, 310], "softmax": [296, 297, 298, 310], "qvaluemodul": [297, 313, 622, 623, 625, 629], "distributionaldqnnet": [297, 598], "make_log_softmax": 297, "character": [297, 313, 339, 341, 343, 638], "overflow": [297, 298, 313, 314, 320, 339, 341, 343, 344], "var_num": [297, 298, 314], "mult": [297, 298, 313, 314], "action_value_kei": [297, 298, 313, 314, 351, 365, 375, 377, 379, 383], "action_mask_kei": [297, 298, 301, 313, 314], "nbin": 297, "log_softmax": 297, "qvalue_actor": [297, 313], "greedi": [298, 301, 314, 326, 332, 337, 598, 620, 622, 623, 625], "1707": [298, 358, 367], "06887": [298, 358], "my_action_valu": [298, 314], "chanc": 298, "std_bia": 299, "std_min_val": 299, "belief": [299, 308, 315, 316, 317], "1912": [299, 359, 360, 361], "01603": [299, 359, 360, 361], "softplu": [299, 307], "out_features_valu": 300, "cnn_kwarg": [300, 620], "mlp_kwarg": [300, 620], "duel": [300, 598], "cnn": [300, 620, 623, 625, 640], "06581": 300, "eps_init": [301, 312, 620, 622, 623, 625, 629], "eps_end": [301, 312, 620], "explorative_polici": [301, 312], "9055": 301, "9277": 301, "6295": 301, "2532": 301, "grad_fn": [301, 339, 344], "addbackward0": 301, "embedd": [302, 304], "grucel": [302, 343], "python_bas": [302, 304], "custom_kei": [302, 304], "hasn": [302, 304], "set_recurrent_mod": [302, 304, 622], "recurrent_mod": [302, 304], "rnn": [302, 304, 357, 370, 385, 622, 623, 625], "rs": [302, 619], "gru_module_train": 302, "policy_train": [302, 383], "traj_td": 302, "make_cudnn_bas": [302, 304], "make_python_bas": [302, 304, 623], "supplementari": [302, 304, 621, 641], "That": [302, 304, 621, 634], "dealt": [302, 304], "poorli": [302, 304], "meth": [302, 304, 365, 636], "lstmmodul": [302, 598, 622, 623], "data_collector": [302, 304, 620], "upscal": [303, 320, 321], "tanh_loc": [303, 320, 321], "event_dim": [303, 319, 320], "poor": [303, 320, 321], "explos": [303, 320, 321], "lstmcell": [304, 623], "b_ih": 304, "b_hh": 304, "recurrent_state_h": 304, "recurrent_state_c": 304, "triplet": [304, 313, 314], "lstm_modul": 304, "rs_h": 304, "rs_c": 304, "single_bias_last_lay": [305, 464], "layer_class": [305, 464], "layer_kwarg": [305, 464], "perceptron": [305, 464, 625], "noisylinear": [305, 620], "noisylazylinear": 305, "neg_inf": 306, "inf": 306, "use_cross_entropi": 306, "api_doc": 306, "tf_agent": 306, "sparse_mask": 306, "cross_entropi": 306, "1203": 306, "0928": 306, "0831": 306, "1972": 306, "entropi": [306, 310, 348, 349, 350, 351, 356, 357, 363, 364, 366, 367, 368, 370, 371, 372, 375, 376, 378, 379, 380, 381, 419, 420, 635], "scale_map": [307, 467], "biased_softplus_1": [307, 467], "scale_lb": [307, 315, 316, 467], "normal_param": 307, "1803": [308, 309], "10122": [308, 309], "rnn_hidden": 308, "latent": [309, 317], "grad_method": 310, "reparamgradientstrategi": [310, 598], "passthrough": 310, "relaxedonehot": 310, "inres": 311, "mu": [311, 312, 621], "ornstein": [312, 598, 619, 623], "uhlenbeck": [312, 598, 619, 623], "ou": [312, 619], "noise_t": 312, "noise_": 312, "theta": [312, 621, 636], "sigma_t": 312, "sigma_": 312, "ou_prev_nois": 312, "ou_step": 312, "x0": 312, "sigma_min": 312, "n_steps_ann": 312, "is_init_kei": 312, "_ou_prev_nois": 312, "_ou_step": 312, "tensordict_modul": [313, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 351, 352, 356, 357, 363, 367, 368, 369, 370, 371, 372], "chose": 314, "hidden_dim": [315, 316], "posterior": [315, 317, 360], "rssm": [315, 316, 317, 360], "1811": [315, 316, 317], "04551": [315, 316, 317], "obs_embed": 315, "rnn_hidden_dim": 316, "dream": 316, "rssm_prior": 317, "rssm_posterior": 317, "s_": [317, 591, 631], "s_t": 317, "a_t": 317, "b_t": 317, "a_": 317, "evid": 317, "o_t": 317, "b_": 317, "o_": 317, "amend": 317, "safe_tanh": 320, "tanhtransform": 320, "get_mod": [320, 344], "custommodul": 322, "imaginari": 323, "imagin": 323, "transition_model": 323, "reward_model": 323, "get_reward_oper": 323, "get_transition_model_oper": 323, "engine_arg": 324, "asyncenginearg": [324, 333], "num_replica": [324, 333, 337, 579, 586, 591], "actor_class": 324, "enable_prefix_cach": 324, "replica": [324, 333, 337, 586], "placement": 324, "samplingparam": 324, "num_devic": [324, 333, 334], "max_model_len": 324, "4096": 324, "sampling_param": [324, 333], "temperatur": [324, 326, 332, 337, 349, 356, 363], "max_token": [324, 326, 332, 337], "tensor_parallel_s": [324, 333], "actor_index": 324, "fault": 324, "resili": 324, "collective_rpc": [324, 582], "create_load_balanc": 324, "kv": 324, "loadbalanc": 324, "rout": 324, "smart": 324, "lb": 324, "selected_actor_index": 324, "select_actor": 324, "prefix_length": 324, "overload_threshold": 324, "enable_fp32_output": [324, 333, 334], "fp32": [324, 333, 334], "prompt_token_id": 324, "use_tqdm": 324, "lora_request": 324, "prompt_adapter_request": 324, "guided_options_request": 324, "timeout_second": 324, "requestoutput": 324, "tokensprompt": 324, "lora": 324, "get_cache_usag": 324, "fraction": [324, 348, 350, 367], "get_master_address": 324, "get_master_port": 324, "get_num_unfinished_request": 324, "unfinish": 324, "get_random_actor_index": 324, "init_weight_update_group": 324, "asyncvllmengineservic": 324, "asyncllmengin": 324, "parameter_nam": 324, "to_text": [325, 331], "to_token": [325, 330], "logprob": [326, 332, 337, 632], "input_kei": [326, 332, 337, 632], "attention_mask_kei": [326, 332, 337], "generate_kwarg": [326, 329, 332, 337, 632], "max_new_token": [326, 329, 332, 337, 632], "num_return_sequ": [326, 332, 337], "top_p": [326, 332, 337], "nucleu": [326, 332, 337], "top_k": [326, 332, 337], "repetition_penalti": [326, 332, 337], "do_sampl": [326, 332, 337], "num_beam": [326, 332, 337], "beam": [326, 332, 337], "length_penalti": [326, 332, 337], "early_stop": [326, 332, 337], "stop_sequ": [326, 332, 337], "win": 326, "pad_model_input": [326, 332, 337], "num_sampl": [326, 329, 332, 337], "tokens_kei": [326, 329, 332, 337], "masks_kei": [326, 329, 332, 337], "ref_batch": [326, 332, 337], "min_batch_s": [326, 332, 337], "max_batch_s": [326, 332, 337], "batching_timeout": [326, 332, 337], "ref_transformers_wrapp": [326, 337], "ref_vllm_wrapp": [326, 332], "cleanup_batch": [326, 329, 332, 337], "flush": [326, 332, 337], "cancel": [326, 332, 337], "pend": [326, 332, 337, 572], "_batch_queu": [326, 332, 337], "tensordict_out": [326, 332, 337, 641], "logits_onli": [326, 332, 337], "get_batching_st": [326, 329, 332, 337], "logits_kei": [326, 332, 337], "llmmaskedcategor": 326, "alter": [326, 329, 332, 337, 340, 365], "is_tdmodule_compat": [326, 332, 337, 375, 377, 379, 383], "weak": [326, 332, 337], "reset_out_kei": [326, 332, 337, 375, 377, 379, 383], "select_out_kei": [326, 332, 337, 348, 349, 351, 352, 356, 357, 363, 367, 368, 370, 371, 372, 375, 377, 379, 383, 623], "reset_parameters_recurs": [326, 332, 337, 365, 375, 377, 379, 383], "old_param": [326, 332, 337], "bork": [326, 332, 337], "dork": [326, 332, 337], "reset_paramet": [326, 332, 337], "complic": [326, 332, 337, 375, 377, 379, 383, 636, 638, 641], "out_keys_sourc": [326, 332, 337, 375, 377, 379, 383], "z": [326, 332, 337, 375, 377, 379, 383], "all_attention_mask": [328, 332, 337, 632], "all_assistant_mask": [328, 332, 337, 632], "validate_model": 329, "automodelforcausallm": [329, 332, 632], "remote_wrapp": 329, "tensordict_input": 329, "dist_params_kei": 329, "dist_sample_kei": 329, "get_dist_with_prompt_mask": [329, 337], "to_histori": [330, 331], "wast": 332, "simpler": [332, 580, 620, 624, 632], "unsur": 332, "overlong": 332, "tokenization_util": [332, 337], "output_scor": 332, "discourag": [332, 337, 621, 636], "pad_token_id": 332, "bad_words_id": 332, "force_words_id": 332, "no_repeat_ngram_s": 332, "gram": 332, "encoder_repetition_penalti": 332, "repetit": [332, 621, 624, 627], "num_beam_group": 332, "diversity_penalti": 332, "return_dict_in_gener": 332, "ref_categorical_sequenti": [332, 337], "repeat_interleave_caus": 332, "sequence_length": 332, "_create_block_diagonal_attention_mask": 332, "causal": 332, "data_parallel_s": 333, "pipeline_parallel_s": 333, "_model": [333, 334], "make_ray_work": 334, "enforce_eag": 334, "rayllmwork": 334, "localllmwrapp": 334, "world_siz": [335, 336, 579, 586], "statelessprocessgroup": [335, 336], "plane": [335, 336], "pyncclcommun": [335, 336], "async_engin": 337, "presence_penalti": 337, "frequency_penalti": 337, "ignore_eo": 337, "prompt_logprob": 337, "detoken": 337, "include_stop_str_in_output": 337, "spaces_between_special_token": 337, "sampling_typ": 337, "temperature_last": 337, "top_p_last": 337, "top_k_last": 337, "assistant_mask_kei": 337, "set_token": 337, "translat": [339, 341], "3635": 339, "0340": 339, "1476": 339, "3911": 339, "1664": 339, "5455": 339, "2247": 339, "4583": 339, "2916": 339, "2160": 339, "5337": 339, "5193": 339, "addmmbackward0": 339, "lookahead": 340, "window": [340, 634, 638, 640], "n_action": [340, 349, 351, 353, 355, 366, 370], "reshape_cat": 340, "actor_bas": 340, "obs_cat": 340, "obs_cat_reshap": 340, "action_orig": 340, "multistepenvwrapp": 340, "ego": 340, "default_interaction_typ": [341, 344, 625], "interaction_typ": [341, 344], "set_interaction_typ": [341, 344], "compositedistribut": [341, 344, 348, 367, 625], "distribution_map": [341, 344], "name_map": [341, 344], "distribution_kwarg": [341, 344, 621, 634, 635], "cache_dist": [341, 344], "n_empirical_estim": [341, 344], "compound": [341, 625], "cube": 342, "functionalmodul": 343, "functionalmodulewithbuff": 343, "td_fmodul": 343, "td_function": 343, "td_state": 343, "params_repeat": 343, "td_vmap": [343, 346], "random_sampl": [343, 344], "suppli": 344, "paliat": 344, "get_median": 344, "get_mean": 344, "sample_key_nam": 344, "_log_prob": 344, "composite_lp_aggreg": 344, "induc": 344, "clampbackward0": 344, "anihil": 344, "probabilistictensordictsequenti": [345, 348, 350, 364, 367, 369, 554, 555, 640], "partial_toler": [345, 346, 633], "AND": [345, 346, 351], "tensordictsequ": 346, "safeprobabilisticmodul": 346, "spec1": 346, "net1": 346, "module1": 346, "td_module1": 346, "spec2": 346, "module2": 346, "td_module2": 346, "9944": 347, "9991": 347, "3020": 347, "2299": 347, "5418": 347, "2989": 347, "6849": 347, "2690": 347, "9649": 347, "5686": 347, "8602": 347, "0315": 347, "8455": 347, "6027": 347, "4746": 347, "7843": 347, "7782": 347, "2111": 347, "5115": 347, "4687": 347, "5760": 347, "1602": 348, "01783v2": 348, "entropy_bonu": [348, 350, 364, 367, 379, 471, 621], "favour": [348, 350, 364, 367, 379], "samples_mc_entropi": [348, 350, 364, 366, 367, 379, 471], "entropy_coeff": [348, 350, 364, 367, 379, 471], "critic_coeff": [348, 350, 364, 367, 471], "loss_critic_typ": [348, 350, 364, 367, 369, 471, 621], "l1": [348, 350, 352, 353, 357, 364, 367, 368, 369, 371, 372, 619], "l2": [348, 350, 352, 353, 354, 355, 357, 360, 361, 364, 367, 368, 369, 371, 372, 619, 634], "smooth_l1": [348, 349, 350, 351, 352, 353, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 471, 621], "separate_loss": [348, 350, 351, 352, 356, 357, 363, 364, 367, 368, 369, 370, 371, 372, 471], "advantage_kei": [348, 350, 364, 367, 369, 379, 382, 385, 386, 387, 388, 471], "value_target_kei": [348, 350, 364, 367, 369, 385, 386, 387, 388, 471], "value_target": [348, 350, 364, 367, 369, 385, 386, 387, 388, 621, 635], "ddp": [348, 350, 364, 367, 369], "fsdp": [348, 350, 364, 367, 369], "divid": [348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 379, 552, 619, 634, 635, 636], "clip_valu": [348, 350, 364, 367, 369, 379, 471], "loss_crit": [348, 367, 621, 635], "loss_entropi": [348, 367, 376, 378, 380, 381, 621, 635], "loss_object": [348, 367, 376, 378, 380, 381, 621, 635], "recur": [348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 385, 386, 387, 388, 389, 625], "next_reward": [348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 385, 386, 387, 388], "next_don": [348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 385, 386, 387, 388], "next_termin": [348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 385, 386, 387, 388], "loss_obj": 348, "next_observ": [348, 349, 351, 352, 353, 355, 356, 357, 363, 367, 368, 369, 370, 371, 372, 633], "sacloss": [348, 414, 420, 605], "default_kei": [348, 349, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 366, 367, 368, 369, 370, 371, 372, 383, 389], "_acceptedkei": [348, 349, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 389], "make_value_estim": [348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 373, 375, 377, 379, 383, 619, 620, 634, 635, 640], "value_typ": [348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 619], "hyperparam": [348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 619], "enum": [348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 619], "default_value_estim": [348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 619, 640], "default_value_kwarg": [348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 619], "dqn_loss": [348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 373, 375, 377, 379, 383], "td1": [348, 349, 351, 352, 353, 355, 357, 358, 359, 363, 365, 367, 368, 369, 370, 371, 372, 375, 377, 379, 383, 619], "cql": [349, 355], "conserv": [349, 355], "qvalue_network": [349, 351, 356, 357, 363, 368, 370, 371, 372, 414, 420], "unti": [349, 351, 363, 368, 370, 371, 372], "loss_funct": [349, 351, 352, 353, 354, 355, 356, 357, 363, 368, 370, 371, 372, 383, 619, 634], "alpha_init": [349, 351, 357, 366, 368, 370], "min_alpha": [349, 351, 357, 366, 368, 370], "max_alpha": [349, 351, 357, 366, 368, 370], "fixed_alpha": [349, 351, 357, 366, 368, 370], "target_entropi": [349, 351, 357, 366, 368, 370], "prod": [349, 351, 366, 370], "delay_actor": [349, 352, 370, 371, 372], "delay_qvalu": [349, 357, 368, 370, 371, 372], "min_q_weight": 349, "max_q_backup": 349, "backup": 349, "deterministic_backup": 349, "num_random": 349, "with_lagrang": 349, "lagrang": 349, "lagrange_thresh": 349, "deactivate_vmap": [349, 351, 357, 363, 368, 370, 371, 372, 385, 386, 387, 388], "valueclass": [349, 351, 352, 357, 368, 370, 371, 372], "qvalu": [349, 351, 356, 357, 363, 368, 370, 371, 372], "loss_actor": [349, 351, 352, 356, 357, 363, 368, 369, 370, 371, 372, 410, 619, 634], "loss_actor_bc": 349, "loss_alpha": [349, 351, 357, 368, 370], "loss_cql": [349, 355], "loss_qvalu": [349, 351, 355, 356, 357, 363, 368, 370, 371, 372], "loss_alpha_prim": 349, "ess": [350, 367, 375, 376, 378, 379, 380, 381], "coupl": [350, 367, 584, 622, 625, 626, 636, 638], "clip_epsilon": [350, 379, 621, 635], "head_nam": [350, 364, 367], "ppo_entropy_coeffici": [350, 364, 367], "normalize_advantag": [350, 364, 367, 471, 635], "normalize_advantage_exclude_dim": [350, 364, 367, 471], "multiobject": [350, 364, 367], "value_kei": [350, 364, 367, 385, 386, 387, 388, 471, 619], "somemodul": [350, 364, 367], "actor_head": [350, 364, 367], "someactor": [350, 364, 367], "value_head": [350, 364, 367], "somevalu": [350, 364, 367], "crossq": 351, "IN": 351, "FOR": 351, "simplic": [351, 620, 621, 627, 637, 638, 640], "openreview": [351, 368], "pczqttstix": 351, "qvalue_loss": [351, 371], "actor_loss": [351, 371], "alpha_loss": [351, 357, 370], "num_qvalue_net": [351, 356, 357, 363, 368, 370, 371, 372], "maybe_init_target_entropi": 351, "fault_toler": 351, "target_entropy_buff": 351, "delay_valu": [352, 353, 355, 358, 369, 370, 620, 622, 623, 629, 634], "loss_valu": [352, 356, 363, 369, 370, 619, 621, 634, 635], "pred_valu": [352, 355, 371, 372, 619], "pred_value_max": [352, 619], "target_valu": [352, 355, 368, 371, 372, 619], "target_value_max": [352, 619], "qvalueactor": [353, 355, 620, 622], "double_dqn": 353, "06461": 353, "mult_one_hot": [353, 356, 357], "loss_val": [353, 355, 383, 605, 619, 621, 622, 623, 626, 627, 629, 634, 635, 638], "01345": 354, "distanc": [355, 364, 385, 635], "dcql_loss": 355, "iql": [356, 363, 619, 634, 635], "2110": [356, 363], "06169": [356, 363], "expectil": [356, 363], "tau": [356, 363, 619, 620, 634], "antmaz": [356, 363], "sticht": [356, 363], "onehotcategor": [356, 357, 598], "target_entropy_weight": 357, "skip_done_st": [357, 370], "disctount": 358, "distributionalqvalueactor": 358, "input_tensordict": [358, 619], "actor_model": 359, "imagination_horizon": 359, "unrol": 359, "discount_loss": [359, 361], "lambda_kl": 360, "lambda_reco": 360, "lambda_reward": 360, "reco_loss": 360, "reward_loss": 360, "free_nat": 360, "nat": 360, "delayed_clamp": 360, "global_averag": 360, "value_loss": 361, "fake_data": 361, "gail": 362, "1606": 362, "03476": 362, "discriminator_network": 362, "use_grad_penalti": 362, "gp_lambda": 362, "discrimin": 362, "qvalueclass": 363, "loss_value_diff": 363, "diff": 363, "old_polici": 364, "new_polici": 364, "apart": [364, 635], "dtarg": 364, "samples_mc_kl": 364, "analyt": 364, "decrement": 364, "loss_": [365, 410, 605, 619, 626], "equip": [365, 622, 623, 625], "gh": 365, "_forward_value_estimator_kei": 365, "value_estim": [365, 375, 377, 379, 383, 385, 386, 387, 388, 389, 619, 635], "myloss": 365, "action2": 365, "augment": [365, 591, 627, 629, 638], "set_exploration_typ": [365, 409, 621, 622, 623, 625, 634, 640], "deterministic_sampling_mod": 365, "convert_to_funct": [365, 375, 377, 379, 383, 619], "expand_dim": [365, 375, 377, 379, 383], "create_target_param": [365, 375, 377, 379, 383, 619], "compare_against": [365, 375, 377, 379, 383, 619], "isol": [365, 375, 377, 379, 383, 401, 403, 586, 589, 623], "_param": [365, 375, 377, 379, 383], "resampl": [365, 375, 377, 379, 383], "_target_param": [365, 375, 377, 379, 383], "from_stateful_net": [365, 375, 377, 379, 383], "network_nam": [365, 375, 377, 379, 383], "stateful_net": [365, 375, 377, 379, 383], "get_stateful_net": [365, 375, 377, 379, 383], "Such": [365, 375, 377, 379, 383], "blend": [365, 375, 377, 379, 383], "vmap_random": [365, 374, 375, 377, 379, 383], "add_random_modul": [365, 375, 377, 379, 383, 605], "proxim": [367, 419, 472, 621, 635], "flavor": [367, 619, 634, 635, 640], "clipppoloss": [367, 605, 621, 635], "klpenppoloss": [367, 605], "06347": 367, "log_explained_vari": [367, 471], "explain": [367, 623, 637], "explained_vari": 367, "wors": 367, "gae": [367, 419, 472, 605, 619, 621, 635], "ppo_loss": 367, "tdlambda": [367, 619], "base_lay": 367, "action_log_prob": 367, "randn_lik": 367, "kl_approx": [367, 376, 378, 380, 381], "samplelogprob": 367, "gripper": 367, "composite_entropi": 367, "0234": 367, "set_composite_lp_aggreg": [367, 635], "redq": 368, "ay8zfzm0tdd": 368, "sub_sample_len": 368, "subsampl": [368, 405], "action_log_prob_actor": 368, "state_action_value_actor": [368, 371, 372], "connectionist": 369, "william": 369, "1992": 369, "doi": 369, "1007": 369, "bf00992696": 369, "actor_net": [369, 619, 621], "1801": 370, "01290": 370, "1812": 370, "05905": 370, "minimalist": 371, "06860": 371, "policy_nois": [371, 372], "noise_clip": [371, 372], "td3_bc": 371, "bc_loss": 371, "lmbd": 371, "next_state_valu": [371, 372], "td0": [373, 619, 634], "cispo": 375, "eps_low": [375, 379], "eps_high": [375, 379], "minimax": 375, "m1": 375, "llmoutputtyp": [375, 377, 379], "output_typ": [375, 377, 379], "cispolossoutput": [375, 589], "tensor_kei": [375, 377, 379, 385, 386, 387, 388, 389], "grpoloss": [375, 377, 589, 591], "my_advantage_kei": [375, 377, 379], "clip_fract": [376, 378, 380, 381], "loss_kl_to_ref": [376, 378, 380, 381, 383, 384], "kl_to_ref": [376, 378, 380, 381, 384], "loss_kl_to_infer": [376, 378, 380, 381], "kl_to_infer": [376, 378, 380, 381], "asymmetr": [377, 379], "eq": [377, 379], "dapolossoutput": [377, 589], "instabl": 379, "diagnost": 379, "masking_strategi": 379, "sft": [379, 383], "surrog": 379, "symmetr": 379, "dapo": [379, 589], "kl_mask_threshold": 379, "pi_theta": 379, "pi_ref": 379, "drift": 379, "token_mean": 379, "prompt_mean": 379, "kl_to_ref_coeff": [379, 383], "kl_to_inference_coeff": 379, "grpolossoutput": [379, 382, 589], "grpo_siz": 382, "hit": 382, "supervis": [383, 626, 627, 638, 641], "normalize_by_seq_length": 383, "minor_sft": 383, "minorsft": 383, "shime": 383, "xie": 383, "hong": 383, "chen": 383, "fred": 383, "yu": 383, "zey": 383, "sun": 383, "xiuyu": 383, "wu": 383, "2024": 383, "minor": [383, 634], "_chat_templ": 383, "policy_ref": 383, "txt_start": 383, "zip": [383, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "loss_sft": [383, 384], "1506": 385, "02438": 385, "exponenti": [385, 386, 387, 388, 412], "lmbda": [385, 388, 419, 619, 621, 635], "average_ga": [385, 621], "skip_exist": [385, 386, 387, 388], "get_default_devic": [385, 386, 387, 388, 389], "time_dim": [385, 387, 388], "auto_reset_env": 385, "next_valu": [385, 386, 387, 388, 389], "gradient_mod": 385, "value_error": [385, 386, 387, 388, 389], "marker": [385, 619], "trajecotri": 385, "fair": 385, "target_param": [385, 386, 387, 388, 389, 619, 635], "98": [385, 386, 387, 388], "94": [385, 388], "unpack": [385, 386, 387, 388], "aka": [386, 620, 634], "average_reward": [386, 387, 388], "tdestim": [386, 387, 389], "infti": 387, "valuefunctionbas": 389, "preproc": [390, 623, 634], "as_non_tensor": [390, 634], "render_method": 390, "pass_tensordict": 390, "syntact": 390, "sugar": 390, "relax": 390, "out_file_bas": 391, "skip_reset": 391, "center_crop": 392, "make_grid": 392, "log_video": 392, "csv": [392, 394, 396, 459, 620, 628, 629], "tensorboard": [392, 396, 398, 415, 419, 461, 472, 628, 640], "log_dir": [392, 393, 394, 396, 398, 400, 459, 461, 462, 620, 629], "cheetah_video": 392, "run_video": 392, "sec": [392, 636], "video_fp": [392, 394, 397, 459, 462], "run_video_0": 392, "cur_dir": 394, "csv_log": 394, "add_video": 394, "video_": 394, "experiment_nam": [395, 396], "logger_typ": 396, "logger_nam": 396, "mlflow": [396, 397], "wandb_kwarg": 396, "mlflow_kwarg": 396, "trackio_kwarg": 396, "tracking_uri": 397, "uri": 397, "datastor": 397, "tb_log": [398, 461], "tensoarboard": 398, "td_log": 398, "trackio": 399, "save_dir": [400, 462], "resum": 400, "uncategor": 400, "torchrl_servic": [401, 403], "discoveri": 401, "instantli": 401, "tokenizerclass": [401, 403], "modelclass": 401, "tok": 401, "service_factori": [401, 402, 612], "max_restart": 401, "register_with_opt": [401, 612], "actor_opt": [401, 612], "constructor_kwarg": 401, "readabl": 401, "concern": [401, 579, 591, 626], "model_path": 401, "ongo": [401, 402], "destruct": [401, 402], "init_kwarg": 403, "servicebas": [403, 612], "unsupport": [403, 574], "my_funct": 404, "sub_traj_len": 405, "min_sub_traj_len": 405, "register_op": [405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 416, 418, 620], "process_optim_batch": [405, 411, 412], "td_out": [405, 413], "_process_optim_batch_hook": 405, "batch_subsampl": 405, "clear_cuda": 406, "pre_optim_step": 406, "log_pbar": [407, 408, 409, 412, 620], "count_fram": 407, "pre_steps_log": [407, 408], "count_frames_log": 407, "lognam": 408, "include_std": 408, "log_reward": [408, 419, 420, 620], "r_train": 408, "log_action_norm": 408, "action_norm": 408, "percentag": 408, "log_don": 408, "done_percentag": 408, "record_interv": [409, 619, 620], "record_fram": [409, 552, 619, 620], "policy_explor": [409, 559, 619, 620, 623, 625, 629], "log_kei": [409, 620], "underestim": 409, "r_evalu": [409, 619], "loss_compon": 410, "appl": 410, "optimizer_hook": 410, "flatten_tensordict": [411, 620], "max_dim": 411, "rb_trainer": 411, "batch_process": [411, 412, 413], "post_loss": 411, "999": [412, 541, 542, 543, 546, 547, 551, 620], "jitter": 412, "finfo": 412, "default_dtyp": 412, "update_reward_stat": 412, "normalize_reward": 412, "make_train": 413, "_process_batch_hook": 413, "select_kei": 413, "target_params_updat": 414, "targetnetupdat": [414, 420, 556, 558, 559], "target_net_updat": [414, 420, 559, 619, 620], "softupd": [414, 619, 620, 622, 623, 626, 629, 634], "target_net_updater_hook": 414, "post_optim": [414, 620], "versatil": [415, 624], "optim_steps_per_batch": [415, 419, 420, 472, 620], "clip_grad_norm": [415, 419, 420, 472], "clip_norm": [415, 419, 420, 472], "progress_bar": [415, 419, 420, 472], "save_trainer_interv": [415, 419, 420, 472], "log_interv": [415, 419, 420, 472, 620], "save_trainer_fil": [415, 419, 420, 472], "async_collect": [415, 417, 419, 472], "utd": [415, 417, 619, 622], "utd_ratio": 415, "log_tim": [415, 419, 472], "logtim": [415, 419], "updateweight": [415, 419, 472, 613, 620], "load_from_fil": [415, 419, 420], "update_count": 417, "utdr_hook": 417, "update_weights_interv": [418, 620], "policy_weights_gett": 418, "weight_update_map": [418, 419, 472], "post_step": [418, 620], "num_epoch": [419, 472, 621, 635], "enable_log": [419, 420], "log_act": [419, 420], "log_observ": [419, 420], "add_ga": [419, 472], "ppotrainerconfig": 419, "welcom": [419, 591, 624], "elsewher": 420, "3e": [420, 621, 622, 634, 635], "asynccollectorconfig": 421, "collectorconfig": 422, "storageensemblewrit": 436, "batched_env_typ": 439, "make_batched_env": 439, "make_gym_env": 445, "mogymenv": 449, "meltingpotenv": 450, "openmlenv": 452, "openspielenv": 453, "pettingzooenv": [454, 634], "robohiveenv": 455, "smacv2env": 456, "unity_mlag": 457, "unitymlagentsenv": 457, "activationconfig": [463, 464], "normconfig": 463, "aggregatorconfig": 463, "layerconfig": 464, "valuemodelconfig": 465, "mlpconfig": [467, 468, 469], "eval_mod": 467, "extract_normal_param": 467, "param_kei": 467, "_make_tanh_normal_model": 467, "_make_tensordict_modul": 468, "_make_value_model": 469, "networkconfig": 469, "loss_typ": [470, 471], "_make_ppo_loss": 471, "_make_ppo_train": 472, "sensibl": 472, "batchsizetransform": [477, 623], "binarizereward": 478, "burnintransform": 479, "centercrop": 482, "cliptransform": 483, "conditionalpolicyswitch": 485, "dtypecasttransform": 488, "devicecasttransform": 489, "discreteactionproject": 490, "gym_transform": 492, "endoflifetransform": 492, "exclude_kei": 493, "finitetensordictcheck": 494, "flattenobserv": 495, "frameskiptransform": 496, "linearisereward": 501, "multiact": 502, "rb_transform": 503, "multisteptransform": 503, "noopresetenv": [504, 640, 641], "permutetransform": 506, "pinmemorytransform": 507, "r3mtransform": [508, 637], "crop_siz": 509, "randomcroptensordict": [509, 619], "key_map": 511, "reward2gotransform": 513, "include_kei": 517, "signtransform": 518, "squeezetransform": 519, "targetreturn": 522, "primer_spec": 523, "timemaxpool": 524, "vc1transform": 532, "viprewardtransform": 533, "viptransform": 534, "lambd": 538, "t0": [538, 623, 629], "weight_decai": [538, 539, 540, 541, 542, 543, 545, 546, 547, 548, 550, 619, 620], "foreach": [538, 539, 540, 542, 546, 548, 549, 550], "maxim": [538, 539, 540, 542, 548, 549, 550, 619, 626, 636], "asgd": 538, "rho": 539, "adadelta": 539, "lr_decai": 540, "initial_accumulator_valu": 540, "adagrad": 540, "amsgrad": [541, 542], "fuse": 542, "adamw": 542, "002": [543, 546], "adamax": 543, "max_it": 544, "max_ev": 544, "tolerance_grad": 544, "07": 544, "tolerance_chang": 544, "09": 544, "history_s": 544, "line_search_fn": 544, "lbfg": 544, "lion": 545, "momentum_decai": 546, "004": 546, "nadam": 546, "radam": 547, "momentum": [548, 550], "rmsprop": 548, "eta": 549, "step_siz": 549, "rprop": 549, "dampen": 550, "nesterov": 550, "sgd": 550, "sparseadam": 551, "dictconfig": [552, 553, 554, 555, 557, 558, 559, 560, 563], "unknowingli": 552, "annealing_fram": [552, 619], "init_env_step": [552, 553, 619], "proof_environ": [553, 619], "sta": 553, "ot": 553, "actor_model_explor": [554, 555, 619], "make_env_kwarg": [554, 555], "replayargsconfig": 557, "constitu": 559, "egreedywrapp": 559, "ddpgloss": [559, 605, 619, 626, 634, 640], "env_proof": 559, "obs_spec": 559, "net_valu": 559, "dir": [559, 620], "gettempdir": 559, "transformed_env_constructor": 560, "num_env_per_collector": [561, 562], "_multi_sync": 562, "video_tag": 563, "norm_obs_onli": 563, "custom_env_mak": 563, "custom_env": 563, "return_transformed_env": 563, "action_dim_gsd": 563, "state_dim_gsd": 563, "obs_norm_state_dict": 563, "weights_buff": 564, "ONE": [564, 569, 572, 578], "receive_initial_weight": 564, "interf": 564, "surround": [564, 635], "send_initial_weight": 564, "send_weight": [564, 569, 572, 574, 576, 579, 581], "send_weights_async": [564, 566, 569, 572], "acknowledg": [564, 565, 566, 567, 570, 571, 573, 574, 575, 578, 580, 586], "wait_ack": [564, 566, 569, 572], "setup_connection_and_weights_on_send": [564, 566, 569, 572, 574, 576], "3600": 565, "get_store_info": 565, "hour": 565, "apply_weight": [565, 567, 568, 570, 571, 573, 575, 577, 578, 580, 582, 584, 586], "rendez": [565, 567, 570, 571, 573, 575, 578, 580, 586], "vou": [565, 567, 570, 571, 573, 575, 578, 580, 586], "_setup_connection_and_weights_on_sender_impl": [565, 566, 567, 570, 571, 573, 575, 578, 580, 586], "_setup_connection_and_weights_on_receiver_impl": [565, 567, 570, 571, 573, 575, 578, 580, 586], "create_transport": [565, 567, 568, 570, 571, 573, 575, 578, 580, 586], "_run_process": [565, 567, 568, 570, 571, 573, 575, 578, 580, 586], "prepare_weight": [565, 567, 568, 570, 571, 573, 575, 578, 580, 586], "lookup": [565, 567, 568, 570, 571, 573, 575, 578, 580, 586, 620], "sharedmemweightsyncschem": [565, 567, 568, 570, 571, 573, 578, 580, 586], "receiver_transport": [565, 567, 568, 570, 571, 573, 575, 578, 580, 586], "sender_transport": [565, 567, 568, 570, 571, 573, 575, 578, 580, 586], "shared_transport": [565, 567, 568, 570, 571, 573, 575, 578, 580, 586], "weight_queu": 566, "ack_queu": 566, "listen": [567, 575], "phase": [567, 635, 638], "benefici": 567, "transmiss": [567, 571, 572, 573, 575, 577], "wait_async": [567, 575], "_unique_weight": [567, 575], "_receiver_shared_weight": [567, 575], "worker_rank": [569, 570], "deadlock": 569, "somecollector": 571, "transform_modul": 571, "connection_info_nam": [571, 572, 573], "collis": [571, 573, 634, 635], "remote_actor": [571, 572, 573], "connection_info": 572, "set_model": 572, "_setup_distributed_connection_send": 572, "pure": 574, "register_weight": 574, "params_map": [574, 578], "basecontext": 574, "init_queu": 574, "send_ack": 574, "unique_weight": 574, "_send_instruct": 575, "notifi": 575, "extract_a": 577, "extract_weight": [577, 587], "device_map_fn": 578, "gpus_per_replica": [579, 586, 591], "init_all_workers_group": [579, 584, 585, 586, 591], "check_connect": [579, 581], "mono": 579, "remote_addr": [580, 581], "local_addr": [580, 581], "tmp": 580, "mnt": 580, "nf": 580, "mount": 580, "create_receiv": [580, 582, 586], "vllmdoublebufferweightreceiv": 580, "llm_engin": 580, "model_executor": 580, "create_send": [580, 583, 586], "vllmdoublebufferweightsend": 580, "vllmdoublebuffertransport": 580, "vllmdoublebuffersyncschem": [582, 583, 591], "load_weight": 582, "poll_and_appli": [582, 584], "_update_weights_with_nccl_broadcast_simpl": 582, "180": 582, "register_model": [583, 585, 586, 591], "vllmweightsyncschem": [584, 585, 591], "get_actor": 584, "particip": [584, 586], "torchrpcvllmreceiv": 584, "rpc_sync": 584, "get_metadata": 584, "grpc": 585, "vllmcollectivetransport": [585, 586], "bandwidth": 585, "torchrpcvllmsend": 585, "rpc_async": 585, "prepare_rec": 585, "tp_size": 586, "dp_size": 586, "pp_size": 586, "approxim": [586, 635, 641], "handshak": 586, "12345": 586, "vllmweightsend": 586, "vllmweightreceiv": 586, "init_send": 586, "sender_actor": 586, "init_receiv": 586, "receiver_actor": 586, "llmlossoutput": 589, "cispoloss": 589, "mcadvantag": 589, "sftloss": [589, 591], "sftlossoutput": 589, "topkrewardselector": 589, "sweep": 589, "journei": 590, "textbook": 590, "highlight": [590, 634], "ever": [590, 635], "bump": 590, "pr": [590, 591], "five": [591, 620], "make_polici": 591, "29500": 591, "_weight_send": 591, "training_model": 591, "policy_version_track": 591, "migrat": 591, "ref_servic": 591, "step_data": 591, "gsm8krewardpars": 591, "ifevalscor": 591, "excel": 591, "bsz": 591, "num_token": 591, "predetermin": 591, "hasattr": [591, 619], "text_complet": 591, "sophist": [591, 621, 635], "format_compon": 591, "structure_scor": 591, "think_scor": 591, "answer_scor": 591, "completion_bonu": 591, "potential_answ": 591, "compl": 591, "et": 591, "parseerror": 591, "unnecessari": 591, "characterist": [591, 619, 636], "\u03b5": 598, "satisfi": 598, "additivegaussianmodul": [598, 625, 634], "consistentdropoutmodul": 598, "egreedymodul": [598, 620, 622, 623, 625, 629], "ornsteinuhlenbeckprocessmodul": [598, 619, 625], "duelingcnndqnet": [598, 620], "ddpgcnnactor": 598, "ddpgcnnqnet": 598, "ddpgmlpactor": [598, 619], "ddpgmlpqnet": [598, 619], "onlinedtactor": 598, "dtactor": 598, "dreameractor": 598, "obsencod": 598, "obsdecod": 598, "rssmposterior": 598, "rssmprior": 598, "rssmrollout": 598, "independentnorm": 598, "tanhdelta": [598, 619, 634], "truncatednorm": 598, "reusabl": [605, 619, 638], "trainabl": [605, 619, 626, 637], "\u03bb": 605, "customiz": [605, 622], "total_loss": [605, 626], "distributionaldqnloss": [605, 620], "iqlloss": 605, "discreteiqlloss": 605, "cqlloss": 605, "discretecqlloss": 605, "ppoloss": 605, "a2closs": 605, "reinforceloss": 605, "discretesacloss": 605, "td3loss": 605, "redqloss": 605, "crossqloss": 605, "td3bcloss": 605, "gailloss": 605, "dtloss": 605, "onlinedtloss": 605, "dreameractorloss": 605, "dreamermodelloss": 605, "dreamervalueloss": 605, "agnost": [612, 631], "monarch": 612, "anywher": 612, "tenant": 612, "my_namespac": 612, "tokenizerservic": 612, "50000": 612, "my_servic": 612, "myserviceclass": 612, "arg1": 612, "value1": 612, "arg2": 612, "value2": 612, "gpu_servic": 612, "gpuservic": 612, "collid": [612, 623, 635], "register_servic": 612, "shared_token": 612, "use_servic": 612, "worker2": 612, "train_servic": 612, "eval_servic": 612, "30000": 612, "busi": 612, "infrequ": 612, "use_distributed_servic": 612, "queu": 612, "persistentpythonprocess": 612, "_lock": 612, "next_idx": 612, "temp": 612, "python_executor_fast": 612, "python_executor_heavi": 612, "fast_env": 612, "heavy_env": 612, "mycustomservic": 612, "param1": 612, "tokenizer_servic": 612, "servicecontext": 612, "__enter__": 612, "__exit__": 612, "myservic": 612, "stick": [612, 623], "distributed_servic": 612, "python_executor_servic": 612, "test_servic": 612, "test_python_executor_servic": 612, "ref_llm": [612, 631], "torchsnapshot": 613, "logscalar": [613, 620], "mlflowlogg": 613, "trackiologg": 613, "get_logg": 613, "generate_exp_nam": 613, "batchsubsampl": 613, "clearcudacach": 613, "countframeslog": 613, "optimizerhook": [613, 620], "logvalidationreward": [613, 619, 620], "replaybuffertrain": [613, 620], "rewardnorm": 613, "selectkei": 613, "targetnetupdaterhook": 613, "utdrhook": 613, "000": [618, 622, 639], "galleri": [618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "mem": [618, 639], "mb": [618, 639], "coding_ddpg": [618, 619, 639], "coding_dqn": [618, 620, 639], "coding_ppo": [618, 621, 639], "dqn_with_rnn": [618, 622, 639], "llm_browser": [618, 631, 639], "llm_wrapper": [618, 632, 639], "multi_task": [618, 633, 639], "multiagent_competitive_ddpg": [618, 634, 639], "multiagent_ppo": [618, 635, 639], "pretrained_model": [618, 637, 639], "rb_tutori": [618, 638, 639], "torchrl_demo": [618, 639, 640], "torchrl_env": [618, 639, 641], "author": [619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 634, 635, 636, 638, 641], "vincent": [619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 636, 638, 641], "moen": [619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 636, 638, 641], "assembl": 619, "ground": [619, 636], "transpar": [619, 622], "bash": 619, "is_fork": [619, 620, 621, 622, 634, 635, 637], "get_start_method": [619, 620, 621, 622, 634, 635, 637], "collector_devic": 619, "swappabl": 619, "smth": 619, "loss_dict": 619, "oblivi": [619, 621, 638], "elementari": 619, "didact": [619, 623], "dilut": 619, "pessimist": [619, 620, 621], "target_actor_network_param": 619, "actor_in_kei": 619, "actor_crit": 619, "compromis": 619, "td0estim": 619, "td1estim": 619, "tdlambdaestim": 619, "hp": 619, "_value_estim": 619, "hold_out_param": 619, "_loss_actor": 619, "td_copi": 619, "actor_network_param": [619, 634], "value_network_param": [619, 634], "distance_loss": 619, "_loss_valu": 619, "pred_val": 619, "target_value_network_param": 619, "smooth": [619, 620, 626], "pow": 619, "glue": 619, "_forward": 619, "remaind": 619, "env_librari": 619, "env_task": 619, "env_arg": [619, 620], "torchr": 619, "rescal": 619, "presum": 619, "make_transformed_env": 619, "reward_sc": 619, "parallel_env_constructor": 619, "env_per_collector": 619, "transform_state_dict": 619, "make_t_env": 619, "seem": [619, 622, 624], "cheat": 619, "10m": 619, "nutshel": 619, "cautiou": 619, "thousand": [619, 622], "get_env_stat": 619, "proof_env": 619, "5000": [619, 623, 629], "recal": [619, 621, 631, 638], "materi": 619, "make_ddpg_actor": 619, "q_net": 619, "qnet": 619, "suggest": [619, 635], "tight": 619, "10_000": [619, 621], "traj_len": [619, 622], "make_record": 619, "recorder_obj": 619, "pick": [619, 620, 625, 631], "make_replay_buff": 619, "buffer_s": [619, 620, 622], "random_crop_len": 619, "prb": 619, "buffer_scratch_dir": [619, 620, 622, 627, 637], "dataflow": 619, "ceil_div": 619, "update_to_data": 619, "realiz": 619, "ve": [619, 622, 629, 631], "_must_": 619, "outdat": 619, "trick": [619, 620], "despit": 619, "hardupd": [619, 626], "optimizer_actor": 619, "optimizer_valu": 619, "total_collection_step": 619, "rewards_ev": 619, "collected_fram": 619, "r0": 619, "numel": [619, 621, 623, 629, 634, 637, 638], "current_fram": [619, 634], "sampled_tensordict": 619, "gn1": 619, "clip_grad_norm_": [619, 621, 634, 635, 636], "gn2": 619, "gn": [619, 636], "td_record": 619, "rn": 619, "2f": 619, "plot": [619, 621, 622, 634, 635, 636], "mention": [619, 622, 638, 641], "matplotlib": [619, 621, 622, 623, 634, 635, 636, 638, 641], "pyplot": [619, 621, 622, 623, 634, 635, 636, 638, 641], "plt": [619, 621, 622, 623, 634, 635, 636, 638, 641], "legend": [619, 634], "xlabel": [619, 622, 635, 636], "ylabel": [619, 635], "tight_layout": 619, "concret": [619, 621, 631], "takeawai": [619, 620, 623, 631], "distpatch": 619, "jupyt": [619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "ipynb": [619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "sphinx": [619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641], "road": 620, "aspect": [620, 626], "highest": [620, 625], "prerequisit": [620, 622, 631], "amort": [620, 621], "cart": 620, "pole": 620, "un": 620, "actuat": 620, "frictionless": 620, "is_notebook": 620, "shell": 620, "get_ipython": 620, "__class__": [620, 632], "zmqinteractiveshel": 620, "qtconsol": 620, "terminalinteractiveshel": 620, "ipython": [620, 635, 636], "nameerror": [620, 632, 634], "umbrella": 620, "misplac": 620, "misus": 620, "64x64": 620, "motion": [620, 636], "obs_norm_sd": 620, "mp_context": 620, "get_norm_stat": 620, "test_env": 620, "mathbb": 620, "rightarrow": 620, "make_model": 620, "dummy_env": 620, "init_bia": 620, "exploration_modul": [620, 622, 623, 625, 629], "eps_greedy_v": 620, "eps_greedy_val_env": 620, "actor_explor": 620, "get_replay_buff": 620, "n_optim": [620, 626, 627], "parametriz": 620, "get_collector": 620, "bunch": 620, "ubiquit": [620, 624], "get_loss_modul": 620, "target_updat": [620, 634], "995": 620, "hopefulli": 620, "sensit": [620, 622], "variat": 620, "2e": [620, 636], "wd": 620, "upd": 620, "harder": [620, 640], "5_000": 620, "500000": 620, "005": [620, 634], "mandatori": [620, 621, 635, 636], "fairer": 620, "budget": 620, "dqn_exp_": 620, "uuid1": [620, 641], "cumbersom": 620, "buffer_hook": 620, "trainerhookbas": 620, "aliv": 620, "total_reward": 620, "ti": 620, "print_csv_files_in_fold": 620, "folder_path": 620, "csv_file": 620, "output_str": 620, "dirpath": 620, "endswith": 620, "qvaluenetwork": 620, "worst": 620, "accuraci": 620, "fanci": [620, 627], "talk": 621, "six": 621, "invent": 621, "theta_k": 621, "pi_": 621, "exceed": 621, "indispens": 621, "loader": 621, "analyz": 621, "lingua": 621, "franca": 621, "defaultdict": [621, 636], "max_grad_norm": [621, 634, 635], "sub_batch_s": 621, "95": [621, 622], "entropy_ep": [621, 635], "inverteddoublependulum": 621, "transmit": 621, "stai": 621, "told": 621, "confid": [621, 634, 635], "ran": 621, "f_": 621, "mu_": 621, "difficulti": [621, 641], "brought": [621, 622, 625], "d_ob": 621, "d_action": 621, "said": 621, "value_modul": [621, 640], "briefli": [621, 634, 635], "refil": [621, 635], "easiest": [621, 626, 634, 635], "hide": [621, 634, 635], "mathemat": [621, 634, 635], "tradeoff": [621, 635], "advantage_modul": 621, "entropy_coef": [621, 635], "critic_coef": 621, "lr_schedul": [621, 636], "cosineannealinglr": [621, 636], "eval_str": 621, "tensordict_data": [621, 635], "data_view": [621, 635], "subdata": [621, 634, 635], "cum_reward_str": 621, "stepcount_str": 621, "param_group": [621, 634], "lr_str": 621, "eval_rollout": 621, "figsiz": [621, 636], "subplot": [621, 634, 636, 641], "84x84": [622, 623], "accessori": 622, "stamp": 622, "backbon": [622, 625, 633, 640], "emb": 622, "n_cell": 622, "bidirect": 622, "wouldn": 622, "qval": 622, "stoch_polici": 622, "opportun": [622, 634], "uniniti": 622, "again": [622, 623, 624, 625, 627, 635, 637, 638, 641], "strongli": 622, "sake": [622, 637, 638], "longest": 622, "enough": [622, 638], "strong": 623, "impress": 623, "edg": 623, "arduino": 623, "raspberri": 623, "alon": 623, "examplifi": 623, "ship": 623, "nearest": 623, "value_mlp": [623, 629], "init_rand_step": [623, 629], "total_count": [623, 629], "total_episod": [623, 629], "screen": [623, 634], "color": [623, 634], "clearer": [623, 625], "unblock": 623, "policy_transform": 623, "fake_td": 623, "exported_polici": 623, "div": 623, "graph_modul": 623, "print_read": 623, "group0": 623, "group0_agent0_ob": 623, "group0_agent0": 623, "agent0_ob": 623, "obvious": 623, "digress": 623, "exported_stochastic_polici": 623, "trace": 623, "hidden0": 623, "hidden1": 623, "recurrent_polici": 623, "happi": 623, "fake_ob": 623, "fake_hidden0": 623, "fake_hidden1": 623, "fake_is_init": 623, "exported_recurrent_polici": 623, "platform": [623, 640], "aoti": 623, "_inductor": 623, "aoti_compile_and_packag": 623, "aoti_load_packag": 623, "pt2": 623, "pkg_path": 623, "package_path": 623, "compiled_modul": 623, "onnxruntim": 623, "showcas": [623, 636], "plenti": 623, "tensorrt": 623, "android": 623, "aleinterfac": 623, "rom": [623, 641], "loadrom": 623, "reset_gam": 623, "screen_ob": 623, "getscreenrgb": 623, "tick_param": 623, "bottom": 623, "labelleft": 623, "labelbottom": 623, "imshow": [623, 641], "dynamo_export": 623, "as_tensor": 623, "onnx_policy_export": 623, "onnx_file_path": 623, "ort_sess": 623, "inferencesess": 623, "cpuexecutionprovid": 623, "onnxruntime_input": 623, "get_input": 623, "onnx_polici": 623, "f811": 623, "onnxruntime_output": 623, "num_step": 623, "deploy": 623, "topic": [624, 625, 626], "straight": 624, "backtrack": 624, "reset_with_act": 624, "stepped_data": 624, "spatial": 624, "useless": 624, "policyless": 624, "glanc": 624, "appreci": 624, "examin": [624, 634], "tackl": 625, "intric": 625, "delv": 625, "extractor": 625, "analog": 625, "realm": 625, "exploration_polici": [625, 634], "2d": [625, 634, 635], "innov": [625, 626], "rollout_explor": 625, "sole": 626, "n_collect": 626, "get_next_batch": 626, "ddpg_loss": 626, "prove": 626, "reliev": 626, "accustom": 627, "surprisingli": 627, "matter": 627, "art": [627, 634, 635], "pseudo": [627, 636], "countless": 627, "yourself": [627, 634, 635], "chapter": 628, "everywher": 628, "log_scalar": 628, "my_scalar": 628, "excess": 628, "lesson": 629, "voluntarili": 629, "training_loop": 629, "video_record": 629, "arbitrarili": 629, "num": 629, "t1": 629, "conclud": [629, 637], "tutorials_python": 630, "tutorials_jupyt": 630, "playwright": 631, "autom": 631, "__future__": 631, "browsertransform": 631, "filterwarn": [631, 632], "browser_transform": 631, "rewardtransform": 631, "last_item": 631, "execute_tool_act": 631, "current_st": 631, "nllm": 631, "nenviron": 631, "button": 631, "css": 631, "btnk": 631, "extract_typ": 631, "suppress": 632, "vllm_use_v1": 632, "5b": 632, "canada": 632, "vllm_wrapper": 632, "return_text": 632, "return_token": 632, "return_mask": 632, "data_histori": 632, "nload": 632, "transformers_token": 632, "transformers_wrapp": 632, "result_tf": 632, "data_text": 632, "vllm_text_wrapp": 632, "result_vllm_text": 632, "nvllm": 632, "transformers_text_wrapp": 632, "result_tf_text": 632, "vllm_logprobs_wrapp": 632, "result_vllm_lp": 632, "transformers_logprobs_wrapp": 632, "result_tf_lp": 632, "ntensorclass": 632, "analysi": 632, "ntext": 632, "__annotations__": 632, "ntoken": 632, "nlogprob": 632, "nmask": 632, "nerror": 632, "invalid_mod": 632, "nrl": 632, "env_stat": 632, "action_output": 632, "60": [632, 640], "env1_obs_kei": 633, "observation_stand": 633, "env2_obs_kei": 633, "observation_walk": 633, "tdreset1": 633, "tdreset2": 633, "policy_common": 633, "policy_stand": 633, "policy_walk": 633, "env1_mak": 633, "env2_mak": 633, "_single_task": 633, "td_rollout": 633, "matteo": [634, 635], "bettini": [634, 635], "benchmarl": [634, 635], "simple_tag": 634, "maddpg": [634, 635], "multiagentparticleenviron": 634, "mpe": 634, "centralis": [634, 635], "tie": [634, 635], "iddpg": [634, 635], "optimis": [634, 635], "sutton": [634, 635], "richard": 634, "andrew": 634, "barto": [634, 635], "mit": 634, "press": 634, "2018": 634, "mathbf": [634, 635], "decentralis": [634, 635], "literatur": [634, 635], "overcom": [634, 635], "stationari": [634, 635], "establish": 634, "gui": [634, 635], "multiagentmlp": [634, 635], "is_sphinx": 634, "__sphinx_build__": 634, "n_iter": [634, 635, 636], "evad": 634, "iteration_when_stop_training_evad": 634, "memory_s": 634, "n_optimiser_step": 634, "train_batch_s": 634, "polyak_tau": 634, "furthermor": [634, 635], "chaser": 634, "red": 634, "circl": [634, 635], "touch": [634, 636], "penal": [634, 635], "obstacl": 634, "drag": [634, 635], "elast": [634, 635], "Their": [634, 635], "imped": 634, "n_chaser": 634, "n_evad": 634, "n_obstacl": 634, "use_vma": 634, "simple_tag_v3": 634, "num_good": 634, "num_adversari": 634, "num_obstacl": 634, "max_cycl": 634, "num_vmas_env": [634, 635], "num_good_ag": 634, "num_landmark": 634, "four": [634, 635, 636], "n_agents_in_that_group": 634, "stress": [634, 635], "paramount": [634, 635], "n_rollout_step": [634, 635], "evolut": [634, 635], "group_nam": 634, "n_agents_in_group": 634, "signifi": [634, 635], "agents_exploration_polici": 634, "utilis": [634, 635], "homogen": [634, 635], "n_obs_per_ag": [634, 635], "n_actions_per_ag": [634, 635], "share_parameters_polici": [634, 635], "policy_net": [634, 635], "n_agent_input": [634, 635], "n_agent_output": [634, 635], "share_param": [634, 635], "_agent": 634, "grant": [634, 635], "converg": [634, 635], "share_parameters_crit": [634, 635], "obs_act": 634, "cat_modul": 634, "critic_modul": 634, "fantast": [634, 635], "reset_td": 634, "interfer": 634, "subject": [634, 636], "flatten_kei": 634, "process_batch": 634, "group_shap": 634, "get_item_shap": [634, 635], "nested_done_kei": 634, "nested_terminated_kei": 634, "desc": [634, 635], "episode_reward_mean_": 634, "episode_reward_mean_map": 634, "train_group_map": 634, "group_batch": 634, "_group": 634, "loss_nam": 634, "episode_reward_mean": [634, 635], "proce": 634, "fig": [634, 638], "set_ylabel": 634, "axvlin": 634, "orang": 634, "set_xlabel": 634, "video_logg": 634, "vmas_log": 634, "env_with_rend": 634, "vmas_rend": 634, "print_log_dir": 634, "profici": [634, 635], "qmix": [634, 635], "lidar": 635, "sensor": 635, "mappo": 635, "ippo": 635, "_t": [635, 636], "analys": 635, "visualis": 635, "vmas_devic": 635, "6_000": 635, "minibatch_s": 635, "generalis": 635, "simd": 635, "warp": 635, "todai": 635, "dot": [635, 636], "scenario_nam": 635, "critic_net": 635, "minibatch": 635, "episode_reward_mean_list": 635, "critic_network_param": 635, "target_critic_network_param": 635, "xvfb": 635, "pyvirtualdisplai": 635, "1400": 635, "900": 635, "pil": 635, "rendering_callback": 635, "fromarrai": 635, "gif": 635, "save_al": 635, "append_imag": 635, "freeli": 636, "undertaken": 636, "broader": 636, "wider": 636, "acquaint": 636, "avenu": 636, "_apply_to_composit": 636, "default_x": 636, "default_i": 636, "upward": 636, "angular": 636, "sin": 636, "theta_t": 636, "rad": 636, "theta_": 636, "angl": 636, "new_th": 636, "new_thdot": 636, "g_forc": 636, "angle_norm": 636, "zeros_lik": 636, "albeit": 636, "high_th": 636, "high_thdot": 636, "low_th": 636, "low_thdot": 636, "trivial": 636, "irrelev": 636, "_make_spec": 636, "td_param": 636, "render_fp": 636, "random_": 636, "_make_step": 636, "staticmethod": 636, "skeleton": 636, "sine": 636, "cosin": 636, "sintransform": 636, "costransform": 636, "t_sin": 636, "t_co": 636, "cat_transform": 636, "simple_rollout": 636, "_data": 636, "unexplor": 636, "recreat": 636, "20_000": 636, "init_td": 636, "traj_return": 636, "last_reward": 636, "is_ipython": 636, "inlin": 636, "get_backend": 636, "ion": 636, "gcf": 636, "clear_output": 636, "env_transform": [637, 641], "wiser": 637, "_storag": [637, 638], "batteri": 638, "gc": 638, "filesystem": 638, "buffer_list": 638, "lowest": 638, "medium": 638, "buffer_lazytensor": 638, "tempdir": 638, "buffer_lazymemmap": 638, "fullest": 638, "mydata": 638, "buffer_lazi": 638, "_i": 638, "artifici": 638, "hamper": 638, "hist": 638, "recycl": 638, "reappear": 638, "unfold": 638, "problemat": 638, "4th": 638, "tensordictmaxvaluewrit": 638, "demo": 640, "icml": 640, "vmoen": 640, "fb": 640, "invest": 640, "media": 640, "predominantli": 640, "data2": 640, "sub_key1": 640, "scturctur": 640, "data_stack": 640, "data_sampl": 640, "_sampler": 640, "_sum_tre": 640, "modulenotfounderror": 640, "backbone_modul": 640, "params_expand": 640, "exec_sequ": 640, "tensordict_exp": 640, "base_modul": 640, "roughli": 640, "tensordicts_prealloc": 640, "tensordicts_stack": 640, "tensordict_rollout": [640, 641], "automatical": 640, "particularili": 640, "concatmodul": 640, "loss_td": 640, "contributor": 640, "curiou": 640, "nascent": 640, "unsupervis": 641, "licens": 641, "pygam": 641, "_build_env": 641, "deserv": 641, "__episode__": 641, "__trajectory__": 641, "void": 641, "reproduct": 641, "tensordict_tprim": 641, "inconsist": 641, "wrapper1": 641, "wrapper2": 641, "obviou": 641, "truth": 641, "env_transformed_bi": 641, "stanc": 641, "transformeddistribut": 641, "base_dist": 641, "concat": 641, "mofidi": 641, "transformedenviron": 641, "moderet": 641, "computation": 641, "incom": 641, "amongst": 641, "has_cuda": 641, "device_count": 641, "worri": 641, "convention": 641, "markovian": 641, "bar_": 641, "get_someth": 641, "aargh": 641, "is_clos": 641, "foo_list": 641, "121": 641, "evolv": 641, "steadi": 641, "approx": 641, "sd": 641, "absor": 641, "_extra_st": 641}, "objects": {"torchrl": [[31, 0, 1, "", "auto_unwrap_transformed_env"], [282, 0, 1, "", "implement_for"], [404, 0, 1, "", "set_auto_unwrap_transformed_env"]], "torchrl.collectors": [[32, 0, 1, "", "AsyncCollector"], [33, 0, 1, "", "BaseCollector"], [34, 0, 1, "", "Collector"], [35, 0, 1, "", "MultiAsyncCollector"], [36, 0, 1, "", "MultiCollector"], [37, 0, 1, "", "MultiProcessedWeightUpdater"], [38, 0, 1, "", "MultiSyncCollector"], [39, 0, 1, "", "RayWeightUpdater"], [40, 0, 1, "", "VanillaWeightUpdater"], [41, 0, 1, "", "WeightUpdaterBase"]], "torchrl.collectors.AsyncCollector": [[32, 1, 1, "", "async_shutdown"], [32, 1, 1, "", "cascade_execute"], [32, 1, 1, "", "get_cached_weights"], [32, 1, 1, "", "get_model"], [32, 1, 1, "", "get_policy_version"], [32, 1, 1, "", "getattr_env"], [32, 1, 1, "", "getattr_policy"], [32, 1, 1, "", "getattr_rb"], [32, 1, 1, "", "increment_version"], [32, 1, 1, "", "init_updater"], [32, 1, 1, "", "load_state_dict"], [32, 1, 1, "", "pause"], [32, 2, 1, "", "policy_version"], [32, 1, 1, "", "receive_weights"], [32, 1, 1, "", "register_scheme_receiver"], [32, 1, 1, "", "reset"], [32, 1, 1, "", "set_seed"], [32, 1, 1, "", "shutdown"], [32, 1, 1, "", "start"], [32, 1, 1, "", "state_dict"], [32, 1, 1, "", "update_policy_weights_"], [32, 2, 1, "", "worker_idx"]], "torchrl.collectors.BaseCollector": [[33, 1, 1, "", "async_shutdown"], [33, 1, 1, "", "cascade_execute"], [33, 1, 1, "", "init_updater"], [33, 1, 1, "", "pause"], [33, 1, 1, "", "receive_weights"], [33, 1, 1, "", "register_scheme_receiver"], [33, 1, 1, "", "start"], [33, 1, 1, "", "update_policy_weights_"], [33, 2, 1, "", "worker_idx"]], "torchrl.collectors.Collector": [[34, 1, 1, "", "async_shutdown"], [34, 1, 1, "", "cascade_execute"], [34, 1, 1, "", "get_model"], [34, 1, 1, "", "get_policy_version"], [34, 1, 1, "", "getattr_env"], [34, 1, 1, "", "getattr_policy"], [34, 1, 1, "", "getattr_rb"], [34, 1, 1, "", "increment_version"], [34, 1, 1, "", "init_updater"], [34, 1, 1, "", "iterator"], [34, 1, 1, "", "load_state_dict"], [34, 1, 1, "", "pause"], [34, 2, 1, "", "policy_version"], [34, 1, 1, "", "receive_weights"], [34, 1, 1, "", "register_scheme_receiver"], [34, 1, 1, "", "reset"], [34, 1, 1, "", "rollout"], [34, 1, 1, "", "set_seed"], [34, 1, 1, "", "shutdown"], [34, 1, 1, "", "start"], [34, 1, 1, "", "state_dict"], [34, 1, 1, "", "update_policy_weights_"], [34, 2, 1, "", "worker_idx"]], "torchrl.collectors.MultiAsyncCollector": [[35, 1, 1, "", "async_shutdown"], [35, 1, 1, "", "cascade_execute"], [35, 1, 1, "", "get_cached_weights"], [35, 1, 1, "", "get_model"], [35, 1, 1, "", "get_policy_version"], [35, 1, 1, "", "getattr_env"], [35, 1, 1, "", "getattr_policy"], [35, 1, 1, "", "getattr_rb"], [35, 1, 1, "", "increment_version"], [35, 1, 1, "", "init_updater"], [35, 1, 1, "", "load_state_dict"], [35, 1, 1, "", "pause"], [35, 2, 1, "", "policy_version"], [35, 1, 1, "", "receive_weights"], [35, 1, 1, "", "register_scheme_receiver"], [35, 1, 1, "", "reset"], [35, 1, 1, "", "set_seed"], [35, 1, 1, "", "shutdown"], [35, 1, 1, "", "start"], [35, 1, 1, "", "state_dict"], [35, 1, 1, "", "update_policy_weights_"], [35, 2, 1, "", "worker_idx"]], "torchrl.collectors.MultiCollector": [[36, 1, 1, "", "async_shutdown"], [36, 1, 1, "", "cascade_execute"], [36, 1, 1, "", "get_cached_weights"], [36, 1, 1, "", "get_model"], [36, 1, 1, "", "get_policy_version"], [36, 1, 1, "", "getattr_env"], [36, 1, 1, "", "getattr_policy"], [36, 1, 1, "", "getattr_rb"], [36, 1, 1, "", "increment_version"], [36, 1, 1, "", "init_updater"], [36, 1, 1, "", "load_state_dict"], [36, 1, 1, "", "pause"], [36, 2, 1, "", "policy_version"], [36, 1, 1, "", "receive_weights"], [36, 1, 1, "", "register_scheme_receiver"], [36, 1, 1, "", "reset"], [36, 1, 1, "", "set_seed"], [36, 1, 1, "", "shutdown"], [36, 1, 1, "", "start"], [36, 1, 1, "", "state_dict"], [36, 1, 1, "", "update_policy_weights_"], [36, 2, 1, "", "worker_idx"]], "torchrl.collectors.MultiProcessedWeightUpdater": [[37, 1, 1, "", "all_worker_ids"], [37, 2, 1, "", "collector"], [37, 2, 1, "", "collectors"], [37, 1, 1, "", "from_policy"], [37, 1, 1, "", "increment_version"], [37, 1, 1, "", "init"], [37, 2, 1, "", "post_hooks"], [37, 1, 1, "", "push_weights"], [37, 1, 1, "", "register_collector"], [37, 1, 1, "", "register_post_hook"]], "torchrl.collectors.MultiSyncCollector": [[38, 1, 1, "", "async_shutdown"], [38, 1, 1, "", "cascade_execute"], [38, 1, 1, "", "get_cached_weights"], [38, 1, 1, "", "get_model"], [38, 1, 1, "", "get_policy_version"], [38, 1, 1, "", "getattr_env"], [38, 1, 1, "", "getattr_policy"], [38, 1, 1, "", "getattr_rb"], [38, 1, 1, "", "increment_version"], [38, 1, 1, "", "init_updater"], [38, 1, 1, "", "load_state_dict"], [38, 1, 1, "", "pause"], [38, 2, 1, "", "policy_version"], [38, 1, 1, "", "receive_weights"], [38, 1, 1, "", "register_scheme_receiver"], [38, 1, 1, "", "reset"], [38, 1, 1, "", "set_seed"], [38, 1, 1, "", "shutdown"], [38, 1, 1, "", "start"], [38, 1, 1, "", "state_dict"], [38, 1, 1, "", "update_policy_weights_"], [38, 2, 1, "", "worker_idx"]], "torchrl.collectors.RayWeightUpdater": [[39, 1, 1, "", "_get_server_weights"], [39, 1, 1, "", "_maybe_map_weights"], [39, 1, 1, "", "_skip_update"], [39, 1, 1, "", "_sync_weights_with_worker"], [39, 1, 1, "id0", "all_worker_ids"], [39, 2, 1, "", "collector"], [39, 2, 1, "", "collectors"], [39, 1, 1, "", "from_policy"], [39, 1, 1, "", "increment_version"], [39, 1, 1, "", "init"], [39, 2, 1, "", "post_hooks"], [39, 1, 1, "", "push_weights"], [39, 1, 1, "", "register_collector"], [39, 1, 1, "", "register_post_hook"]], "torchrl.collectors.VanillaWeightUpdater": [[40, 1, 1, "", "all_worker_ids"], [40, 2, 1, "", "collector"], [40, 2, 1, "", "collectors"], [40, 1, 1, "", "from_policy"], [40, 1, 1, "", "increment_version"], [40, 1, 1, "", "init"], [40, 2, 1, "", "post_hooks"], [40, 1, 1, "", "push_weights"], [40, 1, 1, "", "register_collector"], [40, 1, 1, "", "register_post_hook"]], "torchrl.collectors.WeightUpdaterBase": [[41, 1, 1, "", "all_worker_ids"], [41, 2, 1, "", "collector"], [41, 2, 1, "", "collectors"], [41, 1, 1, "id0", "from_policy"], [41, 1, 1, "", "increment_version"], [41, 1, 1, "", "init"], [41, 2, 1, "", "post_hooks"], [41, 1, 1, "id1", "push_weights"], [41, 1, 1, "id2", "register_collector"], [41, 1, 1, "", "register_post_hook"]], "torchrl.collectors.distributed": [[42, 0, 1, "", "DistributedCollector"], [43, 0, 1, "", "DistributedDataCollector"], [44, 0, 1, "", "DistributedSyncCollector"], [45, 0, 1, "", "DistributedSyncDataCollector"], [46, 0, 1, "", "DistributedWeightUpdater"], [47, 0, 1, "", "RPCCollector"], [48, 0, 1, "", "RPCDataCollector"], [49, 0, 1, "", "RPCWeightUpdater"], [50, 0, 1, "", "RayCollector"], [51, 0, 1, "", "submitit_delayed_launcher"]], "torchrl.collectors.distributed.DistributedCollector": [[42, 1, 1, "", "async_shutdown"], [42, 1, 1, "", "cascade_execute"], [42, 1, 1, "", "init_updater"], [42, 1, 1, "", "pause"], [42, 1, 1, "", "receive_weights"], [42, 1, 1, "", "register_scheme_receiver"], [42, 1, 1, "", "start"], [42, 1, 1, "", "update_policy_weights_"], [42, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.DistributedDataCollector": [[43, 1, 1, "", "async_shutdown"], [43, 1, 1, "", "cascade_execute"], [43, 1, 1, "", "init_updater"], [43, 1, 1, "", "pause"], [43, 1, 1, "", "receive_weights"], [43, 1, 1, "", "register_scheme_receiver"], [43, 1, 1, "", "start"], [43, 1, 1, "", "update_policy_weights_"], [43, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.DistributedSyncCollector": [[44, 1, 1, "", "async_shutdown"], [44, 1, 1, "", "cascade_execute"], [44, 1, 1, "", "init_updater"], [44, 1, 1, "", "pause"], [44, 1, 1, "", "receive_weights"], [44, 1, 1, "", "register_scheme_receiver"], [44, 1, 1, "", "start"], [44, 1, 1, "", "update_policy_weights_"], [44, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.DistributedSyncDataCollector": [[45, 1, 1, "", "async_shutdown"], [45, 1, 1, "", "cascade_execute"], [45, 1, 1, "", "init_updater"], [45, 1, 1, "", "pause"], [45, 1, 1, "", "receive_weights"], [45, 1, 1, "", "register_scheme_receiver"], [45, 1, 1, "", "start"], [45, 1, 1, "", "update_policy_weights_"], [45, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.DistributedWeightUpdater": [[46, 1, 1, "", "_get_server_weights"], [46, 1, 1, "", "_maybe_map_weights"], [46, 1, 1, "", "_sync_weights_with_worker"], [46, 1, 1, "id0", "all_worker_ids"], [46, 2, 1, "", "collector"], [46, 2, 1, "", "collectors"], [46, 1, 1, "", "from_policy"], [46, 1, 1, "", "increment_version"], [46, 1, 1, "", "init"], [46, 2, 1, "", "post_hooks"], [46, 1, 1, "", "push_weights"], [46, 1, 1, "", "register_collector"], [46, 1, 1, "", "register_post_hook"], [46, 1, 1, "", "update_weights"]], "torchrl.collectors.distributed.RPCCollector": [[47, 1, 1, "", "async_shutdown"], [47, 1, 1, "", "cascade_execute"], [47, 1, 1, "", "init_updater"], [47, 1, 1, "", "pause"], [47, 1, 1, "", "receive_weights"], [47, 1, 1, "", "register_scheme_receiver"], [47, 1, 1, "", "start"], [47, 1, 1, "", "update_policy_weights_"], [47, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.RPCDataCollector": [[48, 1, 1, "", "async_shutdown"], [48, 1, 1, "", "cascade_execute"], [48, 1, 1, "", "init_updater"], [48, 1, 1, "", "pause"], [48, 1, 1, "", "receive_weights"], [48, 1, 1, "", "register_scheme_receiver"], [48, 1, 1, "", "start"], [48, 1, 1, "", "update_policy_weights_"], [48, 2, 1, "", "worker_idx"]], "torchrl.collectors.distributed.RPCWeightUpdater": [[49, 1, 1, "", "_get_server_weights"], [49, 1, 1, "", "_maybe_map_weights"], [49, 1, 1, "", "_sync_weights_with_worker"], [49, 1, 1, "id0", "all_worker_ids"], [49, 2, 1, "", "collector"], [49, 2, 1, "", "collectors"], [49, 1, 1, "", "from_policy"], [49, 1, 1, "", "increment_version"], [49, 1, 1, "", "init"], [49, 2, 1, "", "post_hooks"], [49, 1, 1, "", "push_weights"], [49, 1, 1, "", "register_collector"], [49, 1, 1, "", "register_post_hook"], [49, 1, 1, "", "update_weights"]], "torchrl.collectors.distributed.RayCollector": [[50, 1, 1, "", "add_collectors"], [50, 1, 1, "", "async_shutdown"], [50, 1, 1, "", "cascade_execute"], [50, 1, 1, "", "init_updater"], [50, 1, 1, "", "load_state_dict"], [50, 1, 1, "", "local_policy"], [50, 1, 1, "", "pause"], [50, 1, 1, "", "receive_weights"], [50, 1, 1, "", "register_scheme_receiver"], [50, 2, 1, "", "remote_collectors"], [50, 1, 1, "", "set_seed"], [50, 1, 1, "", "shutdown"], [50, 1, 1, "", "start"], [50, 1, 1, "", "state_dict"], [50, 1, 1, "", "stop_remote_collectors"], [50, 1, 1, "", "update_policy_weights_"], [50, 2, 1, "", "worker_idx"]], "torchrl.collectors.llm": [[52, 0, 1, "", "LLMCollector"], [53, 0, 1, "", "RayLLMCollector"], [54, 0, 1, "", "vLLMUpdater"], [55, 0, 1, "", "vLLMUpdaterV2"]], "torchrl.collectors.llm.LLMCollector": [[52, 1, 1, "", "as_remote"], [52, 1, 1, "", "async_shutdown"], [52, 1, 1, "", "cascade_execute"], [52, 2, 1, "", "dialog_turns_per_batch"], [52, 1, 1, "", "get_model"], [52, 1, 1, "", "get_policy_model"], [52, 1, 1, "", "get_policy_version"], [52, 1, 1, "", "getattr_env"], [52, 1, 1, "", "getattr_policy"], [52, 1, 1, "", "getattr_rb"], [52, 1, 1, "", "increment_version"], [52, 1, 1, "", "init_updater"], [52, 1, 1, "", "is_initialized"], [52, 1, 1, "", "iterator"], [52, 1, 1, "", "load_state_dict"], [52, 1, 1, "", "pause"], [52, 2, 1, "", "policy_version"], [52, 1, 1, "", "receive_weights"], [52, 1, 1, "", "register_scheme_receiver"], [52, 1, 1, "", "reset"], [52, 2, 1, "", "rollout"], [52, 1, 1, "", "set_seed"], [52, 1, 1, "", "shutdown"], [52, 1, 1, "", "start"], [52, 1, 1, "", "state_dict"], [52, 1, 1, "", "update_policy_weights_"], [52, 2, 1, "", "worker_idx"]], "torchrl.collectors.llm.RayLLMCollector": [[53, 1, 1, "", "as_remote"], [53, 1, 1, "", "async_shutdown"], [53, 1, 1, "", "cascade_execute"], [53, 2, 1, "", "dialog_turns_per_batch"], [53, 1, 1, "", "get_model"], [53, 1, 1, "", "get_policy_model"], [53, 1, 1, "", "get_policy_version"], [53, 1, 1, "", "getattr_env"], [53, 1, 1, "", "getattr_policy"], [53, 1, 1, "", "getattr_rb"], [53, 1, 1, "", "increment_version"], [53, 1, 1, "", "init_updater"], [53, 1, 1, "", "is_initialized"], [53, 1, 1, "", "iterator"], [53, 1, 1, "", "load_state_dict"], [53, 1, 1, "", "next"], [53, 1, 1, "", "pause"], [53, 2, 1, "", "policy_version"], [53, 1, 1, "", "receive_weights"], [53, 1, 1, "", "register_scheme_receiver"], [53, 1, 1, "", "reset"], [53, 2, 1, "", "rollout"], [53, 1, 1, "", "set_seed"], [53, 1, 1, "", "shutdown"], [53, 1, 1, "", "start"], [53, 1, 1, "", "state_dict"], [53, 2, 1, "", "total_dialog_turns"], [53, 1, 1, "", "update_policy_weights_"], [53, 2, 1, "", "weight_updater"], [53, 2, 1, "", "worker_idx"]], "torchrl.collectors.llm.vLLMUpdater": [[54, 1, 1, "", "_get_server_weights"], [54, 1, 1, "", "_maybe_map_weights"], [54, 1, 1, "", "_sync_weights_with_worker"], [54, 1, 1, "id0", "all_worker_ids"], [54, 2, 1, "", "collector"], [54, 2, 1, "", "collectors"], [54, 1, 1, "", "from_policy"], [54, 1, 1, "", "get_model_metadata"], [54, 1, 1, "", "increment_version"], [54, 1, 1, "id1", "init"], [54, 2, 1, "", "post_hooks"], [54, 1, 1, "", "push_weights"], [54, 1, 1, "", "register_collector"], [54, 1, 1, "", "register_post_hook"]], "torchrl.collectors.llm.vLLMUpdaterV2": [[55, 1, 1, "", "all_worker_ids"], [55, 2, 1, "", "collector"], [55, 2, 1, "", "collectors"], [55, 1, 1, "", "from_policy"], [55, 1, 1, "", "get_model_metadata"], [55, 1, 1, "", "get_tp_size"], [55, 1, 1, "", "increment_version"], [55, 1, 1, "", "init"], [55, 2, 1, "", "post_hooks"], [55, 1, 1, "", "push_weights"], [55, 1, 1, "", "push_weights_from_transformers"], [55, 1, 1, "", "push_weights_from_transformers_optimized"], [55, 1, 1, "", "register_collector"], [55, 1, 1, "", "register_post_hook"]], "torchrl.collectors.utils": [[56, 3, 1, "", "split_trajectories"]], "torchrl.data": [[57, 0, 1, "", "Binary"], [58, 0, 1, "", "Bounded"], [59, 0, 1, "", "Categorical"], [60, 0, 1, "", "Composite"], [61, 0, 1, "", "MultiCategorical"], [62, 0, 1, "", "MultiOneHot"], [63, 0, 1, "", "NonTensor"], [64, 0, 1, "", "OneHot"], [65, 0, 1, "", "PrioritizedReplayBuffer"], [66, 0, 1, "", "RayReplayBuffer"], [67, 0, 1, "", "RemoteTensorDictReplayBuffer"], [68, 0, 1, "", "ReplayBuffer"], [69, 0, 1, "", "ReplayBufferEnsemble"], [70, 0, 1, "", "Stacked"], [71, 0, 1, "", "StackedComposite"], [72, 0, 1, "", "TensorDictPrioritizedReplayBuffer"], [73, 0, 1, "", "TensorDictReplayBuffer"], [74, 0, 1, "", "TensorSpec"], [75, 0, 1, "", "Unbounded"], [76, 0, 1, "", "UnboundedContinuous"], [77, 0, 1, "", "UnboundedDiscrete"]], "torchrl.data.Binary": [[57, 1, 1, "", "assert_is_in"], [57, 1, 1, "", "cardinality"], [57, 1, 1, "", "clear_device_"], [57, 1, 1, "", "clone"], [57, 1, 1, "", "contains"], [57, 1, 1, "", "cpu"], [57, 1, 1, "", "cuda"], [57, 4, 1, "", "device"], [57, 1, 1, "", "encode"], [57, 1, 1, "", "enumerate"], [57, 1, 1, "", "erase_memoize_cache"], [57, 1, 1, "", "expand"], [57, 1, 1, "", "flatten"], [57, 1, 1, "", "implements_for_spec"], [57, 1, 1, "", "index"], [57, 1, 1, "", "is_in"], [57, 1, 1, "", "make_neg_dim"], [57, 1, 1, "", "memoize_encode"], [57, 2, 1, "", "ndim"], [57, 1, 1, "", "ndimension"], [57, 1, 1, "", "one"], [57, 1, 1, "", "ones"], [57, 1, 1, "", "project"], [57, 1, 1, "", "rand"], [57, 1, 1, "", "reshape"], [57, 1, 1, "", "sample"], [57, 1, 1, "", "set_provisional_n"], [57, 1, 1, "", "squeeze"], [57, 1, 1, "", "to"], [57, 1, 1, "", "to_categorical"], [57, 1, 1, "", "to_categorical_spec"], [57, 1, 1, "", "to_numpy"], [57, 1, 1, "", "to_one_hot"], [57, 1, 1, "", "to_one_hot_spec"], [57, 1, 1, "", "type_check"], [57, 1, 1, "", "unflatten"], [57, 1, 1, "", "unsqueeze"], [57, 1, 1, "", "update_mask"], [57, 1, 1, "", "view"], [57, 1, 1, "", "zero"], [57, 1, 1, "", "zeros"]], "torchrl.data.Bounded": [[58, 1, 1, "", "assert_is_in"], [58, 1, 1, "", "cardinality"], [58, 1, 1, "", "clear_device_"], [58, 1, 1, "", "clone"], [58, 1, 1, "", "contains"], [58, 1, 1, "", "cpu"], [58, 1, 1, "", "cuda"], [58, 2, 1, "", "device"], [58, 1, 1, "", "encode"], [58, 1, 1, "", "enumerate"], [58, 1, 1, "", "erase_memoize_cache"], [58, 1, 1, "", "expand"], [58, 1, 1, "", "flatten"], [58, 1, 1, "", "implements_for_spec"], [58, 1, 1, "", "index"], [58, 1, 1, "", "is_in"], [58, 1, 1, "", "make_neg_dim"], [58, 1, 1, "", "memoize_encode"], [58, 2, 1, "", "ndim"], [58, 1, 1, "", "ndimension"], [58, 1, 1, "", "one"], [58, 1, 1, "", "ones"], [58, 1, 1, "", "project"], [58, 1, 1, "", "rand"], [58, 1, 1, "", "reshape"], [58, 1, 1, "", "sample"], [58, 1, 1, "", "squeeze"], [58, 1, 1, "", "to"], [58, 1, 1, "", "to_numpy"], [58, 1, 1, "", "type_check"], [58, 1, 1, "", "unflatten"], [58, 1, 1, "", "unsqueeze"], [58, 1, 1, "", "view"], [58, 1, 1, "", "zero"], [58, 1, 1, "", "zeros"]], "torchrl.data.Categorical": [[59, 1, 1, "", "assert_is_in"], [59, 1, 1, "", "cardinality"], [59, 1, 1, "", "clear_device_"], [59, 1, 1, "", "clone"], [59, 1, 1, "", "contains"], [59, 1, 1, "", "cpu"], [59, 1, 1, "", "cuda"], [59, 4, 1, "", "device"], [59, 1, 1, "", "encode"], [59, 1, 1, "", "enumerate"], [59, 1, 1, "", "erase_memoize_cache"], [59, 1, 1, "", "expand"], [59, 1, 1, "", "flatten"], [59, 1, 1, "", "implements_for_spec"], [59, 1, 1, "", "index"], [59, 1, 1, "", "is_in"], [59, 1, 1, "", "make_neg_dim"], [59, 1, 1, "", "memoize_encode"], [59, 2, 1, "", "ndim"], [59, 1, 1, "", "ndimension"], [59, 1, 1, "", "one"], [59, 1, 1, "", "ones"], [59, 1, 1, "", "project"], [59, 1, 1, "", "rand"], [59, 1, 1, "", "reshape"], [59, 1, 1, "", "sample"], [59, 1, 1, "", "set_provisional_n"], [59, 1, 1, "", "squeeze"], [59, 1, 1, "", "to"], [59, 1, 1, "", "to_categorical"], [59, 1, 1, "", "to_categorical_spec"], [59, 1, 1, "", "to_numpy"], [59, 1, 1, "", "to_one_hot"], [59, 1, 1, "", "to_one_hot_spec"], [59, 1, 1, "", "type_check"], [59, 1, 1, "", "unflatten"], [59, 1, 1, "", "unsqueeze"], [59, 1, 1, "", "update_mask"], [59, 1, 1, "", "view"], [59, 1, 1, "", "zero"], [59, 1, 1, "", "zeros"]], "torchrl.data.Composite": [[60, 1, 1, "", "assert_is_in"], [60, 1, 1, "", "cardinality"], [60, 1, 1, "", "clear_device_"], [60, 1, 1, "", "clone"], [60, 1, 1, "", "contains"], [60, 1, 1, "", "cpu"], [60, 1, 1, "", "cuda"], [60, 2, 1, "", "device"], [60, 1, 1, "", "empty"], [60, 1, 1, "", "encode"], [60, 1, 1, "", "enumerate"], [60, 1, 1, "", "erase_memoize_cache"], [60, 1, 1, "", "expand"], [60, 1, 1, "", "flatten"], [60, 1, 1, "", "get"], [60, 1, 1, "", "implements_for_spec"], [60, 1, 1, "", "index"], [60, 1, 1, "", "is_empty"], [60, 1, 1, "", "is_in"], [60, 1, 1, "", "items"], [60, 1, 1, "", "keys"], [60, 1, 1, "", "lock_"], [60, 1, 1, "", "make_neg_dim"], [60, 1, 1, "", "memoize_encode"], [60, 2, 1, "", "names"], [60, 2, 1, "", "ndim"], [60, 1, 1, "", "ndimension"], [60, 1, 1, "", "one"], [60, 1, 1, "", "ones"], [60, 1, 1, "", "ones_update"], [60, 1, 1, "", "pop"], [60, 1, 1, "", "project"], [60, 1, 1, "", "rand"], [60, 1, 1, "", "rand_update"], [60, 1, 1, "", "refine_names"], [60, 1, 1, "", "reshape"], [60, 1, 1, "", "sample"], [60, 1, 1, "", "separates"], [60, 1, 1, "", "set"], [60, 1, 1, "", "squeeze"], [60, 1, 1, "", "to"], [60, 1, 1, "", "to_numpy"], [60, 1, 1, "", "type_check"], [60, 1, 1, "", "unflatten"], [60, 1, 1, "", "unlock_"], [60, 1, 1, "", "unsqueeze"], [60, 1, 1, "", "values"], [60, 1, 1, "", "view"], [60, 1, 1, "", "zero"], [60, 1, 1, "", "zeros"], [60, 1, 1, "", "zeros_update"]], "torchrl.data.MultiCategorical": [[61, 1, 1, "", "assert_is_in"], [61, 1, 1, "", "cardinality"], [61, 1, 1, "", "clear_device_"], [61, 1, 1, "", "clone"], [61, 1, 1, "", "contains"], [61, 1, 1, "", "cpu"], [61, 1, 1, "", "cuda"], [61, 4, 1, "", "device"], [61, 1, 1, "", "encode"], [61, 1, 1, "", "enumerate"], [61, 1, 1, "", "erase_memoize_cache"], [61, 1, 1, "", "expand"], [61, 1, 1, "", "flatten"], [61, 1, 1, "", "implements_for_spec"], [61, 1, 1, "", "index"], [61, 1, 1, "", "is_in"], [61, 1, 1, "", "make_neg_dim"], [61, 1, 1, "", "memoize_encode"], [61, 2, 1, "", "ndim"], [61, 1, 1, "", "ndimension"], [61, 1, 1, "", "one"], [61, 1, 1, "", "ones"], [61, 1, 1, "", "project"], [61, 1, 1, "", "rand"], [61, 1, 1, "", "reshape"], [61, 1, 1, "", "sample"], [61, 1, 1, "", "set_provisional_n"], [61, 1, 1, "", "squeeze"], [61, 1, 1, "", "to"], [61, 1, 1, "", "to_categorical"], [61, 1, 1, "", "to_categorical_spec"], [61, 1, 1, "", "to_numpy"], [61, 1, 1, "", "to_one_hot"], [61, 1, 1, "", "to_one_hot_spec"], [61, 1, 1, "", "type_check"], [61, 1, 1, "", "unflatten"], [61, 1, 1, "", "unsqueeze"], [61, 1, 1, "", "update_mask"], [61, 1, 1, "", "view"], [61, 1, 1, "", "zero"], [61, 1, 1, "", "zeros"]], "torchrl.data.MultiOneHot": [[62, 1, 1, "", "assert_is_in"], [62, 1, 1, "", "cardinality"], [62, 1, 1, "", "clear_device_"], [62, 1, 1, "", "clone"], [62, 1, 1, "", "contains"], [62, 1, 1, "", "cpu"], [62, 1, 1, "", "cuda"], [62, 4, 1, "", "device"], [62, 1, 1, "", "encode"], [62, 1, 1, "", "enumerate"], [62, 1, 1, "", "erase_memoize_cache"], [62, 1, 1, "", "expand"], [62, 1, 1, "", "flatten"], [62, 1, 1, "", "implements_for_spec"], [62, 1, 1, "", "index"], [62, 1, 1, "", "is_in"], [62, 1, 1, "", "make_neg_dim"], [62, 1, 1, "", "memoize_encode"], [62, 2, 1, "", "ndim"], [62, 1, 1, "", "ndimension"], [62, 1, 1, "", "one"], [62, 1, 1, "", "ones"], [62, 1, 1, "", "project"], [62, 1, 1, "", "rand"], [62, 1, 1, "", "reshape"], [62, 1, 1, "", "sample"], [62, 1, 1, "", "squeeze"], [62, 1, 1, "", "to"], [62, 1, 1, "", "to_categorical"], [62, 1, 1, "", "to_categorical_spec"], [62, 1, 1, "", "to_numpy"], [62, 1, 1, "", "to_one_hot"], [62, 1, 1, "", "to_one_hot_spec"], [62, 1, 1, "", "type_check"], [62, 1, 1, "", "unflatten"], [62, 1, 1, "", "unsqueeze"], [62, 1, 1, "", "update_mask"], [62, 1, 1, "", "view"], [62, 1, 1, "", "zero"], [62, 1, 1, "", "zeros"]], "torchrl.data.NonTensor": [[63, 1, 1, "", "assert_is_in"], [63, 1, 1, "", "cardinality"], [63, 1, 1, "", "clear_device_"], [63, 1, 1, "", "clone"], [63, 1, 1, "", "contains"], [63, 1, 1, "", "cpu"], [63, 1, 1, "", "cuda"], [63, 2, 1, "", "device"], [63, 1, 1, "", "encode"], [63, 1, 1, "", "enumerate"], [63, 1, 1, "", "erase_memoize_cache"], [63, 1, 1, "", "expand"], [63, 1, 1, "", "flatten"], [63, 1, 1, "", "implements_for_spec"], [63, 1, 1, "", "index"], [63, 1, 1, "", "is_in"], [63, 1, 1, "", "make_neg_dim"], [63, 1, 1, "", "memoize_encode"], [63, 2, 1, "", "ndim"], [63, 1, 1, "", "ndimension"], [63, 1, 1, "", "one"], [63, 1, 1, "", "ones"], [63, 1, 1, "", "project"], [63, 1, 1, "", "rand"], [63, 1, 1, "", "reshape"], [63, 1, 1, "", "sample"], [63, 1, 1, "", "squeeze"], [63, 1, 1, "", "to"], [63, 1, 1, "", "to_numpy"], [63, 1, 1, "", "type_check"], [63, 1, 1, "", "unflatten"], [63, 1, 1, "", "unsqueeze"], [63, 1, 1, "", "view"], [63, 1, 1, "", "zero"], [63, 1, 1, "", "zeros"]], "torchrl.data.OneHot": [[64, 1, 1, "", "assert_is_in"], [64, 1, 1, "", "cardinality"], [64, 1, 1, "", "clear_device_"], [64, 1, 1, "", "clone"], [64, 1, 1, "", "contains"], [64, 1, 1, "", "cpu"], [64, 1, 1, "", "cuda"], [64, 4, 1, "", "device"], [64, 1, 1, "", "encode"], [64, 1, 1, "", "enumerate"], [64, 1, 1, "", "erase_memoize_cache"], [64, 1, 1, "", "expand"], [64, 1, 1, "", "flatten"], [64, 1, 1, "", "implements_for_spec"], [64, 1, 1, "", "index"], [64, 1, 1, "", "is_in"], [64, 1, 1, "", "make_neg_dim"], [64, 1, 1, "", "memoize_encode"], [64, 2, 1, "", "ndim"], [64, 1, 1, "", "ndimension"], [64, 1, 1, "", "one"], [64, 1, 1, "", "ones"], [64, 1, 1, "", "project"], [64, 1, 1, "", "rand"], [64, 1, 1, "", "reshape"], [64, 1, 1, "", "sample"], [64, 1, 1, "", "squeeze"], [64, 1, 1, "", "to"], [64, 1, 1, "", "to_categorical"], [64, 1, 1, "", "to_categorical_spec"], [64, 1, 1, "", "to_numpy"], [64, 1, 1, "", "to_one_hot"], [64, 1, 1, "", "to_one_hot_spec"], [64, 1, 1, "", "type_check"], [64, 1, 1, "", "unflatten"], [64, 1, 1, "", "unsqueeze"], [64, 1, 1, "", "update_mask"], [64, 1, 1, "", "view"], [64, 1, 1, "", "zero"], [64, 1, 1, "", "zeros"]], "torchrl.data.PrioritizedReplayBuffer": [[65, 1, 1, "", "add"], [65, 1, 1, "", "append_transform"], [65, 1, 1, "", "as_remote"], [65, 2, 1, "", "batch_size"], [65, 1, 1, "", "dump"], [65, 1, 1, "", "dumps"], [65, 1, 1, "", "empty"], [65, 1, 1, "", "extend"], [65, 2, 1, "", "initialized"], [65, 1, 1, "", "insert_transform"], [65, 1, 1, "", "load"], [65, 1, 1, "", "loads"], [65, 1, 1, "", "next"], [65, 1, 1, "", "register_load_hook"], [65, 1, 1, "", "register_save_hook"], [65, 1, 1, "", "sample"], [65, 2, 1, "", "sampler"], [65, 1, 1, "", "save"], [65, 1, 1, "", "set_sampler"], [65, 1, 1, "", "set_storage"], [65, 1, 1, "", "set_writer"], [65, 2, 1, "", "storage"], [65, 2, 1, "", "transform"], [65, 2, 1, "", "write_count"], [65, 2, 1, "", "writer"]], "torchrl.data.RayReplayBuffer": [[66, 1, 1, "", "add"], [66, 1, 1, "", "append_transform"], [66, 1, 1, "", "as_remote"], [66, 2, 1, "", "batch_size"], [66, 1, 1, "", "close"], [66, 1, 1, "", "dump"], [66, 1, 1, "", "dumps"], [66, 1, 1, "", "empty"], [66, 1, 1, "", "extend"], [66, 2, 1, "", "initialized"], [66, 1, 1, "", "insert_transform"], [66, 1, 1, "", "load"], [66, 1, 1, "", "loads"], [66, 1, 1, "", "next"], [66, 1, 1, "", "register_load_hook"], [66, 1, 1, "", "register_save_hook"], [66, 1, 1, "", "sample"], [66, 2, 1, "", "sampler"], [66, 1, 1, "", "save"], [66, 1, 1, "", "set_sampler"], [66, 1, 1, "", "set_storage"], [66, 1, 1, "", "set_writer"], [66, 2, 1, "", "storage"], [66, 2, 1, "", "transform"], [66, 2, 1, "", "write_count"], [66, 2, 1, "", "writer"]], "torchrl.data.RemoteTensorDictReplayBuffer": [[67, 1, 1, "", "add"], [67, 1, 1, "", "append_transform"], [67, 1, 1, "", "as_remote"], [67, 2, 1, "", "batch_size"], [67, 1, 1, "", "dump"], [67, 1, 1, "", "dumps"], [67, 1, 1, "", "empty"], [67, 1, 1, "", "extend"], [67, 2, 1, "", "initialized"], [67, 1, 1, "", "insert_transform"], [67, 1, 1, "", "load"], [67, 1, 1, "", "loads"], [67, 1, 1, "", "next"], [67, 1, 1, "", "register_load_hook"], [67, 1, 1, "", "register_save_hook"], [67, 1, 1, "", "sample"], [67, 2, 1, "", "sampler"], [67, 1, 1, "", "save"], [67, 1, 1, "", "set_sampler"], [67, 1, 1, "", "set_storage"], [67, 1, 1, "", "set_writer"], [67, 2, 1, "", "storage"], [67, 2, 1, "", "transform"], [67, 2, 1, "", "write_count"], [67, 2, 1, "", "writer"]], "torchrl.data.ReplayBuffer": [[68, 1, 1, "", "add"], [68, 1, 1, "", "append_transform"], [68, 1, 1, "", "as_remote"], [68, 2, 1, "", "batch_size"], [68, 1, 1, "", "dump"], [68, 1, 1, "", "dumps"], [68, 1, 1, "", "empty"], [68, 1, 1, "", "extend"], [68, 2, 1, "", "initialized"], [68, 1, 1, "", "insert_transform"], [68, 1, 1, "", "load"], [68, 1, 1, "", "loads"], [68, 1, 1, "", "next"], [68, 1, 1, "", "register_load_hook"], [68, 1, 1, "", "register_save_hook"], [68, 1, 1, "", "sample"], [68, 2, 1, "", "sampler"], [68, 1, 1, "", "save"], [68, 1, 1, "", "set_sampler"], [68, 1, 1, "", "set_storage"], [68, 1, 1, "", "set_writer"], [68, 2, 1, "", "storage"], [68, 2, 1, "", "transform"], [68, 2, 1, "", "write_count"], [68, 2, 1, "", "writer"]], "torchrl.data.ReplayBufferEnsemble": [[69, 1, 1, "", "add"], [69, 1, 1, "", "append_transform"], [69, 1, 1, "", "as_remote"], [69, 2, 1, "", "batch_size"], [69, 1, 1, "", "dump"], [69, 1, 1, "", "dumps"], [69, 1, 1, "", "empty"], [69, 1, 1, "", "extend"], [69, 2, 1, "", "initialized"], [69, 1, 1, "", "insert_transform"], [69, 1, 1, "", "load"], [69, 1, 1, "", "loads"], [69, 1, 1, "", "next"], [69, 1, 1, "", "register_load_hook"], [69, 1, 1, "", "register_save_hook"], [69, 1, 1, "", "sample"], [69, 2, 1, "", "sampler"], [69, 1, 1, "", "save"], [69, 1, 1, "", "set_sampler"], [69, 1, 1, "", "set_storage"], [69, 1, 1, "", "set_writer"], [69, 2, 1, "", "storage"], [69, 2, 1, "", "transform"], [69, 2, 1, "", "write_count"], [69, 2, 1, "", "writer"]], "torchrl.data.Stacked": [[70, 1, 1, "", "assert_is_in"], [70, 1, 1, "", "cardinality"], [70, 1, 1, "", "clear_device_"], [70, 1, 1, "", "clone"], [70, 1, 1, "", "contains"], [70, 1, 1, "", "cpu"], [70, 1, 1, "", "cuda"], [70, 2, 1, "", "device"], [70, 1, 1, "", "encode"], [70, 1, 1, "", "enumerate"], [70, 1, 1, "", "erase_memoize_cache"], [70, 1, 1, "", "expand"], [70, 1, 1, "", "flatten"], [70, 1, 1, "", "implements_for_spec"], [70, 1, 1, "", "index"], [70, 1, 1, "", "is_in"], [70, 1, 1, "", "make_neg_dim"], [70, 1, 1, "", "memoize_encode"], [70, 2, 1, "", "ndim"], [70, 1, 1, "", "ndimension"], [70, 1, 1, "", "one"], [70, 1, 1, "", "ones"], [70, 1, 1, "", "project"], [70, 1, 1, "", "rand"], [70, 1, 1, "", "reshape"], [70, 1, 1, "", "sample"], [70, 1, 1, "", "squeeze"], [70, 1, 1, "", "to"], [70, 1, 1, "", "to_numpy"], [70, 1, 1, "", "type_check"], [70, 1, 1, "", "unflatten"], [70, 1, 1, "", "unsqueeze"], [70, 1, 1, "", "view"], [70, 1, 1, "", "zero"], [70, 1, 1, "", "zeros"]], "torchrl.data.StackedComposite": [[71, 1, 1, "", "assert_is_in"], [71, 1, 1, "", "cardinality"], [71, 1, 1, "", "clear_device_"], [71, 1, 1, "", "clone"], [71, 1, 1, "", "contains"], [71, 1, 1, "", "cpu"], [71, 1, 1, "", "cuda"], [71, 2, 1, "", "device"], [71, 1, 1, "", "empty"], [71, 1, 1, "", "encode"], [71, 1, 1, "", "enumerate"], [71, 1, 1, "", "erase_memoize_cache"], [71, 1, 1, "", "expand"], [71, 1, 1, "", "flatten"], [71, 1, 1, "", "get"], [71, 1, 1, "", "implements_for_spec"], [71, 1, 1, "", "index"], [71, 1, 1, "", "is_empty"], [71, 1, 1, "", "is_in"], [71, 1, 1, "", "items"], [71, 1, 1, "", "keys"], [71, 1, 1, "", "lock_"], [71, 1, 1, "", "make_neg_dim"], [71, 1, 1, "", "memoize_encode"], [71, 2, 1, "", "names"], [71, 2, 1, "", "ndim"], [71, 1, 1, "", "ndimension"], [71, 1, 1, "", "one"], [71, 1, 1, "", "ones"], [71, 1, 1, "", "ones_update"], [71, 1, 1, "", "pop"], [71, 1, 1, "", "project"], [71, 1, 1, "", "rand"], [71, 1, 1, "", "rand_update"], [71, 1, 1, "", "refine_names"], [71, 1, 1, "", "reshape"], [71, 1, 1, "", "sample"], [71, 1, 1, "", "separates"], [71, 1, 1, "", "set"], [71, 1, 1, "", "squeeze"], [71, 1, 1, "", "to"], [71, 1, 1, "", "to_numpy"], [71, 1, 1, "", "type_check"], [71, 1, 1, "", "unflatten"], [71, 1, 1, "", "unlock_"], [71, 1, 1, "", "unsqueeze"], [71, 1, 1, "", "values"], [71, 1, 1, "", "view"], [71, 1, 1, "", "zero"], [71, 1, 1, "", "zeros"], [71, 1, 1, "", "zeros_update"]], "torchrl.data.TensorDictPrioritizedReplayBuffer": [[72, 1, 1, "", "add"], [72, 1, 1, "", "append_transform"], [72, 1, 1, "", "as_remote"], [72, 2, 1, "", "batch_size"], [72, 1, 1, "", "dump"], [72, 1, 1, "", "dumps"], [72, 1, 1, "", "empty"], [72, 1, 1, "", "extend"], [72, 2, 1, "", "initialized"], [72, 1, 1, "", "insert_transform"], [72, 1, 1, "", "load"], [72, 1, 1, "", "loads"], [72, 1, 1, "", "next"], [72, 1, 1, "", "register_load_hook"], [72, 1, 1, "", "register_save_hook"], [72, 1, 1, "", "sample"], [72, 2, 1, "", "sampler"], [72, 1, 1, "", "save"], [72, 1, 1, "", "set_sampler"], [72, 1, 1, "", "set_storage"], [72, 1, 1, "", "set_writer"], [72, 2, 1, "", "storage"], [72, 2, 1, "", "transform"], [72, 2, 1, "", "write_count"], [72, 2, 1, "", "writer"]], "torchrl.data.TensorDictReplayBuffer": [[73, 1, 1, "", "add"], [73, 1, 1, "", "append_transform"], [73, 1, 1, "", "as_remote"], [73, 2, 1, "", "batch_size"], [73, 1, 1, "", "dump"], [73, 1, 1, "", "dumps"], [73, 1, 1, "", "empty"], [73, 1, 1, "", "extend"], [73, 2, 1, "", "initialized"], [73, 1, 1, "", "insert_transform"], [73, 1, 1, "", "load"], [73, 1, 1, "", "loads"], [73, 1, 1, "", "next"], [73, 1, 1, "", "register_load_hook"], [73, 1, 1, "", "register_save_hook"], [73, 1, 1, "", "sample"], [73, 2, 1, "", "sampler"], [73, 1, 1, "", "save"], [73, 1, 1, "", "set_sampler"], [73, 1, 1, "", "set_storage"], [73, 1, 1, "", "set_writer"], [73, 2, 1, "", "storage"], [73, 2, 1, "", "transform"], [73, 2, 1, "", "write_count"], [73, 2, 1, "", "writer"]], "torchrl.data.TensorSpec": [[74, 1, 1, "", "assert_is_in"], [74, 1, 1, "", "cardinality"], [74, 1, 1, "", "clear_device_"], [74, 1, 1, "", "clone"], [74, 1, 1, "", "contains"], [74, 1, 1, "", "cpu"], [74, 1, 1, "", "cuda"], [74, 2, 1, "", "device"], [74, 1, 1, "", "encode"], [74, 1, 1, "", "enumerate"], [74, 1, 1, "", "erase_memoize_cache"], [74, 1, 1, "", "expand"], [74, 1, 1, "", "flatten"], [74, 1, 1, "", "implements_for_spec"], [74, 1, 1, "", "index"], [74, 1, 1, "", "is_in"], [74, 1, 1, "", "make_neg_dim"], [74, 1, 1, "", "memoize_encode"], [74, 2, 1, "", "ndim"], [74, 1, 1, "", "ndimension"], [74, 1, 1, "", "one"], [74, 1, 1, "", "ones"], [74, 1, 1, "", "project"], [74, 1, 1, "", "rand"], [74, 1, 1, "", "reshape"], [74, 1, 1, "", "sample"], [74, 1, 1, "", "squeeze"], [74, 1, 1, "", "to"], [74, 1, 1, "", "to_numpy"], [74, 1, 1, "", "type_check"], [74, 1, 1, "", "unflatten"], [74, 1, 1, "", "unsqueeze"], [74, 1, 1, "", "view"], [74, 1, 1, "", "zero"], [74, 1, 1, "", "zeros"]], "torchrl.data.Unbounded": [[75, 1, 1, "", "assert_is_in"], [75, 1, 1, "", "cardinality"], [75, 1, 1, "", "clear_device_"], [75, 1, 1, "", "clone"], [75, 1, 1, "", "contains"], [75, 1, 1, "", "cpu"], [75, 1, 1, "", "cuda"], [75, 2, 1, "", "device"], [75, 1, 1, "", "encode"], [75, 1, 1, "", "enumerate"], [75, 1, 1, "", "erase_memoize_cache"], [75, 1, 1, "", "expand"], [75, 1, 1, "", "flatten"], [75, 1, 1, "", "implements_for_spec"], [75, 1, 1, "", "index"], [75, 1, 1, "", "is_in"], [75, 1, 1, "", "make_neg_dim"], [75, 1, 1, "", "memoize_encode"], [75, 2, 1, "", "ndim"], [75, 1, 1, "", "ndimension"], [75, 1, 1, "", "one"], [75, 1, 1, "", "ones"], [75, 1, 1, "", "project"], [75, 1, 1, "", "rand"], [75, 1, 1, "", "reshape"], [75, 1, 1, "", "sample"], [75, 1, 1, "", "squeeze"], [75, 1, 1, "", "to"], [75, 1, 1, "", "to_numpy"], [75, 1, 1, "", "type_check"], [75, 1, 1, "", "unflatten"], [75, 1, 1, "", "unsqueeze"], [75, 1, 1, "", "view"], [75, 1, 1, "", "zero"], [75, 1, 1, "", "zeros"]], "torchrl.data.UnboundedContinuous": [[76, 1, 1, "", "assert_is_in"], [76, 1, 1, "", "cardinality"], [76, 1, 1, "", "clear_device_"], [76, 1, 1, "", "clone"], [76, 1, 1, "", "contains"], [76, 1, 1, "", "cpu"], [76, 1, 1, "", "cuda"], [76, 2, 1, "", "device"], [76, 1, 1, "", "encode"], [76, 1, 1, "", "enumerate"], [76, 1, 1, "", "erase_memoize_cache"], [76, 1, 1, "", "expand"], [76, 1, 1, "", "flatten"], [76, 1, 1, "", "implements_for_spec"], [76, 1, 1, "", "index"], [76, 1, 1, "", "is_in"], [76, 1, 1, "", "make_neg_dim"], [76, 1, 1, "", "memoize_encode"], [76, 2, 1, "", "ndim"], [76, 1, 1, "", "ndimension"], [76, 1, 1, "", "one"], [76, 1, 1, "", "ones"], [76, 1, 1, "", "project"], [76, 1, 1, "", "rand"], [76, 1, 1, "", "reshape"], [76, 1, 1, "", "sample"], [76, 1, 1, "", "squeeze"], [76, 1, 1, "", "to"], [76, 1, 1, "", "to_numpy"], [76, 1, 1, "", "type_check"], [76, 1, 1, "", "unflatten"], [76, 1, 1, "", "unsqueeze"], [76, 1, 1, "", "view"], [76, 1, 1, "", "zero"], [76, 1, 1, "", "zeros"]], "torchrl.data.UnboundedDiscrete": [[77, 1, 1, "", "assert_is_in"], [77, 1, 1, "", "cardinality"], [77, 1, 1, "", "clear_device_"], [77, 1, 1, "", "clone"], [77, 1, 1, "", "contains"], [77, 1, 1, "", "cpu"], [77, 1, 1, "", "cuda"], [77, 2, 1, "", "device"], [77, 1, 1, "", "encode"], [77, 1, 1, "", "enumerate"], [77, 1, 1, "", "erase_memoize_cache"], [77, 1, 1, "", "expand"], [77, 1, 1, "", "flatten"], [77, 1, 1, "", "implements_for_spec"], [77, 1, 1, "", "index"], [77, 1, 1, "", "is_in"], [77, 1, 1, "", "make_neg_dim"], [77, 1, 1, "", "memoize_encode"], [77, 2, 1, "", "ndim"], [77, 1, 1, "", "ndimension"], [77, 1, 1, "", "one"], [77, 1, 1, "", "ones"], [77, 1, 1, "", "project"], [77, 1, 1, "", "rand"], [77, 1, 1, "", "reshape"], [77, 1, 1, "", "sample"], [77, 1, 1, "", "squeeze"], [77, 1, 1, "", "to"], [77, 1, 1, "", "to_numpy"], [77, 1, 1, "", "type_check"], [77, 1, 1, "", "unflatten"], [77, 1, 1, "", "unsqueeze"], [77, 1, 1, "", "view"], [77, 1, 1, "", "zero"], [77, 1, 1, "", "zeros"]], "torchrl.data.datasets": [[78, 0, 1, "", "AtariDQNExperienceReplay"], [79, 0, 1, "", "D4RLExperienceReplay"], [80, 0, 1, "", "GenDGRLExperienceReplay"], [81, 0, 1, "", "MinariExperienceReplay"], [82, 0, 1, "", "OpenMLExperienceReplay"], [83, 0, 1, "", "OpenXExperienceReplay"], [84, 0, 1, "", "RobosetExperienceReplay"], [85, 0, 1, "", "VD4RLExperienceReplay"]], "torchrl.data.datasets.AtariDQNExperienceReplay": [[78, 1, 1, "", "add"], [78, 1, 1, "", "append_transform"], [78, 1, 1, "", "as_remote"], [78, 2, 1, "", "batch_size"], [78, 2, 1, "", "data_path"], [78, 2, 1, "", "data_path_root"], [78, 1, 1, "", "delete"], [78, 1, 1, "", "dump"], [78, 1, 1, "", "dumps"], [78, 1, 1, "", "empty"], [78, 1, 1, "", "extend"], [78, 2, 1, "", "initialized"], [78, 1, 1, "", "insert_transform"], [78, 1, 1, "", "load"], [78, 1, 1, "", "loads"], [78, 1, 1, "", "next"], [78, 1, 1, "", "preprocess"], [78, 1, 1, "", "register_load_hook"], [78, 1, 1, "", "register_save_hook"], [78, 1, 1, "", "sample"], [78, 2, 1, "", "sampler"], [78, 1, 1, "", "save"], [78, 1, 1, "", "set_sampler"], [78, 1, 1, "", "set_storage"], [78, 1, 1, "", "set_writer"], [78, 2, 1, "", "storage"], [78, 2, 1, "", "transform"], [78, 2, 1, "", "write_count"], [78, 2, 1, "", "writer"]], "torchrl.data.datasets.D4RLExperienceReplay": [[79, 1, 1, "", "add"], [79, 1, 1, "", "append_transform"], [79, 1, 1, "", "as_remote"], [79, 2, 1, "", "batch_size"], [79, 2, 1, "", "data_path"], [79, 2, 1, "", "data_path_root"], [79, 1, 1, "", "delete"], [79, 1, 1, "", "dump"], [79, 1, 1, "", "dumps"], [79, 1, 1, "", "empty"], [79, 1, 1, "", "extend"], [79, 2, 1, "", "initialized"], [79, 1, 1, "", "insert_transform"], [79, 1, 1, "", "load"], [79, 1, 1, "", "loads"], [79, 1, 1, "", "next"], [79, 1, 1, "", "preprocess"], [79, 1, 1, "", "register_load_hook"], [79, 1, 1, "", "register_save_hook"], [79, 1, 1, "", "sample"], [79, 2, 1, "", "sampler"], [79, 1, 1, "", "save"], [79, 1, 1, "", "set_sampler"], [79, 1, 1, "", "set_storage"], [79, 1, 1, "", "set_writer"], [79, 2, 1, "", "storage"], [79, 2, 1, "", "transform"], [79, 2, 1, "", "write_count"], [79, 2, 1, "", "writer"]], "torchrl.data.datasets.GenDGRLExperienceReplay": [[80, 1, 1, "", "add"], [80, 1, 1, "", "append_transform"], [80, 1, 1, "", "as_remote"], [80, 2, 1, "", "batch_size"], [80, 2, 1, "", "data_path"], [80, 2, 1, "", "data_path_root"], [80, 1, 1, "", "delete"], [80, 1, 1, "", "dump"], [80, 1, 1, "", "dumps"], [80, 1, 1, "", "empty"], [80, 1, 1, "", "extend"], [80, 2, 1, "", "initialized"], [80, 1, 1, "", "insert_transform"], [80, 1, 1, "", "load"], [80, 1, 1, "", "loads"], [80, 1, 1, "", "next"], [80, 1, 1, "", "preprocess"], [80, 1, 1, "", "register_load_hook"], [80, 1, 1, "", "register_save_hook"], [80, 1, 1, "", "sample"], [80, 2, 1, "", "sampler"], [80, 1, 1, "", "save"], [80, 1, 1, "", "set_sampler"], [80, 1, 1, "", "set_storage"], [80, 1, 1, "", "set_writer"], [80, 2, 1, "", "storage"], [80, 2, 1, "", "transform"], [80, 2, 1, "", "write_count"], [80, 2, 1, "", "writer"]], "torchrl.data.datasets.MinariExperienceReplay": [[81, 1, 1, "", "add"], [81, 1, 1, "", "append_transform"], [81, 1, 1, "", "as_remote"], [81, 2, 1, "", "batch_size"], [81, 2, 1, "", "data_path"], [81, 2, 1, "", "data_path_root"], [81, 1, 1, "", "delete"], [81, 1, 1, "", "dump"], [81, 1, 1, "", "dumps"], [81, 1, 1, "", "empty"], [81, 1, 1, "", "extend"], [81, 2, 1, "", "initialized"], [81, 1, 1, "", "insert_transform"], [81, 1, 1, "", "load"], [81, 1, 1, "", "loads"], [81, 1, 1, "", "next"], [81, 1, 1, "", "preprocess"], [81, 1, 1, "", "register_load_hook"], [81, 1, 1, "", "register_save_hook"], [81, 1, 1, "", "sample"], [81, 2, 1, "", "sampler"], [81, 1, 1, "", "save"], [81, 1, 1, "", "set_sampler"], [81, 1, 1, "", "set_storage"], [81, 1, 1, "", "set_writer"], [81, 2, 1, "", "storage"], [81, 2, 1, "", "transform"], [81, 2, 1, "", "write_count"], [81, 2, 1, "", "writer"]], "torchrl.data.datasets.OpenMLExperienceReplay": [[82, 1, 1, "", "add"], [82, 1, 1, "", "append_transform"], [82, 1, 1, "", "as_remote"], [82, 2, 1, "", "batch_size"], [82, 2, 1, "", "data_path"], [82, 2, 1, "", "data_path_root"], [82, 1, 1, "", "delete"], [82, 1, 1, "", "dump"], [82, 1, 1, "", "dumps"], [82, 1, 1, "", "empty"], [82, 1, 1, "", "extend"], [82, 2, 1, "", "initialized"], [82, 1, 1, "", "insert_transform"], [82, 1, 1, "", "load"], [82, 1, 1, "", "loads"], [82, 1, 1, "", "next"], [82, 1, 1, "", "preprocess"], [82, 1, 1, "", "register_load_hook"], [82, 1, 1, "", "register_save_hook"], [82, 1, 1, "", "sample"], [82, 2, 1, "", "sampler"], [82, 1, 1, "", "save"], [82, 1, 1, "", "set_sampler"], [82, 1, 1, "", "set_storage"], [82, 1, 1, "", "set_writer"], [82, 2, 1, "", "storage"], [82, 2, 1, "", "transform"], [82, 2, 1, "", "write_count"], [82, 2, 1, "", "writer"]], "torchrl.data.datasets.OpenXExperienceReplay": [[83, 1, 1, "", "add"], [83, 1, 1, "", "append_transform"], [83, 1, 1, "", "as_remote"], [83, 2, 1, "", "batch_size"], [83, 2, 1, "", "data_path"], [83, 2, 1, "", "data_path_root"], [83, 1, 1, "", "delete"], [83, 1, 1, "", "dump"], [83, 1, 1, "", "dumps"], [83, 1, 1, "", "empty"], [83, 1, 1, "", "extend"], [83, 2, 1, "", "initialized"], [83, 1, 1, "", "insert_transform"], [83, 1, 1, "", "load"], [83, 1, 1, "", "loads"], [83, 1, 1, "", "next"], [83, 1, 1, "", "preprocess"], [83, 1, 1, "", "register_load_hook"], [83, 1, 1, "", "register_save_hook"], [83, 1, 1, "", "sample"], [83, 2, 1, "", "sampler"], [83, 1, 1, "", "save"], [83, 1, 1, "", "set_sampler"], [83, 1, 1, "", "set_storage"], [83, 1, 1, "", "set_writer"], [83, 2, 1, "", "storage"], [83, 2, 1, "", "transform"], [83, 2, 1, "", "write_count"], [83, 2, 1, "", "writer"]], "torchrl.data.datasets.RobosetExperienceReplay": [[84, 1, 1, "", "add"], [84, 1, 1, "", "append_transform"], [84, 1, 1, "", "as_remote"], [84, 2, 1, "", "batch_size"], [84, 2, 1, "", "data_path"], [84, 2, 1, "", "data_path_root"], [84, 1, 1, "", "delete"], [84, 1, 1, "", "dump"], [84, 1, 1, "", "dumps"], [84, 1, 1, "", "empty"], [84, 1, 1, "", "extend"], [84, 2, 1, "", "initialized"], [84, 1, 1, "", "insert_transform"], [84, 1, 1, "", "load"], [84, 1, 1, "", "loads"], [84, 1, 1, "", "next"], [84, 1, 1, "", "preprocess"], [84, 1, 1, "", "register_load_hook"], [84, 1, 1, "", "register_save_hook"], [84, 1, 1, "", "sample"], [84, 2, 1, "", "sampler"], [84, 1, 1, "", "save"], [84, 1, 1, "", "set_sampler"], [84, 1, 1, "", "set_storage"], [84, 1, 1, "", "set_writer"], [84, 2, 1, "", "storage"], [84, 2, 1, "", "transform"], [84, 2, 1, "", "write_count"], [84, 2, 1, "", "writer"]], "torchrl.data.datasets.VD4RLExperienceReplay": [[85, 1, 1, "", "add"], [85, 1, 1, "", "append_transform"], [85, 1, 1, "", "as_remote"], [85, 2, 1, "", "batch_size"], [85, 2, 1, "", "data_path"], [85, 2, 1, "", "data_path_root"], [85, 1, 1, "", "delete"], [85, 1, 1, "", "dump"], [85, 1, 1, "", "dumps"], [85, 1, 1, "", "empty"], [85, 1, 1, "", "extend"], [85, 2, 1, "", "initialized"], [85, 1, 1, "", "insert_transform"], [85, 1, 1, "", "load"], [85, 1, 1, "", "loads"], [85, 1, 1, "", "next"], [85, 1, 1, "", "preprocess"], [85, 1, 1, "", "register_load_hook"], [85, 1, 1, "", "register_save_hook"], [85, 1, 1, "", "sample"], [85, 2, 1, "", "sampler"], [85, 1, 1, "", "save"], [85, 1, 1, "", "set_sampler"], [85, 1, 1, "", "set_storage"], [85, 1, 1, "", "set_writer"], [85, 2, 1, "", "storage"], [85, 2, 1, "", "transform"], [85, 2, 1, "", "write_count"], [85, 2, 1, "", "writer"]], "torchrl.data.llm": [[86, 0, 1, "", "ContentBase"], [87, 0, 1, "", "History"], [88, 0, 1, "", "TopKRewardSelector"], [89, 0, 1, "", "add_chat_template"]], "torchrl.data.llm.ContentBase": [[86, 1, 1, "", "cat"], [86, 2, 1, "", "device"], [86, 1, 1, "", "dumps"], [86, 1, 1, "", "fields"], [86, 1, 1, "", "from_any"], [86, 1, 1, "", "from_dataclass"], [86, 1, 1, "", "from_h5"], [86, 1, 1, "", "from_modules"], [86, 1, 1, "", "from_namedtuple"], [86, 1, 1, "", "from_pytree"], [86, 1, 1, "", "from_remote_init"], [86, 1, 1, "", "from_struct_array"], [86, 1, 1, "", "from_tensordict"], [86, 1, 1, "", "from_tuple"], [86, 1, 1, "", "fromkeys"], [86, 1, 1, "", "get"], [86, 1, 1, "", "lazy_stack"], [86, 1, 1, "", "load"], [86, 1, 1, "", "load_"], [86, 1, 1, "", "load_memmap"], [86, 1, 1, "", "load_state_dict"], [86, 1, 1, "", "maybe_dense_stack"], [86, 1, 1, "", "memmap"], [86, 1, 1, "", "memmap_"], [86, 1, 1, "", "memmap_like"], [86, 1, 1, "", "memmap_refresh_"], [86, 1, 1, "", "save"], [86, 1, 1, "", "set"], [86, 1, 1, "", "stack"], [86, 1, 1, "", "state_dict"], [86, 1, 1, "", "to_tensordict"], [86, 1, 1, "", "unbind"]], "torchrl.data.llm.History": [[87, 1, 1, "", "append"], [87, 1, 1, "", "apply_chat_template"], [87, 1, 1, "", "cat"], [87, 1, 1, "", "default_spec"], [87, 2, 1, "", "device"], [87, 1, 1, "", "dumps"], [87, 1, 1, "", "fields"], [87, 1, 1, "", "from_any"], [87, 1, 1, "", "from_chats"], [87, 1, 1, "", "from_dataclass"], [87, 1, 1, "", "from_h5"], [87, 1, 1, "", "from_modules"], [87, 1, 1, "", "from_namedtuple"], [87, 1, 1, "", "from_pytree"], [87, 1, 1, "", "from_remote_init"], [87, 1, 1, "", "from_struct_array"], [87, 1, 1, "", "from_tensordict"], [87, 1, 1, "", "from_text"], [87, 1, 1, "", "from_tuple"], [87, 1, 1, "", "fromkeys"], [87, 1, 1, "", "get"], [87, 1, 1, "", "lazy_stack"], [87, 1, 1, "", "load"], [87, 1, 1, "", "load_"], [87, 1, 1, "", "load_memmap"], [87, 1, 1, "", "load_state_dict"], [87, 1, 1, "", "maybe_dense_stack"], [87, 1, 1, "", "memmap"], [87, 1, 1, "", "memmap_"], [87, 1, 1, "", "memmap_like"], [87, 1, 1, "", "memmap_refresh_"], [87, 1, 1, "", "save"], [87, 1, 1, "", "set"], [87, 1, 1, "", "stack"], [87, 1, 1, "", "state_dict"], [87, 1, 1, "", "to_tensordict"], [87, 1, 1, "", "unbind"]], "torchrl.data.llm.TopKRewardSelector": [[88, 1, 1, "", "add_module"], [88, 1, 1, "", "apply"], [88, 1, 1, "", "bfloat16"], [88, 1, 1, "", "buffers"], [88, 1, 1, "", "children"], [88, 1, 1, "", "close"], [88, 2, 1, "", "collector"], [88, 1, 1, "", "compile"], [88, 2, 1, "", "container"], [88, 1, 1, "", "cpu"], [88, 1, 1, "", "cuda"], [88, 1, 1, "", "double"], [88, 1, 1, "", "eval"], [88, 1, 1, "", "extra_repr"], [88, 1, 1, "", "float"], [88, 1, 1, "", "forward"], [88, 1, 1, "", "get_buffer"], [88, 1, 1, "", "get_extra_state"], [88, 1, 1, "", "get_parameter"], [88, 1, 1, "", "get_submodule"], [88, 1, 1, "", "half"], [88, 1, 1, "", "init"], [88, 1, 1, "", "inv"], [88, 1, 1, "", "ipu"], [88, 1, 1, "", "load_state_dict"], [88, 1, 1, "", "modules"], [88, 1, 1, "", "mtia"], [88, 1, 1, "", "named_buffers"], [88, 1, 1, "", "named_children"], [88, 1, 1, "", "named_modules"], [88, 1, 1, "", "named_parameters"], [88, 1, 1, "", "parameters"], [88, 2, 1, "", "parent"], [88, 1, 1, "", "register_backward_hook"], [88, 1, 1, "", "register_buffer"], [88, 1, 1, "", "register_forward_hook"], [88, 1, 1, "", "register_forward_pre_hook"], [88, 1, 1, "", "register_full_backward_hook"], [88, 1, 1, "", "register_full_backward_pre_hook"], [88, 1, 1, "", "register_load_state_dict_post_hook"], [88, 1, 1, "", "register_load_state_dict_pre_hook"], [88, 1, 1, "", "register_module"], [88, 1, 1, "", "register_parameter"], [88, 1, 1, "", "register_state_dict_post_hook"], [88, 1, 1, "", "register_state_dict_pre_hook"], [88, 1, 1, "", "requires_grad_"], [88, 1, 1, "", "set_extra_state"], [88, 1, 1, "", "set_submodule"], [88, 1, 1, "", "share_memory"], [88, 1, 1, "", "state_dict"], [88, 1, 1, "", "to"], [88, 1, 1, "", "to_empty"], [88, 1, 1, "", "train"], [88, 1, 1, "", "transform_action_spec"], [88, 1, 1, "", "transform_done_spec"], [88, 1, 1, "", "transform_env_batch_size"], [88, 1, 1, "", "transform_env_device"], [88, 1, 1, "", "transform_input_spec"], [88, 1, 1, "", "transform_observation_spec"], [88, 1, 1, "", "transform_output_spec"], [88, 1, 1, "", "transform_reward_spec"], [88, 1, 1, "", "transform_state_spec"], [88, 1, 1, "", "type"], [88, 1, 1, "", "xpu"], [88, 1, 1, "", "zero_grad"]], "torchrl.data.replay_buffers": [[90, 0, 1, "", "CompressedListStorage"], [91, 0, 1, "", "CompressedListStorageCheckpointer"], [92, 0, 1, "", "FlatStorageCheckpointer"], [93, 0, 1, "", "H5StorageCheckpointer"], [94, 0, 1, "", "ImmutableDatasetWriter"], [95, 0, 1, "", "LazyMemmapStorage"], [96, 0, 1, "", "LazyStackStorage"], [97, 0, 1, "", "LazyTensorStorage"], [98, 0, 1, "", "ListStorage"], [99, 0, 1, "", "ListStorageCheckpointer"], [100, 0, 1, "", "NestedStorageCheckpointer"], [101, 0, 1, "", "PrioritizedSampler"], [102, 0, 1, "", "PrioritizedSliceSampler"], [103, 0, 1, "", "RandomSampler"], [104, 0, 1, "", "RoundRobinWriter"], [105, 0, 1, "", "Sampler"], [106, 0, 1, "", "SamplerEnsemble"], [107, 0, 1, "", "SamplerWithoutReplacement"], [108, 0, 1, "", "SliceSampler"], [109, 0, 1, "", "SliceSamplerWithoutReplacement"], [110, 0, 1, "", "Storage"], [111, 0, 1, "", "StorageCheckpointerBase"], [112, 0, 1, "", "StorageEnsemble"], [113, 0, 1, "", "StorageEnsembleCheckpointer"], [114, 0, 1, "", "TensorDictMaxValueWriter"], [115, 0, 1, "", "TensorDictRoundRobinWriter"], [116, 0, 1, "", "TensorStorage"], [117, 0, 1, "", "TensorStorageCheckpointer"], [118, 0, 1, "", "Writer"], [119, 0, 1, "", "WriterEnsemble"]], "torchrl.data.replay_buffers.CompressedListStorage": [[90, 1, 1, "", "attach"], [90, 1, 1, "", "bytes"], [90, 1, 1, "", "dump"], [90, 1, 1, "", "load"], [90, 1, 1, "", "load_state_dict"], [90, 1, 1, "", "save"], [90, 1, 1, "", "state_dict"], [90, 1, 1, "", "to_bytestream"]], "torchrl.data.replay_buffers.CompressedListStorageCheckpointer": [[91, 1, 1, "", "dumps"], [91, 1, 1, "", "loads"]], "torchrl.data.replay_buffers.ImmutableDatasetWriter": [[94, 1, 1, "", "add"], [94, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.LazyMemmapStorage": [[95, 1, 1, "", "attach"], [95, 1, 1, "", "dump"], [95, 1, 1, "", "load"], [95, 1, 1, "", "save"]], "torchrl.data.replay_buffers.LazyStackStorage": [[96, 1, 1, "", "attach"], [96, 1, 1, "", "dump"], [96, 1, 1, "", "load"], [96, 1, 1, "", "save"]], "torchrl.data.replay_buffers.LazyTensorStorage": [[97, 1, 1, "", "attach"], [97, 1, 1, "", "dump"], [97, 1, 1, "", "load"], [97, 1, 1, "", "save"]], "torchrl.data.replay_buffers.ListStorage": [[98, 1, 1, "", "attach"], [98, 1, 1, "", "dump"], [98, 1, 1, "", "load"], [98, 1, 1, "", "save"]], "torchrl.data.replay_buffers.PrioritizedSampler": [[101, 1, 1, "", "update_priority"]], "torchrl.data.replay_buffers.PrioritizedSliceSampler": [[102, 1, 1, "", "update_priority"]], "torchrl.data.replay_buffers.RoundRobinWriter": [[104, 1, 1, "", "add"], [104, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.Storage": [[110, 1, 1, "", "attach"], [110, 1, 1, "", "dump"], [110, 1, 1, "", "load"], [110, 1, 1, "", "save"]], "torchrl.data.replay_buffers.StorageEnsemble": [[112, 1, 1, "", "attach"], [112, 1, 1, "", "dump"], [112, 1, 1, "", "load"], [112, 1, 1, "", "save"]], "torchrl.data.replay_buffers.TensorDictMaxValueWriter": [[114, 1, 1, "", "add"], [114, 1, 1, "", "extend"], [114, 1, 1, "", "get_insert_index"]], "torchrl.data.replay_buffers.TensorDictRoundRobinWriter": [[115, 1, 1, "", "add"], [115, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.TensorStorage": [[116, 1, 1, "", "attach"], [116, 1, 1, "", "dump"], [116, 1, 1, "", "load"], [116, 1, 1, "", "save"]], "torchrl.data.replay_buffers.Writer": [[118, 1, 1, "", "add"], [118, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.WriterEnsemble": [[119, 1, 1, "", "add"], [119, 1, 1, "", "extend"]], "torchrl.envs": [[120, 0, 1, "", "AsyncEnvPool"], [121, 3, 1, "", "BraxEnv"], [122, 3, 1, "", "BraxWrapper"], [123, 0, 1, "", "ChessEnv"], [124, 3, 1, "", "DMControlEnv"], [125, 3, 1, "", "DMControlWrapper"], [126, 0, 1, "", "EnvBase"], [127, 0, 1, "", "EnvCreator"], [128, 0, 1, "", "EnvMetaData"], [129, 3, 1, "", "GymEnv"], [130, 0, 1, "", "GymLikeEnv"], [131, 3, 1, "", "GymWrapper"], [132, 3, 1, "", "HabitatEnv"], [133, 3, 1, "", "IsaacGymEnv"], [134, 3, 1, "", "IsaacGymWrapper"], [135, 3, 1, "", "IsaacLabWrapper"], [136, 3, 1, "", "JumanjiEnv"], [137, 3, 1, "", "JumanjiWrapper"], [138, 0, 1, "", "LLMHashingEnv"], [139, 3, 1, "", "MOGymEnv"], [140, 3, 1, "", "MOGymWrapper"], [141, 3, 1, "", "MarlGroupMapType"], [142, 3, 1, "", "MeltingpotEnv"], [143, 3, 1, "", "MeltingpotWrapper"], [144, 3, 1, "", "ModelBasedEnvBase"], [145, 3, 1, "", "MultiThreadedEnv"], [146, 3, 1, "", "MultiThreadedEnvWrapper"], [147, 3, 1, "", "OpenMLEnv"], [148, 3, 1, "", "OpenSpielEnv"], [149, 3, 1, "", "OpenSpielWrapper"], [150, 0, 1, "", "ParallelEnv"], [151, 0, 1, "", "PendulumEnv"], [152, 3, 1, "", "PettingZooEnv"], [153, 3, 1, "", "PettingZooWrapper"], [154, 0, 1, "", "ProcessorAsyncEnvPool"], [155, 3, 1, "", "RoboHiveEnv"], [156, 3, 1, "", "SMACv2Env"], [157, 3, 1, "", "SMACv2Wrapper"], [158, 0, 1, "", "SerialEnv"], [159, 0, 1, "", "ThreadingAsyncEnvPool"], [160, 0, 1, "", "TicTacToeEnv"], [161, 3, 1, "", "UnityMLAgentsEnv"], [162, 3, 1, "", "UnityMLAgentsWrapper"], [163, 3, 1, "", "VmasEnv"], [164, 3, 1, "", "VmasWrapper"], [165, 3, 1, "", "check_env_specs"], [166, 3, 1, "", "check_marl_grouping"], [167, 3, 1, "", "exploration_type"], [168, 3, 1, "", "get_available_libraries"], [169, 3, 1, "", "gym_backend"], [206, 3, 1, "", "make_composite_from_td"], [144, 1, 1, "", "rand_step"], [209, 3, 1, "", "register_gym_spec_conversion"], [144, 1, 1, "", "reset"], [144, 1, 1, "", "rollout"], [210, 3, 1, "", "set_exploration_type"], [211, 3, 1, "", "set_gym_backend"], [144, 1, 1, "", "set_seed"], [144, 1, 1, "", "step"], [212, 3, 1, "", "step_mdp"], [213, 3, 1, "", "terminated_or_truncated"]], "torchrl.envs.AsyncEnvPool": [[120, 2, 1, "", "action_key"], [120, 2, 1, "", "action_keys"], [120, 2, 1, "", "action_spec"], [120, 2, 1, "", "action_spec_unbatched"], [120, 1, 1, "", "add_module"], [120, 1, 1, "", "add_truncated_keys"], [120, 1, 1, "", "all_actions"], [120, 1, 1, "", "any_done"], [120, 1, 1, "", "append_transform"], [120, 1, 1, "", "apply"], [120, 1, 1, "", "auto_specs_"], [120, 2, 1, "", "batch_dims"], [120, 2, 1, "", "batch_locked"], [120, 2, 1, "", "batch_size"], [120, 1, 1, "", "bfloat16"], [120, 1, 1, "", "buffers"], [120, 1, 1, "", "cardinality"], [120, 1, 1, "", "check_env_specs"], [120, 1, 1, "", "children"], [120, 2, 1, "", "collector"], [120, 1, 1, "", "compile"], [120, 1, 1, "", "cpu"], [120, 1, 1, "", "cuda"], [120, 2, 1, "", "done_key"], [120, 2, 1, "", "done_keys"], [120, 2, 1, "", "done_keys_groups"], [120, 2, 1, "", "done_spec"], [120, 2, 1, "", "done_spec_unbatched"], [120, 1, 1, "", "double"], [120, 1, 1, "", "empty_cache"], [120, 2, 1, "", "env_batch_sizes"], [120, 1, 1, "", "eval"], [120, 1, 1, "", "extra_repr"], [120, 1, 1, "", "fake_tensordict"], [120, 1, 1, "", "float"], [120, 1, 1, "", "forward"], [120, 2, 1, "", "full_action_spec"], [120, 2, 1, "", "full_action_spec_unbatched"], [120, 2, 1, "", "full_done_spec"], [120, 2, 1, "", "full_done_spec_unbatched"], [120, 2, 1, "", "full_observation_spec_unbatched"], [120, 2, 1, "", "full_reward_spec"], [120, 2, 1, "", "full_reward_spec_unbatched"], [120, 2, 1, "", "full_state_spec"], [120, 2, 1, "", "full_state_spec_unbatched"], [120, 1, 1, "", "get_buffer"], [120, 1, 1, "", "get_extra_state"], [120, 1, 1, "", "get_parameter"], [120, 1, 1, "", "get_submodule"], [120, 1, 1, "", "half"], [120, 2, 1, "", "input_spec"], [120, 2, 1, "", "input_spec_unbatched"], [120, 1, 1, "", "ipu"], [120, 2, 1, "", "is_spec_locked"], [120, 1, 1, "", "load_state_dict"], [120, 1, 1, "", "maybe_reset"], [120, 1, 1, "", "modules"], [120, 1, 1, "", "mtia"], [120, 1, 1, "", "named_buffers"], [120, 1, 1, "", "named_children"], [120, 1, 1, "", "named_modules"], [120, 1, 1, "", "named_parameters"], [120, 2, 1, "", "observation_keys"], [120, 2, 1, "", "observation_spec"], [120, 2, 1, "", "observation_spec_unbatched"], [120, 2, 1, "", "output_spec"], [120, 2, 1, "", "output_spec_unbatched"], [120, 1, 1, "", "parameters"], [120, 1, 1, "", "rand_action"], [120, 1, 1, "", "rand_step"], [120, 1, 1, "", "register_backward_hook"], [120, 1, 1, "", "register_buffer"], [120, 1, 1, "", "register_collector"], [120, 1, 1, "", "register_forward_hook"], [120, 1, 1, "", "register_forward_pre_hook"], [120, 1, 1, "", "register_full_backward_hook"], [120, 1, 1, "", "register_full_backward_pre_hook"], [120, 1, 1, "", "register_gym"], [120, 1, 1, "", "register_load_state_dict_post_hook"], [120, 1, 1, "", "register_load_state_dict_pre_hook"], [120, 1, 1, "", "register_module"], [120, 1, 1, "", "register_parameter"], [120, 1, 1, "", "register_state_dict_post_hook"], [120, 1, 1, "", "register_state_dict_pre_hook"], [120, 1, 1, "", "requires_grad_"], [120, 1, 1, "", "reset"], [120, 2, 1, "", "reset_keys"], [120, 2, 1, "", "reward_key"], [120, 2, 1, "", "reward_keys"], [120, 2, 1, "", "reward_spec"], [120, 2, 1, "", "reward_spec_unbatched"], [120, 1, 1, "", "rollout"], [120, 1, 1, "", "set_extra_state"], [120, 1, 1, "", "set_seed"], [120, 1, 1, "", "set_spec_lock_"], [120, 1, 1, "", "set_submodule"], [120, 2, 1, "", "shape"], [120, 1, 1, "", "share_memory"], [120, 2, 1, "", "specs"], [120, 1, 1, "", "state_dict"], [120, 2, 1, "", "state_keys"], [120, 2, 1, "", "state_spec"], [120, 2, 1, "", "state_spec_unbatched"], [120, 1, 1, "", "step"], [120, 1, 1, "", "step_and_maybe_reset"], [120, 1, 1, "", "step_mdp"], [120, 1, 1, "", "to"], [120, 1, 1, "", "to_empty"], [120, 1, 1, "", "train"], [120, 1, 1, "", "type"], [120, 1, 1, "", "xpu"], [120, 1, 1, "", "zero_grad"]], "torchrl.envs.ChessEnv": [[123, 2, 1, "", "action_key"], [123, 2, 1, "", "action_keys"], [123, 2, 1, "", "action_spec"], [123, 2, 1, "", "action_spec_unbatched"], [123, 1, 1, "", "add_module"], [123, 1, 1, "", "add_truncated_keys"], [123, 1, 1, "", "all_actions"], [123, 1, 1, "", "any_done"], [123, 1, 1, "", "append_transform"], [123, 1, 1, "", "apply"], [123, 1, 1, "", "auto_specs_"], [123, 2, 1, "", "batch_dims"], [123, 2, 1, "", "batch_locked"], [123, 2, 1, "", "batch_size"], [123, 1, 1, "", "bfloat16"], [123, 1, 1, "", "buffers"], [123, 1, 1, "", "cardinality"], [123, 1, 1, "", "check_env_specs"], [123, 1, 1, "", "children"], [123, 2, 1, "", "collector"], [123, 1, 1, "", "compile"], [123, 1, 1, "", "cpu"], [123, 1, 1, "", "cuda"], [123, 2, 1, "", "done_key"], [123, 2, 1, "", "done_keys"], [123, 2, 1, "", "done_keys_groups"], [123, 2, 1, "", "done_spec"], [123, 2, 1, "", "done_spec_unbatched"], [123, 1, 1, "", "double"], [123, 1, 1, "", "empty_cache"], [123, 1, 1, "", "eval"], [123, 1, 1, "", "extra_repr"], [123, 1, 1, "", "fake_tensordict"], [123, 1, 1, "", "float"], [123, 1, 1, "", "forward"], [123, 2, 1, "", "full_action_spec"], [123, 2, 1, "", "full_action_spec_unbatched"], [123, 2, 1, "", "full_done_spec"], [123, 2, 1, "", "full_done_spec_unbatched"], [123, 2, 1, "", "full_observation_spec_unbatched"], [123, 2, 1, "", "full_reward_spec"], [123, 2, 1, "", "full_reward_spec_unbatched"], [123, 2, 1, "", "full_state_spec"], [123, 2, 1, "", "full_state_spec_unbatched"], [123, 1, 1, "", "get_buffer"], [123, 1, 1, "", "get_extra_state"], [123, 1, 1, "", "get_legal_moves"], [123, 1, 1, "", "get_parameter"], [123, 1, 1, "", "get_submodule"], [123, 1, 1, "", "half"], [123, 2, 1, "", "input_spec"], [123, 2, 1, "", "input_spec_unbatched"], [123, 1, 1, "", "ipu"], [123, 2, 1, "", "is_spec_locked"], [123, 1, 1, "", "load_state_dict"], [123, 1, 1, "", "maybe_reset"], [123, 1, 1, "", "modules"], [123, 1, 1, "", "mtia"], [123, 1, 1, "", "named_buffers"], [123, 1, 1, "", "named_children"], [123, 1, 1, "", "named_modules"], [123, 1, 1, "", "named_parameters"], [123, 2, 1, "", "observation_keys"], [123, 2, 1, "", "observation_spec"], [123, 2, 1, "", "observation_spec_unbatched"], [123, 2, 1, "", "output_spec"], [123, 2, 1, "", "output_spec_unbatched"], [123, 1, 1, "", "parameters"], [123, 1, 1, "", "rand_action"], [123, 1, 1, "", "rand_step"], [123, 1, 1, "", "register_backward_hook"], [123, 1, 1, "", "register_buffer"], [123, 1, 1, "", "register_collector"], [123, 1, 1, "", "register_forward_hook"], [123, 1, 1, "", "register_forward_pre_hook"], [123, 1, 1, "", "register_full_backward_hook"], [123, 1, 1, "", "register_full_backward_pre_hook"], [123, 1, 1, "", "register_gym"], [123, 1, 1, "", "register_load_state_dict_post_hook"], [123, 1, 1, "", "register_load_state_dict_pre_hook"], [123, 1, 1, "", "register_module"], [123, 1, 1, "", "register_parameter"], [123, 1, 1, "", "register_state_dict_post_hook"], [123, 1, 1, "", "register_state_dict_pre_hook"], [123, 1, 1, "", "requires_grad_"], [123, 1, 1, "", "reset"], [123, 2, 1, "", "reset_keys"], [123, 2, 1, "", "reward_key"], [123, 2, 1, "", "reward_keys"], [123, 2, 1, "", "reward_spec"], [123, 2, 1, "", "reward_spec_unbatched"], [123, 1, 1, "", "rollout"], [123, 1, 1, "", "set_extra_state"], [123, 1, 1, "", "set_seed"], [123, 1, 1, "", "set_spec_lock_"], [123, 1, 1, "", "set_submodule"], [123, 2, 1, "", "shape"], [123, 1, 1, "", "share_memory"], [123, 2, 1, "", "specs"], [123, 1, 1, "", "state_dict"], [123, 2, 1, "", "state_keys"], [123, 2, 1, "", "state_spec"], [123, 2, 1, "", "state_spec_unbatched"], [123, 1, 1, "", "step"], [123, 1, 1, "", "step_and_maybe_reset"], [123, 1, 1, "", "step_mdp"], [123, 1, 1, "", "to"], [123, 1, 1, "", "to_empty"], [123, 1, 1, "", "train"], [123, 1, 1, "", "type"], [123, 1, 1, "", "xpu"], [123, 1, 1, "", "zero_grad"]], "torchrl.envs.EnvBase": [[126, 2, 1, "", "action_key"], [126, 2, 1, "", "action_keys"], [126, 2, 1, "", "action_spec"], [126, 2, 1, "", "action_spec_unbatched"], [126, 1, 1, "", "add_module"], [126, 1, 1, "", "add_truncated_keys"], [126, 1, 1, "", "all_actions"], [126, 1, 1, "", "any_done"], [126, 1, 1, "", "append_transform"], [126, 1, 1, "", "apply"], [126, 1, 1, "", "auto_specs_"], [126, 2, 1, "", "batch_dims"], [126, 2, 1, "", "batch_locked"], [126, 2, 1, "", "batch_size"], [126, 1, 1, "", "bfloat16"], [126, 1, 1, "", "buffers"], [126, 1, 1, "", "cardinality"], [126, 1, 1, "", "check_env_specs"], [126, 1, 1, "", "children"], [126, 2, 1, "", "collector"], [126, 1, 1, "", "compile"], [126, 1, 1, "", "cpu"], [126, 1, 1, "", "cuda"], [126, 2, 1, "", "done_key"], [126, 2, 1, "", "done_keys"], [126, 2, 1, "", "done_keys_groups"], [126, 2, 1, "", "done_spec"], [126, 2, 1, "", "done_spec_unbatched"], [126, 1, 1, "", "double"], [126, 1, 1, "", "empty_cache"], [126, 1, 1, "", "eval"], [126, 1, 1, "", "extra_repr"], [126, 1, 1, "", "fake_tensordict"], [126, 1, 1, "", "float"], [126, 1, 1, "", "forward"], [126, 2, 1, "", "full_action_spec"], [126, 2, 1, "", "full_action_spec_unbatched"], [126, 2, 1, "", "full_done_spec"], [126, 2, 1, "", "full_done_spec_unbatched"], [126, 2, 1, "", "full_observation_spec_unbatched"], [126, 2, 1, "", "full_reward_spec"], [126, 2, 1, "", "full_reward_spec_unbatched"], [126, 2, 1, "", "full_state_spec"], [126, 2, 1, "", "full_state_spec_unbatched"], [126, 1, 1, "", "get_buffer"], [126, 1, 1, "", "get_extra_state"], [126, 1, 1, "", "get_parameter"], [126, 1, 1, "", "get_submodule"], [126, 1, 1, "", "half"], [126, 2, 1, "", "input_spec"], [126, 2, 1, "", "input_spec_unbatched"], [126, 1, 1, "", "ipu"], [126, 2, 1, "", "is_spec_locked"], [126, 1, 1, "", "load_state_dict"], [126, 1, 1, "", "maybe_reset"], [126, 1, 1, "", "modules"], [126, 1, 1, "", "mtia"], [126, 1, 1, "", "named_buffers"], [126, 1, 1, "", "named_children"], [126, 1, 1, "", "named_modules"], [126, 1, 1, "", "named_parameters"], [126, 2, 1, "", "observation_keys"], [126, 2, 1, "", "observation_spec"], [126, 2, 1, "", "observation_spec_unbatched"], [126, 2, 1, "", "output_spec"], [126, 2, 1, "", "output_spec_unbatched"], [126, 1, 1, "", "parameters"], [126, 1, 1, "", "rand_action"], [126, 1, 1, "id0", "rand_step"], [126, 1, 1, "", "register_backward_hook"], [126, 1, 1, "", "register_buffer"], [126, 1, 1, "", "register_collector"], [126, 1, 1, "", "register_forward_hook"], [126, 1, 1, "", "register_forward_pre_hook"], [126, 1, 1, "", "register_full_backward_hook"], [126, 1, 1, "", "register_full_backward_pre_hook"], [126, 1, 1, "", "register_gym"], [126, 1, 1, "", "register_load_state_dict_post_hook"], [126, 1, 1, "", "register_load_state_dict_pre_hook"], [126, 1, 1, "", "register_module"], [126, 1, 1, "", "register_parameter"], [126, 1, 1, "", "register_state_dict_post_hook"], [126, 1, 1, "", "register_state_dict_pre_hook"], [126, 1, 1, "", "requires_grad_"], [126, 1, 1, "id1", "reset"], [126, 2, 1, "", "reset_keys"], [126, 2, 1, "", "reward_key"], [126, 2, 1, "", "reward_keys"], [126, 2, 1, "", "reward_spec"], [126, 2, 1, "", "reward_spec_unbatched"], [126, 1, 1, "id2", "rollout"], [126, 1, 1, "", "set_extra_state"], [126, 1, 1, "id3", "set_seed"], [126, 1, 1, "", "set_spec_lock_"], [126, 1, 1, "", "set_submodule"], [126, 2, 1, "", "shape"], [126, 1, 1, "", "share_memory"], [126, 2, 1, "", "specs"], [126, 1, 1, "", "state_dict"], [126, 2, 1, "", "state_keys"], [126, 2, 1, "", "state_spec"], [126, 2, 1, "", "state_spec_unbatched"], [126, 1, 1, "id4", "step"], [126, 1, 1, "", "step_and_maybe_reset"], [126, 1, 1, "", "step_mdp"], [126, 1, 1, "", "to"], [126, 1, 1, "", "to_empty"], [126, 1, 1, "", "train"], [126, 1, 1, "", "type"], [126, 1, 1, "", "xpu"], [126, 1, 1, "", "zero_grad"]], "torchrl.envs.EnvCreator": [[127, 1, 1, "", "make_variant"]], "torchrl.envs.GymLikeEnv": [[130, 2, 1, "", "action_key"], [130, 2, 1, "", "action_keys"], [130, 2, 1, "", "action_spec"], [130, 2, 1, "", "action_spec_unbatched"], [130, 1, 1, "", "add_module"], [130, 1, 1, "", "add_truncated_keys"], [130, 1, 1, "", "all_actions"], [130, 1, 1, "", "any_done"], [130, 1, 1, "", "append_transform"], [130, 1, 1, "", "apply"], [130, 1, 1, "", "auto_register_info_dict"], [130, 1, 1, "", "auto_specs_"], [130, 2, 1, "", "batch_dims"], [130, 2, 1, "", "batch_locked"], [130, 2, 1, "", "batch_size"], [130, 1, 1, "", "bfloat16"], [130, 1, 1, "", "buffers"], [130, 1, 1, "", "cardinality"], [130, 1, 1, "", "check_env_specs"], [130, 1, 1, "", "children"], [130, 1, 1, "", "close"], [130, 2, 1, "", "collector"], [130, 1, 1, "", "compile"], [130, 1, 1, "", "cpu"], [130, 1, 1, "", "cuda"], [130, 2, 1, "", "done_key"], [130, 2, 1, "", "done_keys"], [130, 2, 1, "", "done_keys_groups"], [130, 2, 1, "", "done_spec"], [130, 2, 1, "", "done_spec_unbatched"], [130, 1, 1, "", "double"], [130, 1, 1, "", "empty_cache"], [130, 1, 1, "", "eval"], [130, 1, 1, "", "extra_repr"], [130, 1, 1, "", "fake_tensordict"], [130, 1, 1, "", "fast_encoding"], [130, 1, 1, "", "float"], [130, 1, 1, "", "forward"], [130, 2, 1, "", "full_action_spec"], [130, 2, 1, "", "full_action_spec_unbatched"], [130, 2, 1, "", "full_done_spec"], [130, 2, 1, "", "full_done_spec_unbatched"], [130, 2, 1, "", "full_observation_spec_unbatched"], [130, 2, 1, "", "full_reward_spec"], [130, 2, 1, "", "full_reward_spec_unbatched"], [130, 2, 1, "", "full_state_spec"], [130, 2, 1, "", "full_state_spec_unbatched"], [130, 1, 1, "", "get_buffer"], [130, 1, 1, "", "get_extra_state"], [130, 1, 1, "", "get_parameter"], [130, 1, 1, "", "get_submodule"], [130, 1, 1, "", "half"], [130, 2, 1, "", "input_spec"], [130, 2, 1, "", "input_spec_unbatched"], [130, 1, 1, "", "ipu"], [130, 2, 1, "", "is_spec_locked"], [130, 1, 1, "", "load_state_dict"], [130, 1, 1, "", "maybe_reset"], [130, 1, 1, "", "modules"], [130, 1, 1, "", "mtia"], [130, 1, 1, "", "named_buffers"], [130, 1, 1, "", "named_children"], [130, 1, 1, "", "named_modules"], [130, 1, 1, "", "named_parameters"], [130, 2, 1, "", "observation_keys"], [130, 2, 1, "", "observation_spec"], [130, 2, 1, "", "observation_spec_unbatched"], [130, 2, 1, "", "output_spec"], [130, 2, 1, "", "output_spec_unbatched"], [130, 1, 1, "", "parameters"], [130, 1, 1, "", "rand_action"], [130, 1, 1, "", "rand_step"], [130, 1, 1, "", "read_action"], [130, 1, 1, "", "read_done"], [130, 1, 1, "", "read_obs"], [130, 1, 1, "", "read_reward"], [130, 1, 1, "", "register_backward_hook"], [130, 1, 1, "", "register_buffer"], [130, 1, 1, "", "register_collector"], [130, 1, 1, "", "register_forward_hook"], [130, 1, 1, "", "register_forward_pre_hook"], [130, 1, 1, "", "register_full_backward_hook"], [130, 1, 1, "", "register_full_backward_pre_hook"], [130, 1, 1, "", "register_gym"], [130, 1, 1, "", "register_load_state_dict_post_hook"], [130, 1, 1, "", "register_load_state_dict_pre_hook"], [130, 1, 1, "", "register_module"], [130, 1, 1, "", "register_parameter"], [130, 1, 1, "", "register_state_dict_post_hook"], [130, 1, 1, "", "register_state_dict_pre_hook"], [130, 1, 1, "", "requires_grad_"], [130, 1, 1, "", "reset"], [130, 2, 1, "", "reset_keys"], [130, 2, 1, "", "reward_key"], [130, 2, 1, "", "reward_keys"], [130, 2, 1, "", "reward_spec"], [130, 2, 1, "", "reward_spec_unbatched"], [130, 1, 1, "", "rollout"], [130, 1, 1, "", "set_extra_state"], [130, 1, 1, "", "set_info_dict_reader"], [130, 1, 1, "", "set_seed"], [130, 1, 1, "", "set_spec_lock_"], [130, 1, 1, "", "set_submodule"], [130, 2, 1, "", "shape"], [130, 1, 1, "", "share_memory"], [130, 2, 1, "", "specs"], [130, 1, 1, "", "state_dict"], [130, 2, 1, "", "state_keys"], [130, 2, 1, "", "state_spec"], [130, 2, 1, "", "state_spec_unbatched"], [130, 1, 1, "", "step"], [130, 1, 1, "", "step_and_maybe_reset"], [130, 1, 1, "", "step_mdp"], [130, 1, 1, "", "to"], [130, 1, 1, "", "to_empty"], [130, 1, 1, "", "train"], [130, 1, 1, "", "type"], [130, 1, 1, "", "xpu"], [130, 1, 1, "", "zero_grad"]], "torchrl.envs.LLMHashingEnv": [[138, 2, 1, "", "action_key"], [138, 2, 1, "", "action_keys"], [138, 2, 1, "", "action_spec"], [138, 2, 1, "", "action_spec_unbatched"], [138, 1, 1, "", "add_module"], [138, 1, 1, "", "add_truncated_keys"], [138, 1, 1, "", "all_actions"], [138, 1, 1, "", "any_done"], [138, 1, 1, "", "append_transform"], [138, 1, 1, "", "apply"], [138, 1, 1, "", "auto_specs_"], [138, 2, 1, "", "batch_dims"], [138, 2, 1, "", "batch_locked"], [138, 2, 1, "", "batch_size"], [138, 1, 1, "", "bfloat16"], [138, 1, 1, "", "buffers"], [138, 1, 1, "", "cardinality"], [138, 1, 1, "", "check_env_specs"], [138, 1, 1, "", "children"], [138, 2, 1, "", "collector"], [138, 1, 1, "", "compile"], [138, 1, 1, "", "cpu"], [138, 1, 1, "", "cuda"], [138, 2, 1, "", "done_key"], [138, 2, 1, "", "done_keys"], [138, 2, 1, "", "done_keys_groups"], [138, 2, 1, "", "done_spec"], [138, 2, 1, "", "done_spec_unbatched"], [138, 1, 1, "", "double"], [138, 1, 1, "", "empty_cache"], [138, 1, 1, "", "eval"], [138, 1, 1, "", "extra_repr"], [138, 1, 1, "", "fake_tensordict"], [138, 1, 1, "", "float"], [138, 1, 1, "", "forward"], [138, 2, 1, "", "full_action_spec"], [138, 2, 1, "", "full_action_spec_unbatched"], [138, 2, 1, "", "full_done_spec"], [138, 2, 1, "", "full_done_spec_unbatched"], [138, 2, 1, "", "full_observation_spec_unbatched"], [138, 2, 1, "", "full_reward_spec"], [138, 2, 1, "", "full_reward_spec_unbatched"], [138, 2, 1, "", "full_state_spec"], [138, 2, 1, "", "full_state_spec_unbatched"], [138, 1, 1, "", "get_buffer"], [138, 1, 1, "", "get_extra_state"], [138, 1, 1, "", "get_parameter"], [138, 1, 1, "", "get_submodule"], [138, 1, 1, "", "half"], [138, 2, 1, "", "input_spec"], [138, 2, 1, "", "input_spec_unbatched"], [138, 1, 1, "", "ipu"], [138, 2, 1, "", "is_spec_locked"], [138, 1, 1, "", "load_state_dict"], [138, 1, 1, "", "make_tensordict"], [138, 1, 1, "", "maybe_reset"], [138, 1, 1, "", "modules"], [138, 1, 1, "", "mtia"], [138, 1, 1, "", "named_buffers"], [138, 1, 1, "", "named_children"], [138, 1, 1, "", "named_modules"], [138, 1, 1, "", "named_parameters"], [138, 2, 1, "", "observation_keys"], [138, 2, 1, "", "observation_spec"], [138, 2, 1, "", "observation_spec_unbatched"], [138, 2, 1, "", "output_spec"], [138, 2, 1, "", "output_spec_unbatched"], [138, 1, 1, "", "parameters"], [138, 1, 1, "", "rand_action"], [138, 1, 1, "", "rand_step"], [138, 1, 1, "", "register_backward_hook"], [138, 1, 1, "", "register_buffer"], [138, 1, 1, "", "register_collector"], [138, 1, 1, "", "register_forward_hook"], [138, 1, 1, "", "register_forward_pre_hook"], [138, 1, 1, "", "register_full_backward_hook"], [138, 1, 1, "", "register_full_backward_pre_hook"], [138, 1, 1, "", "register_gym"], [138, 1, 1, "", "register_load_state_dict_post_hook"], [138, 1, 1, "", "register_load_state_dict_pre_hook"], [138, 1, 1, "", "register_module"], [138, 1, 1, "", "register_parameter"], [138, 1, 1, "", "register_state_dict_post_hook"], [138, 1, 1, "", "register_state_dict_pre_hook"], [138, 1, 1, "", "requires_grad_"], [138, 1, 1, "", "reset"], [138, 2, 1, "", "reset_keys"], [138, 2, 1, "", "reward_key"], [138, 2, 1, "", "reward_keys"], [138, 2, 1, "", "reward_spec"], [138, 2, 1, "", "reward_spec_unbatched"], [138, 1, 1, "", "rollout"], [138, 1, 1, "", "set_extra_state"], [138, 1, 1, "", "set_seed"], [138, 1, 1, "", "set_spec_lock_"], [138, 1, 1, "", "set_submodule"], [138, 2, 1, "", "shape"], [138, 1, 1, "", "share_memory"], [138, 2, 1, "", "specs"], [138, 1, 1, "", "state_dict"], [138, 2, 1, "", "state_keys"], [138, 2, 1, "", "state_spec"], [138, 2, 1, "", "state_spec_unbatched"], [138, 1, 1, "", "step"], [138, 1, 1, "", "step_and_maybe_reset"], [138, 1, 1, "", "step_mdp"], [138, 1, 1, "", "to"], [138, 1, 1, "", "to_empty"], [138, 1, 1, "", "train"], [138, 1, 1, "", "type"], [138, 1, 1, "", "xpu"], [138, 1, 1, "", "zero_grad"]], "torchrl.envs.ParallelEnv": [[150, 2, 1, "", "action_key"], [150, 2, 1, "", "action_keys"], [150, 2, 1, "", "action_spec"], [150, 2, 1, "", "action_spec_unbatched"], [150, 1, 1, "", "add_module"], [150, 1, 1, "", "add_truncated_keys"], [150, 1, 1, "", "all_actions"], [150, 1, 1, "", "any_done"], [150, 1, 1, "", "append_transform"], [150, 1, 1, "", "apply"], [150, 1, 1, "", "auto_specs_"], [150, 2, 1, "", "batch_dims"], [150, 2, 1, "", "batch_locked"], [150, 2, 1, "", "batch_size"], [150, 1, 1, "", "bfloat16"], [150, 1, 1, "", "buffers"], [150, 1, 1, "", "cardinality"], [150, 1, 1, "", "check_env_specs"], [150, 1, 1, "", "children"], [150, 2, 1, "", "collector"], [150, 1, 1, "", "compile"], [150, 1, 1, "", "cpu"], [150, 1, 1, "", "cuda"], [150, 2, 1, "", "done_key"], [150, 2, 1, "", "done_keys"], [150, 2, 1, "", "done_keys_groups"], [150, 2, 1, "", "done_spec"], [150, 2, 1, "", "done_spec_unbatched"], [150, 1, 1, "", "double"], [150, 1, 1, "", "empty_cache"], [150, 1, 1, "", "eval"], [150, 1, 1, "", "extra_repr"], [150, 1, 1, "", "fake_tensordict"], [150, 1, 1, "", "float"], [150, 1, 1, "", "forward"], [150, 2, 1, "", "full_action_spec"], [150, 2, 1, "", "full_action_spec_unbatched"], [150, 2, 1, "", "full_done_spec"], [150, 2, 1, "", "full_done_spec_unbatched"], [150, 2, 1, "", "full_observation_spec_unbatched"], [150, 2, 1, "", "full_reward_spec"], [150, 2, 1, "", "full_reward_spec_unbatched"], [150, 2, 1, "", "full_state_spec"], [150, 2, 1, "", "full_state_spec_unbatched"], [150, 1, 1, "", "get_buffer"], [150, 1, 1, "", "get_extra_state"], [150, 1, 1, "", "get_parameter"], [150, 1, 1, "", "get_submodule"], [150, 1, 1, "", "half"], [150, 2, 1, "", "input_spec"], [150, 2, 1, "", "input_spec_unbatched"], [150, 1, 1, "", "ipu"], [150, 2, 1, "", "is_spec_locked"], [150, 1, 1, "", "load_state_dict"], [150, 1, 1, "", "maybe_reset"], [150, 1, 1, "", "modules"], [150, 1, 1, "", "mtia"], [150, 1, 1, "", "named_buffers"], [150, 1, 1, "", "named_children"], [150, 1, 1, "", "named_modules"], [150, 1, 1, "", "named_parameters"], [150, 2, 1, "", "observation_keys"], [150, 2, 1, "", "observation_spec"], [150, 2, 1, "", "observation_spec_unbatched"], [150, 2, 1, "", "output_spec"], [150, 2, 1, "", "output_spec_unbatched"], [150, 1, 1, "", "parameters"], [150, 1, 1, "", "rand_action"], [150, 1, 1, "", "rand_step"], [150, 1, 1, "", "register_backward_hook"], [150, 1, 1, "", "register_buffer"], [150, 1, 1, "", "register_collector"], [150, 1, 1, "", "register_forward_hook"], [150, 1, 1, "", "register_forward_pre_hook"], [150, 1, 1, "", "register_full_backward_hook"], [150, 1, 1, "", "register_full_backward_pre_hook"], [150, 1, 1, "", "register_gym"], [150, 1, 1, "", "register_load_state_dict_post_hook"], [150, 1, 1, "", "register_load_state_dict_pre_hook"], [150, 1, 1, "", "register_module"], [150, 1, 1, "", "register_parameter"], [150, 1, 1, "", "register_state_dict_post_hook"], [150, 1, 1, "", "register_state_dict_pre_hook"], [150, 1, 1, "", "requires_grad_"], [150, 1, 1, "", "reset"], [150, 2, 1, "", "reset_keys"], [150, 2, 1, "", "reward_key"], [150, 2, 1, "", "reward_keys"], [150, 2, 1, "", "reward_spec"], [150, 2, 1, "", "reward_spec_unbatched"], [150, 1, 1, "", "rollout"], [150, 1, 1, "", "set_extra_state"], [150, 1, 1, "", "set_seed"], [150, 1, 1, "", "set_spec_lock_"], [150, 1, 1, "", "set_submodule"], [150, 2, 1, "", "shape"], [150, 1, 1, "", "share_memory"], [150, 2, 1, "", "specs"], [150, 1, 1, "", "state_dict"], [150, 2, 1, "", "state_keys"], [150, 2, 1, "", "state_spec"], [150, 2, 1, "", "state_spec_unbatched"], [150, 1, 1, "", "step"], [150, 1, 1, "", "step_and_maybe_reset"], [150, 1, 1, "", "step_mdp"], [150, 1, 1, "", "to"], [150, 1, 1, "", "to_empty"], [150, 1, 1, "", "train"], [150, 1, 1, "", "type"], [150, 1, 1, "", "update_kwargs"], [150, 1, 1, "", "xpu"], [150, 1, 1, "", "zero_grad"]], "torchrl.envs.PendulumEnv": [[151, 2, 1, "", "action_key"], [151, 2, 1, "", "action_keys"], [151, 2, 1, "", "action_spec"], [151, 2, 1, "", "action_spec_unbatched"], [151, 1, 1, "", "add_module"], [151, 1, 1, "", "add_truncated_keys"], [151, 1, 1, "", "all_actions"], [151, 1, 1, "", "any_done"], [151, 1, 1, "", "append_transform"], [151, 1, 1, "", "apply"], [151, 1, 1, "", "auto_specs_"], [151, 2, 1, "", "batch_dims"], [151, 2, 1, "", "batch_size"], [151, 1, 1, "", "bfloat16"], [151, 1, 1, "", "buffers"], [151, 1, 1, "", "cardinality"], [151, 1, 1, "", "check_env_specs"], [151, 1, 1, "", "children"], [151, 2, 1, "", "collector"], [151, 1, 1, "", "compile"], [151, 1, 1, "", "cpu"], [151, 1, 1, "", "cuda"], [151, 2, 1, "", "done_key"], [151, 2, 1, "", "done_keys"], [151, 2, 1, "", "done_keys_groups"], [151, 2, 1, "", "done_spec"], [151, 2, 1, "", "done_spec_unbatched"], [151, 1, 1, "", "double"], [151, 1, 1, "", "empty_cache"], [151, 1, 1, "", "eval"], [151, 1, 1, "", "extra_repr"], [151, 1, 1, "", "fake_tensordict"], [151, 1, 1, "", "float"], [151, 1, 1, "", "forward"], [151, 2, 1, "", "full_action_spec"], [151, 2, 1, "", "full_action_spec_unbatched"], [151, 2, 1, "", "full_done_spec"], [151, 2, 1, "", "full_done_spec_unbatched"], [151, 2, 1, "", "full_observation_spec_unbatched"], [151, 2, 1, "", "full_reward_spec"], [151, 2, 1, "", "full_reward_spec_unbatched"], [151, 2, 1, "", "full_state_spec"], [151, 2, 1, "", "full_state_spec_unbatched"], [151, 1, 1, "", "gen_params"], [151, 1, 1, "", "get_buffer"], [151, 1, 1, "", "get_extra_state"], [151, 1, 1, "", "get_parameter"], [151, 1, 1, "", "get_submodule"], [151, 1, 1, "", "half"], [151, 2, 1, "", "input_spec"], [151, 2, 1, "", "input_spec_unbatched"], [151, 1, 1, "", "ipu"], [151, 2, 1, "", "is_spec_locked"], [151, 1, 1, "", "load_state_dict"], [151, 1, 1, "", "maybe_reset"], [151, 1, 1, "", "modules"], [151, 1, 1, "", "mtia"], [151, 1, 1, "", "named_buffers"], [151, 1, 1, "", "named_children"], [151, 1, 1, "", "named_modules"], [151, 1, 1, "", "named_parameters"], [151, 2, 1, "", "observation_keys"], [151, 2, 1, "", "observation_spec"], [151, 2, 1, "", "observation_spec_unbatched"], [151, 2, 1, "", "output_spec"], [151, 2, 1, "", "output_spec_unbatched"], [151, 1, 1, "", "parameters"], [151, 1, 1, "", "rand_action"], [151, 1, 1, "", "rand_step"], [151, 1, 1, "", "register_backward_hook"], [151, 1, 1, "", "register_buffer"], [151, 1, 1, "", "register_collector"], [151, 1, 1, "", "register_forward_hook"], [151, 1, 1, "", "register_forward_pre_hook"], [151, 1, 1, "", "register_full_backward_hook"], [151, 1, 1, "", "register_full_backward_pre_hook"], [151, 1, 1, "", "register_gym"], [151, 1, 1, "", "register_load_state_dict_post_hook"], [151, 1, 1, "", "register_load_state_dict_pre_hook"], [151, 1, 1, "", "register_module"], [151, 1, 1, "", "register_parameter"], [151, 1, 1, "", "register_state_dict_post_hook"], [151, 1, 1, "", "register_state_dict_pre_hook"], [151, 1, 1, "", "requires_grad_"], [151, 1, 1, "", "reset"], [151, 2, 1, "", "reset_keys"], [151, 2, 1, "", "reward_key"], [151, 2, 1, "", "reward_keys"], [151, 2, 1, "", "reward_spec"], [151, 2, 1, "", "reward_spec_unbatched"], [151, 1, 1, "", "rollout"], [151, 1, 1, "", "set_extra_state"], [151, 1, 1, "", "set_seed"], [151, 1, 1, "", "set_spec_lock_"], [151, 1, 1, "", "set_submodule"], [151, 2, 1, "", "shape"], [151, 1, 1, "", "share_memory"], [151, 2, 1, "", "specs"], [151, 1, 1, "", "state_dict"], [151, 2, 1, "", "state_keys"], [151, 2, 1, "", "state_spec"], [151, 2, 1, "", "state_spec_unbatched"], [151, 1, 1, "", "step"], [151, 1, 1, "", "step_and_maybe_reset"], [151, 1, 1, "", "step_mdp"], [151, 1, 1, "", "to"], [151, 1, 1, "", "to_empty"], [151, 1, 1, "", "train"], [151, 1, 1, "", "type"], [151, 1, 1, "", "xpu"], [151, 1, 1, "", "zero_grad"]], "torchrl.envs.ProcessorAsyncEnvPool": [[154, 1, 1, "", "_setup"], [154, 2, 1, "", "action_key"], [154, 2, 1, "", "action_keys"], [154, 2, 1, "", "action_spec"], [154, 2, 1, "", "action_spec_unbatched"], [154, 1, 1, "", "add_module"], [154, 1, 1, "", "add_truncated_keys"], [154, 1, 1, "", "all_actions"], [154, 1, 1, "", "any_done"], [154, 1, 1, "", "append_transform"], [154, 1, 1, "", "apply"], [154, 1, 1, "", "async_reset_recv"], [154, 1, 1, "", "async_reset_send"], [154, 1, 1, "", "async_step_recv"], [154, 1, 1, "", "async_step_send"], [154, 1, 1, "", "auto_specs_"], [154, 2, 1, "", "batch_dims"], [154, 2, 1, "", "batch_locked"], [154, 2, 1, "", "batch_size"], [154, 1, 1, "", "bfloat16"], [154, 1, 1, "", "buffers"], [154, 1, 1, "", "cardinality"], [154, 1, 1, "", "check_env_specs"], [154, 1, 1, "", "children"], [154, 2, 1, "", "collector"], [154, 1, 1, "", "compile"], [154, 1, 1, "", "cpu"], [154, 1, 1, "", "cuda"], [154, 2, 1, "", "done_key"], [154, 2, 1, "", "done_keys"], [154, 2, 1, "", "done_keys_groups"], [154, 2, 1, "", "done_spec"], [154, 2, 1, "", "done_spec_unbatched"], [154, 1, 1, "", "double"], [154, 1, 1, "", "empty_cache"], [154, 2, 1, "", "env_batch_sizes"], [154, 1, 1, "", "eval"], [154, 1, 1, "", "extra_repr"], [154, 1, 1, "", "fake_tensordict"], [154, 1, 1, "", "float"], [154, 1, 1, "", "forward"], [154, 2, 1, "", "full_action_spec"], [154, 2, 1, "", "full_action_spec_unbatched"], [154, 2, 1, "", "full_done_spec"], [154, 2, 1, "", "full_done_spec_unbatched"], [154, 2, 1, "", "full_observation_spec_unbatched"], [154, 2, 1, "", "full_reward_spec"], [154, 2, 1, "", "full_reward_spec_unbatched"], [154, 2, 1, "", "full_state_spec"], [154, 2, 1, "", "full_state_spec_unbatched"], [154, 1, 1, "", "get_buffer"], [154, 1, 1, "", "get_extra_state"], [154, 1, 1, "", "get_parameter"], [154, 1, 1, "", "get_submodule"], [154, 1, 1, "", "half"], [154, 2, 1, "", "input_spec"], [154, 2, 1, "", "input_spec_unbatched"], [154, 1, 1, "", "ipu"], [154, 2, 1, "", "is_spec_locked"], [154, 1, 1, "", "load_state_dict"], [154, 1, 1, "", "maybe_reset"], [154, 1, 1, "", "modules"], [154, 1, 1, "", "mtia"], [154, 1, 1, "", "named_buffers"], [154, 1, 1, "", "named_children"], [154, 1, 1, "", "named_modules"], [154, 1, 1, "", "named_parameters"], [154, 2, 1, "", "observation_keys"], [154, 2, 1, "", "observation_spec"], [154, 2, 1, "", "observation_spec_unbatched"], [154, 2, 1, "", "output_spec"], [154, 2, 1, "", "output_spec_unbatched"], [154, 1, 1, "", "parameters"], [154, 1, 1, "", "rand_action"], [154, 1, 1, "", "rand_step"], [154, 1, 1, "", "register_backward_hook"], [154, 1, 1, "", "register_buffer"], [154, 1, 1, "", "register_collector"], [154, 1, 1, "", "register_forward_hook"], [154, 1, 1, "", "register_forward_pre_hook"], [154, 1, 1, "", "register_full_backward_hook"], [154, 1, 1, "", "register_full_backward_pre_hook"], [154, 1, 1, "", "register_gym"], [154, 1, 1, "", "register_load_state_dict_post_hook"], [154, 1, 1, "", "register_load_state_dict_pre_hook"], [154, 1, 1, "", "register_module"], [154, 1, 1, "", "register_parameter"], [154, 1, 1, "", "register_state_dict_post_hook"], [154, 1, 1, "", "register_state_dict_pre_hook"], [154, 1, 1, "", "requires_grad_"], [154, 1, 1, "", "reset"], [154, 2, 1, "", "reset_keys"], [154, 2, 1, "", "reward_key"], [154, 2, 1, "", "reward_keys"], [154, 2, 1, "", "reward_spec"], [154, 2, 1, "", "reward_spec_unbatched"], [154, 1, 1, "", "rollout"], [154, 1, 1, "", "set_extra_state"], [154, 1, 1, "", "set_seed"], [154, 1, 1, "", "set_spec_lock_"], [154, 1, 1, "", "set_submodule"], [154, 2, 1, "", "shape"], [154, 1, 1, "", "share_memory"], [154, 1, 1, "", "shutdown"], [154, 2, 1, "", "specs"], [154, 1, 1, "", "state_dict"], [154, 2, 1, "", "state_keys"], [154, 2, 1, "", "state_spec"], [154, 2, 1, "", "state_spec_unbatched"], [154, 1, 1, "", "step"], [154, 1, 1, "", "step_and_maybe_reset"], [154, 1, 1, "", "step_mdp"], [154, 1, 1, "", "to"], [154, 1, 1, "", "to_empty"], [154, 1, 1, "", "train"], [154, 1, 1, "", "type"], [154, 1, 1, "", "xpu"], [154, 1, 1, "", "zero_grad"]], "torchrl.envs.SerialEnv": [[158, 2, 1, "", "action_key"], [158, 2, 1, "", "action_keys"], [158, 2, 1, "", "action_spec"], [158, 2, 1, "", "action_spec_unbatched"], [158, 1, 1, "", "add_module"], [158, 1, 1, "", "add_truncated_keys"], [158, 1, 1, "", "all_actions"], [158, 1, 1, "", "any_done"], [158, 1, 1, "", "append_transform"], [158, 1, 1, "", "apply"], [158, 1, 1, "", "auto_specs_"], [158, 2, 1, "", "batch_dims"], [158, 2, 1, "", "batch_locked"], [158, 2, 1, "", "batch_size"], [158, 1, 1, "", "bfloat16"], [158, 1, 1, "", "buffers"], [158, 1, 1, "", "cardinality"], [158, 1, 1, "", "check_env_specs"], [158, 1, 1, "", "children"], [158, 2, 1, "", "collector"], [158, 1, 1, "", "compile"], [158, 1, 1, "", "cpu"], [158, 1, 1, "", "cuda"], [158, 2, 1, "", "done_key"], [158, 2, 1, "", "done_keys"], [158, 2, 1, "", "done_keys_groups"], [158, 2, 1, "", "done_spec"], [158, 2, 1, "", "done_spec_unbatched"], [158, 1, 1, "", "double"], [158, 1, 1, "", "empty_cache"], [158, 1, 1, "", "eval"], [158, 1, 1, "", "extra_repr"], [158, 1, 1, "", "fake_tensordict"], [158, 1, 1, "", "float"], [158, 1, 1, "", "forward"], [158, 2, 1, "", "full_action_spec"], [158, 2, 1, "", "full_action_spec_unbatched"], [158, 2, 1, "", "full_done_spec"], [158, 2, 1, "", "full_done_spec_unbatched"], [158, 2, 1, "", "full_observation_spec_unbatched"], [158, 2, 1, "", "full_reward_spec"], [158, 2, 1, "", "full_reward_spec_unbatched"], [158, 2, 1, "", "full_state_spec"], [158, 2, 1, "", "full_state_spec_unbatched"], [158, 1, 1, "", "get_buffer"], [158, 1, 1, "", "get_extra_state"], [158, 1, 1, "", "get_parameter"], [158, 1, 1, "", "get_submodule"], [158, 1, 1, "", "half"], [158, 2, 1, "", "input_spec"], [158, 2, 1, "", "input_spec_unbatched"], [158, 1, 1, "", "ipu"], [158, 2, 1, "", "is_spec_locked"], [158, 1, 1, "", "load_state_dict"], [158, 1, 1, "", "maybe_reset"], [158, 1, 1, "", "modules"], [158, 1, 1, "", "mtia"], [158, 1, 1, "", "named_buffers"], [158, 1, 1, "", "named_children"], [158, 1, 1, "", "named_modules"], [158, 1, 1, "", "named_parameters"], [158, 2, 1, "", "observation_keys"], [158, 2, 1, "", "observation_spec"], [158, 2, 1, "", "observation_spec_unbatched"], [158, 2, 1, "", "output_spec"], [158, 2, 1, "", "output_spec_unbatched"], [158, 1, 1, "", "parameters"], [158, 1, 1, "", "rand_action"], [158, 1, 1, "", "rand_step"], [158, 1, 1, "", "register_backward_hook"], [158, 1, 1, "", "register_buffer"], [158, 1, 1, "", "register_collector"], [158, 1, 1, "", "register_forward_hook"], [158, 1, 1, "", "register_forward_pre_hook"], [158, 1, 1, "", "register_full_backward_hook"], [158, 1, 1, "", "register_full_backward_pre_hook"], [158, 1, 1, "", "register_gym"], [158, 1, 1, "", "register_load_state_dict_post_hook"], [158, 1, 1, "", "register_load_state_dict_pre_hook"], [158, 1, 1, "", "register_module"], [158, 1, 1, "", "register_parameter"], [158, 1, 1, "", "register_state_dict_post_hook"], [158, 1, 1, "", "register_state_dict_pre_hook"], [158, 1, 1, "", "requires_grad_"], [158, 1, 1, "", "reset"], [158, 2, 1, "", "reset_keys"], [158, 2, 1, "", "reward_key"], [158, 2, 1, "", "reward_keys"], [158, 2, 1, "", "reward_spec"], [158, 2, 1, "", "reward_spec_unbatched"], [158, 1, 1, "", "rollout"], [158, 1, 1, "", "set_extra_state"], [158, 1, 1, "", "set_seed"], [158, 1, 1, "", "set_spec_lock_"], [158, 1, 1, "", "set_submodule"], [158, 2, 1, "", "shape"], [158, 1, 1, "", "share_memory"], [158, 2, 1, "", "specs"], [158, 1, 1, "", "state_dict"], [158, 2, 1, "", "state_keys"], [158, 2, 1, "", "state_spec"], [158, 2, 1, "", "state_spec_unbatched"], [158, 1, 1, "", "step"], [158, 1, 1, "", "step_and_maybe_reset"], [158, 1, 1, "", "step_mdp"], [158, 1, 1, "", "to"], [158, 1, 1, "", "to_empty"], [158, 1, 1, "", "train"], [158, 1, 1, "", "type"], [158, 1, 1, "", "update_kwargs"], [158, 1, 1, "", "xpu"], [158, 1, 1, "", "zero_grad"]], "torchrl.envs.ThreadingAsyncEnvPool": [[159, 1, 1, "", "_setup"], [159, 2, 1, "", "action_key"], [159, 2, 1, "", "action_keys"], [159, 2, 1, "", "action_spec"], [159, 2, 1, "", "action_spec_unbatched"], [159, 1, 1, "", "add_module"], [159, 1, 1, "", "add_truncated_keys"], [159, 1, 1, "", "all_actions"], [159, 1, 1, "", "any_done"], [159, 1, 1, "", "append_transform"], [159, 1, 1, "", "apply"], [159, 1, 1, "", "async_reset_recv"], [159, 1, 1, "", "async_reset_send"], [159, 1, 1, "", "async_step_recv"], [159, 1, 1, "", "async_step_send"], [159, 1, 1, "", "auto_specs_"], [159, 2, 1, "", "batch_dims"], [159, 2, 1, "", "batch_locked"], [159, 2, 1, "", "batch_size"], [159, 1, 1, "", "bfloat16"], [159, 1, 1, "", "buffers"], [159, 1, 1, "", "cardinality"], [159, 1, 1, "", "check_env_specs"], [159, 1, 1, "", "children"], [159, 2, 1, "", "collector"], [159, 1, 1, "", "compile"], [159, 1, 1, "", "cpu"], [159, 1, 1, "", "cuda"], [159, 2, 1, "", "done_key"], [159, 2, 1, "", "done_keys"], [159, 2, 1, "", "done_keys_groups"], [159, 2, 1, "", "done_spec"], [159, 2, 1, "", "done_spec_unbatched"], [159, 1, 1, "", "double"], [159, 1, 1, "", "empty_cache"], [159, 2, 1, "", "env_batch_sizes"], [159, 1, 1, "", "eval"], [159, 1, 1, "", "extra_repr"], [159, 1, 1, "", "fake_tensordict"], [159, 1, 1, "", "float"], [159, 1, 1, "", "forward"], [159, 2, 1, "", "full_action_spec"], [159, 2, 1, "", "full_action_spec_unbatched"], [159, 2, 1, "", "full_done_spec"], [159, 2, 1, "", "full_done_spec_unbatched"], [159, 2, 1, "", "full_observation_spec_unbatched"], [159, 2, 1, "", "full_reward_spec"], [159, 2, 1, "", "full_reward_spec_unbatched"], [159, 2, 1, "", "full_state_spec"], [159, 2, 1, "", "full_state_spec_unbatched"], [159, 1, 1, "", "get_buffer"], [159, 1, 1, "", "get_extra_state"], [159, 1, 1, "", "get_parameter"], [159, 1, 1, "", "get_submodule"], [159, 1, 1, "", "half"], [159, 2, 1, "", "input_spec"], [159, 2, 1, "", "input_spec_unbatched"], [159, 1, 1, "", "ipu"], [159, 2, 1, "", "is_spec_locked"], [159, 1, 1, "", "load_state_dict"], [159, 1, 1, "", "maybe_reset"], [159, 1, 1, "", "modules"], [159, 1, 1, "", "mtia"], [159, 1, 1, "", "named_buffers"], [159, 1, 1, "", "named_children"], [159, 1, 1, "", "named_modules"], [159, 1, 1, "", "named_parameters"], [159, 2, 1, "", "observation_keys"], [159, 2, 1, "", "observation_spec"], [159, 2, 1, "", "observation_spec_unbatched"], [159, 2, 1, "", "output_spec"], [159, 2, 1, "", "output_spec_unbatched"], [159, 1, 1, "", "parameters"], [159, 1, 1, "", "rand_action"], [159, 1, 1, "", "rand_step"], [159, 1, 1, "", "register_backward_hook"], [159, 1, 1, "", "register_buffer"], [159, 1, 1, "", "register_collector"], [159, 1, 1, "", "register_forward_hook"], [159, 1, 1, "", "register_forward_pre_hook"], [159, 1, 1, "", "register_full_backward_hook"], [159, 1, 1, "", "register_full_backward_pre_hook"], [159, 1, 1, "", "register_gym"], [159, 1, 1, "", "register_load_state_dict_post_hook"], [159, 1, 1, "", "register_load_state_dict_pre_hook"], [159, 1, 1, "", "register_module"], [159, 1, 1, "", "register_parameter"], [159, 1, 1, "", "register_state_dict_post_hook"], [159, 1, 1, "", "register_state_dict_pre_hook"], [159, 1, 1, "", "requires_grad_"], [159, 1, 1, "", "reset"], [159, 2, 1, "", "reset_keys"], [159, 2, 1, "", "reward_key"], [159, 2, 1, "", "reward_keys"], [159, 2, 1, "", "reward_spec"], [159, 2, 1, "", "reward_spec_unbatched"], [159, 1, 1, "", "rollout"], [159, 1, 1, "", "set_extra_state"], [159, 1, 1, "", "set_seed"], [159, 1, 1, "", "set_spec_lock_"], [159, 1, 1, "", "set_submodule"], [159, 2, 1, "", "shape"], [159, 1, 1, "", "share_memory"], [159, 1, 1, "", "shutdown"], [159, 2, 1, "", "specs"], [159, 1, 1, "", "state_dict"], [159, 2, 1, "", "state_keys"], [159, 2, 1, "", "state_spec"], [159, 2, 1, "", "state_spec_unbatched"], [159, 1, 1, "", "step"], [159, 1, 1, "", "step_and_maybe_reset"], [159, 1, 1, "", "step_mdp"], [159, 1, 1, "", "to"], [159, 1, 1, "", "to_empty"], [159, 1, 1, "", "train"], [159, 1, 1, "", "type"], [159, 1, 1, "", "xpu"], [159, 1, 1, "", "zero_grad"]], "torchrl.envs.TicTacToeEnv": [[160, 2, 1, "", "action_key"], [160, 2, 1, "", "action_keys"], [160, 2, 1, "", "action_spec"], [160, 2, 1, "", "action_spec_unbatched"], [160, 1, 1, "", "add_module"], [160, 1, 1, "", "add_truncated_keys"], [160, 1, 1, "", "all_actions"], [160, 1, 1, "", "any_done"], [160, 1, 1, "", "append_transform"], [160, 1, 1, "", "apply"], [160, 1, 1, "", "auto_specs_"], [160, 2, 1, "", "batch_dims"], [160, 2, 1, "", "batch_size"], [160, 1, 1, "", "bfloat16"], [160, 1, 1, "", "buffers"], [160, 1, 1, "", "cardinality"], [160, 1, 1, "", "check_env_specs"], [160, 1, 1, "", "children"], [160, 2, 1, "", "collector"], [160, 1, 1, "", "compile"], [160, 1, 1, "", "cpu"], [160, 1, 1, "", "cuda"], [160, 2, 1, "", "done_key"], [160, 2, 1, "", "done_keys"], [160, 2, 1, "", "done_keys_groups"], [160, 2, 1, "", "done_spec"], [160, 2, 1, "", "done_spec_unbatched"], [160, 1, 1, "", "double"], [160, 1, 1, "", "empty_cache"], [160, 1, 1, "", "eval"], [160, 1, 1, "", "extra_repr"], [160, 1, 1, "", "fake_tensordict"], [160, 1, 1, "", "float"], [160, 1, 1, "", "forward"], [160, 2, 1, "", "full_action_spec"], [160, 2, 1, "", "full_action_spec_unbatched"], [160, 2, 1, "", "full_done_spec"], [160, 2, 1, "", "full_done_spec_unbatched"], [160, 2, 1, "", "full_observation_spec_unbatched"], [160, 2, 1, "", "full_reward_spec"], [160, 2, 1, "", "full_reward_spec_unbatched"], [160, 2, 1, "", "full_state_spec"], [160, 2, 1, "", "full_state_spec_unbatched"], [160, 1, 1, "", "get_buffer"], [160, 1, 1, "", "get_extra_state"], [160, 1, 1, "", "get_parameter"], [160, 1, 1, "", "get_submodule"], [160, 1, 1, "", "half"], [160, 2, 1, "", "input_spec"], [160, 2, 1, "", "input_spec_unbatched"], [160, 1, 1, "", "ipu"], [160, 2, 1, "", "is_spec_locked"], [160, 1, 1, "", "load_state_dict"], [160, 1, 1, "", "maybe_reset"], [160, 1, 1, "", "modules"], [160, 1, 1, "", "mtia"], [160, 1, 1, "", "named_buffers"], [160, 1, 1, "", "named_children"], [160, 1, 1, "", "named_modules"], [160, 1, 1, "", "named_parameters"], [160, 2, 1, "", "observation_keys"], [160, 2, 1, "", "observation_spec"], [160, 2, 1, "", "observation_spec_unbatched"], [160, 2, 1, "", "output_spec"], [160, 2, 1, "", "output_spec_unbatched"], [160, 1, 1, "", "parameters"], [160, 1, 1, "", "rand_action"], [160, 1, 1, "", "rand_step"], [160, 1, 1, "", "register_backward_hook"], [160, 1, 1, "", "register_buffer"], [160, 1, 1, "", "register_collector"], [160, 1, 1, "", "register_forward_hook"], [160, 1, 1, "", "register_forward_pre_hook"], [160, 1, 1, "", "register_full_backward_hook"], [160, 1, 1, "", "register_full_backward_pre_hook"], [160, 1, 1, "", "register_gym"], [160, 1, 1, "", "register_load_state_dict_post_hook"], [160, 1, 1, "", "register_load_state_dict_pre_hook"], [160, 1, 1, "", "register_module"], [160, 1, 1, "", "register_parameter"], [160, 1, 1, "", "register_state_dict_post_hook"], [160, 1, 1, "", "register_state_dict_pre_hook"], [160, 1, 1, "", "requires_grad_"], [160, 1, 1, "", "reset"], [160, 2, 1, "", "reset_keys"], [160, 2, 1, "", "reward_key"], [160, 2, 1, "", "reward_keys"], [160, 2, 1, "", "reward_spec"], [160, 2, 1, "", "reward_spec_unbatched"], [160, 1, 1, "", "rollout"], [160, 1, 1, "", "set_extra_state"], [160, 1, 1, "", "set_seed"], [160, 1, 1, "", "set_spec_lock_"], [160, 1, 1, "", "set_submodule"], [160, 2, 1, "", "shape"], [160, 1, 1, "", "share_memory"], [160, 2, 1, "", "specs"], [160, 1, 1, "", "state_dict"], [160, 2, 1, "", "state_keys"], [160, 2, 1, "", "state_spec"], [160, 2, 1, "", "state_spec_unbatched"], [160, 1, 1, "", "step"], [160, 1, 1, "", "step_and_maybe_reset"], [160, 1, 1, "", "step_mdp"], [160, 1, 1, "", "to"], [160, 1, 1, "", "to_empty"], [160, 1, 1, "", "train"], [160, 1, 1, "", "type"], [160, 1, 1, "", "xpu"], [160, 1, 1, "", "zero_grad"]], "torchrl.envs.llm": [[170, 0, 1, "", "ChatEnv"], [171, 0, 1, "", "DatasetChatEnv"], [172, 0, 1, "", "GSM8KEnv"], [173, 0, 1, "", "GSM8KPrepareQuestion"], [174, 0, 1, "", "GSM8KRewardParser"], [175, 0, 1, "", "IFEvalEnv"], [176, 0, 1, "", "IFEvalScoreData"], [177, 0, 1, "", "IfEvalScorer"], [178, 0, 1, "", "LLMEnv"], [179, 0, 1, "", "LLMHashingEnv"], [180, 0, 1, "", "MLGymWrapper"], [181, 0, 1, "", "make_gsm8k_env"], [182, 0, 1, "", "make_mlgym"]], "torchrl.envs.llm.ChatEnv": [[170, 2, 1, "", "action_key"], [170, 2, 1, "", "action_keys"], [170, 2, 1, "", "action_spec"], [170, 2, 1, "", "action_spec_unbatched"], [170, 1, 1, "", "add_module"], [170, 1, 1, "", "add_truncated_keys"], [170, 1, 1, "", "all_actions"], [170, 1, 1, "", "any_done"], [170, 1, 1, "", "append_transform"], [170, 1, 1, "", "apply"], [170, 1, 1, "", "auto_specs_"], [170, 2, 1, "", "batch_dims"], [170, 2, 1, "", "batch_locked"], [170, 2, 1, "", "batch_size"], [170, 1, 1, "", "bfloat16"], [170, 1, 1, "", "buffers"], [170, 1, 1, "", "cardinality"], [170, 1, 1, "", "check_env_specs"], [170, 1, 1, "", "children"], [170, 2, 1, "", "collector"], [170, 1, 1, "", "compile"], [170, 1, 1, "", "cpu"], [170, 1, 1, "", "cuda"], [170, 2, 1, "", "done_key"], [170, 2, 1, "", "done_keys"], [170, 2, 1, "", "done_keys_groups"], [170, 2, 1, "", "done_spec"], [170, 2, 1, "", "done_spec_unbatched"], [170, 1, 1, "", "double"], [170, 1, 1, "", "empty_cache"], [170, 1, 1, "", "eval"], [170, 1, 1, "", "extra_repr"], [170, 1, 1, "", "fake_tensordict"], [170, 1, 1, "", "float"], [170, 1, 1, "", "forward"], [170, 1, 1, "", "from_dataloader"], [170, 2, 1, "", "full_action_spec"], [170, 2, 1, "", "full_action_spec_unbatched"], [170, 2, 1, "", "full_done_spec"], [170, 2, 1, "", "full_done_spec_unbatched"], [170, 2, 1, "", "full_observation_spec_unbatched"], [170, 2, 1, "", "full_reward_spec"], [170, 2, 1, "", "full_reward_spec_unbatched"], [170, 2, 1, "", "full_state_spec"], [170, 2, 1, "", "full_state_spec_unbatched"], [170, 1, 1, "", "get_buffer"], [170, 1, 1, "", "get_extra_state"], [170, 1, 1, "", "get_parameter"], [170, 1, 1, "", "get_submodule"], [170, 1, 1, "", "half"], [170, 2, 1, "", "input_spec"], [170, 2, 1, "", "input_spec_unbatched"], [170, 1, 1, "", "ipu"], [170, 2, 1, "", "is_spec_locked"], [170, 1, 1, "", "load_state_dict"], [170, 1, 1, "", "maybe_reset"], [170, 1, 1, "", "modules"], [170, 1, 1, "", "mtia"], [170, 1, 1, "", "named_buffers"], [170, 1, 1, "", "named_children"], [170, 1, 1, "", "named_modules"], [170, 1, 1, "", "named_parameters"], [170, 2, 1, "", "observation_keys"], [170, 2, 1, "", "observation_spec"], [170, 2, 1, "", "observation_spec_unbatched"], [170, 2, 1, "", "output_spec"], [170, 2, 1, "", "output_spec_unbatched"], [170, 1, 1, "", "parameters"], [170, 1, 1, "", "rand_action"], [170, 1, 1, "", "rand_step"], [170, 1, 1, "", "register_backward_hook"], [170, 1, 1, "", "register_buffer"], [170, 1, 1, "", "register_collector"], [170, 1, 1, "", "register_forward_hook"], [170, 1, 1, "", "register_forward_pre_hook"], [170, 1, 1, "", "register_full_backward_hook"], [170, 1, 1, "", "register_full_backward_pre_hook"], [170, 1, 1, "", "register_gym"], [170, 1, 1, "", "register_load_state_dict_post_hook"], [170, 1, 1, "", "register_load_state_dict_pre_hook"], [170, 1, 1, "", "register_module"], [170, 1, 1, "", "register_parameter"], [170, 1, 1, "", "register_state_dict_post_hook"], [170, 1, 1, "", "register_state_dict_pre_hook"], [170, 1, 1, "", "requires_grad_"], [170, 1, 1, "id0", "reset"], [170, 2, 1, "", "reset_keys"], [170, 2, 1, "", "reward_key"], [170, 2, 1, "", "reward_keys"], [170, 2, 1, "", "reward_spec"], [170, 2, 1, "", "reward_spec_unbatched"], [170, 1, 1, "", "rollout"], [170, 1, 1, "", "set_extra_state"], [170, 1, 1, "", "set_seed"], [170, 1, 1, "", "set_spec_lock_"], [170, 1, 1, "", "set_submodule"], [170, 2, 1, "", "shape"], [170, 1, 1, "", "share_memory"], [170, 2, 1, "", "specs"], [170, 1, 1, "", "state_dict"], [170, 2, 1, "", "state_keys"], [170, 2, 1, "", "state_spec"], [170, 2, 1, "", "state_spec_unbatched"], [170, 1, 1, "id1", "step"], [170, 1, 1, "", "step_and_maybe_reset"], [170, 1, 1, "", "step_mdp"], [170, 1, 1, "", "to"], [170, 1, 1, "", "to_empty"], [170, 1, 1, "", "train"], [170, 1, 1, "", "type"], [170, 1, 1, "", "xpu"], [170, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.DatasetChatEnv": [[171, 2, 1, "", "action_key"], [171, 2, 1, "", "action_keys"], [171, 2, 1, "", "action_spec"], [171, 2, 1, "", "action_spec_unbatched"], [171, 1, 1, "", "add_module"], [171, 1, 1, "", "add_truncated_keys"], [171, 1, 1, "", "all_actions"], [171, 1, 1, "", "any_done"], [171, 1, 1, "", "append_transform"], [171, 1, 1, "", "apply"], [171, 1, 1, "", "auto_specs_"], [171, 2, 1, "", "batch_dims"], [171, 2, 1, "", "batch_locked"], [171, 2, 1, "", "batch_size"], [171, 1, 1, "", "bfloat16"], [171, 1, 1, "", "buffers"], [171, 1, 1, "", "cardinality"], [171, 1, 1, "", "check_env_specs"], [171, 1, 1, "", "children"], [171, 2, 1, "", "collector"], [171, 1, 1, "", "compile"], [171, 1, 1, "", "cpu"], [171, 1, 1, "", "cuda"], [171, 2, 1, "", "done_key"], [171, 2, 1, "", "done_keys"], [171, 2, 1, "", "done_keys_groups"], [171, 2, 1, "", "done_spec"], [171, 2, 1, "", "done_spec_unbatched"], [171, 1, 1, "", "double"], [171, 1, 1, "", "empty_cache"], [171, 1, 1, "", "eval"], [171, 1, 1, "", "extra_repr"], [171, 1, 1, "", "fake_tensordict"], [171, 1, 1, "", "float"], [171, 1, 1, "", "forward"], [171, 1, 1, "", "from_dataloader"], [171, 2, 1, "", "full_action_spec"], [171, 2, 1, "", "full_action_spec_unbatched"], [171, 2, 1, "", "full_done_spec"], [171, 2, 1, "", "full_done_spec_unbatched"], [171, 2, 1, "", "full_observation_spec_unbatched"], [171, 2, 1, "", "full_reward_spec"], [171, 2, 1, "", "full_reward_spec_unbatched"], [171, 2, 1, "", "full_state_spec"], [171, 2, 1, "", "full_state_spec_unbatched"], [171, 1, 1, "", "get_buffer"], [171, 1, 1, "", "get_extra_state"], [171, 1, 1, "", "get_parameter"], [171, 1, 1, "", "get_submodule"], [171, 1, 1, "", "half"], [171, 2, 1, "", "input_spec"], [171, 2, 1, "", "input_spec_unbatched"], [171, 1, 1, "", "insert_transform"], [171, 1, 1, "", "ipu"], [171, 2, 1, "", "is_spec_locked"], [171, 1, 1, "", "load_state_dict"], [171, 1, 1, "", "maybe_reset"], [171, 1, 1, "", "modules"], [171, 1, 1, "", "mtia"], [171, 1, 1, "", "named_buffers"], [171, 1, 1, "", "named_children"], [171, 1, 1, "", "named_modules"], [171, 1, 1, "", "named_parameters"], [171, 2, 1, "", "observation_keys"], [171, 2, 1, "", "observation_spec"], [171, 2, 1, "", "observation_spec_unbatched"], [171, 2, 1, "", "output_spec"], [171, 2, 1, "", "output_spec_unbatched"], [171, 1, 1, "", "parameters"], [171, 1, 1, "", "rand_action"], [171, 1, 1, "", "rand_step"], [171, 1, 1, "", "register_backward_hook"], [171, 1, 1, "", "register_buffer"], [171, 1, 1, "", "register_collector"], [171, 1, 1, "", "register_forward_hook"], [171, 1, 1, "", "register_forward_pre_hook"], [171, 1, 1, "", "register_full_backward_hook"], [171, 1, 1, "", "register_full_backward_pre_hook"], [171, 1, 1, "", "register_gym"], [171, 1, 1, "", "register_load_state_dict_post_hook"], [171, 1, 1, "", "register_load_state_dict_pre_hook"], [171, 1, 1, "", "register_module"], [171, 1, 1, "", "register_parameter"], [171, 1, 1, "", "register_state_dict_post_hook"], [171, 1, 1, "", "register_state_dict_pre_hook"], [171, 1, 1, "", "requires_grad_"], [171, 1, 1, "", "reset"], [171, 1, 1, "", "reset_dataloader"], [171, 2, 1, "", "reset_keys"], [171, 2, 1, "", "reward_key"], [171, 2, 1, "", "reward_keys"], [171, 2, 1, "", "reward_spec"], [171, 2, 1, "", "reward_spec_unbatched"], [171, 1, 1, "", "rollout"], [171, 1, 1, "", "set_extra_state"], [171, 1, 1, "", "set_missing_tolerance"], [171, 1, 1, "", "set_seed"], [171, 1, 1, "", "set_spec_lock_"], [171, 1, 1, "", "set_submodule"], [171, 2, 1, "", "shape"], [171, 1, 1, "", "share_memory"], [171, 2, 1, "", "specs"], [171, 1, 1, "", "state_dict"], [171, 2, 1, "", "state_keys"], [171, 2, 1, "", "state_spec"], [171, 2, 1, "", "state_spec_unbatched"], [171, 1, 1, "", "step"], [171, 1, 1, "", "step_and_maybe_reset"], [171, 1, 1, "", "step_mdp"], [171, 1, 1, "", "to"], [171, 1, 1, "", "to_empty"], [171, 1, 1, "", "train"], [171, 1, 1, "", "type"], [171, 1, 1, "", "xpu"], [171, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KEnv": [[172, 2, 1, "", "action_key"], [172, 2, 1, "", "action_keys"], [172, 2, 1, "", "action_spec"], [172, 2, 1, "", "action_spec_unbatched"], [172, 1, 1, "", "add_module"], [172, 1, 1, "", "add_truncated_keys"], [172, 1, 1, "", "all_actions"], [172, 1, 1, "", "any_done"], [172, 1, 1, "", "append_transform"], [172, 1, 1, "", "apply"], [172, 1, 1, "", "auto_specs_"], [172, 2, 1, "", "batch_dims"], [172, 2, 1, "", "batch_locked"], [172, 2, 1, "", "batch_size"], [172, 1, 1, "", "bfloat16"], [172, 1, 1, "", "buffers"], [172, 1, 1, "", "cardinality"], [172, 1, 1, "", "check_env_specs"], [172, 1, 1, "", "children"], [172, 2, 1, "", "collector"], [172, 1, 1, "", "compile"], [172, 1, 1, "", "cpu"], [172, 1, 1, "", "cuda"], [172, 2, 1, "", "done_key"], [172, 2, 1, "", "done_keys"], [172, 2, 1, "", "done_keys_groups"], [172, 2, 1, "", "done_spec"], [172, 2, 1, "", "done_spec_unbatched"], [172, 1, 1, "", "double"], [172, 1, 1, "", "empty_cache"], [172, 1, 1, "", "eval"], [172, 1, 1, "", "extra_repr"], [172, 1, 1, "", "fake_tensordict"], [172, 1, 1, "", "float"], [172, 1, 1, "", "forward"], [172, 1, 1, "", "from_dataloader"], [172, 2, 1, "", "full_action_spec"], [172, 2, 1, "", "full_action_spec_unbatched"], [172, 2, 1, "", "full_done_spec"], [172, 2, 1, "", "full_done_spec_unbatched"], [172, 2, 1, "", "full_observation_spec_unbatched"], [172, 2, 1, "", "full_reward_spec"], [172, 2, 1, "", "full_reward_spec_unbatched"], [172, 2, 1, "", "full_state_spec"], [172, 2, 1, "", "full_state_spec_unbatched"], [172, 1, 1, "", "get_buffer"], [172, 1, 1, "", "get_extra_state"], [172, 1, 1, "", "get_parameter"], [172, 1, 1, "", "get_submodule"], [172, 1, 1, "", "half"], [172, 2, 1, "", "input_spec"], [172, 2, 1, "", "input_spec_unbatched"], [172, 1, 1, "", "insert_transform"], [172, 1, 1, "", "ipu"], [172, 2, 1, "", "is_spec_locked"], [172, 1, 1, "", "load_state_dict"], [172, 1, 1, "", "maybe_reset"], [172, 1, 1, "", "modules"], [172, 1, 1, "", "mtia"], [172, 1, 1, "", "named_buffers"], [172, 1, 1, "", "named_children"], [172, 1, 1, "", "named_modules"], [172, 1, 1, "", "named_parameters"], [172, 2, 1, "", "observation_keys"], [172, 2, 1, "", "observation_spec"], [172, 2, 1, "", "observation_spec_unbatched"], [172, 2, 1, "", "output_spec"], [172, 2, 1, "", "output_spec_unbatched"], [172, 1, 1, "", "parameters"], [172, 1, 1, "", "rand_action"], [172, 1, 1, "", "rand_step"], [172, 1, 1, "", "register_backward_hook"], [172, 1, 1, "", "register_buffer"], [172, 1, 1, "", "register_collector"], [172, 1, 1, "", "register_forward_hook"], [172, 1, 1, "", "register_forward_pre_hook"], [172, 1, 1, "", "register_full_backward_hook"], [172, 1, 1, "", "register_full_backward_pre_hook"], [172, 1, 1, "", "register_gym"], [172, 1, 1, "", "register_load_state_dict_post_hook"], [172, 1, 1, "", "register_load_state_dict_pre_hook"], [172, 1, 1, "", "register_module"], [172, 1, 1, "", "register_parameter"], [172, 1, 1, "", "register_state_dict_post_hook"], [172, 1, 1, "", "register_state_dict_pre_hook"], [172, 1, 1, "", "requires_grad_"], [172, 1, 1, "", "reset"], [172, 1, 1, "", "reset_dataloader"], [172, 2, 1, "", "reset_keys"], [172, 2, 1, "", "reward_key"], [172, 2, 1, "", "reward_keys"], [172, 2, 1, "", "reward_spec"], [172, 2, 1, "", "reward_spec_unbatched"], [172, 1, 1, "", "rollout"], [172, 1, 1, "", "set_extra_state"], [172, 1, 1, "", "set_missing_tolerance"], [172, 1, 1, "", "set_seed"], [172, 1, 1, "", "set_spec_lock_"], [172, 1, 1, "", "set_submodule"], [172, 2, 1, "", "shape"], [172, 1, 1, "", "share_memory"], [172, 2, 1, "", "specs"], [172, 1, 1, "", "state_dict"], [172, 2, 1, "", "state_keys"], [172, 2, 1, "", "state_spec"], [172, 2, 1, "", "state_spec_unbatched"], [172, 1, 1, "", "step"], [172, 1, 1, "", "step_and_maybe_reset"], [172, 1, 1, "", "step_mdp"], [172, 1, 1, "", "to"], [172, 1, 1, "", "to_empty"], [172, 1, 1, "", "train"], [172, 1, 1, "", "type"], [172, 1, 1, "", "xpu"], [172, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KPrepareQuestion": [[173, 1, 1, "", "add_module"], [173, 1, 1, "", "apply"], [173, 1, 1, "", "bfloat16"], [173, 1, 1, "", "buffers"], [173, 1, 1, "", "children"], [173, 1, 1, "", "close"], [173, 2, 1, "", "collector"], [173, 1, 1, "", "compile"], [173, 2, 1, "", "container"], [173, 1, 1, "", "cpu"], [173, 1, 1, "", "cuda"], [173, 1, 1, "", "double"], [173, 1, 1, "", "eval"], [173, 1, 1, "", "extra_repr"], [173, 1, 1, "", "float"], [173, 1, 1, "", "forward"], [173, 1, 1, "", "get_buffer"], [173, 1, 1, "", "get_extra_state"], [173, 1, 1, "", "get_parameter"], [173, 1, 1, "", "get_submodule"], [173, 1, 1, "", "half"], [173, 1, 1, "", "init"], [173, 1, 1, "", "inv"], [173, 1, 1, "", "ipu"], [173, 1, 1, "", "load_state_dict"], [173, 1, 1, "", "modules"], [173, 1, 1, "", "mtia"], [173, 1, 1, "", "named_buffers"], [173, 1, 1, "", "named_children"], [173, 1, 1, "", "named_modules"], [173, 1, 1, "", "named_parameters"], [173, 1, 1, "", "parameters"], [173, 2, 1, "", "parent"], [173, 1, 1, "", "register_backward_hook"], [173, 1, 1, "", "register_buffer"], [173, 1, 1, "", "register_forward_hook"], [173, 1, 1, "", "register_forward_pre_hook"], [173, 1, 1, "", "register_full_backward_hook"], [173, 1, 1, "", "register_full_backward_pre_hook"], [173, 1, 1, "", "register_load_state_dict_post_hook"], [173, 1, 1, "", "register_load_state_dict_pre_hook"], [173, 1, 1, "", "register_module"], [173, 1, 1, "", "register_parameter"], [173, 1, 1, "", "register_state_dict_post_hook"], [173, 1, 1, "", "register_state_dict_pre_hook"], [173, 1, 1, "", "requires_grad_"], [173, 1, 1, "", "set_extra_state"], [173, 1, 1, "", "set_submodule"], [173, 1, 1, "", "share_memory"], [173, 1, 1, "", "state_dict"], [173, 1, 1, "", "to"], [173, 1, 1, "", "to_empty"], [173, 1, 1, "", "train"], [173, 1, 1, "", "transform_action_spec"], [173, 1, 1, "", "transform_done_spec"], [173, 1, 1, "", "transform_env_batch_size"], [173, 1, 1, "", "transform_env_device"], [173, 1, 1, "", "transform_input_spec"], [173, 1, 1, "", "transform_observation_spec"], [173, 1, 1, "", "transform_output_spec"], [173, 1, 1, "", "transform_reward_spec"], [173, 1, 1, "", "transform_state_spec"], [173, 1, 1, "", "type"], [173, 1, 1, "", "xpu"], [173, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KRewardParser": [[174, 1, 1, "", "add_module"], [174, 1, 1, "", "apply"], [174, 1, 1, "", "bfloat16"], [174, 1, 1, "", "buffers"], [174, 1, 1, "", "children"], [174, 1, 1, "", "close"], [174, 2, 1, "", "collector"], [174, 1, 1, "", "compile"], [174, 2, 1, "", "container"], [174, 1, 1, "", "cpu"], [174, 1, 1, "", "cuda"], [174, 1, 1, "", "double"], [174, 1, 1, "", "eval"], [174, 1, 1, "", "extra_repr"], [174, 1, 1, "", "extract_tags"], [174, 1, 1, "", "float"], [174, 1, 1, "", "forward"], [174, 1, 1, "", "get_buffer"], [174, 1, 1, "", "get_extra_state"], [174, 1, 1, "", "get_parameter"], [174, 1, 1, "", "get_submodule"], [174, 1, 1, "", "half"], [174, 1, 1, "", "init"], [174, 1, 1, "", "inv"], [174, 1, 1, "", "ipu"], [174, 1, 1, "", "load_state_dict"], [174, 1, 1, "", "modules"], [174, 1, 1, "", "mtia"], [174, 1, 1, "", "named_buffers"], [174, 1, 1, "", "named_children"], [174, 1, 1, "", "named_modules"], [174, 1, 1, "", "named_parameters"], [174, 1, 1, "", "parameters"], [174, 2, 1, "", "parent"], [174, 1, 1, "", "register_backward_hook"], [174, 1, 1, "", "register_buffer"], [174, 1, 1, "", "register_forward_hook"], [174, 1, 1, "", "register_forward_pre_hook"], [174, 1, 1, "", "register_full_backward_hook"], [174, 1, 1, "", "register_full_backward_pre_hook"], [174, 1, 1, "", "register_load_state_dict_post_hook"], [174, 1, 1, "", "register_load_state_dict_pre_hook"], [174, 1, 1, "", "register_module"], [174, 1, 1, "", "register_parameter"], [174, 1, 1, "", "register_state_dict_post_hook"], [174, 1, 1, "", "register_state_dict_pre_hook"], [174, 1, 1, "", "requires_grad_"], [174, 1, 1, "", "set_extra_state"], [174, 1, 1, "", "set_submodule"], [174, 1, 1, "", "share_memory"], [174, 1, 1, "", "state_dict"], [174, 1, 1, "", "to"], [174, 1, 1, "", "to_empty"], [174, 1, 1, "", "train"], [174, 1, 1, "", "transform_action_spec"], [174, 1, 1, "", "transform_done_spec"], [174, 1, 1, "", "transform_env_batch_size"], [174, 1, 1, "", "transform_env_device"], [174, 1, 1, "", "transform_input_spec"], [174, 1, 1, "", "transform_observation_spec"], [174, 1, 1, "", "transform_output_spec"], [174, 1, 1, "", "transform_reward_spec"], [174, 1, 1, "", "transform_state_spec"], [174, 1, 1, "", "type"], [174, 1, 1, "", "xpu"], [174, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.IFEvalEnv": [[175, 2, 1, "", "action_key"], [175, 2, 1, "", "action_keys"], [175, 2, 1, "", "action_spec"], [175, 2, 1, "", "action_spec_unbatched"], [175, 1, 1, "", "add_module"], [175, 1, 1, "", "add_truncated_keys"], [175, 1, 1, "", "all_actions"], [175, 1, 1, "", "any_done"], [175, 1, 1, "", "append_transform"], [175, 1, 1, "", "apply"], [175, 1, 1, "", "auto_specs_"], [175, 2, 1, "", "batch_dims"], [175, 2, 1, "", "batch_locked"], [175, 2, 1, "", "batch_size"], [175, 1, 1, "", "bfloat16"], [175, 1, 1, "", "buffers"], [175, 1, 1, "", "cardinality"], [175, 1, 1, "", "check_env_specs"], [175, 1, 1, "", "children"], [175, 2, 1, "", "collector"], [175, 1, 1, "", "compile"], [175, 1, 1, "", "cpu"], [175, 1, 1, "", "cuda"], [175, 2, 1, "", "done_key"], [175, 2, 1, "", "done_keys"], [175, 2, 1, "", "done_keys_groups"], [175, 2, 1, "", "done_spec"], [175, 2, 1, "", "done_spec_unbatched"], [175, 1, 1, "", "double"], [175, 1, 1, "", "empty_cache"], [175, 1, 1, "", "eval"], [175, 1, 1, "", "extra_repr"], [175, 1, 1, "", "fake_tensordict"], [175, 1, 1, "", "float"], [175, 1, 1, "", "forward"], [175, 1, 1, "", "from_dataloader"], [175, 2, 1, "", "full_action_spec"], [175, 2, 1, "", "full_action_spec_unbatched"], [175, 2, 1, "", "full_done_spec"], [175, 2, 1, "", "full_done_spec_unbatched"], [175, 2, 1, "", "full_observation_spec_unbatched"], [175, 2, 1, "", "full_reward_spec"], [175, 2, 1, "", "full_reward_spec_unbatched"], [175, 2, 1, "", "full_state_spec"], [175, 2, 1, "", "full_state_spec_unbatched"], [175, 1, 1, "", "get_buffer"], [175, 1, 1, "", "get_extra_state"], [175, 1, 1, "", "get_parameter"], [175, 1, 1, "", "get_submodule"], [175, 1, 1, "", "half"], [175, 2, 1, "", "input_spec"], [175, 2, 1, "", "input_spec_unbatched"], [175, 1, 1, "", "insert_transform"], [175, 1, 1, "", "ipu"], [175, 2, 1, "", "is_spec_locked"], [175, 1, 1, "", "load_state_dict"], [175, 1, 1, "", "maybe_reset"], [175, 1, 1, "", "modules"], [175, 1, 1, "", "mtia"], [175, 1, 1, "", "named_buffers"], [175, 1, 1, "", "named_children"], [175, 1, 1, "", "named_modules"], [175, 1, 1, "", "named_parameters"], [175, 2, 1, "", "observation_keys"], [175, 2, 1, "", "observation_spec"], [175, 2, 1, "", "observation_spec_unbatched"], [175, 2, 1, "", "output_spec"], [175, 2, 1, "", "output_spec_unbatched"], [175, 1, 1, "", "parameters"], [175, 1, 1, "", "rand_action"], [175, 1, 1, "", "rand_step"], [175, 1, 1, "", "register_backward_hook"], [175, 1, 1, "", "register_buffer"], [175, 1, 1, "", "register_collector"], [175, 1, 1, "", "register_forward_hook"], [175, 1, 1, "", "register_forward_pre_hook"], [175, 1, 1, "", "register_full_backward_hook"], [175, 1, 1, "", "register_full_backward_pre_hook"], [175, 1, 1, "", "register_gym"], [175, 1, 1, "", "register_load_state_dict_post_hook"], [175, 1, 1, "", "register_load_state_dict_pre_hook"], [175, 1, 1, "", "register_module"], [175, 1, 1, "", "register_parameter"], [175, 1, 1, "", "register_state_dict_post_hook"], [175, 1, 1, "", "register_state_dict_pre_hook"], [175, 1, 1, "", "requires_grad_"], [175, 1, 1, "", "reset"], [175, 1, 1, "", "reset_dataloader"], [175, 2, 1, "", "reset_keys"], [175, 2, 1, "", "reward_key"], [175, 2, 1, "", "reward_keys"], [175, 2, 1, "", "reward_spec"], [175, 2, 1, "", "reward_spec_unbatched"], [175, 1, 1, "", "rollout"], [175, 1, 1, "", "set_extra_state"], [175, 1, 1, "", "set_missing_tolerance"], [175, 1, 1, "", "set_seed"], [175, 1, 1, "", "set_spec_lock_"], [175, 1, 1, "", "set_submodule"], [175, 2, 1, "", "shape"], [175, 1, 1, "", "share_memory"], [175, 2, 1, "", "specs"], [175, 1, 1, "", "state_dict"], [175, 2, 1, "", "state_keys"], [175, 2, 1, "", "state_spec"], [175, 2, 1, "", "state_spec_unbatched"], [175, 1, 1, "", "step"], [175, 1, 1, "", "step_and_maybe_reset"], [175, 1, 1, "", "step_mdp"], [175, 1, 1, "", "to"], [175, 1, 1, "", "to_empty"], [175, 1, 1, "", "train"], [175, 1, 1, "", "type"], [175, 1, 1, "", "xpu"], [175, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.IFEvalScoreData": [[176, 1, 1, "", "cat"], [176, 2, 1, "", "device"], [176, 1, 1, "", "dumps"], [176, 1, 1, "", "fields"], [176, 1, 1, "", "from_any"], [176, 1, 1, "", "from_dataclass"], [176, 1, 1, "", "from_h5"], [176, 1, 1, "", "from_modules"], [176, 1, 1, "", "from_namedtuple"], [176, 1, 1, "", "from_pytree"], [176, 1, 1, "", "from_remote_init"], [176, 1, 1, "", "from_struct_array"], [176, 1, 1, "", "from_tensordict"], [176, 1, 1, "", "from_tuple"], [176, 1, 1, "", "fromkeys"], [176, 1, 1, "", "get"], [176, 1, 1, "", "lazy_stack"], [176, 1, 1, "", "load"], [176, 1, 1, "", "load_"], [176, 1, 1, "", "load_memmap"], [176, 1, 1, "", "load_state_dict"], [176, 1, 1, "", "maybe_dense_stack"], [176, 1, 1, "", "memmap"], [176, 1, 1, "", "memmap_"], [176, 1, 1, "", "memmap_like"], [176, 1, 1, "", "memmap_refresh_"], [176, 1, 1, "", "save"], [176, 1, 1, "", "set"], [176, 1, 1, "", "stack"], [176, 1, 1, "", "state_dict"], [176, 1, 1, "", "to_tensordict"], [176, 1, 1, "", "unbind"]], "torchrl.envs.llm.IfEvalScorer": [[177, 1, 1, "", "add_module"], [177, 1, 1, "", "apply"], [177, 1, 1, "", "bfloat16"], [177, 1, 1, "", "buffers"], [177, 1, 1, "", "children"], [177, 1, 1, "", "close"], [177, 2, 1, "", "collector"], [177, 1, 1, "", "compile"], [177, 2, 1, "", "container"], [177, 1, 1, "", "cpu"], [177, 1, 1, "", "cuda"], [177, 1, 1, "", "default_reward_aggregator"], [177, 1, 1, "", "double"], [177, 1, 1, "", "eval"], [177, 1, 1, "", "extra_repr"], [177, 1, 1, "", "float"], [177, 1, 1, "", "forward"], [177, 1, 1, "", "get_buffer"], [177, 1, 1, "", "get_extra_state"], [177, 1, 1, "", "get_parameter"], [177, 1, 1, "", "get_submodule"], [177, 1, 1, "", "half"], [177, 1, 1, "", "init"], [177, 1, 1, "", "inv"], [177, 1, 1, "", "ipu"], [177, 1, 1, "", "load_state_dict"], [177, 1, 1, "", "modules"], [177, 1, 1, "", "mtia"], [177, 1, 1, "", "named_buffers"], [177, 1, 1, "", "named_children"], [177, 1, 1, "", "named_modules"], [177, 1, 1, "", "named_parameters"], [177, 1, 1, "", "parameters"], [177, 2, 1, "", "parent"], [177, 1, 1, "", "register_backward_hook"], [177, 1, 1, "", "register_buffer"], [177, 1, 1, "", "register_forward_hook"], [177, 1, 1, "", "register_forward_pre_hook"], [177, 1, 1, "", "register_full_backward_hook"], [177, 1, 1, "", "register_full_backward_pre_hook"], [177, 1, 1, "", "register_load_state_dict_post_hook"], [177, 1, 1, "", "register_load_state_dict_pre_hook"], [177, 1, 1, "", "register_module"], [177, 1, 1, "", "register_parameter"], [177, 1, 1, "", "register_state_dict_post_hook"], [177, 1, 1, "", "register_state_dict_pre_hook"], [177, 1, 1, "", "requires_grad_"], [177, 1, 1, "", "set_extra_state"], [177, 1, 1, "", "set_submodule"], [177, 1, 1, "", "share_memory"], [177, 1, 1, "", "state_dict"], [177, 1, 1, "", "to"], [177, 1, 1, "", "to_empty"], [177, 1, 1, "", "train"], [177, 1, 1, "", "transform_action_spec"], [177, 1, 1, "", "transform_done_spec"], [177, 1, 1, "", "transform_env_batch_size"], [177, 1, 1, "", "transform_env_device"], [177, 1, 1, "", "transform_input_spec"], [177, 1, 1, "", "transform_observation_spec"], [177, 1, 1, "", "transform_output_spec"], [177, 1, 1, "", "transform_reward_spec"], [177, 1, 1, "", "transform_state_spec"], [177, 1, 1, "", "type"], [177, 1, 1, "", "xpu"], [177, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.LLMEnv": [[178, 2, 1, "", "action_key"], [178, 2, 1, "", "action_keys"], [178, 2, 1, "", "action_spec"], [178, 2, 1, "", "action_spec_unbatched"], [178, 1, 1, "", "add_module"], [178, 1, 1, "", "add_truncated_keys"], [178, 1, 1, "", "all_actions"], [178, 1, 1, "", "any_done"], [178, 1, 1, "", "append_transform"], [178, 1, 1, "", "apply"], [178, 1, 1, "", "auto_specs_"], [178, 2, 1, "", "batch_dims"], [178, 2, 1, "", "batch_locked"], [178, 2, 1, "", "batch_size"], [178, 1, 1, "", "bfloat16"], [178, 1, 1, "", "buffers"], [178, 1, 1, "", "cardinality"], [178, 1, 1, "", "check_env_specs"], [178, 1, 1, "", "children"], [178, 2, 1, "", "collector"], [178, 1, 1, "", "compile"], [178, 1, 1, "", "cpu"], [178, 1, 1, "", "cuda"], [178, 2, 1, "", "done_key"], [178, 2, 1, "", "done_keys"], [178, 2, 1, "", "done_keys_groups"], [178, 2, 1, "", "done_spec"], [178, 2, 1, "", "done_spec_unbatched"], [178, 1, 1, "", "double"], [178, 1, 1, "", "empty_cache"], [178, 1, 1, "", "eval"], [178, 1, 1, "", "extra_repr"], [178, 1, 1, "", "fake_tensordict"], [178, 1, 1, "", "float"], [178, 1, 1, "", "forward"], [178, 1, 1, "id0", "from_dataloader"], [178, 2, 1, "", "full_action_spec"], [178, 2, 1, "", "full_action_spec_unbatched"], [178, 2, 1, "", "full_done_spec"], [178, 2, 1, "", "full_done_spec_unbatched"], [178, 2, 1, "", "full_observation_spec_unbatched"], [178, 2, 1, "", "full_reward_spec"], [178, 2, 1, "", "full_reward_spec_unbatched"], [178, 2, 1, "", "full_state_spec"], [178, 2, 1, "", "full_state_spec_unbatched"], [178, 1, 1, "", "get_buffer"], [178, 1, 1, "", "get_extra_state"], [178, 1, 1, "", "get_parameter"], [178, 1, 1, "", "get_submodule"], [178, 1, 1, "", "half"], [178, 2, 1, "", "input_spec"], [178, 2, 1, "", "input_spec_unbatched"], [178, 1, 1, "", "ipu"], [178, 2, 1, "", "is_spec_locked"], [178, 1, 1, "", "load_state_dict"], [178, 1, 1, "", "maybe_reset"], [178, 1, 1, "", "modules"], [178, 1, 1, "", "mtia"], [178, 1, 1, "", "named_buffers"], [178, 1, 1, "", "named_children"], [178, 1, 1, "", "named_modules"], [178, 1, 1, "", "named_parameters"], [178, 2, 1, "", "observation_keys"], [178, 2, 1, "", "observation_spec"], [178, 2, 1, "", "observation_spec_unbatched"], [178, 2, 1, "", "output_spec"], [178, 2, 1, "", "output_spec_unbatched"], [178, 1, 1, "", "parameters"], [178, 1, 1, "", "rand_action"], [178, 1, 1, "", "rand_step"], [178, 1, 1, "", "register_backward_hook"], [178, 1, 1, "", "register_buffer"], [178, 1, 1, "", "register_collector"], [178, 1, 1, "", "register_forward_hook"], [178, 1, 1, "", "register_forward_pre_hook"], [178, 1, 1, "", "register_full_backward_hook"], [178, 1, 1, "", "register_full_backward_pre_hook"], [178, 1, 1, "", "register_gym"], [178, 1, 1, "", "register_load_state_dict_post_hook"], [178, 1, 1, "", "register_load_state_dict_pre_hook"], [178, 1, 1, "", "register_module"], [178, 1, 1, "", "register_parameter"], [178, 1, 1, "", "register_state_dict_post_hook"], [178, 1, 1, "", "register_state_dict_pre_hook"], [178, 1, 1, "", "requires_grad_"], [178, 1, 1, "", "reset"], [178, 2, 1, "", "reset_keys"], [178, 2, 1, "", "reward_key"], [178, 2, 1, "", "reward_keys"], [178, 2, 1, "", "reward_spec"], [178, 2, 1, "", "reward_spec_unbatched"], [178, 1, 1, "", "rollout"], [178, 1, 1, "", "set_extra_state"], [178, 1, 1, "", "set_seed"], [178, 1, 1, "", "set_spec_lock_"], [178, 1, 1, "", "set_submodule"], [178, 2, 1, "", "shape"], [178, 1, 1, "", "share_memory"], [178, 2, 1, "", "specs"], [178, 1, 1, "", "state_dict"], [178, 2, 1, "", "state_keys"], [178, 2, 1, "", "state_spec"], [178, 2, 1, "", "state_spec_unbatched"], [178, 1, 1, "", "step"], [178, 1, 1, "", "step_and_maybe_reset"], [178, 1, 1, "", "step_mdp"], [178, 1, 1, "", "to"], [178, 1, 1, "", "to_empty"], [178, 1, 1, "", "train"], [178, 1, 1, "", "type"], [178, 1, 1, "", "xpu"], [178, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.LLMHashingEnv": [[179, 2, 1, "", "action_key"], [179, 2, 1, "", "action_keys"], [179, 2, 1, "", "action_spec"], [179, 2, 1, "", "action_spec_unbatched"], [179, 1, 1, "", "add_module"], [179, 1, 1, "", "add_truncated_keys"], [179, 1, 1, "", "all_actions"], [179, 1, 1, "", "any_done"], [179, 1, 1, "", "append_transform"], [179, 1, 1, "", "apply"], [179, 1, 1, "", "auto_specs_"], [179, 2, 1, "", "batch_dims"], [179, 2, 1, "", "batch_locked"], [179, 2, 1, "", "batch_size"], [179, 1, 1, "", "bfloat16"], [179, 1, 1, "", "buffers"], [179, 1, 1, "", "cardinality"], [179, 1, 1, "", "check_env_specs"], [179, 1, 1, "", "children"], [179, 2, 1, "", "collector"], [179, 1, 1, "", "compile"], [179, 1, 1, "", "cpu"], [179, 1, 1, "", "cuda"], [179, 2, 1, "", "done_key"], [179, 2, 1, "", "done_keys"], [179, 2, 1, "", "done_keys_groups"], [179, 2, 1, "", "done_spec"], [179, 2, 1, "", "done_spec_unbatched"], [179, 1, 1, "", "double"], [179, 1, 1, "", "empty_cache"], [179, 1, 1, "", "eval"], [179, 1, 1, "", "extra_repr"], [179, 1, 1, "", "fake_tensordict"], [179, 1, 1, "", "float"], [179, 1, 1, "", "forward"], [179, 2, 1, "", "full_action_spec"], [179, 2, 1, "", "full_action_spec_unbatched"], [179, 2, 1, "", "full_done_spec"], [179, 2, 1, "", "full_done_spec_unbatched"], [179, 2, 1, "", "full_observation_spec_unbatched"], [179, 2, 1, "", "full_reward_spec"], [179, 2, 1, "", "full_reward_spec_unbatched"], [179, 2, 1, "", "full_state_spec"], [179, 2, 1, "", "full_state_spec_unbatched"], [179, 1, 1, "", "get_buffer"], [179, 1, 1, "", "get_extra_state"], [179, 1, 1, "", "get_parameter"], [179, 1, 1, "", "get_submodule"], [179, 1, 1, "", "half"], [179, 2, 1, "", "input_spec"], [179, 2, 1, "", "input_spec_unbatched"], [179, 1, 1, "", "ipu"], [179, 2, 1, "", "is_spec_locked"], [179, 1, 1, "", "load_state_dict"], [179, 1, 1, "", "make_tensordict"], [179, 1, 1, "", "maybe_reset"], [179, 1, 1, "", "modules"], [179, 1, 1, "", "mtia"], [179, 1, 1, "", "named_buffers"], [179, 1, 1, "", "named_children"], [179, 1, 1, "", "named_modules"], [179, 1, 1, "", "named_parameters"], [179, 2, 1, "", "observation_keys"], [179, 2, 1, "", "observation_spec"], [179, 2, 1, "", "observation_spec_unbatched"], [179, 2, 1, "", "output_spec"], [179, 2, 1, "", "output_spec_unbatched"], [179, 1, 1, "", "parameters"], [179, 1, 1, "", "rand_action"], [179, 1, 1, "", "rand_step"], [179, 1, 1, "", "register_backward_hook"], [179, 1, 1, "", "register_buffer"], [179, 1, 1, "", "register_collector"], [179, 1, 1, "", "register_forward_hook"], [179, 1, 1, "", "register_forward_pre_hook"], [179, 1, 1, "", "register_full_backward_hook"], [179, 1, 1, "", "register_full_backward_pre_hook"], [179, 1, 1, "", "register_gym"], [179, 1, 1, "", "register_load_state_dict_post_hook"], [179, 1, 1, "", "register_load_state_dict_pre_hook"], [179, 1, 1, "", "register_module"], [179, 1, 1, "", "register_parameter"], [179, 1, 1, "", "register_state_dict_post_hook"], [179, 1, 1, "", "register_state_dict_pre_hook"], [179, 1, 1, "", "requires_grad_"], [179, 1, 1, "", "reset"], [179, 2, 1, "", "reset_keys"], [179, 2, 1, "", "reward_key"], [179, 2, 1, "", "reward_keys"], [179, 2, 1, "", "reward_spec"], [179, 2, 1, "", "reward_spec_unbatched"], [179, 1, 1, "", "rollout"], [179, 1, 1, "", "set_extra_state"], [179, 1, 1, "", "set_seed"], [179, 1, 1, "", "set_spec_lock_"], [179, 1, 1, "", "set_submodule"], [179, 2, 1, "", "shape"], [179, 1, 1, "", "share_memory"], [179, 2, 1, "", "specs"], [179, 1, 1, "", "state_dict"], [179, 2, 1, "", "state_keys"], [179, 2, 1, "", "state_spec"], [179, 2, 1, "", "state_spec_unbatched"], [179, 1, 1, "", "step"], [179, 1, 1, "", "step_and_maybe_reset"], [179, 1, 1, "", "step_mdp"], [179, 1, 1, "", "to"], [179, 1, 1, "", "to_empty"], [179, 1, 1, "", "train"], [179, 1, 1, "", "type"], [179, 1, 1, "", "xpu"], [179, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.MLGymWrapper": [[180, 2, 1, "", "action_key"], [180, 2, 1, "", "action_keys"], [180, 2, 1, "", "action_spec"], [180, 2, 1, "", "action_spec_unbatched"], [180, 1, 1, "", "add_module"], [180, 1, 1, "", "add_truncated_keys"], [180, 1, 1, "", "all_actions"], [180, 1, 1, "", "any_done"], [180, 1, 1, "", "append_transform"], [180, 1, 1, "", "apply"], [180, 1, 1, "", "auto_register_info_dict"], [180, 1, 1, "", "auto_specs_"], [180, 2, 1, "", "batch_dims"], [180, 2, 1, "", "batch_locked"], [180, 2, 1, "", "batch_size"], [180, 1, 1, "", "bfloat16"], [180, 1, 1, "", "buffers"], [180, 1, 1, "", "cardinality"], [180, 1, 1, "", "check_env_specs"], [180, 1, 1, "", "children"], [180, 1, 1, "", "close"], [180, 2, 1, "", "collector"], [180, 1, 1, "", "compile"], [180, 1, 1, "", "cpu"], [180, 1, 1, "", "cuda"], [180, 2, 1, "", "done_key"], [180, 2, 1, "", "done_keys"], [180, 2, 1, "", "done_keys_groups"], [180, 2, 1, "", "done_spec"], [180, 2, 1, "", "done_spec_unbatched"], [180, 1, 1, "", "double"], [180, 1, 1, "", "empty_cache"], [180, 1, 1, "", "eval"], [180, 1, 1, "", "extra_repr"], [180, 1, 1, "", "fake_tensordict"], [180, 1, 1, "", "fast_encoding"], [180, 1, 1, "", "float"], [180, 1, 1, "", "forward"], [180, 2, 1, "", "full_action_spec"], [180, 2, 1, "", "full_action_spec_unbatched"], [180, 2, 1, "", "full_done_spec"], [180, 2, 1, "", "full_done_spec_unbatched"], [180, 2, 1, "", "full_observation_spec_unbatched"], [180, 2, 1, "", "full_reward_spec"], [180, 2, 1, "", "full_reward_spec_unbatched"], [180, 2, 1, "", "full_state_spec"], [180, 2, 1, "", "full_state_spec_unbatched"], [180, 1, 1, "", "get_buffer"], [180, 1, 1, "", "get_extra_state"], [180, 1, 1, "", "get_library_name"], [180, 1, 1, "", "get_parameter"], [180, 1, 1, "", "get_submodule"], [180, 1, 1, "", "half"], [180, 2, 1, "", "input_spec"], [180, 2, 1, "", "input_spec_unbatched"], [180, 1, 1, "", "ipu"], [180, 2, 1, "", "is_spec_locked"], [180, 1, 1, "", "load_state_dict"], [180, 1, 1, "", "maybe_reset"], [180, 1, 1, "", "modules"], [180, 1, 1, "", "mtia"], [180, 1, 1, "", "named_buffers"], [180, 1, 1, "", "named_children"], [180, 1, 1, "", "named_modules"], [180, 1, 1, "", "named_parameters"], [180, 2, 1, "", "observation_keys"], [180, 2, 1, "", "observation_spec"], [180, 2, 1, "", "observation_spec_unbatched"], [180, 2, 1, "", "output_spec"], [180, 2, 1, "", "output_spec_unbatched"], [180, 1, 1, "", "parameters"], [180, 1, 1, "", "rand_action"], [180, 1, 1, "", "rand_step"], [180, 1, 1, "", "read_action"], [180, 1, 1, "", "read_done"], [180, 1, 1, "", "read_obs"], [180, 1, 1, "", "read_reward"], [180, 1, 1, "", "register_backward_hook"], [180, 1, 1, "", "register_buffer"], [180, 1, 1, "", "register_collector"], [180, 1, 1, "", "register_forward_hook"], [180, 1, 1, "", "register_forward_pre_hook"], [180, 1, 1, "", "register_full_backward_hook"], [180, 1, 1, "", "register_full_backward_pre_hook"], [180, 1, 1, "", "register_gym"], [180, 1, 1, "", "register_load_state_dict_post_hook"], [180, 1, 1, "", "register_load_state_dict_pre_hook"], [180, 1, 1, "", "register_module"], [180, 1, 1, "", "register_parameter"], [180, 1, 1, "", "register_state_dict_post_hook"], [180, 1, 1, "", "register_state_dict_pre_hook"], [180, 1, 1, "", "requires_grad_"], [180, 1, 1, "", "reset"], [180, 2, 1, "", "reset_keys"], [180, 2, 1, "", "reward_key"], [180, 2, 1, "", "reward_keys"], [180, 2, 1, "", "reward_spec"], [180, 2, 1, "", "reward_spec_unbatched"], [180, 1, 1, "", "rollout"], [180, 1, 1, "", "set_extra_state"], [180, 1, 1, "", "set_info_dict_reader"], [180, 1, 1, "", "set_seed"], [180, 1, 1, "", "set_spec_lock_"], [180, 1, 1, "", "set_submodule"], [180, 2, 1, "", "shape"], [180, 1, 1, "", "share_memory"], [180, 2, 1, "", "specs"], [180, 1, 1, "", "state_dict"], [180, 2, 1, "", "state_keys"], [180, 2, 1, "", "state_spec"], [180, 2, 1, "", "state_spec_unbatched"], [180, 1, 1, "", "step"], [180, 1, 1, "", "step_and_maybe_reset"], [180, 1, 1, "", "step_mdp"], [180, 1, 1, "", "to"], [180, 1, 1, "", "to_empty"], [180, 1, 1, "", "train"], [180, 1, 1, "", "type"], [180, 1, 1, "", "xpu"], [180, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms": [[183, 0, 1, "", "AddThinkingPrompt"], [184, 0, 1, "", "BrowserTransform"], [185, 0, 1, "", "DataLoadingPrimer"], [186, 0, 1, "", "ExecuteToolsInOrder"], [187, 0, 1, "", "JSONCallParser"], [188, 0, 1, "", "KLComputation"], [189, 0, 1, "", "KLRewardTransform"], [190, 0, 1, "", "MCPToolTransform"], [191, 0, 1, "", "PolicyVersion"], [192, 0, 1, "", "PythonExecutorService"], [193, 0, 1, "", "PythonInterpreter"], [194, 0, 1, "", "RayDataLoadingPrimer"], [195, 0, 1, "", "RetrieveKL"], [196, 0, 1, "", "RetrieveLogProb"], [197, 0, 1, "", "SimpleToolTransform"], [198, 0, 1, "", "TemplateTransform"], [199, 0, 1, "", "Tokenizer"], [200, 0, 1, "", "ToolCall"], [201, 0, 1, "", "ToolRegistry"], [202, 0, 1, "", "ToolService"], [203, 0, 1, "", "XMLBlockParser"], [204, 0, 1, "", "as_nested_tensor"], [205, 0, 1, "", "as_padded_tensor"]], "torchrl.envs.llm.transforms.AddThinkingPrompt": [[183, 1, 1, "", "add_module"], [183, 1, 1, "", "apply"], [183, 1, 1, "", "bfloat16"], [183, 1, 1, "", "buffers"], [183, 1, 1, "", "children"], [183, 1, 1, "", "close"], [183, 2, 1, "", "collector"], [183, 1, 1, "", "compile"], [183, 2, 1, "", "container"], [183, 1, 1, "", "cpu"], [183, 1, 1, "", "cuda"], [183, 1, 1, "", "double"], [183, 1, 1, "", "eval"], [183, 1, 1, "", "extra_repr"], [183, 1, 1, "", "float"], [183, 1, 1, "", "forward"], [183, 1, 1, "", "get_buffer"], [183, 1, 1, "", "get_extra_state"], [183, 1, 1, "", "get_parameter"], [183, 1, 1, "", "get_submodule"], [183, 1, 1, "", "half"], [183, 1, 1, "", "init"], [183, 1, 1, "", "inv"], [183, 1, 1, "", "ipu"], [183, 1, 1, "", "load_state_dict"], [183, 1, 1, "", "modules"], [183, 1, 1, "", "mtia"], [183, 1, 1, "", "named_buffers"], [183, 1, 1, "", "named_children"], [183, 1, 1, "", "named_modules"], [183, 1, 1, "", "named_parameters"], [183, 1, 1, "", "parameters"], [183, 2, 1, "", "parent"], [183, 1, 1, "", "register_backward_hook"], [183, 1, 1, "", "register_buffer"], [183, 1, 1, "", "register_forward_hook"], [183, 1, 1, "", "register_forward_pre_hook"], [183, 1, 1, "", "register_full_backward_hook"], [183, 1, 1, "", "register_full_backward_pre_hook"], [183, 1, 1, "", "register_load_state_dict_post_hook"], [183, 1, 1, "", "register_load_state_dict_pre_hook"], [183, 1, 1, "", "register_module"], [183, 1, 1, "", "register_parameter"], [183, 1, 1, "", "register_state_dict_post_hook"], [183, 1, 1, "", "register_state_dict_pre_hook"], [183, 1, 1, "", "requires_grad_"], [183, 1, 1, "", "set_extra_state"], [183, 1, 1, "", "set_submodule"], [183, 1, 1, "", "share_memory"], [183, 1, 1, "", "state_dict"], [183, 1, 1, "", "to"], [183, 1, 1, "", "to_empty"], [183, 1, 1, "", "train"], [183, 1, 1, "", "transform_action_spec"], [183, 1, 1, "", "transform_done_spec"], [183, 1, 1, "", "transform_env_batch_size"], [183, 1, 1, "", "transform_env_device"], [183, 1, 1, "", "transform_input_spec"], [183, 1, 1, "", "transform_observation_spec"], [183, 1, 1, "", "transform_output_spec"], [183, 1, 1, "", "transform_reward_spec"], [183, 1, 1, "", "transform_state_spec"], [183, 1, 1, "", "type"], [183, 1, 1, "", "xpu"], [183, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.BrowserTransform": [[184, 1, 1, "", "add_module"], [184, 1, 1, "", "apply"], [184, 1, 1, "", "bfloat16"], [184, 1, 1, "", "buffers"], [184, 1, 1, "", "children"], [184, 1, 1, "", "clone"], [184, 1, 1, "", "close"], [184, 2, 1, "", "collector"], [184, 1, 1, "", "compile"], [184, 2, 1, "", "container"], [184, 1, 1, "", "cpu"], [184, 1, 1, "", "cuda"], [184, 1, 1, "", "double"], [184, 1, 1, "", "eval"], [184, 1, 1, "", "extra_repr"], [184, 1, 1, "", "float"], [184, 1, 1, "", "forward"], [184, 1, 1, "", "get_buffer"], [184, 1, 1, "", "get_extra_state"], [184, 1, 1, "", "get_parameter"], [184, 1, 1, "", "get_submodule"], [184, 1, 1, "", "half"], [184, 1, 1, "", "init"], [184, 1, 1, "", "inv"], [184, 1, 1, "", "ipu"], [184, 1, 1, "", "load_state_dict"], [184, 1, 1, "", "modules"], [184, 1, 1, "", "mtia"], [184, 1, 1, "", "named_buffers"], [184, 1, 1, "", "named_children"], [184, 1, 1, "", "named_modules"], [184, 1, 1, "", "named_parameters"], [184, 1, 1, "", "parameters"], [184, 2, 1, "", "parent"], [184, 1, 1, "", "register_backward_hook"], [184, 1, 1, "", "register_buffer"], [184, 1, 1, "", "register_forward_hook"], [184, 1, 1, "", "register_forward_pre_hook"], [184, 1, 1, "", "register_full_backward_hook"], [184, 1, 1, "", "register_full_backward_pre_hook"], [184, 1, 1, "", "register_load_state_dict_post_hook"], [184, 1, 1, "", "register_load_state_dict_pre_hook"], [184, 1, 1, "", "register_module"], [184, 1, 1, "", "register_parameter"], [184, 1, 1, "", "register_state_dict_post_hook"], [184, 1, 1, "", "register_state_dict_pre_hook"], [184, 1, 1, "", "requires_grad_"], [184, 1, 1, "", "set_extra_state"], [184, 1, 1, "", "set_submodule"], [184, 1, 1, "", "share_memory"], [184, 1, 1, "", "state_dict"], [184, 1, 1, "", "to"], [184, 1, 1, "", "to_empty"], [184, 1, 1, "", "train"], [184, 1, 1, "", "transform_action_spec"], [184, 1, 1, "", "transform_done_spec"], [184, 1, 1, "", "transform_env_batch_size"], [184, 1, 1, "", "transform_env_device"], [184, 1, 1, "", "transform_input_spec"], [184, 1, 1, "", "transform_observation_spec"], [184, 1, 1, "", "transform_output_spec"], [184, 1, 1, "", "transform_reward_spec"], [184, 1, 1, "", "transform_state_spec"], [184, 1, 1, "", "type"], [184, 1, 1, "", "xpu"], [184, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.DataLoadingPrimer": [[185, 1, 1, "", "add_module"], [185, 1, 1, "", "apply"], [185, 1, 1, "", "bfloat16"], [185, 1, 1, "", "buffers"], [185, 1, 1, "", "children"], [185, 1, 1, "", "close"], [185, 2, 1, "", "collector"], [185, 1, 1, "", "compile"], [185, 2, 1, "", "container"], [185, 1, 1, "", "cpu"], [185, 1, 1, "", "cuda"], [185, 1, 1, "", "double"], [185, 1, 1, "", "eval"], [185, 1, 1, "", "extra_repr"], [185, 1, 1, "", "float"], [185, 1, 1, "", "forward"], [185, 1, 1, "", "get_buffer"], [185, 1, 1, "", "get_extra_state"], [185, 1, 1, "", "get_parameter"], [185, 1, 1, "", "get_submodule"], [185, 1, 1, "", "half"], [185, 1, 1, "", "init"], [185, 1, 1, "", "inv"], [185, 1, 1, "", "ipu"], [185, 1, 1, "", "load_state_dict"], [185, 1, 1, "", "modules"], [185, 1, 1, "", "mtia"], [185, 1, 1, "", "named_buffers"], [185, 1, 1, "", "named_children"], [185, 1, 1, "", "named_modules"], [185, 1, 1, "", "named_parameters"], [185, 1, 1, "", "parameters"], [185, 2, 1, "", "parent"], [185, 1, 1, "", "register_backward_hook"], [185, 1, 1, "", "register_buffer"], [185, 1, 1, "", "register_forward_hook"], [185, 1, 1, "", "register_forward_pre_hook"], [185, 1, 1, "", "register_full_backward_hook"], [185, 1, 1, "", "register_full_backward_pre_hook"], [185, 1, 1, "", "register_load_state_dict_post_hook"], [185, 1, 1, "", "register_load_state_dict_pre_hook"], [185, 1, 1, "", "register_module"], [185, 1, 1, "", "register_parameter"], [185, 1, 1, "", "register_state_dict_post_hook"], [185, 1, 1, "", "register_state_dict_pre_hook"], [185, 1, 1, "", "requires_grad_"], [185, 1, 1, "", "reset_dataloader"], [185, 1, 1, "", "set_extra_state"], [185, 1, 1, "", "set_submodule"], [185, 1, 1, "", "share_memory"], [185, 1, 1, "", "state_dict"], [185, 1, 1, "", "to"], [185, 1, 1, "", "to_empty"], [185, 1, 1, "", "train"], [185, 1, 1, "", "transform_action_spec"], [185, 1, 1, "", "transform_done_spec"], [185, 1, 1, "", "transform_env_batch_size"], [185, 1, 1, "", "transform_env_device"], [185, 1, 1, "", "transform_input_spec"], [185, 1, 1, "", "transform_observation_spec"], [185, 1, 1, "", "transform_output_spec"], [185, 1, 1, "", "transform_reward_spec"], [185, 1, 1, "", "transform_state_spec"], [185, 1, 1, "", "type"], [185, 1, 1, "", "xpu"], [185, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.ExecuteToolsInOrder": [[186, 1, 1, "", "add_module"], [186, 1, 1, "", "apply"], [186, 1, 1, "", "bfloat16"], [186, 1, 1, "", "buffers"], [186, 1, 1, "", "children"], [186, 1, 1, "", "close"], [186, 2, 1, "", "collector"], [186, 1, 1, "", "compile"], [186, 2, 1, "", "container"], [186, 1, 1, "", "cpu"], [186, 1, 1, "", "cuda"], [186, 1, 1, "", "double"], [186, 1, 1, "", "eval"], [186, 1, 1, "", "extra_repr"], [186, 1, 1, "", "float"], [186, 1, 1, "", "forward"], [186, 1, 1, "", "get_buffer"], [186, 1, 1, "", "get_extra_state"], [186, 1, 1, "", "get_parameter"], [186, 1, 1, "", "get_submodule"], [186, 1, 1, "", "half"], [186, 1, 1, "", "init"], [186, 1, 1, "", "inv"], [186, 1, 1, "", "ipu"], [186, 1, 1, "", "load_state_dict"], [186, 1, 1, "", "modules"], [186, 1, 1, "", "mtia"], [186, 1, 1, "", "named_buffers"], [186, 1, 1, "", "named_children"], [186, 1, 1, "", "named_modules"], [186, 1, 1, "", "named_parameters"], [186, 1, 1, "", "parameters"], [186, 2, 1, "", "parent"], [186, 1, 1, "", "register_backward_hook"], [186, 1, 1, "", "register_buffer"], [186, 1, 1, "", "register_forward_hook"], [186, 1, 1, "", "register_forward_pre_hook"], [186, 1, 1, "", "register_full_backward_hook"], [186, 1, 1, "", "register_full_backward_pre_hook"], [186, 1, 1, "", "register_load_state_dict_post_hook"], [186, 1, 1, "", "register_load_state_dict_pre_hook"], [186, 1, 1, "", "register_module"], [186, 1, 1, "", "register_parameter"], [186, 1, 1, "", "register_state_dict_post_hook"], [186, 1, 1, "", "register_state_dict_pre_hook"], [186, 1, 1, "", "requires_grad_"], [186, 1, 1, "", "set_extra_state"], [186, 1, 1, "", "set_submodule"], [186, 1, 1, "", "share_memory"], [186, 1, 1, "", "state_dict"], [186, 1, 1, "", "to"], [186, 1, 1, "", "to_empty"], [186, 1, 1, "", "train"], [186, 1, 1, "", "transform_action_spec"], [186, 1, 1, "", "transform_done_spec"], [186, 1, 1, "", "transform_env_batch_size"], [186, 1, 1, "", "transform_env_device"], [186, 1, 1, "", "transform_input_spec"], [186, 1, 1, "", "transform_observation_spec"], [186, 1, 1, "", "transform_output_spec"], [186, 1, 1, "", "transform_reward_spec"], [186, 1, 1, "", "transform_state_spec"], [186, 1, 1, "", "type"], [186, 1, 1, "", "xpu"], [186, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.KLComputation": [[188, 1, 1, "", "add_module"], [188, 1, 1, "", "apply"], [188, 1, 1, "", "bfloat16"], [188, 1, 1, "", "buffers"], [188, 1, 1, "", "children"], [188, 1, 1, "", "close"], [188, 2, 1, "", "collector"], [188, 1, 1, "", "compile"], [188, 2, 1, "", "container"], [188, 1, 1, "", "cpu"], [188, 1, 1, "", "cuda"], [188, 1, 1, "", "double"], [188, 1, 1, "", "eval"], [188, 1, 1, "", "extra_repr"], [188, 1, 1, "", "float"], [188, 1, 1, "", "forward"], [188, 1, 1, "", "get_buffer"], [188, 1, 1, "", "get_extra_state"], [188, 1, 1, "", "get_parameter"], [188, 1, 1, "", "get_submodule"], [188, 1, 1, "", "half"], [188, 1, 1, "", "init"], [188, 1, 1, "", "inv"], [188, 1, 1, "", "ipu"], [188, 1, 1, "", "load_state_dict"], [188, 1, 1, "", "modules"], [188, 1, 1, "", "mtia"], [188, 1, 1, "", "named_buffers"], [188, 1, 1, "", "named_children"], [188, 1, 1, "", "named_modules"], [188, 1, 1, "", "named_parameters"], [188, 1, 1, "", "parameters"], [188, 2, 1, "", "parent"], [188, 1, 1, "", "register_backward_hook"], [188, 1, 1, "", "register_buffer"], [188, 1, 1, "", "register_forward_hook"], [188, 1, 1, "", "register_forward_pre_hook"], [188, 1, 1, "", "register_full_backward_hook"], [188, 1, 1, "", "register_full_backward_pre_hook"], [188, 1, 1, "", "register_load_state_dict_post_hook"], [188, 1, 1, "", "register_load_state_dict_pre_hook"], [188, 1, 1, "", "register_module"], [188, 1, 1, "", "register_parameter"], [188, 1, 1, "", "register_state_dict_post_hook"], [188, 1, 1, "", "register_state_dict_pre_hook"], [188, 1, 1, "", "requires_grad_"], [188, 1, 1, "", "set_extra_state"], [188, 1, 1, "", "set_submodule"], [188, 1, 1, "", "share_memory"], [188, 1, 1, "", "state_dict"], [188, 1, 1, "", "to"], [188, 1, 1, "", "to_empty"], [188, 1, 1, "", "train"], [188, 1, 1, "", "transform_action_spec"], [188, 1, 1, "", "transform_done_spec"], [188, 1, 1, "", "transform_env_batch_size"], [188, 1, 1, "", "transform_env_device"], [188, 1, 1, "", "transform_input_spec"], [188, 1, 1, "", "transform_observation_spec"], [188, 1, 1, "", "transform_output_spec"], [188, 1, 1, "", "transform_reward_spec"], [188, 1, 1, "", "transform_state_spec"], [188, 1, 1, "", "type"], [188, 1, 1, "", "xpu"], [188, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.KLRewardTransform": [[189, 1, 1, "", "add_module"], [189, 1, 1, "", "apply"], [189, 1, 1, "", "bfloat16"], [189, 1, 1, "", "buffers"], [189, 1, 1, "", "children"], [189, 1, 1, "", "close"], [189, 2, 1, "", "collector"], [189, 1, 1, "", "compile"], [189, 2, 1, "", "container"], [189, 1, 1, "", "cpu"], [189, 1, 1, "", "cuda"], [189, 1, 1, "", "double"], [189, 1, 1, "", "eval"], [189, 1, 1, "", "extra_repr"], [189, 1, 1, "", "float"], [189, 1, 1, "", "forward"], [189, 1, 1, "", "get_buffer"], [189, 1, 1, "", "get_extra_state"], [189, 1, 1, "", "get_parameter"], [189, 1, 1, "", "get_submodule"], [189, 1, 1, "", "half"], [189, 1, 1, "", "init"], [189, 1, 1, "", "inv"], [189, 1, 1, "", "ipu"], [189, 1, 1, "", "load_state_dict"], [189, 1, 1, "", "modules"], [189, 1, 1, "", "mtia"], [189, 1, 1, "", "named_buffers"], [189, 1, 1, "", "named_children"], [189, 1, 1, "", "named_modules"], [189, 1, 1, "", "named_parameters"], [189, 1, 1, "", "parameters"], [189, 2, 1, "", "parent"], [189, 1, 1, "", "register_backward_hook"], [189, 1, 1, "", "register_buffer"], [189, 1, 1, "", "register_forward_hook"], [189, 1, 1, "", "register_forward_pre_hook"], [189, 1, 1, "", "register_full_backward_hook"], [189, 1, 1, "", "register_full_backward_pre_hook"], [189, 1, 1, "", "register_load_state_dict_post_hook"], [189, 1, 1, "", "register_load_state_dict_pre_hook"], [189, 1, 1, "", "register_module"], [189, 1, 1, "", "register_parameter"], [189, 1, 1, "", "register_state_dict_post_hook"], [189, 1, 1, "", "register_state_dict_pre_hook"], [189, 1, 1, "", "requires_grad_"], [189, 1, 1, "", "set_extra_state"], [189, 1, 1, "", "set_submodule"], [189, 1, 1, "", "share_memory"], [189, 1, 1, "", "state_dict"], [189, 1, 1, "", "to"], [189, 1, 1, "", "to_empty"], [189, 1, 1, "", "train"], [189, 1, 1, "", "transform_action_spec"], [189, 1, 1, "", "transform_done_spec"], [189, 1, 1, "", "transform_env_batch_size"], [189, 1, 1, "", "transform_env_device"], [189, 1, 1, "", "transform_input_spec"], [189, 1, 1, "", "transform_observation_spec"], [189, 1, 1, "", "transform_output_spec"], [189, 1, 1, "", "transform_reward_spec"], [189, 1, 1, "", "transform_state_spec"], [189, 1, 1, "", "type"], [189, 1, 1, "", "xpu"], [189, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.MCPToolTransform": [[190, 1, 1, "", "add_module"], [190, 1, 1, "", "apply"], [190, 1, 1, "", "bfloat16"], [190, 1, 1, "", "buffers"], [190, 1, 1, "", "children"], [190, 1, 1, "", "close"], [190, 2, 1, "", "collector"], [190, 1, 1, "", "compile"], [190, 2, 1, "", "container"], [190, 1, 1, "", "cpu"], [190, 1, 1, "", "cuda"], [190, 1, 1, "", "double"], [190, 1, 1, "", "eval"], [190, 1, 1, "", "extra_repr"], [190, 1, 1, "", "float"], [190, 1, 1, "", "forward"], [190, 1, 1, "", "get_buffer"], [190, 1, 1, "", "get_extra_state"], [190, 1, 1, "", "get_parameter"], [190, 1, 1, "", "get_submodule"], [190, 1, 1, "", "half"], [190, 1, 1, "", "init"], [190, 1, 1, "", "inv"], [190, 1, 1, "", "ipu"], [190, 1, 1, "", "load_state_dict"], [190, 1, 1, "", "modules"], [190, 1, 1, "", "mtia"], [190, 1, 1, "", "named_buffers"], [190, 1, 1, "", "named_children"], [190, 1, 1, "", "named_modules"], [190, 1, 1, "", "named_parameters"], [190, 1, 1, "", "parameters"], [190, 2, 1, "", "parent"], [190, 1, 1, "", "register_backward_hook"], [190, 1, 1, "", "register_buffer"], [190, 1, 1, "", "register_forward_hook"], [190, 1, 1, "", "register_forward_pre_hook"], [190, 1, 1, "", "register_full_backward_hook"], [190, 1, 1, "", "register_full_backward_pre_hook"], [190, 1, 1, "", "register_load_state_dict_post_hook"], [190, 1, 1, "", "register_load_state_dict_pre_hook"], [190, 1, 1, "", "register_module"], [190, 1, 1, "", "register_parameter"], [190, 1, 1, "", "register_state_dict_post_hook"], [190, 1, 1, "", "register_state_dict_pre_hook"], [190, 1, 1, "", "requires_grad_"], [190, 1, 1, "", "set_extra_state"], [190, 1, 1, "", "set_submodule"], [190, 1, 1, "", "share_memory"], [190, 1, 1, "", "state_dict"], [190, 1, 1, "", "to"], [190, 1, 1, "", "to_empty"], [190, 1, 1, "", "train"], [190, 1, 1, "", "transform_action_spec"], [190, 1, 1, "", "transform_done_spec"], [190, 1, 1, "", "transform_env_batch_size"], [190, 1, 1, "", "transform_env_device"], [190, 1, 1, "", "transform_input_spec"], [190, 1, 1, "", "transform_observation_spec"], [190, 1, 1, "", "transform_output_spec"], [190, 1, 1, "", "transform_reward_spec"], [190, 1, 1, "", "transform_state_spec"], [190, 1, 1, "", "type"], [190, 1, 1, "", "xpu"], [190, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.PolicyVersion": [[191, 1, 1, "", "add_module"], [191, 1, 1, "", "apply"], [191, 1, 1, "", "bfloat16"], [191, 1, 1, "", "buffers"], [191, 1, 1, "", "children"], [191, 1, 1, "", "close"], [191, 2, 1, "", "collector"], [191, 1, 1, "", "compile"], [191, 2, 1, "", "container"], [191, 1, 1, "", "cpu"], [191, 1, 1, "", "cuda"], [191, 1, 1, "", "double"], [191, 1, 1, "", "eval"], [191, 1, 1, "", "extra_repr"], [191, 1, 1, "", "float"], [191, 1, 1, "", "forward"], [191, 1, 1, "", "get_buffer"], [191, 1, 1, "", "get_extra_state"], [191, 1, 1, "", "get_parameter"], [191, 1, 1, "", "get_submodule"], [191, 1, 1, "", "half"], [191, 1, 1, "", "increment_version"], [191, 1, 1, "", "init"], [191, 1, 1, "", "inv"], [191, 1, 1, "", "ipu"], [191, 1, 1, "", "load_state_dict"], [191, 1, 1, "", "modules"], [191, 1, 1, "", "mtia"], [191, 1, 1, "", "named_buffers"], [191, 1, 1, "", "named_children"], [191, 1, 1, "", "named_modules"], [191, 1, 1, "", "named_parameters"], [191, 1, 1, "", "parameters"], [191, 2, 1, "", "parent"], [191, 1, 1, "", "register_backward_hook"], [191, 1, 1, "", "register_buffer"], [191, 1, 1, "", "register_forward_hook"], [191, 1, 1, "", "register_forward_pre_hook"], [191, 1, 1, "", "register_full_backward_hook"], [191, 1, 1, "", "register_full_backward_pre_hook"], [191, 1, 1, "", "register_load_state_dict_post_hook"], [191, 1, 1, "", "register_load_state_dict_pre_hook"], [191, 1, 1, "", "register_module"], [191, 1, 1, "", "register_parameter"], [191, 1, 1, "", "register_state_dict_post_hook"], [191, 1, 1, "", "register_state_dict_pre_hook"], [191, 1, 1, "", "requires_grad_"], [191, 1, 1, "", "set_extra_state"], [191, 1, 1, "", "set_submodule"], [191, 1, 1, "", "share_memory"], [191, 1, 1, "", "state_dict"], [191, 1, 1, "", "to"], [191, 1, 1, "", "to_empty"], [191, 1, 1, "", "train"], [191, 1, 1, "", "transform_action_spec"], [191, 1, 1, "", "transform_done_spec"], [191, 1, 1, "", "transform_env_batch_size"], [191, 1, 1, "", "transform_env_device"], [191, 1, 1, "", "transform_input_spec"], [191, 1, 1, "", "transform_observation_spec"], [191, 1, 1, "", "transform_output_spec"], [191, 1, 1, "", "transform_reward_spec"], [191, 1, 1, "", "transform_state_spec"], [191, 1, 1, "", "type"], [191, 2, 1, "", "version"], [191, 1, 1, "", "xpu"], [191, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.PythonExecutorService": [[192, 1, 1, "", "cleanup"], [192, 1, 1, "", "execute"]], "torchrl.envs.llm.transforms.PythonInterpreter": [[193, 1, 1, "", "add_module"], [193, 1, 1, "", "apply"], [193, 1, 1, "", "bfloat16"], [193, 1, 1, "", "buffers"], [193, 1, 1, "", "children"], [193, 1, 1, "", "clone"], [193, 1, 1, "", "close"], [193, 2, 1, "", "collector"], [193, 1, 1, "", "compile"], [193, 2, 1, "", "container"], [193, 1, 1, "", "cpu"], [193, 1, 1, "", "cuda"], [193, 1, 1, "", "double"], [193, 1, 1, "", "eval"], [193, 1, 1, "", "extra_repr"], [193, 1, 1, "", "float"], [193, 1, 1, "", "forward"], [193, 1, 1, "", "get_buffer"], [193, 1, 1, "", "get_extra_state"], [193, 1, 1, "", "get_parameter"], [193, 1, 1, "", "get_submodule"], [193, 1, 1, "", "half"], [193, 1, 1, "", "init"], [193, 1, 1, "", "inv"], [193, 1, 1, "", "ipu"], [193, 1, 1, "", "load_state_dict"], [193, 1, 1, "", "modules"], [193, 1, 1, "", "mtia"], [193, 1, 1, "", "named_buffers"], [193, 1, 1, "", "named_children"], [193, 1, 1, "", "named_modules"], [193, 1, 1, "", "named_parameters"], [193, 1, 1, "", "parameters"], [193, 2, 1, "", "parent"], [193, 1, 1, "", "register_backward_hook"], [193, 1, 1, "", "register_buffer"], [193, 1, 1, "", "register_forward_hook"], [193, 1, 1, "", "register_forward_pre_hook"], [193, 1, 1, "", "register_full_backward_hook"], [193, 1, 1, "", "register_full_backward_pre_hook"], [193, 1, 1, "", "register_load_state_dict_post_hook"], [193, 1, 1, "", "register_load_state_dict_pre_hook"], [193, 1, 1, "", "register_module"], [193, 1, 1, "", "register_parameter"], [193, 1, 1, "", "register_state_dict_post_hook"], [193, 1, 1, "", "register_state_dict_pre_hook"], [193, 1, 1, "", "requires_grad_"], [193, 1, 1, "", "set_extra_state"], [193, 1, 1, "", "set_submodule"], [193, 1, 1, "", "share_memory"], [193, 1, 1, "", "state_dict"], [193, 1, 1, "", "to"], [193, 1, 1, "", "to_empty"], [193, 1, 1, "", "train"], [193, 1, 1, "", "transform_action_spec"], [193, 1, 1, "", "transform_done_spec"], [193, 1, 1, "", "transform_env_batch_size"], [193, 1, 1, "", "transform_env_device"], [193, 1, 1, "", "transform_input_spec"], [193, 1, 1, "", "transform_observation_spec"], [193, 1, 1, "", "transform_output_spec"], [193, 1, 1, "", "transform_reward_spec"], [193, 1, 1, "", "transform_state_spec"], [193, 1, 1, "", "type"], [193, 1, 1, "", "xpu"], [193, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.RayDataLoadingPrimer": [[194, 1, 1, "", "add_module"], [194, 1, 1, "", "apply"], [194, 2, 1, "", "base_env"], [194, 1, 1, "", "bfloat16"], [194, 1, 1, "", "buffers"], [194, 1, 1, "", "children"], [194, 1, 1, "", "clone"], [194, 1, 1, "", "close"], [194, 2, 1, "", "collector"], [194, 1, 1, "", "compile"], [194, 2, 1, "", "container"], [194, 1, 1, "", "cpu"], [194, 1, 1, "", "cuda"], [194, 2, 1, "", "data_keys"], [194, 2, 1, "", "dataloader"], [194, 2, 1, "", "device"], [194, 1, 1, "", "double"], [194, 1, 1, "", "dump"], [194, 1, 1, "", "empty_cache"], [194, 2, 1, "", "endless_dataloader"], [194, 1, 1, "", "eval"], [194, 1, 1, "", "extra_repr"], [194, 1, 1, "", "float"], [194, 1, 1, "", "forward"], [194, 1, 1, "", "get_buffer"], [194, 1, 1, "", "get_extra_state"], [194, 1, 1, "", "get_parameter"], [194, 1, 1, "", "get_submodule"], [194, 1, 1, "", "half"], [194, 2, 1, "", "in_keys"], [194, 2, 1, "", "in_keys_inv"], [194, 1, 1, "", "init"], [194, 1, 1, "", "inv"], [194, 1, 1, "", "ipu"], [194, 1, 1, "", "load_state_dict"], [194, 2, 1, "", "missing_tolerance"], [194, 1, 1, "", "modules"], [194, 1, 1, "", "mtia"], [194, 1, 1, "", "named_buffers"], [194, 1, 1, "", "named_children"], [194, 1, 1, "", "named_modules"], [194, 1, 1, "", "named_parameters"], [194, 2, 1, "", "out_keys"], [194, 2, 1, "", "out_keys_inv"], [194, 1, 1, "", "parameters"], [194, 2, 1, "", "parent"], [194, 2, 1, "", "primers"], [194, 1, 1, "", "register_backward_hook"], [194, 1, 1, "", "register_buffer"], [194, 1, 1, "", "register_forward_hook"], [194, 1, 1, "", "register_forward_pre_hook"], [194, 1, 1, "", "register_full_backward_hook"], [194, 1, 1, "", "register_full_backward_pre_hook"], [194, 1, 1, "", "register_load_state_dict_post_hook"], [194, 1, 1, "", "register_load_state_dict_pre_hook"], [194, 1, 1, "", "register_module"], [194, 1, 1, "", "register_parameter"], [194, 1, 1, "", "register_state_dict_post_hook"], [194, 1, 1, "", "register_state_dict_pre_hook"], [194, 2, 1, "", "repeats"], [194, 1, 1, "", "requires_grad_"], [194, 1, 1, "", "reset_dataloader"], [194, 1, 1, "", "reset_parent"], [194, 1, 1, "", "set_container"], [194, 1, 1, "", "set_extra_state"], [194, 1, 1, "", "set_missing_tolerance"], [194, 1, 1, "", "set_submodule"], [194, 1, 1, "", "share_memory"], [194, 2, 1, "", "stack_method"], [194, 1, 1, "", "state_dict"], [194, 1, 1, "", "to"], [194, 1, 1, "", "to_empty"], [194, 1, 1, "", "train"], [194, 1, 1, "", "transform_action_spec"], [194, 1, 1, "", "transform_done_spec"], [194, 1, 1, "", "transform_env_batch_size"], [194, 1, 1, "", "transform_env_device"], [194, 1, 1, "", "transform_input_spec"], [194, 1, 1, "", "transform_observation_spec"], [194, 1, 1, "", "transform_output_spec"], [194, 1, 1, "", "transform_reward_spec"], [194, 1, 1, "", "transform_state_spec"], [194, 1, 1, "", "type"], [194, 1, 1, "", "xpu"], [194, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.RetrieveKL": [[195, 1, 1, "", "add_module"], [195, 1, 1, "", "append"], [195, 1, 1, "", "apply"], [195, 1, 1, "", "bfloat16"], [195, 1, 1, "", "buffers"], [195, 1, 1, "", "children"], [195, 1, 1, "", "close"], [195, 2, 1, "", "collector"], [195, 1, 1, "", "compile"], [195, 2, 1, "", "container"], [195, 1, 1, "", "cpu"], [195, 1, 1, "", "cuda"], [195, 1, 1, "", "double"], [195, 1, 1, "", "eval"], [195, 1, 1, "", "extra_repr"], [195, 1, 1, "", "float"], [195, 1, 1, "", "forward"], [195, 1, 1, "", "get_buffer"], [195, 1, 1, "", "get_extra_state"], [195, 1, 1, "", "get_parameter"], [195, 1, 1, "", "get_submodule"], [195, 1, 1, "", "half"], [195, 1, 1, "", "init"], [195, 1, 1, "", "insert"], [195, 1, 1, "", "inv"], [195, 1, 1, "", "ipu"], [195, 1, 1, "", "load_state_dict"], [195, 1, 1, "", "modules"], [195, 1, 1, "", "mtia"], [195, 1, 1, "", "named_buffers"], [195, 1, 1, "", "named_children"], [195, 1, 1, "", "named_modules"], [195, 1, 1, "", "named_parameters"], [195, 1, 1, "", "parameters"], [195, 2, 1, "", "parent"], [195, 1, 1, "", "pop"], [195, 1, 1, "", "register_backward_hook"], [195, 1, 1, "", "register_buffer"], [195, 1, 1, "", "register_forward_hook"], [195, 1, 1, "", "register_forward_pre_hook"], [195, 1, 1, "", "register_full_backward_hook"], [195, 1, 1, "", "register_full_backward_pre_hook"], [195, 1, 1, "", "register_load_state_dict_post_hook"], [195, 1, 1, "", "register_load_state_dict_pre_hook"], [195, 1, 1, "", "register_module"], [195, 1, 1, "", "register_parameter"], [195, 1, 1, "", "register_state_dict_post_hook"], [195, 1, 1, "", "register_state_dict_pre_hook"], [195, 1, 1, "", "requires_grad_"], [195, 1, 1, "", "set_extra_state"], [195, 1, 1, "", "set_submodule"], [195, 1, 1, "", "share_memory"], [195, 1, 1, "", "state_dict"], [195, 1, 1, "", "to"], [195, 1, 1, "", "to_empty"], [195, 1, 1, "", "train"], [195, 1, 1, "", "transform_action_spec"], [195, 1, 1, "", "transform_done_spec"], [195, 1, 1, "", "transform_env_batch_size"], [195, 1, 1, "", "transform_env_device"], [195, 1, 1, "", "transform_input_spec"], [195, 1, 1, "", "transform_observation_spec"], [195, 1, 1, "", "transform_output_spec"], [195, 1, 1, "", "transform_reward_spec"], [195, 1, 1, "", "transform_state_spec"], [195, 1, 1, "", "type"], [195, 1, 1, "", "xpu"], [195, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.RetrieveLogProb": [[196, 1, 1, "", "add_module"], [196, 1, 1, "", "apply"], [196, 1, 1, "", "bfloat16"], [196, 1, 1, "", "buffers"], [196, 1, 1, "", "children"], [196, 1, 1, "", "close"], [196, 2, 1, "", "collector"], [196, 1, 1, "", "compile"], [196, 2, 1, "", "container"], [196, 1, 1, "", "cpu"], [196, 1, 1, "", "cuda"], [196, 1, 1, "", "double"], [196, 1, 1, "", "eval"], [196, 1, 1, "", "extra_repr"], [196, 1, 1, "", "float"], [196, 1, 1, "", "forward"], [196, 1, 1, "", "get_buffer"], [196, 1, 1, "", "get_extra_state"], [196, 1, 1, "", "get_parameter"], [196, 1, 1, "", "get_submodule"], [196, 1, 1, "", "half"], [196, 1, 1, "", "init"], [196, 1, 1, "", "inv"], [196, 1, 1, "", "ipu"], [196, 1, 1, "", "load_state_dict"], [196, 1, 1, "", "modules"], [196, 1, 1, "", "mtia"], [196, 1, 1, "", "named_buffers"], [196, 1, 1, "", "named_children"], [196, 1, 1, "", "named_modules"], [196, 1, 1, "", "named_parameters"], [196, 1, 1, "", "parameters"], [196, 2, 1, "", "parent"], [196, 1, 1, "", "register_backward_hook"], [196, 1, 1, "", "register_buffer"], [196, 1, 1, "", "register_forward_hook"], [196, 1, 1, "", "register_forward_pre_hook"], [196, 1, 1, "", "register_full_backward_hook"], [196, 1, 1, "", "register_full_backward_pre_hook"], [196, 1, 1, "", "register_load_state_dict_post_hook"], [196, 1, 1, "", "register_load_state_dict_pre_hook"], [196, 1, 1, "", "register_module"], [196, 1, 1, "", "register_parameter"], [196, 1, 1, "", "register_state_dict_post_hook"], [196, 1, 1, "", "register_state_dict_pre_hook"], [196, 1, 1, "", "requires_grad_"], [196, 1, 1, "", "set_extra_state"], [196, 1, 1, "", "set_submodule"], [196, 1, 1, "", "share_memory"], [196, 1, 1, "", "state_dict"], [196, 1, 1, "", "to"], [196, 1, 1, "", "to_empty"], [196, 1, 1, "", "train"], [196, 1, 1, "", "transform_action_spec"], [196, 1, 1, "", "transform_done_spec"], [196, 1, 1, "", "transform_env_batch_size"], [196, 1, 1, "", "transform_env_device"], [196, 1, 1, "", "transform_input_spec"], [196, 1, 1, "", "transform_observation_spec"], [196, 1, 1, "", "transform_output_spec"], [196, 1, 1, "", "transform_reward_spec"], [196, 1, 1, "", "transform_state_spec"], [196, 1, 1, "", "type"], [196, 1, 1, "", "xpu"], [196, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.SimpleToolTransform": [[197, 1, 1, "", "add_module"], [197, 1, 1, "", "apply"], [197, 1, 1, "", "bfloat16"], [197, 1, 1, "", "buffers"], [197, 1, 1, "", "children"], [197, 1, 1, "", "close"], [197, 2, 1, "", "collector"], [197, 1, 1, "", "compile"], [197, 2, 1, "", "container"], [197, 1, 1, "", "cpu"], [197, 1, 1, "", "cuda"], [197, 1, 1, "", "double"], [197, 1, 1, "", "eval"], [197, 1, 1, "", "extra_repr"], [197, 1, 1, "", "float"], [197, 1, 1, "", "forward"], [197, 1, 1, "", "get_buffer"], [197, 1, 1, "", "get_extra_state"], [197, 1, 1, "", "get_parameter"], [197, 1, 1, "", "get_submodule"], [197, 1, 1, "", "half"], [197, 1, 1, "", "init"], [197, 1, 1, "", "inv"], [197, 1, 1, "", "ipu"], [197, 1, 1, "", "load_state_dict"], [197, 1, 1, "", "modules"], [197, 1, 1, "", "mtia"], [197, 1, 1, "", "named_buffers"], [197, 1, 1, "", "named_children"], [197, 1, 1, "", "named_modules"], [197, 1, 1, "", "named_parameters"], [197, 1, 1, "", "parameters"], [197, 2, 1, "", "parent"], [197, 1, 1, "", "register_backward_hook"], [197, 1, 1, "", "register_buffer"], [197, 1, 1, "", "register_forward_hook"], [197, 1, 1, "", "register_forward_pre_hook"], [197, 1, 1, "", "register_full_backward_hook"], [197, 1, 1, "", "register_full_backward_pre_hook"], [197, 1, 1, "", "register_load_state_dict_post_hook"], [197, 1, 1, "", "register_load_state_dict_pre_hook"], [197, 1, 1, "", "register_module"], [197, 1, 1, "", "register_parameter"], [197, 1, 1, "", "register_state_dict_post_hook"], [197, 1, 1, "", "register_state_dict_pre_hook"], [197, 1, 1, "", "requires_grad_"], [197, 1, 1, "", "set_extra_state"], [197, 1, 1, "", "set_submodule"], [197, 1, 1, "", "share_memory"], [197, 1, 1, "", "state_dict"], [197, 1, 1, "", "to"], [197, 1, 1, "", "to_empty"], [197, 1, 1, "", "train"], [197, 1, 1, "", "transform_action_spec"], [197, 1, 1, "", "transform_done_spec"], [197, 1, 1, "", "transform_env_batch_size"], [197, 1, 1, "", "transform_env_device"], [197, 1, 1, "", "transform_input_spec"], [197, 1, 1, "", "transform_observation_spec"], [197, 1, 1, "", "transform_output_spec"], [197, 1, 1, "", "transform_reward_spec"], [197, 1, 1, "", "transform_state_spec"], [197, 1, 1, "", "type"], [197, 1, 1, "", "xpu"], [197, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.TemplateTransform": [[198, 1, 1, "", "add_module"], [198, 1, 1, "", "apply"], [198, 1, 1, "", "bfloat16"], [198, 1, 1, "", "buffers"], [198, 1, 1, "", "children"], [198, 1, 1, "", "close"], [198, 2, 1, "", "collector"], [198, 1, 1, "", "compile"], [198, 2, 1, "", "container"], [198, 1, 1, "", "cpu"], [198, 1, 1, "", "cuda"], [198, 1, 1, "", "double"], [198, 1, 1, "", "eval"], [198, 1, 1, "", "extra_repr"], [198, 1, 1, "", "float"], [198, 1, 1, "", "forward"], [198, 1, 1, "", "get_buffer"], [198, 1, 1, "", "get_extra_state"], [198, 1, 1, "", "get_parameter"], [198, 1, 1, "", "get_submodule"], [198, 1, 1, "", "half"], [198, 1, 1, "", "init"], [198, 1, 1, "", "inv"], [198, 1, 1, "", "ipu"], [198, 1, 1, "", "load_state_dict"], [198, 1, 1, "", "modules"], [198, 1, 1, "", "mtia"], [198, 1, 1, "", "named_buffers"], [198, 1, 1, "", "named_children"], [198, 1, 1, "", "named_modules"], [198, 1, 1, "", "named_parameters"], [198, 1, 1, "", "parameters"], [198, 2, 1, "", "parent"], [198, 1, 1, "", "register_backward_hook"], [198, 1, 1, "", "register_buffer"], [198, 1, 1, "", "register_forward_hook"], [198, 1, 1, "", "register_forward_pre_hook"], [198, 1, 1, "", "register_full_backward_hook"], [198, 1, 1, "", "register_full_backward_pre_hook"], [198, 1, 1, "", "register_load_state_dict_post_hook"], [198, 1, 1, "", "register_load_state_dict_pre_hook"], [198, 1, 1, "", "register_module"], [198, 1, 1, "", "register_parameter"], [198, 1, 1, "", "register_state_dict_post_hook"], [198, 1, 1, "", "register_state_dict_pre_hook"], [198, 1, 1, "", "requires_grad_"], [198, 1, 1, "", "set_extra_state"], [198, 1, 1, "", "set_submodule"], [198, 1, 1, "", "share_memory"], [198, 1, 1, "", "state_dict"], [198, 1, 1, "", "to"], [198, 1, 1, "", "to_empty"], [198, 1, 1, "", "train"], [198, 1, 1, "", "transform_action_spec"], [198, 1, 1, "", "transform_done_spec"], [198, 1, 1, "", "transform_env_batch_size"], [198, 1, 1, "", "transform_env_device"], [198, 1, 1, "", "transform_input_spec"], [198, 1, 1, "", "transform_observation_spec"], [198, 1, 1, "", "transform_output_spec"], [198, 1, 1, "", "transform_reward_spec"], [198, 1, 1, "", "transform_state_spec"], [198, 1, 1, "", "type"], [198, 1, 1, "", "xpu"], [198, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.Tokenizer": [[199, 1, 1, "", "add_module"], [199, 1, 1, "", "apply"], [199, 1, 1, "", "bfloat16"], [199, 1, 1, "", "buffers"], [199, 1, 1, "", "children"], [199, 1, 1, "", "close"], [199, 2, 1, "", "collector"], [199, 1, 1, "", "compile"], [199, 2, 1, "", "container"], [199, 1, 1, "", "cpu"], [199, 1, 1, "", "cuda"], [199, 1, 1, "", "double"], [199, 1, 1, "", "eval"], [199, 1, 1, "", "extra_repr"], [199, 1, 1, "", "float"], [199, 1, 1, "", "forward"], [199, 1, 1, "", "get_buffer"], [199, 1, 1, "", "get_extra_state"], [199, 1, 1, "", "get_parameter"], [199, 1, 1, "", "get_submodule"], [199, 1, 1, "", "half"], [199, 1, 1, "", "init"], [199, 1, 1, "", "inv"], [199, 1, 1, "", "ipu"], [199, 1, 1, "", "load_state_dict"], [199, 1, 1, "", "modules"], [199, 1, 1, "", "mtia"], [199, 1, 1, "", "named_buffers"], [199, 1, 1, "", "named_children"], [199, 1, 1, "", "named_modules"], [199, 1, 1, "", "named_parameters"], [199, 1, 1, "", "parameters"], [199, 2, 1, "", "parent"], [199, 1, 1, "", "register_backward_hook"], [199, 1, 1, "", "register_buffer"], [199, 1, 1, "", "register_forward_hook"], [199, 1, 1, "", "register_forward_pre_hook"], [199, 1, 1, "", "register_full_backward_hook"], [199, 1, 1, "", "register_full_backward_pre_hook"], [199, 1, 1, "", "register_load_state_dict_post_hook"], [199, 1, 1, "", "register_load_state_dict_pre_hook"], [199, 1, 1, "", "register_module"], [199, 1, 1, "", "register_parameter"], [199, 1, 1, "", "register_state_dict_post_hook"], [199, 1, 1, "", "register_state_dict_pre_hook"], [199, 1, 1, "", "requires_grad_"], [199, 1, 1, "", "set_extra_state"], [199, 1, 1, "", "set_submodule"], [199, 1, 1, "", "share_memory"], [199, 1, 1, "", "state_dict"], [199, 1, 1, "", "to"], [199, 1, 1, "", "to_empty"], [199, 1, 1, "", "train"], [199, 1, 1, "", "transform_action_spec"], [199, 1, 1, "", "transform_done_spec"], [199, 1, 1, "", "transform_env_batch_size"], [199, 1, 1, "", "transform_env_device"], [199, 1, 1, "", "transform_input_spec"], [199, 1, 1, "", "transform_observation_spec"], [199, 1, 1, "", "transform_output_spec"], [199, 1, 1, "", "transform_reward_spec"], [199, 1, 1, "", "transform_state_spec"], [199, 1, 1, "", "type"], [199, 1, 1, "", "xpu"], [199, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.ToolRegistry": [[201, 1, 1, "", "get"], [201, 1, 1, "", "register"]], "torchrl.envs.model_based.dreamer": [[207, 3, 1, "", "DreamerDecoder"], [208, 3, 1, "", "DreamerEnv"]], "torchrl.envs.transforms": [[214, 0, 1, "", "ActionDiscretizer"], [215, 0, 1, "", "ActionMask"], [216, 0, 1, "", "AutoResetEnv"], [217, 0, 1, "", "AutoResetTransform"], [218, 0, 1, "", "BatchSizeTransform"], [219, 0, 1, "", "BinarizeReward"], [220, 0, 1, "", "BurnInTransform"], [221, 0, 1, "", "CatFrames"], [222, 0, 1, "", "CatTensors"], [223, 0, 1, "", "CenterCrop"], [224, 0, 1, "", "ClipTransform"], [225, 0, 1, "", "Compose"], [226, 0, 1, "", "ConditionalPolicySwitch"], [227, 0, 1, "", "ConditionalSkip"], [228, 0, 1, "", "Crop"], [229, 0, 1, "", "DTypeCastTransform"], [230, 0, 1, "", "DeviceCastTransform"], [231, 0, 1, "", "DiscreteActionProjection"], [232, 0, 1, "", "DoubleToFloat"], [233, 0, 1, "", "EndOfLifeTransform"], [234, 0, 1, "", "ExcludeTransform"], [235, 0, 1, "", "FiniteTensorDictCheck"], [236, 0, 1, "", "FlattenObservation"], [237, 0, 1, "", "FrameSkipTransform"], [238, 0, 1, "", "GrayScale"], [239, 0, 1, "", "Hash"], [240, 0, 1, "", "InitTracker"], [241, 0, 1, "", "KLRewardTransform"], [242, 0, 1, "", "LineariseRewards"], [243, 0, 1, "", "ModuleTransform"], [244, 0, 1, "", "MultiAction"], [245, 0, 1, "", "NoopResetEnv"], [246, 0, 1, "", "ObservationNorm"], [247, 0, 1, "", "ObservationTransform"], [248, 0, 1, "", "PermuteTransform"], [249, 0, 1, "", "PinMemoryTransform"], [250, 0, 1, "", "R3MTransform"], [251, 0, 1, "", "RandomCropTensorDict"], [252, 0, 1, "", "RemoveEmptySpecs"], [253, 0, 1, "", "RenameTransform"], [254, 0, 1, "", "Resize"], [255, 0, 1, "", "Reward2GoTransform"], [256, 0, 1, "", "RewardClipping"], [257, 0, 1, "", "RewardScaling"], [258, 0, 1, "", "RewardSum"], [259, 0, 1, "", "SelectTransform"], [260, 0, 1, "", "SignTransform"], [261, 0, 1, "", "SqueezeTransform"], [262, 0, 1, "", "Stack"], [263, 0, 1, "", "StepCounter"], [264, 0, 1, "", "TargetReturn"], [265, 0, 1, "", "TensorDictPrimer"], [266, 0, 1, "", "TimeMaxPool"], [267, 0, 1, "", "Timer"], [268, 0, 1, "", "ToTensorImage"], [269, 0, 1, "", "Tokenizer"], [270, 0, 1, "", "TrajCounter"], [271, 0, 1, "", "Transform"], [272, 0, 1, "", "TransformedEnv"], [273, 0, 1, "", "UnaryTransform"], [274, 0, 1, "", "UnsqueezeTransform"], [275, 0, 1, "", "VC1Transform"], [276, 0, 1, "", "VIPRewardTransform"], [277, 0, 1, "", "VIPTransform"], [278, 0, 1, "", "VecGymEnvTransform"], [279, 0, 1, "", "VecNorm"], [280, 0, 1, "", "VecNormV2"], [281, 0, 1, "", "gSDENoise"]], "torchrl.envs.transforms.ActionDiscretizer": [[214, 0, 1, "", "SamplingStrategy"], [214, 1, 1, "", "inv"], [214, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.ActionMask": [[215, 1, 1, "", "forward"]], "torchrl.envs.transforms.AutoResetEnv": [[216, 1, 1, "", "insert_transform"]], "torchrl.envs.transforms.AutoResetTransform": [[217, 1, 1, "", "forward"]], "torchrl.envs.transforms.BatchSizeTransform": [[218, 1, 1, "", "forward"], [218, 1, 1, "", "transform_env_batch_size"], [218, 1, 1, "", "transform_input_spec"], [218, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.BinarizeReward": [[219, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.BurnInTransform": [[220, 1, 1, "", "forward"]], "torchrl.envs.transforms.CatFrames": [[221, 1, 1, "", "forward"], [221, 1, 1, "", "make_rb_transform_and_sampler"], [221, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CatTensors": [[222, 1, 1, "", "forward"], [222, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CenterCrop": [[223, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ClipTransform": [[224, 1, 1, "", "transform_observation_spec"], [224, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.Compose": [[225, 1, 1, "", "append"], [225, 1, 1, "", "close"], [225, 1, 1, "", "forward"], [225, 1, 1, "", "init"], [225, 1, 1, "", "insert"], [225, 1, 1, "", "pop"], [225, 1, 1, "", "to"], [225, 1, 1, "", "transform_action_spec"], [225, 1, 1, "", "transform_env_batch_size"], [225, 1, 1, "", "transform_env_device"], [225, 1, 1, "", "transform_input_spec"], [225, 1, 1, "", "transform_observation_spec"], [225, 1, 1, "", "transform_output_spec"], [225, 1, 1, "", "transform_reward_spec"], [225, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.ConditionalPolicySwitch": [[226, 1, 1, "", "forward"]], "torchrl.envs.transforms.ConditionalSkip": [[227, 1, 1, "", "forward"]], "torchrl.envs.transforms.Crop": [[228, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.DTypeCastTransform": [[229, 1, 1, "", "forward"], [229, 1, 1, "", "transform_input_spec"], [229, 1, 1, "", "transform_observation_spec"], [229, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.DeviceCastTransform": [[230, 1, 1, "", "forward"], [230, 1, 1, "", "transform_action_spec"], [230, 1, 1, "", "transform_done_spec"], [230, 1, 1, "", "transform_env_device"], [230, 1, 1, "", "transform_input_spec"], [230, 1, 1, "", "transform_observation_spec"], [230, 1, 1, "", "transform_output_spec"], [230, 1, 1, "", "transform_reward_spec"], [230, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.DiscreteActionProjection": [[231, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.EndOfLifeTransform": [[233, 1, 1, "", "forward"], [233, 1, 1, "", "register_keys"], [233, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ExcludeTransform": [[234, 1, 1, "", "forward"], [234, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.FiniteTensorDictCheck": [[235, 1, 1, "", "forward"]], "torchrl.envs.transforms.FlattenObservation": [[236, 1, 1, "", "forward"], [236, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.FrameSkipTransform": [[237, 1, 1, "", "forward"]], "torchrl.envs.transforms.GrayScale": [[238, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Hash": [[239, 1, 1, "", "get_input_from_hash"], [239, 1, 1, "", "reproducible_hash"], [239, 1, 1, "", "state_dict"]], "torchrl.envs.transforms.InitTracker": [[240, 1, 1, "", "forward"], [240, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.KLRewardTransform": [[241, 1, 1, "", "forward"], [241, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.LineariseRewards": [[242, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.ModuleTransform": [[243, 1, 1, "", "forward"], [243, 1, 1, "", "transform_action_spec"], [243, 1, 1, "", "transform_done_spec"], [243, 1, 1, "", "transform_observation_spec"], [243, 1, 1, "", "transform_reward_spec"], [243, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.MultiAction": [[244, 1, 1, "", "transform_input_spec"], [244, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.ObservationNorm": [[246, 1, 1, "", "init_stats"], [246, 1, 1, "", "transform_action_spec"], [246, 1, 1, "", "transform_observation_spec"], [246, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.PermuteTransform": [[248, 1, 1, "", "transform_input_spec"], [248, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.PinMemoryTransform": [[249, 1, 1, "", "forward"]], "torchrl.envs.transforms.R3MTransform": [[250, 1, 1, "", "to"]], "torchrl.envs.transforms.RandomCropTensorDict": [[251, 1, 1, "", "forward"]], "torchrl.envs.transforms.RemoveEmptySpecs": [[252, 1, 1, "", "forward"], [252, 1, 1, "", "transform_input_spec"], [252, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.RenameTransform": [[253, 1, 1, "", "forward"], [253, 1, 1, "", "transform_input_spec"], [253, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.Resize": [[254, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Reward2GoTransform": [[255, 1, 1, "", "forward"]], "torchrl.envs.transforms.RewardClipping": [[256, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardScaling": [[257, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardSum": [[258, 1, 1, "", "forward"], [258, 1, 1, "", "transform_input_spec"], [258, 1, 1, "", "transform_observation_spec"], [258, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.SelectTransform": [[259, 1, 1, "", "forward"], [259, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.SignTransform": [[260, 1, 1, "", "transform_observation_spec"], [260, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.Stack": [[262, 1, 1, "", "forward"], [262, 1, 1, "", "transform_done_spec"], [262, 1, 1, "", "transform_input_spec"], [262, 1, 1, "", "transform_observation_spec"], [262, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.StepCounter": [[263, 1, 1, "", "forward"], [263, 1, 1, "", "transform_input_spec"], [263, 1, 1, "", "transform_observation_spec"], [263, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.TargetReturn": [[264, 1, 1, "", "forward"], [264, 1, 1, "", "transform_input_spec"], [264, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TensorDictPrimer": [[265, 1, 1, "", "forward"], [265, 1, 1, "", "to"], [265, 1, 1, "", "transform_input_spec"], [265, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TimeMaxPool": [[266, 1, 1, "", "forward"], [266, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Timer": [[267, 1, 1, "", "forward"], [267, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ToTensorImage": [[268, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Tokenizer": [[269, 1, 1, "", "forward"], [269, 1, 1, "", "transform_done_spec"], [269, 1, 1, "", "transform_input_spec"], [269, 1, 1, "", "transform_observation_spec"], [269, 1, 1, "", "transform_output_spec"], [269, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.TrajCounter": [[270, 1, 1, "", "forward"], [270, 1, 1, "", "load_state_dict"], [270, 1, 1, "", "state_dict"], [270, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Transform": [[271, 1, 1, "", "clone"], [271, 1, 1, "", "close"], [271, 2, 1, "", "collector"], [271, 2, 1, "", "container"], [271, 1, 1, "", "forward"], [271, 1, 1, "", "init"], [271, 1, 1, "", "inv"], [271, 2, 1, "", "parent"], [271, 1, 1, "", "reset_parent"], [271, 1, 1, "", "set_container"], [271, 1, 1, "", "to"], [271, 1, 1, "", "transform_action_spec"], [271, 1, 1, "", "transform_done_spec"], [271, 1, 1, "", "transform_env_batch_size"], [271, 1, 1, "", "transform_env_device"], [271, 1, 1, "", "transform_input_spec"], [271, 1, 1, "", "transform_observation_spec"], [271, 1, 1, "", "transform_output_spec"], [271, 1, 1, "", "transform_reward_spec"], [271, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.TransformedEnv": [[272, 1, 1, "", "add_truncated_keys"], [272, 1, 1, "", "append_transform"], [272, 2, 1, "", "batch_locked"], [272, 2, 1, "", "batch_size"], [272, 1, 1, "", "empty_cache"], [272, 1, 1, "", "eval"], [272, 2, 1, "", "input_spec"], [272, 1, 1, "", "insert_transform"], [272, 1, 1, "", "load_state_dict"], [272, 2, 1, "", "output_spec"], [272, 1, 1, "", "rand_action"], [272, 1, 1, "", "set_missing_tolerance"], [272, 1, 1, "", "set_seed"], [272, 1, 1, "", "state_dict"], [272, 1, 1, "", "to"], [272, 1, 1, "", "train"]], "torchrl.envs.transforms.UnaryTransform": [[273, 1, 1, "", "transform_action_spec"], [273, 1, 1, "", "transform_done_spec"], [273, 1, 1, "", "transform_input_spec"], [273, 1, 1, "", "transform_observation_spec"], [273, 1, 1, "", "transform_output_spec"], [273, 1, 1, "", "transform_reward_spec"], [273, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.UnsqueezeTransform": [[274, 1, 1, "", "transform_action_spec"], [274, 1, 1, "", "transform_observation_spec"], [274, 1, 1, "", "transform_reward_spec"], [274, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.VC1Transform": [[275, 1, 1, "", "forward"], [275, 1, 1, "", "make_noload_model"], [275, 1, 1, "", "to"], [275, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VIPRewardTransform": [[276, 1, 1, "", "forward"], [276, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.VIPTransform": [[277, 1, 1, "", "to"]], "torchrl.envs.transforms.VecGymEnvTransform": [[278, 1, 1, "", "forward"], [278, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VecNorm": [[279, 1, 1, "", "build_td_for_shared_vecnorm"], [279, 1, 1, "", "forward"], [279, 1, 1, "", "freeze"], [279, 1, 1, "", "frozen_copy"], [279, 1, 1, "", "get_extra_state"], [279, 2, 1, "", "loc"], [279, 2, 1, "", "scale"], [279, 1, 1, "", "set_extra_state"], [279, 2, 1, "", "standard_normal"], [279, 1, 1, "", "to_observation_norm"], [279, 1, 1, "", "transform_observation_spec"], [279, 1, 1, "", "unfreeze"]], "torchrl.envs.transforms.VecNormV2": [[280, 1, 1, "", "clone"], [280, 1, 1, "id0", "freeze"], [280, 1, 1, "id1", "frozen_copy"], [280, 1, 1, "id2", "get_extra_state"], [280, 2, 1, "id3", "loc"], [280, 2, 1, "id4", "scale"], [280, 1, 1, "id5", "set_extra_state"], [280, 2, 1, "id6", "standard_normal"], [280, 1, 1, "", "to_observation_norm"], [280, 1, 1, "id7", "transform_observation_spec"], [280, 1, 1, "id8", "transform_output_spec"], [280, 1, 1, "id9", "transform_reward_spec"], [280, 1, 1, "id10", "unfreeze"]], "torchrl.implement_for": [[282, 1, 1, "", "get_class_that_defined_method"], [282, 1, 1, "", "import_module"], [282, 1, 1, "", "module_set"], [282, 1, 1, "", "reset"]], "torchrl.modules": [[283, 0, 1, "", "ActorCriticOperator"], [284, 0, 1, "", "ActorCriticWrapper"], [285, 0, 1, "", "ActorValueOperator"], [286, 0, 1, "", "AdditiveGaussianModule"], [287, 0, 1, "", "ConsistentDropoutModule"], [288, 0, 1, "", "ConvNet"], [289, 0, 1, "", "DTActor"], [290, 0, 1, "", "DdpgCnnActor"], [291, 0, 1, "", "DdpgCnnQNet"], [292, 0, 1, "", "DdpgMlpActor"], [293, 0, 1, "", "DdpgMlpQNet"], [294, 0, 1, "", "DecisionTransformer"], [295, 0, 1, "", "Delta"], [296, 0, 1, "", "DistributionalDQNnet"], [297, 0, 1, "", "DistributionalQValueActor"], [298, 0, 1, "", "DistributionalQValueModule"], [299, 0, 1, "", "DreamerActor"], [300, 0, 1, "", "DuelingCnnDQNet"], [301, 0, 1, "", "EGreedyModule"], [302, 0, 1, "", "GRUModule"], [303, 0, 1, "", "IndependentNormal"], [304, 0, 1, "", "LSTMModule"], [305, 0, 1, "", "MLP"], [306, 0, 1, "", "MaskedCategorical"], [307, 0, 1, "", "NormalParamExtractor"], [308, 0, 1, "", "ObsDecoder"], [309, 0, 1, "", "ObsEncoder"], [310, 0, 1, "", "OneHotCategorical"], [311, 0, 1, "", "OnlineDTActor"], [312, 0, 1, "", "OrnsteinUhlenbeckProcessModule"], [313, 0, 1, "", "QValueActor"], [314, 0, 1, "", "QValueModule"], [315, 0, 1, "", "RSSMPosterior"], [316, 0, 1, "", "RSSMPrior"], [317, 0, 1, "", "RSSMRollout"], [318, 0, 1, "", "ReparamGradientStrategy"], [319, 0, 1, "", "TanhDelta"], [320, 0, 1, "", "TanhNormal"], [321, 0, 1, "", "TruncatedNormal"], [322, 0, 1, "", "ValueOperator"], [323, 0, 1, "", "WorldModelWrapper"]], "torchrl.modules.ActorCriticOperator": [[283, 1, 1, "", "get_critic_operator"], [283, 1, 1, "", "get_policy_head"], [283, 1, 1, "", "get_value_head"], [283, 1, 1, "", "get_value_operator"]], "torchrl.modules.ActorCriticWrapper": [[284, 1, 1, "", "get_policy_head"], [284, 1, 1, "", "get_policy_operator"], [284, 1, 1, "", "get_value_head"], [284, 1, 1, "", "get_value_operator"]], "torchrl.modules.ActorValueOperator": [[285, 1, 1, "", "get_policy_head"], [285, 1, 1, "", "get_policy_operator"], [285, 1, 1, "", "get_value_head"], [285, 1, 1, "", "get_value_operator"]], "torchrl.modules.AdditiveGaussianModule": [[286, 1, 1, "", "forward"], [286, 1, 1, "", "step"]], "torchrl.modules.ConsistentDropoutModule": [[287, 1, 1, "", "forward"], [287, 1, 1, "", "make_tensordict_primer"]], "torchrl.modules.ConvNet": [[288, 1, 1, "", "default_atari_dqn"], [288, 1, 1, "", "forward"]], "torchrl.modules.DTActor": [[289, 1, 1, "", "default_config"], [289, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnActor": [[290, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnQNet": [[291, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpActor": [[292, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpQNet": [[293, 1, 1, "", "forward"]], "torchrl.modules.DecisionTransformer": [[294, 0, 1, "", "DTConfig"], [294, 1, 1, "", "forward"]], "torchrl.modules.Delta": [[295, 1, 1, "", "expand"], [295, 1, 1, "", "log_prob"], [295, 2, 1, "", "mean"], [295, 2, 1, "", "mode"], [295, 1, 1, "", "rsample"], [295, 1, 1, "", "sample"]], "torchrl.modules.DistributionalDQNnet": [[296, 1, 1, "", "forward"]], "torchrl.modules.DistributionalQValueModule": [[298, 1, 1, "", "forward"]], "torchrl.modules.DreamerActor": [[299, 1, 1, "", "forward"]], "torchrl.modules.DuelingCnnDQNet": [[300, 1, 1, "", "forward"]], "torchrl.modules.EGreedyModule": [[301, 1, 1, "", "forward"], [301, 1, 1, "", "step"]], "torchrl.modules.GRUModule": [[302, 1, 1, "", "forward"], [302, 1, 1, "", "make_cudnn_based"], [302, 1, 1, "", "make_python_based"], [302, 1, 1, "id0", "make_tensordict_primer"], [302, 1, 1, "", "set_recurrent_mode"]], "torchrl.modules.IndependentNormal": [[303, 2, 1, "", "mode"]], "torchrl.modules.LSTMModule": [[304, 1, 1, "", "forward"], [304, 1, 1, "", "make_cudnn_based"], [304, 1, 1, "", "make_python_based"], [304, 1, 1, "id0", "make_tensordict_primer"], [304, 1, 1, "", "set_recurrent_mode"]], "torchrl.modules.MLP": [[305, 1, 1, "", "forward"]], "torchrl.modules.MaskedCategorical": [[306, 1, 1, "", "entropy"], [306, 1, 1, "", "log_prob"], [306, 2, 1, "", "padding_value"], [306, 1, 1, "", "sample"]], "torchrl.modules.NormalParamExtractor": [[307, 1, 1, "", "forward"]], "torchrl.modules.ObsDecoder": [[308, 1, 1, "", "forward"]], "torchrl.modules.ObsEncoder": [[309, 1, 1, "", "forward"]], "torchrl.modules.OneHotCategorical": [[310, 1, 1, "", "entropy"], [310, 1, 1, "", "log_prob"], [310, 2, 1, "", "mode"], [310, 1, 1, "", "rsample"], [310, 1, 1, "", "sample"]], "torchrl.modules.OnlineDTActor": [[311, 1, 1, "", "default_config"], [311, 1, 1, "", "forward"]], "torchrl.modules.OrnsteinUhlenbeckProcessModule": [[312, 1, 1, "", "forward"], [312, 1, 1, "", "step"]], "torchrl.modules.QValueModule": [[314, 1, 1, "", "forward"]], "torchrl.modules.RSSMPosterior": [[315, 1, 1, "", "forward"]], "torchrl.modules.RSSMPrior": [[316, 1, 1, "", "forward"]], "torchrl.modules.RSSMRollout": [[317, 1, 1, "", "forward"]], "torchrl.modules.TanhDelta": [[319, 2, 1, "", "mean"], [319, 2, 1, "", "mode"]], "torchrl.modules.TanhNormal": [[320, 1, 1, "", "get_mode"], [320, 2, 1, "", "mean"], [320, 2, 1, "", "mode"], [320, 2, 1, "", "support"]], "torchrl.modules.TruncatedNormal": [[321, 1, 1, "", "log_prob"], [321, 2, 1, "", "mode"]], "torchrl.modules.WorldModelWrapper": [[323, 1, 1, "", "get_reward_operator"], [323, 1, 1, "", "get_transition_model_operator"]], "torchrl.modules.llm": [[324, 0, 1, "", "AsyncVLLM"], [325, 0, 1, "", "ChatHistory"], [326, 0, 1, "", "LLMWrapperBase"], [327, 0, 1, "", "LogProbs"], [328, 0, 1, "", "Masks"], [329, 0, 1, "", "RemoteTransformersWrapper"], [330, 0, 1, "", "Text"], [331, 0, 1, "", "Tokens"], [332, 0, 1, "", "TransformersWrapper"], [333, 0, 1, "", "make_async_vllm_engine"], [334, 0, 1, "", "make_vllm_worker"], [335, 0, 1, "", "stateless_init_process_group"], [336, 0, 1, "", "stateless_init_process_group_async"], [337, 0, 1, "", "vLLMWrapper"]], "torchrl.modules.llm.AsyncVLLM": [[324, 1, 1, "", "collective_rpc"], [324, 1, 1, "", "create_load_balancer"], [324, 1, 1, "", "from_pretrained"], [324, 1, 1, "", "generate"], [324, 1, 1, "", "get_cache_usage"], [324, 1, 1, "", "get_master_address"], [324, 1, 1, "", "get_master_port"], [324, 1, 1, "", "get_model_metadata"], [324, 1, 1, "", "get_num_unfinished_requests"], [324, 1, 1, "", "get_random_actor_index"], [324, 1, 1, "", "get_tp_size"], [324, 1, 1, "", "init_weight_update_group"], [324, 1, 1, "", "launch"], [324, 1, 1, "", "shutdown"], [324, 1, 1, "", "update_weights"]], "torchrl.modules.llm.ChatHistory": [[325, 1, 1, "", "cat"], [325, 1, 1, "", "default_spec"], [325, 2, 1, "", "device"], [325, 1, 1, "", "dumps"], [325, 1, 1, "", "fields"], [325, 1, 1, "", "from_any"], [325, 1, 1, "", "from_dataclass"], [325, 1, 1, "", "from_h5"], [325, 1, 1, "", "from_modules"], [325, 1, 1, "", "from_namedtuple"], [325, 1, 1, "", "from_pytree"], [325, 1, 1, "", "from_remote_init"], [325, 1, 1, "", "from_struct_array"], [325, 1, 1, "", "from_tensordict"], [325, 1, 1, "", "from_tuple"], [325, 1, 1, "", "fromkeys"], [325, 1, 1, "", "get"], [325, 1, 1, "", "lazy_stack"], [325, 1, 1, "", "load"], [325, 1, 1, "", "load_"], [325, 1, 1, "", "load_memmap"], [325, 1, 1, "", "load_state_dict"], [325, 1, 1, "", "maybe_dense_stack"], [325, 1, 1, "", "memmap"], [325, 1, 1, "", "memmap_"], [325, 1, 1, "", "memmap_like"], [325, 1, 1, "", "memmap_refresh_"], [325, 1, 1, "", "save"], [325, 1, 1, "", "set"], [325, 1, 1, "", "stack"], [325, 1, 1, "", "state_dict"], [325, 1, 1, "", "to_tensordict"], [325, 1, 1, "", "to_text"], [325, 1, 1, "", "to_tokens"], [325, 1, 1, "", "unbind"]], "torchrl.modules.llm.LLMWrapperBase": [[326, 1, 1, "", "add_module"], [326, 1, 1, "", "apply"], [326, 2, 1, "", "batching"], [326, 1, 1, "", "bfloat16"], [326, 1, 1, "", "buffers"], [326, 1, 1, "", "children"], [326, 1, 1, "", "cleanup_batching"], [326, 2, 1, "", "collector"], [326, 1, 1, "", "compile"], [326, 1, 1, "", "cpu"], [326, 1, 1, "", "cuda"], [326, 1, 1, "", "double"], [326, 1, 1, "", "eval"], [326, 1, 1, "", "extra_repr"], [326, 1, 1, "", "float"], [326, 1, 1, "", "forward"], [326, 1, 1, "", "get_batching_state"], [326, 1, 1, "", "get_buffer"], [326, 1, 1, "", "get_dist"], [326, 1, 1, "", "get_extra_state"], [326, 1, 1, "", "get_new_version"], [326, 1, 1, "", "get_parameter"], [326, 1, 1, "", "get_submodule"], [326, 1, 1, "", "half"], [326, 1, 1, "", "ipu"], [326, 1, 1, "", "is_tdmodule_compatible"], [326, 1, 1, "", "load_state_dict"], [326, 1, 1, "", "modules"], [326, 1, 1, "", "mtia"], [326, 1, 1, "", "named_buffers"], [326, 1, 1, "", "named_children"], [326, 1, 1, "", "named_modules"], [326, 1, 1, "", "named_parameters"], [326, 1, 1, "", "parameters"], [326, 1, 1, "", "register_backward_hook"], [326, 1, 1, "", "register_buffer"], [326, 1, 1, "", "register_collector"], [326, 1, 1, "", "register_forward_hook"], [326, 1, 1, "", "register_forward_pre_hook"], [326, 1, 1, "", "register_full_backward_hook"], [326, 1, 1, "", "register_full_backward_pre_hook"], [326, 1, 1, "", "register_load_state_dict_post_hook"], [326, 1, 1, "", "register_load_state_dict_pre_hook"], [326, 1, 1, "", "register_module"], [326, 1, 1, "", "register_parameter"], [326, 1, 1, "", "register_state_dict_post_hook"], [326, 1, 1, "", "register_state_dict_pre_hook"], [326, 1, 1, "", "requires_grad_"], [326, 1, 1, "", "reset_out_keys"], [326, 1, 1, "", "reset_parameters_recursive"], [326, 1, 1, "", "select_out_keys"], [326, 1, 1, "", "set_extra_state"], [326, 1, 1, "", "set_submodule"], [326, 1, 1, "", "share_memory"], [326, 1, 1, "", "state_dict"], [326, 1, 1, "", "to"], [326, 1, 1, "", "to_empty"], [326, 1, 1, "", "train"], [326, 1, 1, "", "type"], [326, 1, 1, "", "xpu"], [326, 1, 1, "", "zero_grad"]], "torchrl.modules.llm.LogProbs": [[327, 1, 1, "", "cat"], [327, 1, 1, "", "default_spec"], [327, 2, 1, "", "device"], [327, 1, 1, "", "dumps"], [327, 1, 1, "", "fields"], [327, 1, 1, "", "from_any"], [327, 1, 1, "", "from_dataclass"], [327, 1, 1, "", "from_h5"], [327, 1, 1, "", "from_modules"], [327, 1, 1, "", "from_namedtuple"], [327, 1, 1, "", "from_pytree"], [327, 1, 1, "", "from_remote_init"], [327, 1, 1, "", "from_struct_array"], [327, 1, 1, "", "from_tensordict"], [327, 1, 1, "", "from_tuple"], [327, 1, 1, "", "fromkeys"], [327, 1, 1, "", "get"], [327, 1, 1, "", "lazy_stack"], [327, 1, 1, "", "load"], [327, 1, 1, "", "load_"], [327, 1, 1, "", "load_memmap"], [327, 1, 1, "", "load_state_dict"], [327, 1, 1, "", "maybe_dense_stack"], [327, 1, 1, "", "memmap"], [327, 1, 1, "", "memmap_"], [327, 1, 1, "", "memmap_like"], [327, 1, 1, "", "memmap_refresh_"], [327, 1, 1, "", "save"], [327, 1, 1, "", "set"], [327, 1, 1, "", "stack"], [327, 1, 1, "", "state_dict"], [327, 1, 1, "", "to_tensordict"], [327, 1, 1, "", "unbind"]], "torchrl.modules.llm.Masks": [[328, 1, 1, "", "cat"], [328, 1, 1, "", "default_spec"], [328, 2, 1, "", "device"], [328, 1, 1, "", "dumps"], [328, 1, 1, "", "fields"], [328, 1, 1, "", "from_any"], [328, 1, 1, "", "from_dataclass"], [328, 1, 1, "", "from_h5"], [328, 1, 1, "", "from_modules"], [328, 1, 1, "", "from_namedtuple"], [328, 1, 1, "", "from_pytree"], [328, 1, 1, "", "from_remote_init"], [328, 1, 1, "", "from_struct_array"], [328, 1, 1, "", "from_tensordict"], [328, 1, 1, "", "from_tuple"], [328, 1, 1, "", "fromkeys"], [328, 1, 1, "", "get"], [328, 1, 1, "", "lazy_stack"], [328, 1, 1, "", "load"], [328, 1, 1, "", "load_"], [328, 1, 1, "", "load_memmap"], [328, 1, 1, "", "load_state_dict"], [328, 1, 1, "", "maybe_dense_stack"], [328, 1, 1, "", "memmap"], [328, 1, 1, "", "memmap_"], [328, 1, 1, "", "memmap_like"], [328, 1, 1, "", "memmap_refresh_"], [328, 1, 1, "", "save"], [328, 1, 1, "", "set"], [328, 1, 1, "", "stack"], [328, 1, 1, "", "state_dict"], [328, 1, 1, "", "to_tensordict"], [328, 1, 1, "", "unbind"]], "torchrl.modules.llm.RemoteTransformersWrapper": [[329, 2, 1, "", "batching"], [329, 1, 1, "", "cleanup_batching"], [329, 2, 1, "", "collector"], [329, 2, 1, "", "device"], [329, 2, 1, "", "dist_params_keys"], [329, 2, 1, "", "dist_sample_keys"], [329, 2, 1, "", "generate"], [329, 1, 1, "", "get_batching_state"], [329, 1, 1, "", "get_dist"], [329, 1, 1, "", "get_dist_with_prompt_mask"], [329, 1, 1, "", "get_new_version"], [329, 2, 1, "", "in_keys"], [329, 2, 1, "", "inplace"], [329, 2, 1, "", "layout"], [329, 1, 1, "", "log_prob"], [329, 2, 1, "", "log_prob_keys"], [329, 2, 1, "", "log_probs_key"], [329, 2, 1, "", "masks_key"], [329, 2, 1, "", "num_samples"], [329, 2, 1, "", "out_keys"], [329, 2, 1, "", "pad_output"], [329, 2, 1, "", "text_key"], [329, 2, 1, "", "tokens_key"]], "torchrl.modules.llm.Text": [[330, 1, 1, "", "cat"], [330, 1, 1, "", "default_spec"], [330, 2, 1, "", "device"], [330, 1, 1, "", "dumps"], [330, 1, 1, "", "fields"], [330, 1, 1, "", "from_any"], [330, 1, 1, "", "from_dataclass"], [330, 1, 1, "", "from_h5"], [330, 1, 1, "", "from_modules"], [330, 1, 1, "", "from_namedtuple"], [330, 1, 1, "", "from_pytree"], [330, 1, 1, "", "from_remote_init"], [330, 1, 1, "", "from_struct_array"], [330, 1, 1, "", "from_tensordict"], [330, 1, 1, "", "from_tuple"], [330, 1, 1, "", "fromkeys"], [330, 1, 1, "", "get"], [330, 1, 1, "", "lazy_stack"], [330, 1, 1, "", "load"], [330, 1, 1, "", "load_"], [330, 1, 1, "", "load_memmap"], [330, 1, 1, "", "load_state_dict"], [330, 1, 1, "", "maybe_dense_stack"], [330, 1, 1, "", "memmap"], [330, 1, 1, "", "memmap_"], [330, 1, 1, "", "memmap_like"], [330, 1, 1, "", "memmap_refresh_"], [330, 1, 1, "", "save"], [330, 1, 1, "", "set"], [330, 1, 1, "", "stack"], [330, 1, 1, "", "state_dict"], [330, 1, 1, "", "to_history"], [330, 1, 1, "", "to_tensordict"], [330, 1, 1, "", "to_tokens"], [330, 1, 1, "", "unbind"]], "torchrl.modules.llm.Tokens": [[331, 1, 1, "", "cat"], [331, 1, 1, "", "default_spec"], [331, 2, 1, "", "device"], [331, 1, 1, "", "dumps"], [331, 1, 1, "", "fields"], [331, 1, 1, "", "from_any"], [331, 1, 1, "", "from_dataclass"], [331, 1, 1, "", "from_h5"], [331, 1, 1, "", "from_modules"], [331, 1, 1, "", "from_namedtuple"], [331, 1, 1, "", "from_pytree"], [331, 1, 1, "", "from_remote_init"], [331, 1, 1, "", "from_struct_array"], [331, 1, 1, "", "from_tensordict"], [331, 1, 1, "", "from_tuple"], [331, 1, 1, "", "fromkeys"], [331, 1, 1, "", "get"], [331, 1, 1, "", "lazy_stack"], [331, 1, 1, "", "load"], [331, 1, 1, "", "load_"], [331, 1, 1, "", "load_memmap"], [331, 1, 1, "", "load_state_dict"], [331, 1, 1, "", "maybe_dense_stack"], [331, 1, 1, "", "memmap"], [331, 1, 1, "", "memmap_"], [331, 1, 1, "", "memmap_like"], [331, 1, 1, "", "memmap_refresh_"], [331, 1, 1, "", "save"], [331, 1, 1, "", "set"], [331, 1, 1, "", "stack"], [331, 1, 1, "", "state_dict"], [331, 1, 1, "", "to_history"], [331, 1, 1, "", "to_tensordict"], [331, 1, 1, "", "to_text"], [331, 1, 1, "", "unbind"]], "torchrl.modules.llm.TransformersWrapper": [[332, 1, 1, "", "add_module"], [332, 1, 1, "", "apply"], [332, 2, 1, "", "batching"], [332, 1, 1, "", "bfloat16"], [332, 1, 1, "", "buffers"], [332, 1, 1, "", "children"], [332, 1, 1, "", "cleanup_batching"], [332, 2, 1, "", "collector"], [332, 1, 1, "", "compile"], [332, 1, 1, "", "cpu"], [332, 1, 1, "", "cuda"], [332, 1, 1, "", "double"], [332, 1, 1, "", "eval"], [332, 1, 1, "", "extra_repr"], [332, 1, 1, "", "float"], [332, 1, 1, "", "forward"], [332, 1, 1, "", "get_batching_state"], [332, 1, 1, "", "get_buffer"], [332, 1, 1, "", "get_dist"], [332, 1, 1, "", "get_extra_state"], [332, 1, 1, "", "get_new_version"], [332, 1, 1, "", "get_parameter"], [332, 1, 1, "", "get_submodule"], [332, 1, 1, "", "half"], [332, 1, 1, "", "ipu"], [332, 1, 1, "", "is_tdmodule_compatible"], [332, 1, 1, "", "load_state_dict"], [332, 1, 1, "", "modules"], [332, 1, 1, "", "mtia"], [332, 1, 1, "", "named_buffers"], [332, 1, 1, "", "named_children"], [332, 1, 1, "", "named_modules"], [332, 1, 1, "", "named_parameters"], [332, 1, 1, "", "parameters"], [332, 1, 1, "", "register_backward_hook"], [332, 1, 1, "", "register_buffer"], [332, 1, 1, "", "register_collector"], [332, 1, 1, "", "register_forward_hook"], [332, 1, 1, "", "register_forward_pre_hook"], [332, 1, 1, "", "register_full_backward_hook"], [332, 1, 1, "", "register_full_backward_pre_hook"], [332, 1, 1, "", "register_load_state_dict_post_hook"], [332, 1, 1, "", "register_load_state_dict_pre_hook"], [332, 1, 1, "", "register_module"], [332, 1, 1, "", "register_parameter"], [332, 1, 1, "", "register_state_dict_post_hook"], [332, 1, 1, "", "register_state_dict_pre_hook"], [332, 1, 1, "", "repeat_interleave_causal"], [332, 1, 1, "", "requires_grad_"], [332, 1, 1, "", "reset_out_keys"], [332, 1, 1, "", "reset_parameters_recursive"], [332, 1, 1, "", "select_out_keys"], [332, 1, 1, "", "set_extra_state"], [332, 1, 1, "", "set_submodule"], [332, 1, 1, "", "share_memory"], [332, 1, 1, "", "state_dict"], [332, 1, 1, "", "to"], [332, 1, 1, "", "to_empty"], [332, 1, 1, "", "train"], [332, 1, 1, "", "type"], [332, 1, 1, "", "xpu"], [332, 1, 1, "", "zero_grad"]], "torchrl.modules.llm.vLLMWrapper": [[337, 1, 1, "", "add_module"], [337, 1, 1, "", "apply"], [337, 2, 1, "", "batching"], [337, 1, 1, "", "bfloat16"], [337, 1, 1, "", "buffers"], [337, 1, 1, "", "children"], [337, 1, 1, "", "cleanup_batching"], [337, 2, 1, "", "collector"], [337, 1, 1, "", "compile"], [337, 1, 1, "", "cpu"], [337, 1, 1, "", "cuda"], [337, 1, 1, "", "double"], [337, 1, 1, "", "eval"], [337, 1, 1, "", "extra_repr"], [337, 1, 1, "", "float"], [337, 1, 1, "", "forward"], [337, 1, 1, "", "get_batching_state"], [337, 1, 1, "", "get_buffer"], [337, 1, 1, "", "get_dist"], [337, 1, 1, "", "get_dist_with_prompt_mask"], [337, 1, 1, "", "get_extra_state"], [337, 1, 1, "", "get_new_version"], [337, 1, 1, "", "get_parameter"], [337, 1, 1, "", "get_submodule"], [337, 1, 1, "", "half"], [337, 1, 1, "", "ipu"], [337, 1, 1, "", "is_tdmodule_compatible"], [337, 1, 1, "", "load_state_dict"], [337, 1, 1, "", "modules"], [337, 1, 1, "", "mtia"], [337, 1, 1, "", "named_buffers"], [337, 1, 1, "", "named_children"], [337, 1, 1, "", "named_modules"], [337, 1, 1, "", "named_parameters"], [337, 1, 1, "", "parameters"], [337, 1, 1, "", "register_backward_hook"], [337, 1, 1, "", "register_buffer"], [337, 1, 1, "", "register_collector"], [337, 1, 1, "", "register_forward_hook"], [337, 1, 1, "", "register_forward_pre_hook"], [337, 1, 1, "", "register_full_backward_hook"], [337, 1, 1, "", "register_full_backward_pre_hook"], [337, 1, 1, "", "register_load_state_dict_post_hook"], [337, 1, 1, "", "register_load_state_dict_pre_hook"], [337, 1, 1, "", "register_module"], [337, 1, 1, "", "register_parameter"], [337, 1, 1, "", "register_state_dict_post_hook"], [337, 1, 1, "", "register_state_dict_pre_hook"], [337, 1, 1, "", "requires_grad_"], [337, 1, 1, "", "reset_out_keys"], [337, 1, 1, "", "reset_parameters_recursive"], [337, 1, 1, "", "select_out_keys"], [337, 1, 1, "", "set_extra_state"], [337, 1, 1, "", "set_submodule"], [337, 1, 1, "", "set_tokenizer"], [337, 1, 1, "", "share_memory"], [337, 1, 1, "", "state_dict"], [337, 1, 1, "", "to"], [337, 1, 1, "", "to_empty"], [337, 1, 1, "", "train"], [337, 1, 1, "", "type"], [337, 1, 1, "", "xpu"], [337, 1, 1, "", "zero_grad"]], "torchrl.modules.models.utils": [[338, 0, 1, "", "SquashDims"]], "torchrl.modules.models.utils.SquashDims": [[338, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module": [[339, 0, 1, "", "Actor"], [340, 0, 1, "", "MultiStepActorWrapper"], [341, 0, 1, "", "ProbabilisticActor"], [342, 0, 1, "", "RandomPolicy"], [343, 0, 1, "", "SafeModule"], [344, 0, 1, "", "SafeProbabilisticModule"], [345, 0, 1, "", "SafeProbabilisticTensorDictSequential"], [346, 0, 1, "", "SafeSequential"], [347, 0, 1, "", "TanhModule"]], "torchrl.modules.tensordict_module.MultiStepActorWrapper": [[340, 1, 1, "", "forward"], [340, 2, 1, "", "init_key"]], "torchrl.modules.tensordict_module.SafeModule": [[343, 1, 1, "", "random"], [343, 1, 1, "", "random_sample"], [343, 1, 1, "", "to"]], "torchrl.modules.tensordict_module.SafeProbabilisticModule": [[344, 1, 1, "", "random"], [344, 1, 1, "", "random_sample"]], "torchrl.modules.tensordict_module.TanhModule": [[347, 1, 1, "", "forward"]], "torchrl.objectives": [[348, 0, 1, "", "A2CLoss"], [349, 0, 1, "", "CQLLoss"], [350, 0, 1, "", "ClipPPOLoss"], [351, 0, 1, "", "CrossQLoss"], [352, 0, 1, "", "DDPGLoss"], [353, 0, 1, "", "DQNLoss"], [354, 0, 1, "", "DTLoss"], [355, 0, 1, "", "DiscreteCQLLoss"], [356, 0, 1, "", "DiscreteIQLLoss"], [357, 0, 1, "", "DiscreteSACLoss"], [358, 0, 1, "", "DistributionalDQNLoss"], [359, 0, 1, "", "DreamerActorLoss"], [360, 0, 1, "", "DreamerModelLoss"], [361, 0, 1, "", "DreamerValueLoss"], [362, 0, 1, "", "GAILLoss"], [363, 0, 1, "", "IQLLoss"], [364, 0, 1, "", "KLPENPPOLoss"], [365, 0, 1, "", "LossModule"], [366, 0, 1, "", "OnlineDTLoss"], [367, 0, 1, "", "PPOLoss"], [368, 0, 1, "", "REDQLoss"], [369, 0, 1, "", "ReinforceLoss"], [370, 0, 1, "", "SACLoss"], [371, 0, 1, "", "TD3BCLoss"], [372, 0, 1, "", "TD3Loss"], [373, 0, 1, "", "ValueEstimators"], [374, 0, 1, "", "add_random_module"]], "torchrl.objectives.A2CLoss": [[348, 4, 1, "", "default_keys"], [348, 1, 1, "", "forward"], [348, 2, 1, "", "functional"], [348, 1, 1, "", "loss_critic"], [348, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.CQLLoss": [[349, 4, 1, "", "default_keys"], [349, 1, 1, "", "forward"], [349, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ClipPPOLoss": [[350, 1, 1, "", "forward"]], "torchrl.objectives.CrossQLoss": [[351, 1, 1, "", "actor_loss"], [351, 1, 1, "", "alpha_loss"], [351, 4, 1, "", "default_keys"], [351, 1, 1, "", "forward"], [351, 1, 1, "", "load_state_dict"], [351, 1, 1, "", "make_value_estimator"], [351, 1, 1, "", "maybe_init_target_entropy"], [351, 1, 1, "", "qvalue_loss"], [351, 1, 1, "", "set_keys"], [351, 1, 1, "", "state_dict"], [351, 2, 1, "", "target_entropy_buffer"]], "torchrl.objectives.DDPGLoss": [[352, 4, 1, "", "default_keys"], [352, 1, 1, "", "forward"], [352, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DQNLoss": [[353, 4, 1, "", "default_keys"], [353, 1, 1, "", "forward"], [353, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DTLoss": [[354, 4, 1, "", "default_keys"], [354, 1, 1, "", "forward"]], "torchrl.objectives.DiscreteCQLLoss": [[355, 4, 1, "", "default_keys"], [355, 1, 1, "", "forward"], [355, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DiscreteIQLLoss": [[356, 4, 1, "", "default_keys"], [356, 1, 1, "", "forward"]], "torchrl.objectives.DiscreteSACLoss": [[357, 1, 1, "", "alpha_loss"], [357, 4, 1, "", "default_keys"], [357, 1, 1, "", "forward"], [357, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DistributionalDQNLoss": [[358, 4, 1, "", "default_keys"], [358, 1, 1, "", "forward"], [358, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerActorLoss": [[359, 4, 1, "", "default_keys"], [359, 1, 1, "", "forward"], [359, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerModelLoss": [[360, 4, 1, "", "default_keys"], [360, 1, 1, "", "forward"]], "torchrl.objectives.DreamerValueLoss": [[361, 4, 1, "", "default_keys"], [361, 1, 1, "", "forward"]], "torchrl.objectives.GAILLoss": [[362, 4, 1, "", "default_keys"], [362, 1, 1, "", "forward"]], "torchrl.objectives.IQLLoss": [[363, 4, 1, "", "default_keys"], [363, 1, 1, "", "forward"], [363, 1, 1, "", "loss_value_diff"], [363, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.KLPENPPOLoss": [[364, 1, 1, "", "forward"]], "torchrl.objectives.LossModule": [[365, 1, 1, "", "convert_to_functional"], [365, 1, 1, "", "forward"], [365, 1, 1, "", "from_stateful_net"], [365, 2, 1, "", "functional"], [365, 1, 1, "", "get_stateful_net"], [365, 1, 1, "", "make_value_estimator"], [365, 1, 1, "", "named_parameters"], [365, 1, 1, "", "parameters"], [365, 1, 1, "", "reset_parameters_recursive"], [365, 1, 1, "", "set_keys"], [365, 2, 1, "", "value_estimator"], [365, 2, 1, "", "vmap_randomness"]], "torchrl.objectives.OnlineDTLoss": [[366, 4, 1, "", "default_keys"], [366, 1, 1, "", "forward"]], "torchrl.objectives.PPOLoss": [[367, 4, 1, "", "default_keys"], [367, 1, 1, "", "forward"], [367, 2, 1, "", "functional"], [367, 1, 1, "", "loss_critic"], [367, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.REDQLoss": [[368, 4, 1, "", "default_keys"], [368, 1, 1, "", "forward"], [368, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ReinforceLoss": [[369, 4, 1, "", "default_keys"], [369, 1, 1, "", "forward"], [369, 2, 1, "", "functional"], [369, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.SACLoss": [[370, 1, 1, "", "alpha_loss"], [370, 4, 1, "", "default_keys"], [370, 1, 1, "", "forward"], [370, 1, 1, "", "load_state_dict"], [370, 1, 1, "", "make_value_estimator"], [370, 1, 1, "", "state_dict"]], "torchrl.objectives.TD3BCLoss": [[371, 1, 1, "", "actor_loss"], [371, 4, 1, "", "default_keys"], [371, 1, 1, "", "forward"], [371, 1, 1, "", "make_value_estimator"], [371, 1, 1, "", "qvalue_loss"]], "torchrl.objectives.TD3Loss": [[372, 4, 1, "", "default_keys"], [372, 1, 1, "", "forward"], [372, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.llm": [[375, 0, 1, "", "CISPOLoss"], [376, 0, 1, "", "CISPOLossOutput"], [377, 0, 1, "", "DAPO"], [378, 0, 1, "", "DAPOLossOutput"], [379, 0, 1, "", "GRPOLoss"], [380, 0, 1, "", "GRPOLossOutput"], [381, 0, 1, "", "LLMLossOutput"], [382, 0, 1, "", "MCAdvantage"], [383, 0, 1, "", "SFTLoss"], [384, 0, 1, "", "SFTLossOutput"]], "torchrl.objectives.llm.CISPOLoss": [[375, 1, 1, "", "add_module"], [375, 1, 1, "", "apply"], [375, 1, 1, "", "bfloat16"], [375, 1, 1, "", "buffers"], [375, 1, 1, "", "children"], [375, 1, 1, "", "compile"], [375, 1, 1, "", "convert_to_functional"], [375, 1, 1, "", "cpu"], [375, 1, 1, "", "cuda"], [375, 1, 1, "", "double"], [375, 1, 1, "", "eval"], [375, 1, 1, "", "extra_repr"], [375, 1, 1, "", "float"], [375, 1, 1, "", "forward"], [375, 1, 1, "", "from_stateful_net"], [375, 2, 1, "", "functional"], [375, 1, 1, "", "get_buffer"], [375, 1, 1, "", "get_extra_state"], [375, 1, 1, "", "get_parameter"], [375, 1, 1, "", "get_stateful_net"], [375, 1, 1, "", "get_submodule"], [375, 1, 1, "", "half"], [375, 1, 1, "", "ipu"], [375, 1, 1, "", "is_tdmodule_compatible"], [375, 1, 1, "", "load_state_dict"], [375, 1, 1, "", "make_value_estimator"], [375, 1, 1, "", "modules"], [375, 1, 1, "", "mtia"], [375, 1, 1, "", "named_buffers"], [375, 1, 1, "", "named_children"], [375, 1, 1, "", "named_modules"], [375, 1, 1, "", "named_parameters"], [375, 4, 1, "", "output_type"], [375, 1, 1, "", "parameters"], [375, 1, 1, "", "register_backward_hook"], [375, 1, 1, "", "register_buffer"], [375, 1, 1, "", "register_forward_hook"], [375, 1, 1, "", "register_forward_pre_hook"], [375, 1, 1, "", "register_full_backward_hook"], [375, 1, 1, "", "register_full_backward_pre_hook"], [375, 1, 1, "", "register_load_state_dict_post_hook"], [375, 1, 1, "", "register_load_state_dict_pre_hook"], [375, 1, 1, "", "register_module"], [375, 1, 1, "", "register_parameter"], [375, 1, 1, "", "register_state_dict_post_hook"], [375, 1, 1, "", "register_state_dict_pre_hook"], [375, 1, 1, "", "requires_grad_"], [375, 1, 1, "", "reset_out_keys"], [375, 1, 1, "", "reset_parameters_recursive"], [375, 1, 1, "", "select_out_keys"], [375, 1, 1, "", "set_extra_state"], [375, 1, 1, "", "set_keys"], [375, 1, 1, "", "set_submodule"], [375, 1, 1, "", "share_memory"], [375, 1, 1, "", "state_dict"], [375, 2, 1, "", "tensor_keys"], [375, 1, 1, "", "to"], [375, 1, 1, "", "to_empty"], [375, 1, 1, "", "train"], [375, 1, 1, "", "type"], [375, 2, 1, "", "value_estimator"], [375, 2, 1, "", "vmap_randomness"], [375, 1, 1, "", "xpu"], [375, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.CISPOLossOutput": [[376, 1, 1, "", "cat"], [376, 2, 1, "", "device"], [376, 1, 1, "", "dumps"], [376, 1, 1, "", "fields"], [376, 1, 1, "", "from_any"], [376, 1, 1, "", "from_dataclass"], [376, 1, 1, "", "from_h5"], [376, 1, 1, "", "from_modules"], [376, 1, 1, "", "from_namedtuple"], [376, 1, 1, "", "from_pytree"], [376, 1, 1, "", "from_remote_init"], [376, 1, 1, "", "from_struct_array"], [376, 1, 1, "", "from_tensordict"], [376, 1, 1, "", "from_tuple"], [376, 1, 1, "", "fromkeys"], [376, 1, 1, "", "get"], [376, 1, 1, "", "lazy_stack"], [376, 1, 1, "", "load"], [376, 1, 1, "", "load_"], [376, 1, 1, "", "load_memmap"], [376, 1, 1, "", "load_state_dict"], [376, 1, 1, "", "maybe_dense_stack"], [376, 1, 1, "", "memmap"], [376, 1, 1, "", "memmap_"], [376, 1, 1, "", "memmap_like"], [376, 1, 1, "", "memmap_refresh_"], [376, 1, 1, "", "save"], [376, 1, 1, "", "set"], [376, 1, 1, "", "stack"], [376, 1, 1, "", "state_dict"], [376, 1, 1, "", "to_tensordict"], [376, 1, 1, "", "unbind"]], "torchrl.objectives.llm.DAPO": [[377, 1, 1, "", "add_module"], [377, 1, 1, "", "apply"], [377, 1, 1, "", "bfloat16"], [377, 1, 1, "", "buffers"], [377, 1, 1, "", "children"], [377, 1, 1, "", "compile"], [377, 1, 1, "", "convert_to_functional"], [377, 1, 1, "", "cpu"], [377, 1, 1, "", "cuda"], [377, 1, 1, "", "double"], [377, 1, 1, "", "eval"], [377, 1, 1, "", "extra_repr"], [377, 1, 1, "", "float"], [377, 1, 1, "", "forward"], [377, 1, 1, "", "from_stateful_net"], [377, 2, 1, "", "functional"], [377, 1, 1, "", "get_buffer"], [377, 1, 1, "", "get_extra_state"], [377, 1, 1, "", "get_parameter"], [377, 1, 1, "", "get_stateful_net"], [377, 1, 1, "", "get_submodule"], [377, 1, 1, "", "half"], [377, 1, 1, "", "ipu"], [377, 1, 1, "", "is_tdmodule_compatible"], [377, 1, 1, "", "load_state_dict"], [377, 1, 1, "", "make_value_estimator"], [377, 1, 1, "", "modules"], [377, 1, 1, "", "mtia"], [377, 1, 1, "", "named_buffers"], [377, 1, 1, "", "named_children"], [377, 1, 1, "", "named_modules"], [377, 1, 1, "", "named_parameters"], [377, 4, 1, "", "output_type"], [377, 1, 1, "", "parameters"], [377, 1, 1, "", "register_backward_hook"], [377, 1, 1, "", "register_buffer"], [377, 1, 1, "", "register_forward_hook"], [377, 1, 1, "", "register_forward_pre_hook"], [377, 1, 1, "", "register_full_backward_hook"], [377, 1, 1, "", "register_full_backward_pre_hook"], [377, 1, 1, "", "register_load_state_dict_post_hook"], [377, 1, 1, "", "register_load_state_dict_pre_hook"], [377, 1, 1, "", "register_module"], [377, 1, 1, "", "register_parameter"], [377, 1, 1, "", "register_state_dict_post_hook"], [377, 1, 1, "", "register_state_dict_pre_hook"], [377, 1, 1, "", "requires_grad_"], [377, 1, 1, "", "reset_out_keys"], [377, 1, 1, "", "reset_parameters_recursive"], [377, 1, 1, "", "select_out_keys"], [377, 1, 1, "", "set_extra_state"], [377, 1, 1, "", "set_keys"], [377, 1, 1, "", "set_submodule"], [377, 1, 1, "", "share_memory"], [377, 1, 1, "", "state_dict"], [377, 2, 1, "", "tensor_keys"], [377, 1, 1, "", "to"], [377, 1, 1, "", "to_empty"], [377, 1, 1, "", "train"], [377, 1, 1, "", "type"], [377, 2, 1, "", "value_estimator"], [377, 2, 1, "", "vmap_randomness"], [377, 1, 1, "", "xpu"], [377, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.DAPOLossOutput": [[378, 1, 1, "", "cat"], [378, 2, 1, "", "device"], [378, 1, 1, "", "dumps"], [378, 1, 1, "", "fields"], [378, 1, 1, "", "from_any"], [378, 1, 1, "", "from_dataclass"], [378, 1, 1, "", "from_h5"], [378, 1, 1, "", "from_modules"], [378, 1, 1, "", "from_namedtuple"], [378, 1, 1, "", "from_pytree"], [378, 1, 1, "", "from_remote_init"], [378, 1, 1, "", "from_struct_array"], [378, 1, 1, "", "from_tensordict"], [378, 1, 1, "", "from_tuple"], [378, 1, 1, "", "fromkeys"], [378, 1, 1, "", "get"], [378, 1, 1, "", "lazy_stack"], [378, 1, 1, "", "load"], [378, 1, 1, "", "load_"], [378, 1, 1, "", "load_memmap"], [378, 1, 1, "", "load_state_dict"], [378, 1, 1, "", "maybe_dense_stack"], [378, 1, 1, "", "memmap"], [378, 1, 1, "", "memmap_"], [378, 1, 1, "", "memmap_like"], [378, 1, 1, "", "memmap_refresh_"], [378, 1, 1, "", "save"], [378, 1, 1, "", "set"], [378, 1, 1, "", "stack"], [378, 1, 1, "", "state_dict"], [378, 1, 1, "", "to_tensordict"], [378, 1, 1, "", "unbind"]], "torchrl.objectives.llm.GRPOLoss": [[379, 1, 1, "", "add_module"], [379, 1, 1, "", "apply"], [379, 1, 1, "", "bfloat16"], [379, 1, 1, "", "buffers"], [379, 1, 1, "", "children"], [379, 1, 1, "", "compile"], [379, 1, 1, "", "convert_to_functional"], [379, 1, 1, "", "cpu"], [379, 1, 1, "", "cuda"], [379, 1, 1, "", "double"], [379, 1, 1, "", "eval"], [379, 1, 1, "", "extra_repr"], [379, 1, 1, "", "float"], [379, 1, 1, "", "forward"], [379, 1, 1, "", "from_stateful_net"], [379, 2, 1, "", "functional"], [379, 1, 1, "", "get_buffer"], [379, 1, 1, "", "get_extra_state"], [379, 1, 1, "", "get_parameter"], [379, 1, 1, "", "get_stateful_net"], [379, 1, 1, "", "get_submodule"], [379, 1, 1, "", "half"], [379, 1, 1, "", "ipu"], [379, 1, 1, "", "is_tdmodule_compatible"], [379, 1, 1, "", "load_state_dict"], [379, 1, 1, "", "make_value_estimator"], [379, 1, 1, "", "modules"], [379, 1, 1, "", "mtia"], [379, 1, 1, "", "named_buffers"], [379, 1, 1, "", "named_children"], [379, 1, 1, "", "named_modules"], [379, 1, 1, "", "named_parameters"], [379, 4, 1, "", "output_type"], [379, 1, 1, "", "parameters"], [379, 1, 1, "", "register_backward_hook"], [379, 1, 1, "", "register_buffer"], [379, 1, 1, "", "register_forward_hook"], [379, 1, 1, "", "register_forward_pre_hook"], [379, 1, 1, "", "register_full_backward_hook"], [379, 1, 1, "", "register_full_backward_pre_hook"], [379, 1, 1, "", "register_load_state_dict_post_hook"], [379, 1, 1, "", "register_load_state_dict_pre_hook"], [379, 1, 1, "", "register_module"], [379, 1, 1, "", "register_parameter"], [379, 1, 1, "", "register_state_dict_post_hook"], [379, 1, 1, "", "register_state_dict_pre_hook"], [379, 1, 1, "", "requires_grad_"], [379, 1, 1, "", "reset_out_keys"], [379, 1, 1, "", "reset_parameters_recursive"], [379, 1, 1, "", "select_out_keys"], [379, 1, 1, "", "set_extra_state"], [379, 1, 1, "", "set_keys"], [379, 1, 1, "", "set_submodule"], [379, 1, 1, "", "share_memory"], [379, 1, 1, "", "state_dict"], [379, 2, 1, "", "tensor_keys"], [379, 1, 1, "", "to"], [379, 1, 1, "", "to_empty"], [379, 1, 1, "", "train"], [379, 1, 1, "", "type"], [379, 2, 1, "", "value_estimator"], [379, 2, 1, "", "vmap_randomness"], [379, 1, 1, "", "xpu"], [379, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.GRPOLossOutput": [[380, 1, 1, "", "cat"], [380, 2, 1, "", "device"], [380, 1, 1, "", "dumps"], [380, 1, 1, "", "fields"], [380, 1, 1, "", "from_any"], [380, 1, 1, "", "from_dataclass"], [380, 1, 1, "", "from_h5"], [380, 1, 1, "", "from_modules"], [380, 1, 1, "", "from_namedtuple"], [380, 1, 1, "", "from_pytree"], [380, 1, 1, "", "from_remote_init"], [380, 1, 1, "", "from_struct_array"], [380, 1, 1, "", "from_tensordict"], [380, 1, 1, "", "from_tuple"], [380, 1, 1, "", "fromkeys"], [380, 1, 1, "", "get"], [380, 1, 1, "", "lazy_stack"], [380, 1, 1, "", "load"], [380, 1, 1, "", "load_"], [380, 1, 1, "", "load_memmap"], [380, 1, 1, "", "load_state_dict"], [380, 1, 1, "", "maybe_dense_stack"], [380, 1, 1, "", "memmap"], [380, 1, 1, "", "memmap_"], [380, 1, 1, "", "memmap_like"], [380, 1, 1, "", "memmap_refresh_"], [380, 1, 1, "", "save"], [380, 1, 1, "", "set"], [380, 1, 1, "", "stack"], [380, 1, 1, "", "state_dict"], [380, 1, 1, "", "to_tensordict"], [380, 1, 1, "", "unbind"]], "torchrl.objectives.llm.LLMLossOutput": [[381, 1, 1, "", "cat"], [381, 2, 1, "", "device"], [381, 1, 1, "", "dumps"], [381, 1, 1, "", "fields"], [381, 1, 1, "", "from_any"], [381, 1, 1, "", "from_dataclass"], [381, 1, 1, "", "from_h5"], [381, 1, 1, "", "from_modules"], [381, 1, 1, "", "from_namedtuple"], [381, 1, 1, "", "from_pytree"], [381, 1, 1, "", "from_remote_init"], [381, 1, 1, "", "from_struct_array"], [381, 1, 1, "", "from_tensordict"], [381, 1, 1, "", "from_tuple"], [381, 1, 1, "", "fromkeys"], [381, 1, 1, "", "get"], [381, 1, 1, "", "lazy_stack"], [381, 1, 1, "", "load"], [381, 1, 1, "", "load_"], [381, 1, 1, "", "load_memmap"], [381, 1, 1, "", "load_state_dict"], [381, 1, 1, "", "maybe_dense_stack"], [381, 1, 1, "", "memmap"], [381, 1, 1, "", "memmap_"], [381, 1, 1, "", "memmap_like"], [381, 1, 1, "", "memmap_refresh_"], [381, 1, 1, "", "save"], [381, 1, 1, "", "set"], [381, 1, 1, "", "stack"], [381, 1, 1, "", "state_dict"], [381, 1, 1, "", "to_tensordict"], [381, 1, 1, "", "unbind"]], "torchrl.objectives.llm.MCAdvantage": [[382, 1, 1, "", "add_module"], [382, 1, 1, "", "apply"], [382, 1, 1, "", "bfloat16"], [382, 1, 1, "", "buffers"], [382, 1, 1, "", "children"], [382, 1, 1, "", "close"], [382, 2, 1, "", "collector"], [382, 1, 1, "", "compile"], [382, 2, 1, "", "container"], [382, 1, 1, "", "cpu"], [382, 1, 1, "", "cuda"], [382, 1, 1, "", "double"], [382, 1, 1, "", "eval"], [382, 1, 1, "", "extra_repr"], [382, 1, 1, "", "float"], [382, 1, 1, "", "forward"], [382, 1, 1, "", "get_buffer"], [382, 1, 1, "", "get_extra_state"], [382, 1, 1, "", "get_parameter"], [382, 1, 1, "", "get_submodule"], [382, 1, 1, "", "half"], [382, 1, 1, "", "init"], [382, 1, 1, "", "inv"], [382, 1, 1, "", "ipu"], [382, 1, 1, "", "load_state_dict"], [382, 1, 1, "", "modules"], [382, 1, 1, "", "mtia"], [382, 1, 1, "", "named_buffers"], [382, 1, 1, "", "named_children"], [382, 1, 1, "", "named_modules"], [382, 1, 1, "", "named_parameters"], [382, 1, 1, "", "parameters"], [382, 2, 1, "", "parent"], [382, 1, 1, "", "register_backward_hook"], [382, 1, 1, "", "register_buffer"], [382, 1, 1, "", "register_forward_hook"], [382, 1, 1, "", "register_forward_pre_hook"], [382, 1, 1, "", "register_full_backward_hook"], [382, 1, 1, "", "register_full_backward_pre_hook"], [382, 1, 1, "", "register_load_state_dict_post_hook"], [382, 1, 1, "", "register_load_state_dict_pre_hook"], [382, 1, 1, "", "register_module"], [382, 1, 1, "", "register_parameter"], [382, 1, 1, "", "register_state_dict_post_hook"], [382, 1, 1, "", "register_state_dict_pre_hook"], [382, 1, 1, "", "requires_grad_"], [382, 1, 1, "", "set_extra_state"], [382, 1, 1, "", "set_submodule"], [382, 1, 1, "", "share_memory"], [382, 1, 1, "", "state_dict"], [382, 1, 1, "", "to"], [382, 1, 1, "", "to_empty"], [382, 1, 1, "", "train"], [382, 1, 1, "", "transform_action_spec"], [382, 1, 1, "", "transform_done_spec"], [382, 1, 1, "", "transform_env_batch_size"], [382, 1, 1, "", "transform_env_device"], [382, 1, 1, "", "transform_input_spec"], [382, 1, 1, "", "transform_observation_spec"], [382, 1, 1, "", "transform_output_spec"], [382, 1, 1, "", "transform_reward_spec"], [382, 1, 1, "", "transform_state_spec"], [382, 1, 1, "", "type"], [382, 1, 1, "", "xpu"], [382, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.SFTLoss": [[383, 1, 1, "", "add_module"], [383, 1, 1, "", "apply"], [383, 1, 1, "", "bfloat16"], [383, 1, 1, "", "buffers"], [383, 1, 1, "", "children"], [383, 1, 1, "", "compile"], [383, 1, 1, "", "convert_to_functional"], [383, 1, 1, "", "cpu"], [383, 1, 1, "", "cuda"], [383, 4, 1, "", "default_keys"], [383, 1, 1, "", "double"], [383, 1, 1, "", "eval"], [383, 1, 1, "", "extra_repr"], [383, 1, 1, "", "float"], [383, 1, 1, "", "forward"], [383, 1, 1, "", "from_stateful_net"], [383, 2, 1, "", "functional"], [383, 1, 1, "", "get_buffer"], [383, 1, 1, "", "get_extra_state"], [383, 1, 1, "", "get_parameter"], [383, 1, 1, "", "get_stateful_net"], [383, 1, 1, "", "get_submodule"], [383, 1, 1, "", "half"], [383, 1, 1, "", "ipu"], [383, 1, 1, "", "is_tdmodule_compatible"], [383, 1, 1, "", "load_state_dict"], [383, 1, 1, "", "make_value_estimator"], [383, 1, 1, "", "modules"], [383, 1, 1, "", "mtia"], [383, 1, 1, "", "named_buffers"], [383, 1, 1, "", "named_children"], [383, 1, 1, "", "named_modules"], [383, 1, 1, "", "named_parameters"], [383, 1, 1, "", "parameters"], [383, 1, 1, "", "register_backward_hook"], [383, 1, 1, "", "register_buffer"], [383, 1, 1, "", "register_forward_hook"], [383, 1, 1, "", "register_forward_pre_hook"], [383, 1, 1, "", "register_full_backward_hook"], [383, 1, 1, "", "register_full_backward_pre_hook"], [383, 1, 1, "", "register_load_state_dict_post_hook"], [383, 1, 1, "", "register_load_state_dict_pre_hook"], [383, 1, 1, "", "register_module"], [383, 1, 1, "", "register_parameter"], [383, 1, 1, "", "register_state_dict_post_hook"], [383, 1, 1, "", "register_state_dict_pre_hook"], [383, 1, 1, "", "requires_grad_"], [383, 1, 1, "", "reset_out_keys"], [383, 1, 1, "", "reset_parameters_recursive"], [383, 1, 1, "", "select_out_keys"], [383, 1, 1, "", "set_extra_state"], [383, 1, 1, "", "set_keys"], [383, 1, 1, "", "set_submodule"], [383, 1, 1, "", "share_memory"], [383, 1, 1, "", "state_dict"], [383, 1, 1, "", "to"], [383, 1, 1, "", "to_empty"], [383, 1, 1, "", "train"], [383, 1, 1, "", "type"], [383, 2, 1, "", "value_estimator"], [383, 2, 1, "", "vmap_randomness"], [383, 1, 1, "", "xpu"], [383, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.SFTLossOutput": [[384, 1, 1, "", "cat"], [384, 2, 1, "", "device"], [384, 1, 1, "", "dumps"], [384, 1, 1, "", "fields"], [384, 1, 1, "", "from_any"], [384, 1, 1, "", "from_dataclass"], [384, 1, 1, "", "from_h5"], [384, 1, 1, "", "from_modules"], [384, 1, 1, "", "from_namedtuple"], [384, 1, 1, "", "from_pytree"], [384, 1, 1, "", "from_remote_init"], [384, 1, 1, "", "from_struct_array"], [384, 1, 1, "", "from_tensordict"], [384, 1, 1, "", "from_tuple"], [384, 1, 1, "", "fromkeys"], [384, 1, 1, "", "get"], [384, 1, 1, "", "lazy_stack"], [384, 1, 1, "", "load"], [384, 1, 1, "", "load_"], [384, 1, 1, "", "load_memmap"], [384, 1, 1, "", "load_state_dict"], [384, 1, 1, "", "maybe_dense_stack"], [384, 1, 1, "", "memmap"], [384, 1, 1, "", "memmap_"], [384, 1, 1, "", "memmap_like"], [384, 1, 1, "", "memmap_refresh_"], [384, 1, 1, "", "save"], [384, 1, 1, "", "set"], [384, 1, 1, "", "stack"], [384, 1, 1, "", "state_dict"], [384, 1, 1, "", "to_tensordict"], [384, 1, 1, "", "unbind"]], "torchrl.objectives.value": [[385, 0, 1, "", "GAE"], [386, 0, 1, "", "TD0Estimator"], [387, 0, 1, "", "TD1Estimator"], [388, 0, 1, "", "TDLambdaEstimator"], [389, 0, 1, "", "ValueEstimatorBase"]], "torchrl.objectives.value.GAE": [[385, 1, 1, "", "forward"], [385, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD0Estimator": [[386, 1, 1, "", "forward"], [386, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD1Estimator": [[387, 1, 1, "", "forward"], [387, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TDLambdaEstimator": [[388, 1, 1, "", "forward"], [388, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.ValueEstimatorBase": [[389, 4, 1, "", "default_keys"], [389, 1, 1, "", "forward"], [389, 1, 1, "", "set_keys"], [389, 1, 1, "", "value_estimate"]], "torchrl.record": [[390, 3, 1, "", "PixelRenderTransform"], [391, 3, 1, "", "TensorDictRecorder"], [392, 3, 1, "", "VideoRecorder"]], "torchrl.record.loggers": [[393, 3, 1, "", "Logger"], [395, 3, 1, "", "generate_exp_name"], [396, 3, 1, "", "get_logger"]], "torchrl.record.loggers.csv": [[394, 3, 1, "", "CSVLogger"]], "torchrl.record.loggers.mlflow": [[397, 3, 1, "", "MLFlowLogger"]], "torchrl.record.loggers.tensorboard": [[398, 3, 1, "", "TensorboardLogger"]], "torchrl.record.loggers.trackio": [[399, 3, 1, "", "TrackioLogger"]], "torchrl.record.loggers.wandb": [[400, 3, 1, "", "WandbLogger"]], "torchrl.services": [[401, 0, 1, "", "RayService"], [402, 0, 1, "", "ServiceBase"], [403, 0, 1, "", "get_services"]], "torchrl.services.RayService": [[401, 1, 1, "", "get"], [401, 1, 1, "", "list"], [401, 1, 1, "", "register"], [401, 1, 1, "", "register_with_options"], [401, 1, 1, "", "reset"], [401, 1, 1, "", "shutdown"]], "torchrl.services.ServiceBase": [[402, 1, 1, "", "get"], [402, 1, 1, "", "list"], [402, 1, 1, "", "register"], [402, 1, 1, "", "reset"]], "torchrl.trainers": [[405, 0, 1, "", "BatchSubSampler"], [406, 0, 1, "", "ClearCudaCache"], [407, 0, 1, "", "CountFramesLog"], [408, 0, 1, "", "LogScalar"], [409, 0, 1, "", "LogValidationReward"], [410, 0, 1, "", "OptimizerHook"], [411, 0, 1, "", "ReplayBufferTrainer"], [412, 0, 1, "", "RewardNormalizer"], [413, 0, 1, "", "SelectKeys"], [414, 0, 1, "", "TargetNetUpdaterHook"], [415, 0, 1, "", "Trainer"], [416, 0, 1, "", "TrainerHookBase"], [417, 0, 1, "", "UTDRHook"], [418, 0, 1, "", "UpdateWeights"]], "torchrl.trainers.BatchSubSampler": [[405, 1, 1, "", "register"]], "torchrl.trainers.ClearCudaCache": [[406, 1, 1, "", "register"]], "torchrl.trainers.CountFramesLog": [[407, 1, 1, "", "register"]], "torchrl.trainers.LogScalar": [[408, 1, 1, "", "register"]], "torchrl.trainers.LogValidationReward": [[409, 1, 1, "", "register"]], "torchrl.trainers.OptimizerHook": [[410, 1, 1, "", "register"]], "torchrl.trainers.ReplayBufferTrainer": [[411, 1, 1, "", "register"]], "torchrl.trainers.RewardNormalizer": [[412, 1, 1, "", "register"]], "torchrl.trainers.SelectKeys": [[413, 1, 1, "", "register"]], "torchrl.trainers.TargetNetUpdaterHook": [[414, 1, 1, "", "register"]], "torchrl.trainers.Trainer": [[415, 1, 1, "", "load_from_file"]], "torchrl.trainers.TrainerHookBase": [[416, 1, 1, "", "register"]], "torchrl.trainers.UTDRHook": [[417, 1, 1, "", "load_state_dict"], [417, 1, 1, "", "register"], [417, 1, 1, "", "state_dict"]], "torchrl.trainers.UpdateWeights": [[418, 1, 1, "", "register"]], "torchrl.trainers.algorithms": [[419, 0, 1, "", "PPOTrainer"], [420, 0, 1, "", "SACTrainer"]], "torchrl.trainers.algorithms.PPOTrainer": [[419, 1, 1, "", "load_from_file"]], "torchrl.trainers.algorithms.SACTrainer": [[420, 1, 1, "", "load_from_file"]], "torchrl.trainers.algorithms.configs.collectors": [[421, 4, 1, "", "AsyncDataCollectorConfig"], [422, 4, 1, "", "SyncDataCollectorConfig"]], "torchrl.trainers.algorithms.configs.common": [[423, 0, 1, "", "ConfigBase"]], "torchrl.trainers.algorithms.configs.data": [[424, 0, 1, "", "LazyMemmapStorageConfig"], [425, 0, 1, "", "LazyStackStorageConfig"], [426, 0, 1, "", "LazyTensorStorageConfig"], [427, 0, 1, "", "ListStorageConfig"], [428, 0, 1, "", "PrioritizedSamplerConfig"], [429, 0, 1, "", "RandomSamplerConfig"], [430, 0, 1, "", "ReplayBufferConfig"], [431, 0, 1, "", "RoundRobinWriterConfig"], [432, 0, 1, "", "SamplerWithoutReplacementConfig"], [433, 0, 1, "", "SliceSamplerConfig"], [434, 0, 1, "", "SliceSamplerWithoutReplacementConfig"], [435, 0, 1, "", "StorageEnsembleConfig"], [436, 0, 1, "", "StorageEnsembleWriterConfig"], [437, 0, 1, "", "TensorDictReplayBufferConfig"], [438, 0, 1, "", "TensorStorageConfig"]], "torchrl.trainers.algorithms.configs.envs": [[439, 0, 1, "", "BatchedEnvConfig"], [440, 0, 1, "", "EnvConfig"], [441, 0, 1, "", "TransformedEnvConfig"]], "torchrl.trainers.algorithms.configs.envs_libs": [[442, 0, 1, "", "BraxEnvConfig"], [443, 0, 1, "", "DMControlEnvConfig"], [444, 0, 1, "", "EnvLibsConfig"], [445, 0, 1, "", "GymEnvConfig"], [446, 0, 1, "", "HabitatEnvConfig"], [447, 0, 1, "", "IsaacGymEnvConfig"], [448, 0, 1, "", "JumanjiEnvConfig"], [449, 0, 1, "", "MOGymEnvConfig"], [450, 0, 1, "", "MeltingpotEnvConfig"], [451, 0, 1, "", "MultiThreadedEnvConfig"], [452, 0, 1, "", "OpenMLEnvConfig"], [453, 0, 1, "", "OpenSpielEnvConfig"], [454, 0, 1, "", "PettingZooEnvConfig"], [455, 0, 1, "", "RoboHiveEnvConfig"], [456, 0, 1, "", "SMACv2EnvConfig"], [457, 0, 1, "", "UnityMLAgentsEnvConfig"], [458, 0, 1, "", "VmasEnvConfig"]], "torchrl.trainers.algorithms.configs.logging": [[459, 0, 1, "", "CSVLoggerConfig"], [460, 0, 1, "", "LoggerConfig"], [461, 0, 1, "", "TensorboardLoggerConfig"], [462, 0, 1, "", "WandbLoggerConfig"]], "torchrl.trainers.algorithms.configs.modules": [[463, 0, 1, "", "ConvNetConfig"], [464, 0, 1, "", "MLPConfig"], [465, 0, 1, "", "ModelConfig"], [466, 0, 1, "", "NetworkConfig"], [467, 0, 1, "", "TanhNormalModelConfig"], [468, 0, 1, "", "TensorDictModuleConfig"], [469, 0, 1, "", "ValueModelConfig"]], "torchrl.trainers.algorithms.configs.objectives": [[470, 0, 1, "", "LossConfig"], [471, 0, 1, "", "PPOLossConfig"]], "torchrl.trainers.algorithms.configs.trainers": [[472, 0, 1, "", "PPOTrainerConfig"], [473, 0, 1, "", "TrainerConfig"]], "torchrl.trainers.algorithms.configs.transforms": [[474, 0, 1, "", "ActionDiscretizerConfig"], [475, 0, 1, "", "ActionMaskConfig"], [476, 0, 1, "", "AutoResetTransformConfig"], [477, 0, 1, "", "BatchSizeTransformConfig"], [478, 0, 1, "", "BinarizeRewardConfig"], [479, 0, 1, "", "BurnInTransformConfig"], [480, 0, 1, "", "CatFramesConfig"], [481, 0, 1, "", "CatTensorsConfig"], [482, 0, 1, "", "CenterCropConfig"], [483, 0, 1, "", "ClipTransformConfig"], [484, 0, 1, "", "ComposeConfig"], [485, 0, 1, "", "ConditionalPolicySwitchConfig"], [486, 0, 1, "", "ConditionalSkipConfig"], [487, 0, 1, "", "CropConfig"], [488, 0, 1, "", "DTypeCastTransformConfig"], [489, 0, 1, "", "DeviceCastTransformConfig"], [490, 0, 1, "", "DiscreteActionProjectionConfig"], [491, 0, 1, "", "DoubleToFloatConfig"], [492, 0, 1, "", "EndOfLifeTransformConfig"], [493, 0, 1, "", "ExcludeTransformConfig"], [494, 0, 1, "", "FiniteTensorDictCheckConfig"], [495, 0, 1, "", "FlattenObservationConfig"], [496, 0, 1, "", "FrameSkipTransformConfig"], [497, 0, 1, "", "GrayScaleConfig"], [498, 0, 1, "", "HashConfig"], [499, 0, 1, "", "InitTrackerConfig"], [500, 0, 1, "", "KLRewardTransformConfig"], [501, 0, 1, "", "LineariseRewardsConfig"], [502, 0, 1, "", "MultiActionConfig"], [503, 0, 1, "", "MultiStepTransformConfig"], [504, 0, 1, "", "NoopResetEnvConfig"], [505, 0, 1, "", "ObservationNormConfig"], [506, 0, 1, "", "PermuteTransformConfig"], [507, 0, 1, "", "PinMemoryTransformConfig"], [508, 0, 1, "", "R3MTransformConfig"], [509, 0, 1, "", "RandomCropTensorDictConfig"], [510, 0, 1, "", "RemoveEmptySpecsConfig"], [511, 0, 1, "", "RenameTransformConfig"], [512, 0, 1, "", "ResizeConfig"], [513, 0, 1, "", "Reward2GoTransformConfig"], [514, 0, 1, "", "RewardClippingConfig"], [515, 0, 1, "", "RewardScalingConfig"], [516, 0, 1, "", "RewardSumConfig"], [517, 0, 1, "", "SelectTransformConfig"], [518, 0, 1, "", "SignTransformConfig"], [519, 0, 1, "", "SqueezeTransformConfig"], [520, 0, 1, "", "StackConfig"], [521, 0, 1, "", "StepCounterConfig"], [522, 0, 1, "", "TargetReturnConfig"], [523, 0, 1, "", "TensorDictPrimerConfig"], [524, 0, 1, "", "TimeMaxPoolConfig"], [525, 0, 1, "", "TimerConfig"], [526, 0, 1, "", "ToTensorImageConfig"], [527, 0, 1, "", "TokenizerConfig"], [528, 0, 1, "", "TrajCounterConfig"], [529, 0, 1, "", "TransformConfig"], [530, 0, 1, "", "UnaryTransformConfig"], [531, 0, 1, "", "UnsqueezeTransformConfig"], [532, 0, 1, "", "VC1TransformConfig"], [533, 0, 1, "", "VIPRewardTransformConfig"], [534, 0, 1, "", "VIPTransformConfig"], [535, 0, 1, "", "VecGymEnvTransformConfig"], [536, 0, 1, "", "VecNormConfig"], [537, 0, 1, "", "VecNormV2Config"]], "torchrl.trainers.algorithms.configs.utils": [[538, 0, 1, "", "ASGDConfig"], [539, 0, 1, "", "AdadeltaConfig"], [540, 0, 1, "", "AdagradConfig"], [541, 0, 1, "", "AdamConfig"], [542, 0, 1, "", "AdamWConfig"], [543, 0, 1, "", "AdamaxConfig"], [544, 0, 1, "", "LBFGSConfig"], [545, 0, 1, "", "LionConfig"], [546, 0, 1, "", "NAdamConfig"], [547, 0, 1, "", "RAdamConfig"], [548, 0, 1, "", "RMSpropConfig"], [549, 0, 1, "", "RpropConfig"], [550, 0, 1, "", "SGDConfig"], [551, 0, 1, "", "SparseAdamConfig"]], "torchrl.trainers.helpers": [[552, 3, 1, "", "correct_for_frame_skip"], [553, 3, 1, "", "get_stats_random_rollout"], [554, 3, 1, "", "make_collector_offpolicy"], [555, 3, 1, "", "make_collector_onpolicy"], [556, 3, 1, "", "make_dqn_loss"], [557, 3, 1, "", "make_replay_buffer"], [558, 3, 1, "", "make_target_updater"], [559, 3, 1, "", "make_trainer"], [560, 3, 1, "", "parallel_env_constructor"], [561, 3, 1, "", "sync_async_collector"], [562, 3, 1, "", "sync_sync_collector"], [563, 3, 1, "", "transformed_env_constructor"]], "torchrl.weight_update": [[564, 0, 1, "", "DistributedTransport"], [565, 0, 1, "", "DistributedWeightSyncScheme"], [566, 0, 1, "", "MPTransport"], [567, 0, 1, "", "MultiProcessWeightSyncScheme"], [568, 0, 1, "", "NoWeightSyncScheme"], [569, 0, 1, "", "RPCTransport"], [570, 0, 1, "", "RPCWeightSyncScheme"], [571, 0, 1, "", "RayModuleTransformScheme"], [572, 0, 1, "", "RayTransport"], [573, 0, 1, "", "RayWeightSyncScheme"], [574, 0, 1, "", "SharedMemTransport"], [575, 0, 1, "", "SharedMemWeightSyncScheme"], [576, 0, 1, "", "TransportBackend"], [577, 0, 1, "", "WeightStrategy"], [578, 0, 1, "", "WeightSyncScheme"]], "torchrl.weight_update.DistributedTransport": [[564, 1, 1, "", "receive_initial_weights"], [564, 1, 1, "", "receive_weights"], [564, 1, 1, "", "send_initial_weights"], [564, 1, 1, "", "send_weights"], [564, 1, 1, "", "send_weights_async"], [564, 1, 1, "", "setup_connection_and_weights_on_receiver"], [564, 1, 1, "", "setup_connection_and_weights_on_sender"], [564, 1, 1, "", "wait_ack"]], "torchrl.weight_update.DistributedWeightSyncScheme": [[565, 1, 1, "", "apply_weights"], [565, 1, 1, "", "connect"], [565, 2, 1, "", "context"], [565, 1, 1, "", "create_transport"], [565, 1, 1, "", "init_on_receiver"], [565, 1, 1, "", "init_on_sender"], [565, 2, 1, "", "model"], [565, 2, 1, "", "model_id"], [565, 1, 1, "", "prepare_weights"], [565, 1, 1, "", "receive"], [565, 2, 1, "", "receiver_transport"], [565, 1, 1, "", "send"], [565, 2, 1, "", "sender_transports"], [565, 2, 1, "", "shared_transport"], [565, 1, 1, "", "shutdown"], [565, 2, 1, "", "weights"], [565, 2, 1, "", "worker_idx"]], "torchrl.weight_update.MPTransport": [[566, 1, 1, "", "receive_weights"], [566, 1, 1, "", "send_weights_async"], [566, 1, 1, "", "setup_connection_and_weights_on_receiver"], [566, 1, 1, "", "setup_connection_and_weights_on_sender"]], "torchrl.weight_update.MultiProcessWeightSyncScheme": [[567, 1, 1, "", "apply_weights"], [567, 1, 1, "", "connect"], [567, 2, 1, "", "context"], [567, 1, 1, "", "create_transport"], [567, 1, 1, "", "init_on_receiver"], [567, 1, 1, "", "init_on_sender"], [567, 2, 1, "", "model"], [567, 2, 1, "", "model_id"], [567, 1, 1, "", "prepare_weights"], [567, 1, 1, "", "receive"], [567, 2, 1, "", "receiver_transport"], [567, 1, 1, "", "send"], [567, 2, 1, "", "sender_transports"], [567, 2, 1, "", "shared_transport"], [567, 1, 1, "", "shutdown"], [567, 2, 1, "", "weights"], [567, 2, 1, "", "worker_idx"]], "torchrl.weight_update.NoWeightSyncScheme": [[568, 1, 1, "", "apply_weights"], [568, 1, 1, "", "connect"], [568, 2, 1, "", "context"], [568, 1, 1, "", "create_transport"], [568, 1, 1, "", "init_on_receiver"], [568, 1, 1, "", "init_on_sender"], [568, 2, 1, "", "model"], [568, 2, 1, "", "model_id"], [568, 1, 1, "", "prepare_weights"], [568, 1, 1, "", "receive"], [568, 2, 1, "", "receiver_transport"], [568, 1, 1, "", "send"], [568, 2, 1, "", "sender_transports"], [568, 2, 1, "", "shared_transport"], [568, 1, 1, "", "shutdown"], [568, 2, 1, "", "weights"], [568, 2, 1, "", "worker_idx"]], "torchrl.weight_update.RPCTransport": [[569, 1, 1, "", "receive_weights"], [569, 1, 1, "", "send_weights"], [569, 1, 1, "", "send_weights_async"], [569, 1, 1, "", "setup_connection_and_weights_on_receiver"], [569, 1, 1, "", "setup_connection_and_weights_on_sender"], [569, 1, 1, "", "wait_ack"]], "torchrl.weight_update.RPCWeightSyncScheme": [[570, 1, 1, "", "apply_weights"], [570, 1, 1, "", "connect"], [570, 2, 1, "", "context"], [570, 1, 1, "", "create_transport"], [570, 1, 1, "", "init_on_receiver"], [570, 1, 1, "", "init_on_sender"], [570, 2, 1, "", "model"], [570, 2, 1, "", "model_id"], [570, 1, 1, "", "prepare_weights"], [570, 1, 1, "", "receive"], [570, 2, 1, "", "receiver_transport"], [570, 1, 1, "", "send"], [570, 2, 1, "", "sender_transports"], [570, 2, 1, "", "shared_transport"], [570, 1, 1, "", "shutdown"], [570, 2, 1, "", "weights"], [570, 2, 1, "", "worker_idx"]], "torchrl.weight_update.RayModuleTransformScheme": [[571, 1, 1, "", "apply_weights"], [571, 1, 1, "", "connect"], [571, 2, 1, "", "connection_info_name"], [571, 2, 1, "", "context"], [571, 1, 1, "", "create_transport"], [571, 1, 1, "", "init_on_receiver"], [571, 1, 1, "", "init_on_sender"], [571, 2, 1, "", "model"], [571, 2, 1, "", "model_id"], [571, 1, 1, "", "prepare_weights"], [571, 1, 1, "", "receive"], [571, 2, 1, "", "receiver_transport"], [571, 1, 1, "", "send"], [571, 2, 1, "", "sender_transports"], [571, 2, 1, "", "shared_transport"], [571, 1, 1, "", "shutdown"], [571, 2, 1, "", "weights"], [571, 2, 1, "", "worker_idx"]], "torchrl.weight_update.RayTransport": [[572, 1, 1, "", "receive_weights"], [572, 1, 1, "", "send_weights"], [572, 1, 1, "", "send_weights_async"], [572, 1, 1, "", "set_model"], [572, 1, 1, "", "setup_connection_and_weights_on_receiver"], [572, 1, 1, "", "setup_connection_and_weights_on_sender"], [572, 1, 1, "", "wait_ack"]], "torchrl.weight_update.RayWeightSyncScheme": [[573, 1, 1, "", "apply_weights"], [573, 1, 1, "", "connect"], [573, 2, 1, "", "connection_info_name"], [573, 2, 1, "", "context"], [573, 1, 1, "", "create_transport"], [573, 1, 1, "", "init_on_receiver"], [573, 1, 1, "", "init_on_sender"], [573, 2, 1, "", "model"], [573, 2, 1, "", "model_id"], [573, 1, 1, "", "prepare_weights"], [573, 1, 1, "", "receive"], [573, 2, 1, "", "receiver_transport"], [573, 1, 1, "", "send"], [573, 2, 1, "", "sender_transports"], [573, 2, 1, "", "shared_transport"], [573, 1, 1, "", "shutdown"], [573, 2, 1, "", "weights"], [573, 2, 1, "", "worker_idx"]], "torchrl.weight_update.SharedMemTransport": [[574, 1, 1, "", "receive_weights"], [574, 1, 1, "", "register_weights"], [574, 1, 1, "", "send_ack"], [574, 1, 1, "", "send_weights"], [574, 1, 1, "", "setup_connection_and_weights_on_receiver"], [574, 1, 1, "", "setup_connection_and_weights_on_sender"], [574, 2, 1, "", "unique_weights"]], "torchrl.weight_update.SharedMemWeightSyncScheme": [[575, 1, 1, "", "apply_weights"], [575, 1, 1, "", "connect"], [575, 2, 1, "", "context"], [575, 1, 1, "", "create_transport"], [575, 1, 1, "", "init_on_receiver"], [575, 1, 1, "", "init_on_sender"], [575, 2, 1, "", "model"], [575, 2, 1, "", "model_id"], [575, 1, 1, "", "prepare_weights"], [575, 1, 1, "", "receive"], [575, 2, 1, "", "receiver_transport"], [575, 1, 1, "", "send"], [575, 2, 1, "", "sender_transports"], [575, 2, 1, "", "shared_transport"], [575, 1, 1, "", "shutdown"], [575, 2, 1, "", "weights"], [575, 2, 1, "", "worker_idx"]], "torchrl.weight_update.TransportBackend": [[576, 1, 1, "", "receive_weights"], [576, 1, 1, "", "send_weights"], [576, 1, 1, "", "setup_connection_and_weights_on_receiver"], [576, 1, 1, "", "setup_connection_and_weights_on_sender"]], "torchrl.weight_update.WeightStrategy": [[577, 1, 1, "", "apply_weights"], [577, 1, 1, "", "extract_weights"]], "torchrl.weight_update.WeightSyncScheme": [[578, 1, 1, "", "apply_weights"], [578, 1, 1, "", "connect"], [578, 2, 1, "", "context"], [578, 1, 1, "", "create_transport"], [578, 1, 1, "", "init_on_receiver"], [578, 1, 1, "", "init_on_sender"], [578, 2, 1, "", "model"], [578, 2, 1, "", "model_id"], [578, 1, 1, "", "prepare_weights"], [578, 1, 1, "", "receive"], [578, 2, 1, "", "receiver_transport"], [578, 1, 1, "", "send"], [578, 2, 1, "", "sender_transports"], [578, 2, 1, "", "shared_transport"], [578, 1, 1, "", "shutdown"], [578, 2, 1, "", "weights"], [578, 2, 1, "", "worker_idx"]], "torchrl.weight_update.llm": [[579, 0, 1, "", "VLLMCollectiveTransport"], [580, 0, 1, "", "VLLMDoubleBufferSyncScheme"], [581, 0, 1, "", "VLLMDoubleBufferTransport"], [582, 0, 1, "", "VLLMDoubleBufferWeightReceiver"], [583, 0, 1, "", "VLLMDoubleBufferWeightSender"], [584, 0, 1, "", "VLLMWeightReceiver"], [585, 0, 1, "", "VLLMWeightSender"], [586, 0, 1, "", "VLLMWeightSyncScheme"], [587, 0, 1, "", "get_model_metadata"]], "torchrl.weight_update.llm.VLLMCollectiveTransport": [[579, 1, 1, "", "check_connection"], [579, 1, 1, "", "init_all_workers_group"], [579, 1, 1, "", "receive_weights"], [579, 1, 1, "", "send_weights"]], "torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme": [[580, 1, 1, "", "apply_weights"], [580, 1, 1, "", "connect"], [580, 2, 1, "", "context"], [580, 1, 1, "", "create_receiver"], [580, 1, 1, "", "create_sender"], [580, 1, 1, "", "create_transport"], [580, 1, 1, "", "init_on_receiver"], [580, 1, 1, "", "init_on_sender"], [580, 2, 1, "", "model"], [580, 2, 1, "", "model_id"], [580, 1, 1, "", "prepare_weights"], [580, 1, 1, "", "receive"], [580, 2, 1, "", "receiver_transport"], [580, 1, 1, "", "send"], [580, 2, 1, "", "sender_transports"], [580, 2, 1, "", "shared_transport"], [580, 1, 1, "", "shutdown"], [580, 2, 1, "", "weights"], [580, 2, 1, "", "worker_idx"]], "torchrl.weight_update.llm.VLLMDoubleBufferTransport": [[581, 1, 1, "", "check_connection"], [581, 1, 1, "", "receive_weights"], [581, 1, 1, "", "send_weights"]], "torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver": [[582, 1, 1, "", "apply_weights"], [582, 1, 1, "", "poll_and_apply"]], "torchrl.weight_update.llm.VLLMDoubleBufferWeightSender": [[583, 1, 1, "", "register_model"], [583, 1, 1, "", "update_weights"]], "torchrl.weight_update.llm.VLLMWeightReceiver": [[584, 1, 1, "", "apply_weights"], [584, 1, 1, "", "init_all_workers_group"], [584, 1, 1, "", "poll_and_apply"]], "torchrl.weight_update.llm.VLLMWeightSender": [[585, 1, 1, "", "init_all_workers_group"], [585, 1, 1, "", "register_model"], [585, 1, 1, "", "update_weights"]], "torchrl.weight_update.llm.VLLMWeightSyncScheme": [[586, 1, 1, "", "apply_weights"], [586, 1, 1, "", "connect"], [586, 2, 1, "", "context"], [586, 1, 1, "", "create_receiver"], [586, 1, 1, "", "create_sender"], [586, 1, 1, "", "create_transport"], [586, 1, 1, "", "init_on_receiver"], [586, 1, 1, "", "init_on_sender"], [586, 2, 1, "", "model"], [586, 2, 1, "", "model_id"], [586, 1, 1, "", "prepare_weights"], [586, 1, 1, "", "receive"], [586, 2, 1, "", "receiver_transport"], [586, 1, 1, "", "send"], [586, 2, 1, "", "sender_transports"], [586, 2, 1, "", "shared_transport"], [586, 1, 1, "", "shutdown"], [586, 2, 1, "", "weights"], [586, 2, 1, "", "worker_idx"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:property", "3": "py:function", "4": "py:attribute"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "property", "Python property"], "3": ["py", "function", "Python function"], "4": ["py", "attribute", "Python attribute"]}, "titleterms": {"torchrl": [0, 1, 7, 10, 16, 17, 25, 28, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 598, 605, 613, 617, 619, 620, 621, 623, 625, 631, 632, 634, 635, 636, 640, 641], "instal": [0, 25, 26, 631, 640], "get": [0, 7, 612, 624, 625, 626, 627, 628, 629], "start": [0, 7, 612, 624, 625, 626, 627, 628, 629, 631], "tutori": [0, 621, 634, 635], "basic": [0, 2, 7, 612, 614, 631, 638], "intermedi": [0, 27], "advanc": [0, 612], "refer": [0, 589, 612], "knowledg": [0, 590], "base": [0, 7, 17, 26, 590, 591, 603, 611, 623], "indic": 0, "tabl": 0, "collector": [1, 2, 3, 4, 5, 6, 34, 421, 422, 592, 619, 620, 621, 622, 627, 629, 634, 635, 640], "packag": [1, 10, 16, 598, 605, 613, 617], "multicollector": [1, 5, 36], "api": [1, 17, 589, 612], "kei": [1, 10, 16, 21, 591, 598, 605, 612, 613], "featur": [1, 10, 16, 598, 605, 612, 613], "quick": [1, 7, 10, 16, 591, 598, 605, 613], "exampl": [1, 6, 7, 10, 16, 22, 30, 591, 598, 605, 612, 613, 620, 632, 638], "legaci": [1, 3, 6, 591], "name": [1, 3], "document": [1, 10, 16, 28, 591, 598, 605, 613], "section": [1, 10, 16, 591, 598, 605, 613], "batch": [2, 17, 22, 619, 636, 638], "size": [2, 17, 619, 638], "polici": [2, 23, 591, 610, 619, 621, 622, 623, 625, 629, 633, 634, 635, 636], "copi": 2, "distribut": [3, 601], "replai": [4, 7, 12, 21, 619, 620, 621, 622, 627, 629, 634, 635, 638, 640], "buffer": [4, 7, 12, 21, 619, 620, 621, 622, 627, 629, 634, 635, 638, 640], "interoper": 4, "helper": [4, 17, 604, 631], "function": [4, 23, 591, 620, 621, 626, 634, 635, 640], "singl": [5, 23], "node": 5, "data": [5, 7, 10, 12, 23, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 593, 595, 619, 620, 621, 627, 629, 634, 635, 640], "us": [5, 6, 21, 23, 25, 28, 622, 637, 638, 640], "run": [5, 7, 623, 624, 641], "asynchron": 5, "weight": [6, 591, 592], "synchron": [6, 592], "lifecycl": 6, "phase": 6, "1": [6, 26, 631, 632], "initi": 6, "No": 6, "commun": 6, "2": [6, 26, 631, 632], "connect": 6, "rendez": 6, "vou": 6, "3": [6, 631, 632], "ongo": 6, "updat": [6, 591, 619], "scheme": [6, 592], "specif": [6, 17, 591, 614, 633], "behavior": 6, "sharedmemweightsyncschem": [6, 575], "multiprocessweightsyncschem": [6, 567], "distributedweightsyncschem": [6, 565], "rpcweightsyncschem": [6, 570], "rayweightsyncschem": [6, 573], "raymoduletransformschem": [6, 571], "background": 6, "thread": 6, "architectur": [6, 591], "usag": [6, 7, 612], "sync": [6, 640], "standalon": 6, "transport": 6, "interfac": [6, 591], "timeout": 6, "support": [6, 12], "avail": [6, 7, 18, 21], "configur": [7, 612, 631], "system": [7, 14], "simpl": [7, 623, 636], "categori": 7, "group": [7, 634], "more": [7, 638], "complex": [7, 638], "parallel": [7, 22, 619, 633, 641], "environ": [7, 17, 18, 19, 21, 22, 23, 25, 26, 591, 594, 619, 620, 621, 622, 624, 629, 631, 632, 633, 634, 635, 636, 640, 641], "transform": [7, 21, 271, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 591, 597, 619, 621, 624, 632, 634, 635, 636, 638, 640, 641], "option": [7, 26, 612], "complet": 7, "train": [7, 23, 27, 615, 619, 621, 622, 623, 626, 629, 634, 635, 636], "experi": [7, 619, 636], "hyperparamet": [7, 620, 621, 634, 635], "sweep": 7, "custom": [7, 17, 30, 612, 636, 638], "file": 7, "store": [7, 620, 638], "implement": [7, 23], "detail": [7, 22], "class": [7, 12, 17, 22, 593, 595, 601, 636, 640], "librari": [7, 18, 640], "model": [7, 23, 603, 619, 620, 622, 623, 626, 637, 640], "network": [7, 600, 619, 620, 621, 622, 625, 634, 635], "collect": [7, 620, 621, 627], "storag": [7, 12, 15, 110, 619, 627, 638], "optim": [7, 23, 619, 620, 626, 629], "log": [7, 459, 460, 461, 462, 628, 632], "creat": [7, 624], "best": [7, 612], "practic": [7, 612], "futur": 7, "extens": 7, "dataset": 11, "core": [12, 591], "compos": [12, 225], "type": 12, "choos": 12, "sampl": [12, 13, 638], "index": 12, "strategi": [13, 602], "writer": [13, 118], "tensorspec": [14, 74], "backend": 15, "perform": [15, 612, 631], "env": [16, 17, 439, 440, 441, 636, 640, 641], "spec": [17, 18, 21, 636, 641], "lock": [17, 22], "method": [17, 606, 608, 610, 611, 619], "nativ": 17, "domain": 17, "wrapper": [18, 591, 595, 625, 632], "auto": 18, "reset": [18, 22, 636, 641], "dynam": [18, 23, 638], "multi": [19, 633, 634, 635], "agent": [19, 23, 634, 635], "record": [20, 616, 619, 628], "video": [20, 30, 628], "forward": [21, 23, 619], "invers": 21, "understand": 21, "tensor": [21, 638], "expos": 21, "outsid": 21, "world": [21, 603], "design": [21, 591, 629], "your": [21, 23, 25, 619, 623, 629, 636], "own": [21, 629], "tip": 21, "subclass": 21, "clone": [21, 26], "mask": [21, 328], "action": [21, 23, 622, 636], "vector": [22, 640], "partial": 22, "step": [22, 619, 621, 624, 627, 631, 634, 635, 638, 641], "async": [22, 640], "thing": [23, 619, 636], "consid": 23, "when": [23, 26], "debug": 23, "rl": [23, 28, 603, 608, 624, 626, 632, 640], "gener": [23, 30], "have": 23, "you": 23, "valid": [23, 632], "algorithm": [23, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 614], "few": 23, "small": 23, "toi": 23, "problem": 23, "known": 23, "return": 23, "e": 23, "g": 23, "gridworld": 23, "mountaincar": 23, "visual": 23, "Be": 23, "veri": 23, "care": 23, "ani": 23, "augment": 23, "doe": 23, "entropi": 23, "converg": 23, "too": [23, 27], "quickli": 23, "slowli": 23, "chang": [23, 640], "drastic": 23, "reward": [23, 591, 593], "beyond": 23, "go": 23, "up": [23, 25], "Is": 23, "favor": 23, "compon": [23, 591, 607], "i": 23, "veloc": 23, "vs": 23, "l2": 23, "magnitud": 23, "task": [23, 591, 633], "horizon": 23, "extrem": 23, "long": 23, "ar": 23, "normal": [23, 619, 620, 621], "standard": 23, "explor": [23, 602, 619, 620, 625, 632], "valu": [23, 599, 600, 607, 611, 619, 621, 622, 625], "loss": [23, 609, 619, 620, 621, 622, 629, 634, 635], "earli": 23, "roughli": 23, "uniformli": 23, "random": [23, 634, 635], "intrins": 23, "decai": 23, "learn": [23, 621, 634, 635], "progress": 23, "singleton": 23, "episod": 23, "remain": 23, "constant": [23, 620], "increas": 23, "an": [23, 621, 622, 624, 636], "can": 23, "low": 23, "also": [23, 612], "offlin": [23, 608], "observ": [23, 619], "space": 23, "effect": [23, 636], "dramat": 23, "dure": [23, 26], "high": 23, "dimension": 23, "work": [24, 25, 26, 612, 623], "gym": [24, 640, 641], "what": 24, "openai": 24, "version": [24, 26, 29, 591], "habitat": 25, "lab": 25, "set": [25, 30], "from": [25, 26], "pip": [25, 26], "common": [25, 26, 27, 423, 607], "issu": [25, 26, 29], "mujoco": 26, "prerequisit": [26, 619], "render": [26, 30, 629, 634, 635, 641], "all": 26, "new": 26, "bindindg": 26, "old": 26, "bind": 26, "py": 26, "repo": [26, 28], "import": [26, 619, 632], "pytorch": [27, 28, 29, 623], "error": [27, 632], "solut": 27, "gradient": [27, 610], "relat": 27, "newcom": 27, "my": 27, "slow": 27, "bug": 27, "resourc": 28, "paper": 28, "functorch": 28, "blog": 28, "websit": 28, "educ": 28, "forum": 28, "how": [29, 612], "reproduc": [29, 636], "workaround": 29, "customis": 30, "tweak": 30, "principl": 30, "auto_unwrap_transformed_env": 31, "asynccollector": 32, "basecollector": 33, "multiasynccollector": 35, "multiprocessedweightupdat": 37, "multisynccollector": 38, "rayweightupdat": 39, "vanillaweightupdat": 40, "weightupdaterbas": 41, "distributedcollector": 42, "distributeddatacollector": 43, "distributedsynccollector": 44, "distributedsyncdatacollector": 45, "distributedweightupdat": 46, "rpccollector": 47, "rpcdatacollector": 48, "rpcweightupdat": 49, "raycollector": 50, "submitit_delayed_launch": 51, "llmcollector": 52, "rayllmcollector": 53, "vllmupdat": 54, "vllmupdaterv2": 55, "split_trajectori": 56, "binari": [57, 623], "bound": 58, "categor": 59, "composit": 60, "multicategor": 61, "multionehot": 62, "nontensor": 63, "onehot": 64, "prioritizedreplaybuff": 65, "rayreplaybuff": 66, "remotetensordictreplaybuff": 67, "replaybuff": 68, "replaybufferensembl": 69, "stack": [70, 262], "stackedcomposit": 71, "tensordictprioritizedreplaybuff": 72, "tensordictreplaybuff": 73, "unbound": 75, "unboundedcontinu": 76, "unboundeddiscret": 77, "ataridqnexperiencereplai": 78, "d4rlexperiencereplai": 79, "gendgrlexperiencereplai": 80, "minariexperiencereplai": 81, "openmlexperiencereplai": 82, "openxexperiencereplai": 83, "robosetexperiencereplai": 84, "vd4rlexperiencereplai": 85, "contentbas": 86, "histori": [87, 593, 632], "topkrewardselector": 88, "add_chat_templ": 89, "compressedliststorag": 90, "compressedliststoragecheckpoint": 91, "flatstoragecheckpoint": 92, "h5storagecheckpoint": 93, "immutabledatasetwrit": 94, "lazymemmapstorag": 95, "lazystackstorag": 96, "lazytensorstorag": 97, "liststorag": 98, "liststoragecheckpoint": 99, "nestedstoragecheckpoint": 100, "prioritizedsampl": 101, "prioritizedslicesampl": 102, "randomsampl": 103, "roundrobinwrit": 104, "sampler": 105, "samplerensembl": 106, "samplerwithoutreplac": 107, "slicesampl": 108, "slicesamplerwithoutreplac": 109, "storagecheckpointerbas": 111, "storageensembl": 112, "storageensemblecheckpoint": 113, "tensordictmaxvaluewrit": 114, "tensordictroundrobinwrit": 115, "tensorstorag": 116, "tensorstoragecheckpoint": 117, "writerensembl": 119, "asyncenvpool": 120, "braxenv": 121, "braxwrapp": 122, "chessenv": 123, "dmcontrolenv": 124, "dmcontrolwrapp": 125, "envbas": [126, 636], "envcreat": 127, "envmetadata": 128, "gymenv": 129, "gymlikeenv": 130, "gymwrapp": 131, "habitatenv": 132, "isaacgymenv": 133, "isaacgymwrapp": 134, "isaaclabwrapp": 135, "jumanjienv": 136, "jumanjiwrapp": 137, "llmhashingenv": [138, 179], "mogymenv": 139, "mogymwrapp": 140, "marlgroupmaptyp": 141, "meltingpotenv": 142, "meltingpotwrapp": 143, "modelbasedenvbas": 144, "multithreadedenv": 145, "multithreadedenvwrapp": 146, "openmlenv": 147, "openspielenv": 148, "openspielwrapp": 149, "parallelenv": 150, "pendulumenv": 151, "pettingzooenv": 152, "pettingzoowrapp": 153, "processorasyncenvpool": 154, "robohiveenv": 155, "smacv2env": 156, "smacv2wrapp": 157, "serialenv": 158, "threadingasyncenvpool": 159, "tictactoeenv": 160, "unitymlagentsenv": 161, "unitymlagentswrapp": 162, "vmasenv": 163, "vmaswrapp": 164, "check_env_spec": 165, "check_marl_group": 166, "exploration_typ": 167, "get_available_librari": 168, "gym_backend": 169, "chatenv": [170, 591], "datasetchatenv": 171, "gsm8kenv": 172, "gsm8kpreparequest": 173, "gsm8krewardpars": 174, "ifevalenv": 175, "ifevalscoredata": 176, "ifevalscor": 177, "llmenv": 178, "mlgymwrapp": 180, "make_gsm8k_env": 181, "make_mlgym": 182, "addthinkingprompt": 183, "browsertransform": 184, "dataloadingprim": 185, "executetoolsinord": 186, "jsoncallpars": 187, "klcomput": 188, "klrewardtransform": [189, 241], "mcptooltransform": 190, "policyvers": 191, "pythonexecutorservic": 192, "pythoninterpret": 193, "raydataloadingprim": 194, "retrievekl": 195, "retrievelogprob": 196, "simpletooltransform": 197, "templatetransform": 198, "token": [199, 269, 331], "toolcal": 200, "toolregistri": 201, "toolservic": 202, "xmlblockpars": 203, "as_nested_tensor": 204, "as_padded_tensor": 205, "make_composite_from_td": 206, "dreamerdecod": 207, "dreamerenv": 208, "register_gym_spec_convers": 209, "set_exploration_typ": 210, "set_gym_backend": 211, "step_mdp": 212, "terminated_or_trunc": 213, "actiondiscret": 214, "actionmask": 215, "autoresetenv": 216, "autoresettransform": 217, "batchsizetransform": 218, "binarizereward": 219, "burnintransform": 220, "catfram": [221, 638], "cattensor": 222, "centercrop": 223, "cliptransform": 224, "conditionalpolicyswitch": 226, "conditionalskip": 227, "crop": 228, "dtypecasttransform": 229, "devicecasttransform": 230, "discreteactionproject": 231, "doubletofloat": 232, "endoflifetransform": 233, "excludetransform": 234, "finitetensordictcheck": 235, "flattenobserv": 236, "frameskiptransform": 237, "grayscal": 238, "hash": 239, "inittrack": 240, "linearisereward": 242, "moduletransform": 243, "multiact": 244, "noopresetenv": 245, "observationnorm": 246, "observationtransform": 247, "permutetransform": 248, "pinmemorytransform": 249, "r3mtransform": 250, "randomcroptensordict": 251, "removeemptyspec": 252, "renametransform": 253, "resiz": 254, "reward2gotransform": 255, "rewardclip": 256, "rewardsc": 257, "rewardsum": 258, "selecttransform": 259, "signtransform": 260, "squeezetransform": 261, "stepcount": 263, "targetreturn": 264, "tensordictprim": 265, "timemaxpool": 266, "timer": 267, "totensorimag": 268, "trajcount": 270, "transformedenv": 272, "unarytransform": 273, "unsqueezetransform": 274, "vc1transform": 275, "viprewardtransform": 276, "viptransform": 277, "vecgymenvtransform": 278, "vecnorm": [279, 641], "vecnormv2": 280, "gsdenois": 281, "implement_for": 282, "actorcriticoper": 283, "actorcriticwrapp": 284, "actorvalueoper": 285, "additivegaussianmodul": 286, "consistentdropoutmodul": 287, "convnet": 288, "dtactor": 289, "ddpgcnnactor": 290, "ddpgcnnqnet": 291, "ddpgmlpactor": 292, "ddpgmlpqnet": 293, "decisiontransform": 294, "delta": 295, "distributionaldqnnet": 296, "distributionalqvalueactor": 297, "distributionalqvaluemodul": 298, "dreameractor": 299, "duelingcnndqnet": 300, "egreedymodul": 301, "grumodul": 302, "independentnorm": 303, "lstmmodul": 304, "mlp": [305, 622], "maskedcategor": 306, "normalparamextractor": 307, "obsdecod": 308, "obsencod": 309, "onehotcategor": 310, "onlinedtactor": 311, "ornsteinuhlenbeckprocessmodul": 312, "qvalueactor": 313, "qvaluemodul": 314, "rssmposterior": 315, "rssmprior": 316, "rssmrollout": 317, "reparamgradientstrategi": 318, "tanhdelta": 319, "tanhnorm": 320, "truncatednorm": 321, "valueoper": 322, "worldmodelwrapp": 323, "asyncvllm": 324, "chathistori": 325, "llmwrapperbas": 326, "logprob": 327, "remotetransformerswrapp": 329, "text": [330, 632], "transformerswrapp": 332, "make_async_vllm_engin": 333, "make_vllm_work": 334, "stateless_init_process_group": 335, "stateless_init_process_group_async": 336, "vllmwrapper": 337, "squashdim": 338, "actor": [339, 599, 606, 619, 625], "multistepactorwrapp": 340, "probabilisticactor": 341, "randompolici": 342, "safemodul": [343, 599], "safeprobabilisticmodul": 344, "safeprobabilistictensordictsequenti": 345, "safesequenti": 346, "tanhmodul": 347, "a2closs": 348, "cqlloss": 349, "clipppoloss": 350, "crossqloss": 351, "ddpgloss": 352, "dqnloss": 353, "dtloss": 354, "discretecqlloss": 355, "discreteiqlloss": 356, "discretesacloss": 357, "distributionaldqnloss": 358, "dreameractorloss": 359, "dreamermodelloss": 360, "dreamervalueloss": 361, "gailloss": 362, "iqlloss": 363, "klpenppoloss": 364, "lossmodul": [365, 619, 626], "onlinedtloss": 366, "ppoloss": 367, "redqloss": 368, "reinforceloss": 369, "sacloss": 370, "td3bcloss": 371, "td3loss": 372, "valueestim": 373, "add_random_modul": 374, "cispoloss": 375, "cispolossoutput": 376, "dapo": 377, "dapolossoutput": 378, "grpoloss": 379, "grpolossoutput": 380, "llmlossoutput": 381, "mcadvantag": 382, "sftloss": 383, "sftlossoutput": 384, "gae": 385, "td0estim": 386, "td1estim": 387, "tdlambdaestim": 388, "valueestimatorbas": 389, "pixelrendertransform": 390, "tensordictrecord": 391, "videorecord": 392, "logger": [393, 616, 628, 629], "csvlogger": 394, "generate_exp_nam": 395, "get_logg": 396, "mlflowlogg": 397, "tensorboardlogg": 398, "trackiologg": 399, "wandblogg": 400, "rayservic": 401, "servicebas": 402, "get_servic": 403, "set_auto_unwrap_transformed_env": 404, "batchsubsampl": 405, "clearcudacach": 406, "countframeslog": 407, "logscalar": 408, "logvalidationreward": 409, "optimizerhook": 410, "replaybuffertrain": 411, "rewardnorm": 412, "selectkei": 413, "targetnetupdaterhook": 414, "trainer": [415, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 613, 614, 620], "trainerhookbas": 416, "utdrhook": 417, "updateweight": 418, "ppotrain": 419, "sactrain": 420, "config": [421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 640], "asyncdatacollectorconfig": 421, "syncdatacollectorconfig": 422, "configbas": 423, "lazymemmapstorageconfig": 424, "lazystackstorageconfig": 425, "lazytensorstorageconfig": 426, "liststorageconfig": 427, "prioritizedsamplerconfig": 428, "randomsamplerconfig": 429, "replaybufferconfig": 430, "roundrobinwriterconfig": 431, "samplerwithoutreplacementconfig": 432, "slicesamplerconfig": 433, "slicesamplerwithoutreplacementconfig": 434, "storageensembleconfig": 435, "storageensemblewriterconfig": 436, "tensordictreplaybufferconfig": 437, "tensorstorageconfig": 438, "batchedenvconfig": 439, "envconfig": 440, "transformedenvconfig": 441, "envs_lib": [442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458], "braxenvconfig": 442, "dmcontrolenvconfig": 443, "envlibsconfig": 444, "gymenvconfig": 445, "habitatenvconfig": 446, "isaacgymenvconfig": 447, "jumanjienvconfig": 448, "mogymenvconfig": 449, "meltingpotenvconfig": 450, "multithreadedenvconfig": 451, "openmlenvconfig": 452, "openspielenvconfig": 453, "pettingzooenvconfig": 454, "robohiveenvconfig": 455, "smacv2envconfig": 456, "unitymlagentsenvconfig": 457, "vmasenvconfig": 458, "csvloggerconfig": 459, "loggerconfig": 460, "tensorboardloggerconfig": 461, "wandbloggerconfig": 462, "modul": [463, 464, 465, 466, 467, 468, 469, 598, 599, 609, 619, 622, 623, 625, 629, 640], "convnetconfig": 463, "mlpconfig": 464, "modelconfig": 465, "networkconfig": 466, "tanhnormalmodelconfig": 467, "tensordictmoduleconfig": 468, "valuemodelconfig": 469, "object": [470, 471, 591, 596, 605, 619, 626, 640], "lossconfig": 470, "ppolossconfig": 471, "ppotrainerconfig": 472, "trainerconfig": 473, "actiondiscretizerconfig": 474, "actionmaskconfig": 475, "autoresettransformconfig": 476, "batchsizetransformconfig": 477, "binarizerewardconfig": 478, "burnintransformconfig": 479, "catframesconfig": 480, "cattensorsconfig": 481, "centercropconfig": 482, "cliptransformconfig": 483, "composeconfig": 484, "conditionalpolicyswitchconfig": 485, "conditionalskipconfig": 486, "cropconfig": 487, "dtypecasttransformconfig": 488, "devicecasttransformconfig": 489, "discreteactionprojectionconfig": 490, "doubletofloatconfig": 491, "endoflifetransformconfig": 492, "excludetransformconfig": 493, "finitetensordictcheckconfig": 494, "flattenobservationconfig": 495, "frameskiptransformconfig": 496, "grayscaleconfig": 497, "hashconfig": 498, "inittrackerconfig": 499, "klrewardtransformconfig": 500, "lineariserewardsconfig": 501, "multiactionconfig": 502, "multisteptransformconfig": 503, "noopresetenvconfig": 504, "observationnormconfig": 505, "permutetransformconfig": 506, "pinmemorytransformconfig": 507, "r3mtransformconfig": 508, "randomcroptensordictconfig": 509, "removeemptyspecsconfig": 510, "renametransformconfig": 511, "resizeconfig": 512, "reward2gotransformconfig": 513, "rewardclippingconfig": 514, "rewardscalingconfig": 515, "rewardsumconfig": 516, "selecttransformconfig": 517, "signtransformconfig": 518, "squeezetransformconfig": 519, "stackconfig": 520, "stepcounterconfig": 521, "targetreturnconfig": 522, "tensordictprimerconfig": 523, "timemaxpoolconfig": 524, "timerconfig": 525, "totensorimageconfig": 526, "tokenizerconfig": 527, "trajcounterconfig": 528, "transformconfig": 529, "unarytransformconfig": 530, "unsqueezetransformconfig": 531, "vc1transformconfig": 532, "viprewardtransformconfig": 533, "viptransformconfig": 534, "vecgymenvtransformconfig": 535, "vecnormconfig": 536, "vecnormv2config": 537, "util": [538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 595, 604, 614, 616, 634], "asgdconfig": 538, "adadeltaconfig": 539, "adagradconfig": 540, "adamconfig": 541, "adamwconfig": 542, "adamaxconfig": 543, "lbfgsconfig": 544, "lionconfig": 545, "nadamconfig": 546, "radamconfig": 547, "rmspropconfig": 548, "rpropconfig": 549, "sgdconfig": 550, "sparseadamconfig": 551, "correct_for_frame_skip": 552, "get_stats_random_rollout": 553, "make_collector_offpolici": 554, "make_collector_onpolici": 555, "make_dqn_loss": 556, "make_replay_buff": 557, "make_target_updat": 558, "make_train": 559, "parallel_env_constructor": 560, "sync_async_collector": 561, "sync_sync_collector": 562, "transformed_env_constructor": 563, "distributedtransport": 564, "mptransport": 566, "noweightsyncschem": 568, "rpctransport": 569, "raytransport": 572, "sharedmemtransport": 574, "transportbackend": 576, "weightstrategi": 577, "weightsyncschem": 578, "vllmcollectivetransport": 579, "vllmdoublebuffersyncschem": 580, "vllmdoublebuffertransport": 581, "vllmdoublebufferweightreceiv": 582, "vllmdoublebufferweightsend": 583, "vllmweightreceiv": 584, "vllmweightsend": 585, "vllmweightsyncschem": 586, "get_model_metadata": 587, "readm": [588, 630], "tuto": [588, 630], "contribut": [590, 640], "content": 590, "llm": [591, 592, 594, 595, 596, 597, 631, 632], "track": 591, "deprec": 591, "integr": [591, 632, 638], "structur": [593, 595, 632, 638], "topk": 593, "selector": 593, "grpo": 596, "sft": 596, "tensordictmodul": [599, 623, 625, 640], "probabilist": [599, 625], "q": [599, 620, 622, 625], "critic": [600, 606, 634, 635], "estim": [607, 619], "other": [609, 638], "servic": 612, "registri": 612, "overview": [612, 619, 622], "registr": 612, "access": [612, 641], "cross": 612, "worker": 612, "visibl": 612, "namespac": 612, "isol": 612, "cleanup": 612, "python": 612, "executor": 612, "condit": 612, "pattern": 612, "It": 612, "consider": [612, 626], "multipl": 612, "see": 612, "hook": [614, 615, 620], "builder": 614, "_util": 617, "comput": [618, 620, 636, 639], "time": [618, 619, 639], "code": [619, 636], "ddpg": [619, 634], "setup": [619, 622, 631, 632], "The": 619, "__init__": 619, "put": 619, "togeth": [619, 636], "call": 619, "execut": [619, 631, 633, 636], "stat": 619, "build": [619, 620, 629, 631, 638], "evalu": 619, "construct": 619, "target": [619, 620, 626], "result": [619, 621, 631, 634, 635], "conclus": [619, 620, 621, 622, 623, 631, 632, 634, 635, 636, 638], "next": [619, 621, 624, 627, 634, 635, 638], "A": [620, 638], "dqn": [620, 622], "deep": 620, "paramet": [620, 621, 626], "regist": 620, "possibl": 620, "improv": 620, "reinforc": [621, 634, 635], "ppo": [621, 635], "defin": [621, 634, 635], "loop": [621, 622, 623, 629, 634, 635, 636], "recurr": [622, 623], "convolut": 622, "lstm": 622, "select": 622, "further": [622, 626], "read": 622, "export": 623, "introduct": [623, 640], "fast": 623, "recap": 623, "stochast": 623, "aotinductor": 623, "free": 623, "c": 623, "onnx": 623, "rollout": [623, 624, 633, 634, 635, 636, 641], "ted": 624, "s": [625, 626], "special": [625, 640], "output": 626, "first": 629, "tool": 631, "enabl": 631, "interact": 631, "4": [631, 632], "search": 631, "5": [631, 632], "extract": 631, "vllm": 632, "input": 632, "mode": 632, "probabl": 632, "onli": 632, "tensorclass": [632, 638], "6": 632, "handl": 632, "7": 632, "divers": 633, "competit": 634, "map": 634, "pendulum": 636, "write": 636, "_step": 636, "simul": 636, "_reset": 636, "metadata": 636, "_spec": 636, "shape": 636, "seed": [636, 641], "wrap": 636, "test": 636, "our": 636, "pretrain": 637, "vanilla": 638, "tensordict": [638, 640], "pytre": 638, "iter": 638, "over": 638, "fix": 638, "priorit": 638, "save": 638, "raw": 638, "imag": 638, "trajectori": 638, "sequenc": 640, "program": 640, "ensembl": 640, "meta": 640, "vmap": 640, "multiprocess": 640, "frame_skip": 641, "deepmind": 641, "control": 641, "devic": 641, "close": 641, "attribut": 641, "kwarg": 641}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 56}})
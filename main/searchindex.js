Search.setIndex({"docnames": ["index", "reference/collectors", "reference/collectors_basics", "reference/collectors_distributed", "reference/collectors_replay", "reference/collectors_single", "reference/collectors_weightsync", "reference/config", "reference/cudnn_persistent_rnn", "reference/cudnn_rnn_determinism", "reference/data", "reference/data_datasets", "reference/data_replaybuffers", "reference/data_samplers", "reference/data_specs", "reference/data_storage", "reference/envs", "reference/envs_api", "reference/envs_libraries", "reference/envs_multiagent", "reference/envs_recorders", "reference/envs_transforms", "reference/envs_vectorized", "reference/generated/knowledge_base/DEBUGGING_RL", "reference/generated/knowledge_base/GYM", "reference/generated/knowledge_base/HABITAT", "reference/generated/knowledge_base/MUJOCO_INSTALLATION", "reference/generated/knowledge_base/PRO-TIPS", "reference/generated/knowledge_base/RESOURCES", "reference/generated/knowledge_base/VERSIONING_ISSUES", "reference/generated/knowledge_base/VIDEO_CUSTOMISATION", "reference/generated/torchrl.auto_unwrap_transformed_env", "reference/generated/torchrl.collectors.DataCollectorBase", "reference/generated/torchrl.collectors.MultiProcessedWeightUpdater", "reference/generated/torchrl.collectors.MultiSyncDataCollector", "reference/generated/torchrl.collectors.MultiaSyncDataCollector", "reference/generated/torchrl.collectors.RayWeightUpdater", "reference/generated/torchrl.collectors.SyncDataCollector", "reference/generated/torchrl.collectors.VanillaWeightUpdater", "reference/generated/torchrl.collectors.WeightUpdaterBase", "reference/generated/torchrl.collectors.aSyncDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedWeightUpdater", "reference/generated/torchrl.collectors.distributed.RPCDataCollector", "reference/generated/torchrl.collectors.distributed.RPCWeightUpdater", "reference/generated/torchrl.collectors.distributed.RayCollector", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher", "reference/generated/torchrl.collectors.llm.LLMCollector", "reference/generated/torchrl.collectors.llm.RayLLMCollector", "reference/generated/torchrl.collectors.llm.vLLMUpdater", "reference/generated/torchrl.collectors.llm.vLLMUpdaterV2", "reference/generated/torchrl.collectors.utils.split_trajectories", "reference/generated/torchrl.data.Binary", "reference/generated/torchrl.data.Bounded", "reference/generated/torchrl.data.Categorical", "reference/generated/torchrl.data.Composite", "reference/generated/torchrl.data.DiscreteTensorSpec", "reference/generated/torchrl.data.LazyStackedCompositeSpec", "reference/generated/torchrl.data.MultiCategorical", "reference/generated/torchrl.data.MultiDiscreteTensorSpec", "reference/generated/torchrl.data.MultiOneHot", "reference/generated/torchrl.data.NonTensor", "reference/generated/torchrl.data.OneHot", "reference/generated/torchrl.data.PrioritizedReplayBuffer", "reference/generated/torchrl.data.RayReplayBuffer", "reference/generated/torchrl.data.RemoteTensorDictReplayBuffer", "reference/generated/torchrl.data.ReplayBuffer", "reference/generated/torchrl.data.ReplayBufferEnsemble", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer", "reference/generated/torchrl.data.TensorDictReplayBuffer", "reference/generated/torchrl.data.TensorSpec", "reference/generated/torchrl.data.Unbounded", "reference/generated/torchrl.data.UnboundedContinuous", "reference/generated/torchrl.data.UnboundedDiscrete", "reference/generated/torchrl.data.datasets.AtariDQNExperienceReplay", "reference/generated/torchrl.data.datasets.D4RLExperienceReplay", "reference/generated/torchrl.data.datasets.GenDGRLExperienceReplay", "reference/generated/torchrl.data.datasets.MinariExperienceReplay", "reference/generated/torchrl.data.datasets.OpenMLExperienceReplay", "reference/generated/torchrl.data.datasets.OpenXExperienceReplay", "reference/generated/torchrl.data.datasets.RobosetExperienceReplay", "reference/generated/torchrl.data.datasets.VD4RLExperienceReplay", "reference/generated/torchrl.data.llm.ContentBase", "reference/generated/torchrl.data.llm.History", "reference/generated/torchrl.data.llm.TopKRewardSelector", "reference/generated/torchrl.data.llm.add_chat_template", "reference/generated/torchrl.data.replay_buffers.CompressedListStorage", "reference/generated/torchrl.data.replay_buffers.CompressedListStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.FlatStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.H5StorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.ImmutableDatasetWriter", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage", "reference/generated/torchrl.data.replay_buffers.LazyStackStorage", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage", "reference/generated/torchrl.data.replay_buffers.ListStorage", "reference/generated/torchrl.data.replay_buffers.ListStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.NestedStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler", "reference/generated/torchrl.data.replay_buffers.PrioritizedSliceSampler", "reference/generated/torchrl.data.replay_buffers.RandomSampler", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.Sampler", "reference/generated/torchrl.data.replay_buffers.SamplerEnsemble", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.SliceSampler", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.Storage", "reference/generated/torchrl.data.replay_buffers.StorageCheckpointerBase", "reference/generated/torchrl.data.replay_buffers.StorageEnsemble", "reference/generated/torchrl.data.replay_buffers.StorageEnsembleCheckpointer", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.TensorStorage", "reference/generated/torchrl.data.replay_buffers.TensorStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.Writer", "reference/generated/torchrl.data.replay_buffers.WriterEnsemble", "reference/generated/torchrl.envs.AsyncEnvPool", "reference/generated/torchrl.envs.BraxEnv", "reference/generated/torchrl.envs.BraxWrapper", "reference/generated/torchrl.envs.ChessEnv", "reference/generated/torchrl.envs.DMControlEnv", "reference/generated/torchrl.envs.DMControlWrapper", "reference/generated/torchrl.envs.EnvBase", "reference/generated/torchrl.envs.EnvCreator", "reference/generated/torchrl.envs.EnvMetaData", "reference/generated/torchrl.envs.GymEnv", "reference/generated/torchrl.envs.GymLikeEnv", "reference/generated/torchrl.envs.GymWrapper", "reference/generated/torchrl.envs.HabitatEnv", "reference/generated/torchrl.envs.IsaacGymEnv", "reference/generated/torchrl.envs.IsaacGymWrapper", "reference/generated/torchrl.envs.IsaacLabWrapper", "reference/generated/torchrl.envs.JumanjiEnv", "reference/generated/torchrl.envs.JumanjiWrapper", "reference/generated/torchrl.envs.LLMHashingEnv", "reference/generated/torchrl.envs.MOGymEnv", "reference/generated/torchrl.envs.MOGymWrapper", "reference/generated/torchrl.envs.MarlGroupMapType", "reference/generated/torchrl.envs.MeltingpotEnv", "reference/generated/torchrl.envs.MeltingpotWrapper", "reference/generated/torchrl.envs.ModelBasedEnvBase", "reference/generated/torchrl.envs.MultiThreadedEnv", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper", "reference/generated/torchrl.envs.OpenMLEnv", "reference/generated/torchrl.envs.OpenSpielEnv", "reference/generated/torchrl.envs.OpenSpielWrapper", "reference/generated/torchrl.envs.ParallelEnv", "reference/generated/torchrl.envs.PendulumEnv", "reference/generated/torchrl.envs.PettingZooEnv", "reference/generated/torchrl.envs.PettingZooWrapper", "reference/generated/torchrl.envs.ProcessorAsyncEnvPool", "reference/generated/torchrl.envs.RandomPolicy", "reference/generated/torchrl.envs.RoboHiveEnv", "reference/generated/torchrl.envs.SMACv2Env", "reference/generated/torchrl.envs.SMACv2Wrapper", "reference/generated/torchrl.envs.SerialEnv", "reference/generated/torchrl.envs.ThreadingAsyncEnvPool", "reference/generated/torchrl.envs.TicTacToeEnv", "reference/generated/torchrl.envs.UnityMLAgentsEnv", "reference/generated/torchrl.envs.UnityMLAgentsWrapper", "reference/generated/torchrl.envs.VmasEnv", "reference/generated/torchrl.envs.VmasWrapper", "reference/generated/torchrl.envs.check_env_specs", "reference/generated/torchrl.envs.check_marl_grouping", "reference/generated/torchrl.envs.exploration_type", "reference/generated/torchrl.envs.get_available_libraries", "reference/generated/torchrl.envs.gym_backend", "reference/generated/torchrl.envs.llm.ChatEnv", "reference/generated/torchrl.envs.llm.DatasetChatEnv", "reference/generated/torchrl.envs.llm.GSM8KEnv", "reference/generated/torchrl.envs.llm.GSM8KPrepareQuestion", "reference/generated/torchrl.envs.llm.GSM8KRewardParser", "reference/generated/torchrl.envs.llm.IFEvalEnv", "reference/generated/torchrl.envs.llm.IFEvalScoreData", "reference/generated/torchrl.envs.llm.IfEvalScorer", "reference/generated/torchrl.envs.llm.LLMEnv", "reference/generated/torchrl.envs.llm.LLMHashingEnv", "reference/generated/torchrl.envs.llm.MLGymWrapper", "reference/generated/torchrl.envs.llm.make_gsm8k_env", "reference/generated/torchrl.envs.llm.make_mlgym", "reference/generated/torchrl.envs.llm.transforms.AddThinkingPrompt", "reference/generated/torchrl.envs.llm.transforms.BrowserTransform", "reference/generated/torchrl.envs.llm.transforms.DataLoadingPrimer", "reference/generated/torchrl.envs.llm.transforms.ExecuteToolsInOrder", "reference/generated/torchrl.envs.llm.transforms.JSONCallParser", "reference/generated/torchrl.envs.llm.transforms.KLComputation", "reference/generated/torchrl.envs.llm.transforms.KLRewardTransform", "reference/generated/torchrl.envs.llm.transforms.MCPToolTransform", "reference/generated/torchrl.envs.llm.transforms.PolicyVersion", "reference/generated/torchrl.envs.llm.transforms.PythonExecutorService", "reference/generated/torchrl.envs.llm.transforms.PythonInterpreter", "reference/generated/torchrl.envs.llm.transforms.RayDataLoadingPrimer", "reference/generated/torchrl.envs.llm.transforms.RetrieveKL", "reference/generated/torchrl.envs.llm.transforms.RetrieveLogProb", "reference/generated/torchrl.envs.llm.transforms.SimpleToolTransform", "reference/generated/torchrl.envs.llm.transforms.TemplateTransform", "reference/generated/torchrl.envs.llm.transforms.Tokenizer", "reference/generated/torchrl.envs.llm.transforms.ToolCall", "reference/generated/torchrl.envs.llm.transforms.ToolRegistry", "reference/generated/torchrl.envs.llm.transforms.ToolService", "reference/generated/torchrl.envs.llm.transforms.XMLBlockParser", "reference/generated/torchrl.envs.llm.transforms.as_nested_tensor", "reference/generated/torchrl.envs.llm.transforms.as_padded_tensor", "reference/generated/torchrl.envs.make_composite_from_td", "reference/generated/torchrl.envs.model_based.dreamer.DreamerDecoder", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv", "reference/generated/torchrl.envs.register_gym_spec_conversion", "reference/generated/torchrl.envs.set_exploration_type", "reference/generated/torchrl.envs.set_gym_backend", "reference/generated/torchrl.envs.step_mdp", "reference/generated/torchrl.envs.terminated_or_truncated", "reference/generated/torchrl.envs.transforms.ActionDiscretizer", "reference/generated/torchrl.envs.transforms.ActionMask", "reference/generated/torchrl.envs.transforms.AutoResetEnv", "reference/generated/torchrl.envs.transforms.AutoResetTransform", "reference/generated/torchrl.envs.transforms.BatchSizeTransform", "reference/generated/torchrl.envs.transforms.BinarizeReward", "reference/generated/torchrl.envs.transforms.BurnInTransform", "reference/generated/torchrl.envs.transforms.CatFrames", "reference/generated/torchrl.envs.transforms.CatTensors", "reference/generated/torchrl.envs.transforms.CenterCrop", "reference/generated/torchrl.envs.transforms.ClipTransform", "reference/generated/torchrl.envs.transforms.Compose", "reference/generated/torchrl.envs.transforms.ConditionalPolicySwitch", "reference/generated/torchrl.envs.transforms.ConditionalSkip", "reference/generated/torchrl.envs.transforms.Crop", "reference/generated/torchrl.envs.transforms.DTypeCastTransform", "reference/generated/torchrl.envs.transforms.DeviceCastTransform", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection", "reference/generated/torchrl.envs.transforms.DoubleToFloat", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform", "reference/generated/torchrl.envs.transforms.ExcludeTransform", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck", "reference/generated/torchrl.envs.transforms.FlattenObservation", "reference/generated/torchrl.envs.transforms.FrameSkipTransform", "reference/generated/torchrl.envs.transforms.GrayScale", "reference/generated/torchrl.envs.transforms.Hash", "reference/generated/torchrl.envs.transforms.InitTracker", "reference/generated/torchrl.envs.transforms.KLRewardTransform", "reference/generated/torchrl.envs.transforms.LineariseRewards", "reference/generated/torchrl.envs.transforms.ModuleTransform", "reference/generated/torchrl.envs.transforms.MultiAction", "reference/generated/torchrl.envs.transforms.NoopResetEnv", "reference/generated/torchrl.envs.transforms.ObservationNorm", "reference/generated/torchrl.envs.transforms.ObservationTransform", "reference/generated/torchrl.envs.transforms.PermuteTransform", "reference/generated/torchrl.envs.transforms.PinMemoryTransform", "reference/generated/torchrl.envs.transforms.R3MTransform", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict", "reference/generated/torchrl.envs.transforms.RemoveEmptySpecs", "reference/generated/torchrl.envs.transforms.RenameTransform", "reference/generated/torchrl.envs.transforms.Resize", "reference/generated/torchrl.envs.transforms.Reward2GoTransform", "reference/generated/torchrl.envs.transforms.RewardClipping", "reference/generated/torchrl.envs.transforms.RewardScaling", "reference/generated/torchrl.envs.transforms.RewardSum", "reference/generated/torchrl.envs.transforms.SelectTransform", "reference/generated/torchrl.envs.transforms.SignTransform", "reference/generated/torchrl.envs.transforms.SqueezeTransform", "reference/generated/torchrl.envs.transforms.Stack", "reference/generated/torchrl.envs.transforms.StepCounter", "reference/generated/torchrl.envs.transforms.TargetReturn", "reference/generated/torchrl.envs.transforms.TensorDictPrimer", "reference/generated/torchrl.envs.transforms.TimeMaxPool", "reference/generated/torchrl.envs.transforms.Timer", "reference/generated/torchrl.envs.transforms.ToTensorImage", "reference/generated/torchrl.envs.transforms.Tokenizer", "reference/generated/torchrl.envs.transforms.TrajCounter", "reference/generated/torchrl.envs.transforms.Transform", "reference/generated/torchrl.envs.transforms.TransformedEnv", "reference/generated/torchrl.envs.transforms.UnaryTransform", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform", "reference/generated/torchrl.envs.transforms.VC1Transform", "reference/generated/torchrl.envs.transforms.VIPRewardTransform", "reference/generated/torchrl.envs.transforms.VIPTransform", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform", "reference/generated/torchrl.envs.transforms.VecNorm", "reference/generated/torchrl.envs.transforms.VecNormV2", "reference/generated/torchrl.envs.transforms.gSDENoise", "reference/generated/torchrl.implement_for", "reference/generated/torchrl.modules.ActorCriticOperator", "reference/generated/torchrl.modules.ActorCriticWrapper", "reference/generated/torchrl.modules.ActorValueOperator", "reference/generated/torchrl.modules.AdditiveGaussianModule", "reference/generated/torchrl.modules.ConsistentDropoutModule", "reference/generated/torchrl.modules.ConvNet", "reference/generated/torchrl.modules.DTActor", "reference/generated/torchrl.modules.DdpgCnnActor", "reference/generated/torchrl.modules.DdpgCnnQNet", "reference/generated/torchrl.modules.DdpgMlpActor", "reference/generated/torchrl.modules.DdpgMlpQNet", "reference/generated/torchrl.modules.DecisionTransformer", "reference/generated/torchrl.modules.Delta", "reference/generated/torchrl.modules.DistributionalDQNnet", "reference/generated/torchrl.modules.DistributionalQValueActor", "reference/generated/torchrl.modules.DistributionalQValueModule", "reference/generated/torchrl.modules.DreamerActor", "reference/generated/torchrl.modules.DuelingCnnDQNet", "reference/generated/torchrl.modules.EGreedyModule", "reference/generated/torchrl.modules.GRUModule", "reference/generated/torchrl.modules.IndependentNormal", "reference/generated/torchrl.modules.LSTMModule", "reference/generated/torchrl.modules.MLP", "reference/generated/torchrl.modules.MaskedCategorical", "reference/generated/torchrl.modules.NormalParamExtractor", "reference/generated/torchrl.modules.ObsDecoder", "reference/generated/torchrl.modules.ObsEncoder", "reference/generated/torchrl.modules.OneHotCategorical", "reference/generated/torchrl.modules.OnlineDTActor", "reference/generated/torchrl.modules.OrnsteinUhlenbeckProcessModule", "reference/generated/torchrl.modules.QValueActor", "reference/generated/torchrl.modules.QValueModule", "reference/generated/torchrl.modules.RSSMPosterior", "reference/generated/torchrl.modules.RSSMPrior", "reference/generated/torchrl.modules.RSSMRollout", "reference/generated/torchrl.modules.ReparamGradientStrategy", "reference/generated/torchrl.modules.TanhDelta", "reference/generated/torchrl.modules.TanhNormal", "reference/generated/torchrl.modules.TruncatedNormal", "reference/generated/torchrl.modules.ValueOperator", "reference/generated/torchrl.modules.WorldModelWrapper", "reference/generated/torchrl.modules.llm.AsyncVLLM", "reference/generated/torchrl.modules.llm.ChatHistory", "reference/generated/torchrl.modules.llm.LLMWrapperBase", "reference/generated/torchrl.modules.llm.LogProbs", "reference/generated/torchrl.modules.llm.Masks", "reference/generated/torchrl.modules.llm.RemoteTransformersWrapper", "reference/generated/torchrl.modules.llm.Text", "reference/generated/torchrl.modules.llm.Tokens", "reference/generated/torchrl.modules.llm.TransformersWrapper", "reference/generated/torchrl.modules.llm.make_async_vllm_engine", "reference/generated/torchrl.modules.llm.make_vllm_worker", "reference/generated/torchrl.modules.llm.stateless_init_process_group", "reference/generated/torchrl.modules.llm.stateless_init_process_group_async", "reference/generated/torchrl.modules.llm.vLLMWrapper", "reference/generated/torchrl.modules.models.utils.SquashDims", "reference/generated/torchrl.modules.tensordict_module.Actor", "reference/generated/torchrl.modules.tensordict_module.MultiStepActorWrapper", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor", "reference/generated/torchrl.modules.tensordict_module.SafeModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential", "reference/generated/torchrl.modules.tensordict_module.SafeSequential", "reference/generated/torchrl.modules.tensordict_module.TanhModule", "reference/generated/torchrl.objectives.A2CLoss", "reference/generated/torchrl.objectives.CQLLoss", "reference/generated/torchrl.objectives.ClipPPOLoss", "reference/generated/torchrl.objectives.CrossQLoss", "reference/generated/torchrl.objectives.DDPGLoss", "reference/generated/torchrl.objectives.DQNLoss", "reference/generated/torchrl.objectives.DTLoss", "reference/generated/torchrl.objectives.DiscreteCQLLoss", "reference/generated/torchrl.objectives.DiscreteIQLLoss", "reference/generated/torchrl.objectives.DiscreteSACLoss", "reference/generated/torchrl.objectives.DistributionalDQNLoss", "reference/generated/torchrl.objectives.DreamerActorLoss", "reference/generated/torchrl.objectives.DreamerModelLoss", "reference/generated/torchrl.objectives.DreamerValueLoss", "reference/generated/torchrl.objectives.GAILLoss", "reference/generated/torchrl.objectives.IQLLoss", "reference/generated/torchrl.objectives.KLPENPPOLoss", "reference/generated/torchrl.objectives.LossModule", "reference/generated/torchrl.objectives.OnlineDTLoss", "reference/generated/torchrl.objectives.PPOLoss", "reference/generated/torchrl.objectives.REDQLoss", "reference/generated/torchrl.objectives.ReinforceLoss", "reference/generated/torchrl.objectives.SACLoss", "reference/generated/torchrl.objectives.TD3BCLoss", "reference/generated/torchrl.objectives.TD3Loss", "reference/generated/torchrl.objectives.ValueEstimators", "reference/generated/torchrl.objectives.add_random_module", "reference/generated/torchrl.objectives.llm.CISPOLossOutput", "reference/generated/torchrl.objectives.llm.DAPO", "reference/generated/torchrl.objectives.llm.DAPOLossOutput", "reference/generated/torchrl.objectives.llm.GRPOLoss", "reference/generated/torchrl.objectives.llm.GRPOLossOutput", "reference/generated/torchrl.objectives.llm.LLMLossOutput", "reference/generated/torchrl.objectives.llm.MCAdvantage", "reference/generated/torchrl.objectives.llm.SFTLoss", "reference/generated/torchrl.objectives.llm.SFTLossOutput", "reference/generated/torchrl.objectives.value.GAE", "reference/generated/torchrl.objectives.value.TD0Estimator", "reference/generated/torchrl.objectives.value.TD1Estimator", "reference/generated/torchrl.objectives.value.TDLambdaEstimator", "reference/generated/torchrl.objectives.value.ValueEstimatorBase", "reference/generated/torchrl.record.PixelRenderTransform", "reference/generated/torchrl.record.TensorDictRecorder", "reference/generated/torchrl.record.VideoRecorder", "reference/generated/torchrl.record.loggers.Logger", "reference/generated/torchrl.record.loggers.csv.CSVLogger", "reference/generated/torchrl.record.loggers.generate_exp_name", "reference/generated/torchrl.record.loggers.get_logger", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger", "reference/generated/torchrl.record.loggers.wandb.WandbLogger", "reference/generated/torchrl.services.RayService", "reference/generated/torchrl.services.ServiceBase", "reference/generated/torchrl.services.get_services", "reference/generated/torchrl.set_auto_unwrap_transformed_env", "reference/generated/torchrl.trainers.BatchSubSampler", "reference/generated/torchrl.trainers.ClearCudaCache", "reference/generated/torchrl.trainers.CountFramesLog", "reference/generated/torchrl.trainers.LogScalar", "reference/generated/torchrl.trainers.LogValidationReward", "reference/generated/torchrl.trainers.OptimizerHook", "reference/generated/torchrl.trainers.ReplayBufferTrainer", "reference/generated/torchrl.trainers.RewardNormalizer", "reference/generated/torchrl.trainers.SelectKeys", "reference/generated/torchrl.trainers.TargetNetUpdaterHook", "reference/generated/torchrl.trainers.Trainer", "reference/generated/torchrl.trainers.TrainerHookBase", "reference/generated/torchrl.trainers.UTDRHook", "reference/generated/torchrl.trainers.UpdateWeights", "reference/generated/torchrl.trainers.algorithms.PPOTrainer", "reference/generated/torchrl.trainers.algorithms.SACTrainer", "reference/generated/torchrl.trainers.algorithms.configs.collectors.AsyncDataCollectorConfig", "reference/generated/torchrl.trainers.algorithms.configs.collectors.DataCollectorConfig", "reference/generated/torchrl.trainers.algorithms.configs.collectors.MultiSyncDataCollectorConfig", "reference/generated/torchrl.trainers.algorithms.configs.collectors.MultiaSyncDataCollectorConfig", "reference/generated/torchrl.trainers.algorithms.configs.collectors.SyncDataCollectorConfig", "reference/generated/torchrl.trainers.algorithms.configs.common.ConfigBase", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyMemmapStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyStackStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyTensorStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.ListStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.PrioritizedSamplerConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.RandomSamplerConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.ReplayBufferConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.RoundRobinWriterConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.SamplerWithoutReplacementConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerWithoutReplacementConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleWriterConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorDictReplayBufferConfig", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorStorageConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs.BatchedEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs.EnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs.TransformedEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.BraxEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.DMControlEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.EnvLibsConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.GymEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.HabitatEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.IsaacGymEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.JumanjiEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MOGymEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MeltingpotEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MultiThreadedEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenMLEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenSpielEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.PettingZooEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.RoboHiveEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.SMACv2EnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.UnityMLAgentsEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.VmasEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.CSVLoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.LoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.TensorboardLoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.logging.WandbLoggerConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.ConvNetConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.MLPConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.ModelConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.NetworkConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.TanhNormalModelConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.TensorDictModuleConfig", "reference/generated/torchrl.trainers.algorithms.configs.modules.ValueModelConfig", "reference/generated/torchrl.trainers.algorithms.configs.objectives.LossConfig", "reference/generated/torchrl.trainers.algorithms.configs.objectives.PPOLossConfig", "reference/generated/torchrl.trainers.algorithms.configs.trainers.PPOTrainerConfig", "reference/generated/torchrl.trainers.algorithms.configs.trainers.TrainerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionDiscretizerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionMaskConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.AutoResetTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BatchSizeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BinarizeRewardConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BurnInTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatFramesConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatTensorsConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CenterCropConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ClipTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ComposeConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalPolicySwitchConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalSkipConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CropConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DTypeCastTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DeviceCastTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DiscreteActionProjectionConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DoubleToFloatConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.EndOfLifeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ExcludeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FiniteTensorDictCheckConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FlattenObservationConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FrameSkipTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.GrayScaleConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.HashConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.InitTrackerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.KLRewardTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.LineariseRewardsConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiActionConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiStepTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.NoopResetEnvConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ObservationNormConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PermuteTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PinMemoryTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.R3MTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RandomCropTensorDictConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RemoveEmptySpecsConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RenameTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ResizeConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.Reward2GoTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardClippingConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardScalingConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardSumConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SelectTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SignTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SqueezeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StackConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StepCounterConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TargetReturnConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TensorDictPrimerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimeMaxPoolConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ToTensorImageConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TokenizerConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TrajCounterConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnaryTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnsqueezeTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VC1TransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPRewardTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecGymEnvTransformConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormConfig", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormV2Config", "reference/generated/torchrl.trainers.algorithms.configs.utils.ASGDConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdadeltaConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdagradConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamWConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamaxConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.LBFGSConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.LionConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.NAdamConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.RAdamConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.RMSpropConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.RpropConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.SGDConfig", "reference/generated/torchrl.trainers.algorithms.configs.utils.SparseAdamConfig", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy", "reference/generated/torchrl.trainers.helpers.make_dqn_loss", "reference/generated/torchrl.trainers.helpers.make_replay_buffer", "reference/generated/torchrl.trainers.helpers.make_target_updater", "reference/generated/torchrl.trainers.helpers.make_trainer", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor", "reference/generated/torchrl.trainers.helpers.sync_async_collector", "reference/generated/torchrl.trainers.helpers.sync_sync_collector", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor", "reference/generated/torchrl.weight_update.DistributedTransport", "reference/generated/torchrl.weight_update.DistributedWeightSyncScheme", "reference/generated/torchrl.weight_update.MPTransport", "reference/generated/torchrl.weight_update.MultiProcessWeightSyncScheme", "reference/generated/torchrl.weight_update.NoWeightSyncScheme", "reference/generated/torchrl.weight_update.RPCTransport", "reference/generated/torchrl.weight_update.RPCWeightSyncScheme", "reference/generated/torchrl.weight_update.RayActorTransport", "reference/generated/torchrl.weight_update.RayModuleTransformReceiver", "reference/generated/torchrl.weight_update.RayModuleTransformScheme", "reference/generated/torchrl.weight_update.RayModuleTransformSender", "reference/generated/torchrl.weight_update.RayTransport", "reference/generated/torchrl.weight_update.RayWeightSyncScheme", "reference/generated/torchrl.weight_update.SharedMemTransport", "reference/generated/torchrl.weight_update.SharedMemWeightSyncScheme", "reference/generated/torchrl.weight_update.TransportBackend", "reference/generated/torchrl.weight_update.WeightReceiver", "reference/generated/torchrl.weight_update.WeightSender", "reference/generated/torchrl.weight_update.WeightSyncScheme", "reference/generated/torchrl.weight_update.llm.VLLMCollectiveTransport", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferTransport", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightSender", "reference/generated/torchrl.weight_update.llm.VLLMWeightReceiver", "reference/generated/torchrl.weight_update.llm.VLLMWeightSender", "reference/generated/torchrl.weight_update.llm.VLLMWeightSyncScheme", "reference/generated/torchrl.weight_update.llm.get_model_metadata", "reference/generated/tutorials/README", "reference/index", "reference/knowledge_base", "reference/llms", "reference/llms_collectors", "reference/llms_data", "reference/llms_envs", "reference/llms_modules", "reference/llms_objectives", "reference/llms_transforms", "reference/modules", "reference/modules_actors", "reference/modules_critics", "reference/modules_distributions", "reference/modules_exploration", "reference/modules_models", "reference/modules_utils", "reference/objectives", "reference/objectives_actorcritic", "reference/objectives_common", "reference/objectives_offline", "reference/objectives_other", "reference/objectives_policy", "reference/objectives_value", "reference/services", "reference/trainers", "reference/trainers_basics", "reference/trainers_hooks", "reference/trainers_loggers", "reference/utils", "sg_execution_times", "tutorials/coding_ddpg", "tutorials/coding_dqn", "tutorials/coding_ppo", "tutorials/dqn_with_rnn", "tutorials/export", "tutorials/getting-started-0", "tutorials/getting-started-1", "tutorials/getting-started-2", "tutorials/getting-started-3", "tutorials/getting-started-4", "tutorials/getting-started-5", "tutorials/index", "tutorials/llm_browser", "tutorials/llm_wrappers", "tutorials/multi_task", "tutorials/multiagent_competitive_ddpg", "tutorials/multiagent_ppo", "tutorials/pendulum", "tutorials/pretrained_models", "tutorials/rb_tutorial", "tutorials/sg_execution_times", "tutorials/torchrl_demo", "tutorials/torchrl_envs"], "filenames": ["index.rst", "reference/collectors.rst", "reference/collectors_basics.rst", "reference/collectors_distributed.rst", "reference/collectors_replay.rst", "reference/collectors_single.rst", "reference/collectors_weightsync.rst", "reference/config.rst", "reference/cudnn_persistent_rnn.rst", "reference/cudnn_rnn_determinism.rst", "reference/data.rst", "reference/data_datasets.rst", "reference/data_replaybuffers.rst", "reference/data_samplers.rst", "reference/data_specs.rst", "reference/data_storage.rst", "reference/envs.rst", "reference/envs_api.rst", "reference/envs_libraries.rst", "reference/envs_multiagent.rst", "reference/envs_recorders.rst", "reference/envs_transforms.rst", "reference/envs_vectorized.rst", "reference/generated/knowledge_base/DEBUGGING_RL.rst", "reference/generated/knowledge_base/GYM.rst", "reference/generated/knowledge_base/HABITAT.rst", "reference/generated/knowledge_base/MUJOCO_INSTALLATION.rst", "reference/generated/knowledge_base/PRO-TIPS.rst", "reference/generated/knowledge_base/RESOURCES.rst", "reference/generated/knowledge_base/VERSIONING_ISSUES.rst", "reference/generated/knowledge_base/VIDEO_CUSTOMISATION.rst", "reference/generated/torchrl.auto_unwrap_transformed_env.rst", "reference/generated/torchrl.collectors.DataCollectorBase.rst", "reference/generated/torchrl.collectors.MultiProcessedWeightUpdater.rst", "reference/generated/torchrl.collectors.MultiSyncDataCollector.rst", "reference/generated/torchrl.collectors.MultiaSyncDataCollector.rst", "reference/generated/torchrl.collectors.RayWeightUpdater.rst", "reference/generated/torchrl.collectors.SyncDataCollector.rst", "reference/generated/torchrl.collectors.VanillaWeightUpdater.rst", "reference/generated/torchrl.collectors.WeightUpdaterBase.rst", "reference/generated/torchrl.collectors.aSyncDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedWeightUpdater.rst", "reference/generated/torchrl.collectors.distributed.RPCDataCollector.rst", "reference/generated/torchrl.collectors.distributed.RPCWeightUpdater.rst", "reference/generated/torchrl.collectors.distributed.RayCollector.rst", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher.rst", "reference/generated/torchrl.collectors.llm.LLMCollector.rst", "reference/generated/torchrl.collectors.llm.RayLLMCollector.rst", "reference/generated/torchrl.collectors.llm.vLLMUpdater.rst", "reference/generated/torchrl.collectors.llm.vLLMUpdaterV2.rst", "reference/generated/torchrl.collectors.utils.split_trajectories.rst", "reference/generated/torchrl.data.Binary.rst", "reference/generated/torchrl.data.Bounded.rst", "reference/generated/torchrl.data.Categorical.rst", "reference/generated/torchrl.data.Composite.rst", "reference/generated/torchrl.data.DiscreteTensorSpec.rst", "reference/generated/torchrl.data.LazyStackedCompositeSpec.rst", "reference/generated/torchrl.data.MultiCategorical.rst", "reference/generated/torchrl.data.MultiDiscreteTensorSpec.rst", "reference/generated/torchrl.data.MultiOneHot.rst", "reference/generated/torchrl.data.NonTensor.rst", "reference/generated/torchrl.data.OneHot.rst", "reference/generated/torchrl.data.PrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.RayReplayBuffer.rst", "reference/generated/torchrl.data.RemoteTensorDictReplayBuffer.rst", "reference/generated/torchrl.data.ReplayBuffer.rst", "reference/generated/torchrl.data.ReplayBufferEnsemble.rst", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.TensorDictReplayBuffer.rst", "reference/generated/torchrl.data.TensorSpec.rst", "reference/generated/torchrl.data.Unbounded.rst", "reference/generated/torchrl.data.UnboundedContinuous.rst", "reference/generated/torchrl.data.UnboundedDiscrete.rst", "reference/generated/torchrl.data.datasets.AtariDQNExperienceReplay.rst", "reference/generated/torchrl.data.datasets.D4RLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.GenDGRLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.MinariExperienceReplay.rst", "reference/generated/torchrl.data.datasets.OpenMLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.OpenXExperienceReplay.rst", "reference/generated/torchrl.data.datasets.RobosetExperienceReplay.rst", "reference/generated/torchrl.data.datasets.VD4RLExperienceReplay.rst", "reference/generated/torchrl.data.llm.ContentBase.rst", "reference/generated/torchrl.data.llm.History.rst", "reference/generated/torchrl.data.llm.TopKRewardSelector.rst", "reference/generated/torchrl.data.llm.add_chat_template.rst", "reference/generated/torchrl.data.replay_buffers.CompressedListStorage.rst", "reference/generated/torchrl.data.replay_buffers.CompressedListStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.FlatStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.H5StorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.ImmutableDatasetWriter.rst", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage.rst", "reference/generated/torchrl.data.replay_buffers.LazyStackStorage.rst", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.ListStorage.rst", "reference/generated/torchrl.data.replay_buffers.ListStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.NestedStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler.rst", "reference/generated/torchrl.data.replay_buffers.PrioritizedSliceSampler.rst", "reference/generated/torchrl.data.replay_buffers.RandomSampler.rst", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.Sampler.rst", "reference/generated/torchrl.data.replay_buffers.SamplerEnsemble.rst", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.SliceSampler.rst", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.Storage.rst", "reference/generated/torchrl.data.replay_buffers.StorageCheckpointerBase.rst", "reference/generated/torchrl.data.replay_buffers.StorageEnsemble.rst", "reference/generated/torchrl.data.replay_buffers.StorageEnsembleCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.TensorStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.Writer.rst", "reference/generated/torchrl.data.replay_buffers.WriterEnsemble.rst", "reference/generated/torchrl.envs.AsyncEnvPool.rst", "reference/generated/torchrl.envs.BraxEnv.rst", "reference/generated/torchrl.envs.BraxWrapper.rst", "reference/generated/torchrl.envs.ChessEnv.rst", "reference/generated/torchrl.envs.DMControlEnv.rst", "reference/generated/torchrl.envs.DMControlWrapper.rst", "reference/generated/torchrl.envs.EnvBase.rst", "reference/generated/torchrl.envs.EnvCreator.rst", "reference/generated/torchrl.envs.EnvMetaData.rst", "reference/generated/torchrl.envs.GymEnv.rst", "reference/generated/torchrl.envs.GymLikeEnv.rst", "reference/generated/torchrl.envs.GymWrapper.rst", "reference/generated/torchrl.envs.HabitatEnv.rst", "reference/generated/torchrl.envs.IsaacGymEnv.rst", "reference/generated/torchrl.envs.IsaacGymWrapper.rst", "reference/generated/torchrl.envs.IsaacLabWrapper.rst", "reference/generated/torchrl.envs.JumanjiEnv.rst", "reference/generated/torchrl.envs.JumanjiWrapper.rst", "reference/generated/torchrl.envs.LLMHashingEnv.rst", "reference/generated/torchrl.envs.MOGymEnv.rst", "reference/generated/torchrl.envs.MOGymWrapper.rst", "reference/generated/torchrl.envs.MarlGroupMapType.rst", "reference/generated/torchrl.envs.MeltingpotEnv.rst", "reference/generated/torchrl.envs.MeltingpotWrapper.rst", "reference/generated/torchrl.envs.ModelBasedEnvBase.rst", "reference/generated/torchrl.envs.MultiThreadedEnv.rst", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper.rst", "reference/generated/torchrl.envs.OpenMLEnv.rst", "reference/generated/torchrl.envs.OpenSpielEnv.rst", "reference/generated/torchrl.envs.OpenSpielWrapper.rst", "reference/generated/torchrl.envs.ParallelEnv.rst", "reference/generated/torchrl.envs.PendulumEnv.rst", "reference/generated/torchrl.envs.PettingZooEnv.rst", "reference/generated/torchrl.envs.PettingZooWrapper.rst", "reference/generated/torchrl.envs.ProcessorAsyncEnvPool.rst", "reference/generated/torchrl.envs.RandomPolicy.rst", "reference/generated/torchrl.envs.RoboHiveEnv.rst", "reference/generated/torchrl.envs.SMACv2Env.rst", "reference/generated/torchrl.envs.SMACv2Wrapper.rst", "reference/generated/torchrl.envs.SerialEnv.rst", "reference/generated/torchrl.envs.ThreadingAsyncEnvPool.rst", "reference/generated/torchrl.envs.TicTacToeEnv.rst", "reference/generated/torchrl.envs.UnityMLAgentsEnv.rst", "reference/generated/torchrl.envs.UnityMLAgentsWrapper.rst", "reference/generated/torchrl.envs.VmasEnv.rst", "reference/generated/torchrl.envs.VmasWrapper.rst", "reference/generated/torchrl.envs.check_env_specs.rst", "reference/generated/torchrl.envs.check_marl_grouping.rst", "reference/generated/torchrl.envs.exploration_type.rst", "reference/generated/torchrl.envs.get_available_libraries.rst", "reference/generated/torchrl.envs.gym_backend.rst", "reference/generated/torchrl.envs.llm.ChatEnv.rst", "reference/generated/torchrl.envs.llm.DatasetChatEnv.rst", "reference/generated/torchrl.envs.llm.GSM8KEnv.rst", "reference/generated/torchrl.envs.llm.GSM8KPrepareQuestion.rst", "reference/generated/torchrl.envs.llm.GSM8KRewardParser.rst", "reference/generated/torchrl.envs.llm.IFEvalEnv.rst", "reference/generated/torchrl.envs.llm.IFEvalScoreData.rst", "reference/generated/torchrl.envs.llm.IfEvalScorer.rst", "reference/generated/torchrl.envs.llm.LLMEnv.rst", "reference/generated/torchrl.envs.llm.LLMHashingEnv.rst", "reference/generated/torchrl.envs.llm.MLGymWrapper.rst", "reference/generated/torchrl.envs.llm.make_gsm8k_env.rst", "reference/generated/torchrl.envs.llm.make_mlgym.rst", "reference/generated/torchrl.envs.llm.transforms.AddThinkingPrompt.rst", "reference/generated/torchrl.envs.llm.transforms.BrowserTransform.rst", "reference/generated/torchrl.envs.llm.transforms.DataLoadingPrimer.rst", "reference/generated/torchrl.envs.llm.transforms.ExecuteToolsInOrder.rst", "reference/generated/torchrl.envs.llm.transforms.JSONCallParser.rst", "reference/generated/torchrl.envs.llm.transforms.KLComputation.rst", "reference/generated/torchrl.envs.llm.transforms.KLRewardTransform.rst", "reference/generated/torchrl.envs.llm.transforms.MCPToolTransform.rst", "reference/generated/torchrl.envs.llm.transforms.PolicyVersion.rst", "reference/generated/torchrl.envs.llm.transforms.PythonExecutorService.rst", "reference/generated/torchrl.envs.llm.transforms.PythonInterpreter.rst", "reference/generated/torchrl.envs.llm.transforms.RayDataLoadingPrimer.rst", "reference/generated/torchrl.envs.llm.transforms.RetrieveKL.rst", "reference/generated/torchrl.envs.llm.transforms.RetrieveLogProb.rst", "reference/generated/torchrl.envs.llm.transforms.SimpleToolTransform.rst", "reference/generated/torchrl.envs.llm.transforms.TemplateTransform.rst", "reference/generated/torchrl.envs.llm.transforms.Tokenizer.rst", "reference/generated/torchrl.envs.llm.transforms.ToolCall.rst", "reference/generated/torchrl.envs.llm.transforms.ToolRegistry.rst", "reference/generated/torchrl.envs.llm.transforms.ToolService.rst", "reference/generated/torchrl.envs.llm.transforms.XMLBlockParser.rst", "reference/generated/torchrl.envs.llm.transforms.as_nested_tensor.rst", "reference/generated/torchrl.envs.llm.transforms.as_padded_tensor.rst", "reference/generated/torchrl.envs.make_composite_from_td.rst", "reference/generated/torchrl.envs.model_based.dreamer.DreamerDecoder.rst", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv.rst", "reference/generated/torchrl.envs.register_gym_spec_conversion.rst", "reference/generated/torchrl.envs.set_exploration_type.rst", "reference/generated/torchrl.envs.set_gym_backend.rst", "reference/generated/torchrl.envs.step_mdp.rst", "reference/generated/torchrl.envs.terminated_or_truncated.rst", "reference/generated/torchrl.envs.transforms.ActionDiscretizer.rst", "reference/generated/torchrl.envs.transforms.ActionMask.rst", "reference/generated/torchrl.envs.transforms.AutoResetEnv.rst", "reference/generated/torchrl.envs.transforms.AutoResetTransform.rst", "reference/generated/torchrl.envs.transforms.BatchSizeTransform.rst", "reference/generated/torchrl.envs.transforms.BinarizeReward.rst", "reference/generated/torchrl.envs.transforms.BurnInTransform.rst", "reference/generated/torchrl.envs.transforms.CatFrames.rst", "reference/generated/torchrl.envs.transforms.CatTensors.rst", "reference/generated/torchrl.envs.transforms.CenterCrop.rst", "reference/generated/torchrl.envs.transforms.ClipTransform.rst", "reference/generated/torchrl.envs.transforms.Compose.rst", "reference/generated/torchrl.envs.transforms.ConditionalPolicySwitch.rst", "reference/generated/torchrl.envs.transforms.ConditionalSkip.rst", "reference/generated/torchrl.envs.transforms.Crop.rst", "reference/generated/torchrl.envs.transforms.DTypeCastTransform.rst", "reference/generated/torchrl.envs.transforms.DeviceCastTransform.rst", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection.rst", "reference/generated/torchrl.envs.transforms.DoubleToFloat.rst", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform.rst", "reference/generated/torchrl.envs.transforms.ExcludeTransform.rst", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck.rst", "reference/generated/torchrl.envs.transforms.FlattenObservation.rst", "reference/generated/torchrl.envs.transforms.FrameSkipTransform.rst", "reference/generated/torchrl.envs.transforms.GrayScale.rst", "reference/generated/torchrl.envs.transforms.Hash.rst", "reference/generated/torchrl.envs.transforms.InitTracker.rst", "reference/generated/torchrl.envs.transforms.KLRewardTransform.rst", "reference/generated/torchrl.envs.transforms.LineariseRewards.rst", "reference/generated/torchrl.envs.transforms.ModuleTransform.rst", "reference/generated/torchrl.envs.transforms.MultiAction.rst", "reference/generated/torchrl.envs.transforms.NoopResetEnv.rst", "reference/generated/torchrl.envs.transforms.ObservationNorm.rst", "reference/generated/torchrl.envs.transforms.ObservationTransform.rst", "reference/generated/torchrl.envs.transforms.PermuteTransform.rst", "reference/generated/torchrl.envs.transforms.PinMemoryTransform.rst", "reference/generated/torchrl.envs.transforms.R3MTransform.rst", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict.rst", "reference/generated/torchrl.envs.transforms.RemoveEmptySpecs.rst", "reference/generated/torchrl.envs.transforms.RenameTransform.rst", "reference/generated/torchrl.envs.transforms.Resize.rst", "reference/generated/torchrl.envs.transforms.Reward2GoTransform.rst", "reference/generated/torchrl.envs.transforms.RewardClipping.rst", "reference/generated/torchrl.envs.transforms.RewardScaling.rst", "reference/generated/torchrl.envs.transforms.RewardSum.rst", "reference/generated/torchrl.envs.transforms.SelectTransform.rst", "reference/generated/torchrl.envs.transforms.SignTransform.rst", "reference/generated/torchrl.envs.transforms.SqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.Stack.rst", "reference/generated/torchrl.envs.transforms.StepCounter.rst", "reference/generated/torchrl.envs.transforms.TargetReturn.rst", "reference/generated/torchrl.envs.transforms.TensorDictPrimer.rst", "reference/generated/torchrl.envs.transforms.TimeMaxPool.rst", "reference/generated/torchrl.envs.transforms.Timer.rst", "reference/generated/torchrl.envs.transforms.ToTensorImage.rst", "reference/generated/torchrl.envs.transforms.Tokenizer.rst", "reference/generated/torchrl.envs.transforms.TrajCounter.rst", "reference/generated/torchrl.envs.transforms.Transform.rst", "reference/generated/torchrl.envs.transforms.TransformedEnv.rst", "reference/generated/torchrl.envs.transforms.UnaryTransform.rst", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.VC1Transform.rst", "reference/generated/torchrl.envs.transforms.VIPRewardTransform.rst", "reference/generated/torchrl.envs.transforms.VIPTransform.rst", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform.rst", "reference/generated/torchrl.envs.transforms.VecNorm.rst", "reference/generated/torchrl.envs.transforms.VecNormV2.rst", "reference/generated/torchrl.envs.transforms.gSDENoise.rst", "reference/generated/torchrl.implement_for.rst", "reference/generated/torchrl.modules.ActorCriticOperator.rst", "reference/generated/torchrl.modules.ActorCriticWrapper.rst", "reference/generated/torchrl.modules.ActorValueOperator.rst", "reference/generated/torchrl.modules.AdditiveGaussianModule.rst", "reference/generated/torchrl.modules.ConsistentDropoutModule.rst", "reference/generated/torchrl.modules.ConvNet.rst", "reference/generated/torchrl.modules.DTActor.rst", "reference/generated/torchrl.modules.DdpgCnnActor.rst", "reference/generated/torchrl.modules.DdpgCnnQNet.rst", "reference/generated/torchrl.modules.DdpgMlpActor.rst", "reference/generated/torchrl.modules.DdpgMlpQNet.rst", "reference/generated/torchrl.modules.DecisionTransformer.rst", "reference/generated/torchrl.modules.Delta.rst", "reference/generated/torchrl.modules.DistributionalDQNnet.rst", "reference/generated/torchrl.modules.DistributionalQValueActor.rst", "reference/generated/torchrl.modules.DistributionalQValueModule.rst", "reference/generated/torchrl.modules.DreamerActor.rst", "reference/generated/torchrl.modules.DuelingCnnDQNet.rst", "reference/generated/torchrl.modules.EGreedyModule.rst", "reference/generated/torchrl.modules.GRUModule.rst", "reference/generated/torchrl.modules.IndependentNormal.rst", "reference/generated/torchrl.modules.LSTMModule.rst", "reference/generated/torchrl.modules.MLP.rst", "reference/generated/torchrl.modules.MaskedCategorical.rst", "reference/generated/torchrl.modules.NormalParamExtractor.rst", "reference/generated/torchrl.modules.ObsDecoder.rst", "reference/generated/torchrl.modules.ObsEncoder.rst", "reference/generated/torchrl.modules.OneHotCategorical.rst", "reference/generated/torchrl.modules.OnlineDTActor.rst", "reference/generated/torchrl.modules.OrnsteinUhlenbeckProcessModule.rst", "reference/generated/torchrl.modules.QValueActor.rst", "reference/generated/torchrl.modules.QValueModule.rst", "reference/generated/torchrl.modules.RSSMPosterior.rst", "reference/generated/torchrl.modules.RSSMPrior.rst", "reference/generated/torchrl.modules.RSSMRollout.rst", "reference/generated/torchrl.modules.ReparamGradientStrategy.rst", "reference/generated/torchrl.modules.TanhDelta.rst", "reference/generated/torchrl.modules.TanhNormal.rst", "reference/generated/torchrl.modules.TruncatedNormal.rst", "reference/generated/torchrl.modules.ValueOperator.rst", "reference/generated/torchrl.modules.WorldModelWrapper.rst", "reference/generated/torchrl.modules.llm.AsyncVLLM.rst", "reference/generated/torchrl.modules.llm.ChatHistory.rst", "reference/generated/torchrl.modules.llm.LLMWrapperBase.rst", "reference/generated/torchrl.modules.llm.LogProbs.rst", "reference/generated/torchrl.modules.llm.Masks.rst", "reference/generated/torchrl.modules.llm.RemoteTransformersWrapper.rst", "reference/generated/torchrl.modules.llm.Text.rst", "reference/generated/torchrl.modules.llm.Tokens.rst", "reference/generated/torchrl.modules.llm.TransformersWrapper.rst", "reference/generated/torchrl.modules.llm.make_async_vllm_engine.rst", "reference/generated/torchrl.modules.llm.make_vllm_worker.rst", "reference/generated/torchrl.modules.llm.stateless_init_process_group.rst", "reference/generated/torchrl.modules.llm.stateless_init_process_group_async.rst", "reference/generated/torchrl.modules.llm.vLLMWrapper.rst", "reference/generated/torchrl.modules.models.utils.SquashDims.rst", "reference/generated/torchrl.modules.tensordict_module.Actor.rst", "reference/generated/torchrl.modules.tensordict_module.MultiStepActorWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor.rst", "reference/generated/torchrl.modules.tensordict_module.SafeModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential.rst", "reference/generated/torchrl.modules.tensordict_module.SafeSequential.rst", "reference/generated/torchrl.modules.tensordict_module.TanhModule.rst", "reference/generated/torchrl.objectives.A2CLoss.rst", "reference/generated/torchrl.objectives.CQLLoss.rst", "reference/generated/torchrl.objectives.ClipPPOLoss.rst", "reference/generated/torchrl.objectives.CrossQLoss.rst", "reference/generated/torchrl.objectives.DDPGLoss.rst", "reference/generated/torchrl.objectives.DQNLoss.rst", "reference/generated/torchrl.objectives.DTLoss.rst", "reference/generated/torchrl.objectives.DiscreteCQLLoss.rst", "reference/generated/torchrl.objectives.DiscreteIQLLoss.rst", "reference/generated/torchrl.objectives.DiscreteSACLoss.rst", "reference/generated/torchrl.objectives.DistributionalDQNLoss.rst", "reference/generated/torchrl.objectives.DreamerActorLoss.rst", "reference/generated/torchrl.objectives.DreamerModelLoss.rst", "reference/generated/torchrl.objectives.DreamerValueLoss.rst", "reference/generated/torchrl.objectives.GAILLoss.rst", "reference/generated/torchrl.objectives.IQLLoss.rst", "reference/generated/torchrl.objectives.KLPENPPOLoss.rst", "reference/generated/torchrl.objectives.LossModule.rst", "reference/generated/torchrl.objectives.OnlineDTLoss.rst", "reference/generated/torchrl.objectives.PPOLoss.rst", "reference/generated/torchrl.objectives.REDQLoss.rst", "reference/generated/torchrl.objectives.ReinforceLoss.rst", "reference/generated/torchrl.objectives.SACLoss.rst", "reference/generated/torchrl.objectives.TD3BCLoss.rst", "reference/generated/torchrl.objectives.TD3Loss.rst", "reference/generated/torchrl.objectives.ValueEstimators.rst", "reference/generated/torchrl.objectives.add_random_module.rst", "reference/generated/torchrl.objectives.llm.CISPOLossOutput.rst", "reference/generated/torchrl.objectives.llm.DAPO.rst", "reference/generated/torchrl.objectives.llm.DAPOLossOutput.rst", "reference/generated/torchrl.objectives.llm.GRPOLoss.rst", "reference/generated/torchrl.objectives.llm.GRPOLossOutput.rst", "reference/generated/torchrl.objectives.llm.LLMLossOutput.rst", "reference/generated/torchrl.objectives.llm.MCAdvantage.rst", "reference/generated/torchrl.objectives.llm.SFTLoss.rst", "reference/generated/torchrl.objectives.llm.SFTLossOutput.rst", "reference/generated/torchrl.objectives.value.GAE.rst", "reference/generated/torchrl.objectives.value.TD0Estimator.rst", "reference/generated/torchrl.objectives.value.TD1Estimator.rst", "reference/generated/torchrl.objectives.value.TDLambdaEstimator.rst", "reference/generated/torchrl.objectives.value.ValueEstimatorBase.rst", "reference/generated/torchrl.record.PixelRenderTransform.rst", "reference/generated/torchrl.record.TensorDictRecorder.rst", "reference/generated/torchrl.record.VideoRecorder.rst", "reference/generated/torchrl.record.loggers.Logger.rst", "reference/generated/torchrl.record.loggers.csv.CSVLogger.rst", "reference/generated/torchrl.record.loggers.generate_exp_name.rst", "reference/generated/torchrl.record.loggers.get_logger.rst", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger.rst", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger.rst", "reference/generated/torchrl.record.loggers.wandb.WandbLogger.rst", "reference/generated/torchrl.services.RayService.rst", "reference/generated/torchrl.services.ServiceBase.rst", "reference/generated/torchrl.services.get_services.rst", "reference/generated/torchrl.set_auto_unwrap_transformed_env.rst", "reference/generated/torchrl.trainers.BatchSubSampler.rst", "reference/generated/torchrl.trainers.ClearCudaCache.rst", "reference/generated/torchrl.trainers.CountFramesLog.rst", "reference/generated/torchrl.trainers.LogScalar.rst", "reference/generated/torchrl.trainers.LogValidationReward.rst", "reference/generated/torchrl.trainers.OptimizerHook.rst", "reference/generated/torchrl.trainers.ReplayBufferTrainer.rst", "reference/generated/torchrl.trainers.RewardNormalizer.rst", "reference/generated/torchrl.trainers.SelectKeys.rst", "reference/generated/torchrl.trainers.TargetNetUpdaterHook.rst", "reference/generated/torchrl.trainers.Trainer.rst", "reference/generated/torchrl.trainers.TrainerHookBase.rst", "reference/generated/torchrl.trainers.UTDRHook.rst", "reference/generated/torchrl.trainers.UpdateWeights.rst", "reference/generated/torchrl.trainers.algorithms.PPOTrainer.rst", "reference/generated/torchrl.trainers.algorithms.SACTrainer.rst", "reference/generated/torchrl.trainers.algorithms.configs.collectors.AsyncDataCollectorConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.collectors.DataCollectorConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.collectors.MultiSyncDataCollectorConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.collectors.MultiaSyncDataCollectorConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.collectors.SyncDataCollectorConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.common.ConfigBase.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyMemmapStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyStackStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.LazyTensorStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.ListStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.PrioritizedSamplerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.RandomSamplerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.ReplayBufferConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.RoundRobinWriterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.SamplerWithoutReplacementConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.SliceSamplerWithoutReplacementConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.StorageEnsembleWriterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorDictReplayBufferConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.data.TensorStorageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs.BatchedEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs.EnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs.TransformedEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.BraxEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.DMControlEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.EnvLibsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.GymEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.HabitatEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.IsaacGymEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.JumanjiEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MOGymEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MeltingpotEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.MultiThreadedEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenMLEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.OpenSpielEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.PettingZooEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.RoboHiveEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.SMACv2EnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.UnityMLAgentsEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.envs_libs.VmasEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.CSVLoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.LoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.TensorboardLoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.logging.WandbLoggerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.ConvNetConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.MLPConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.ModelConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.NetworkConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.TanhNormalModelConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.TensorDictModuleConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.modules.ValueModelConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.objectives.LossConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.objectives.PPOLossConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.trainers.PPOTrainerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.trainers.TrainerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionDiscretizerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ActionMaskConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.AutoResetTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BatchSizeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BinarizeRewardConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.BurnInTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatFramesConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CatTensorsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CenterCropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ClipTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ComposeConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalPolicySwitchConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ConditionalSkipConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.CropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DTypeCastTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DeviceCastTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DiscreteActionProjectionConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.DoubleToFloatConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.EndOfLifeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ExcludeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FiniteTensorDictCheckConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FlattenObservationConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.FrameSkipTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.GrayScaleConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.HashConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.InitTrackerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.KLRewardTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.LineariseRewardsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiActionConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.MultiStepTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.NoopResetEnvConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ObservationNormConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PermuteTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.PinMemoryTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.R3MTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RandomCropTensorDictConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RemoveEmptySpecsConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RenameTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ResizeConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.Reward2GoTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardClippingConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardScalingConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.RewardSumConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SelectTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SignTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.SqueezeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StackConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.StepCounterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TargetReturnConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TensorDictPrimerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimeMaxPoolConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TimerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.ToTensorImageConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TokenizerConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TrajCounterConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.TransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnaryTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.UnsqueezeTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VC1TransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPRewardTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VIPTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecGymEnvTransformConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.transforms.VecNormV2Config.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.ASGDConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdadeltaConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdagradConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamWConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.AdamaxConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.LBFGSConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.LionConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.NAdamConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.RAdamConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.RMSpropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.RpropConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.SGDConfig.rst", "reference/generated/torchrl.trainers.algorithms.configs.utils.SparseAdamConfig.rst", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip.rst", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout.rst", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_dqn_loss.rst", "reference/generated/torchrl.trainers.helpers.make_replay_buffer.rst", "reference/generated/torchrl.trainers.helpers.make_target_updater.rst", "reference/generated/torchrl.trainers.helpers.make_trainer.rst", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor.rst", "reference/generated/torchrl.trainers.helpers.sync_async_collector.rst", "reference/generated/torchrl.trainers.helpers.sync_sync_collector.rst", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor.rst", "reference/generated/torchrl.weight_update.DistributedTransport.rst", "reference/generated/torchrl.weight_update.DistributedWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.MPTransport.rst", "reference/generated/torchrl.weight_update.MultiProcessWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.NoWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.RPCTransport.rst", "reference/generated/torchrl.weight_update.RPCWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.RayActorTransport.rst", "reference/generated/torchrl.weight_update.RayModuleTransformReceiver.rst", "reference/generated/torchrl.weight_update.RayModuleTransformScheme.rst", "reference/generated/torchrl.weight_update.RayModuleTransformSender.rst", "reference/generated/torchrl.weight_update.RayTransport.rst", "reference/generated/torchrl.weight_update.RayWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.SharedMemTransport.rst", "reference/generated/torchrl.weight_update.SharedMemWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.TransportBackend.rst", "reference/generated/torchrl.weight_update.WeightReceiver.rst", "reference/generated/torchrl.weight_update.WeightSender.rst", "reference/generated/torchrl.weight_update.WeightSyncScheme.rst", "reference/generated/torchrl.weight_update.llm.VLLMCollectiveTransport.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferTransport.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver.rst", "reference/generated/torchrl.weight_update.llm.VLLMDoubleBufferWeightSender.rst", "reference/generated/torchrl.weight_update.llm.VLLMWeightReceiver.rst", "reference/generated/torchrl.weight_update.llm.VLLMWeightSender.rst", "reference/generated/torchrl.weight_update.llm.VLLMWeightSyncScheme.rst", "reference/generated/torchrl.weight_update.llm.get_model_metadata.rst", "reference/generated/tutorials/README.rst", "reference/index.rst", "reference/knowledge_base.rst", "reference/llms.rst", "reference/llms_collectors.rst", "reference/llms_data.rst", "reference/llms_envs.rst", "reference/llms_modules.rst", "reference/llms_objectives.rst", "reference/llms_transforms.rst", "reference/modules.rst", "reference/modules_actors.rst", "reference/modules_critics.rst", "reference/modules_distributions.rst", "reference/modules_exploration.rst", "reference/modules_models.rst", "reference/modules_utils.rst", "reference/objectives.rst", "reference/objectives_actorcritic.rst", "reference/objectives_common.rst", "reference/objectives_offline.rst", "reference/objectives_other.rst", "reference/objectives_policy.rst", "reference/objectives_value.rst", "reference/services.rst", "reference/trainers.rst", "reference/trainers_basics.rst", "reference/trainers_hooks.rst", "reference/trainers_loggers.rst", "reference/utils.rst", "sg_execution_times.rst", "tutorials/coding_ddpg.rst", "tutorials/coding_dqn.rst", "tutorials/coding_ppo.rst", "tutorials/dqn_with_rnn.rst", "tutorials/export.rst", "tutorials/getting-started-0.rst", "tutorials/getting-started-1.rst", "tutorials/getting-started-2.rst", "tutorials/getting-started-3.rst", "tutorials/getting-started-4.rst", "tutorials/getting-started-5.rst", "tutorials/index.rst", "tutorials/llm_browser.rst", "tutorials/llm_wrappers.rst", "tutorials/multi_task.rst", "tutorials/multiagent_competitive_ddpg.rst", "tutorials/multiagent_ppo.rst", "tutorials/pendulum.rst", "tutorials/pretrained_models.rst", "tutorials/rb_tutorial.rst", "tutorials/sg_execution_times.rst", "tutorials/torchrl_demo.rst", "tutorials/torchrl_envs.rst"], "titles": ["TorchRL", "torchrl.collectors package", "Collector Basics", "Distributed Collectors", "Collectors and Replay Buffers", "Single Node Collectors", "Weight Synchronization", "TorchRL Configuration System", "&lt;no title&gt;", "&lt;no title&gt;", "torchrl.data package", "Datasets", "Replay Buffers", "Sampling Strategies", "TensorSpec System", "Storage Backends", "torchrl.envs package", "Environment API", "Library Wrappers", "Multi-agent Environments", "Recorders", "Transforms", "Vectorized and Parallel Environments", "Things to consider when debugging RL", "Working with gym", "Working with <code class=\"docutils literal notranslate\"><span class=\"pre\">habitat-lab</span></code>", "Working with MuJoCo-based environments", "Common PyTorch errors and solutions", "Useful resources", "Versioning Issues", "Customising Video Renders", "auto_unwrap_transformed_env", "DataCollectorBase", "MultiProcessedWeightUpdater", "MultiSyncDataCollector", "MultiaSyncDataCollector", "RayWeightUpdater", "SyncDataCollector", "VanillaWeightUpdater", "WeightUpdaterBase", "aSyncDataCollector", "DistributedDataCollector", "DistributedSyncDataCollector", "DistributedWeightUpdater", "RPCDataCollector", "RPCWeightUpdater", "RayCollector", "submitit_delayed_launcher", "LLMCollector", "RayLLMCollector", "vLLMUpdater", "vLLMUpdaterV2", "split_trajectories", "Binary", "Bounded", "Categorical", "Composite", "DiscreteTensorSpec", "LazyStackedCompositeSpec", "MultiCategorical", "MultiDiscreteTensorSpec", "MultiOneHot", "NonTensor", "OneHot", "PrioritizedReplayBuffer", "RayReplayBuffer", "RemoteTensorDictReplayBuffer", "ReplayBuffer", "ReplayBufferEnsemble", "TensorDictPrioritizedReplayBuffer", "TensorDictReplayBuffer", "TensorSpec", "Unbounded", "UnboundedContinuous", "UnboundedDiscrete", "AtariDQNExperienceReplay", "D4RLExperienceReplay", "GenDGRLExperienceReplay", "MinariExperienceReplay", "OpenMLExperienceReplay", "OpenXExperienceReplay", "RobosetExperienceReplay", "VD4RLExperienceReplay", "ContentBase", "History", "TopKRewardSelector", "add_chat_template", "CompressedListStorage", "CompressedListStorageCheckpointer", "FlatStorageCheckpointer", "H5StorageCheckpointer", "ImmutableDatasetWriter", "LazyMemmapStorage", "LazyStackStorage", "LazyTensorStorage", "ListStorage", "ListStorageCheckpointer", "NestedStorageCheckpointer", "PrioritizedSampler", "PrioritizedSliceSampler", "RandomSampler", "RoundRobinWriter", "Sampler", "SamplerEnsemble", "SamplerWithoutReplacement", "SliceSampler", "SliceSamplerWithoutReplacement", "Storage", "StorageCheckpointerBase", "StorageEnsemble", "StorageEnsembleCheckpointer", "TensorDictMaxValueWriter", "TensorDictRoundRobinWriter", "TensorStorage", "TensorStorageCheckpointer", "Writer", "WriterEnsemble", "AsyncEnvPool", "BraxEnv", "BraxWrapper", "ChessEnv", "DMControlEnv", "DMControlWrapper", "EnvBase", "EnvCreator", "EnvMetaData", "GymEnv", "GymLikeEnv", "GymWrapper", "HabitatEnv", "IsaacGymEnv", "IsaacGymWrapper", "IsaacLabWrapper", "JumanjiEnv", "JumanjiWrapper", "LLMHashingEnv", "MOGymEnv", "MOGymWrapper", "MarlGroupMapType", "MeltingpotEnv", "MeltingpotWrapper", "ModelBasedEnvBase", "MultiThreadedEnv", "MultiThreadedEnvWrapper", "OpenMLEnv", "OpenSpielEnv", "OpenSpielWrapper", "ParallelEnv", "PendulumEnv", "PettingZooEnv", "PettingZooWrapper", "ProcessorAsyncEnvPool", "RandomPolicy", "RoboHiveEnv", "SMACv2Env", "SMACv2Wrapper", "SerialEnv", "ThreadingAsyncEnvPool", "TicTacToeEnv", "UnityMLAgentsEnv", "UnityMLAgentsWrapper", "VmasEnv", "VmasWrapper", "check_env_specs", "check_marl_grouping", "exploration_type", "get_available_libraries", "gym_backend", "ChatEnv", "DatasetChatEnv", "GSM8KEnv", "GSM8KPrepareQuestion", "GSM8KRewardParser", "IFEvalEnv", "IFEvalScoreData", "IfEvalScorer", "LLMEnv", "LLMHashingEnv", "MLGymWrapper", "make_gsm8k_env", "make_mlgym", "AddThinkingPrompt", "BrowserTransform", "DataLoadingPrimer", "ExecuteToolsInOrder", "JSONCallParser", "KLComputation", "KLRewardTransform", "MCPToolTransform", "PolicyVersion", "PythonExecutorService", "PythonInterpreter", "RayDataLoadingPrimer", "RetrieveKL", "RetrieveLogProb", "SimpleToolTransform", "TemplateTransform", "Tokenizer", "ToolCall", "ToolRegistry", "ToolService", "XMLBlockParser", "as_nested_tensor", "as_padded_tensor", "make_composite_from_td", "DreamerDecoder", "DreamerEnv", "register_gym_spec_conversion", "set_exploration_type", "set_gym_backend", "step_mdp", "terminated_or_truncated", "ActionDiscretizer", "ActionMask", "AutoResetEnv", "AutoResetTransform", "BatchSizeTransform", "BinarizeReward", "BurnInTransform", "CatFrames", "CatTensors", "CenterCrop", "ClipTransform", "Compose", "ConditionalPolicySwitch", "ConditionalSkip", "Crop", "DTypeCastTransform", "DeviceCastTransform", "DiscreteActionProjection", "DoubleToFloat", "EndOfLifeTransform", "ExcludeTransform", "FiniteTensorDictCheck", "FlattenObservation", "FrameSkipTransform", "GrayScale", "Hash", "InitTracker", "KLRewardTransform", "LineariseRewards", "ModuleTransform", "MultiAction", "NoopResetEnv", "ObservationNorm", "ObservationTransform", "PermuteTransform", "PinMemoryTransform", "R3MTransform", "RandomCropTensorDict", "RemoveEmptySpecs", "RenameTransform", "Resize", "Reward2GoTransform", "RewardClipping", "RewardScaling", "RewardSum", "SelectTransform", "SignTransform", "SqueezeTransform", "Stack", "StepCounter", "TargetReturn", "TensorDictPrimer", "TimeMaxPool", "Timer", "ToTensorImage", "Tokenizer", "TrajCounter", "Transform", "TransformedEnv", "UnaryTransform", "UnsqueezeTransform", "VC1Transform", "VIPRewardTransform", "VIPTransform", "VecGymEnvTransform", "VecNorm", "VecNormV2", "gSDENoise", "implement_for", "ActorCriticOperator", "ActorCriticWrapper", "ActorValueOperator", "AdditiveGaussianModule", "ConsistentDropoutModule", "ConvNet", "DTActor", "DdpgCnnActor", "DdpgCnnQNet", "DdpgMlpActor", "DdpgMlpQNet", "DecisionTransformer", "Delta", "DistributionalDQNnet", "DistributionalQValueActor", "DistributionalQValueModule", "DreamerActor", "DuelingCnnDQNet", "EGreedyModule", "GRUModule", "IndependentNormal", "LSTMModule", "MLP", "MaskedCategorical", "NormalParamExtractor", "ObsDecoder", "ObsEncoder", "OneHotCategorical", "OnlineDTActor", "OrnsteinUhlenbeckProcessModule", "QValueActor", "QValueModule", "RSSMPosterior", "RSSMPrior", "RSSMRollout", "ReparamGradientStrategy", "TanhDelta", "TanhNormal", "TruncatedNormal", "ValueOperator", "WorldModelWrapper", "AsyncVLLM", "ChatHistory", "LLMWrapperBase", "LogProbs", "Masks", "RemoteTransformersWrapper", "Text", "Tokens", "TransformersWrapper", "make_async_vllm_engine", "make_vllm_worker", "stateless_init_process_group", "stateless_init_process_group_async", "vLLMWrapper", "SquashDims", "Actor", "MultiStepActorWrapper", "ProbabilisticActor", "SafeModule", "SafeProbabilisticModule", "SafeProbabilisticTensorDictSequential", "SafeSequential", "TanhModule", "A2CLoss", "CQLLoss", "ClipPPOLoss", "CrossQLoss", "DDPGLoss", "DQNLoss", "DTLoss", "DiscreteCQLLoss", "DiscreteIQLLoss", "DiscreteSACLoss", "DistributionalDQNLoss", "DreamerActorLoss", "DreamerModelLoss", "DreamerValueLoss", "GAILLoss", "IQLLoss", "KLPENPPOLoss", "LossModule", "OnlineDTLoss", "PPOLoss", "REDQLoss", "ReinforceLoss", "SACLoss", "TD3BCLoss", "TD3Loss", "ValueEstimators", "add_random_module", "CISPOLossOutput", "DAPO", "DAPOLossOutput", "GRPOLoss", "GRPOLossOutput", "LLMLossOutput", "MCAdvantage", "SFTLoss", "SFTLossOutput", "GAE", "TD0Estimator", "TD1Estimator", "TDLambdaEstimator", "ValueEstimatorBase", "PixelRenderTransform", "TensorDictRecorder", "VideoRecorder", "Logger", "CSVLogger", "generate_exp_name", "get_logger", "MLFlowLogger", "TensorboardLogger", "WandbLogger", "RayService", "ServiceBase", "get_services", "set_auto_unwrap_transformed_env", "BatchSubSampler", "ClearCudaCache", "CountFramesLog", "LogScalar", "LogValidationReward", "OptimizerHook", "ReplayBufferTrainer", "RewardNormalizer", "SelectKeys", "TargetNetUpdaterHook", "Trainer", "TrainerHookBase", "UTDRHook", "UpdateWeights", "PPOTrainer", "SACTrainer", "torchrl.trainers.algorithms.configs.collectors.AsyncDataCollectorConfig", "torchrl.trainers.algorithms.configs.collectors.DataCollectorConfig", "torchrl.trainers.algorithms.configs.collectors.MultiSyncDataCollectorConfig", "torchrl.trainers.algorithms.configs.collectors.MultiaSyncDataCollectorConfig", "torchrl.trainers.algorithms.configs.collectors.SyncDataCollectorConfig", "torchrl.trainers.algorithms.configs.common.ConfigBase", "torchrl.trainers.algorithms.configs.data.LazyMemmapStorageConfig", "torchrl.trainers.algorithms.configs.data.LazyStackStorageConfig", "torchrl.trainers.algorithms.configs.data.LazyTensorStorageConfig", "torchrl.trainers.algorithms.configs.data.ListStorageConfig", "torchrl.trainers.algorithms.configs.data.PrioritizedSamplerConfig", "torchrl.trainers.algorithms.configs.data.RandomSamplerConfig", "torchrl.trainers.algorithms.configs.data.ReplayBufferConfig", "torchrl.trainers.algorithms.configs.data.RoundRobinWriterConfig", "torchrl.trainers.algorithms.configs.data.SamplerWithoutReplacementConfig", "torchrl.trainers.algorithms.configs.data.SliceSamplerConfig", "torchrl.trainers.algorithms.configs.data.SliceSamplerWithoutReplacementConfig", "torchrl.trainers.algorithms.configs.data.StorageEnsembleConfig", "torchrl.trainers.algorithms.configs.data.StorageEnsembleWriterConfig", "torchrl.trainers.algorithms.configs.data.TensorDictReplayBufferConfig", "torchrl.trainers.algorithms.configs.data.TensorStorageConfig", "torchrl.trainers.algorithms.configs.envs.BatchedEnvConfig", "torchrl.trainers.algorithms.configs.envs.EnvConfig", "torchrl.trainers.algorithms.configs.envs.TransformedEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.BraxEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.DMControlEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.EnvLibsConfig", "torchrl.trainers.algorithms.configs.envs_libs.GymEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.HabitatEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.IsaacGymEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.JumanjiEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.MOGymEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.MeltingpotEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.MultiThreadedEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.OpenMLEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.OpenSpielEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.PettingZooEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.RoboHiveEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.SMACv2EnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.UnityMLAgentsEnvConfig", "torchrl.trainers.algorithms.configs.envs_libs.VmasEnvConfig", "torchrl.trainers.algorithms.configs.logging.CSVLoggerConfig", "torchrl.trainers.algorithms.configs.logging.LoggerConfig", "torchrl.trainers.algorithms.configs.logging.TensorboardLoggerConfig", "torchrl.trainers.algorithms.configs.logging.WandbLoggerConfig", "torchrl.trainers.algorithms.configs.modules.ConvNetConfig", "torchrl.trainers.algorithms.configs.modules.MLPConfig", "torchrl.trainers.algorithms.configs.modules.ModelConfig", "torchrl.trainers.algorithms.configs.modules.NetworkConfig", "torchrl.trainers.algorithms.configs.modules.TanhNormalModelConfig", "torchrl.trainers.algorithms.configs.modules.TensorDictModuleConfig", "torchrl.trainers.algorithms.configs.modules.ValueModelConfig", "torchrl.trainers.algorithms.configs.objectives.LossConfig", "torchrl.trainers.algorithms.configs.objectives.PPOLossConfig", "torchrl.trainers.algorithms.configs.trainers.PPOTrainerConfig", "torchrl.trainers.algorithms.configs.trainers.TrainerConfig", "torchrl.trainers.algorithms.configs.transforms.ActionDiscretizerConfig", "torchrl.trainers.algorithms.configs.transforms.ActionMaskConfig", "torchrl.trainers.algorithms.configs.transforms.AutoResetTransformConfig", "torchrl.trainers.algorithms.configs.transforms.BatchSizeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.BinarizeRewardConfig", "torchrl.trainers.algorithms.configs.transforms.BurnInTransformConfig", "torchrl.trainers.algorithms.configs.transforms.CatFramesConfig", "torchrl.trainers.algorithms.configs.transforms.CatTensorsConfig", "torchrl.trainers.algorithms.configs.transforms.CenterCropConfig", "torchrl.trainers.algorithms.configs.transforms.ClipTransformConfig", "torchrl.trainers.algorithms.configs.transforms.ComposeConfig", "torchrl.trainers.algorithms.configs.transforms.ConditionalPolicySwitchConfig", "torchrl.trainers.algorithms.configs.transforms.ConditionalSkipConfig", "torchrl.trainers.algorithms.configs.transforms.CropConfig", "torchrl.trainers.algorithms.configs.transforms.DTypeCastTransformConfig", "torchrl.trainers.algorithms.configs.transforms.DeviceCastTransformConfig", "torchrl.trainers.algorithms.configs.transforms.DiscreteActionProjectionConfig", "torchrl.trainers.algorithms.configs.transforms.DoubleToFloatConfig", "torchrl.trainers.algorithms.configs.transforms.EndOfLifeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.ExcludeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.FiniteTensorDictCheckConfig", "torchrl.trainers.algorithms.configs.transforms.FlattenObservationConfig", "torchrl.trainers.algorithms.configs.transforms.FrameSkipTransformConfig", "torchrl.trainers.algorithms.configs.transforms.GrayScaleConfig", "torchrl.trainers.algorithms.configs.transforms.HashConfig", "torchrl.trainers.algorithms.configs.transforms.InitTrackerConfig", "torchrl.trainers.algorithms.configs.transforms.KLRewardTransformConfig", "torchrl.trainers.algorithms.configs.transforms.LineariseRewardsConfig", "torchrl.trainers.algorithms.configs.transforms.MultiActionConfig", "torchrl.trainers.algorithms.configs.transforms.MultiStepTransformConfig", "torchrl.trainers.algorithms.configs.transforms.NoopResetEnvConfig", "torchrl.trainers.algorithms.configs.transforms.ObservationNormConfig", "torchrl.trainers.algorithms.configs.transforms.PermuteTransformConfig", "torchrl.trainers.algorithms.configs.transforms.PinMemoryTransformConfig", "torchrl.trainers.algorithms.configs.transforms.R3MTransformConfig", "torchrl.trainers.algorithms.configs.transforms.RandomCropTensorDictConfig", "torchrl.trainers.algorithms.configs.transforms.RemoveEmptySpecsConfig", "torchrl.trainers.algorithms.configs.transforms.RenameTransformConfig", "torchrl.trainers.algorithms.configs.transforms.ResizeConfig", "torchrl.trainers.algorithms.configs.transforms.Reward2GoTransformConfig", "torchrl.trainers.algorithms.configs.transforms.RewardClippingConfig", "torchrl.trainers.algorithms.configs.transforms.RewardScalingConfig", "torchrl.trainers.algorithms.configs.transforms.RewardSumConfig", "torchrl.trainers.algorithms.configs.transforms.SelectTransformConfig", "torchrl.trainers.algorithms.configs.transforms.SignTransformConfig", "torchrl.trainers.algorithms.configs.transforms.SqueezeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.StackConfig", "torchrl.trainers.algorithms.configs.transforms.StepCounterConfig", "torchrl.trainers.algorithms.configs.transforms.TargetReturnConfig", "torchrl.trainers.algorithms.configs.transforms.TensorDictPrimerConfig", "torchrl.trainers.algorithms.configs.transforms.TimeMaxPoolConfig", "torchrl.trainers.algorithms.configs.transforms.TimerConfig", "torchrl.trainers.algorithms.configs.transforms.ToTensorImageConfig", "torchrl.trainers.algorithms.configs.transforms.TokenizerConfig", "torchrl.trainers.algorithms.configs.transforms.TrajCounterConfig", "torchrl.trainers.algorithms.configs.transforms.TransformConfig", "torchrl.trainers.algorithms.configs.transforms.UnaryTransformConfig", "torchrl.trainers.algorithms.configs.transforms.UnsqueezeTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VC1TransformConfig", "torchrl.trainers.algorithms.configs.transforms.VIPRewardTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VIPTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VecGymEnvTransformConfig", "torchrl.trainers.algorithms.configs.transforms.VecNormConfig", "torchrl.trainers.algorithms.configs.transforms.VecNormV2Config", "torchrl.trainers.algorithms.configs.utils.ASGDConfig", "torchrl.trainers.algorithms.configs.utils.AdadeltaConfig", "torchrl.trainers.algorithms.configs.utils.AdagradConfig", "torchrl.trainers.algorithms.configs.utils.AdamConfig", "torchrl.trainers.algorithms.configs.utils.AdamWConfig", "torchrl.trainers.algorithms.configs.utils.AdamaxConfig", "torchrl.trainers.algorithms.configs.utils.LBFGSConfig", "torchrl.trainers.algorithms.configs.utils.LionConfig", "torchrl.trainers.algorithms.configs.utils.NAdamConfig", "torchrl.trainers.algorithms.configs.utils.RAdamConfig", "torchrl.trainers.algorithms.configs.utils.RMSpropConfig", "torchrl.trainers.algorithms.configs.utils.RpropConfig", "torchrl.trainers.algorithms.configs.utils.SGDConfig", "torchrl.trainers.algorithms.configs.utils.SparseAdamConfig", "correct_for_frame_skip", "get_stats_random_rollout", "make_collector_offpolicy", "make_collector_onpolicy", "make_dqn_loss", "make_replay_buffer", "make_target_updater", "make_trainer", "parallel_env_constructor", "sync_async_collector", "sync_sync_collector", "transformed_env_constructor", "DistributedTransport", "DistributedWeightSyncScheme", "MPTransport", "MultiProcessWeightSyncScheme", "NoWeightSyncScheme", "RPCTransport", "RPCWeightSyncScheme", "RayActorTransport", "RayModuleTransformReceiver", "RayModuleTransformScheme", "RayModuleTransformSender", "RayTransport", "RayWeightSyncScheme", "SharedMemTransport", "SharedMemWeightSyncScheme", "TransportBackend", "WeightReceiver", "WeightSender", "WeightSyncScheme", "VLLMCollectiveTransport", "VLLMDoubleBufferSyncScheme", "VLLMDoubleBufferTransport", "VLLMDoubleBufferWeightReceiver", "VLLMDoubleBufferWeightSender", "VLLMWeightReceiver", "VLLMWeightSender", "VLLMWeightSyncScheme", "get_model_metadata", "README Tutos", "API Reference", "Knowledge Base", "LLM Interface", "LLM Collectors", "Data Structures", "LLM Environments", "LLM Wrappers", "LLM Objectives", "LLM Transforms", "torchrl.modules package", "Actor Modules", "Value Networks and Critics", "Distribution Classes", "Exploration Strategies", "World Models and Model-Based RL", "Utilities and Helpers", "torchrl.objectives package", "Actor-Critic Methods", "Common Components", "Offline RL Methods", "Other Loss Modules", "Policy Gradient Methods", "Value-Based Methods", "Service Registry", "torchrl.trainers package", "Trainer Basics", "Training Hooks", "Loggers", "torchrl._utils package", "Computation times", "TorchRL objectives: Coding a DDPG loss", "TorchRL trainer: A DQN example", "Reinforcement Learning (PPO) with TorchRL Tutorial", "Recurrent DQN: Training recurrent policies", "Exporting TorchRL modules", "Get started with Environments, TED and transforms", "Get started with TorchRL\u2019s modules", "Getting started with model optimization", "Get started with data collection and storage", "Get started with logging", "Get started with your own first training loop", "README Tutos", "TorchRL LLM: Building Tool-Enabled Environments", "LLM Wrappers in TorchRL", "Task-specific policy in multi-task environments", "Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial", "Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial", "Pendulum: Writing your environment and transforms with TorchRL", "Using pretrained models", "Using Replay Buffers", "Computation times", "Introduction to TorchRL", "TorchRL envs"], "terms": {"an": [0, 2, 6, 12, 16, 17, 18, 19, 20, 21, 22, 24, 27, 28, 29, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 91, 92, 93, 94, 95, 99, 101, 103, 105, 106, 107, 109, 111, 112, 113, 115, 116, 117, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 134, 135, 141, 142, 144, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 163, 164, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 212, 213, 215, 216, 218, 219, 221, 227, 229, 230, 233, 237, 241, 243, 244, 248, 249, 250, 251, 253, 262, 263, 264, 265, 266, 268, 269, 270, 273, 276, 277, 278, 281, 282, 283, 286, 288, 289, 290, 291, 293, 295, 296, 299, 300, 302, 303, 310, 311, 318, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 333, 334, 335, 336, 338, 339, 341, 342, 345, 346, 347, 348, 350, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 391, 395, 398, 404, 405, 410, 411, 414, 415, 551, 558, 559, 560, 561, 565, 592, 593, 621, 622, 625, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 639, 640, 642, 643], "open": [0, 24, 26, 80, 83, 84, 92, 174, 280, 323, 325, 326, 328, 329, 333, 334, 372, 374, 376, 377, 380, 622, 633, 636, 637, 642], "sourc": [0, 2, 4, 23, 26, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "reinforc": [0, 7, 15, 22, 28, 77, 139, 140, 168, 169, 219, 278, 288, 289, 290, 291, 296, 310, 345, 346, 348, 351, 352, 353, 355, 360, 366, 367, 368, 414, 593, 605, 607, 610, 620, 622, 626, 627, 632, 634, 638, 641, 642], "learn": [0, 7, 15, 19, 22, 26, 27, 28, 41, 77, 78, 79, 81, 82, 83, 84, 98, 99, 123, 139, 140, 144, 147, 156, 168, 169, 174, 175, 219, 278, 288, 289, 290, 291, 296, 310, 323, 325, 326, 328, 329, 345, 346, 347, 348, 351, 352, 353, 355, 359, 360, 364, 365, 366, 367, 368, 372, 374, 375, 376, 377, 380, 414, 415, 593, 605, 607, 610, 620, 621, 622, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634, 635, 638, 640, 641, 642, 643], "rl": [0, 2, 6, 10, 11, 12, 16, 18, 22, 24, 27, 29, 34, 35, 37, 40, 48, 75, 132, 141, 168, 219, 262, 320, 330, 335, 337, 339, 345, 347, 361, 362, 364, 366, 375, 400, 590, 591, 592, 600, 601, 603, 606, 607, 613, 621, 622, 623, 629, 632, 636, 637, 639, 640, 643], "librari": [0, 2, 3, 6, 10, 16, 17, 20, 22, 24, 25, 26, 27, 28, 29, 30, 34, 35, 41, 42, 44, 120, 121, 122, 131, 142, 166, 175, 188, 322, 398, 591, 592, 619, 621, 622, 623, 625, 626, 627, 629, 636, 637, 638, 643], "pytorch": [0, 2, 3, 6, 19, 20, 48, 52, 78, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 161, 162, 163, 168, 169, 170, 173, 176, 177, 178, 219, 265, 266, 410, 581, 590, 592, 603, 621, 623, 624, 628, 632, 636, 637, 638, 642, 643], "you": [0, 2, 5, 7, 12, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 37, 41, 42, 44, 46, 48, 50, 77, 84, 85, 86, 117, 120, 123, 127, 131, 135, 138, 139, 140, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 209, 219, 240, 269, 277, 278, 324, 330, 335, 341, 364, 373, 375, 378, 379, 395, 399, 572, 579, 585, 587, 588, 592, 593, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "can": [0, 2, 3, 4, 6, 7, 8, 12, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 93, 98, 99, 104, 105, 106, 111, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 131, 133, 134, 135, 138, 139, 140, 145, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 200, 207, 209, 211, 212, 213, 215, 216, 218, 219, 222, 223, 225, 227, 229, 230, 231, 234, 237, 242, 243, 244, 248, 249, 253, 256, 260, 261, 262, 263, 267, 268, 269, 270, 271, 273, 275, 277, 278, 280, 285, 286, 288, 295, 296, 299, 300, 301, 302, 304, 305, 310, 311, 312, 319, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 335, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 395, 396, 397, 399, 403, 404, 414, 463, 559, 560, 561, 563, 565, 566, 568, 571, 572, 574, 575, 576, 579, 580, 582, 585, 587, 588, 592, 593, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "directli": [0, 23, 27, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 68, 75, 78, 85, 117, 118, 119, 120, 123, 126, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 237, 238, 239, 241, 244, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 271, 273, 274, 276, 277, 278, 322, 327, 341, 362, 368, 373, 375, 378, 379, 561, 562, 567, 569, 570, 571, 572, 573, 575, 578, 579, 585, 587, 593, 622, 623, 624, 625, 626, 636, 637, 638, 640], "from": [0, 1, 2, 4, 5, 6, 7, 10, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 92, 93, 94, 95, 98, 99, 103, 104, 105, 106, 107, 109, 111, 113, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 138, 139, 140, 141, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 204, 209, 210, 211, 212, 213, 215, 216, 218, 219, 220, 222, 223, 224, 225, 227, 228, 229, 230, 231, 232, 237, 238, 239, 240, 244, 246, 248, 249, 250, 251, 252, 253, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 275, 276, 277, 278, 280, 281, 282, 283, 285, 288, 289, 290, 291, 292, 294, 295, 296, 298, 299, 300, 301, 302, 303, 304, 305, 308, 309, 310, 311, 312, 315, 318, 319, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 388, 396, 400, 403, 406, 410, 412, 413, 414, 415, 426, 427, 431, 470, 550, 551, 555, 557, 558, 561, 562, 564, 571, 572, 576, 577, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 592, 593, 600, 607, 614, 615, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643], "pypi": [0, 642], "see": [0, 3, 6, 17, 18, 19, 21, 22, 25, 26, 27, 28, 34, 35, 37, 40, 41, 42, 44, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 93, 99, 105, 106, 117, 120, 123, 127, 130, 132, 134, 135, 139, 140, 142, 145, 146, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 223, 225, 242, 248, 263, 266, 268, 269, 270, 273, 275, 277, 278, 279, 281, 283, 285, 286, 300, 301, 302, 303, 305, 315, 319, 322, 323, 324, 325, 326, 328, 329, 330, 335, 339, 340, 341, 347, 348, 359, 361, 362, 364, 368, 372, 373, 374, 375, 376, 377, 378, 379, 380, 388, 395, 396, 406, 414, 570, 575, 576, 578, 584, 586, 588, 591, 593, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 633, 636, 637, 638, 640, 642, 643], "more": [0, 2, 6, 9, 17, 21, 22, 23, 25, 27, 28, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 98, 99, 111, 117, 120, 123, 126, 127, 128, 130, 131, 134, 135, 139, 140, 145, 146, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 266, 269, 273, 278, 279, 280, 284, 285, 295, 296, 303, 305, 320, 322, 323, 324, 325, 326, 328, 329, 330, 335, 337, 340, 341, 345, 355, 362, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 395, 396, 405, 588, 591, 592, 593, 607, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 633, 634, 635, 636, 637, 638, 639, 642, 643], "about": [0, 21, 24, 26, 28, 41, 42, 44, 45, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 78, 81, 82, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 181, 193, 324, 330, 335, 621, 622, 623, 625, 626, 627, 628, 629, 630, 631, 636, 637, 638, 640, 642, 643], "instruct": [0, 25, 26, 29, 47, 76, 84, 132, 170, 175, 229, 231, 593, 621, 622, 623, 624, 633, 636, 637, 640], "dedic": [0, 3, 6, 19, 41, 42, 44, 46, 67, 68, 69, 70, 147, 156, 281, 282, 283, 322, 593, 621, 626, 628, 629, 631, 635, 637], "section": [0, 7, 17, 23, 123, 591, 622, 625, 626, 631, 636, 637], "below": [0, 6, 17, 22, 26, 34, 35, 37, 40, 41, 42, 44, 46, 67, 69, 70, 72, 83, 84, 85, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 225, 242, 248, 263, 268, 269, 270, 273, 275, 286, 301, 303, 315, 319, 323, 324, 325, 326, 328, 329, 330, 335, 339, 340, 347, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 406, 621, 622, 623, 624, 625, 626, 636, 638], "pip": [0, 29, 79, 188, 625, 626, 627, 628, 629, 630, 631, 633, 637, 642, 643], "provid": [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 15, 16, 17, 18, 19, 21, 22, 24, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 92, 93, 95, 98, 99, 100, 103, 105, 106, 114, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 133, 134, 135, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 211, 212, 216, 218, 219, 220, 221, 222, 226, 227, 230, 234, 237, 241, 243, 244, 246, 248, 249, 252, 253, 256, 257, 262, 263, 264, 267, 268, 270, 272, 273, 275, 276, 277, 278, 280, 286, 292, 293, 296, 299, 300, 302, 303, 304, 311, 312, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 335, 337, 338, 339, 341, 344, 345, 346, 347, 348, 349, 350, 352, 354, 355, 356, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 392, 396, 397, 400, 406, 412, 413, 421, 551, 557, 563, 565, 568, 571, 574, 575, 576, 580, 582, 587, 588, 592, 593, 595, 597, 607, 614, 615, 621, 622, 623, 624, 625, 626, 627, 629, 630, 634, 635, 636, 637, 638, 639, 640, 642, 643], "python": [0, 5, 7, 22, 24, 25, 26, 29, 34, 35, 46, 48, 49, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 84, 143, 159, 160, 168, 188, 190, 191, 209, 300, 302, 304, 591, 593, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "first": [0, 1, 2, 6, 9, 17, 18, 19, 20, 22, 23, 24, 26, 27, 34, 35, 37, 40, 41, 42, 44, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 92, 94, 99, 105, 106, 111, 113, 117, 120, 123, 126, 127, 128, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 183, 184, 215, 216, 219, 220, 224, 225, 234, 242, 244, 248, 249, 265, 266, 270, 273, 278, 280, 286, 293, 295, 296, 300, 302, 303, 304, 307, 311, 322, 329, 337, 339, 340, 341, 347, 357, 361, 362, 364, 373, 375, 379, 387, 388, 408, 575, 576, 620, 621, 622, 623, 624, 625, 626, 629, 630, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643], "low": [0, 18, 54, 56, 71, 72, 99, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 181, 204, 212, 222, 229, 237, 240, 263, 271, 296, 317, 318, 319, 339, 341, 344, 364, 481, 621, 622, 623, 625, 636, 637, 638, 642], "high": [0, 1, 18, 22, 28, 54, 56, 69, 72, 83, 84, 98, 99, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 175, 176, 177, 178, 181, 204, 212, 222, 229, 237, 240, 243, 263, 271, 296, 317, 318, 319, 323, 325, 326, 328, 329, 339, 341, 344, 354, 364, 367, 372, 374, 376, 377, 380, 381, 481, 587, 615, 621, 622, 623, 634, 636, 637, 638, 640, 642], "level": [0, 19, 21, 22, 23, 34, 35, 47, 56, 58, 64, 65, 67, 68, 83, 84, 87, 126, 128, 174, 186, 194, 219, 261, 269, 300, 302, 323, 325, 326, 328, 329, 354, 361, 367, 372, 374, 376, 377, 380, 615, 621, 622, 625, 629, 642], "abstract": [0, 6, 19, 27, 39, 71, 75, 79, 115, 123, 245, 385, 397, 401, 411, 421, 577, 580, 623, 625, 638, 642], "ar": [0, 1, 2, 6, 7, 9, 10, 12, 17, 18, 19, 20, 21, 22, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 103, 104, 105, 106, 107, 109, 111, 113, 117, 120, 123, 124, 126, 127, 128, 134, 135, 138, 139, 140, 141, 144, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 210, 211, 212, 214, 215, 216, 218, 219, 222, 223, 225, 227, 228, 229, 230, 231, 233, 234, 237, 239, 240, 242, 243, 246, 248, 253, 256, 260, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 284, 291, 293, 295, 299, 300, 302, 304, 305, 308, 311, 314, 315, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 335, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 395, 396, 397, 398, 399, 406, 410, 412, 413, 414, 415, 557, 561, 562, 563, 564, 567, 568, 570, 572, 573, 574, 575, 576, 578, 579, 580, 582, 584, 585, 586, 587, 588, 593, 600, 607, 614, 619, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "intend": [0, 26, 34, 35, 37, 40, 41, 42, 44, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 218, 229, 362, 642], "effici": [0, 1, 3, 6, 9, 10, 12, 23, 27, 36, 88, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 190, 330, 348, 412, 593, 595, 607, 614, 621, 622, 623, 624, 625, 628, 629, 631, 635, 636, 637, 639, 640, 642], "modular": [0, 7, 75, 187, 343, 600, 615, 625, 640, 642], "document": [0, 24, 26, 30, 41, 42, 46, 80, 85, 117, 120, 123, 127, 132, 135, 145, 146, 147, 148, 151, 156, 157, 158, 159, 160, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 270, 324, 330, 335, 373, 375, 378, 379, 590, 591, 614, 622, 624, 625, 626, 629, 632, 642], "properli": [0, 4, 5, 21, 22, 48, 72, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 193, 194, 210, 225, 300, 302, 381, 593, 623, 624, 630, 636, 637, 638, 642], "test": [0, 7, 20, 22, 24, 48, 117, 118, 119, 120, 123, 127, 133, 134, 135, 139, 140, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 181, 183, 268, 273, 404, 557, 582, 583, 586, 587, 593, 614, 623, 624, 625, 639, 642], "The": [0, 2, 6, 7, 9, 10, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 90, 98, 99, 103, 105, 106, 107, 111, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 131, 133, 134, 135, 142, 143, 145, 146, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 203, 207, 210, 211, 212, 215, 216, 218, 219, 223, 224, 225, 227, 230, 231, 232, 237, 240, 241, 242, 244, 246, 248, 253, 255, 256, 257, 260, 261, 262, 263, 265, 268, 269, 270, 273, 275, 276, 277, 278, 281, 284, 288, 289, 290, 291, 292, 295, 296, 300, 302, 304, 305, 310, 311, 312, 313, 314, 315, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339, 340, 341, 343, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 390, 393, 394, 395, 396, 397, 399, 400, 405, 412, 413, 414, 415, 458, 468, 470, 557, 559, 560, 563, 564, 565, 566, 568, 570, 571, 574, 575, 576, 578, 580, 581, 582, 585, 586, 588, 593, 595, 596, 597, 614, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 636, 637, 638, 639, 640, 642, 643], "code": [0, 6, 17, 18, 22, 24, 26, 27, 34, 35, 56, 58, 80, 117, 120, 123, 127, 132, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 187, 188, 190, 191, 248, 270, 273, 324, 339, 341, 343, 593, 614, 620, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640, 641, 642, 643], "aim": [0, 21, 26, 248, 273, 275, 303, 550, 592, 621, 622, 642], "support": [0, 2, 3, 4, 6, 7, 10, 16, 18, 19, 22, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 50, 79, 82, 83, 84, 86, 92, 94, 107, 109, 113, 114, 116, 117, 118, 119, 120, 126, 128, 133, 142, 144, 147, 149, 153, 166, 174, 176, 182, 187, 197, 216, 219, 231, 237, 244, 263, 264, 267, 270, 271, 278, 295, 296, 318, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 339, 340, 343, 355, 362, 372, 373, 374, 375, 376, 377, 379, 380, 381, 382, 383, 384, 393, 398, 575, 588, 593, 595, 600, 607, 614, 615, 623, 624, 626, 627, 633, 634, 637, 638, 640, 642], "research": [0, 26, 28, 139, 140, 634, 642], "most": [0, 4, 6, 12, 17, 21, 26, 27, 34, 35, 62, 98, 99, 105, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 229, 276, 614, 621, 623, 625, 626, 627, 628, 629, 630, 631, 638, 642, 643], "written": [0, 4, 13, 17, 22, 48, 49, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 90, 92, 99, 105, 106, 117, 120, 121, 122, 123, 126, 127, 128, 129, 135, 147, 148, 151, 153, 156, 157, 158, 168, 169, 170, 173, 174, 175, 176, 177, 178, 181, 210, 211, 212, 219, 231, 234, 239, 240, 256, 261, 264, 265, 270, 276, 280, 285, 310, 320, 323, 325, 326, 328, 329, 337, 339, 340, 341, 345, 347, 361, 364, 366, 372, 374, 375, 376, 377, 380, 386, 387, 388, 412, 593, 621, 624, 625, 627, 635, 638, 642], "highli": [0, 15, 330, 347, 364, 626, 642, 643], "wai": [0, 1, 2, 4, 19, 21, 22, 23, 46, 56, 58, 68, 75, 78, 111, 131, 169, 170, 173, 193, 219, 223, 248, 251, 268, 269, 275, 276, 300, 302, 364, 381, 382, 383, 384, 415, 593, 614, 621, 622, 623, 625, 626, 628, 629, 635, 636, 637, 638, 639, 640, 642, 643], "easili": [0, 2, 7, 17, 18, 22, 26, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 614, 621, 622, 623, 626, 627, 628, 631, 636, 637, 642, 643], "swap": [0, 2, 16, 17, 126, 276, 623, 625, 639, 642], "compon": [0, 2, 6, 7, 10, 12, 19, 21, 22, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 87, 92, 93, 94, 95, 107, 109, 113, 169, 295, 296, 312, 322, 345, 346, 347, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 373, 375, 379, 405, 410, 591, 607, 621, 622, 623, 624, 625, 627, 628, 631, 633, 635, 636, 637, 638, 639, 642], "transform": [0, 3, 4, 6, 10, 12, 16, 17, 18, 20, 22, 23, 27, 34, 35, 37, 38, 39, 40, 41, 42, 44, 46, 48, 49, 50, 51, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 89, 90, 97, 109, 114, 117, 120, 123, 124, 127, 135, 139, 140, 147, 148, 149, 150, 151, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 210, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 285, 287, 288, 292, 297, 300, 302, 309, 315, 318, 323, 325, 326, 327, 328, 329, 330, 335, 338, 344, 351, 363, 372, 374, 376, 377, 378, 379, 380, 386, 388, 406, 413, 414, 428, 433, 434, 435, 439, 470, 561, 591, 595, 614, 620, 622, 624, 625, 627, 629, 630, 631, 632, 633, 639, 641], "them": [0, 6, 12, 19, 26, 28, 30, 34, 35, 36, 37, 38, 40, 41, 42, 44, 46, 56, 58, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 111, 116, 117, 120, 123, 124, 127, 131, 135, 138, 139, 140, 147, 148, 149, 150, 151, 156, 157, 158, 161, 162, 168, 169, 170, 173, 176, 177, 178, 197, 227, 230, 237, 240, 263, 267, 270, 271, 277, 278, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 303, 305, 306, 307, 309, 310, 312, 313, 314, 336, 338, 344, 346, 348, 354, 360, 361, 365, 367, 368, 369, 382, 383, 384, 388, 583, 584, 585, 614, 621, 622, 624, 625, 626, 627, 629, 630, 634, 635, 636, 637, 638, 639, 640, 642, 643], "write": [0, 17, 27, 34, 35, 37, 40, 48, 52, 56, 58, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 99, 105, 109, 116, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 211, 213, 215, 216, 218, 219, 220, 222, 223, 224, 225, 228, 231, 232, 233, 235, 238, 239, 241, 246, 247, 249, 250, 251, 253, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 272, 273, 274, 276, 277, 320, 323, 325, 326, 328, 329, 337, 340, 341, 343, 348, 349, 350, 352, 353, 354, 360, 365, 367, 368, 369, 372, 374, 376, 377, 378, 380, 385, 388, 582, 583, 585, 593, 614, 615, 620, 621, 622, 623, 624, 625, 626, 627, 629, 630, 631, 632, 633, 635, 636, 637, 639, 640, 641, 642, 643], "new": [0, 2, 6, 7, 18, 21, 23, 27, 34, 35, 37, 40, 46, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 98, 99, 104, 117, 120, 123, 127, 135, 142, 147, 148, 151, 154, 155, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 210, 211, 216, 241, 256, 260, 269, 270, 277, 278, 293, 300, 302, 310, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 340, 341, 345, 346, 347, 350, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 395, 413, 570, 575, 578, 584, 586, 593, 621, 623, 626, 628, 634, 636, 637, 638, 642, 643], "ones": [0, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 69, 70, 71, 72, 73, 74, 83, 84, 85, 105, 106, 117, 120, 123, 127, 135, 147, 148, 149, 150, 151, 152, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 220, 223, 224, 227, 228, 230, 244, 248, 253, 260, 263, 269, 270, 273, 275, 278, 304, 323, 324, 325, 326, 328, 329, 330, 335, 340, 345, 346, 347, 348, 349, 360, 361, 364, 365, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 593, 621, 623, 625, 634, 636, 637, 638, 640, 642, 643], "littl": [0, 4, 5, 17, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 270, 345, 347, 361, 364, 366, 623, 624, 625, 629, 640, 642, 643], "effort": [0, 16, 17, 18, 322, 638, 640, 642], "thi": [0, 2, 3, 4, 5, 6, 7, 8, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 97, 98, 99, 103, 104, 105, 106, 107, 109, 111, 113, 114, 116, 117, 118, 119, 120, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 138, 139, 140, 141, 144, 147, 148, 149, 150, 151, 152, 156, 157, 158, 159, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 199, 207, 209, 210, 211, 212, 213, 215, 216, 218, 219, 220, 222, 223, 224, 225, 227, 228, 229, 230, 231, 232, 233, 235, 237, 238, 239, 241, 242, 244, 247, 248, 249, 250, 251, 253, 256, 257, 258, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 273, 274, 275, 276, 277, 278, 280, 281, 282, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 395, 396, 397, 398, 399, 400, 402, 403, 404, 406, 410, 412, 413, 414, 415, 421, 470, 550, 551, 557, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 592, 593, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "repo": [0, 25, 76, 219, 264, 273, 592, 637, 642], "attempt": [0, 34, 35, 37, 40, 41, 42, 44, 46, 83, 84, 85, 105, 106, 117, 120, 121, 122, 123, 126, 127, 128, 129, 135, 147, 148, 151, 153, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 323, 324, 325, 326, 328, 329, 330, 335, 341, 350, 353, 360, 372, 373, 374, 375, 376, 377, 378, 379, 380, 628, 642], "align": [0, 642], "exist": [0, 6, 19, 23, 34, 35, 37, 40, 41, 46, 48, 49, 83, 84, 85, 92, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 220, 228, 241, 268, 269, 270, 280, 293, 323, 324, 325, 326, 328, 329, 330, 335, 341, 348, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 396, 397, 398, 551, 561, 569, 614, 636, 637, 642, 643], "ecosystem": [0, 625, 629, 642], "ha": [0, 2, 4, 6, 7, 18, 21, 22, 23, 24, 26, 27, 29, 31, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 92, 94, 98, 99, 103, 105, 111, 113, 117, 120, 123, 124, 127, 131, 135, 139, 140, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 200, 216, 219, 241, 242, 261, 262, 263, 264, 265, 267, 268, 269, 270, 284, 296, 300, 302, 318, 323, 324, 325, 326, 328, 329, 330, 335, 338, 341, 345, 348, 361, 362, 364, 366, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 388, 414, 470, 593, 621, 622, 623, 624, 625, 626, 629, 630, 633, 635, 636, 637, 638, 639, 640, 642, 643], "dataset": [0, 10, 64, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 91, 99, 103, 105, 106, 144, 168, 169, 170, 173, 174, 175, 176, 179, 183, 192, 277, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 388, 591, 593, 621, 622, 626, 639, 640, 642, 643], "pillar": [0, 642], "environ": [0, 1, 2, 3, 4, 6, 16, 20, 24, 27, 29, 32, 33, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 71, 72, 73, 74, 85, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 206, 212, 213, 215, 216, 218, 219, 220, 224, 225, 227, 228, 229, 230, 235, 242, 243, 244, 248, 249, 250, 253, 256, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 273, 276, 277, 278, 285, 300, 302, 315, 330, 335, 338, 352, 356, 378, 381, 382, 383, 384, 385, 386, 388, 399, 400, 402, 404, 414, 415, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 470, 550, 551, 552, 553, 557, 558, 559, 560, 561, 591, 592, 599, 614, 620, 625, 627, 628, 629, 630, 632, 639, 640, 641], "model": [0, 2, 3, 17, 19, 27, 28, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 50, 51, 83, 84, 85, 86, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 227, 248, 263, 273, 275, 279, 281, 282, 283, 286, 287, 292, 294, 303, 309, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 340, 345, 346, 347, 348, 350, 351, 352, 353, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 396, 397, 410, 463, 465, 467, 552, 553, 554, 563, 565, 566, 568, 569, 570, 571, 572, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 591, 592, 593, 595, 600, 620, 623, 626, 629, 632, 634, 636, 637, 638, 640, 641, 643], "data": [0, 1, 2, 3, 4, 6, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 27, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 132, 133, 134, 135, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 156, 157, 158, 159, 160, 163, 168, 169, 170, 173, 174, 175, 176, 177, 178, 180, 183, 186, 187, 188, 189, 192, 193, 194, 197, 200, 204, 211, 213, 216, 218, 219, 224, 227, 228, 230, 232, 234, 237, 239, 244, 250, 253, 260, 261, 263, 267, 269, 270, 271, 276, 278, 295, 299, 300, 302, 310, 311, 320, 323, 324, 325, 326, 327, 328, 329, 330, 331, 333, 334, 335, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 360, 361, 364, 365, 366, 367, 368, 369, 372, 374, 375, 376, 377, 379, 380, 381, 382, 383, 384, 385, 386, 388, 395, 400, 403, 406, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 470, 552, 557, 559, 560, 561, 564, 581, 586, 591, 593, 596, 600, 614, 615, 620, 624, 625, 626, 627, 628, 632, 633, 634, 638, 639, 640, 641, 643], "util": [0, 6, 11, 17, 22, 34, 35, 37, 40, 41, 42, 44, 46, 47, 52, 67, 83, 84, 85, 105, 106, 117, 118, 119, 120, 123, 127, 133, 134, 135, 140, 147, 148, 149, 150, 151, 156, 157, 158, 164, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 248, 253, 263, 275, 285, 286, 292, 300, 302, 323, 324, 325, 326, 328, 329, 330, 335, 336, 362, 372, 373, 374, 375, 376, 377, 378, 379, 380, 554, 557, 591, 599, 600, 609, 615, 619, 621, 623, 625, 627, 628, 629, 637, 638, 640, 642, 643], "e": [0, 2, 6, 7, 17, 19, 20, 21, 22, 26, 27, 29, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 85, 86, 87, 92, 94, 98, 99, 111, 113, 117, 120, 123, 124, 127, 128, 135, 147, 148, 151, 156, 157, 158, 161, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 218, 220, 223, 224, 225, 226, 234, 237, 240, 242, 244, 248, 256, 263, 265, 268, 269, 270, 273, 275, 280, 296, 300, 301, 302, 305, 312, 318, 319, 323, 324, 325, 326, 328, 329, 330, 333, 334, 335, 338, 339, 340, 341, 345, 347, 348, 349, 353, 354, 360, 361, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 397, 400, 410, 414, 470, 550, 560, 563, 565, 566, 568, 571, 574, 576, 580, 581, 582, 585, 588, 593, 614, 622, 623, 625, 627, 628, 630, 634, 636, 637, 639, 640, 642, 643], "g": [0, 2, 6, 7, 17, 19, 20, 21, 22, 26, 27, 29, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 85, 86, 111, 117, 120, 123, 124, 127, 128, 135, 147, 148, 151, 156, 157, 158, 161, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 218, 220, 223, 224, 234, 237, 240, 244, 248, 256, 263, 265, 268, 269, 270, 273, 275, 280, 300, 301, 302, 318, 319, 323, 324, 325, 326, 328, 329, 330, 333, 334, 335, 339, 340, 341, 348, 364, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 386, 397, 410, 414, 470, 560, 563, 565, 566, 568, 571, 574, 576, 580, 581, 582, 585, 588, 593, 614, 622, 623, 625, 627, 630, 636, 637, 638, 639, 640, 642, 643], "collector": [0, 7, 17, 18, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 105, 106, 117, 120, 123, 127, 135, 147, 148, 151, 152, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 219, 253, 261, 269, 300, 302, 310, 324, 327, 330, 335, 347, 361, 364, 375, 378, 406, 410, 413, 414, 415, 470, 552, 553, 557, 559, 560, 562, 563, 565, 566, 567, 568, 569, 571, 573, 574, 576, 580, 582, 588, 591, 593, 607, 614, 615, 625, 640, 643], "contain": [0, 17, 21, 22, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 91, 99, 101, 103, 105, 106, 107, 112, 115, 116, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 211, 212, 219, 223, 227, 230, 237, 248, 260, 263, 268, 269, 270, 273, 275, 276, 277, 278, 286, 295, 296, 303, 312, 320, 323, 324, 325, 326, 328, 329, 330, 335, 337, 339, 340, 341, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 392, 400, 550, 557, 558, 559, 560, 561, 576, 583, 584, 593, 607, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 636, 637, 638, 639, 640, 642, 643], "etc": [0, 7, 12, 17, 21, 22, 26, 27, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 80, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 239, 260, 270, 280, 303, 318, 324, 330, 335, 373, 375, 378, 379, 396, 563, 564, 565, 566, 568, 571, 574, 576, 579, 580, 582, 588, 600, 622, 623, 629, 640, 642, 643], "have": [0, 2, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 34, 35, 40, 41, 43, 44, 46, 50, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 104, 107, 117, 120, 123, 127, 135, 147, 148, 149, 150, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 207, 211, 212, 215, 219, 224, 227, 230, 231, 239, 243, 244, 260, 261, 263, 267, 268, 269, 270, 277, 278, 284, 286, 303, 304, 310, 322, 323, 324, 325, 326, 328, 329, 330, 335, 338, 342, 343, 345, 347, 361, 364, 366, 368, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 388, 396, 400, 410, 412, 562, 563, 567, 568, 570, 572, 573, 578, 579, 580, 582, 584, 585, 586, 587, 588, 593, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 635, 636, 637, 638, 639, 640, 642, 643], "few": [0, 12, 27, 83, 84, 106, 127, 174, 178, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 388, 400, 593, 614, 623, 624, 627, 636, 637, 640, 642, 643], "depend": [0, 2, 3, 5, 18, 21, 22, 23, 26, 27, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 54, 72, 117, 120, 123, 126, 127, 128, 129, 135, 147, 148, 151, 153, 156, 157, 158, 161, 162, 168, 169, 170, 173, 175, 176, 177, 178, 188, 227, 230, 320, 330, 335, 341, 364, 390, 614, 621, 623, 624, 633, 636, 637, 638, 642, 643], "possibl": [0, 19, 20, 22, 23, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 77, 80, 82, 83, 84, 85, 93, 99, 105, 111, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 223, 248, 263, 268, 269, 270, 273, 275, 286, 322, 323, 324, 325, 326, 328, 329, 330, 335, 340, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 386, 404, 410, 593, 621, 623, 624, 625, 627, 629, 630, 636, 637, 638, 640, 642, 643], "standard": [0, 19, 21, 62, 120, 244, 255, 277, 278, 284, 297, 309, 322, 324, 330, 335, 347, 361, 364, 368, 369, 381, 382, 383, 384, 403, 621, 622, 626, 627, 637, 640, 642], "numpi": [0, 20, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 117, 120, 123, 127, 128, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 237, 266, 271, 280, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 410, 625, 638, 640, 642, 643], "common": [0, 22, 23, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 48, 49, 50, 71, 85, 117, 127, 133, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 213, 231, 269, 281, 282, 283, 324, 345, 346, 347, 348, 353, 354, 360, 361, 364, 365, 366, 367, 368, 369, 375, 378, 396, 397, 414, 416, 418, 419, 557, 591, 592, 593, 607, 614, 621, 623, 627, 630, 635, 636, 637, 638, 639, 642, 643], "openai": [0, 26, 126, 128, 135, 153, 177, 623, 638, 642, 643], "gym": [0, 3, 7, 16, 17, 18, 22, 23, 27, 34, 35, 37, 40, 46, 47, 48, 49, 65, 85, 117, 120, 123, 124, 126, 127, 128, 129, 131, 132, 135, 139, 140, 142, 143, 147, 148, 151, 153, 156, 157, 158, 161, 162, 167, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 207, 209, 215, 219, 222, 231, 238, 239, 244, 246, 251, 253, 256, 263, 269, 276, 277, 280, 378, 447, 557, 592, 621, 622, 623, 624, 626, 630, 631, 638, 639, 640], "onli": [0, 2, 6, 7, 17, 19, 20, 22, 23, 26, 32, 34, 35, 37, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 92, 94, 98, 99, 105, 106, 113, 117, 120, 121, 122, 123, 126, 127, 128, 129, 131, 134, 135, 142, 143, 147, 148, 149, 150, 151, 153, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 215, 219, 220, 222, 223, 224, 225, 227, 229, 230, 234, 237, 242, 244, 248, 249, 253, 260, 261, 262, 263, 264, 268, 269, 270, 273, 275, 277, 278, 280, 295, 302, 304, 311, 324, 327, 330, 335, 337, 339, 340, 341, 342, 343, 345, 347, 348, 349, 353, 354, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 381, 382, 383, 384, 385, 388, 395, 396, 398, 410, 412, 551, 564, 572, 576, 581, 588, 614, 621, 622, 623, 624, 625, 627, 628, 629, 630, 631, 633, 635, 636, 637, 638, 640, 642, 643], "option": [0, 3, 10, 18, 22, 23, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94, 95, 98, 99, 100, 101, 103, 104, 105, 106, 109, 113, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 203, 204, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 227, 229, 230, 231, 232, 234, 235, 237, 238, 239, 240, 241, 242, 243, 244, 248, 249, 251, 252, 255, 256, 257, 260, 261, 262, 263, 264, 266, 267, 268, 270, 271, 272, 273, 275, 276, 277, 278, 280, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 317, 318, 319, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 337, 338, 339, 340, 341, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 390, 393, 395, 396, 397, 398, 400, 402, 403, 404, 405, 406, 407, 410, 413, 414, 415, 470, 551, 557, 559, 560, 561, 563, 565, 566, 568, 571, 574, 575, 576, 580, 581, 582, 585, 587, 588, 591, 593, 624, 626, 629, 636, 637, 640, 642], "On": [0, 6, 19, 21, 26, 41, 42, 44, 46, 56, 77, 575, 576, 582, 593, 622, 636, 637], "end": [0, 6, 17, 34, 35, 40, 48, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 90, 99, 104, 105, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 231, 237, 246, 261, 262, 268, 270, 286, 324, 330, 335, 338, 348, 367, 373, 375, 378, 379, 431, 432, 490, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "come": [0, 1, 2, 4, 6, 18, 20, 21, 27, 34, 35, 37, 40, 41, 42, 44, 46, 48, 111, 117, 120, 123, 127, 134, 135, 138, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 183, 227, 230, 281, 282, 283, 320, 337, 339, 345, 347, 361, 364, 366, 388, 621, 622, 623, 624, 628, 629, 630, 631, 636, 637, 640, 642, 643], "set": [0, 2, 3, 6, 7, 15, 17, 18, 21, 22, 26, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 94, 95, 104, 107, 113, 117, 120, 123, 125, 127, 128, 134, 135, 139, 140, 141, 147, 148, 149, 150, 151, 156, 157, 158, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 208, 209, 211, 213, 215, 216, 219, 220, 223, 227, 230, 237, 238, 239, 240, 248, 253, 261, 262, 263, 264, 268, 269, 270, 273, 275, 277, 278, 280, 300, 302, 304, 310, 315, 318, 322, 323, 324, 325, 326, 328, 329, 330, 335, 340, 341, 347, 348, 354, 359, 361, 362, 364, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 385, 388, 399, 400, 404, 406, 415, 553, 561, 569, 575, 576, 592, 593, 619, 621, 622, 623, 624, 625, 627, 628, 629, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "re": [0, 21, 27, 32, 41, 42, 44, 46, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 86, 104, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 234, 302, 304, 324, 330, 335, 339, 341, 373, 375, 378, 379, 395, 615, 621, 623, 624, 626, 628, 633, 635, 636, 638, 642, 643], "usabl": [0, 615, 624, 642], "function": [0, 1, 7, 12, 17, 18, 19, 20, 21, 22, 27, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94, 95, 107, 109, 113, 117, 120, 123, 124, 127, 128, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 207, 209, 210, 211, 215, 216, 227, 230, 237, 239, 241, 267, 268, 270, 271, 277, 278, 280, 281, 282, 283, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 302, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 319, 320, 323, 324, 325, 326, 328, 329, 330, 335, 336, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 396, 398, 410, 414, 415, 469, 470, 557, 589, 595, 598, 606, 621, 624, 625, 626, 627, 630, 633, 635, 638, 640, 643], "cost": [0, 15, 55, 80, 93, 95, 345, 347, 361, 364, 366, 621, 622, 625, 636, 637, 638, 640], "return": [0, 1, 10, 16, 17, 18, 19, 20, 21, 22, 26, 27, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 91, 93, 99, 101, 103, 105, 106, 109, 111, 112, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 133, 134, 135, 139, 140, 141, 142, 143, 144, 147, 148, 149, 150, 151, 153, 156, 157, 158, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 199, 200, 202, 203, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 280, 281, 282, 283, 286, 287, 288, 289, 290, 291, 293, 300, 301, 302, 303, 304, 305, 308, 309, 312, 313, 314, 315, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339, 340, 341, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 392, 396, 397, 398, 399, 410, 412, 413, 550, 552, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 568, 570, 571, 572, 574, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 593, 607, 614, 621, 622, 623, 625, 627, 628, 630, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "process": [0, 1, 2, 3, 5, 6, 7, 12, 18, 21, 22, 23, 24, 27, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 64, 67, 69, 70, 75, 77, 81, 82, 83, 84, 85, 87, 92, 94, 98, 99, 101, 105, 113, 117, 120, 123, 124, 127, 131, 135, 138, 142, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 218, 219, 227, 230, 237, 263, 266, 268, 269, 277, 278, 296, 300, 302, 310, 312, 322, 323, 324, 325, 326, 328, 329, 330, 333, 334, 335, 347, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 563, 564, 565, 566, 568, 570, 571, 574, 575, 576, 580, 581, 582, 588, 593, 614, 621, 622, 624, 625, 626, 633, 634, 636, 637, 638, 639, 640, 642, 643], "good": [0, 2, 23, 28, 98, 99, 147, 189, 593, 614, 621, 623, 624, 625, 627, 637, 642, 643], "runtim": [0, 22, 52, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 614, 638], "perform": [0, 5, 6, 7, 10, 18, 20, 22, 23, 27, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 50, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 85, 117, 120, 121, 122, 123, 126, 127, 128, 129, 134, 135, 147, 148, 151, 153, 156, 157, 158, 161, 162, 164, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 227, 230, 237, 243, 265, 268, 270, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 312, 313, 314, 322, 323, 324, 325, 326, 328, 329, 330, 331, 335, 336, 338, 344, 347, 348, 357, 364, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 404, 410, 412, 591, 593, 621, 622, 623, 624, 625, 626, 629, 631, 634, 635, 636, 637, 638, 643], "To": [0, 6, 7, 18, 19, 20, 21, 23, 25, 26, 27, 28, 39, 41, 42, 44, 64, 65, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 90, 99, 105, 106, 109, 116, 117, 118, 119, 120, 123, 126, 127, 128, 133, 134, 135, 138, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 161, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 225, 261, 263, 277, 281, 282, 283, 285, 300, 302, 310, 324, 330, 335, 341, 348, 354, 359, 362, 368, 373, 375, 378, 379, 388, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 413, 586, 587, 593, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 636, 637, 638, 639, 640, 642, 643], "read": [0, 17, 26, 52, 56, 58, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 93, 94, 95, 98, 107, 109, 113, 117, 120, 123, 126, 127, 128, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 211, 212, 213, 215, 216, 218, 219, 220, 222, 223, 224, 225, 227, 228, 229, 231, 232, 233, 234, 235, 238, 239, 241, 246, 247, 249, 250, 251, 253, 256, 257, 258, 260, 261, 262, 263, 264, 265, 267, 268, 269, 272, 273, 274, 276, 277, 281, 282, 283, 285, 295, 308, 320, 321, 323, 325, 326, 328, 329, 337, 338, 339, 340, 341, 343, 345, 346, 347, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 388, 404, 410, 582, 583, 584, 621, 622, 623, 625, 626, 627, 635, 636, 637, 638, 639, 642, 643], "philosophi": [0, 28], "capabl": [0, 3, 18, 20, 26, 28, 30, 36, 46, 52, 168, 182, 414, 583, 593, 621, 626, 629, 633, 635, 639, 643], "beyond": [0, 6, 7, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 614, 625], "api": [0, 6, 16, 18, 22, 24, 52, 56, 58, 71, 83, 84, 120, 123, 149, 150, 153, 174, 178, 180, 188, 248, 275, 277, 278, 322, 323, 324, 325, 326, 328, 329, 330, 335, 372, 373, 374, 375, 376, 377, 379, 380, 414, 415, 582, 583, 584, 586, 588, 593, 595, 597, 625, 626, 627, 628, 629, 630, 634, 636, 637, 638, 640, 642, 643], "check": [0, 6, 17, 22, 23, 24, 25, 26, 28, 34, 35, 37, 40, 41, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 67, 71, 72, 73, 74, 83, 84, 85, 89, 90, 97, 105, 117, 120, 123, 124, 126, 127, 128, 135, 141, 147, 148, 151, 156, 157, 158, 163, 164, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 220, 225, 233, 239, 249, 263, 266, 270, 280, 293, 295, 296, 311, 312, 323, 324, 325, 326, 328, 329, 330, 335, 337, 339, 340, 341, 348, 359, 364, 368, 372, 373, 374, 375, 376, 377, 378, 379, 380, 388, 396, 398, 562, 564, 567, 569, 570, 573, 577, 578, 581, 583, 584, 586, 590, 614, 622, 623, 624, 625, 626, 627, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 642, 643], "paper": [0, 77, 80, 118, 119, 121, 122, 129, 133, 134, 139, 140, 142, 143, 153, 161, 162, 248, 273, 275, 286, 352, 368, 373, 375, 621, 623, 636, 637], "releas": [0, 6, 23, 26, 29, 50, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 268, 270, 324, 330, 335, 348, 367, 373, 375, 378, 379, 593, 614], "sync": [0, 1, 6, 7, 34, 35, 37, 40, 41, 42, 43, 44, 45, 46, 48, 49, 117, 189, 322, 413, 557, 562, 563, 621], "so": [0, 5, 21, 22, 23, 25, 26, 29, 30, 46, 56, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 117, 120, 123, 127, 135, 139, 140, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 263, 268, 277, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 342, 343, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 388, 572, 574, 593, 621, 623, 624, 628, 631, 636, 637, 638, 643], "make": [0, 1, 5, 6, 7, 16, 17, 18, 19, 21, 23, 26, 30, 56, 64, 65, 67, 68, 71, 75, 76, 79, 81, 82, 83, 84, 85, 103, 107, 109, 116, 117, 120, 123, 127, 128, 131, 132, 134, 135, 137, 143, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 212, 225, 232, 240, 244, 248, 249, 253, 257, 261, 265, 269, 273, 285, 295, 300, 302, 322, 323, 324, 325, 326, 328, 329, 330, 335, 341, 345, 347, 361, 364, 366, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 396, 406, 553, 561, 576, 600, 621, 622, 623, 624, 625, 626, 627, 628, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "sure": [0, 5, 19, 23, 26, 46, 79, 85, 107, 120, 127, 131, 171, 172, 173, 175, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 225, 253, 269, 295, 378, 561, 621, 623, 624, 625, 628, 636, 637, 638, 640, 642, 643], "alwai": [0, 19, 21, 22, 34, 35, 44, 48, 54, 71, 72, 75, 85, 89, 90, 97, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 239, 243, 265, 277, 278, 324, 330, 335, 355, 362, 373, 375, 378, 379, 463, 570, 575, 578, 583, 584, 586, 614, 622, 623, 624, 625, 636, 637, 638, 640], "enjoi": [0, 22, 80, 629], "latest": [0, 6, 21, 29, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 48, 142, 145, 146, 149, 150, 188, 406, 623, 636, 637, 638, 642], "featur": [0, 6, 18, 21, 22, 23, 34, 35, 37, 40, 41, 42, 44, 46, 50, 52, 62, 63, 71, 78, 83, 84, 99, 105, 106, 117, 120, 123, 127, 135, 138, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 163, 168, 169, 170, 173, 174, 176, 177, 178, 195, 216, 219, 234, 237, 239, 246, 263, 264, 272, 277, 286, 297, 298, 300, 302, 303, 323, 324, 325, 326, 328, 329, 330, 335, 341, 345, 347, 361, 364, 366, 372, 373, 374, 375, 376, 377, 379, 380, 381, 382, 383, 384, 385, 396, 414, 415, 561, 591, 595, 621, 622, 623, 624, 625, 627, 628, 629, 631, 634, 638, 640, 642, 643], "recent": [0, 26, 187, 276, 278, 280, 643], "version": [0, 2, 6, 7, 18, 25, 33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 48, 49, 50, 51, 57, 58, 60, 73, 74, 77, 82, 83, 84, 85, 105, 117, 120, 123, 126, 127, 128, 129, 135, 142, 143, 147, 148, 149, 151, 153, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 219, 267, 276, 277, 278, 280, 283, 300, 302, 323, 324, 325, 326, 327, 328, 329, 330, 334, 335, 345, 347, 361, 362, 364, 366, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 384, 414, 415, 592, 593, 595, 621, 623, 624, 625, 626, 628, 631, 636, 637, 638, 639, 643], "although": [0, 2, 5, 21, 27, 46, 72, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 312, 313, 314, 336, 338, 344, 621, 622, 629, 640], "core": [0, 6, 7, 10, 19, 27, 48, 49, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 98, 99, 168, 614, 615, 616, 624, 627, 642], "guarante": [0, 12, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 85, 87, 92, 93, 94, 95, 107, 109, 113, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 268, 277, 278, 323, 324, 325, 326, 328, 329, 330, 335, 341, 372, 373, 374, 375, 376, 377, 378, 379, 380, 629], "backward": [0, 7, 8, 9, 27, 34, 35, 50, 83, 84, 85, 117, 118, 119, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 270, 277, 278, 323, 324, 325, 326, 328, 329, 330, 335, 341, 345, 346, 348, 349, 353, 354, 360, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 413, 621, 623, 624, 625, 628, 629, 631, 636, 637, 638], "compat": [0, 1, 6, 7, 17, 18, 26, 34, 35, 37, 46, 50, 52, 56, 58, 68, 76, 83, 84, 85, 93, 95, 103, 105, 106, 107, 111, 117, 120, 123, 127, 129, 135, 144, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 261, 270, 273, 277, 278, 280, 300, 302, 311, 322, 323, 324, 325, 326, 328, 329, 330, 335, 345, 346, 348, 349, 350, 352, 353, 354, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 413, 582, 583, 584, 588, 593, 621, 624, 633, 640], "2": [0, 2, 4, 6, 7, 8, 10, 18, 19, 21, 22, 27, 28, 29, 34, 35, 37, 46, 47, 48, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 92, 94, 98, 99, 105, 106, 111, 113, 117, 118, 119, 120, 123, 124, 127, 133, 134, 135, 138, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 204, 211, 215, 216, 218, 220, 223, 224, 225, 227, 228, 229, 230, 239, 240, 244, 246, 248, 250, 253, 256, 260, 261, 262, 263, 268, 269, 270, 273, 275, 277, 278, 280, 285, 286, 287, 288, 289, 290, 291, 292, 295, 296, 298, 299, 300, 302, 303, 304, 305, 309, 310, 318, 320, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 335, 336, 338, 340, 344, 345, 346, 347, 348, 349, 353, 354, 360, 361, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 388, 396, 400, 461, 462, 465, 466, 467, 547, 562, 572, 576, 579, 585, 587, 588, 593, 600, 614, 620, 621, 622, 623, 624, 625, 627, 628, 635, 636, 637, 638, 640, 641, 642, 643], "0": [0, 2, 6, 7, 9, 10, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 34, 35, 36, 37, 40, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 94, 98, 99, 105, 106, 113, 117, 118, 119, 120, 123, 126, 127, 129, 130, 133, 134, 135, 141, 142, 143, 145, 146, 147, 148, 151, 153, 154, 155, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 201, 203, 212, 213, 215, 216, 217, 218, 219, 220, 222, 223, 224, 225, 226, 228, 229, 231, 232, 233, 235, 238, 239, 240, 241, 242, 243, 244, 247, 248, 249, 250, 251, 253, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 273, 274, 275, 276, 277, 278, 280, 284, 285, 286, 288, 289, 290, 291, 292, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 308, 310, 312, 313, 314, 317, 318, 319, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 337, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 352, 354, 355, 356, 357, 358, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 396, 400, 407, 413, 414, 416, 418, 419, 420, 423, 443, 447, 461, 465, 469, 470, 485, 501, 503, 511, 513, 517, 518, 520, 529, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 557, 561, 562, 564, 567, 569, 570, 573, 575, 577, 578, 581, 583, 584, 586, 587, 588, 593, 607, 614, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643], "nightli": [0, 25], "via": [0, 3, 6, 17, 18, 22, 23, 26, 27, 39, 44, 45, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 69, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 84, 86, 93, 127, 147, 156, 176, 178, 184, 188, 240, 248, 251, 275, 324, 330, 335, 348, 351, 362, 373, 375, 379, 414, 562, 563, 565, 566, 567, 568, 570, 571, 572, 573, 574, 575, 576, 578, 579, 580, 581, 582, 584, 585, 586, 587, 588, 607, 621, 622, 623, 624, 627, 629, 640, 642, 643], "tensordict": [0, 1, 2, 6, 10, 16, 17, 18, 19, 20, 21, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 103, 105, 106, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 133, 134, 135, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 202, 203, 204, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 281, 282, 283, 284, 285, 294, 295, 296, 299, 300, 302, 305, 310, 311, 312, 315, 320, 323, 324, 325, 326, 327, 328, 329, 330, 335, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 400, 404, 405, 406, 408, 410, 413, 435, 466, 563, 565, 566, 568, 569, 571, 572, 574, 575, 576, 579, 580, 581, 582, 583, 584, 585, 587, 588, 593, 600, 607, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 643], "git": [0, 25, 26, 29], "clone": [0, 23, 27, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 92, 170, 182, 191, 192, 239, 250, 268, 269, 278, 281, 282, 283, 324, 330, 335, 340, 353, 360, 368, 621, 636, 638, 642], "willing": 0, "contribut": [0, 304, 414], "cd": [0, 26], "path": [0, 18, 25, 26, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 92, 108, 114, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 159, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 209, 248, 275, 323, 324, 325, 326, 327, 328, 329, 330, 335, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 390, 395, 396, 410, 413, 414, 415, 470, 582, 583, 622, 625, 631, 636], "root": [0, 19, 21, 22, 56, 58, 64, 65, 67, 68, 75, 76, 77, 78, 79, 80, 81, 82, 89, 90, 97, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 210, 219, 242, 264, 265, 300, 301, 302, 318, 319, 381, 624, 626, 636, 637, 638, 640, 643], "http": [0, 24, 25, 26, 29, 34, 35, 41, 42, 44, 64, 75, 77, 78, 79, 80, 81, 82, 98, 99, 118, 119, 121, 122, 129, 131, 133, 134, 139, 140, 142, 143, 144, 145, 146, 149, 150, 153, 159, 160, 161, 162, 175, 184, 188, 219, 248, 273, 287, 288, 289, 290, 291, 292, 296, 297, 298, 304, 306, 307, 310, 313, 314, 315, 345, 346, 348, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 363, 364, 365, 366, 367, 368, 381, 590, 632, 633, 639, 642], "github": [0, 24, 25, 26, 29, 41, 42, 44, 75, 77, 78, 80, 118, 119, 121, 122, 126, 129, 133, 134, 139, 140, 142, 143, 145, 146, 149, 150, 153, 159, 160, 161, 162, 216, 219, 273, 627, 631, 633, 636, 637, 642], "com": [0, 24, 25, 26, 29, 41, 42, 44, 77, 80, 81, 118, 119, 121, 122, 129, 131, 133, 134, 139, 140, 142, 143, 145, 146, 149, 150, 153, 159, 160, 161, 162, 219, 633, 642], "setup": [0, 1, 6, 26, 118, 119, 131, 133, 134, 159, 193, 194, 379, 414, 582, 587, 588], "py": [0, 6, 7, 18, 22, 126, 128, 209, 219, 293, 614, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643], "develop": [0, 22, 23, 26, 131, 330, 335, 593, 621, 634, 642], "A": [0, 2, 6, 21, 22, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 99, 100, 101, 102, 104, 105, 107, 111, 112, 113, 114, 115, 117, 120, 123, 125, 127, 129, 130, 132, 135, 147, 148, 151, 152, 153, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 200, 201, 202, 203, 205, 210, 212, 214, 215, 216, 218, 219, 222, 223, 224, 225, 229, 235, 239, 241, 242, 248, 249, 251, 258, 263, 265, 268, 269, 270, 273, 274, 276, 277, 278, 279, 280, 284, 285, 286, 295, 296, 299, 300, 302, 303, 304, 305, 311, 315, 322, 323, 324, 325, 326, 327, 328, 329, 330, 333, 334, 335, 336, 338, 339, 341, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 389, 390, 393, 395, 397, 398, 399, 402, 409, 410, 413, 415, 420, 457, 458, 459, 460, 461, 462, 463, 465, 466, 467, 468, 469, 557, 563, 568, 579, 580, 582, 588, 589, 614, 620, 621, 623, 625, 627, 628, 629, 632, 633, 638, 641, 643], "seri": [0, 12, 17, 26, 27, 63, 91, 101, 111, 112, 115, 116, 156, 243, 269, 388, 621, 622, 623, 630, 631, 636, 637, 640, 643], "quick": [0, 75, 591, 625], "ramp": 0, "up": [0, 1, 2, 5, 6, 7, 8, 21, 22, 27, 28, 32, 33, 34, 35, 36, 37, 40, 41, 42, 44, 46, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 76, 82, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 199, 215, 218, 237, 240, 264, 269, 322, 327, 364, 378, 397, 415, 562, 592, 614, 621, 622, 623, 624, 627, 631, 633, 634, 636, 637, 638, 640, 642, 643], "If": [0, 2, 3, 4, 5, 9, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94, 95, 99, 101, 103, 104, 105, 106, 111, 113, 117, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 134, 135, 139, 140, 141, 142, 143, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 162, 163, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 207, 210, 211, 212, 215, 216, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 234, 237, 239, 240, 241, 242, 243, 244, 248, 249, 252, 253, 256, 257, 262, 263, 264, 265, 266, 267, 268, 270, 271, 273, 275, 277, 278, 280, 285, 286, 295, 296, 299, 300, 302, 303, 304, 310, 311, 312, 320, 322, 323, 324, 325, 326, 328, 329, 330, 331, 335, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 352, 354, 355, 356, 357, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 392, 395, 396, 397, 398, 399, 403, 405, 406, 410, 413, 414, 415, 470, 551, 557, 561, 562, 563, 565, 566, 568, 570, 571, 572, 574, 575, 576, 578, 579, 580, 582, 583, 584, 585, 586, 587, 588, 592, 621, 622, 623, 624, 625, 626, 628, 630, 631, 633, 635, 636, 637, 638, 640, 642, 643], "hurri": [0, 626], "last": [0, 2, 17, 18, 23, 34, 35, 37, 40, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 76, 104, 105, 106, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 133, 134, 135, 142, 143, 147, 148, 151, 153, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 181, 193, 204, 212, 215, 218, 223, 224, 234, 242, 244, 249, 262, 264, 266, 276, 280, 284, 286, 299, 300, 302, 303, 304, 306, 318, 324, 330, 335, 336, 338, 341, 348, 381, 383, 384, 593, 622, 623, 624, 625, 626, 627, 633, 636, 637, 638, 639, 640, 642, 643], "item": [0, 21, 27, 34, 37, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 93, 99, 104, 111, 212, 233, 269, 278, 304, 349, 350, 352, 379, 400, 607, 621, 623, 624, 628, 629, 633, 636, 637, 638, 640], "navig": [0, 182, 633, 637], "previou": [0, 22, 23, 29, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 211, 234, 263, 314, 315, 572, 579, 585, 587, 623, 624, 625, 626, 627, 631, 638, 643], "whenev": [0, 2, 22, 34, 35, 37, 40, 41, 42, 44, 46, 48, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 69, 70, 71, 72, 73, 74, 75, 80, 85, 98, 99, 105, 106, 121, 122, 126, 128, 129, 139, 140, 153, 161, 162, 169, 170, 171, 172, 173, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 209, 234, 238, 269, 270, 276, 324, 330, 335, 362, 373, 375, 378, 379, 381, 382, 383, 384, 386, 413, 630, 633, 640], "want": [0, 5, 21, 22, 25, 26, 27, 37, 46, 48, 106, 169, 170, 173, 183, 219, 244, 324, 330, 335, 345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 373, 375, 379, 614, 621, 622, 623, 624, 625, 626, 628, 629, 630, 636, 637, 638, 639, 640, 642, 643], "ted": [0, 75, 76, 77, 78, 79, 80, 81, 82, 89, 90, 97, 620, 632, 641], "s": [0, 1, 2, 3, 5, 6, 7, 17, 18, 19, 21, 22, 25, 26, 27, 30, 32, 34, 35, 36, 37, 38, 40, 41, 42, 44, 46, 48, 49, 51, 56, 64, 65, 66, 67, 68, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 105, 106, 111, 117, 118, 119, 120, 123, 127, 131, 133, 134, 135, 139, 140, 142, 147, 148, 149, 150, 151, 156, 157, 158, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 223, 224, 237, 242, 248, 261, 263, 266, 267, 268, 269, 270, 273, 275, 277, 278, 281, 283, 284, 286, 293, 296, 299, 300, 302, 318, 322, 323, 324, 325, 326, 328, 329, 330, 335, 338, 339, 340, 341, 344, 346, 347, 348, 353, 359, 360, 361, 362, 364, 367, 368, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 396, 412, 413, 414, 563, 568, 569, 570, 571, 574, 575, 576, 578, 580, 581, 582, 583, 584, 586, 588, 593, 614, 620, 621, 622, 623, 624, 625, 626, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643], "modul": [0, 6, 7, 17, 18, 21, 22, 23, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 64, 67, 68, 69, 70, 83, 84, 85, 111, 117, 118, 119, 120, 123, 127, 135, 141, 144, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 209, 212, 218, 223, 229, 231, 237, 239, 241, 248, 249, 262, 263, 268, 269, 270, 273, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 409, 410, 412, 414, 415, 470, 554, 557, 563, 565, 566, 568, 570, 571, 572, 574, 579, 580, 582, 585, 587, 588, 591, 593, 604, 605, 606, 607, 608, 609, 610, 612, 613, 620, 622, 623, 626, 628, 629, 630, 632, 634, 635, 636, 637, 638, 639, 640, 641], "optim": [0, 1, 2, 15, 27, 51, 83, 84, 85, 117, 118, 119, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 268, 270, 318, 322, 323, 324, 325, 326, 328, 329, 330, 335, 346, 348, 362, 363, 364, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 404, 405, 410, 412, 414, 415, 470, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 557, 591, 614, 615, 620, 623, 624, 625, 626, 627, 629, 632, 634, 636, 637, 638, 641], "collect": [0, 1, 2, 3, 4, 5, 6, 12, 20, 22, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 56, 58, 59, 64, 65, 66, 67, 68, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 104, 117, 120, 123, 127, 135, 147, 148, 151, 153, 156, 157, 158, 163, 168, 169, 170, 173, 174, 175, 176, 177, 178, 183, 189, 193, 195, 199, 216, 217, 218, 219, 220, 221, 223, 226, 227, 230, 234, 236, 240, 244, 245, 248, 250, 252, 253, 254, 255, 256, 260, 262, 263, 264, 266, 269, 270, 271, 275, 277, 278, 280, 286, 293, 303, 304, 308, 310, 323, 325, 326, 328, 329, 338, 346, 349, 352, 354, 365, 367, 368, 369, 372, 374, 376, 377, 380, 388, 400, 403, 405, 406, 410, 412, 413, 414, 415, 470, 550, 551, 557, 559, 560, 581, 586, 587, 588, 591, 593, 600, 607, 615, 620, 621, 624, 625, 626, 627, 628, 631, 632, 636, 637, 638, 639, 640, 641, 642, 643], "storag": [0, 2, 4, 10, 13, 27, 34, 35, 37, 40, 46, 48, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 104, 105, 106, 108, 109, 110, 111, 113, 114, 117, 120, 123, 125, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 218, 219, 227, 230, 253, 323, 324, 325, 326, 328, 329, 330, 335, 347, 361, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 397, 415, 422, 423, 424, 425, 428, 429, 433, 434, 435, 436, 582, 583, 584, 585, 591, 620, 622, 623, 624, 625, 626, 628, 631, 632, 636, 637, 639, 641], "log": [0, 20, 23, 27, 30, 186, 187, 193, 194, 293, 294, 295, 296, 304, 308, 318, 319, 322, 324, 327, 330, 331, 335, 339, 341, 345, 346, 347, 348, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 369, 373, 375, 379, 395, 402, 403, 404, 410, 412, 414, 415, 470, 557, 581, 583, 591, 620, 621, 622, 623, 626, 627, 631, 632, 636, 637, 638, 641, 642], "your": [0, 1, 5, 7, 16, 22, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 41, 42, 43, 44, 45, 48, 85, 117, 120, 123, 127, 131, 135, 138, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 277, 278, 324, 330, 335, 341, 347, 364, 373, 375, 378, 379, 399, 561, 592, 593, 614, 620, 622, 623, 624, 626, 627, 628, 629, 630, 632, 634, 636, 637, 640, 641, 642], "own": [0, 2, 5, 7, 16, 22, 34, 35, 40, 46, 47, 51, 85, 117, 120, 123, 127, 135, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 388, 563, 568, 574, 614, 620, 622, 623, 626, 632, 636, 637, 638, 641], "train": [0, 1, 2, 5, 6, 9, 18, 20, 32, 34, 35, 37, 40, 41, 42, 44, 46, 47, 48, 50, 55, 75, 77, 83, 84, 85, 98, 99, 117, 120, 123, 127, 132, 135, 139, 140, 147, 148, 149, 150, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 227, 235, 248, 262, 267, 270, 273, 275, 284, 288, 290, 299, 310, 322, 323, 324, 325, 326, 328, 329, 330, 333, 334, 335, 345, 346, 347, 348, 349, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 397, 403, 410, 412, 413, 414, 415, 470, 557, 585, 591, 593, 597, 598, 604, 614, 615, 620, 622, 626, 629, 630, 632, 639, 640, 641, 642, 643], "loop": [0, 1, 5, 7, 27, 37, 48, 83, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 284, 299, 310, 323, 325, 326, 328, 329, 346, 348, 354, 360, 364, 365, 367, 368, 369, 372, 374, 376, 377, 380, 381, 382, 383, 384, 406, 410, 564, 570, 578, 584, 585, 586, 615, 617, 620, 621, 622, 626, 628, 629, 630, 632, 635, 640, 641, 642], "ppo": [0, 5, 7, 23, 27, 339, 341, 347, 361, 364, 414, 469, 470, 615, 620, 621, 622, 625, 627, 628, 632, 636, 641], "pendulum": [0, 1, 7, 16, 18, 21, 22, 34, 35, 37, 40, 46, 47, 48, 49, 65, 85, 111, 117, 120, 121, 122, 123, 124, 126, 127, 128, 135, 142, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 219, 222, 223, 225, 232, 238, 239, 244, 251, 253, 257, 258, 261, 263, 264, 265, 268, 269, 270, 271, 277, 278, 285, 300, 302, 378, 557, 600, 620, 622, 623, 626, 627, 628, 632, 641, 642, 643], "introduct": [0, 620, 626, 632, 636, 637, 641, 643], "multi": [0, 1, 4, 16, 17, 26, 28, 34, 35, 40, 64, 67, 69, 70, 85, 89, 90, 97, 117, 120, 123, 127, 135, 139, 140, 147, 148, 151, 154, 155, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 240, 270, 300, 302, 303, 322, 324, 330, 335, 338, 341, 373, 375, 378, 379, 381, 382, 383, 384, 418, 419, 462, 591, 593, 595, 614, 620, 621, 622, 623, 624, 626, 627, 632, 638, 641, 642], "agent": [0, 16, 21, 22, 28, 66, 132, 138, 139, 140, 145, 146, 149, 150, 154, 155, 159, 160, 161, 162, 164, 182, 240, 260, 261, 262, 304, 347, 361, 364, 414, 591, 620, 626, 632, 638, 641], "env": [0, 1, 2, 4, 6, 7, 18, 19, 20, 21, 22, 24, 25, 26, 27, 30, 34, 35, 37, 40, 41, 42, 44, 46, 47, 48, 49, 56, 64, 65, 68, 69, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 111, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 285, 300, 302, 323, 324, 325, 326, 328, 329, 330, 335, 338, 340, 362, 373, 375, 378, 379, 386, 387, 388, 399, 415, 440, 441, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 528, 529, 530, 531, 532, 533, 534, 535, 551, 552, 553, 557, 559, 560, 561, 591, 593, 600, 614, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 639, 640, 641], "us": [0, 1, 2, 3, 4, 5, 7, 8, 9, 12, 15, 16, 17, 18, 19, 20, 22, 24, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 95, 97, 98, 99, 100, 105, 106, 111, 113, 117, 118, 119, 120, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 208, 209, 210, 211, 212, 213, 215, 216, 218, 219, 220, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 237, 238, 239, 240, 241, 242, 244, 247, 248, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 277, 278, 280, 284, 285, 286, 287, 288, 289, 292, 294, 295, 296, 297, 299, 300, 301, 302, 303, 304, 305, 308, 309, 310, 311, 312, 315, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 391, 392, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 458, 468, 470, 551, 552, 553, 555, 557, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 574, 575, 576, 578, 579, 581, 582, 583, 584, 585, 586, 587, 588, 592, 593, 594, 607, 614, 615, 619, 620, 621, 622, 623, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 641, 643], "pretrain": [0, 322, 620, 632, 641], "recurr": [0, 218, 300, 302, 314, 381, 620, 622, 627, 632, 640, 641], "dqn": [0, 7, 75, 212, 231, 286, 295, 296, 345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 373, 375, 379, 554, 620, 625, 627, 628, 631, 632, 641], "polici": [0, 1, 3, 4, 5, 6, 7, 10, 12, 17, 21, 22, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 65, 85, 117, 118, 119, 120, 123, 127, 135, 141, 147, 148, 151, 152, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 208, 224, 229, 239, 242, 262, 265, 269, 281, 282, 283, 284, 285, 295, 296, 299, 300, 302, 310, 311, 312, 324, 327, 330, 335, 337, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 353, 354, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 404, 412, 413, 414, 415, 416, 418, 419, 420, 470, 483, 552, 553, 557, 559, 560, 562, 563, 565, 566, 567, 568, 571, 573, 574, 576, 580, 582, 588, 591, 593, 600, 601, 607, 620, 622, 626, 628, 629, 632, 634, 639, 640, 641, 642, 643], "replai": [0, 1, 5, 10, 13, 15, 27, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 98, 99, 100, 101, 102, 104, 106, 107, 109, 111, 112, 116, 218, 219, 229, 249, 253, 263, 269, 348, 349, 350, 352, 353, 354, 360, 365, 367, 368, 369, 378, 397, 406, 410, 412, 414, 415, 425, 426, 427, 428, 431, 435, 436, 470, 555, 557, 591, 593, 614, 615, 620, 625, 632, 638, 639, 641], "buffer": [0, 1, 3, 5, 6, 10, 13, 15, 18, 22, 23, 27, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 93, 94, 95, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 111, 112, 113, 116, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 218, 219, 223, 228, 229, 237, 248, 249, 253, 263, 268, 269, 270, 273, 275, 284, 310, 323, 324, 325, 326, 328, 329, 330, 335, 340, 343, 347, 348, 349, 350, 352, 353, 354, 360, 361, 364, 365, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 396, 397, 406, 410, 412, 414, 415, 425, 426, 427, 428, 431, 435, 436, 470, 555, 557, 575, 576, 582, 583, 584, 585, 591, 593, 614, 615, 620, 625, 630, 632, 638, 639, 641, 643], "export": [0, 25, 26, 620, 632, 641], "llm": [0, 6, 48, 49, 50, 51, 83, 84, 85, 86, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 372, 373, 374, 375, 376, 377, 378, 379, 380, 498, 581, 582, 583, 584, 585, 586, 587, 588, 589, 591, 595, 614, 620, 632, 641], "build": [0, 3, 7, 21, 26, 52, 56, 64, 65, 66, 67, 68, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 117, 118, 119, 120, 123, 127, 128, 129, 133, 134, 135, 139, 140, 142, 145, 146, 147, 148, 151, 153, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 253, 277, 278, 323, 324, 325, 326, 328, 329, 330, 335, 339, 341, 372, 373, 374, 375, 376, 377, 378, 379, 380, 410, 554, 555, 556, 595, 600, 606, 620, 623, 624, 625, 627, 628, 629, 630, 632, 636, 637, 638, 639, 641, 642, 643], "tool": [0, 3, 18, 20, 24, 84, 168, 182, 184, 185, 188, 191, 195, 198, 199, 200, 201, 593, 595, 596, 599, 620, 624, 626, 632, 636, 638, 640, 641, 643], "enabl": [0, 6, 7, 26, 27, 76, 86, 92, 94, 104, 113, 168, 182, 216, 300, 302, 310, 322, 324, 327, 330, 331, 332, 335, 338, 375, 386, 388, 404, 412, 414, 415, 593, 604, 614, 620, 623, 626, 632, 636, 637, 638, 640, 641], "competit": [0, 22, 139, 140, 620, 632, 637, 641], "ddpg": [0, 288, 289, 290, 291, 349, 415, 620, 622, 628, 632, 637, 641], "task": [0, 7, 19, 22, 28, 77, 80, 117, 120, 121, 122, 123, 127, 130, 135, 139, 140, 147, 148, 149, 150, 151, 153, 156, 157, 158, 161, 162, 168, 169, 170, 173, 175, 176, 177, 178, 180, 248, 261, 270, 273, 275, 353, 360, 415, 591, 620, 621, 622, 623, 624, 626, 627, 632, 633, 636, 637, 638, 641, 643], "specif": [0, 2, 6, 7, 16, 18, 22, 24, 27, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 69, 70, 71, 72, 73, 74, 117, 120, 123, 127, 135, 145, 146, 147, 148, 151, 156, 157, 158, 161, 168, 169, 170, 173, 176, 177, 178, 183, 188, 207, 242, 263, 278, 292, 300, 302, 322, 324, 330, 331, 332, 335, 345, 347, 362, 364, 366, 373, 375, 379, 388, 396, 397, 398, 410, 414, 562, 563, 565, 566, 567, 568, 571, 572, 573, 574, 579, 580, 582, 585, 587, 588, 591, 600, 614, 615, 620, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 636, 637, 640, 641, 642], "object": [0, 17, 21, 23, 25, 26, 34, 35, 36, 37, 40, 41, 42, 44, 46, 48, 49, 56, 62, 68, 71, 83, 84, 85, 86, 87, 92, 93, 94, 95, 103, 107, 109, 113, 116, 117, 120, 123, 127, 133, 135, 147, 148, 151, 152, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 227, 230, 231, 237, 240, 244, 248, 268, 269, 270, 273, 277, 278, 281, 300, 302, 318, 322, 323, 324, 325, 326, 328, 329, 330, 335, 337, 339, 340, 341, 342, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 388, 415, 551, 552, 553, 554, 556, 557, 561, 563, 565, 566, 568, 571, 574, 576, 580, 582, 588, 591, 620, 622, 623, 624, 625, 629, 631, 632, 634, 636, 637, 638, 640, 641, 643], "loss": [0, 7, 19, 21, 27, 231, 304, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 373, 375, 379, 381, 405, 409, 410, 414, 415, 468, 469, 470, 554, 557, 591, 593, 598, 607, 608, 609, 610, 612, 613, 615, 620, 625, 626, 628, 629, 630, 632, 638, 640, 641], "trainer": [0, 6, 7, 322, 345, 346, 347, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 373, 375, 379, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 411, 412, 413, 414, 415, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 581, 582, 586, 587, 588, 591, 620, 621, 632, 641], "exampl": [0, 2, 3, 5, 18, 19, 21, 23, 28, 29, 34, 35, 37, 40, 41, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94, 98, 99, 105, 106, 111, 113, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 199, 201, 204, 205, 209, 210, 211, 212, 213, 215, 216, 218, 219, 220, 222, 223, 224, 225, 227, 228, 229, 230, 231, 232, 233, 235, 237, 238, 239, 240, 241, 244, 246, 247, 248, 249, 250, 251, 252, 253, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 277, 278, 280, 281, 282, 283, 285, 286, 287, 288, 289, 290, 291, 292, 294, 295, 296, 298, 299, 300, 302, 303, 304, 305, 308, 309, 310, 311, 312, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 388, 396, 398, 399, 400, 401, 402, 403, 405, 406, 407, 408, 409, 413, 414, 415, 461, 462, 465, 466, 467, 470, 557, 576, 582, 584, 585, 588, 591, 620, 621, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 641, 642, 643], "packag": [0, 18, 25, 26, 29, 188, 209, 591, 592, 633, 643], "kei": [0, 2, 7, 17, 18, 19, 22, 26, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 76, 83, 84, 85, 89, 98, 99, 103, 105, 106, 111, 117, 120, 123, 127, 133, 134, 135, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 237, 238, 239, 240, 241, 244, 247, 248, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 277, 278, 284, 285, 294, 295, 296, 299, 300, 302, 310, 311, 312, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 403, 404, 405, 407, 408, 410, 413, 414, 551, 583, 584, 589, 591, 621, 623, 624, 625, 626, 628, 633, 634, 635, 636, 637, 638, 640, 642, 643], "interfac": [0, 6, 16, 22, 51, 117, 130, 144, 303, 322, 324, 327, 330, 335, 397, 421, 577, 584, 588, 591, 597, 621, 623, 625, 630, 633, 634, 638, 640], "servic": [0, 46, 184, 187, 190, 191, 193, 199, 200, 241, 322, 331, 396, 397, 398, 591, 593], "registri": [0, 126, 159, 184, 191, 199, 396, 397, 398, 591, 593], "overview": [0, 591, 623, 625, 628, 636, 637, 642], "usag": [0, 1, 12, 18, 24, 26, 34, 35, 37, 40, 41, 42, 44, 46, 76, 82, 88, 90, 111, 169, 187, 189, 190, 216, 219, 231, 300, 302, 322, 324, 330, 335, 347, 348, 353, 360, 361, 364, 367, 370, 373, 375, 379, 396, 398, 413, 414, 591, 593, 621, 623, 624, 627, 628, 630, 636, 637, 640], "executor": [0, 22, 41, 42, 44, 157, 191, 591], "best": [0, 24, 28, 131, 300, 302, 322, 364, 591, 636, 637, 640, 642], "practic": [0, 3, 4, 18, 21, 22, 23, 24, 27, 48, 62, 75, 269, 301, 318, 319, 591, 592, 621, 622, 623, 624, 625, 628, 633, 636, 637, 639, 643], "also": [0, 2, 6, 7, 12, 17, 18, 19, 21, 22, 27, 28, 30, 34, 35, 39, 46, 52, 53, 55, 57, 59, 60, 61, 63, 67, 68, 69, 70, 71, 75, 77, 78, 80, 81, 82, 83, 84, 85, 92, 93, 94, 99, 105, 106, 111, 113, 117, 120, 123, 127, 134, 135, 139, 140, 147, 148, 149, 150, 151, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 207, 209, 210, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 229, 231, 232, 233, 235, 237, 238, 239, 241, 244, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 273, 274, 276, 277, 280, 286, 303, 314, 323, 324, 325, 326, 328, 329, 330, 335, 338, 339, 342, 343, 344, 345, 346, 348, 349, 350, 352, 353, 354, 359, 360, 364, 367, 368, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 386, 388, 403, 591, 593, 621, 622, 623, 624, 625, 626, 627, 628, 629, 633, 635, 636, 637, 638, 640, 642, 643], "_util": [0, 18, 147, 591, 625, 631], "implement_for": [0, 18, 591], "set_auto_unwrap_transformed_env": [0, 31, 270, 591], "auto_unwrap_transformed_env": [0, 399, 591], "configur": [0, 2, 4, 6, 27, 32, 34, 35, 37, 38, 40, 41, 42, 44, 46, 47, 48, 51, 120, 169, 188, 239, 287, 292, 309, 322, 324, 331, 347, 362, 364, 373, 375, 379, 396, 397, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 563, 565, 566, 568, 571, 574, 576, 580, 591, 600, 615, 621, 622, 623, 628, 634, 636, 637, 638], "system": [0, 10, 16, 23, 24, 84, 90, 168, 169, 170, 173, 175, 189, 191, 193, 194, 375, 379, 421, 576, 591, 593, 614, 615, 623, 634, 636, 637, 638], "simpl": [0, 6, 19, 21, 28, 38, 39, 63, 71, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 288, 322, 324, 330, 335, 338, 341, 350, 352, 362, 364, 366, 373, 375, 378, 379, 381, 403, 591, 593, 614, 621, 622, 623, 626, 627, 628, 634, 636, 637, 640, 643], "categori": [0, 56, 77, 591], "group": [0, 18, 19, 22, 50, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 75, 83, 84, 85, 117, 120, 123, 127, 135, 138, 139, 140, 145, 146, 147, 148, 149, 150, 151, 156, 157, 158, 159, 160, 161, 162, 164, 168, 169, 170, 173, 174, 176, 177, 178, 183, 240, 260, 322, 323, 325, 326, 328, 329, 330, 331, 333, 334, 372, 374, 376, 377, 380, 581, 582, 586, 587, 591, 593, 622, 627, 629, 637, 640], "complex": [0, 6, 12, 22, 33, 36, 38, 39, 43, 45, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379, 396, 588, 591, 593, 614, 621, 622, 626, 627], "parallel": [0, 1, 2, 3, 4, 16, 18, 19, 21, 27, 50, 51, 117, 120, 123, 126, 127, 128, 135, 147, 148, 149, 150, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 270, 276, 300, 302, 322, 331, 332, 345, 437, 558, 559, 560, 561, 588, 591, 614, 622, 623, 636, 637, 642], "avail": [0, 2, 3, 6, 16, 20, 23, 25, 34, 35, 40, 46, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 84, 99, 104, 105, 106, 118, 119, 121, 122, 131, 133, 134, 139, 140, 145, 146, 147, 149, 150, 153, 159, 160, 161, 162, 180, 184, 190, 192, 193, 199, 212, 215, 218, 237, 239, 331, 339, 341, 362, 373, 375, 379, 388, 559, 560, 564, 570, 575, 576, 578, 584, 586, 591, 593, 614, 621, 622, 623, 624, 625, 626, 627, 634, 636, 637, 638, 640, 643], "complet": [0, 26, 28, 43, 48, 49, 99, 104, 117, 120, 123, 126, 127, 128, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 175, 176, 177, 178, 182, 219, 261, 322, 378, 414, 567, 569, 572, 573, 579, 581, 585, 587, 588, 591, 592, 593, 614, 621, 623, 626, 633, 634, 635], "run": [0, 1, 2, 16, 18, 19, 22, 23, 24, 25, 26, 27, 29, 32, 33, 34, 35, 37, 40, 41, 42, 43, 44, 46, 48, 49, 65, 75, 77, 85, 99, 105, 106, 117, 118, 119, 120, 121, 122, 123, 126, 127, 133, 134, 135, 141, 142, 143, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 237, 243, 244, 260, 268, 269, 270, 277, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 303, 305, 306, 307, 309, 310, 312, 313, 314, 315, 322, 324, 330, 335, 336, 338, 341, 342, 343, 344, 348, 354, 367, 373, 375, 378, 379, 388, 395, 404, 415, 559, 560, 561, 591, 592, 614, 615, 621, 622, 623, 624, 627, 628, 629, 630, 631, 633, 636, 637, 638, 642], "experi": [0, 1, 16, 17, 64, 67, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 98, 99, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 390, 391, 392, 393, 394, 395, 396, 415, 591, 592, 618, 622, 623, 625, 629, 630, 636, 637, 640], "store": [0, 2, 6, 12, 17, 27, 32, 34, 35, 36, 37, 40, 41, 42, 43, 44, 46, 48, 49, 56, 62, 64, 65, 67, 68, 69, 70, 77, 78, 80, 81, 83, 84, 85, 87, 90, 92, 93, 94, 95, 98, 99, 105, 111, 113, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 237, 265, 276, 277, 278, 284, 310, 322, 323, 324, 325, 326, 328, 329, 330, 335, 345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 395, 414, 415, 470, 562, 563, 572, 574, 575, 591, 621, 623, 624, 627, 629, 631, 636, 637, 639, 643], "implement": [0, 1, 6, 9, 10, 12, 17, 21, 22, 28, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 71, 72, 73, 74, 85, 96, 98, 107, 108, 117, 120, 123, 127, 135, 141, 142, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 223, 227, 228, 232, 235, 239, 242, 250, 251, 257, 261, 267, 269, 270, 271, 277, 278, 280, 300, 301, 302, 317, 318, 319, 322, 324, 330, 332, 335, 345, 346, 348, 351, 352, 353, 359, 360, 362, 363, 364, 366, 367, 368, 373, 375, 378, 379, 386, 400, 414, 415, 552, 562, 586, 587, 588, 591, 593, 614, 615, 621, 622, 623, 624, 625, 636, 637, 638, 642], "detail": [0, 6, 21, 24, 25, 26, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 71, 72, 73, 74, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 266, 270, 296, 305, 322, 323, 324, 325, 326, 328, 329, 330, 335, 345, 347, 355, 361, 362, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 591, 592, 593, 622, 625, 629, 635, 640], "class": [0, 2, 4, 5, 10, 14, 16, 18, 19, 20, 21, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 120, 123, 124, 125, 126, 127, 128, 129, 134, 135, 138, 141, 144, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 209, 210, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 591, 593, 594, 600, 609, 614, 616, 618, 621, 622, 623, 624, 626, 627, 628, 629, 630, 633, 636, 637, 640, 643], "creat": [0, 1, 4, 6, 10, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 29, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 93, 95, 111, 117, 120, 123, 124, 127, 131, 135, 147, 148, 149, 151, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 210, 216, 219, 224, 237, 241, 248, 268, 269, 270, 273, 276, 277, 278, 286, 288, 289, 290, 291, 292, 293, 298, 300, 302, 303, 315, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 340, 341, 348, 350, 355, 364, 365, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 388, 396, 397, 398, 406, 414, 415, 470, 551, 552, 553, 557, 559, 560, 562, 563, 565, 566, 567, 568, 571, 573, 574, 575, 576, 578, 579, 580, 582, 588, 591, 593, 600, 607, 614, 615, 621, 622, 623, 624, 625, 627, 630, 633, 634, 636, 637, 638, 639, 640, 642, 643], "custom": [0, 6, 10, 16, 21, 22, 24, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 78, 83, 84, 85, 86, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 273, 322, 323, 324, 325, 326, 328, 329, 330, 335, 344, 355, 364, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 396, 398, 414, 470, 561, 586, 587, 591, 603, 615, 617, 621, 622, 623, 624, 627, 628, 630, 633, 636, 637], "futur": [0, 23, 37, 39, 50, 52, 83, 84, 85, 89, 90, 97, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 248, 268, 270, 275, 303, 322, 323, 324, 325, 326, 328, 329, 330, 335, 345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 414, 415, 591, 592, 593, 614], "extens": [0, 6, 64, 67, 69, 70, 106, 591, 640], "thing": [0, 5, 19, 21, 22, 26, 27, 83, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 269, 323, 325, 326, 328, 329, 354, 367, 372, 374, 376, 377, 380, 592, 623, 624, 625, 626, 627, 628, 629, 630, 636, 637, 640, 643], "consid": [0, 2, 6, 18, 21, 27, 33, 34, 35, 36, 37, 41, 43, 44, 45, 46, 48, 50, 56, 58, 64, 67, 69, 70, 85, 92, 94, 105, 106, 113, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 229, 277, 293, 304, 317, 324, 330, 335, 346, 348, 360, 365, 367, 368, 369, 373, 375, 378, 379, 381, 383, 384, 592, 593, 614, 621, 626, 627, 628, 638, 640], "when": [0, 2, 3, 6, 7, 8, 17, 18, 20, 21, 22, 24, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 104, 105, 106, 107, 109, 113, 117, 118, 119, 120, 123, 124, 126, 127, 128, 134, 135, 138, 139, 140, 142, 144, 147, 148, 149, 150, 151, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 208, 210, 213, 215, 218, 219, 223, 224, 227, 229, 230, 239, 240, 243, 244, 248, 249, 256, 263, 265, 268, 269, 270, 273, 275, 276, 277, 278, 280, 293, 300, 302, 303, 304, 318, 322, 323, 324, 325, 326, 328, 329, 330, 335, 338, 339, 340, 341, 343, 346, 347, 348, 350, 354, 355, 360, 361, 362, 364, 365, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 388, 390, 393, 395, 396, 406, 412, 413, 561, 572, 575, 576, 579, 581, 585, 587, 588, 592, 593, 614, 621, 622, 623, 624, 625, 627, 629, 630, 636, 637, 638, 639, 640, 642, 643], "debug": [0, 25, 27, 75, 76, 77, 78, 79, 80, 81, 82, 189, 265, 324, 330, 335, 592, 643], "work": [0, 4, 18, 20, 21, 22, 23, 27, 43, 45, 50, 51, 56, 58, 67, 75, 76, 77, 78, 79, 80, 81, 82, 85, 92, 98, 99, 103, 105, 106, 109, 116, 117, 120, 123, 126, 127, 128, 131, 135, 147, 148, 151, 153, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 207, 210, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 238, 239, 241, 247, 248, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 278, 280, 286, 296, 303, 312, 322, 324, 330, 335, 344, 347, 361, 364, 373, 375, 378, 379, 396, 397, 410, 576, 588, 591, 592, 593, 600, 621, 622, 623, 624, 626, 629, 634, 635, 636, 637, 638, 639, 640, 642, 643], "habitat": [0, 18, 129, 444, 592, 639], "lab": [0, 17, 121, 122, 129, 132, 592], "mujoco": [0, 25, 27, 153, 592, 621, 623, 624], "error": [0, 2, 22, 26, 29, 34, 35, 37, 40, 48, 53, 55, 57, 59, 60, 61, 63, 83, 84, 85, 92, 98, 99, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 159, 163, 164, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 249, 268, 280, 322, 323, 324, 325, 326, 328, 329, 330, 335, 354, 362, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 592, 593, 614, 621, 623, 636, 637, 643], "solut": [0, 12, 18, 25, 26, 28, 46, 105, 592, 625, 642], "resourc": [0, 3, 32, 41, 42, 44, 46, 129, 169, 170, 173, 182, 183, 190, 192, 193, 322, 327, 335, 396, 397, 592, 593, 614, 621, 623, 625, 636, 637], "issu": [0, 20, 22, 23, 24, 27, 65, 75, 78, 90, 92, 94, 98, 99, 105, 113, 117, 120, 123, 126, 127, 131, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 183, 192, 193, 210, 219, 249, 264, 295, 296, 311, 312, 322, 337, 339, 340, 341, 347, 364, 414, 592, 593, 634, 642], "customis": [0, 592, 622, 630], "video": [0, 16, 23, 28, 83, 388, 390, 393, 395, 404, 561, 592, 631, 636, 637], "render": [0, 20, 27, 134, 161, 386, 388, 404, 592, 621, 622, 623, 625, 626, 630], "index": [0, 21, 26, 27, 29, 37, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 91, 92, 93, 94, 98, 99, 101, 103, 105, 109, 111, 112, 113, 115, 116, 117, 120, 123, 127, 135, 139, 140, 145, 146, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 173, 174, 176, 177, 178, 193, 210, 214, 219, 223, 229, 270, 304, 322, 323, 325, 326, 328, 329, 338, 372, 374, 376, 377, 380, 588, 626, 633, 635, 636, 637, 640, 642], "search": [0, 56, 58, 144, 184, 185, 201, 211, 324, 330, 335, 622], "page": [0, 26, 182, 395, 628, 633], "bridg": [1, 415], "between": [1, 2, 19, 21, 23, 24, 34, 35, 36, 37, 40, 43, 46, 48, 49, 50, 64, 65, 67, 68, 69, 70, 80, 83, 84, 85, 87, 94, 98, 99, 101, 104, 105, 106, 113, 117, 120, 123, 127, 135, 139, 140, 147, 148, 151, 156, 157, 158, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 224, 229, 243, 254, 265, 268, 270, 277, 278, 286, 294, 296, 300, 302, 303, 322, 323, 324, 325, 326, 328, 329, 330, 333, 334, 335, 339, 341, 345, 347, 348, 349, 352, 353, 354, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 404, 410, 415, 589, 595, 614, 621, 622, 624, 625, 629, 633, 634, 636, 637, 638, 640, 643], "manag": [1, 2, 10, 11, 22, 27, 32, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 48, 49, 51, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 188, 190, 199, 300, 302, 322, 335, 364, 381, 382, 383, 384, 397, 398, 399, 404, 415, 578, 579, 580, 593, 595, 614, 624, 625, 628, 633, 642], "gather": [1, 2, 6, 17, 18, 41, 44, 46, 92, 94, 99, 105, 113, 193, 242, 249, 308, 324, 330, 335, 362, 373, 375, 379, 414, 415, 470, 551, 592, 622, 623, 624, 629, 636, 637, 638, 640, 642, 643], "thei": [1, 2, 3, 6, 7, 17, 20, 21, 22, 23, 27, 28, 34, 35, 37, 39, 40, 41, 42, 44, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 99, 117, 120, 123, 126, 127, 128, 135, 138, 139, 140, 147, 148, 149, 150, 151, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 215, 218, 233, 239, 248, 257, 265, 269, 270, 275, 302, 323, 324, 325, 326, 328, 329, 330, 335, 345, 346, 347, 348, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 406, 410, 562, 567, 570, 573, 575, 578, 584, 586, 601, 614, 621, 622, 623, 624, 625, 628, 635, 636, 637, 638, 639, 640, 642, 643], "handl": [1, 5, 6, 7, 16, 17, 18, 20, 22, 33, 34, 35, 36, 38, 39, 41, 43, 44, 45, 46, 50, 51, 62, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 276, 277, 278, 302, 303, 322, 323, 324, 325, 326, 328, 329, 330, 335, 345, 362, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 396, 397, 403, 410, 415, 559, 560, 562, 563, 564, 565, 566, 567, 568, 570, 571, 572, 573, 574, 576, 580, 581, 582, 588, 593, 595, 614, 621, 622, 623, 624, 626, 628, 633, 637, 640], "reset": [1, 2, 7, 16, 17, 27, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 106, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 163, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 211, 214, 215, 216, 219, 231, 234, 238, 243, 248, 256, 261, 262, 263, 264, 265, 268, 269, 270, 273, 276, 277, 280, 285, 300, 302, 310, 324, 330, 335, 338, 362, 373, 375, 378, 379, 387, 396, 397, 593, 614, 621, 622, 623, 624, 626, 629, 633, 635, 636, 637, 642], "execut": [1, 2, 3, 5, 17, 18, 20, 21, 22, 25, 26, 27, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 92, 93, 95, 105, 106, 117, 118, 119, 120, 123, 124, 127, 128, 129, 131, 133, 134, 135, 141, 142, 147, 148, 151, 153, 156, 157, 158, 159, 168, 169, 170, 173, 174, 176, 177, 178, 184, 188, 190, 191, 195, 199, 213, 224, 225, 242, 265, 270, 299, 300, 302, 322, 323, 325, 326, 327, 328, 329, 332, 338, 342, 343, 362, 368, 372, 373, 374, 375, 376, 377, 378, 379, 380, 551, 561, 593, 596, 614, 620, 622, 623, 624, 625, 626, 627, 628, 629, 630, 636, 637, 640, 641, 642, 643], "aggreg": [1, 2, 22, 75, 99, 111, 149, 150, 175, 211, 240, 278, 286, 288, 289, 343, 375, 397, 593, 637], "easi": [1, 7, 16, 17, 18, 21, 24, 30, 75, 79, 117, 120, 121, 122, 123, 127, 133, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 284, 299, 310, 600, 621, 622, 623, 634, 637, 639, 640, 642, 643], "qualiti": [1, 30, 175, 283, 364], "sever": [1, 2, 5, 6, 7, 12, 20, 27, 51, 59, 77, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 220, 222, 223, 240, 270, 323, 324, 325, 326, 328, 329, 330, 335, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 463, 593, 621, 623, 625, 630, 631, 640, 643], "differ": [1, 2, 5, 6, 7, 15, 16, 17, 19, 22, 23, 34, 35, 37, 40, 41, 42, 44, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 80, 83, 84, 85, 98, 103, 117, 118, 119, 120, 123, 124, 127, 133, 134, 135, 138, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 215, 219, 224, 228, 229, 240, 244, 251, 260, 268, 270, 272, 280, 303, 322, 323, 324, 325, 326, 328, 329, 330, 335, 341, 360, 362, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 396, 404, 410, 413, 559, 560, 577, 582, 586, 587, 593, 597, 614, 615, 621, 622, 623, 625, 626, 628, 630, 634, 635, 636, 637, 638, 639, 640, 642, 643], "scenario": [1, 4, 6, 38, 43, 45, 139, 140, 147, 161, 162, 224, 268, 375, 386, 614, 621, 627, 636, 637, 638], "syncdatacollector": [1, 2, 4, 5, 6, 18, 34, 35, 38, 40, 41, 42, 44, 46, 48, 49, 216, 219, 253, 300, 302, 415, 420, 557, 560, 621, 622, 623, 624, 625, 629, 631, 636, 637, 640], "singl": [1, 2, 3, 4, 6, 7, 16, 17, 18, 19, 20, 21, 22, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 56, 58, 61, 62, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 93, 106, 111, 117, 120, 123, 126, 127, 135, 139, 140, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 202, 203, 212, 219, 220, 240, 248, 253, 263, 268, 270, 275, 286, 300, 302, 303, 312, 322, 323, 324, 325, 326, 328, 329, 330, 331, 335, 343, 346, 347, 348, 350, 352, 354, 355, 360, 361, 364, 365, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 561, 562, 567, 572, 573, 579, 585, 587, 588, 591, 593, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 633, 635, 636, 637, 638, 639, 640, 642], "worker": [1, 2, 4, 6, 7, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 64, 67, 68, 69, 70, 71, 77, 82, 83, 84, 85, 124, 142, 147, 156, 171, 172, 174, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 268, 269, 277, 278, 322, 323, 325, 326, 328, 329, 332, 333, 334, 372, 374, 376, 377, 378, 380, 396, 397, 398, 410, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 579, 580, 581, 582, 584, 585, 586, 587, 588, 591, 621, 622, 623, 642, 643], "multisyncdatacollector": [1, 2, 3, 4, 6, 35, 41, 42, 44, 46, 49, 418, 560, 623, 629, 642], "across": [1, 2, 3, 6, 16, 19, 27, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 69, 70, 71, 72, 73, 74, 84, 99, 105, 106, 118, 119, 121, 122, 126, 128, 129, 131, 133, 134, 142, 143, 147, 153, 158, 169, 170, 173, 183, 192, 193, 268, 277, 278, 300, 302, 310, 322, 324, 362, 364, 373, 375, 378, 379, 397, 398, 413, 429, 563, 568, 574, 580, 593, 597, 614, 621, 626, 630, 636, 637, 638], "multipl": [1, 2, 3, 6, 7, 17, 18, 21, 22, 24, 27, 32, 33, 34, 35, 37, 40, 41, 42, 43, 44, 46, 48, 61, 67, 68, 69, 70, 84, 87, 94, 101, 113, 117, 118, 119, 133, 134, 147, 156, 158, 169, 170, 173, 175, 176, 183, 190, 192, 193, 220, 222, 229, 238, 242, 243, 253, 256, 260, 261, 268, 277, 295, 302, 311, 322, 335, 337, 339, 340, 341, 344, 347, 354, 361, 364, 397, 414, 429, 561, 562, 567, 573, 588, 591, 593, 595, 621, 622, 623, 626, 628, 629, 634, 636, 637, 638, 640, 642], "synchron": [1, 3, 22, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 83, 84, 142, 174, 188, 322, 323, 325, 326, 328, 329, 335, 372, 374, 376, 377, 380, 396, 418, 420, 559, 560, 563, 565, 566, 568, 571, 572, 574, 576, 579, 580, 582, 585, 587, 588, 591, 593, 622, 623, 636], "deliveri": [1, 17, 564], "multiasyncdatacollector": [1, 2, 34, 40, 41, 42, 44, 46, 49, 419, 559, 621, 622, 623, 629, 642], "asynchron": [1, 2, 3, 6, 22, 28, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 322, 323, 324, 325, 326, 328, 329, 330, 335, 340, 345, 372, 373, 374, 375, 376, 377, 378, 379, 380, 410, 412, 416, 419, 559, 572, 579, 585, 587, 621, 622, 623], "serv": [1, 2, 16, 22, 41, 44, 46, 83, 84, 129, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 421, 593, 640, 642, 643], "distribut": [1, 6, 10, 15, 21, 22, 23, 28, 29, 33, 36, 39, 41, 42, 43, 44, 45, 46, 47, 50, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 120, 149, 150, 189, 239, 244, 278, 284, 293, 294, 295, 296, 297, 301, 304, 305, 308, 309, 313, 314, 315, 317, 318, 319, 322, 324, 327, 330, 333, 334, 335, 339, 341, 342, 345, 346, 347, 348, 353, 354, 355, 360, 361, 364, 365, 366, 367, 368, 369, 375, 396, 397, 398, 429, 562, 563, 567, 568, 574, 575, 576, 581, 582, 586, 587, 591, 600, 614, 622, 623, 625, 627, 629, 636, 637, 638, 642, 643], "For": [1, 2, 5, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 34, 35, 37, 40, 41, 42, 44, 46, 49, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 76, 80, 82, 83, 84, 85, 86, 92, 94, 99, 105, 113, 117, 120, 123, 126, 127, 128, 132, 134, 135, 147, 148, 149, 150, 151, 156, 157, 158, 159, 161, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 227, 230, 234, 244, 262, 269, 270, 276, 281, 283, 296, 300, 302, 304, 311, 322, 323, 324, 325, 326, 328, 329, 330, 335, 345, 353, 355, 360, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 398, 404, 570, 572, 574, 576, 578, 581, 583, 584, 586, 588, 593, 614, 621, 622, 623, 624, 626, 627, 629, 630, 633, 636, 637, 638, 639, 640, 643], "node": [1, 3, 7, 15, 39, 41, 42, 44, 46, 47, 56, 58, 82, 83, 84, 135, 174, 177, 268, 322, 323, 325, 326, 328, 329, 333, 334, 372, 374, 376, 377, 380, 581, 582, 588, 591, 614, 629, 642], "rai": [1, 3, 10, 34, 35, 36, 37, 40, 46, 48, 49, 50, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 169, 170, 173, 183, 187, 190, 191, 192, 193, 241, 322, 327, 332, 335, 396, 397, 398, 569, 570, 571, 572, 573, 574, 581, 586, 587, 588, 614], "rpc": [1, 3, 34, 35, 37, 40, 44, 45, 47, 48, 49, 66, 322, 562, 567, 568, 581, 584, 586, 587], "backend": [1, 3, 7, 8, 10, 16, 17, 18, 20, 22, 26, 34, 35, 37, 40, 41, 42, 46, 47, 48, 117, 120, 123, 126, 127, 135, 147, 148, 151, 156, 157, 158, 167, 168, 169, 170, 173, 176, 177, 178, 190, 191, 209, 280, 324, 330, 331, 332, 335, 397, 398, 443, 447, 563, 580, 586, 587, 591, 597, 614, 621, 623, 624, 625, 626, 629, 630, 634, 638], "flexibl": [1, 6, 10, 16, 22, 28, 142, 168, 370, 593, 614, 621, 625, 634, 640, 643], "choos": [1, 2, 3, 6, 22, 30, 62, 117, 120, 138, 300, 302, 364, 621, 622, 623, 625, 636, 637, 640, 642], "async": [1, 7, 16, 34, 35, 37, 40, 41, 42, 44, 46, 48, 65, 117, 151, 157, 188, 276, 322, 331, 334, 335, 412, 414, 470, 572, 579, 585, 587], "devic": [1, 2, 3, 6, 12, 17, 18, 19, 21, 22, 26, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 93, 94, 95, 98, 105, 106, 113, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 207, 210, 212, 216, 223, 227, 228, 230, 231, 232, 237, 239, 240, 241, 246, 247, 248, 250, 251, 253, 257, 260, 261, 263, 266, 269, 270, 271, 273, 275, 277, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294, 295, 296, 298, 299, 300, 302, 303, 309, 310, 311, 312, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339, 340, 341, 343, 345, 346, 347, 348, 349, 350, 352, 353, 354, 360, 361, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 406, 413, 416, 418, 419, 420, 422, 424, 436, 437, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 461, 462, 469, 487, 506, 530, 531, 532, 555, 581, 588, 621, 622, 623, 624, 625, 636, 637, 638, 639, 642], "control": [1, 2, 7, 13, 17, 18, 22, 24, 27, 37, 52, 56, 58, 67, 68, 69, 70, 98, 99, 105, 117, 120, 121, 122, 123, 127, 134, 135, 138, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 183, 192, 193, 194, 210, 229, 288, 289, 290, 291, 300, 302, 310, 314, 322, 340, 341, 342, 345, 347, 348, 361, 362, 364, 373, 375, 379, 381, 386, 399, 415, 593, 614, 621, 622, 623, 624, 625, 626, 627, 628, 636, 637, 638, 640, 642], "where": [1, 2, 4, 7, 17, 18, 19, 20, 21, 22, 23, 26, 27, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 53, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 90, 92, 94, 99, 105, 106, 111, 113, 114, 117, 120, 123, 127, 135, 138, 141, 144, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 207, 210, 211, 212, 213, 216, 219, 224, 231, 239, 248, 253, 256, 261, 262, 263, 264, 265, 269, 270, 272, 275, 276, 284, 299, 300, 302, 304, 310, 315, 323, 324, 325, 326, 328, 329, 330, 335, 339, 340, 341, 345, 346, 347, 348, 353, 354, 355, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 395, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 576, 582, 583, 615, 621, 622, 623, 625, 626, 633, 635, 636, 637, 638, 640, 643], "weight": [1, 2, 23, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 64, 68, 83, 84, 85, 98, 99, 103, 117, 118, 119, 120, 123, 127, 135, 147, 148, 151, 154, 155, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 237, 240, 248, 263, 268, 269, 270, 273, 275, 300, 302, 322, 323, 324, 325, 326, 328, 329, 330, 335, 340, 345, 346, 347, 348, 354, 357, 364, 367, 368, 372, 373, 374, 375, 376, 377, 378, 379, 380, 413, 415, 499, 556, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 591, 621, 622, 623, 635, 638, 640, 642], "keep": [1, 2, 7, 20, 21, 22, 23, 26, 27, 35, 64, 67, 68, 69, 70, 83, 84, 85, 104, 111, 120, 147, 156, 174, 187, 189, 193, 210, 244, 248, 275, 277, 278, 310, 323, 325, 326, 328, 329, 338, 347, 364, 372, 374, 375, 376, 377, 378, 380, 388, 402, 410, 621, 622, 623, 624, 629, 630, 631, 637, 638, 640, 643], "infer": [1, 2, 6, 21, 33, 34, 35, 36, 37, 39, 41, 43, 44, 45, 46, 48, 49, 50, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 183, 192, 193, 194, 219, 277, 304, 322, 332, 335, 339, 341, 352, 375, 379, 386, 397, 582, 588, 593, 597, 621, 623, 625, 629, 631, 634, 640, 642], "date": [1, 33, 36, 120, 218, 391], "integr": [1, 6, 7, 16, 50, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 291, 300, 302, 322, 324, 330, 335, 340, 373, 375, 378, 379, 626, 627, 629, 633, 636, 637, 638, 639], "seamless": [1, 6, 303, 322, 576, 593, 634], "batch": [1, 4, 7, 9, 16, 18, 19, 20, 34, 35, 36, 37, 40, 41, 42, 44, 46, 48, 49, 51, 52, 56, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 94, 95, 99, 100, 104, 105, 106, 111, 113, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 133, 134, 135, 141, 142, 144, 145, 146, 147, 148, 151, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 211, 216, 219, 223, 225, 234, 242, 244, 246, 249, 253, 260, 263, 265, 269, 270, 272, 276, 277, 278, 293, 300, 302, 304, 308, 310, 317, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 338, 340, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 400, 403, 406, 407, 408, 410, 412, 413, 414, 415, 437, 470, 559, 560, 561, 593, 595, 607, 622, 623, 624, 625, 626, 629, 631, 633, 635, 636, 637, 639, 642, 643], "strategi": [1, 2, 5, 6, 7, 10, 12, 22, 37, 80, 83, 84, 103, 138, 174, 186, 212, 299, 308, 322, 323, 325, 326, 328, 329, 335, 372, 374, 375, 376, 377, 380, 563, 565, 566, 568, 571, 574, 576, 580, 582, 588, 591, 593, 600, 614, 621, 622, 625, 627, 636, 637, 640, 642], "organ": [1, 2, 7, 16, 633, 638, 640], "import": [1, 6, 7, 10, 16, 18, 19, 20, 21, 22, 23, 25, 29, 30, 34, 35, 37, 40, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94, 98, 99, 105, 106, 111, 113, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 137, 139, 140, 141, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 164, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 204, 209, 210, 211, 212, 213, 215, 216, 218, 219, 222, 224, 225, 231, 232, 237, 238, 239, 240, 244, 246, 248, 250, 251, 252, 253, 256, 257, 258, 260, 261, 262, 263, 264, 265, 268, 269, 271, 275, 277, 278, 280, 281, 282, 283, 285, 288, 289, 290, 291, 294, 295, 296, 298, 299, 300, 302, 303, 305, 310, 311, 312, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 388, 402, 404, 414, 415, 557, 588, 593, 600, 607, 614, 615, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 635, 636, 637, 638, 639, 640, 642, 643], "gymenv": [1, 6, 16, 18, 20, 21, 22, 24, 30, 34, 35, 37, 40, 46, 47, 48, 49, 65, 85, 111, 117, 120, 123, 124, 127, 129, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 212, 215, 216, 219, 222, 223, 224, 225, 231, 237, 238, 239, 244, 246, 251, 252, 253, 256, 258, 262, 263, 264, 265, 268, 269, 270, 271, 277, 278, 285, 300, 302, 338, 378, 386, 388, 443, 557, 600, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 639, 640, 642, 643], "parallelenv": [1, 3, 4, 16, 18, 20, 22, 34, 35, 37, 40, 44, 48, 49, 85, 111, 117, 120, 123, 127, 135, 142, 148, 149, 150, 151, 153, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 268, 269, 278, 300, 302, 378, 386, 558, 621, 622, 623, 626, 635, 642, 643], "def": [1, 7, 16, 18, 20, 21, 22, 47, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 117, 120, 123, 124, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 207, 209, 213, 215, 216, 218, 219, 220, 223, 224, 225, 227, 228, 230, 231, 232, 233, 235, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 273, 274, 276, 277, 278, 280, 320, 323, 324, 325, 326, 328, 329, 330, 335, 338, 339, 346, 348, 349, 354, 360, 362, 365, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 386, 399, 586, 587, 593, 614, 621, 622, 625, 633, 635, 636, 637, 638, 640, 642, 643], "make_env": [1, 4, 16, 20, 22, 147, 156, 162, 268, 277, 278, 386, 552, 553, 593, 621, 622, 642, 643], "v1": [1, 6, 7, 16, 18, 20, 21, 22, 30, 34, 35, 37, 40, 46, 47, 48, 49, 65, 76, 78, 83, 84, 85, 111, 117, 120, 123, 124, 126, 127, 128, 133, 134, 135, 142, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 215, 216, 219, 222, 224, 225, 232, 238, 239, 244, 251, 253, 256, 257, 258, 261, 262, 263, 264, 265, 268, 269, 271, 277, 278, 285, 300, 302, 323, 325, 326, 328, 329, 338, 372, 374, 376, 377, 378, 380, 386, 600, 622, 624, 626, 627, 628, 629, 630, 631, 638, 640, 642, 643], "4": [1, 4, 6, 7, 10, 16, 17, 22, 26, 53, 56, 58, 61, 63, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 94, 98, 99, 105, 106, 113, 117, 118, 119, 120, 121, 122, 123, 127, 133, 134, 135, 136, 137, 138, 141, 143, 147, 148, 151, 154, 155, 156, 157, 158, 168, 169, 170, 173, 174, 175, 176, 177, 178, 192, 212, 213, 215, 216, 219, 224, 225, 231, 253, 260, 261, 262, 268, 277, 278, 281, 282, 283, 285, 286, 287, 288, 289, 290, 291, 292, 295, 296, 297, 298, 299, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 320, 323, 325, 326, 328, 329, 336, 337, 338, 339, 340, 343, 345, 346, 348, 349, 350, 352, 353, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 379, 380, 386, 387, 396, 414, 415, 470, 478, 488, 494, 572, 579, 582, 585, 587, 593, 614, 620, 621, 622, 623, 624, 630, 636, 637, 638, 640, 641, 642, 643], "my_polici": 1, "frames_per_batch": [1, 2, 4, 6, 7, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 65, 216, 219, 253, 300, 302, 415, 416, 418, 419, 420, 550, 621, 622, 623, 624, 625, 629, 631, 636, 637, 640, 642], "200": [1, 7, 16, 34, 35, 37, 46, 65, 75, 85, 117, 120, 123, 126, 127, 128, 135, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 253, 288, 289, 297, 313, 314, 324, 330, 335, 373, 375, 378, 379, 386, 388, 621, 624, 625, 629, 631, 640], "total_fram": [1, 4, 6, 7, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 65, 216, 219, 253, 410, 414, 415, 416, 418, 419, 420, 470, 550, 557, 615, 621, 622, 623, 624, 625, 629, 631, 636, 637, 640, 642], "10000": [1, 6, 34, 35, 40, 46, 147, 410, 414, 415, 470, 624], "shape": [1, 4, 6, 14, 17, 18, 19, 22, 34, 35, 37, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 92, 93, 94, 98, 105, 111, 113, 117, 120, 121, 122, 123, 126, 127, 128, 133, 134, 135, 138, 139, 140, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 161, 162, 163, 168, 169, 170, 173, 174, 175, 176, 177, 178, 181, 183, 186, 193, 194, 204, 210, 212, 216, 218, 220, 227, 230, 231, 232, 237, 239, 240, 244, 246, 250, 251, 253, 257, 260, 261, 263, 266, 271, 277, 279, 281, 282, 283, 285, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 300, 302, 303, 304, 305, 308, 309, 310, 311, 312, 317, 318, 320, 323, 324, 325, 326, 328, 329, 330, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 379, 380, 381, 382, 383, 384, 385, 386, 388, 400, 406, 410, 461, 462, 465, 466, 467, 557, 581, 586, 587, 589, 593, 621, 622, 623, 624, 625, 627, 628, 631, 633, 634, 635, 636, 637, 639, 640, 642, 643], "50": [1, 34, 35, 37, 46, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 75, 82, 85, 105, 106, 139, 140, 181, 322, 327, 330, 335, 547, 614, 624, 634, 640], "step": [1, 2, 3, 4, 6, 7, 16, 17, 18, 19, 21, 23, 27, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 75, 83, 84, 85, 89, 90, 97, 99, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 133, 134, 135, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 210, 211, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 234, 235, 238, 239, 241, 242, 244, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 273, 274, 276, 277, 284, 297, 299, 300, 302, 310, 315, 323, 325, 326, 328, 329, 338, 339, 341, 345, 356, 364, 372, 374, 376, 377, 378, 380, 381, 382, 383, 384, 387, 390, 400, 404, 410, 412, 414, 415, 470, 593, 615, 622, 624, 625, 627, 628, 630, 631, 634, 635, 638, 639, 642], "each": [1, 2, 3, 5, 6, 7, 12, 15, 17, 19, 20, 21, 22, 23, 26, 27, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 56, 58, 59, 61, 67, 68, 69, 75, 76, 77, 80, 83, 84, 85, 98, 99, 103, 105, 106, 108, 111, 117, 120, 123, 124, 127, 135, 139, 140, 147, 148, 149, 150, 151, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 238, 240, 242, 248, 253, 256, 261, 262, 263, 264, 268, 269, 275, 277, 278, 280, 284, 295, 296, 299, 300, 302, 306, 312, 315, 322, 323, 324, 325, 326, 328, 329, 330, 335, 341, 343, 347, 361, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 388, 396, 404, 406, 559, 560, 563, 568, 574, 576, 580, 581, 582, 588, 593, 614, 621, 622, 623, 624, 627, 628, 629, 631, 636, 637, 638, 639, 640, 642, 643], "updat": [1, 17, 18, 21, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 56, 58, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 98, 99, 117, 120, 123, 127, 135, 141, 147, 148, 149, 150, 151, 156, 157, 158, 159, 160, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 211, 213, 215, 216, 227, 229, 230, 237, 250, 261, 262, 268, 270, 274, 277, 278, 284, 299, 310, 311, 312, 322, 323, 324, 325, 326, 328, 329, 330, 335, 339, 340, 341, 345, 346, 347, 348, 349, 350, 352, 354, 355, 356, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 404, 409, 410, 412, 413, 415, 552, 553, 556, 557, 562, 563, 564, 567, 569, 570, 571, 572, 573, 574, 575, 576, 578, 579, 584, 585, 586, 587, 588, 591, 622, 623, 624, 625, 628, 631, 636, 637, 638, 640, 643], "period": [1, 6, 189, 581], "should_upd": 1, "update_policy_weights_": [1, 2, 6, 32, 34, 35, 37, 39, 40, 41, 42, 44, 46, 48, 49, 189, 621, 637, 642], "shutdown": [1, 6, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 151, 157, 188, 216, 322, 396, 614, 621, 622, 640, 642], "basic": [1, 6, 21, 38, 86, 141, 168, 396, 398, 414, 591, 593, 615, 623, 628, 629, 631, 636, 642, 643], "size": [1, 16, 18, 19, 22, 34, 35, 37, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 93, 94, 95, 98, 99, 100, 104, 105, 106, 107, 113, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 133, 134, 135, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 210, 212, 216, 218, 219, 220, 223, 226, 227, 230, 231, 232, 234, 237, 240, 242, 246, 248, 250, 251, 253, 257, 259, 260, 261, 263, 265, 266, 269, 270, 271, 272, 275, 277, 281, 282, 283, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 302, 303, 304, 305, 308, 309, 310, 311, 312, 313, 314, 317, 320, 322, 323, 324, 325, 326, 328, 329, 330, 335, 336, 337, 338, 339, 340, 343, 345, 346, 347, 348, 349, 350, 352, 353, 354, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 388, 396, 400, 406, 412, 414, 415, 581, 586, 587, 593, 622, 623, 624, 625, 626, 627, 629, 633, 636, 637, 638, 643], "copi": [1, 6, 18, 33, 36, 41, 42, 44, 46, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 71, 72, 73, 74, 80, 83, 84, 85, 92, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 215, 219, 237, 251, 262, 268, 269, 270, 277, 278, 280, 300, 302, 323, 324, 325, 326, 328, 329, 330, 335, 348, 362, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 386, 575, 593, 621, 622, 624, 626, 636, 640, 642], "distributeddatacollector": [1, 3, 43, 47], "rpcdatacollector": [1, 3, 45, 47], "distributedsyncdatacollector": 1, "submitit_delayed_launch": 1, "raycollector": [1, 36, 65], "sender": [1, 38, 562, 563, 564, 565, 566, 567, 568, 571, 572, 573, 574, 576, 577, 579, 580, 581, 582, 583, 585, 588, 593], "receiv": [1, 22, 33, 36, 38, 39, 43, 45, 50, 51, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 224, 269, 270, 278, 303, 323, 324, 325, 326, 328, 329, 330, 335, 372, 373, 374, 375, 376, 377, 378, 379, 380, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 573, 574, 575, 576, 577, 578, 580, 581, 582, 583, 584, 586, 588, 621, 623, 628, 635, 638], "transport": [1, 562, 563, 564, 565, 566, 567, 568, 569, 571, 572, 573, 574, 575, 576, 580, 581, 582, 583, 584, 588], "scheme": [1, 34, 35, 37, 39, 40, 48, 49, 563, 565, 566, 568, 570, 571, 572, 574, 576, 578, 579, 580, 582, 584, 585, 586, 587, 588, 593, 643], "legaci": [1, 26, 34, 35, 52, 83, 84, 174, 186, 187, 193, 194, 323, 324, 325, 326, 328, 329, 330, 335, 372, 374, 376, 377, 380, 413, 563, 565, 566, 568, 574, 576, 578, 579, 580, 591], "interoper": [1, 34, 35], "helper": [1, 16, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 591, 600, 615, 621, 622, 624, 636, 638], "somewhat": [2, 183, 627, 643], "equival": [2, 7, 17, 46, 49, 50, 53, 55, 56, 57, 59, 60, 61, 63, 64, 67, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 117, 118, 119, 120, 123, 126, 127, 128, 129, 132, 133, 134, 135, 142, 143, 145, 146, 147, 148, 151, 153, 156, 157, 158, 159, 160, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 228, 231, 263, 265, 270, 295, 296, 303, 311, 312, 323, 324, 325, 326, 328, 329, 330, 335, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 396, 406, 629, 642, 643], "dataload": [2, 48, 104, 106, 168, 169, 170, 173, 176, 183, 192, 622, 629, 640], "except": [2, 17, 21, 34, 35, 37, 40, 41, 42, 44, 47, 48, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 80, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 233, 253, 262, 263, 264, 268, 270, 284, 299, 300, 302, 308, 310, 323, 324, 325, 326, 328, 329, 330, 335, 345, 348, 362, 364, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 388, 593, 621, 622, 626, 634, 636, 640, 642, 643], "1": [2, 4, 6, 7, 8, 10, 18, 19, 21, 22, 23, 27, 29, 34, 35, 37, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 92, 93, 94, 98, 99, 105, 106, 111, 113, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 133, 134, 135, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 204, 210, 212, 213, 215, 216, 217, 218, 219, 220, 222, 223, 224, 225, 227, 228, 229, 230, 231, 232, 235, 237, 239, 240, 242, 244, 246, 248, 249, 250, 251, 253, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 271, 273, 275, 277, 278, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 296, 298, 299, 300, 301, 302, 303, 304, 305, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 357, 360, 361, 363, 364, 365, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 388, 396, 398, 400, 404, 406, 407, 415, 416, 418, 419, 420, 422, 424, 437, 443, 461, 462, 465, 467, 469, 470, 474, 479, 500, 503, 513, 522, 537, 542, 547, 557, 561, 562, 564, 567, 569, 572, 573, 575, 576, 577, 579, 581, 582, 583, 585, 586, 587, 588, 592, 593, 614, 620, 621, 622, 623, 624, 625, 627, 628, 629, 631, 635, 636, 637, 638, 639, 640, 641, 642, 643], "over": [2, 7, 18, 20, 21, 22, 23, 27, 34, 35, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 98, 99, 104, 105, 106, 117, 120, 123, 127, 135, 139, 140, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 212, 229, 244, 256, 264, 278, 304, 308, 315, 318, 324, 330, 335, 343, 355, 357, 362, 373, 375, 378, 379, 381, 386, 406, 550, 621, 622, 623, 625, 626, 627, 628, 629, 636, 637, 638, 643], "non": [2, 6, 12, 17, 22, 27, 34, 35, 37, 40, 41, 42, 44, 46, 49, 51, 53, 54, 56, 58, 62, 64, 71, 72, 73, 74, 80, 83, 84, 85, 93, 95, 117, 120, 123, 127, 135, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 216, 217, 219, 223, 234, 248, 260, 263, 269, 270, 271, 272, 273, 275, 278, 285, 300, 302, 305, 323, 324, 325, 326, 328, 329, 330, 335, 340, 341, 345, 346, 348, 349, 350, 352, 353, 354, 355, 356, 357, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 562, 564, 570, 572, 576, 578, 579, 584, 585, 586, 587, 621, 624, 625, 636, 637, 638, 640, 643], "static": [2, 56, 58, 99, 105, 106, 129, 148, 172, 178, 277, 280, 324, 330, 335, 360, 373, 375, 379, 626, 638, 640], "like": [2, 4, 6, 7, 17, 19, 21, 22, 23, 26, 30, 43, 46, 56, 58, 62, 64, 67, 68, 69, 70, 83, 84, 85, 87, 95, 106, 117, 120, 123, 124, 127, 129, 135, 138, 147, 148, 149, 150, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 231, 263, 266, 323, 324, 325, 326, 327, 328, 329, 330, 335, 341, 345, 347, 361, 364, 365, 366, 372, 373, 374, 375, 376, 377, 378, 379, 380, 397, 562, 564, 576, 614, 621, 623, 624, 625, 626, 627, 628, 629, 630, 631, 636, 637, 638, 639, 640, 642, 643], "being": [2, 3, 17, 18, 21, 22, 26, 27, 34, 35, 37, 39, 40, 41, 42, 44, 45, 46, 83, 84, 85, 93, 95, 98, 99, 111, 114, 117, 120, 123, 126, 127, 128, 129, 134, 135, 147, 148, 151, 153, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 208, 218, 227, 229, 230, 237, 243, 251, 263, 268, 269, 270, 299, 300, 302, 310, 323, 324, 325, 326, 328, 329, 330, 335, 347, 348, 361, 362, 364, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 388, 406, 413, 559, 560, 561, 563, 565, 566, 568, 571, 574, 576, 580, 582, 588, 614, 621, 622, 623, 624, 629, 636, 637, 638, 640], "torchrl": [2, 3, 5, 6, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 593, 614, 620, 624, 626, 628, 629, 630, 631, 632, 635, 639, 640, 641], "accept": [2, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 67, 72, 77, 78, 81, 82, 83, 84, 85, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 214, 219, 223, 234, 237, 248, 256, 260, 263, 268, 269, 270, 271, 272, 273, 275, 303, 323, 324, 325, 326, 328, 329, 330, 335, 340, 341, 342, 348, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 388, 614, 623, 626, 630, 640, 642, 643], "two": [2, 6, 7, 18, 22, 23, 27, 29, 59, 60, 61, 64, 67, 68, 69, 70, 80, 83, 84, 85, 104, 105, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 224, 244, 248, 268, 275, 291, 300, 302, 315, 318, 323, 324, 325, 326, 328, 329, 330, 335, 341, 361, 364, 368, 372, 373, 374, 375, 376, 377, 378, 379, 380, 404, 410, 593, 621, 622, 623, 624, 625, 626, 627, 629, 630, 634, 635, 636, 637, 638, 640, 642, 643], "main": [2, 6, 7, 19, 24, 34, 35, 39, 44, 47, 52, 65, 82, 124, 168, 191, 219, 224, 322, 341, 410, 563, 564, 565, 566, 568, 570, 571, 574, 576, 578, 580, 582, 584, 586, 588, 593, 621, 622, 633, 634, 635, 642, 643], "argument": [2, 3, 18, 19, 20, 21, 22, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 90, 92, 93, 94, 95, 98, 99, 103, 104, 105, 106, 109, 111, 113, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 139, 140, 142, 143, 145, 146, 147, 148, 149, 151, 153, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 200, 204, 210, 212, 213, 215, 216, 218, 219, 220, 222, 223, 224, 225, 228, 231, 232, 233, 235, 237, 238, 239, 241, 242, 247, 248, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 280, 284, 285, 286, 295, 296, 299, 300, 302, 303, 304, 310, 311, 312, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 337, 338, 339, 340, 341, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 393, 395, 396, 397, 398, 402, 410, 414, 415, 550, 557, 558, 561, 614, 621, 622, 623, 624, 625, 626, 627, 629, 636, 637, 638, 640, 642, 643], "list": [2, 21, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 93, 95, 103, 104, 105, 106, 107, 109, 117, 120, 121, 122, 123, 126, 127, 128, 129, 135, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 162, 164, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 202, 203, 210, 217, 218, 222, 223, 227, 228, 230, 239, 240, 244, 246, 248, 256, 258, 266, 267, 268, 269, 270, 272, 273, 275, 277, 285, 286, 288, 294, 296, 298, 300, 302, 303, 304, 306, 311, 312, 320, 322, 323, 324, 325, 326, 328, 329, 330, 332, 335, 338, 341, 343, 344, 346, 348, 360, 362, 365, 367, 368, 369, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 384, 386, 387, 396, 397, 398, 404, 406, 425, 433, 434, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 473, 475, 476, 477, 478, 479, 480, 481, 482, 485, 486, 487, 488, 489, 491, 492, 493, 494, 495, 496, 497, 498, 499, 501, 503, 504, 505, 506, 507, 510, 511, 512, 513, 514, 515, 516, 517, 518, 520, 521, 522, 523, 524, 525, 528, 529, 530, 531, 532, 533, 534, 535, 559, 560, 563, 568, 572, 579, 580, 582, 585, 587, 588, 614, 621, 623, 626, 627, 628, 629, 633, 634, 635, 636, 638, 639, 640, 642, 643], "constructor": [2, 17, 21, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 65, 67, 69, 70, 80, 83, 84, 98, 111, 117, 120, 123, 127, 135, 142, 147, 148, 151, 156, 157, 158, 161, 168, 169, 170, 173, 174, 175, 176, 177, 178, 193, 194, 215, 219, 268, 286, 303, 322, 323, 324, 325, 326, 328, 329, 330, 335, 339, 341, 345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 379, 380, 381, 382, 383, 384, 385, 396, 397, 414, 558, 561, 593, 614, 621, 622, 623, 626, 629, 636, 637, 640, 642], "iter": [2, 5, 6, 18, 20, 35, 37, 46, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 95, 104, 117, 118, 119, 120, 123, 127, 133, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 232, 244, 257, 280, 285, 286, 295, 303, 311, 320, 322, 323, 324, 325, 326, 328, 329, 330, 335, 337, 339, 340, 342, 343, 362, 372, 373, 374, 375, 376, 377, 378, 379, 380, 404, 406, 408, 410, 621, 623, 624, 629, 631, 636, 637, 638], "queri": [2, 18, 34, 83, 84, 85, 93, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 201, 248, 273, 277, 323, 324, 325, 326, 328, 329, 330, 335, 343, 372, 373, 374, 375, 376, 377, 378, 379, 380, 621, 628, 633, 638, 642], "defin": [2, 6, 7, 14, 21, 34, 35, 37, 39, 40, 48, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 249, 262, 280, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 303, 305, 306, 307, 309, 310, 312, 313, 314, 323, 324, 325, 326, 328, 329, 330, 335, 336, 338, 344, 350, 352, 362, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 409, 470, 558, 614, 621, 622, 624, 628, 631, 638, 640, 643], "number": [2, 16, 17, 18, 19, 27, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 93, 94, 95, 98, 99, 103, 105, 106, 113, 117, 118, 119, 120, 123, 126, 127, 128, 133, 134, 135, 141, 142, 143, 144, 147, 148, 149, 150, 151, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 229, 231, 232, 233, 235, 238, 239, 241, 243, 244, 247, 249, 250, 251, 253, 255, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 273, 274, 276, 277, 284, 286, 293, 297, 298, 299, 300, 301, 302, 303, 305, 306, 307, 310, 313, 314, 317, 318, 319, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 393, 395, 396, 400, 402, 404, 410, 412, 413, 414, 415, 470, 550, 551, 559, 560, 561, 581, 582, 583, 588, 593, 621, 622, 623, 624, 626, 627, 629, 631, 636, 637, 638, 639, 640, 643], "befor": [2, 4, 17, 21, 22, 23, 25, 26, 29, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 55, 57, 59, 60, 79, 85, 104, 106, 111, 117, 120, 123, 127, 128, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 216, 217, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 230, 231, 232, 234, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 250, 251, 252, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 276, 277, 278, 300, 302, 303, 322, 324, 330, 335, 345, 346, 347, 348, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 382, 383, 384, 406, 572, 575, 576, 579, 581, 585, 586, 587, 588, 593, 614, 621, 623, 624, 625, 629, 630, 636, 637, 638, 640, 643], "deliv": [2, 18, 37, 80, 183, 621, 622, 626, 629, 642], "stack": [2, 4, 17, 18, 19, 22, 26, 27, 34, 35, 37, 41, 44, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 71, 72, 73, 74, 83, 84, 93, 98, 117, 120, 123, 126, 127, 128, 135, 138, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 183, 184, 193, 194, 202, 203, 219, 224, 242, 277, 300, 302, 315, 323, 325, 326, 328, 329, 338, 342, 343, 346, 348, 360, 365, 367, 368, 369, 372, 374, 376, 377, 380, 381, 387, 400, 423, 518, 593, 622, 625, 626, 633, 634, 635, 636, 638, 642], "user": [2, 6, 12, 18, 20, 21, 22, 24, 27, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 52, 75, 76, 80, 82, 84, 85, 86, 99, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 159, 163, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 220, 237, 262, 268, 270, 292, 324, 330, 335, 348, 364, 367, 368, 373, 375, 378, 379, 388, 558, 578, 579, 593, 621, 622, 626, 628, 629, 634, 638, 642, 643], "reach": [2, 18, 34, 35, 37, 40, 41, 42, 44, 46, 47, 48, 104, 117, 120, 123, 127, 134, 135, 139, 140, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 173, 176, 177, 178, 242, 261, 284, 299, 310, 621, 623, 631, 633, 636, 637, 642, 643], "done": [2, 17, 18, 19, 21, 22, 23, 26, 27, 32, 34, 35, 37, 40, 41, 42, 44, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 89, 90, 97, 99, 105, 106, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 211, 212, 213, 215, 216, 219, 227, 228, 230, 231, 232, 237, 241, 242, 243, 244, 246, 250, 251, 253, 255, 257, 260, 261, 263, 264, 267, 268, 269, 270, 271, 277, 300, 302, 318, 327, 338, 345, 346, 347, 348, 349, 350, 352, 353, 354, 360, 361, 364, 365, 366, 367, 368, 369, 375, 378, 379, 381, 382, 383, 384, 385, 403, 490, 593, 614, 621, 623, 624, 625, 626, 628, 629, 631, 634, 635, 636, 637, 638, 640, 642, 643], "state": [2, 6, 17, 18, 21, 22, 23, 34, 35, 37, 38, 39, 40, 48, 49, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 97, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 133, 134, 135, 141, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 211, 215, 218, 219, 220, 222, 223, 225, 228, 231, 234, 237, 241, 242, 244, 251, 261, 262, 267, 268, 269, 270, 271, 272, 277, 278, 281, 287, 292, 297, 300, 302, 303, 306, 309, 313, 314, 315, 321, 323, 324, 325, 326, 327, 328, 329, 330, 335, 338, 340, 345, 347, 348, 352, 354, 361, 362, 364, 365, 366, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 396, 403, 410, 412, 414, 415, 470, 561, 593, 602, 607, 615, 621, 622, 623, 624, 625, 626, 627, 628, 629, 633, 634, 636, 637, 638, 643], "after": [2, 4, 19, 20, 22, 27, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 65, 68, 75, 83, 84, 85, 94, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 131, 132, 133, 134, 135, 142, 143, 145, 146, 147, 148, 151, 153, 156, 157, 158, 159, 160, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 212, 213, 215, 216, 217, 219, 220, 221, 222, 223, 226, 227, 228, 229, 231, 232, 234, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 250, 251, 252, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 277, 278, 284, 295, 299, 300, 302, 311, 323, 324, 325, 326, 328, 329, 330, 335, 348, 357, 367, 368, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 396, 397, 562, 563, 564, 567, 568, 569, 572, 573, 579, 580, 582, 585, 587, 588, 593, 614, 622, 623, 624, 625, 626, 627, 629, 631, 633, 636, 637, 638, 639, 640, 643], "predefin": [2, 7, 181, 388, 622, 624, 629, 640, 642], "becaus": [2, 18, 21, 22, 23, 26, 49, 56, 58, 75, 83, 84, 85, 93, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 231, 239, 261, 276, 291, 295, 296, 311, 312, 323, 324, 325, 326, 328, 329, 330, 335, 337, 338, 339, 340, 341, 345, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 562, 567, 573, 621, 622, 624, 625, 627, 628, 629, 633, 635, 636, 637, 638, 640, 643], "potenti": [2, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 98, 99, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 175, 176, 177, 178, 638, 640], "comput": [2, 6, 17, 18, 21, 22, 23, 27, 34, 36, 37, 46, 48, 55, 83, 84, 85, 98, 117, 118, 119, 120, 123, 127, 133, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 211, 241, 244, 258, 270, 274, 278, 281, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 315, 318, 319, 323, 324, 325, 326, 327, 328, 329, 330, 335, 336, 338, 339, 341, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 403, 414, 415, 470, 551, 574, 593, 596, 607, 614, 621, 623, 624, 625, 626, 627, 633, 634, 635, 636, 637, 639, 640], "heavi": [2, 6, 27, 75, 614, 640], "crucial": [2, 6, 20, 83, 84, 174, 284, 299, 310, 323, 325, 326, 328, 329, 353, 360, 362, 372, 374, 375, 376, 377, 380, 415, 593, 621, 622, 623, 624, 626, 628, 630, 636, 637, 638, 642, 643], "hyperparamet": [2, 103, 345, 346, 348, 349, 350, 352, 353, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 373, 375, 379, 591, 621, 630, 638, 640], "appropri": [2, 7, 17, 23, 26, 84, 91, 101, 111, 112, 115, 116, 135, 147, 156, 177, 178, 231, 558, 561, 593, 614, 621, 630, 640], "paramet": [2, 6, 7, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 92, 93, 94, 95, 98, 99, 100, 101, 103, 104, 107, 109, 111, 113, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 156, 157, 158, 159, 160, 161, 162, 163, 164, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 199, 200, 202, 203, 204, 208, 209, 210, 211, 212, 213, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 458, 468, 470, 550, 551, 552, 553, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 568, 570, 571, 572, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 607, 614, 621, 624, 625, 627, 631, 636, 637, 638, 639, 642], "take": [2, 17, 20, 21, 22, 27, 39, 52, 77, 83, 84, 87, 108, 114, 117, 118, 119, 120, 123, 127, 133, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 175, 176, 177, 178, 181, 222, 224, 261, 264, 265, 269, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 312, 313, 314, 323, 325, 326, 328, 329, 336, 338, 339, 341, 344, 364, 372, 374, 376, 377, 380, 388, 400, 413, 593, 621, 622, 623, 625, 626, 627, 628, 636, 637, 638, 640, 643], "consider": [2, 21, 22, 27, 126, 128, 269, 322, 591, 593, 622, 636, 637, 640], "whether": [2, 18, 22, 34, 35, 36, 37, 40, 41, 42, 44, 46, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 94, 101, 113, 117, 120, 123, 127, 134, 135, 139, 140, 141, 147, 148, 149, 150, 151, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 211, 215, 224, 225, 227, 230, 241, 262, 268, 270, 277, 278, 286, 300, 302, 303, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 338, 341, 345, 346, 347, 348, 349, 350, 352, 354, 355, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 399, 410, 414, 415, 470, 561, 563, 575, 576, 614, 621, 622, 623, 625, 626, 636, 637, 638, 642, 643], "should": [2, 5, 6, 7, 17, 18, 20, 21, 22, 23, 24, 26, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 92, 95, 99, 105, 106, 107, 111, 114, 117, 120, 121, 122, 123, 126, 127, 128, 129, 134, 135, 138, 141, 147, 148, 149, 150, 151, 156, 157, 158, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 211, 212, 215, 216, 219, 222, 223, 224, 227, 228, 231, 232, 234, 239, 240, 242, 244, 249, 250, 251, 253, 256, 257, 261, 262, 264, 267, 269, 270, 271, 276, 277, 278, 280, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 303, 305, 306, 307, 309, 310, 312, 313, 314, 322, 323, 324, 325, 326, 328, 329, 330, 335, 336, 338, 339, 340, 341, 344, 345, 347, 348, 354, 361, 362, 364, 365, 366, 367, 368, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 388, 390, 399, 404, 405, 406, 410, 557, 559, 560, 561, 564, 578, 579, 581, 588, 614, 621, 622, 623, 624, 625, 627, 629, 630, 633, 635, 636, 637, 638, 639, 640, 642, 643], "occur": [2, 27, 35, 75, 117, 120, 123, 127, 129, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 211, 220, 232, 244, 249, 276, 295, 296, 311, 312, 324, 330, 335, 337, 339, 340, 341, 357, 373, 375, 379, 593, 625, 640, 643], "serial": [2, 15, 18, 22, 34, 35, 37, 40, 41, 42, 44, 46, 48, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 268, 277, 278, 324, 330, 335, 373, 375, 378, 379], "split": [2, 6, 34, 35, 37, 40, 41, 42, 44, 46, 56, 58, 75, 76, 77, 78, 79, 80, 81, 82, 99, 105, 106, 138, 149, 150, 169, 305, 345, 346, 347, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 373, 375, 379, 623, 627, 640, 642], "workload": [2, 322], "result": [2, 3, 7, 17, 18, 20, 21, 22, 26, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 52, 54, 64, 65, 66, 67, 68, 69, 70, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 99, 104, 105, 106, 117, 120, 123, 124, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 199, 200, 201, 210, 211, 212, 215, 216, 217, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 231, 232, 234, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 250, 251, 252, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 277, 278, 284, 296, 299, 300, 302, 303, 312, 318, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 335, 345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 387, 396, 412, 413, 593, 614, 622, 624, 626, 627, 630, 631, 634, 638, 639, 642, 643], "final": [2, 7, 21, 22, 23, 46, 83, 84, 170, 173, 174, 175, 181, 263, 276, 284, 299, 300, 302, 310, 322, 323, 325, 326, 328, 329, 331, 332, 342, 372, 374, 376, 377, 380, 381, 404, 621, 622, 623, 625, 630, 631, 633, 636, 637, 638, 643], "continu": [2, 21, 28, 54, 56, 72, 73, 84, 106, 117, 120, 123, 127, 135, 147, 148, 149, 150, 151, 156, 157, 158, 161, 162, 168, 169, 170, 173, 176, 177, 178, 204, 212, 237, 263, 271, 288, 289, 290, 291, 310, 324, 343, 346, 381, 415, 564, 621, 623, 624, 627, 636, 637, 640], "concomitantli": [2, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 176, 177, 178], "network": [2, 6, 23, 27, 78, 85, 117, 120, 123, 127, 135, 138, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 281, 282, 283, 286, 288, 289, 290, 291, 294, 297, 298, 303, 306, 307, 313, 314, 315, 324, 330, 335, 340, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 381, 382, 383, 384, 385, 409, 415, 461, 463, 464, 465, 467, 470, 556, 557, 591, 600, 606, 625, 628, 631, 635, 638, 643], "impli": [2, 643], "mai": [2, 3, 5, 17, 18, 19, 21, 22, 23, 24, 26, 27, 34, 35, 37, 40, 41, 42, 44, 46, 48, 50, 52, 56, 58, 71, 76, 82, 83, 84, 85, 90, 93, 98, 99, 105, 117, 120, 123, 126, 127, 128, 129, 135, 147, 148, 151, 153, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 239, 244, 257, 268, 270, 272, 277, 278, 300, 302, 303, 323, 324, 325, 326, 328, 329, 330, 335, 341, 347, 354, 361, 364, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 414, 415, 593, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 636, 637, 638, 639, 640, 643], "slightli": [2, 52, 75, 83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 624, 625, 636, 638, 639, 640, 643], "lag": [2, 621, 622, 623], "therefor": [2, 19, 21, 22, 26, 64, 67, 69, 70, 81, 82, 83, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 181, 253, 323, 325, 326, 328, 329, 364, 372, 374, 376, 377, 378, 380, 625, 628, 636, 643], "fastest": 2, "price": 2, "suitabl": [2, 219, 375], "off": [2, 10, 12, 23, 295, 301, 319, 367, 386, 404, 412, 415, 552, 621, 622, 623, 627, 628, 636, 637, 639, 642, 643], "curriculum": [2, 23], "remot": [2, 6, 10, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 147, 156, 174, 187, 192, 193, 278, 323, 325, 326, 327, 328, 329, 335, 372, 374, 376, 377, 380, 396, 397, 562, 567, 568, 572, 573, 574, 581, 586, 587, 588, 614, 643], "rollout": [2, 16, 17, 18, 20, 22, 30, 34, 35, 37, 40, 46, 48, 49, 52, 111, 117, 118, 119, 120, 123, 127, 129, 130, 133, 134, 135, 139, 140, 141, 142, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 161, 162, 163, 168, 169, 170, 173, 176, 177, 178, 183, 212, 213, 215, 216, 219, 222, 224, 225, 227, 230, 231, 232, 237, 239, 240, 246, 250, 251, 256, 257, 258, 261, 262, 264, 265, 268, 271, 277, 278, 285, 300, 302, 310, 315, 338, 345, 386, 388, 551, 607, 621, 623, 624, 627, 628, 629, 630, 631, 639, 640, 642], "necessari": [2, 6, 23, 25, 27, 34, 35, 37, 40, 41, 42, 44, 46, 75, 77, 78, 80, 81, 82, 117, 120, 123, 127, 135, 139, 140, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 173, 176, 177, 178, 257, 365, 381, 382, 383, 384, 385, 621, 623, 627, 628, 629, 633, 634], "synchronis": [2, 124, 636, 637], "either": [2, 24, 47, 51, 53, 64, 65, 67, 68, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 241, 242, 261, 262, 278, 321, 324, 330, 332, 335, 362, 368, 369, 373, 375, 378, 379, 392, 571, 580, 593, 601, 621, 622, 624, 636, 639, 640, 642, 643], "update_at_each_batch": [2, 34, 35, 40], "true": [2, 6, 7, 9, 18, 21, 22, 23, 27, 30, 31, 32, 34, 35, 37, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 92, 93, 94, 95, 98, 99, 101, 103, 104, 105, 106, 113, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 139, 140, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 210, 211, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 229, 232, 234, 237, 238, 239, 240, 242, 243, 244, 248, 249, 251, 252, 255, 256, 257, 260, 261, 263, 266, 267, 268, 269, 270, 271, 272, 273, 275, 277, 278, 280, 281, 282, 283, 284, 286, 288, 289, 290, 291, 295, 296, 298, 300, 302, 303, 304, 310, 311, 312, 317, 318, 319, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 388, 395, 396, 399, 402, 403, 404, 406, 410, 412, 414, 415, 416, 418, 419, 420, 430, 431, 432, 439, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 461, 462, 465, 469, 470, 472, 500, 502, 519, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 561, 562, 563, 570, 575, 576, 578, 583, 584, 586, 593, 614, 621, 622, 623, 624, 625, 627, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "second": [2, 22, 27, 34, 35, 37, 40, 48, 52, 59, 60, 61, 75, 77, 111, 147, 182, 188, 190, 195, 216, 265, 296, 300, 302, 322, 347, 361, 364, 367, 388, 390, 393, 395, 408, 564, 570, 578, 584, 586, 614, 621, 623, 629, 636, 637, 638, 640, 642, 643], "oper": [2, 3, 17, 21, 22, 23, 26, 27, 34, 35, 37, 40, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 85, 93, 94, 99, 105, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 234, 239, 265, 267, 271, 278, 281, 282, 283, 294, 295, 296, 321, 323, 324, 325, 326, 327, 328, 329, 330, 335, 340, 345, 347, 349, 350, 355, 361, 364, 366, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 396, 397, 410, 565, 581, 582, 583, 586, 593, 595, 607, 621, 622, 623, 624, 625, 626, 627, 635, 636, 637, 638, 643], "instanc": [2, 6, 7, 17, 20, 21, 22, 23, 26, 27, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 54, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 92, 93, 94, 97, 99, 105, 106, 113, 117, 120, 122, 123, 124, 126, 127, 128, 132, 135, 141, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 211, 244, 263, 270, 277, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 311, 312, 313, 314, 322, 323, 324, 325, 326, 327, 328, 329, 330, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 344, 346, 348, 350, 353, 354, 360, 362, 365, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 388, 392, 398, 399, 404, 412, 413, 463, 551, 552, 553, 557, 559, 560, 563, 565, 566, 568, 569, 571, 572, 574, 576, 580, 582, 588, 593, 614, 621, 623, 624, 625, 626, 627, 633, 638, 640, 643], "cpu": [2, 3, 18, 22, 27, 29, 34, 35, 37, 40, 46, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 93, 94, 98, 105, 113, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 133, 134, 135, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 210, 212, 216, 223, 227, 228, 230, 231, 232, 237, 240, 241, 246, 248, 250, 251, 253, 257, 260, 261, 263, 269, 270, 271, 273, 275, 281, 282, 283, 285, 294, 295, 296, 300, 302, 310, 311, 312, 320, 323, 324, 325, 326, 327, 328, 329, 330, 335, 337, 338, 339, 340, 343, 345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 386, 396, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 487, 506, 530, 531, 532, 614, 621, 622, 623, 624, 636, 637, 638, 639, 642], "slower": [2, 3, 8, 9, 636], "than": [2, 3, 22, 23, 27, 32, 34, 35, 37, 40, 41, 42, 43, 44, 46, 48, 49, 53, 64, 67, 68, 69, 70, 75, 76, 80, 83, 84, 85, 99, 105, 106, 109, 111, 117, 120, 123, 127, 131, 135, 145, 146, 147, 148, 151, 153, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 183, 187, 193, 224, 240, 242, 251, 278, 284, 291, 295, 300, 302, 303, 305, 320, 323, 325, 326, 328, 329, 330, 337, 340, 341, 362, 372, 373, 374, 375, 376, 377, 378, 379, 380, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 411, 413, 569, 572, 582, 592, 593, 614, 621, 622, 623, 624, 625, 626, 628, 636, 637, 638, 640, 642, 643], "one": [2, 3, 6, 7, 17, 18, 20, 21, 22, 23, 24, 26, 27, 32, 34, 35, 37, 40, 41, 42, 44, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 80, 83, 84, 85, 89, 90, 91, 92, 97, 98, 99, 101, 105, 106, 107, 109, 111, 112, 115, 116, 117, 118, 119, 120, 123, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 216, 219, 222, 224, 225, 227, 228, 229, 230, 237, 240, 241, 243, 244, 248, 253, 256, 259, 260, 262, 263, 264, 269, 270, 272, 275, 277, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294, 295, 296, 297, 298, 299, 300, 302, 303, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 320, 322, 323, 324, 325, 326, 328, 329, 330, 335, 336, 337, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 388, 390, 398, 402, 404, 405, 410, 551, 561, 572, 576, 588, 592, 593, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 635, 636, 637, 638, 639, 640, 643], "cuda": [2, 3, 21, 22, 26, 34, 35, 37, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 85, 117, 118, 119, 120, 123, 127, 129, 130, 131, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 239, 247, 248, 263, 269, 270, 273, 275, 324, 330, 331, 335, 340, 373, 375, 378, 379, 401, 581, 621, 622, 623, 624, 636, 637, 639, 643], "dispatch": [2, 22, 41, 42, 44, 46, 85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 324, 330, 335, 338, 373, 375, 378, 379, 388, 621, 643], "speed": [2, 5, 22, 23, 27, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 98, 99, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 614, 621, 622, 623, 624, 636, 637, 638, 640, 642], "avoid": [2, 7, 17, 20, 78, 85, 92, 94, 105, 113, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 209, 219, 237, 268, 270, 277, 278, 318, 320, 324, 330, 335, 337, 340, 347, 348, 361, 364, 367, 373, 375, 378, 379, 550, 576, 593, 614, 623, 625, 634, 637], "oom": [2, 20, 83, 84, 92, 94, 113, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "choic": [2, 15, 62, 76, 82, 83, 84, 147, 174, 183, 305, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 414, 621, 622, 628, 636, 637], "pass": [2, 4, 5, 9, 12, 17, 18, 19, 20, 21, 22, 23, 32, 34, 35, 37, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 53, 56, 58, 62, 64, 65, 67, 68, 69, 70, 71, 75, 77, 78, 80, 81, 82, 83, 84, 85, 90, 92, 94, 99, 105, 106, 111, 113, 117, 120, 123, 124, 125, 127, 128, 135, 138, 142, 147, 148, 149, 150, 151, 156, 157, 158, 161, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 213, 215, 216, 219, 223, 225, 227, 230, 240, 242, 250, 251, 268, 269, 272, 277, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294, 295, 296, 297, 298, 299, 300, 302, 303, 305, 306, 307, 309, 310, 311, 312, 313, 314, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 338, 339, 340, 341, 343, 344, 346, 347, 348, 360, 361, 362, 364, 365, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 396, 397, 398, 406, 410, 414, 415, 559, 560, 561, 562, 567, 573, 575, 576, 593, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 635, 636, 637, 638, 640, 642, 643], "ie": [2, 17, 41, 44, 47, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 69, 71, 72, 73, 74, 80, 98, 106, 117, 120, 123, 127, 131, 135, 144, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 211, 212, 219, 234, 260, 263, 272, 277, 300, 302, 324, 330, 335, 340, 373, 375, 379, 622, 637], "while": [2, 6, 7, 17, 21, 22, 26, 27, 34, 35, 37, 40, 48, 52, 65, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 253, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 312, 313, 314, 323, 324, 325, 326, 327, 328, 329, 330, 335, 336, 338, 344, 347, 353, 354, 360, 361, 364, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 593, 614, 621, 623, 624, 627, 629, 630, 636, 637, 638, 639, 640, 642], "wait": [2, 32, 34, 35, 40, 41, 42, 43, 44, 46, 47, 65, 92, 94, 159, 181, 322, 562, 564, 567, 569, 570, 572, 573, 578, 579, 581, 584, 585, 586, 587, 588, 624, 638], "impact": [2, 18, 32, 41, 42, 44, 80, 134, 227, 230, 330, 345, 347, 361, 364, 366, 375, 622, 624, 636, 637], "memori": [2, 3, 4, 6, 9, 10, 12, 18, 21, 27, 34, 35, 40, 46, 51, 55, 65, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 87, 88, 90, 92, 93, 97, 117, 118, 119, 120, 123, 124, 127, 131, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 219, 223, 248, 263, 269, 270, 273, 275, 277, 278, 293, 323, 324, 325, 326, 328, 329, 330, 335, 340, 372, 373, 374, 375, 376, 377, 378, 379, 380, 396, 422, 561, 570, 575, 576, 578, 582, 583, 584, 586, 593, 614, 621, 622, 624, 636, 640, 642], "which": [2, 3, 5, 6, 7, 10, 17, 18, 19, 21, 22, 23, 26, 27, 33, 34, 35, 37, 39, 40, 41, 42, 44, 46, 48, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 89, 93, 103, 104, 111, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 131, 133, 134, 135, 139, 140, 142, 143, 145, 146, 147, 148, 151, 153, 156, 157, 158, 159, 160, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 203, 219, 220, 224, 227, 230, 235, 237, 239, 240, 243, 244, 248, 249, 251, 261, 263, 264, 267, 268, 269, 270, 271, 273, 277, 280, 281, 282, 283, 294, 300, 301, 302, 304, 315, 319, 322, 323, 324, 325, 326, 328, 329, 330, 335, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 350, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 388, 396, 400, 405, 414, 571, 572, 579, 585, 587, 593, 595, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 633, 635, 636, 637, 638, 639, 640, 643], "storing_devic": [2, 34, 35, 37, 40, 41, 42, 44, 46, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 416, 418, 419, 420, 622, 624, 637], "dure": [2, 10, 18, 20, 21, 22, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 53, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 90, 92, 94, 95, 98, 99, 103, 105, 117, 120, 123, 124, 127, 134, 135, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 180, 183, 189, 196, 197, 215, 216, 219, 222, 227, 230, 232, 234, 235, 237, 242, 246, 258, 260, 263, 265, 267, 268, 270, 271, 272, 277, 278, 285, 300, 302, 322, 330, 338, 347, 364, 375, 379, 381, 383, 384, 404, 410, 412, 415, 575, 585, 586, 589, 593, 604, 621, 622, 623, 624, 627, 628, 629, 631, 636, 637, 638, 640, 643], "heurist": [2, 23, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 174, 284, 323, 325, 326, 328, 329, 338, 341, 372, 374, 376, 377, 380, 621, 625, 629, 643], "usual": [2, 17, 18, 21, 23, 25, 26, 27, 34, 35, 37, 40, 41, 42, 44, 46, 76, 103, 111, 117, 118, 119, 120, 123, 127, 133, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 268, 364, 368, 375, 379, 381, 382, 383, 384, 385, 387, 592, 593, 595, 621, 622, 623, 624, 627, 629, 630, 637, 640, 643], "same": [2, 4, 6, 7, 18, 19, 21, 22, 23, 37, 39, 41, 42, 44, 46, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 76, 80, 83, 84, 85, 104, 105, 106, 109, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 133, 134, 135, 138, 142, 143, 147, 148, 149, 150, 151, 153, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 219, 227, 229, 230, 235, 237, 240, 242, 243, 244, 260, 268, 269, 270, 277, 280, 286, 303, 304, 310, 318, 322, 323, 324, 325, 326, 328, 329, 330, 335, 344, 346, 348, 360, 362, 365, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 396, 414, 562, 563, 567, 568, 572, 573, 574, 579, 582, 583, 585, 587, 588, 589, 593, 614, 621, 622, 623, 626, 627, 629, 633, 634, 635, 636, 637, 639, 640, 643], "default": [2, 3, 7, 17, 19, 21, 22, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 90, 92, 93, 94, 95, 98, 99, 101, 103, 104, 105, 106, 111, 113, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 132, 133, 134, 135, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 203, 204, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 253, 255, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 280, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 310, 311, 312, 313, 314, 317, 318, 319, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 393, 394, 395, 396, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 413, 414, 415, 461, 470, 557, 561, 562, 564, 571, 572, 575, 576, 579, 582, 585, 587, 588, 621, 622, 623, 624, 627, 636, 639, 640, 642, 643], "behavior": [2, 18, 21, 22, 23, 34, 35, 46, 71, 80, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 220, 227, 230, 244, 249, 262, 270, 278, 300, 301, 302, 319, 322, 323, 324, 325, 326, 328, 329, 330, 335, 347, 353, 360, 364, 368, 372, 373, 374, 375, 376, 377, 378, 379, 380, 386, 399, 404, 576, 614, 622, 624, 636, 637, 638, 640], "besid": 2, "those": [2, 22, 24, 26, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 99, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 197, 219, 224, 227, 230, 237, 244, 263, 264, 267, 271, 302, 339, 341, 342, 343, 413, 559, 560, 572, 579, 585, 587, 621, 622, 626, 627, 637, 638, 643], "follow": [2, 4, 9, 17, 18, 19, 21, 22, 25, 26, 27, 30, 39, 71, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 99, 105, 106, 117, 118, 119, 120, 123, 126, 127, 128, 133, 134, 135, 141, 144, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 207, 215, 219, 239, 248, 273, 277, 278, 286, 296, 300, 302, 303, 311, 312, 322, 323, 324, 325, 326, 328, 329, 330, 335, 339, 345, 346, 347, 348, 349, 353, 354, 360, 361, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 388, 410, 562, 563, 567, 568, 573, 574, 581, 593, 607, 621, 622, 623, 624, 625, 628, 629, 635, 636, 637, 638, 640, 642, 643], "max_frames_per_traj": [2, 34, 35, 37, 40, 41, 42, 44, 46, 416, 418, 419, 420, 550, 621, 623, 642], "frame": [2, 30, 34, 35, 37, 40, 41, 42, 44, 46, 48, 75, 87, 219, 235, 284, 299, 310, 338, 387, 388, 390, 393, 395, 402, 404, 410, 414, 415, 470, 550, 551, 621, 622, 623, 624, 627, 636, 637, 640, 642, 643], "call": [2, 6, 7, 8, 17, 18, 20, 21, 22, 26, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 93, 94, 95, 99, 100, 104, 105, 107, 109, 113, 114, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 132, 133, 134, 135, 142, 143, 144, 145, 146, 147, 148, 151, 153, 156, 157, 158, 159, 160, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 201, 208, 211, 212, 213, 215, 216, 218, 219, 220, 222, 223, 224, 225, 228, 229, 231, 232, 233, 234, 235, 237, 238, 239, 241, 242, 244, 246, 247, 248, 249, 250, 251, 253, 256, 257, 258, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 280, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 302, 303, 305, 306, 307, 309, 310, 312, 313, 314, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 336, 338, 340, 341, 343, 344, 346, 347, 348, 354, 360, 361, 362, 364, 365, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 390, 396, 397, 404, 406, 563, 565, 566, 567, 568, 569, 570, 571, 572, 574, 576, 578, 579, 580, 581, 582, 584, 585, 586, 587, 588, 593, 595, 614, 622, 623, 624, 625, 626, 627, 629, 630, 636, 637, 638, 640, 642, 643], "init_random_fram": [2, 34, 35, 37, 40, 41, 42, 44, 46, 416, 418, 419, 420, 550, 621, 622, 625, 631], "random": [2, 7, 19, 34, 35, 37, 40, 41, 42, 44, 46, 48, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 80, 82, 100, 111, 117, 120, 123, 127, 135, 141, 147, 148, 151, 152, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 183, 212, 229, 243, 244, 263, 270, 285, 299, 300, 322, 324, 330, 335, 339, 340, 341, 346, 362, 365, 371, 373, 375, 379, 404, 414, 415, 416, 418, 419, 420, 427, 465, 470, 502, 551, 607, 621, 622, 623, 625, 626, 627, 629, 638, 639, 640, 642, 643], "rand_step": [2, 19, 22, 117, 120, 121, 122, 123, 124, 126, 127, 128, 135, 136, 137, 141, 142, 143, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 238, 263, 277, 638, 642, 643], "reset_at_each_it": [2, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 416, 418, 419, 420, 621], "split_traj": [2, 34, 35, 37, 40, 41, 42, 44, 46, 76, 78, 80, 81, 82, 416, 418, 419, 420, 621, 622, 623], "trajectori": [2, 4, 17, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 52, 69, 75, 76, 77, 78, 80, 81, 82, 98, 99, 105, 106, 111, 117, 118, 119, 120, 123, 127, 133, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 219, 249, 261, 268, 302, 310, 364, 378, 381, 384, 400, 431, 432, 621, 622, 623, 624, 626, 629, 631, 638, 642, 643], "pad": [2, 22, 52, 76, 78, 80, 81, 82, 84, 183, 186, 187, 193, 194, 197, 203, 219, 267, 286, 288, 289, 302, 304, 324, 325, 326, 327, 328, 329, 330, 335, 375, 406, 461, 593, 634], "along": [2, 18, 22, 34, 35, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 68, 71, 72, 73, 74, 76, 78, 80, 81, 82, 83, 84, 85, 94, 99, 105, 106, 111, 113, 117, 120, 123, 126, 127, 128, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 203, 204, 218, 219, 220, 242, 244, 246, 249, 256, 260, 266, 295, 302, 303, 304, 323, 324, 325, 326, 328, 329, 330, 335, 339, 340, 341, 348, 362, 368, 372, 373, 374, 375, 376, 377, 378, 379, 380, 621, 622, 624, 626, 628, 636, 637, 638, 640, 642], "mask": [2, 16, 18, 22, 23, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 84, 86, 117, 120, 123, 127, 135, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 193, 194, 213, 249, 285, 295, 296, 299, 304, 311, 312, 324, 327, 330, 335, 354, 367, 375, 379, 403, 406, 593, 595, 622, 624, 625, 634, 643], "point": [2, 6, 19, 22, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 71, 72, 73, 74, 79, 85, 91, 98, 99, 101, 111, 112, 115, 116, 117, 120, 123, 124, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 238, 239, 241, 247, 248, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 273, 274, 275, 276, 277, 322, 324, 330, 335, 340, 355, 373, 375, 378, 379, 410, 592, 615, 617, 622, 623, 635, 636, 637, 638, 640, 642, 643], "boolean": [2, 22, 34, 35, 37, 40, 41, 42, 44, 46, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 99, 105, 106, 127, 178, 211, 215, 224, 249, 261, 304, 310, 593, 624], "repres": [2, 17, 19, 21, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 56, 58, 62, 69, 78, 83, 84, 93, 117, 120, 121, 122, 123, 126, 127, 128, 135, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 173, 174, 176, 177, 178, 235, 249, 265, 277, 295, 296, 304, 311, 312, 318, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 381, 406, 601, 621, 623, 624, 625, 626, 627, 628, 636, 637], "valid": [2, 7, 19, 52, 111, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 164, 168, 169, 170, 173, 176, 177, 178, 215, 249, 268, 270, 284, 286, 303, 304, 310, 324, 327, 347, 354, 361, 364, 367, 373, 375, 381, 382, 383, 384, 406, 570, 625, 643], "valu": [2, 7, 17, 18, 19, 21, 22, 27, 34, 35, 37, 40, 41, 42, 44, 46, 47, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 98, 99, 105, 106, 111, 117, 120, 123, 127, 128, 135, 138, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 201, 204, 209, 210, 211, 212, 215, 217, 219, 220, 222, 225, 227, 228, 229, 230, 231, 237, 243, 244, 248, 249, 252, 253, 254, 256, 258, 260, 263, 264, 268, 269, 270, 275, 276, 277, 278, 280, 281, 282, 283, 284, 285, 288, 289, 290, 291, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 308, 310, 311, 312, 316, 317, 318, 319, 320, 323, 324, 325, 326, 328, 329, 330, 335, 336, 337, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 388, 399, 400, 402, 403, 404, 405, 406, 410, 414, 467, 470, 557, 591, 600, 607, 622, 625, 628, 629, 630, 635, 636, 637, 638, 640, 642, 643], "exploration_typ": [2, 34, 35, 37, 40, 41, 42, 44, 46, 404, 416, 418, 419, 420, 465, 621, 622], "explor": [2, 7, 279, 284, 295, 296, 299, 310, 311, 312, 337, 339, 340, 341, 345, 362, 364, 404, 415, 552, 553, 557, 591, 600, 623, 624, 625, 626, 628, 629, 631, 636, 637, 638], "reset_when_don": [2, 34, 35, 37, 40], "its": [2, 6, 17, 18, 19, 21, 22, 23, 24, 26, 28, 30, 32, 33, 34, 35, 37, 38, 40, 41, 42, 44, 46, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 67, 68, 69, 71, 72, 73, 74, 83, 84, 85, 94, 98, 99, 105, 106, 117, 120, 123, 127, 134, 135, 141, 147, 148, 149, 150, 151, 156, 157, 158, 161, 164, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 218, 219, 225, 231, 239, 261, 262, 263, 268, 270, 276, 277, 278, 280, 284, 286, 295, 300, 302, 304, 305, 311, 323, 324, 325, 326, 328, 329, 330, 335, 339, 341, 344, 345, 346, 347, 348, 353, 354, 355, 356, 357, 358, 360, 361, 362, 363, 364, 365, 366, 367, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 388, 410, 414, 415, 557, 563, 568, 574, 588, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 636, 637, 638, 639, 640, 642, 643], "within": [2, 20, 21, 22, 34, 35, 39, 40, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 93, 98, 99, 106, 117, 120, 123, 126, 127, 128, 135, 147, 148, 151, 153, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 211, 213, 215, 216, 218, 219, 220, 223, 224, 225, 227, 228, 230, 231, 232, 233, 235, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 278, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 312, 313, 314, 322, 323, 324, 325, 326, 328, 329, 330, 335, 336, 338, 341, 344, 350, 355, 368, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 386, 388, 396, 410, 569, 570, 571, 572, 614, 622, 625, 626, 627, 628, 629, 630, 631, 636, 638, 642], "how": [2, 5, 6, 13, 17, 19, 21, 30, 39, 41, 42, 44, 64, 69, 80, 83, 84, 85, 98, 99, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 133, 134, 135, 139, 140, 142, 143, 145, 146, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 240, 322, 323, 324, 325, 326, 328, 329, 330, 335, 339, 345, 347, 361, 362, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 388, 390, 410, 412, 580, 584, 591, 592, 621, 622, 623, 624, 625, 626, 627, 629, 630, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "tabl": [2, 375, 622, 627], "summar": [2, 17, 185, 638], "what": [2, 6, 7, 18, 19, 21, 22, 27, 30, 64, 71, 75, 99, 105, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 193, 194, 210, 231, 263, 268, 311, 348, 359, 362, 368, 373, 375, 379, 592, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 633, 634, 636, 637, 638, 639, 640, 642, 643], "expect": [2, 5, 8, 17, 18, 21, 22, 23, 26, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 67, 71, 72, 73, 74, 78, 83, 84, 85, 99, 104, 105, 117, 120, 123, 127, 135, 141, 144, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 200, 212, 216, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 231, 232, 234, 236, 238, 239, 240, 241, 242, 244, 246, 248, 250, 251, 252, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 277, 278, 296, 300, 302, 310, 322, 323, 324, 325, 326, 328, 329, 330, 335, 340, 343, 345, 346, 347, 348, 349, 350, 352, 353, 354, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 551, 592, 614, 621, 623, 624, 626, 627, 628, 629, 633, 634, 636, 637, 638, 640, 643], "n": [2, 4, 6, 17, 19, 25, 26, 48, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 85, 98, 99, 117, 118, 119, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 229, 234, 272, 310, 323, 324, 325, 326, 328, 329, 330, 335, 336, 338, 341, 345, 346, 354, 362, 372, 373, 374, 375, 376, 377, 378, 379, 380, 406, 478, 593, 622, 624, 625, 634, 640, 642, 643], "b": [2, 22, 26, 27, 48, 52, 56, 58, 67, 69, 70, 83, 84, 92, 93, 111, 120, 174, 195, 199, 237, 271, 323, 324, 325, 326, 328, 329, 330, 335, 344, 372, 373, 374, 375, 376, 377, 379, 380, 381, 382, 383, 384, 385, 388, 622, 633, 640], "cat_result": [2, 4, 34, 35], "na": [2, 170, 173, 191], "t": [2, 4, 12, 21, 22, 23, 25, 26, 27, 34, 35, 37, 40, 41, 42, 44, 46, 48, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 89, 98, 99, 104, 105, 106, 111, 117, 120, 123, 124, 126, 127, 135, 142, 143, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 227, 228, 230, 231, 232, 233, 235, 237, 238, 239, 241, 247, 248, 249, 250, 251, 252, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 275, 276, 277, 280, 295, 300, 302, 304, 310, 315, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 340, 345, 364, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 388, 395, 410, 413, 561, 562, 563, 565, 566, 567, 568, 571, 573, 574, 575, 576, 580, 582, 588, 592, 593, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 635, 636, 637, 638, 639, 640, 642, 643], "p": [2, 23, 68, 98, 99, 103, 124, 154, 155, 285, 315], "In": [2, 3, 4, 6, 7, 8, 12, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 34, 35, 37, 39, 40, 41, 42, 44, 46, 47, 48, 75, 76, 78, 80, 81, 82, 83, 84, 85, 106, 117, 118, 119, 120, 123, 127, 133, 134, 135, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 227, 228, 230, 238, 248, 253, 257, 262, 263, 266, 268, 269, 270, 273, 275, 276, 278, 280, 301, 303, 314, 318, 319, 323, 324, 325, 326, 328, 329, 330, 335, 340, 341, 343, 345, 346, 348, 349, 350, 352, 353, 354, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 413, 559, 560, 561, 587, 588, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 636, 637, 638, 639, 640, 643], "case": [2, 4, 6, 7, 15, 18, 19, 20, 21, 22, 23, 24, 26, 27, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 77, 78, 80, 81, 82, 83, 84, 89, 90, 97, 111, 117, 120, 123, 126, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 174, 176, 177, 178, 193, 195, 227, 228, 230, 238, 244, 263, 266, 270, 271, 280, 302, 303, 323, 325, 326, 328, 329, 339, 340, 341, 343, 344, 345, 346, 348, 349, 350, 352, 353, 354, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 388, 397, 400, 413, 559, 560, 561, 593, 594, 621, 622, 623, 624, 625, 626, 627, 629, 630, 634, 636, 637, 638, 640, 642, 643], "dimens": [2, 4, 17, 18, 19, 22, 34, 35, 37, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 67, 71, 72, 73, 74, 76, 78, 80, 81, 82, 83, 84, 92, 93, 94, 99, 105, 106, 111, 113, 117, 120, 121, 122, 123, 126, 127, 128, 129, 135, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 173, 174, 175, 176, 177, 178, 183, 203, 204, 212, 218, 219, 220, 234, 242, 244, 246, 249, 256, 259, 260, 263, 266, 272, 277, 278, 286, 287, 292, 293, 295, 300, 302, 303, 304, 309, 317, 318, 323, 325, 326, 328, 329, 330, 335, 336, 338, 345, 346, 347, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 561, 593, 621, 622, 623, 624, 626, 633, 636, 637, 638, 640], "time": [2, 4, 5, 7, 17, 22, 23, 26, 27, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 52, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 89, 92, 111, 117, 118, 119, 120, 123, 124, 127, 133, 134, 135, 138, 144, 147, 148, 149, 150, 151, 153, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 209, 210, 218, 219, 220, 242, 249, 256, 263, 264, 265, 268, 270, 277, 285, 297, 302, 310, 315, 323, 324, 325, 326, 328, 329, 330, 335, 338, 341, 346, 347, 348, 354, 357, 360, 361, 362, 364, 365, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 410, 414, 470, 523, 570, 578, 584, 586, 588, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 636, 637, 638, 640, 642, 643], "adapt": [2, 4, 213, 242, 261, 277, 322, 354, 361, 367, 593, 621, 625, 638], "equal": [2, 34, 35, 40, 75, 85, 99, 105, 106, 120, 142, 145, 146, 147, 156, 176, 243, 244, 286, 300, 302, 303, 304, 347, 364, 375, 400, 559, 560, 621, 623, 639], "introduc": [2, 6, 98, 99, 147, 156, 300, 302, 310, 621, 636], "some": [2, 6, 8, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 47, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 67, 68, 71, 72, 73, 74, 76, 82, 83, 84, 85, 87, 92, 94, 111, 113, 117, 118, 119, 120, 123, 126, 127, 128, 133, 134, 135, 139, 140, 147, 148, 149, 150, 151, 156, 157, 158, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 201, 215, 248, 263, 270, 273, 288, 300, 323, 324, 325, 326, 328, 329, 330, 335, 341, 342, 343, 372, 373, 374, 375, 376, 377, 378, 379, 380, 388, 400, 550, 593, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 636, 637, 638, 640, 642, 643], "confus": [2, 53, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 270, 324, 330, 335, 373, 375, 378, 379], "other": [2, 3, 5, 6, 7, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 30, 34, 35, 37, 40, 41, 42, 44, 46, 47, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 71, 72, 73, 74, 75, 76, 78, 80, 81, 82, 83, 84, 85, 87, 92, 93, 94, 95, 103, 104, 105, 106, 107, 109, 113, 117, 120, 123, 126, 127, 128, 132, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 222, 224, 228, 229, 250, 257, 263, 266, 273, 277, 278, 296, 299, 300, 302, 305, 312, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 341, 345, 346, 347, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 386, 396, 398, 403, 406, 559, 560, 564, 587, 588, 591, 593, 607, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 636, 637, 638, 639, 642, 643], "better": [2, 6, 19, 22, 27, 28, 34, 35, 37, 50, 51, 52, 134, 168, 169, 170, 173, 175, 187, 300, 302, 322, 331, 335, 593, 623, 626, 638, 642], "consist": [2, 6, 16, 17, 18, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 69, 70, 71, 72, 73, 74, 77, 80, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 239, 276, 286, 303, 324, 330, 335, 373, 375, 378, 379, 586, 589, 597, 614, 621, 622, 623, 634, 638, 639, 643], "interact": [2, 20, 21, 23, 24, 26, 27, 34, 35, 37, 40, 41, 42, 44, 46, 80, 117, 120, 123, 127, 135, 139, 140, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 179, 182, 270, 339, 341, 415, 593, 621, 623, 625, 626, 627, 629, 636, 637, 638, 643], "separ": [2, 4, 7, 23, 27, 34, 35, 37, 40, 41, 44, 46, 48, 52, 56, 58, 67, 69, 70, 75, 77, 83, 84, 174, 181, 219, 248, 275, 322, 323, 325, 326, 328, 329, 346, 349, 352, 354, 365, 367, 368, 369, 372, 374, 376, 377, 380, 381, 396, 581, 593, 614, 621, 622, 627, 628, 636, 637, 640, 643], "interchang": [2, 623, 626, 630, 634, 639, 640], "wherea": [2, 47, 48, 62, 80, 85, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 133, 134, 135, 142, 143, 147, 148, 151, 153, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 224, 229, 268, 270, 324, 330, 335, 348, 362, 367, 373, 375, 378, 379, 630], "correspond": [2, 21, 22, 23, 34, 35, 37, 40, 41, 42, 44, 46, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 69, 71, 72, 73, 74, 77, 80, 82, 83, 84, 85, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 237, 248, 263, 268, 270, 275, 277, 278, 299, 300, 302, 304, 310, 323, 324, 325, 326, 328, 329, 330, 335, 339, 341, 348, 350, 353, 354, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 397, 621, 622, 623, 625, 626, 628, 629, 630, 636, 637, 638, 639], "sub": [2, 3, 21, 22, 34, 35, 40, 41, 42, 44, 46, 56, 58, 75, 80, 85, 105, 111, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 249, 268, 269, 278, 324, 330, 335, 342, 343, 373, 375, 378, 379, 400, 410, 621, 622, 623, 629, 635, 642, 643], "doesn": [2, 23, 34, 35, 40, 85, 111, 117, 120, 123, 127, 135, 142, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 227, 230, 280, 324, 327, 330, 335, 367, 373, 375, 378, 379, 574, 582, 625, 626], "understood": [2, 621], "basi": [2, 111, 640, 642], "we": [2, 6, 12, 17, 18, 19, 21, 22, 24, 26, 28, 30, 49, 50, 52, 56, 64, 67, 69, 70, 75, 76, 80, 82, 85, 92, 104, 106, 111, 117, 118, 119, 120, 123, 124, 127, 131, 133, 134, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 224, 239, 248, 251, 257, 268, 273, 276, 277, 278, 280, 302, 304, 322, 324, 330, 335, 345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 388, 414, 562, 567, 572, 573, 576, 592, 593, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 635, 636, 637, 638, 639, 640, 642, 643], "anoth": [2, 18, 21, 22, 27, 33, 36, 38, 39, 43, 45, 50, 71, 80, 84, 93, 99, 105, 117, 120, 123, 126, 127, 128, 131, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 194, 216, 225, 227, 228, 230, 263, 269, 303, 339, 345, 346, 347, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 373, 375, 379, 397, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 411, 413, 621, 623, 624, 625, 627, 628, 635, 636, 637, 638, 643], "wise": [2, 242, 375], "requir": [2, 4, 6, 17, 18, 22, 23, 26, 27, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 76, 78, 80, 83, 84, 85, 93, 98, 99, 105, 106, 117, 120, 123, 127, 131, 135, 142, 147, 148, 151, 153, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 219, 223, 224, 237, 248, 260, 263, 268, 269, 270, 273, 275, 278, 300, 302, 303, 315, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 340, 341, 342, 343, 345, 346, 347, 348, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 386, 388, 390, 398, 413, 414, 470, 575, 576, 582, 587, 588, 593, 621, 622, 623, 624, 626, 627, 628, 630, 633, 634, 636, 637, 638, 640, 642, 643], "method": [2, 6, 16, 20, 21, 22, 23, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 93, 94, 95, 98, 99, 105, 106, 107, 108, 109, 111, 113, 117, 120, 123, 126, 127, 128, 129, 134, 135, 147, 148, 151, 152, 153, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 207, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 227, 228, 231, 232, 233, 234, 235, 238, 239, 241, 242, 244, 247, 248, 249, 250, 251, 252, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 273, 274, 275, 276, 277, 278, 280, 281, 282, 283, 284, 285, 293, 295, 296, 299, 300, 302, 311, 312, 315, 322, 323, 324, 325, 326, 328, 329, 330, 335, 337, 339, 340, 341, 342, 345, 346, 348, 349, 350, 352, 353, 354, 355, 356, 359, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 385, 386, 387, 396, 397, 403, 415, 558, 563, 564, 565, 566, 568, 569, 570, 571, 572, 574, 575, 576, 578, 579, 580, 581, 582, 584, 585, 586, 587, 588, 591, 607, 614, 619, 622, 623, 624, 625, 626, 627, 628, 629, 630, 633, 636, 638, 640, 643], "op": [2, 7, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 53, 54, 55, 57, 59, 60, 61, 62, 63, 71, 72, 73, 74, 184, 243, 276, 284, 299, 388, 413, 566, 574, 575, 586], "sinc": [2, 3, 6, 19, 21, 23, 24, 26, 30, 34, 35, 37, 39, 40, 48, 49, 50, 52, 64, 67, 69, 70, 75, 82, 83, 84, 85, 98, 99, 106, 111, 117, 120, 123, 127, 135, 147, 148, 149, 150, 151, 153, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 225, 284, 285, 287, 288, 289, 290, 291, 292, 294, 295, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 311, 312, 313, 314, 323, 324, 325, 326, 328, 329, 330, 335, 336, 338, 344, 372, 373, 374, 375, 376, 377, 378, 379, 380, 386, 388, 570, 576, 578, 584, 586, 593, 621, 622, 623, 624, 626, 627, 628, 633, 636, 638, 639, 640, 642, 643], "goal": [2, 6, 17, 23, 75, 76, 77, 78, 79, 80, 81, 82, 135, 177, 262, 621, 622, 623, 624, 633, 637, 638], "policy_devic": [2, 34, 35, 37, 40, 41, 42, 44, 46, 416, 418, 419, 420, 622], "explicitli": [2, 22, 23, 55, 68, 86, 89, 90, 97, 215, 339, 399, 614, 622, 624, 629, 636, 637, 640], "do": [2, 5, 17, 21, 22, 23, 26, 62, 82, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 173, 175, 176, 177, 178, 191, 193, 194, 210, 212, 224, 249, 263, 268, 276, 277, 282, 300, 302, 341, 362, 373, 375, 379, 381, 388, 587, 588, 593, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 635, 636, 637, 638, 640, 642, 643], "deepcopi": [2, 362, 373, 375, 379, 636], "structur": [2, 6, 7, 12, 16, 17, 22, 26, 62, 64, 67, 69, 70, 71, 83, 84, 93, 111, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 175, 176, 177, 178, 183, 193, 194, 200, 211, 227, 230, 263, 310, 323, 324, 325, 326, 328, 329, 330, 335, 345, 354, 364, 367, 372, 374, 376, 377, 380, 381, 382, 383, 384, 385, 421, 593, 600, 607, 614, 621, 623, 624, 626, 629, 636, 637, 638, 639], "place": [2, 7, 21, 22, 38, 56, 58, 68, 83, 84, 85, 92, 94, 103, 105, 113, 117, 120, 123, 124, 127, 135, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 211, 215, 223, 231, 248, 263, 269, 270, 273, 275, 276, 277, 323, 324, 325, 326, 327, 328, 329, 330, 335, 338, 340, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 406, 413, 550, 575, 576, 593, 622, 623, 627, 630, 636, 637, 638, 640], "instanti": [2, 6, 7, 17, 22, 34, 35, 46, 48, 49, 64, 65, 66, 67, 68, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 98, 99, 131, 134, 174, 178, 215, 223, 237, 263, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 381, 382, 383, 384, 385, 386, 396, 397, 414, 461, 462, 465, 466, 467, 578, 579, 614, 621, 622, 627, 628, 630, 636, 637, 638, 640, 643], "all": [2, 3, 6, 7, 17, 18, 19, 21, 22, 23, 27, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 117, 120, 121, 122, 123, 124, 126, 127, 128, 129, 134, 135, 139, 140, 141, 145, 146, 147, 148, 149, 150, 151, 156, 157, 158, 161, 162, 164, 166, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 204, 208, 210, 212, 218, 219, 222, 223, 227, 228, 230, 233, 239, 243, 244, 248, 256, 258, 260, 263, 264, 269, 270, 273, 275, 277, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 303, 305, 306, 307, 309, 310, 312, 313, 314, 315, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 336, 338, 340, 341, 343, 344, 345, 346, 347, 348, 357, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 388, 396, 397, 398, 405, 410, 414, 421, 470, 550, 559, 560, 561, 562, 564, 567, 569, 572, 573, 575, 576, 579, 581, 584, 585, 586, 587, 588, 592, 609, 614, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 635, 636, 637, 638, 640, 642, 643], "graph": [2, 21, 23, 27, 83, 84, 118, 119, 133, 134, 174, 187, 323, 324, 325, 326, 328, 329, 330, 335, 372, 373, 374, 375, 376, 377, 379, 380, 621, 625, 638], "reli": [2, 6, 17, 30, 52, 263, 300, 302, 333, 334, 345, 364, 381, 412, 621, 623, 625, 627, 629, 638, 643], "third": [2, 244, 265, 296, 636, 637], "parti": 2, "try": [2, 23, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 56, 58, 83, 84, 174, 323, 324, 325, 326, 328, 329, 330, 335, 372, 374, 376, 377, 380, 593, 621, 622, 623, 625, 628, 629, 634, 636, 637, 638, 642, 643], "limit": [2, 7, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 187, 193, 194, 219, 239, 345, 347, 361, 362, 364, 366, 373, 375, 379, 593, 614, 621, 622, 624, 636, 637, 638], "chart": 2, "show": [2, 7, 30, 34, 35, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 224, 322, 324, 330, 335, 373, 375, 378, 379, 388, 414, 415, 470, 621, 623, 624, 625, 633, 636, 637, 638, 640, 642], "decis": [2, 18, 19, 287, 292, 309, 351, 363, 624, 626, 627, 636, 637, 640, 643], "tree": [2, 83, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 219, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 636, 640], "These": [3, 6, 26, 77, 82, 114, 161, 248, 275, 278, 373, 375, 379, 593, 600, 607, 614, 621, 623, 636, 637, 638, 640, 643], "gloo": [3, 41, 42, 47, 563], "nccl": [3, 6, 41, 42, 322, 333, 334, 563, 581, 582, 586, 587, 588], "mpi": [3, 41, 42], "launcher": [3, 41, 42, 44, 47], "submitit": [3, 41, 42, 44, 47], "torch": [3, 6, 10, 17, 18, 19, 21, 22, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 93, 94, 95, 98, 99, 101, 104, 105, 106, 111, 112, 113, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 133, 134, 135, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 210, 211, 212, 213, 215, 216, 217, 218, 220, 223, 224, 225, 227, 228, 229, 230, 231, 232, 237, 239, 240, 241, 244, 246, 248, 250, 251, 253, 255, 256, 257, 258, 260, 261, 262, 263, 264, 266, 269, 270, 271, 273, 275, 277, 278, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 308, 309, 310, 311, 312, 317, 318, 319, 320, 322, 323, 324, 325, 326, 328, 329, 330, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 390, 400, 407, 408, 415, 461, 462, 465, 466, 467, 486, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 557, 562, 563, 567, 568, 581, 586, 587, 588, 593, 600, 615, 621, 622, 623, 624, 625, 627, 628, 629, 631, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "multiprocess": [3, 5, 6, 22, 33, 34, 35, 41, 42, 44, 46, 67, 68, 69, 70, 75, 82, 92, 93, 94, 95, 117, 124, 125, 147, 151, 156, 277, 278, 562, 563, 564, 565, 567, 568, 572, 573, 574, 614, 621, 622, 623, 624, 629, 636, 637, 638, 639, 643], "mode": [3, 21, 25, 32, 34, 35, 37, 40, 41, 42, 44, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 85, 117, 120, 123, 127, 132, 135, 142, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 227, 230, 262, 270, 277, 278, 293, 300, 301, 302, 308, 317, 318, 319, 323, 324, 325, 326, 328, 329, 330, 335, 339, 341, 347, 362, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 386, 399, 404, 520, 593, 607, 614, 621, 622, 636, 637, 642, 643], "find": [3, 23, 25, 26, 41, 42, 44, 64, 105, 106, 181, 284, 310, 397, 403, 407, 586, 621, 622, 625, 627, 628, 633, 636, 637], "folder": [3, 83, 84, 161, 174, 219, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 622], "variou": [3, 6, 10, 15, 19, 21, 22, 33, 120, 269, 345, 346, 347, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 370, 373, 375, 379, 388, 559, 560, 595, 617, 621, 622, 623, 625, 626, 627, 628, 630, 636, 637, 640, 643], "machin": [3, 6, 26, 41, 42, 44, 79, 131, 582, 636, 637, 642], "One": [3, 4, 6, 22, 23, 27, 53, 55, 56, 57, 58, 61, 63, 111, 117, 118, 119, 147, 151, 156, 157, 219, 253, 273, 284, 308, 340, 344, 392, 614, 621, 622, 640, 643], "wonder": 3, "why": [3, 22, 210, 636, 638, 643], "instead": [3, 21, 22, 23, 26, 27, 34, 35, 37, 39, 40, 41, 42, 44, 46, 48, 49, 50, 53, 55, 65, 80, 83, 84, 85, 98, 99, 117, 120, 123, 127, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 234, 280, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 312, 313, 314, 323, 324, 325, 326, 328, 329, 330, 335, 336, 338, 340, 344, 345, 347, 348, 350, 353, 354, 355, 360, 361, 364, 365, 366, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 385, 561, 578, 579, 624, 625, 626, 627, 631, 638, 640, 643], "gener": [3, 5, 6, 16, 17, 21, 22, 26, 27, 28, 34, 35, 37, 40, 41, 42, 44, 46, 50, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 102, 104, 117, 120, 123, 124, 127, 135, 139, 140, 141, 144, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 211, 213, 216, 223, 225, 227, 228, 232, 237, 239, 242, 244, 250, 251, 256, 257, 261, 263, 267, 269, 271, 276, 278, 285, 293, 300, 302, 304, 308, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 335, 337, 339, 341, 359, 365, 372, 374, 375, 376, 377, 378, 379, 380, 381, 391, 403, 410, 428, 593, 595, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "lower": [3, 15, 22, 46, 54, 98, 99, 222, 277, 278, 313, 314, 344, 364, 623, 636, 638], "io": [3, 30, 75, 80, 133, 134, 142, 145, 146, 159, 160, 200, 625], "footprint": [3, 640], "need": [3, 4, 6, 7, 17, 18, 19, 20, 21, 22, 23, 26, 27, 29, 32, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 48, 50, 64, 67, 68, 69, 70, 71, 83, 84, 85, 107, 111, 117, 120, 123, 127, 131, 135, 138, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 222, 224, 225, 234, 240, 248, 251, 264, 268, 269, 270, 275, 277, 278, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 311, 312, 313, 314, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 336, 338, 339, 340, 344, 354, 366, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 385, 388, 396, 410, 561, 566, 569, 574, 575, 588, 593, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 636, 637, 638, 640, 642, 643], "commun": [3, 18, 22, 43, 45, 83, 84, 135, 147, 151, 156, 174, 177, 322, 323, 325, 326, 328, 329, 333, 334, 372, 374, 376, 377, 380, 562, 564, 565, 567, 569, 571, 572, 573, 575, 577, 580, 581, 586, 587, 588, 592, 614, 623, 643], "yet": [3, 118, 119, 133, 328, 329, 378, 563, 565, 566, 568, 571, 574, 575, 576, 580, 582, 588, 639], "spec": [3, 16, 19, 22, 34, 35, 37, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 76, 84, 85, 117, 118, 119, 120, 123, 125, 126, 127, 128, 129, 132, 133, 134, 135, 141, 142, 143, 145, 146, 147, 148, 151, 152, 153, 156, 157, 158, 159, 160, 161, 162, 163, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 207, 210, 211, 212, 213, 216, 217, 219, 220, 221, 222, 223, 226, 227, 228, 229, 230, 231, 232, 234, 236, 238, 239, 240, 241, 242, 244, 246, 248, 250, 251, 252, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 277, 278, 284, 295, 296, 299, 300, 302, 310, 311, 312, 314, 323, 325, 326, 328, 329, 337, 339, 340, 341, 343, 344, 345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 378, 593, 600, 621, 622, 623, 624, 625, 626, 627, 631, 633, 635, 636, 637, 642], "plai": [3, 19, 149, 150, 158, 168, 219, 622, 623, 628, 640, 643], "role": [3, 19, 84, 86, 140, 168, 170, 173, 181, 188, 193, 194, 195, 330, 335, 379, 622, 628, 634, 643], "opposit": [3, 636], "direct": [3, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 362, 373, 375, 378, 379, 569, 570, 622, 628, 634], "faster": [3, 23, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 81, 82, 98, 142, 304, 381, 382, 383, 384, 624, 625, 636, 637], "vector": [3, 16, 21, 27, 53, 63, 118, 119, 128, 133, 134, 138, 149, 150, 153, 161, 162, 229, 276, 278, 288, 290, 303, 381, 384, 591, 621, 622, 624, 635, 636, 637, 638, 639, 643], "share": [3, 6, 7, 15, 19, 21, 25, 27, 34, 35, 37, 40, 46, 48, 52, 67, 68, 69, 70, 71, 83, 84, 87, 90, 92, 93, 94, 95, 99, 101, 105, 107, 109, 113, 124, 147, 156, 169, 170, 173, 174, 183, 190, 191, 192, 193, 260, 268, 277, 278, 281, 282, 283, 300, 302, 323, 325, 326, 328, 329, 345, 346, 347, 348, 349, 353, 354, 360, 361, 364, 365, 366, 367, 368, 369, 372, 374, 376, 377, 380, 397, 428, 463, 465, 466, 467, 561, 570, 572, 575, 576, 578, 582, 583, 584, 585, 586, 593, 614, 623, 625, 631, 633, 634, 635, 636, 637, 642, 643], "among": [3, 18, 62, 149, 150, 268, 354, 367, 636, 637], "achiev": [3, 4, 21, 23, 85, 117, 120, 123, 127, 131, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 211, 262, 285, 324, 330, 335, 339, 373, 375, 378, 379, 406, 621, 622, 623, 624, 625, 633, 636, 637, 638, 640, 642, 643], "prohibit": [3, 21, 111], "slow": [3, 22, 23, 30, 83, 84, 93, 105, 106, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "compar": [3, 21, 22, 80, 111, 346, 348, 360, 365, 367, 368, 369, 404, 614, 621, 623, 625, 627, 628, 636, 637, 640, 643], "gpu": [3, 26, 27, 49, 51, 85, 92, 94, 113, 117, 120, 123, 127, 128, 131, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 241, 322, 324, 327, 330, 331, 332, 335, 373, 375, 378, 379, 396, 581, 587, 588, 621, 623, 624, 636, 637, 643], "nativ": [3, 6, 16, 26, 28, 78, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 219, 322, 335, 388, 624, 640], "driver": [3, 26], "mean": [3, 5, 6, 7, 17, 19, 21, 22, 23, 26, 34, 35, 36, 37, 40, 41, 42, 44, 46, 48, 69, 71, 75, 83, 84, 93, 98, 99, 105, 106, 111, 117, 118, 119, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 181, 215, 244, 268, 277, 278, 284, 293, 297, 300, 302, 309, 317, 318, 323, 325, 326, 328, 329, 339, 341, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 374, 375, 376, 377, 379, 380, 381, 382, 383, 384, 403, 414, 621, 622, 623, 625, 627, 636, 637, 638, 640, 643], "keyword": [3, 21, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 90, 92, 93, 94, 95, 98, 99, 103, 105, 106, 109, 113, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 133, 134, 135, 139, 140, 142, 143, 145, 146, 147, 148, 151, 153, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 200, 204, 212, 213, 215, 216, 218, 219, 220, 222, 223, 224, 225, 228, 231, 232, 233, 235, 237, 238, 239, 241, 242, 247, 248, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 280, 284, 285, 295, 299, 300, 302, 304, 310, 311, 322, 323, 324, 325, 326, 328, 329, 330, 331, 335, 337, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 393, 395, 397, 410, 414, 415, 558, 621, 622, 623, 625, 627, 630, 636, 637, 640, 642, 643], "given": [3, 4, 12, 22, 34, 35, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 99, 105, 106, 117, 120, 123, 127, 135, 141, 145, 146, 147, 148, 151, 156, 157, 158, 159, 160, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 212, 223, 229, 237, 244, 248, 263, 267, 269, 270, 271, 273, 275, 277, 278, 284, 285, 295, 296, 297, 299, 300, 302, 312, 315, 316, 320, 323, 324, 325, 326, 328, 329, 330, 335, 337, 338, 340, 341, 342, 343, 349, 350, 352, 362, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 397, 401, 404, 557, 571, 621, 622, 623, 626, 627, 628, 629, 630, 637, 638, 643], "mani": [3, 7, 16, 18, 19, 22, 23, 67, 83, 84, 118, 119, 121, 122, 123, 126, 128, 129, 133, 134, 142, 143, 153, 174, 176, 181, 183, 263, 323, 325, 326, 328, 329, 345, 347, 354, 361, 364, 372, 374, 375, 376, 377, 380, 412, 614, 621, 622, 623, 625, 626, 627, 629, 631, 636, 637, 638, 640, 642, 643], "eg": [3, 17, 22, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 87, 92, 93, 94, 95, 107, 109, 113, 117, 120, 121, 122, 123, 126, 127, 128, 129, 131, 135, 147, 148, 151, 153, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 229, 261, 270, 280, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 388], "gymnasium": [3, 17, 18, 22, 24, 34, 35, 37, 40, 48, 117, 120, 123, 126, 127, 128, 132, 135, 136, 137, 147, 148, 151, 156, 157, 158, 167, 168, 169, 170, 173, 176, 177, 178, 209, 232, 257, 261, 276, 280, 443, 622, 623, 625, 638, 642], "warn": [3, 22, 34, 35, 83, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 270, 277, 284, 299, 310, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 399, 622, 633, 634], "quickli": [3, 22, 622, 636, 637, 643], "becom": [3, 22, 23, 46, 396, 397, 575, 614, 636, 637, 643], "quit": [3, 22, 30, 75, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 621, 622, 623, 625, 627, 636, 637, 643], "annoi": [3, 22], "By": [3, 6, 17, 21, 22, 33, 36, 37, 38, 39, 43, 45, 56, 58, 63, 85, 117, 120, 121, 122, 123, 126, 127, 128, 129, 135, 139, 140, 147, 148, 149, 150, 151, 153, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 238, 239, 241, 242, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 341, 362, 373, 375, 378, 379, 399, 404, 561, 576, 593, 621, 624, 636, 639, 640, 643], "filter": [3, 21, 22, 23, 99, 105, 106, 345, 346, 348, 349, 353, 354, 360, 364, 365, 367, 375, 396, 626], "out": [3, 17, 19, 21, 22, 23, 24, 28, 33, 36, 38, 39, 43, 45, 46, 50, 51, 76, 80, 83, 84, 85, 90, 99, 105, 106, 117, 120, 123, 127, 135, 147, 148, 149, 150, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 260, 263, 284, 295, 296, 304, 311, 312, 323, 324, 325, 326, 328, 329, 330, 335, 337, 339, 340, 341, 362, 372, 373, 374, 375, 376, 377, 378, 379, 380, 396, 621, 622, 623, 624, 625, 626, 627, 629, 636, 637, 638, 640, 642, 643], "still": [3, 17, 22, 28, 72, 80, 117, 118, 119, 120, 123, 127, 133, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 268, 270, 310, 324, 330, 335, 361, 362, 373, 375, 379, 572, 577, 579, 585, 587, 593, 621, 622, 624, 635, 638, 640, 643], "wish": [3, 22, 30, 34, 35, 40, 80, 209, 628, 640], "displai": [3, 22, 26, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 410, 621, 622, 633, 637, 638], "filter_warnings_subprocess": [3, 22], "fals": [3, 18, 22, 30, 31, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 101, 103, 104, 105, 106, 107, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 210, 211, 212, 213, 215, 216, 219, 220, 223, 225, 227, 230, 231, 232, 234, 237, 238, 239, 241, 242, 243, 244, 246, 248, 249, 250, 251, 253, 255, 256, 257, 260, 261, 263, 266, 267, 268, 269, 270, 271, 272, 273, 275, 277, 278, 280, 281, 282, 283, 284, 285, 286, 288, 294, 295, 296, 299, 300, 301, 302, 303, 304, 310, 311, 312, 318, 319, 320, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 335, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 388, 395, 399, 402, 403, 404, 406, 407, 410, 414, 415, 416, 418, 419, 420, 422, 423, 424, 425, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 474, 475, 500, 503, 513, 524, 536, 537, 538, 539, 540, 546, 547, 548, 561, 570, 575, 576, 578, 584, 586, 614, 621, 622, 623, 624, 625, 630, 631, 633, 634, 635, 636, 637, 638, 639, 642, 643], "simplest": [4, 6, 111, 324, 330, 335, 344, 373, 375, 379, 621, 623, 627, 636, 637, 640, 643], "transit": [4, 76, 80, 85, 99, 106, 111, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 315, 321, 324, 330, 335, 373, 375, 378, 379, 621, 624, 626, 627, 629, 636, 638, 640], "sampl": [4, 5, 7, 10, 15, 23, 27, 28, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 87, 92, 93, 94, 98, 99, 100, 103, 104, 105, 106, 109, 111, 113, 117, 120, 123, 127, 135, 141, 144, 147, 148, 151, 156, 157, 158, 165, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 208, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 273, 274, 276, 277, 278, 284, 293, 295, 296, 299, 301, 304, 308, 309, 310, 311, 312, 313, 315, 318, 319, 324, 327, 330, 335, 337, 339, 340, 341, 345, 346, 347, 348, 349, 350, 352, 361, 363, 364, 368, 369, 375, 378, 400, 406, 410, 412, 415, 426, 427, 430, 431, 432, 472, 550, 591, 621, 622, 623, 624, 625, 626, 627, 629, 631, 636, 637, 639, 642, 643], "attent": [4, 27, 176, 219, 324, 330, 335, 375, 621, 624, 634, 643], "built": [4, 7, 10, 16, 17, 21, 24, 26, 68, 83, 84, 118, 119, 126, 133, 134, 144, 145, 174, 315, 323, 325, 326, 328, 329, 345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 379, 380, 555, 557, 558, 561, 593, 600, 614, 621, 622, 623, 624, 625, 628, 630, 633, 638, 640, 643], "flatten": [4, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 111, 174, 216, 234, 323, 325, 326, 328, 329, 336, 372, 374, 376, 377, 378, 380, 381, 406, 583, 584, 593, 637], "suffici": [4, 18, 23, 621], "preprocess": [4, 10, 16, 75, 76, 77, 78, 79, 80, 81, 82, 269, 622, 625], "popul": [4, 17, 34, 35, 37, 46, 48, 49, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 176, 238, 263, 293, 362, 373, 375, 379, 621, 623, 624, 627, 629, 638, 640], "replaybuff": [4, 10, 12, 21, 34, 35, 37, 40, 46, 48, 49, 64, 65, 66, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 87, 92, 93, 98, 99, 100, 105, 106, 115, 219, 249, 253, 350, 355, 396, 414, 415, 428, 555, 557, 623, 625, 629, 631, 636, 637, 639, 640, 642], "lazytensorstorag": [4, 10, 12, 34, 35, 37, 40, 48, 64, 67, 69, 70, 98, 105, 106, 111, 253, 415, 424, 623, 625, 631, 636, 637, 640], "lambda": [4, 6, 34, 35, 37, 40, 46, 47, 48, 49, 67, 111, 117, 120, 123, 124, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 181, 209, 216, 224, 225, 237, 239, 263, 271, 278, 280, 285, 295, 311, 324, 330, 335, 338, 339, 356, 358, 359, 368, 373, 375, 379, 381, 384, 386, 413, 414, 557, 586, 593, 621, 622, 624, 625, 636, 637, 639, 640, 642, 643], "reshap": [4, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 80, 105, 111, 216, 300, 302, 303, 386, 593, 623, 636, 637], "extend": [4, 7, 10, 27, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 87, 91, 92, 95, 98, 99, 101, 105, 106, 109, 111, 112, 115, 116, 168, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 212, 218, 253, 269, 362, 373, 375, 378, 379, 406, 414, 586, 587, 593, 595, 603, 621, 622, 623, 625, 629, 631, 636, 637, 639, 640, 642], "slice": [4, 10, 17, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 76, 80, 99, 105, 106, 212, 218, 219, 323, 431, 432, 624, 640], "recommend": [4, 23, 26, 34, 35, 37, 40, 41, 42, 44, 46, 64, 67, 69, 70, 83, 84, 105, 111, 131, 168, 169, 170, 173, 174, 187, 219, 322, 323, 325, 326, 328, 329, 330, 333, 334, 335, 347, 364, 372, 373, 374, 375, 376, 377, 380, 593, 614, 629, 634, 636, 637], "multidimension": [4, 69, 98, 99, 640], "slicesampl": [4, 10, 75, 99, 106, 219, 431, 624, 640], "sampler": [4, 7, 10, 13, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 87, 92, 93, 94, 95, 98, 99, 100, 103, 104, 105, 106, 107, 109, 111, 113, 219, 249, 350, 355, 428, 435, 621, 623, 624, 636, 637, 640], "must": [4, 6, 18, 21, 22, 26, 30, 34, 35, 37, 38, 39, 40, 41, 42, 44, 46, 47, 50, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 86, 87, 92, 93, 94, 95, 99, 105, 106, 107, 108, 109, 111, 113, 117, 118, 120, 123, 124, 127, 133, 135, 145, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 161, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 207, 212, 215, 216, 219, 222, 224, 225, 231, 235, 237, 239, 241, 242, 244, 246, 257, 260, 262, 263, 264, 267, 268, 270, 271, 272, 277, 286, 295, 296, 300, 302, 303, 304, 311, 312, 320, 322, 324, 327, 330, 335, 337, 338, 339, 340, 341, 344, 345, 346, 348, 349, 350, 352, 353, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 381, 382, 383, 384, 385, 390, 395, 396, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 572, 579, 581, 582, 585, 587, 588, 589, 593, 621, 622, 623, 624, 627, 633, 635, 638, 640], "ensur": [4, 6, 7, 17, 21, 32, 34, 35, 37, 40, 41, 42, 43, 44, 45, 46, 48, 64, 69, 85, 98, 99, 104, 117, 120, 123, 127, 132, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 213, 219, 248, 261, 270, 273, 277, 278, 295, 300, 302, 322, 324, 330, 335, 347, 361, 364, 373, 375, 378, 379, 396, 564, 572, 579, 581, 585, 586, 587, 589, 593, 597, 614, 622, 623, 624, 638, 640], "clearli": 4, "dimension": [4, 64, 67, 69, 70, 176, 229, 300, 302, 381, 637], "num_slic": [4, 75, 80, 99, 105, 106, 431, 432, 640], "trajectory_kei": [4, 52, 105, 106], "traj_id": [4, 17, 34, 35, 37, 48, 52, 216, 253, 629, 640], "dim": [4, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 105, 174, 188, 203, 219, 220, 242, 246, 259, 260, 263, 272, 277, 323, 325, 326, 328, 329, 338, 372, 374, 376, 377, 380, 478, 479, 500, 504, 517, 518, 522, 529, 561, 593, 622, 623, 625, 636, 638, 640], "ndim": [4, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 69, 70, 71, 72, 73, 74, 92, 94, 98, 99, 111, 113, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 242, 338, 422, 424, 436], "regular": [4, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 83, 84, 85, 98, 103, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 273, 274, 276, 277, 294, 296, 300, 302, 311, 312, 323, 325, 326, 327, 328, 329, 340, 341, 355, 364, 372, 374, 376, 377, 378, 379, 380, 413, 414, 415, 621, 622, 625, 626, 627, 631, 633, 640, 643], "behav": [4, 22, 129, 141, 308, 353, 360, 362, 373, 375, 379, 625, 639], "accordingli": [4, 22, 83, 84, 99, 172, 174, 225, 242, 261, 262, 311, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 624], "3": [4, 18, 19, 20, 22, 25, 26, 29, 30, 34, 35, 37, 40, 46, 48, 49, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 94, 98, 99, 105, 106, 111, 113, 117, 120, 121, 122, 123, 126, 127, 128, 129, 130, 135, 138, 139, 140, 142, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 204, 213, 215, 216, 219, 223, 224, 225, 229, 231, 232, 237, 239, 244, 246, 248, 250, 251, 253, 256, 257, 260, 261, 262, 263, 266, 268, 269, 270, 271, 273, 275, 278, 280, 281, 282, 283, 285, 286, 288, 289, 290, 292, 295, 296, 298, 300, 302, 303, 304, 305, 308, 312, 320, 322, 323, 324, 325, 326, 328, 329, 330, 335, 336, 337, 339, 340, 343, 344, 345, 346, 348, 349, 350, 352, 353, 354, 355, 356, 357, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 388, 396, 408, 461, 478, 501, 562, 572, 576, 579, 585, 587, 588, 600, 614, 620, 621, 622, 623, 624, 626, 627, 629, 630, 636, 637, 638, 640, 641, 642, 643], "isn": [4, 22, 27, 34, 35, 37, 40, 41, 42, 44, 46, 80, 83, 84, 98, 111, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 174, 176, 177, 178, 215, 231, 237, 295, 323, 325, 326, 328, 329, 340, 372, 374, 376, 377, 380, 381, 627, 628, 630, 636, 637], "current": [4, 18, 22, 31, 33, 34, 35, 36, 37, 40, 43, 45, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 96, 99, 106, 117, 120, 123, 127, 129, 135, 142, 145, 146, 147, 148, 151, 156, 157, 158, 165, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 215, 216, 219, 237, 249, 262, 263, 264, 268, 269, 270, 278, 297, 310, 314, 315, 318, 323, 324, 325, 326, 327, 328, 329, 330, 333, 334, 335, 338, 345, 347, 348, 355, 361, 364, 366, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 391, 396, 397, 398, 562, 585, 586, 587, 614, 621, 622, 623, 624, 628, 636, 637, 638, 640, 643], "fulli": [4, 6, 27, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 622, 625, 628, 638, 640], "ani": [4, 7, 12, 17, 18, 19, 21, 22, 24, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 90, 91, 92, 93, 94, 95, 101, 104, 106, 107, 109, 111, 112, 113, 115, 116, 117, 120, 123, 124, 127, 128, 135, 142, 147, 148, 149, 150, 151, 156, 157, 158, 159, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 200, 211, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 234, 235, 237, 238, 239, 241, 247, 248, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 273, 274, 276, 277, 278, 280, 285, 286, 292, 293, 303, 322, 323, 324, 325, 326, 328, 329, 330, 335, 338, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 352, 353, 354, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 386, 388, 393, 396, 397, 403, 410, 412, 413, 414, 416, 418, 419, 420, 422, 424, 428, 431, 432, 433, 434, 435, 436, 437, 439, 443, 447, 461, 462, 463, 465, 466, 467, 469, 470, 475, 482, 483, 484, 521, 528, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 585, 586, 587, 588, 592, 614, 621, 622, 623, 624, 625, 627, 628, 633, 636, 637, 638, 640, 642, 643], "consecut": [4, 17, 75, 104, 131, 302, 310, 388, 624, 626, 629, 637, 640, 643], "won": [4, 22, 23, 34, 35, 37, 40, 41, 42, 44, 46, 80, 83, 84, 85, 117, 120, 123, 124, 126, 127, 135, 142, 143, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 248, 275, 323, 324, 325, 326, 328, 329, 330, 335, 345, 372, 373, 374, 375, 376, 377, 378, 379, 380, 410, 561, 622, 623, 626, 627], "therebi": [4, 386, 621, 622], "interrupt": [4, 127, 178, 338, 396, 397], "allow": [5, 6, 7, 12, 16, 17, 18, 20, 21, 22, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 56, 58, 62, 63, 67, 68, 69, 70, 75, 80, 83, 84, 85, 86, 93, 99, 103, 105, 106, 117, 118, 119, 120, 123, 127, 133, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 210, 215, 216, 251, 278, 303, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 575, 576, 593, 614, 621, 623, 624, 625, 626, 627, 628, 634, 636, 637, 638, 640, 642, 643], "start": [5, 20, 21, 22, 23, 24, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 65, 71, 75, 82, 98, 99, 105, 106, 117, 120, 123, 124, 127, 132, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 210, 212, 226, 316, 370, 405, 563, 568, 575, 580, 581, 582, 586, 588, 591, 620, 621, 622, 624, 625, 632, 637, 638, 640, 641, 643], "get": [5, 6, 18, 19, 21, 22, 23, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 56, 58, 64, 67, 75, 76, 80, 83, 84, 85, 92, 94, 99, 105, 106, 107, 109, 111, 113, 117, 120, 123, 124, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 186, 188, 192, 193, 194, 199, 213, 218, 220, 224, 227, 229, 230, 239, 244, 249, 262, 263, 266, 270, 277, 278, 299, 311, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 337, 339, 341, 372, 373, 374, 375, 376, 377, 379, 380, 381, 382, 383, 384, 385, 388, 392, 396, 397, 398, 563, 565, 566, 568, 571, 574, 576, 580, 582, 586, 588, 591, 593, 607, 620, 621, 622, 623, 624, 625, 632, 634, 636, 637, 638, 640, 641, 642, 643], "rid": [5, 324, 330, 335, 373, 375, 379], "natur": [5, 18, 32, 41, 42, 44, 168, 184, 621, 627, 628, 629, 640], "background": [5, 32, 34, 35, 40, 41, 42, 44, 46, 49, 188, 640], "simpli": [5, 6, 7, 20, 22, 25, 83, 84, 109, 111, 116, 174, 180, 232, 257, 276, 323, 325, 326, 328, 329, 362, 372, 373, 374, 375, 376, 377, 379, 380, 381, 621, 623, 628, 633, 636, 637, 643], "replay_buff": [5, 7, 27, 34, 35, 37, 40, 46, 48, 49, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 219, 406, 413, 414, 415, 416, 418, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 470, 557, 621, 622, 623, 624, 629, 636, 637, 640], "rb": [5, 34, 35, 37, 40, 48, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 87, 93, 98, 99, 105, 106, 111, 219, 253, 622, 624, 625, 629, 631, 637, 639, 640, 642], "paus": [5, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49], "sleep": [5, 34, 35, 37, 40, 48, 65, 124, 643], "10": [5, 6, 18, 20, 26, 47, 52, 53, 55, 57, 59, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 93, 94, 98, 105, 106, 111, 113, 117, 118, 119, 120, 123, 124, 127, 133, 134, 135, 141, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 161, 162, 168, 169, 170, 173, 174, 176, 177, 178, 181, 183, 186, 188, 190, 191, 195, 212, 213, 216, 218, 219, 224, 225, 262, 264, 265, 266, 277, 278, 285, 287, 288, 290, 292, 294, 299, 300, 302, 304, 309, 310, 323, 325, 326, 328, 329, 339, 341, 344, 346, 350, 352, 359, 364, 365, 366, 369, 372, 373, 374, 375, 376, 377, 380, 381, 382, 383, 384, 388, 396, 400, 462, 465, 466, 467, 472, 477, 520, 538, 564, 614, 615, 621, 622, 623, 624, 625, 626, 627, 631, 636, 638, 640, 642, 643], "i": [5, 6, 17, 19, 22, 34, 35, 37, 40, 41, 42, 44, 46, 48, 56, 58, 64, 67, 70, 83, 84, 85, 87, 88, 92, 94, 98, 99, 105, 106, 113, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 225, 226, 242, 248, 253, 256, 268, 270, 275, 296, 300, 302, 305, 312, 323, 324, 325, 326, 328, 329, 330, 335, 338, 339, 340, 341, 345, 347, 348, 349, 353, 354, 360, 361, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 400, 550, 593, 621, 622, 623, 624, 625, 627, 628, 629, 630, 631, 636, 637, 638, 640, 642, 643], "rang": [5, 17, 19, 23, 27, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 92, 94, 111, 117, 120, 123, 124, 127, 135, 139, 140, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 175, 176, 177, 178, 183, 253, 266, 277, 280, 323, 325, 326, 328, 329, 361, 368, 369, 372, 374, 376, 377, 380, 621, 623, 624, 625, 628, 629, 631, 636, 637, 638, 640, 642], "optim_step": [5, 625, 631], "rest": [5, 7, 34, 35, 40, 623, 624, 636, 638, 642], "multithread": [5, 22, 64, 67, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 142, 143, 629, 640], "mind": [5, 21, 22, 75, 80, 99, 105, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 636, 637], "gil": 5, "relat": [5, 19, 22, 23, 29, 56, 64, 147, 173, 234, 345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 622, 631, 638], "restrict": [5, 22, 83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 622, 633, 639, 640, 643], "hand": [5, 19, 26, 46, 56, 636, 637, 638], "let": [5, 6, 7, 19, 25, 26, 30, 52, 64, 67, 69, 70, 85, 117, 120, 123, 127, 135, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 295, 324, 330, 335, 373, 375, 378, 379, 404, 593, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "child": [5, 39, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 622], "fill": [5, 34, 35, 37, 40, 41, 42, 44, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 75, 127, 178, 215, 263, 276, 302, 381, 624, 638, 639], "truli": [5, 276, 396, 642], "decoupl": [5, 32, 34, 35, 37, 40, 41, 42, 44, 48, 621, 628, 642], "been": [5, 18, 24, 26, 27, 31, 41, 44, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 104, 117, 120, 123, 127, 131, 135, 139, 140, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 239, 241, 261, 262, 269, 270, 300, 302, 338, 345, 362, 364, 366, 373, 375, 379, 396, 563, 565, 566, 568, 570, 571, 574, 575, 576, 578, 580, 582, 584, 586, 588, 621, 622, 623, 624, 635, 636, 637, 638, 640, 642, 643], "shut": [5, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 151, 157, 396], "down": [5, 23, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 151, 157, 396, 624, 626], "async_shutdown": [5, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 65], "drastic": [5, 6, 134, 147, 640], "hardwar": [5, 6, 17, 625], "load": [5, 6, 25, 26, 34, 35, 37, 40, 48, 49, 50, 51, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 90, 92, 93, 94, 95, 107, 108, 109, 113, 114, 117, 120, 122, 123, 127, 135, 147, 148, 151, 156, 157, 158, 159, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 209, 277, 278, 322, 323, 324, 325, 326, 328, 329, 330, 335, 372, 373, 374, 375, 376, 377, 378, 379, 380, 410, 412, 414, 415, 561, 584, 593, 596, 621, 623, 625, 633, 634, 640], "factor": [5, 27, 30, 253, 284, 299, 301, 310, 318, 319, 346, 352, 355, 356, 358, 414, 621, 622, 625, 627, 631, 636, 637, 640, 643], "signific": [5, 21, 24, 27, 614, 623, 642, 643], "understand": [5, 19, 27, 32, 41, 42, 44, 614, 621, 622, 625, 626, 627, 633, 636, 637], "affect": [5, 22, 27, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 225, 270, 278, 323, 324, 325, 326, 328, 329, 330, 335, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 396, 636], "algorithm": [5, 7, 10, 12, 18, 20, 27, 28, 32, 41, 42, 44, 141, 212, 260, 345, 364, 365, 367, 412, 414, 415, 607, 608, 611, 612, 613, 615, 621, 622, 623, 624, 625, 627, 628, 629, 630, 636, 637, 639, 640, 642], "legitim": [5, 643], "unless": [5, 22, 34, 35, 37, 40, 41, 42, 44, 46, 48, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 80, 83, 84, 85, 89, 104, 117, 120, 123, 127, 135, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 268, 270, 278, 323, 324, 325, 326, 328, 329, 330, 335, 345, 346, 348, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 623], "benchmark": [5, 18, 22, 28, 118, 119, 127, 133, 134, 178], "pipelin": [6, 19, 26, 127, 178, 331, 593, 597, 623], "typic": [6, 17, 22, 23, 27, 32, 33, 36, 37, 38, 41, 42, 43, 44, 45, 46, 48, 78, 85, 98, 99, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 231, 262, 324, 330, 335, 339, 346, 348, 362, 364, 367, 373, 375, 378, 379, 414, 567, 571, 572, 573, 574, 581, 588, 593, 623, 625, 626, 628, 629, 634, 636, 637, 638], "big": [6, 623, 629, 640, 643], "bucket": [6, 169], "occasion": 6, "tradit": [6, 628, 636], "neural": [6, 7, 138, 149, 150, 286, 340, 381, 600, 622, 623, 624, 627, 636, 637, 638, 643], "both": [6, 7, 18, 26, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 50, 56, 58, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 117, 120, 123, 124, 126, 127, 135, 139, 140, 147, 148, 149, 150, 151, 156, 157, 158, 159, 163, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 211, 212, 219, 237, 251, 267, 268, 270, 281, 282, 283, 286, 296, 300, 302, 303, 312, 322, 324, 330, 332, 335, 345, 347, 348, 349, 353, 354, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 381, 396, 397, 403, 404, 413, 470, 586, 587, 588, 593, 614, 621, 623, 625, 626, 628, 633, 634, 636, 637, 638, 639, 640, 643], "anyth": [6, 23, 34, 35, 37, 40, 41, 42, 44, 46], "happen": [6, 7, 18, 21, 22, 43, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 280, 310, 412, 622, 625, 628, 629, 630, 639, 643], "held": 6, "name": [6, 7, 17, 18, 21, 25, 26, 34, 35, 37, 40, 50, 51, 56, 58, 75, 77, 79, 82, 83, 84, 85, 86, 117, 118, 120, 121, 123, 127, 133, 135, 139, 140, 142, 145, 147, 148, 149, 150, 151, 153, 156, 157, 158, 161, 162, 164, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 207, 211, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 229, 231, 232, 233, 235, 237, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 273, 274, 276, 277, 280, 295, 300, 302, 311, 316, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 345, 346, 347, 348, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 390, 392, 393, 394, 395, 396, 397, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 411, 412, 413, 581, 586, 587, 589, 607, 614, 621, 622, 623, 624, 625, 628, 629, 630, 633, 636, 637, 638, 639, 643], "datacollector": [6, 34, 35, 37, 40, 46, 48, 49, 364, 623, 629, 640], "hi": [6, 86, 330, 335], "postprocess": [6, 37], "hook": [6, 33, 36, 38, 39, 43, 45, 50, 51, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 114, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 312, 313, 314, 323, 324, 325, 326, 328, 329, 330, 335, 336, 338, 344, 372, 373, 374, 375, 376, 377, 378, 379, 380, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 470, 591, 615], "itself": [6, 21, 37, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 215, 323, 324, 325, 326, 328, 329, 330, 335, 362, 368, 372, 373, 374, 375, 376, 377, 378, 379, 380, 571, 623, 626], "transfer": [6, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 51, 83, 84, 174, 323, 325, 326, 328, 329, 341, 372, 374, 376, 377, 380, 581, 582, 586, 587], "think": [6, 21, 84, 168, 170, 172, 173, 175, 181, 592, 593, 623, 636, 637, 643], "world": [6, 19, 24, 141, 321, 322, 331, 357, 396, 591, 600, 614, 625, 630, 636, 637, 638, 643], "engin": [6, 26, 50, 51, 153, 322, 331, 332, 335, 378, 581, 582, 584, 586, 587, 588, 593, 633, 638], "veri": [6, 12, 15, 18, 19, 22, 83, 84, 133, 134, 173, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 622, 626, 629, 633, 636, 638, 640, 642, 643], "kernel": [6, 286], "vs": [6, 278, 280, 324, 330, 335, 396], "forward": [6, 16, 27, 34, 35, 37, 40, 41, 42, 44, 46, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 213, 215, 216, 218, 219, 220, 223, 224, 225, 227, 228, 229, 230, 231, 232, 233, 234, 235, 238, 239, 241, 244, 247, 248, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 303, 305, 306, 307, 309, 310, 312, 313, 314, 315, 320, 322, 324, 330, 335, 336, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 381, 382, 383, 384, 385, 624, 638, 642], "format": [6, 20, 61, 63, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 89, 90, 97, 103, 111, 117, 120, 123, 127, 135, 147, 148, 149, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 201, 219, 223, 248, 263, 269, 270, 273, 275, 324, 328, 330, 335, 340, 373, 375, 378, 379, 388, 589, 593, 595, 596, 597, 607, 621, 622, 625, 626, 628, 630, 633, 642, 643], "quantiz": 6, "much": [6, 22, 27, 34, 35, 40, 64, 69, 80, 83, 84, 98, 99, 147, 156, 174, 323, 325, 326, 328, 329, 361, 364, 372, 374, 376, 377, 380, 623, 625, 626, 630, 636, 637, 638, 640, 643], "cannot": [6, 18, 22, 23, 26, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 56, 61, 63, 67, 69, 70, 87, 94, 95, 99, 101, 105, 106, 113, 117, 120, 123, 126, 127, 128, 131, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 227, 230, 249, 256, 268, 311, 345, 348, 364, 622, 623, 624, 625, 636, 637, 638], "dump": [6, 20, 30, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 88, 90, 92, 93, 94, 95, 107, 109, 113, 174, 188, 192, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 386, 387, 388, 630, 631, 636], "dict": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 90, 99, 105, 106, 117, 120, 123, 124, 125, 126, 127, 128, 135, 139, 140, 142, 145, 146, 147, 148, 149, 150, 151, 156, 157, 158, 159, 160, 161, 162, 164, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 200, 237, 239, 263, 268, 270, 276, 277, 278, 280, 286, 287, 288, 289, 290, 291, 292, 298, 303, 309, 322, 323, 324, 325, 326, 328, 329, 330, 335, 339, 341, 348, 354, 367, 368, 372, 373, 374, 375, 376, 377, 378, 379, 380, 388, 392, 393, 396, 397, 398, 404, 410, 412, 413, 414, 415, 416, 418, 419, 420, 437, 461, 462, 470, 509, 552, 553, 559, 560, 561, 563, 565, 566, 568, 571, 572, 574, 575, 576, 579, 580, 581, 582, 583, 585, 586, 587, 588, 589, 614, 621, 622, 623, 640, 642, 643], "who": 6, "activ": [6, 25, 26, 28, 286, 292, 297, 303, 347, 361, 364, 638, 642], "ask": [6, 22, 27, 75, 80, 99, 105, 106, 330, 388, 623, 624, 626, 627, 636, 637, 639, 643], "push": [6, 51, 379, 586], "intermedi": [6, 23, 34, 35, 218, 285, 296, 300, 302, 315, 324, 330, 335, 373, 375, 379, 621, 625, 639], "approach": [6, 21, 37, 64, 67, 69, 70, 83, 84, 174, 187, 219, 244, 323, 325, 326, 328, 329, 333, 334, 335, 368, 372, 374, 376, 377, 380, 415, 575, 582, 593, 621, 623, 628, 629, 636, 643], "intermediari": 6, "server": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 188], "fetch": [6, 38, 83, 84, 118, 119, 121, 122, 174, 239, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 586, 627, 639, 640], "tri": [6, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 322, 324, 330, 335, 340, 373, 375, 378, 379, 630], "account": [6, 92, 94, 113, 117, 120, 123, 126, 127, 128, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 215, 225, 304, 622, 624, 640, 643], "problem": [6, 18, 26, 27, 28, 37, 173, 375, 575, 622, 623, 624, 629, 636, 637, 638, 640, 643], "manner": [6, 127, 178, 248, 273, 621, 622, 623, 629, 635, 638, 640], "individu": [6, 7, 23, 37, 41, 42, 44, 46, 68, 85, 99, 111, 117, 120, 123, 127, 135, 139, 140, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 278, 324, 330, 335, 347, 361, 364, 373, 375, 378, 379, 621, 624, 637], "four": [6, 636, 637, 638], "somehow": 6, "refer": [6, 7, 17, 18, 21, 26, 27, 28, 30, 45, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 85, 117, 120, 123, 126, 127, 128, 132, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 237, 268, 269, 270, 277, 283, 296, 297, 304, 306, 307, 313, 314, 315, 323, 324, 325, 326, 328, 329, 330, 335, 345, 348, 355, 356, 357, 358, 364, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 563, 565, 566, 568, 569, 571, 574, 575, 576, 580, 581, 582, 588, 620, 621, 623, 625, 627, 628, 629, 630, 636, 637, 640], "initi": [6, 23, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 55, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 92, 94, 111, 117, 120, 123, 127, 135, 145, 146, 147, 148, 151, 156, 157, 158, 159, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 218, 237, 244, 248, 263, 270, 273, 278, 279, 280, 284, 299, 310, 322, 323, 324, 325, 326, 327, 328, 329, 330, 333, 334, 335, 338, 345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 396, 398, 561, 562, 563, 565, 566, 567, 568, 569, 571, 572, 573, 574, 576, 579, 580, 581, 582, 585, 586, 587, 588, 593, 614, 621, 622, 624, 626, 627, 629, 633, 636, 638, 643], "cast": [6, 34, 35, 37, 40, 41, 42, 44, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 85, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 133, 134, 135, 142, 143, 145, 146, 147, 148, 151, 153, 156, 157, 158, 159, 160, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 227, 228, 230, 231, 232, 233, 235, 238, 239, 241, 247, 248, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 273, 274, 275, 276, 277, 278, 323, 324, 325, 326, 328, 329, 330, 335, 340, 347, 361, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 636, 643], "destin": [6, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 218, 227, 228, 230, 237, 268, 270, 273, 277, 323, 324, 325, 326, 328, 329, 330, 335, 348, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 388, 413, 414, 470], "actual": [6, 17, 18, 21, 23, 26, 33, 36, 38, 39, 43, 45, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 276, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 550, 586, 589, 593, 621, 623, 625, 636, 637, 638], "through": [6, 12, 17, 18, 21, 22, 23, 24, 27, 34, 35, 37, 39, 40, 41, 44, 46, 48, 49, 51, 56, 58, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 117, 118, 119, 120, 123, 126, 127, 128, 131, 133, 134, 135, 138, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 182, 183, 188, 215, 225, 227, 230, 249, 280, 285, 303, 322, 323, 325, 326, 328, 329, 335, 338, 339, 341, 342, 343, 362, 372, 374, 376, 377, 380, 381, 382, 383, 384, 399, 564, 567, 569, 570, 573, 581, 614, 621, 622, 623, 624, 626, 628, 635, 636, 637, 638, 639, 640, 643], "els": [6, 118, 119, 183, 216, 306, 614, 621, 622, 623, 624, 633, 634, 636, 637, 638, 639], "runnabl": 6, "repositori": [6, 26, 77, 78, 79, 82, 161, 162, 636, 637], "weight_sync_standalon": 6, "standalon": [6, 281, 282, 283, 625, 627], "weight_sync_collector": 6, "outsid": [6, 22, 37, 228, 268, 630, 636, 637, 638], "simplifi": [6, 48, 51, 64, 207, 327, 627, 638, 640], "init_on_send": [6, 563, 565, 566, 568, 571, 574, 575, 576, 580, 582, 588], "model_id": [6, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 562, 563, 564, 565, 566, 567, 568, 569, 571, 572, 573, 574, 575, 576, 577, 579, 580, 581, 582, 583, 585, 587, 588], "kwarg": [6, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 54, 56, 57, 58, 60, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 90, 92, 93, 94, 95, 97, 98, 99, 105, 106, 107, 109, 111, 113, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 200, 206, 207, 213, 214, 216, 223, 241, 248, 250, 259, 263, 268, 269, 270, 272, 274, 275, 277, 279, 281, 282, 283, 284, 285, 286, 288, 289, 290, 291, 294, 295, 296, 298, 299, 300, 301, 302, 303, 308, 310, 311, 312, 315, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 392, 393, 395, 396, 397, 402, 410, 414, 415, 552, 553, 558, 559, 560, 563, 565, 566, 568, 571, 574, 576, 577, 580, 582, 588, 614, 623, 625, 637], "side": [6, 18, 23, 186, 187, 193, 194, 200, 304, 324, 563, 565, 566, 568, 571, 574, 576, 580, 581, 582, 588, 643], "init_on_work": [6, 563, 565, 566, 568, 571, 574, 576, 580, 582, 588], "get_send": [6, 563, 565, 566, 568, 571, 574, 576, 580, 582, 588], "get_receiv": [6, 563, 565, 566, 568, 571, 574, 576, 580, 582, 588], "here": [6, 7, 18, 19, 21, 23, 26, 27, 28, 29, 34, 35, 46, 81, 82, 111, 117, 120, 121, 122, 123, 127, 131, 135, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 191, 219, 268, 395, 593, 621, 622, 623, 624, 625, 626, 627, 629, 631, 636, 637, 638, 640, 642, 643], "nn": [6, 17, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 65, 83, 84, 85, 117, 118, 119, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 165, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 224, 229, 231, 239, 248, 263, 269, 270, 273, 275, 281, 282, 283, 285, 286, 288, 289, 290, 291, 295, 297, 298, 299, 300, 302, 303, 305, 310, 311, 320, 323, 324, 325, 326, 328, 329, 330, 335, 337, 338, 339, 340, 341, 342, 343, 345, 346, 348, 349, 350, 352, 353, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 466, 557, 563, 565, 566, 568, 571, 572, 574, 579, 580, 582, 585, 587, 588, 600, 621, 622, 623, 624, 625, 627, 628, 631, 635, 636, 637, 638, 639, 642], "mp": [6, 41, 42, 44, 75, 76, 77, 78, 79, 80, 81, 82, 124, 277, 278, 563, 564, 568, 580, 582, 588], "weight_upd": [6, 33, 34, 36, 37, 38, 39, 43, 45, 46, 48, 49, 50, 51, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 593], "multiprocessweightsyncschem": [6, 34, 35], "sharedmemweightsyncschem": [6, 563, 565, 566, 568, 570, 571, 574, 578, 580, 582, 584, 586, 588], "linear": [6, 21, 34, 35, 37, 40, 46, 48, 49, 65, 83, 84, 85, 117, 118, 119, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 239, 248, 263, 269, 270, 273, 275, 281, 282, 283, 285, 286, 288, 289, 290, 291, 298, 299, 303, 305, 310, 311, 313, 314, 320, 323, 324, 325, 326, 328, 329, 330, 335, 337, 338, 339, 340, 343, 345, 346, 348, 349, 350, 352, 353, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 557, 600, 622, 635, 639, 642], "state_dict": [6, 34, 35, 37, 40, 46, 48, 49, 50, 51, 83, 84, 85, 87, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 268, 270, 277, 278, 323, 324, 325, 326, 328, 329, 330, 335, 348, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 412, 561, 565, 566, 568, 571, 574, 580, 582, 588, 589, 621, 622, 643], "pipe": [6, 34, 35, 37, 40, 48, 147, 563, 564, 565, 568, 572, 574, 575, 576, 580, 582, 588], "parent_pip": 6, "child_pip": 6, "send_async": [6, 572, 579, 585, 587], "wait_async": [6, 572, 579, 585, 587], "block": [6, 49, 51, 86, 91, 116, 132, 173, 175, 184, 191, 201, 322, 562, 570, 572, 578, 579, 584, 585, 586, 587, 593, 621, 624, 625, 628, 629, 636, 640], "timeout": [6, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 147, 182, 188, 190, 191, 195, 322, 324, 330, 335, 562, 564, 567, 569, 570, 573, 575, 577, 578, 581, 583, 584, 586, 614], "001": [6, 7, 539, 540, 545, 548, 549, 570, 578, 584, 586, 621, 638], "were": [6, 26, 34, 35, 37, 39, 40, 41, 42, 44, 46, 66, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 147, 156, 237, 347, 364, 562, 564, 570, 578, 584, 586, 593, 595, 623, 636, 640], "appli": [6, 7, 10, 21, 22, 23, 33, 36, 37, 43, 45, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 227, 228, 229, 231, 232, 233, 234, 235, 238, 239, 240, 241, 243, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 273, 274, 276, 277, 295, 318, 323, 324, 325, 326, 328, 329, 330, 335, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 386, 403, 405, 562, 567, 569, 570, 572, 573, 578, 579, 584, 585, 586, 587, 593, 621, 622, 623, 629, 633, 636, 638, 642, 643], "auto": [6, 16, 50, 86, 94, 113, 123, 128, 214, 215, 270, 276, 310, 346, 348, 354, 363, 365, 367, 368, 369, 396, 398, 575, 576, 588, 636, 637], "registr": [6, 7, 39, 396, 575, 576, 591, 622], "shared_schem": 6, "auto_regist": [6, 575, 576], "lazi": [6, 22, 83, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 173, 174, 176, 177, 178, 248, 273, 323, 325, 326, 328, 329, 342, 343, 372, 374, 376, 377, 380, 422, 423, 424, 575, 576, 621, 622, 627, 629, 635, 640, 643], "parent_pipe2": 6, "child_pipe2": 6, "automat": [6, 7, 18, 19, 20, 22, 24, 31, 39, 51, 54, 68, 71, 72, 82, 83, 84, 86, 92, 94, 106, 113, 117, 118, 119, 120, 123, 126, 127, 128, 135, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 172, 173, 174, 176, 177, 178, 189, 215, 227, 230, 244, 263, 276, 278, 300, 302, 322, 323, 324, 325, 326, 328, 329, 330, 333, 334, 335, 337, 338, 339, 341, 372, 374, 376, 377, 380, 386, 399, 403, 410, 414, 470, 570, 575, 576, 578, 584, 586, 588, 595, 600, 614, 621, 623, 624, 626, 627, 636, 637, 638, 640, 642], "shared_send": 6, "weights_td": 6, "from_modul": [6, 83, 84, 174, 323, 324, 325, 326, 328, 329, 330, 335, 340, 343, 372, 374, 376, 377, 380, 413, 576, 642], "seamlessli": [6, 19, 168, 189, 593, 600, 634, 638], "tensordictmodul": [6, 17, 21, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 65, 117, 118, 119, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 218, 224, 239, 281, 282, 283, 285, 295, 300, 302, 311, 312, 315, 321, 324, 330, 335, 338, 339, 340, 342, 343, 344, 346, 348, 349, 353, 354, 356, 357, 358, 359, 360, 362, 365, 367, 368, 369, 373, 375, 379, 381, 382, 383, 384, 404, 466, 557, 600, 621, 623, 624, 628, 631, 635, 636, 637, 638, 639, 643], "cartpol": [6, 7, 18, 20, 22, 30, 117, 120, 121, 122, 123, 124, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 215, 216, 219, 224, 256, 262, 277, 338, 386, 622, 624, 627, 629, 630, 631, 640, 643], "observation_spec": [6, 17, 18, 19, 85, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197, 213, 216, 219, 220, 221, 222, 223, 226, 227, 228, 230, 231, 234, 236, 237, 238, 239, 241, 244, 246, 248, 250, 252, 256, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 276, 277, 278, 300, 302, 378, 551, 557, 621, 623, 628, 635, 636, 637, 638, 643], "observ": [6, 7, 10, 16, 17, 18, 19, 21, 22, 27, 34, 35, 37, 40, 46, 48, 49, 65, 75, 76, 77, 78, 79, 80, 81, 82, 85, 87, 89, 90, 97, 99, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 133, 134, 135, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197, 205, 210, 212, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 231, 232, 234, 236, 237, 238, 239, 241, 242, 244, 245, 246, 250, 251, 252, 253, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 276, 277, 278, 281, 282, 283, 285, 287, 288, 289, 290, 291, 292, 295, 299, 300, 302, 306, 307, 309, 310, 311, 313, 315, 320, 321, 337, 338, 339, 345, 346, 347, 348, 349, 350, 352, 353, 354, 357, 360, 361, 364, 365, 366, 367, 368, 369, 378, 381, 382, 383, 384, 385, 386, 388, 414, 415, 466, 557, 593, 600, 601, 622, 623, 624, 625, 626, 627, 628, 630, 631, 635, 636, 637, 638, 640, 642, 643], "action_spec": [6, 17, 18, 19, 21, 34, 35, 37, 40, 41, 42, 44, 46, 48, 85, 117, 118, 119, 120, 123, 127, 133, 134, 135, 141, 147, 148, 149, 150, 151, 152, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 213, 216, 219, 223, 227, 228, 230, 239, 241, 244, 250, 253, 269, 270, 271, 272, 295, 311, 314, 337, 339, 346, 348, 350, 352, 365, 367, 368, 369, 378, 557, 600, 621, 622, 623, 624, 625, 627, 628, 629, 631, 635, 636, 637, 638, 639, 640, 642, 643], "in_kei": [6, 7, 20, 21, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 65, 68, 75, 76, 77, 78, 79, 80, 81, 82, 85, 117, 118, 119, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 205, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 281, 282, 283, 285, 294, 295, 300, 302, 311, 320, 324, 327, 330, 335, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 359, 360, 361, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 381, 382, 383, 384, 387, 388, 463, 465, 466, 467, 473, 476, 477, 478, 479, 480, 481, 485, 486, 487, 488, 489, 492, 493, 494, 495, 496, 497, 498, 499, 501, 503, 504, 505, 506, 507, 510, 511, 512, 513, 514, 516, 517, 518, 520, 521, 522, 524, 525, 528, 529, 530, 531, 532, 533, 534, 535, 557, 600, 621, 622, 623, 624, 625, 627, 628, 631, 634, 635, 636, 637, 638, 639, 640, 642, 643], "out_kei": [6, 7, 21, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 65, 68, 75, 76, 77, 78, 79, 80, 81, 82, 85, 117, 118, 119, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 205, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 281, 282, 283, 285, 294, 296, 300, 302, 311, 312, 320, 324, 327, 330, 335, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 353, 354, 359, 360, 361, 364, 365, 366, 367, 368, 373, 375, 378, 379, 381, 382, 383, 384, 386, 388, 404, 463, 465, 466, 467, 473, 476, 477, 478, 479, 480, 481, 485, 486, 487, 488, 489, 492, 493, 494, 495, 496, 497, 498, 499, 501, 503, 504, 505, 506, 507, 510, 511, 512, 513, 514, 516, 517, 518, 520, 521, 522, 523, 524, 525, 526, 528, 529, 530, 531, 532, 533, 534, 535, 557, 600, 621, 622, 623, 624, 625, 627, 631, 634, 635, 636, 637, 638, 639, 640, 642, 643], "action": [6, 7, 10, 16, 17, 18, 19, 22, 27, 28, 34, 35, 37, 40, 46, 48, 49, 63, 65, 75, 76, 77, 78, 79, 80, 81, 82, 85, 98, 99, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 133, 134, 135, 138, 139, 140, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 210, 212, 213, 216, 222, 223, 224, 227, 228, 229, 230, 231, 232, 234, 235, 237, 239, 241, 242, 243, 244, 246, 250, 251, 253, 257, 261, 263, 267, 269, 270, 271, 272, 276, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294, 295, 296, 297, 299, 300, 302, 303, 304, 309, 310, 311, 312, 314, 315, 317, 318, 320, 324, 330, 335, 337, 338, 339, 341, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 381, 382, 383, 384, 385, 403, 414, 415, 466, 472, 557, 561, 593, 600, 601, 602, 604, 621, 622, 623, 625, 626, 627, 628, 633, 634, 635, 636, 637, 639, 642, 643], "create_env_fn": [6, 7, 34, 35, 37, 40, 41, 42, 44, 46, 124, 147, 156, 416, 418, 419, 420, 437, 470, 621, 642], "64": [6, 21, 68, 75, 80, 83, 84, 174, 219, 252, 288, 289, 298, 300, 302, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 461, 600, 614, 621, 622, 623, 624, 625, 627, 631, 635, 638, 640, 642, 643], "1000": [6, 23, 37, 48, 67, 87, 92, 93, 98, 105, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 219, 277, 284, 299, 310, 339, 341, 415, 525, 621, 622, 623, 624, 625, 627, 629, 631, 634, 638, 639, 640], "weight_sync_schem": [6, 32, 34, 35, 37, 39, 40, 41, 42, 44, 46, 48, 413, 414, 416, 418, 419, 420, 470, 593], "enumer": [6, 34, 35, 37, 46, 48, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 67, 70, 71, 72, 73, 74, 85, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 370, 373, 375, 378, 379, 621, 622, 623, 624, 631, 636, 640, 642], "everi": [6, 17, 27, 34, 35, 36, 37, 40, 48, 49, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 107, 117, 118, 119, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 261, 262, 277, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 303, 305, 306, 307, 309, 310, 312, 313, 314, 324, 330, 335, 336, 338, 344, 347, 361, 362, 364, 373, 375, 378, 379, 410, 621, 622, 623, 624, 626, 627, 636, 637, 638], "new_weight": [6, 189], "frequent": [6, 27, 614, 640], "192": [6, 139, 140], "zero": [6, 18, 22, 23, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 92, 94, 98, 99, 105, 106, 111, 113, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 210, 216, 218, 220, 224, 227, 229, 230, 244, 250, 253, 260, 278, 289, 290, 291, 298, 299, 300, 302, 304, 310, 312, 323, 324, 325, 326, 328, 329, 330, 335, 341, 345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 575, 624, 625, 634, 640, 642, 643], "extrem": [6, 30, 147, 156, 345, 347, 361, 364, 366, 375], "fast": [6, 26, 28, 93, 118, 119, 210, 251, 365, 614, 621, 622, 623, 642], "ideal": [6, 23, 168, 224, 244, 375, 634, 638], "determin": [6, 22, 34, 35, 36, 64, 69, 76, 83, 84, 98, 99, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 161, 162, 163, 168, 169, 170, 172, 173, 174, 176, 177, 178, 181, 184, 248, 275, 310, 323, 324, 325, 326, 328, 329, 330, 335, 348, 372, 374, 375, 376, 377, 380, 622, 627, 636, 637], "dictionari": [6, 32, 33, 34, 35, 37, 40, 41, 42, 43, 44, 46, 48, 49, 56, 83, 84, 85, 86, 99, 103, 105, 106, 117, 120, 123, 126, 127, 128, 135, 139, 140, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 200, 237, 263, 268, 270, 278, 323, 324, 325, 326, 328, 329, 330, 335, 339, 341, 348, 354, 367, 368, 372, 373, 374, 375, 376, 377, 378, 379, 380, 396, 404, 412, 559, 560, 561, 575, 576, 622, 623, 626, 628, 636, 638, 643], "advanc": [6, 10, 22, 46, 64, 67, 69, 70, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 322, 396, 591, 626, 629, 640], "per": [6, 7, 19, 20, 23, 34, 35, 37, 40, 41, 42, 44, 46, 49, 77, 85, 98, 99, 105, 111, 131, 133, 134, 147, 149, 150, 194, 222, 242, 256, 286, 297, 299, 322, 331, 338, 364, 375, 388, 390, 393, 395, 410, 412, 414, 415, 470, 559, 560, 572, 588, 593, 621, 622, 623, 624, 625, 627, 628, 631, 636, 637, 640, 642], "11": [6, 29, 52, 63, 92, 93, 94, 98, 106, 113, 124, 212, 224, 266, 593], "deprec": [6, 34, 35, 37, 39, 46, 52, 57, 58, 60, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 268, 270, 277, 323, 324, 325, 326, 328, 329, 330, 335, 345, 347, 348, 350, 353, 354, 355, 360, 361, 364, 365, 366, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 591, 643], "soon": [6, 117, 120, 123, 127, 135, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "prefer": [6, 18, 22, 34, 35, 40, 44, 52, 64, 67, 69, 70, 105, 106, 117, 151, 157, 179, 249, 257, 364, 368, 406, 623, 636, 637, 640, 642], "mechan": [6, 23, 33, 34, 35, 36, 37, 38, 40, 43, 45, 46, 48, 49, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 270, 322, 324, 330, 335, 373, 375, 378, 379, 577, 586, 587, 593, 614, 622, 628, 638], "accommod": [6, 18, 19, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 614, 626, 627], "deploy": [6, 625], "facilit": [6, 18, 26, 247, 248, 263, 273, 275, 281, 282, 283, 621, 624, 627, 638], "weightupdaterbas": [6, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51], "base": [6, 10, 12, 16, 19, 21, 22, 23, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 69, 70, 71, 72, 73, 74, 80, 83, 84, 98, 99, 102, 108, 111, 112, 114, 115, 117, 118, 119, 120, 123, 127, 131, 133, 134, 135, 141, 142, 143, 147, 148, 151, 156, 157, 158, 161, 168, 169, 170, 172, 173, 174, 175, 176, 177, 178, 179, 183, 186, 187, 189, 192, 193, 197, 202, 203, 210, 216, 223, 224, 228, 253, 267, 269, 270, 271, 273, 274, 278, 281, 300, 302, 322, 323, 324, 325, 326, 328, 329, 330, 335, 345, 346, 348, 349, 350, 352, 353, 354, 356, 360, 364, 365, 366, 367, 368, 369, 372, 374, 376, 377, 380, 381, 382, 383, 384, 385, 395, 396, 397, 410, 414, 421, 425, 435, 436, 438, 442, 471, 527, 568, 572, 574, 575, 576, 582, 583, 584, 586, 588, 591, 600, 607, 609, 614, 621, 622, 624, 626, 627, 628, 630, 633, 634, 636, 637, 638, 640, 643], "logic": [6, 21, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 86, 636], "tailor": [6, 176, 642], "well": [6, 7, 15, 16, 17, 20, 21, 22, 27, 46, 52, 64, 67, 69, 70, 71, 85, 99, 103, 107, 114, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 269, 270, 288, 313, 314, 324, 330, 335, 341, 362, 364, 368, 373, 375, 378, 379, 381, 385, 621, 622, 624, 625, 626, 627, 628, 630, 639, 640, 642, 643], "even": [6, 17, 21, 23, 27, 30, 35, 41, 42, 44, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 87, 92, 93, 94, 95, 99, 105, 107, 109, 113, 117, 120, 123, 124, 127, 131, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 211, 215, 621, 623, 626, 633, 636, 637, 638, 643], "vanillaweightupdat": 6, "assum": [6, 20, 22, 25, 33, 34, 35, 36, 37, 43, 45, 46, 50, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 69, 70, 71, 72, 73, 74, 76, 78, 80, 81, 82, 89, 90, 97, 105, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 183, 204, 218, 221, 226, 234, 248, 249, 256, 263, 270, 273, 275, 285, 300, 302, 344, 350, 354, 355, 367, 378, 388, 621, 623, 635, 638], "divers": [6, 23, 147, 156, 330], "abl": [6, 17, 21, 22, 117, 138, 149, 150, 151, 157, 300, 302, 621, 623, 624, 627, 635, 636, 637, 638, 640], "leav": [6, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 67, 71, 72, 73, 74, 83, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 174, 176, 177, 178, 211, 257, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 621, 629, 640], "untouch": [6, 75, 80, 83, 84, 85, 171, 172, 174, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 216, 223, 227, 228, 232, 239, 242, 250, 251, 257, 261, 267, 269, 271, 278, 323, 325, 326, 328, 329, 372, 374, 376, 377, 378, 380], "particularli": [6, 22, 64, 67, 68, 69, 70, 83, 84, 87, 174, 189, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 412, 415, 614, 625, 642, 643], "benefici": 6, "involv": [6, 83, 84, 126, 128, 129, 139, 140, 153, 174, 216, 219, 268, 300, 302, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 626, 628], "architectur": [6, 23, 187, 292, 322, 330, 600, 614, 628, 636, 637, 642], "special": [6, 7, 18, 56, 58, 73, 74, 83, 84, 174, 178, 323, 324, 325, 326, 328, 329, 330, 335, 372, 374, 376, 377, 380, 570, 571, 572, 574, 593, 594, 598, 611, 614, 621, 624, 625, 643], "retriev": [6, 13, 17, 22, 33, 34, 35, 36, 39, 40, 43, 45, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 103, 105, 106, 117, 120, 123, 126, 127, 128, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 183, 186, 187, 193, 194, 199, 210, 220, 228, 231, 244, 323, 325, 326, 328, 329, 335, 338, 339, 341, 344, 345, 346, 347, 348, 350, 361, 364, 365, 367, 368, 369, 372, 374, 375, 376, 377, 380, 381, 382, 383, 384, 396, 397, 398, 561, 622, 623, 627, 638, 643], "infrastructur": [6, 16, 19, 195, 636, 637], "power": [7, 16, 30, 622], "top": [7, 21, 23, 85, 111, 118, 119, 133, 134, 226, 269, 324, 330, 335, 485, 600, 627], "hydra": [7, 414, 576, 615], "dataclass": [7, 71, 83, 84, 174, 323, 325, 326, 328, 329, 362, 372, 374, 376, 377, 380], "compos": [7, 10, 21, 64, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 100, 101, 102, 111, 112, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 224, 225, 237, 252, 268, 269, 270, 277, 324, 330, 335, 338, 348, 357, 367, 373, 375, 378, 379, 388, 482, 600, 621, 622, 623, 624, 625, 629, 633, 635, 637, 639, 640, 642, 643], "overridden": [7, 22, 33, 36, 38, 39, 43, 45, 75, 77, 78, 80, 81, 82, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 312, 313, 314, 336, 338, 344, 381, 383, 384, 624, 636], "advantag": [7, 21, 22, 27, 176, 183, 298, 345, 347, 361, 364, 366, 373, 375, 378, 381, 382, 383, 384, 385, 621, 622, 623, 624, 637, 638, 643], "glimps": 7, "go": [7, 19, 21, 26, 93, 138, 147, 225, 249, 253, 569, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "sota": [7, 34, 35, 141, 235, 366, 400, 552, 621, 622, 642], "ppo_train": 7, "help": [7, 17, 23, 71, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 231, 324, 330, 331, 332, 335, 345, 347, 361, 364, 366, 373, 375, 378, 379, 414, 592, 621, 622, 623, 624, 633, 634, 636, 637], "overrid": [7, 22, 33, 36, 38, 39, 43, 45, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 67, 71, 72, 73, 74, 75, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 215, 293, 324, 330, 335, 373, 375, 378, 379, 388, 561, 587, 633], "reproduc": [7, 17, 21, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 219, 237, 414, 415, 470, 621, 623, 625, 637], "command": [7, 25, 26, 29, 151, 157, 158, 188, 623, 633, 636, 637, 638, 643], "minim": [7, 16, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 390, 593, 640], "config": [7, 25, 26, 188, 248, 275, 287, 292, 309, 414, 551, 552, 553, 555, 558, 576, 614], "yaml": 7, "training_env": 7, "env_nam": [7, 25, 117, 118, 120, 121, 123, 124, 126, 127, 129, 133, 135, 136, 142, 147, 148, 151, 153, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 621, 623, 643], "part": [7, 12, 20, 21, 22, 23, 27, 75, 77, 78, 80, 81, 82, 85, 99, 117, 118, 120, 123, 127, 133, 135, 145, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 218, 244, 253, 256, 320, 324, 330, 335, 373, 375, 378, 379, 400, 561, 614, 621, 623, 624, 625, 631, 636, 638, 643], "tell": [7, 18, 23, 26, 117, 149, 150, 268, 584, 621, 624, 629, 636, 637], "includ": [7, 12, 16, 19, 21, 23, 26, 28, 46, 62, 71, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 107, 109, 113, 117, 120, 123, 127, 135, 141, 145, 146, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 234, 237, 262, 268, 270, 277, 278, 300, 302, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 345, 348, 354, 362, 364, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 396, 397, 403, 414, 470, 550, 593, 595, 599, 605, 621, 622, 623, 624, 625, 633, 634, 636, 637, 638, 640, 643], "target": [7, 23, 27, 46, 85, 117, 120, 123, 124, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 262, 322, 324, 330, 335, 340, 341, 345, 346, 347, 348, 349, 350, 352, 354, 355, 358, 361, 362, 363, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 381, 382, 383, 384, 385, 409, 415, 550, 556, 557, 624, 625, 631, 636, 638], "proper": [7, 22, 23, 25, 26, 187, 322, 381, 382, 383, 384, 593, 622, 623, 633, 636, 637, 638, 640], "specifi": [7, 15, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 117, 120, 123, 127, 135, 139, 140, 147, 148, 149, 150, 151, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 224, 226, 227, 228, 230, 256, 259, 262, 267, 271, 272, 280, 305, 322, 323, 324, 325, 326, 328, 329, 330, 333, 334, 335, 340, 341, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 395, 398, 572, 579, 585, 587, 614, 621, 623, 624, 625, 629, 633, 636], "select": [7, 23, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 120, 139, 140, 149, 150, 152, 161, 162, 168, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 227, 228, 230, 231, 232, 233, 234, 235, 238, 239, 241, 242, 243, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 295, 311, 322, 324, 330, 335, 373, 375, 378, 379, 408, 621, 625, 626, 634, 636, 640], "syntax": [7, 614, 621], "dmcontrol": [7, 16, 18, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "brax": [7, 16, 27, 117, 118, 119, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 251, 440, 626, 643], "reward": [7, 10, 17, 18, 19, 22, 34, 35, 37, 75, 76, 77, 78, 79, 80, 81, 82, 85, 98, 99, 111, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 133, 134, 135, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 151, 153, 154, 155, 156, 157, 158, 159, 161, 162, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 210, 212, 213, 216, 217, 222, 223, 227, 228, 230, 231, 232, 237, 239, 240, 241, 242, 246, 250, 251, 253, 254, 255, 256, 257, 258, 260, 261, 262, 267, 269, 270, 271, 272, 274, 275, 277, 278, 300, 321, 338, 345, 346, 348, 349, 350, 352, 353, 354, 357, 360, 362, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 381, 382, 383, 384, 385, 402, 403, 404, 407, 414, 415, 561, 596, 615, 621, 622, 623, 624, 625, 626, 630, 633, 634, 636, 637, 638, 642, 643], "mlp": [7, 141, 281, 286, 288, 289, 290, 291, 295, 298, 300, 302, 350, 352, 462, 600, 622, 625, 627, 628, 631, 635, 639, 642], "convnet": [7, 288, 289, 298, 461, 600, 624, 625, 627, 642], "writer": [7, 10, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 87, 91, 94, 99, 101, 105, 111, 112, 113, 116, 428, 429, 434, 435, 623, 640], "logger": [7, 20, 30, 386, 388, 390, 391, 392, 393, 394, 395, 403, 410, 414, 415, 457, 458, 459, 460, 470, 557, 561, 591, 615, 622, 636], "assign": [7, 17, 23, 34, 35, 40, 50, 54, 72, 83, 84, 85, 98, 99, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 268, 270, 323, 324, 325, 326, 328, 329, 330, 333, 334, 335, 348, 349, 350, 352, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 588, 614, 623, 627, 633, 636, 637, 640], "locat": [7, 15, 26, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 207, 226, 231, 244, 255, 278, 301, 318, 319, 322, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 411, 413, 614, 621, 622, 623, 630, 636, 637, 640], "batched_env": 7, "transformed_env": [7, 223, 270, 626], "base_env": [7, 21, 22, 117, 119, 120, 123, 127, 128, 134, 135, 146, 147, 148, 151, 156, 157, 158, 160, 168, 169, 170, 173, 176, 177, 178, 192, 212, 213, 216, 222, 224, 225, 227, 229, 230, 239, 246, 250, 252, 258, 261, 263, 264, 268, 270, 388, 399, 439, 593, 621, 622, 623, 625, 636, 639, 642, 643], "transform0": 7, "noop_reset": 7, "transform1": [7, 21], "step_count": [7, 34, 35, 37, 117, 120, 123, 127, 133, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 225, 261, 519, 623, 624, 625, 626, 631], "noop": [7, 243, 502], "30": [7, 18, 20, 67, 78, 85, 105, 106, 182, 215, 243, 313, 314, 386, 390, 393, 395, 457, 502, 614, 629, 634, 637, 638, 640], "max_step": [7, 16, 17, 30, 111, 117, 120, 123, 127, 135, 139, 140, 141, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 173, 176, 177, 178, 181, 261, 268, 386, 519, 626, 627, 628, 630, 631, 636, 637, 642, 643], "step_count_kei": [7, 224, 225, 261, 519], "num_work": [7, 34, 35, 43, 45, 75, 76, 77, 78, 79, 80, 81, 82, 142, 147, 156, 192, 418, 419, 437, 563, 565, 568, 580, 582, 588, 621, 622], "_partial_": [7, 416, 418, 419, 420, 422, 423, 424, 425, 428, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 461, 462, 463, 464, 465, 466, 467, 468, 469, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549], "construct": [7, 18, 24, 52, 64, 67, 68, 69, 70, 71, 75, 85, 117, 120, 123, 124, 126, 127, 135, 147, 148, 149, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 227, 230, 278, 300, 302, 314, 324, 330, 335, 341, 373, 375, 378, 379, 410, 600, 615, 622, 623, 624, 627, 636, 638, 640, 643], "repeat": [7, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 133, 134, 135, 142, 143, 147, 148, 151, 153, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 179, 183, 192, 268, 293, 322, 324, 330, 335, 526, 623, 636, 637, 638], "layer": [7, 244, 277, 286, 288, 289, 294, 297, 300, 302, 303, 306, 307, 322, 331, 332, 336, 344, 462, 581, 586, 587, 593, 595, 596, 600, 622, 623, 624, 625, 627, 636, 639], "episod": [7, 18, 75, 76, 77, 78, 79, 80, 81, 82, 99, 105, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 210, 215, 253, 256, 262, 381, 414, 622, 626, 631, 636, 637, 640], "track": [7, 20, 23, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 70, 83, 84, 98, 99, 104, 120, 174, 176, 189, 256, 265, 277, 278, 310, 323, 325, 326, 328, 329, 338, 372, 374, 376, 377, 378, 380, 393, 402, 412, 414, 470, 593, 618, 622, 624, 626, 629, 637, 638, 640], "count": [7, 18, 20, 22, 34, 35, 37, 40, 48, 123, 124, 224, 261, 268, 278, 310, 322, 404, 410, 550, 593, 621, 622, 623, 624, 640, 643], "composit": [7, 10, 17, 18, 19, 21, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 84, 85, 103, 109, 116, 117, 120, 123, 125, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 204, 211, 213, 216, 227, 228, 229, 230, 232, 237, 239, 242, 250, 251, 257, 261, 263, 267, 268, 269, 271, 278, 284, 337, 339, 341, 343, 344, 345, 364, 378, 593, 621, 623, 627, 633, 638], "combin": [7, 23, 99, 186, 193, 194, 322, 368, 622, 625, 630, 640, 642], "maximum": [7, 17, 23, 32, 34, 35, 36, 37, 40, 41, 42, 44, 46, 53, 72, 87, 92, 93, 94, 95, 98, 99, 113, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 183, 229, 254, 261, 262, 264, 317, 318, 319, 324, 327, 330, 335, 344, 346, 348, 353, 354, 360, 362, 363, 367, 373, 375, 379, 388, 406, 414, 415, 470, 570, 578, 584, 586, 593, 614, 621, 622, 623, 624, 627, 636, 637, 640], "length": [7, 34, 35, 44, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 75, 80, 84, 99, 105, 106, 109, 117, 120, 123, 127, 133, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 183, 194, 212, 219, 240, 249, 277, 286, 288, 290, 292, 303, 320, 323, 324, 330, 335, 337, 340, 378, 379, 400, 406, 593, 621, 623, 624, 629, 631, 633, 638, 640, 643], "concept": [7, 21, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 593, 622, 633, 640], "nest": [7, 16, 17, 19, 22, 52, 56, 58, 67, 68, 83, 84, 85, 92, 93, 94, 97, 113, 117, 120, 123, 126, 127, 128, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 202, 211, 219, 261, 264, 268, 269, 323, 324, 325, 326, 328, 329, 330, 335, 338, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 399, 403, 615, 622, 623, 625, 637, 638, 640, 642], "deep": [7, 22, 28, 219, 240, 288, 289, 290, 291, 294, 310, 345, 348, 367, 621, 636], "insid": [7, 21, 83, 84, 147, 174, 228, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 614, 643], "factori": [7, 28, 34, 35, 37, 40, 41, 42, 44, 46, 65, 67, 69, 70, 71, 192, 241, 397, 416, 437, 461, 462, 621], "onc": [7, 22, 26, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 68, 80, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 215, 242, 253, 263, 270, 284, 310, 323, 324, 325, 326, 328, 329, 330, 335, 338, 372, 373, 374, 375, 376, 377, 378, 379, 380, 407, 563, 568, 580, 582, 588, 614, 622, 623, 624, 627, 630, 638, 640, 643], "variabl": [7, 18, 20, 22, 23, 26, 27, 39, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 75, 77, 78, 81, 82, 84, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 133, 134, 135, 139, 140, 143, 144, 145, 146, 147, 148, 151, 153, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 173, 176, 177, 178, 183, 194, 198, 200, 223, 265, 269, 278, 281, 282, 283, 300, 302, 324, 330, 335, 362, 365, 399, 593, 622, 634], "interpol": [7, 68, 252, 510, 622, 625], "flag": [7, 17, 19, 27, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 117, 120, 123, 127, 135, 139, 140, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 172, 173, 175, 176, 177, 178, 181, 238, 310, 636, 637, 638, 639], "script": [7, 26, 77, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 399, 557, 561, 615, 621, 622, 625, 630, 636, 637, 638, 640], "discov": [7, 23], "It": [7, 17, 20, 21, 22, 23, 26, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 93, 103, 111, 116, 117, 120, 123, 127, 129, 135, 141, 142, 147, 148, 149, 150, 151, 156, 157, 158, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 200, 210, 213, 216, 218, 219, 231, 237, 239, 244, 249, 262, 268, 270, 276, 278, 284, 288, 290, 296, 297, 299, 310, 312, 313, 314, 322, 323, 324, 325, 326, 328, 329, 330, 335, 338, 341, 345, 346, 347, 348, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 386, 395, 396, 403, 404, 414, 463, 569, 571, 575, 576, 582, 591, 592, 593, 595, 621, 622, 624, 625, 626, 636, 637, 638, 639, 640, 642, 643], "print": [7, 18, 22, 25, 26, 34, 35, 37, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 98, 99, 105, 106, 111, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 133, 134, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 161, 162, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 201, 204, 209, 210, 211, 212, 215, 216, 219, 220, 224, 225, 227, 228, 229, 230, 238, 244, 250, 251, 253, 256, 261, 263, 264, 265, 266, 277, 278, 281, 282, 283, 286, 288, 289, 290, 291, 292, 295, 298, 299, 300, 302, 303, 304, 305, 308, 310, 311, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 336, 337, 338, 339, 340, 341, 343, 362, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 386, 396, 557, 584, 593, 614, 622, 623, 624, 625, 626, 627, 628, 629, 630, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "someth": [7, 85, 117, 120, 123, 127, 135, 138, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 592, 622, 623, 638, 643], "policy_model": [7, 585], "tanh_norm": 7, "value_model": [7, 356, 358], "policy_network": 7, "value_network": [7, 349, 350, 352, 353, 355, 360, 367, 381, 382, 383, 384, 607, 621, 623, 625, 628, 631, 636], "tensor": [7, 10, 12, 14, 17, 18, 19, 22, 27, 34, 35, 37, 40, 41, 42, 44, 46, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 90, 91, 92, 93, 94, 95, 97, 98, 99, 101, 103, 105, 106, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 133, 134, 135, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 202, 203, 204, 210, 211, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 227, 229, 230, 231, 232, 234, 237, 238, 240, 244, 246, 248, 249, 250, 251, 253, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 271, 272, 273, 275, 277, 278, 281, 282, 283, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 303, 304, 305, 308, 309, 310, 311, 312, 317, 318, 319, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 348, 349, 350, 352, 353, 354, 357, 358, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 403, 424, 436, 575, 593, 595, 621, 622, 623, 624, 625, 626, 627, 636, 637, 638, 642, 643], "without_replac": 7, "round_robin": 7, "adam": [7, 170, 318, 415, 539, 621, 622, 623, 624, 625, 628, 631, 636, 637, 638], "wandb": [7, 388, 392, 395, 410, 414, 460, 470, 630, 642], "out_featur": [7, 85, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 281, 286, 288, 289, 290, 291, 295, 297, 298, 300, 302, 303, 324, 330, 335, 340, 350, 352, 373, 375, 378, 379, 462, 465, 466, 467, 621, 624, 625, 627, 628, 631, 642], "in_featur": [7, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 281, 286, 288, 289, 290, 291, 298, 303, 324, 330, 335, 340, 350, 352, 373, 375, 378, 379, 461, 462, 465, 466, 467, 625, 627, 628], "num_cel": [7, 281, 286, 288, 289, 290, 291, 297, 298, 300, 302, 303, 461, 462, 465, 466, 467, 622, 623, 624, 625, 627, 628, 631, 636, 637, 642], "128": [7, 75, 76, 80, 106, 118, 119, 133, 134, 191, 289, 292, 614, 622, 624, 625, 631, 636, 639, 640], "num_cal": 7, "state_valu": [7, 282, 283, 320, 347, 353, 360, 361, 364, 365, 367, 381, 382, 383, 384, 621, 637], "loss_modul": [7, 347, 361, 362, 364, 373, 375, 379, 409, 410, 413, 414, 415, 470, 556, 557, 607, 615, 621, 622, 623, 636, 637, 640], "100000": [7, 415, 622], "1024": [7, 46, 65, 292, 396, 640], "lr": [7, 415, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 621, 622, 623, 624, 631, 636, 637, 638], "actor_network": [7, 345, 346, 347, 348, 349, 351, 353, 354, 360, 361, 363, 364, 365, 366, 367, 368, 369, 373, 375, 379, 409, 413, 414, 415, 469, 470, 607, 621, 623, 628, 636, 637], "critic_network": [7, 345, 347, 361, 364, 366, 413, 414, 469, 470, 623, 637], "exp_nam": [7, 30, 388, 389, 390, 393, 394, 395, 457, 459, 460, 557, 622, 630, 631], "my_experi": [7, 398], "0001": [7, 278, 297, 305, 465, 536, 539, 543], "chang": [7, 18, 21, 24, 26, 30, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 69, 70, 71, 72, 73, 74, 75, 83, 84, 85, 87, 92, 93, 94, 95, 99, 104, 105, 107, 109, 113, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 223, 227, 228, 230, 232, 239, 242, 250, 251, 257, 261, 267, 269, 270, 271, 277, 278, 323, 324, 325, 326, 328, 329, 330, 335, 345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 414, 415, 593, 614, 621, 624, 634, 636, 637, 638, 639, 640, 643], "rate": [7, 23, 30, 75, 277, 278, 414, 622, 623, 636, 637], "multirun": 7, "01": [7, 215, 244, 278, 310, 345, 347, 361, 364, 375, 536, 538, 540, 546, 547], "8": [7, 25, 26, 56, 58, 67, 75, 76, 77, 78, 79, 80, 81, 82, 98, 99, 105, 106, 117, 118, 119, 120, 121, 122, 123, 127, 135, 145, 146, 147, 148, 151, 156, 157, 158, 159, 168, 169, 170, 173, 176, 177, 178, 212, 215, 224, 225, 262, 265, 271, 278, 281, 282, 283, 286, 288, 289, 298, 303, 339, 340, 343, 360, 621, 622, 638, 640, 642], "my_custom_config": 7, "under": [7, 17, 18, 21, 23, 46, 56, 58, 75, 76, 77, 78, 80, 81, 82, 85, 117, 120, 121, 122, 123, 126, 127, 128, 129, 135, 147, 148, 151, 153, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 238, 239, 240, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 295, 296, 311, 312, 324, 330, 335, 337, 339, 340, 341, 362, 373, 375, 378, 379, 381, 382, 383, 384, 385, 388, 410, 593, 621, 622, 627, 636, 638, 643], "hood": [7, 17, 46, 75, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 638], "configstor": 7, "regist": [7, 20, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 117, 120, 123, 126, 127, 128, 135, 147, 148, 151, 156, 157, 158, 159, 160, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 199, 207, 210, 227, 230, 231, 256, 268, 270, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 312, 313, 314, 323, 324, 325, 326, 328, 329, 330, 335, 336, 338, 344, 345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 386, 388, 396, 397, 398, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 570, 575, 576, 578, 584, 585, 586, 587, 593, 614, 615, 621, 623, 626, 640], "type": [7, 10, 21, 22, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 82, 83, 84, 85, 117, 120, 123, 127, 135, 138, 141, 144, 147, 148, 149, 150, 151, 156, 157, 158, 165, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 199, 202, 203, 207, 208, 210, 212, 216, 219, 223, 227, 228, 231, 232, 237, 239, 242, 248, 250, 251, 257, 261, 263, 267, 268, 269, 270, 271, 273, 275, 277, 278, 284, 286, 295, 303, 316, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 339, 340, 341, 345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 386, 396, 397, 398, 416, 437, 461, 462, 468, 559, 575, 614, 621, 622, 623, 625, 629, 633, 636, 637, 638, 640, 643], "safeti": [7, 34, 35, 40, 141, 147, 156, 278, 614, 633], "id": [7, 26, 33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 48, 49, 51, 52, 68, 99, 105, 106, 117, 120, 123, 126, 127, 135, 147, 148, 151, 156, 157, 158, 159, 160, 168, 169, 170, 173, 175, 176, 177, 178, 198, 310, 322, 330, 348, 365, 391, 395, 460, 581, 629, 640], "config_stor": 7, "cs": 7, "gymenvconfig": 7, "batchedenvconfig": 7, "tanhnormalmodelconfig": [7, 463], "inherit": [7, 21, 22, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 191, 362, 623, 636, 637], "envs_lib": 7, "envlibsconfig": 7, "mycustomenvconfig": 7, "_target_": [7, 416, 418, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 439, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 459, 460, 461, 462, 465, 466, 467, 469, 470, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549], "str": [7, 32, 34, 35, 37, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 92, 93, 94, 95, 98, 99, 111, 113, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 133, 135, 139, 140, 142, 144, 145, 146, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 162, 163, 164, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 208, 211, 215, 219, 231, 237, 238, 239, 241, 248, 252, 261, 262, 265, 267, 268, 270, 271, 273, 275, 276, 277, 280, 286, 287, 288, 289, 290, 291, 294, 295, 296, 298, 300, 302, 303, 304, 305, 309, 311, 312, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 337, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 418, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 439, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 459, 460, 461, 462, 465, 466, 467, 469, 470, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 551, 561, 562, 563, 564, 565, 566, 567, 568, 569, 571, 573, 574, 575, 576, 577, 580, 581, 582, 583, 586, 587, 588, 614, 622, 623, 625, 633], "my_modul": 7, "mycustomenv": 7, "myenv": [7, 147, 216, 227, 230], "custom_param": 7, "float": [7, 18, 21, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 54, 56, 63, 64, 68, 69, 72, 80, 83, 84, 85, 98, 99, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 212, 215, 219, 223, 227, 230, 239, 240, 244, 248, 253, 254, 255, 262, 263, 266, 269, 270, 273, 275, 278, 284, 285, 293, 297, 301, 303, 304, 313, 314, 317, 319, 322, 323, 324, 325, 326, 328, 329, 330, 335, 340, 344, 345, 346, 347, 348, 352, 353, 354, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 407, 414, 415, 426, 462, 465, 469, 470, 481, 499, 501, 503, 511, 512, 513, 520, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 562, 564, 567, 569, 570, 573, 575, 577, 578, 581, 583, 584, 586, 593, 621, 622, 640, 643], "__post_init__": 7, "self": [7, 18, 21, 34, 35, 37, 40, 41, 42, 44, 46, 56, 58, 83, 84, 85, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 213, 215, 216, 218, 219, 220, 223, 224, 225, 227, 228, 230, 231, 232, 233, 235, 238, 239, 241, 247, 248, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 273, 274, 275, 276, 277, 280, 284, 299, 300, 302, 320, 323, 324, 325, 326, 328, 329, 330, 335, 339, 340, 345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 586, 587, 593, 614, 621, 633, 638, 642], "super": [7, 18, 21, 85, 141, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 213, 215, 216, 218, 219, 220, 223, 224, 225, 227, 228, 230, 231, 232, 233, 235, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 320, 346, 348, 349, 354, 360, 365, 367, 368, 369, 378, 587, 621, 638, 642], "my_custom": 7, "begin": [7, 23, 34, 35, 37, 40, 41, 42, 44, 46, 99, 105, 215, 399, 625, 626, 627, 628, 629, 630, 631, 633], "gradual": 7, "add": [7, 10, 16, 21, 23, 25, 46, 56, 58, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 91, 93, 98, 101, 111, 112, 115, 116, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 219, 237, 239, 267, 270, 300, 302, 324, 330, 335, 345, 371, 373, 375, 378, 379, 405, 414, 470, 593, 604, 614, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 636, 637, 638, 640, 642], "leverag": [7, 36, 46, 117, 120, 123, 127, 135, 138, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 322, 593, 621, 637, 643], "sparingli": 7, "correctli": [7, 22, 26, 85, 87, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 593], "duplic": [7, 85, 104, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 346, 348, 350, 355, 360, 362, 365, 367, 368, 369, 373, 375, 378, 379], "As": [7, 19, 22, 23, 67, 68, 69, 70, 71, 75, 117, 120, 123, 127, 135, 138, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 253, 293, 341, 381, 621, 622, 623, 624, 625, 626, 628, 629, 636, 637, 638, 639, 640, 642, 643], "sac": [7, 354, 365, 367, 415, 615], "td3": [7, 368, 369], "expand": [7, 27, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 92, 105, 106, 174, 216, 263, 293, 323, 325, 326, 328, 329, 340, 343, 346, 348, 360, 362, 365, 367, 368, 369, 372, 373, 374, 375, 376, 377, 379, 380, 636, 637, 638, 640, 642], "sactrainerconfig": 7, "td3trainerconfig": 7, "addit": [7, 16, 19, 22, 23, 33, 36, 43, 45, 62, 76, 83, 84, 85, 117, 120, 123, 124, 127, 135, 147, 148, 151, 156, 157, 158, 161, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 223, 248, 263, 267, 269, 270, 273, 275, 284, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 335, 338, 340, 347, 362, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 386, 388, 588, 611, 614, 621, 622, 625, 626, 636, 637, 640], "design": [7, 10, 16, 17, 18, 22, 33, 43, 45, 62, 63, 83, 84, 85, 103, 109, 116, 117, 120, 123, 127, 135, 139, 140, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 219, 237, 249, 268, 270, 278, 322, 323, 324, 325, 326, 328, 329, 330, 335, 345, 346, 347, 348, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 569, 571, 600, 607, 614, 621, 622, 623, 626, 627, 628, 633, 634, 635, 636, 637, 638, 640, 642, 643], "maintain": [7, 18, 24, 28, 34, 35, 62, 187, 190, 199, 219, 278, 354, 367, 580, 593, 614, 638], "circumst": 8, "cudnn": [8, 300, 302, 624, 625], "7": [8, 10, 25, 29, 63, 64, 67, 69, 98, 99, 106, 117, 120, 123, 127, 135, 139, 140, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 175, 176, 177, 178, 212, 215, 224, 225, 262, 265, 278, 285, 286, 289, 303, 322, 330, 335, 588, 621, 640, 642], "5x": 8, "batch_first": [8, 624], "input": [8, 9, 16, 17, 18, 20, 21, 22, 23, 34, 35, 37, 40, 41, 42, 44, 46, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 85, 93, 95, 108, 114, 117, 120, 123, 127, 135, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 151, 156, 157, 158, 159, 160, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 200, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 237, 238, 239, 241, 242, 246, 247, 248, 249, 250, 251, 253, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 285, 286, 288, 289, 290, 291, 294, 295, 296, 299, 300, 302, 303, 305, 310, 311, 312, 313, 314, 318, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 403, 407, 550, 557, 563, 565, 566, 568, 571, 574, 576, 580, 582, 588, 593, 597, 607, 621, 622, 623, 624, 625, 626, 633, 636, 637, 638, 642, 643], "fix": [8, 27, 147, 263, 346, 348, 363, 367, 614, 622, 631, 638, 643], "5": [8, 10, 18, 19, 34, 35, 37, 40, 48, 52, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 75, 84, 85, 87, 105, 106, 111, 117, 120, 123, 124, 127, 133, 134, 135, 139, 140, 142, 147, 148, 151, 154, 155, 156, 157, 158, 161, 162, 168, 170, 173, 175, 176, 177, 178, 181, 191, 212, 215, 216, 218, 224, 225, 240, 253, 260, 261, 262, 268, 278, 285, 286, 288, 289, 294, 295, 297, 298, 301, 303, 306, 311, 318, 319, 322, 331, 332, 335, 338, 344, 361, 364, 366, 368, 369, 375, 386, 461, 462, 465, 467, 547, 593, 614, 620, 621, 622, 625, 627, 631, 636, 637, 638, 640, 641, 642, 643], "condit": [9, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 176, 181, 224, 225, 262, 277, 295, 296, 311, 312, 338, 483, 591, 593, 621, 636, 638, 640], "met": [9, 224, 225, 636, 638], "packedsequ": 9, "dropout": [9, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 270, 285, 300, 302, 303, 324, 330, 335, 373, 375, 378, 379, 462, 624], "comprehens": [10, 16, 414, 415, 593, 595, 600, 607, 614], "around": [10, 24, 26, 40, 69, 70, 86, 117, 120, 123, 127, 135, 141, 147, 148, 151, 152, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 183, 338, 341, 381, 593, 621, 622, 633, 637, 643], "central": [10, 12, 33, 39, 43, 45, 322, 397, 614, 621, 622, 626, 636, 637, 640], "offer": [10, 16, 17, 20, 22, 26, 117, 118, 119, 120, 123, 127, 133, 134, 135, 139, 140, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 268, 386, 600, 621, 622, 625, 626, 628, 629, 636, 638, 640, 643], "memmap": [10, 83, 84, 92, 94, 147, 156, 174, 277, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 388, 390, 406, 582, 583, 585], "compress": [10, 87, 88], "priorit": [10, 27, 64, 69, 98, 99, 348, 349, 350, 352, 353, 354, 360, 365, 367, 368, 369, 426, 576, 621, 622, 629, 642], "mix": [10, 249, 614, 621, 636, 637], "match": [10, 19, 21, 22, 25, 27, 32, 34, 35, 37, 40, 41, 42, 44, 46, 47, 48, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 89, 109, 117, 120, 121, 122, 123, 124, 126, 127, 128, 129, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 216, 217, 219, 220, 221, 222, 223, 226, 227, 228, 229, 231, 232, 234, 236, 238, 239, 240, 241, 242, 244, 246, 250, 251, 252, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 277, 278, 286, 293, 295, 300, 302, 303, 311, 317, 320, 323, 324, 325, 326, 328, 329, 330, 335, 337, 339, 340, 341, 344, 346, 347, 348, 354, 361, 363, 364, 365, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 406, 413, 621, 623, 625, 635, 637, 638, 640, 643], "arbitrari": [10, 16, 17, 22, 53, 63, 67, 117, 120, 123, 127, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 215, 621, 622, 638, 640], "lazymemmapstorag": [10, 12, 15, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 99, 105, 106, 218, 219, 422, 621, 622, 624, 629, 636, 639, 640], "prioritizedsampl": [10, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 99, 350, 355, 426, 621, 640], "max_siz": [10, 64, 67, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 87, 92, 93, 94, 95, 105, 106, 107, 111, 113, 422, 423, 424, 425, 436, 623, 629], "1000000": [10, 75, 76, 77, 78, 79, 80, 81, 82, 396, 415, 536, 615], "max_capac": [10, 98, 99, 426, 621, 640], "alpha": [10, 64, 69, 98, 99, 286, 288, 289, 290, 291, 298, 346, 348, 354, 363, 365, 367, 368, 426, 536, 546, 621, 640, 642], "beta": [10, 23, 64, 69, 98, 99, 353, 360, 361, 379, 426, 539, 540, 541, 543, 544, 545, 549, 621, 622, 640, 642], "batch_siz": [10, 17, 18, 19, 22, 27, 34, 35, 37, 48, 51, 52, 56, 62, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 93, 94, 98, 99, 100, 105, 106, 111, 113, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 133, 134, 135, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 207, 210, 211, 212, 216, 218, 219, 223, 227, 230, 231, 232, 237, 246, 250, 251, 253, 257, 260, 261, 263, 269, 270, 271, 281, 282, 283, 285, 292, 293, 294, 295, 296, 299, 300, 302, 310, 311, 312, 320, 323, 324, 325, 326, 328, 329, 330, 335, 337, 338, 339, 340, 341, 343, 344, 345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 388, 396, 400, 406, 412, 414, 415, 428, 435, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 475, 593, 614, 621, 622, 623, 624, 629, 633, 634, 636, 637, 638, 640, 642, 643], "256": [10, 37, 48, 139, 140, 237, 292, 593, 622, 623, 625, 636, 637], "randn": [10, 22, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 92, 93, 94, 99, 105, 106, 113, 117, 174, 186, 204, 218, 244, 281, 282, 283, 285, 287, 288, 292, 294, 295, 304, 305, 308, 309, 311, 320, 323, 325, 326, 328, 329, 336, 337, 339, 340, 343, 344, 345, 346, 348, 349, 350, 352, 353, 354, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 379, 380, 381, 382, 383, 384, 408, 461, 462, 465, 466, 467, 625, 640, 642, 643], "32": [10, 47, 56, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 106, 127, 134, 154, 155, 161, 162, 178, 183, 190, 191, 192, 219, 237, 286, 287, 288, 289, 291, 292, 298, 303, 306, 307, 309, 386, 396, 460, 461, 462, 465, 466, 467, 614, 622, 624, 625, 627, 628, 638, 639, 640, 642, 643], "compressedliststorag": [10, 88], "compressedliststoragecheckpoint": 10, "flatstoragecheckpoint": 10, "h5storagecheckpoint": 10, "immutabledatasetwrit": [10, 75, 76, 77, 78, 79, 80, 81, 82], "liststorag": [10, 12, 64, 65, 67, 68, 69, 70, 93, 425, 640], "lazystackstorag": [10, 85, 423], "liststoragecheckpoint": 10, "nestedstoragecheckpoint": 10, "storagecheckpointerbas": [10, 67, 107], "storageensembl": [10, 68, 103, 433], "storageensemblecheckpoint": 10, "tensorstorag": [10, 12, 67, 75, 76, 77, 78, 79, 80, 81, 82, 92, 98, 99, 111, 114, 436, 629, 640], "tensorstoragecheckpoint": [10, 92], "prioritizedslicesampl": [10, 640], "randomsampl": [10, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 427, 621, 636], "samplerensembl": [10, 68], "samplerwithoutreplac": [10, 85, 111, 430, 623, 637, 640], "slicesamplerwithoutreplac": [10, 105, 432, 640], "ataridqnexperiencereplai": 10, "d4rlexperiencereplai": 10, "gendgrlexperiencereplai": 10, "minariexperiencereplai": [10, 75, 76, 77, 79, 80, 81, 82], "openmlexperiencereplai": 10, "openxexperiencereplai": [10, 388], "robosetexperiencereplai": [10, 105, 106], "vd4rlexperiencereplai": 10, "tensorspec": [10, 17, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 72, 73, 74, 85, 117, 120, 123, 127, 135, 141, 147, 148, 151, 152, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 211, 212, 216, 217, 219, 220, 221, 222, 223, 226, 227, 228, 229, 231, 232, 234, 236, 238, 239, 240, 241, 242, 244, 246, 250, 251, 252, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 277, 278, 284, 295, 296, 299, 310, 311, 312, 314, 337, 339, 340, 341, 342, 344, 346, 348, 350, 353, 354, 365, 367, 368, 369, 378, 591, 638], "binari": [10, 18, 26, 63, 159, 213, 217, 295, 296, 311, 312, 350, 353, 354, 633], "bound": [10, 18, 23, 46, 56, 72, 85, 117, 120, 123, 127, 135, 147, 148, 151, 152, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 222, 243, 277, 284, 295, 296, 299, 310, 311, 312, 313, 314, 324, 330, 335, 337, 339, 340, 341, 344, 345, 346, 348, 349, 360, 364, 365, 367, 368, 369, 373, 375, 378, 379, 621, 622, 623, 625, 636, 638, 642, 643], "categor": [10, 19, 21, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 117, 118, 119, 120, 123, 126, 127, 128, 129, 132, 133, 134, 135, 139, 140, 142, 143, 145, 146, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 173, 176, 177, 178, 211, 212, 213, 231, 250, 295, 296, 308, 311, 312, 324, 339, 350, 353, 354, 472, 624], "discretetensorspec": 10, "lazystackedcompositespec": 10, "multicategor": [10, 60, 61], "multidiscretetensorspec": 10, "multionehot": [10, 59, 60, 350, 353, 354], "nontensor": [10, 17, 84, 173, 178, 237, 271], "onehot": [10, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 71, 72, 73, 74, 118, 119, 126, 128, 129, 132, 133, 134, 142, 143, 145, 146, 153, 159, 160, 295, 311, 350, 352, 353, 354], "unbound": [10, 18, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 71, 73, 74, 83, 84, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 183, 204, 213, 216, 227, 230, 250, 263, 320, 323, 325, 326, 328, 329, 337, 340, 343, 366, 372, 374, 376, 377, 380, 593, 633, 638, 640], "unboundedcontinu": [10, 72, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 204, 250, 263, 343], "unboundeddiscret": [10, 72, 148, 237], "offlin": [11, 27, 34, 35, 37, 40, 41, 42, 44, 46, 75, 77, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 346, 352, 353, 360, 368, 378, 395, 460, 591, 607, 626, 639, 640], "wide": [12, 22, 24, 642], "give": [12, 22, 26, 56, 58, 69, 77, 84, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 219, 347, 361, 364, 592, 614, 621, 622, 625, 636, 637, 638, 639, 642], "abil": [12, 15, 362, 638, 640], "panel": [12, 623], "almost": [12, 278, 304, 624], "physic": [12, 25, 26, 90, 147, 148, 153, 621, 636, 637, 638], "theori": 12, "crude": 12, "made": [12, 18, 22, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 67, 71, 72, 73, 74, 75, 85, 87, 92, 93, 94, 95, 107, 109, 113, 117, 120, 123, 126, 127, 128, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 263, 269, 310, 324, 330, 335, 350, 362, 373, 375, 378, 379, 463, 621, 622, 624, 636, 637, 639, 640, 642], "ineffici": [12, 23], "contigu": [12, 18, 27, 54, 56, 72, 77, 80, 81, 93, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 204, 237, 240, 263, 271, 638, 640, 642], "indic": [12, 17, 18, 20, 22, 27, 34, 35, 36, 37, 40, 41, 42, 44, 46, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 91, 98, 99, 101, 103, 104, 105, 106, 111, 112, 115, 116, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 133, 134, 135, 142, 143, 147, 148, 151, 153, 156, 157, 158, 161, 162, 168, 169, 170, 173, 174, 176, 177, 178, 211, 212, 219, 220, 224, 261, 262, 263, 264, 270, 278, 280, 286, 303, 304, 310, 311, 312, 323, 325, 326, 328, 329, 338, 345, 346, 347, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 379, 380, 551, 561, 592, 614, 623, 624, 625, 629, 630, 631, 638, 640, 643], "collate_fn": [12, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 168, 169, 170, 173, 640, 642], "__init__": [12, 18, 21, 26, 85, 123, 141, 159, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 209, 213, 215, 216, 218, 219, 220, 223, 224, 225, 227, 228, 230, 231, 232, 233, 235, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 293, 320, 332, 346, 348, 349, 354, 360, 365, 367, 368, 369, 378, 614, 638, 643], "dtype": [14, 18, 19, 22, 34, 35, 37, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 94, 98, 99, 105, 106, 113, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 133, 134, 135, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 207, 210, 211, 212, 213, 216, 217, 223, 224, 227, 228, 229, 230, 231, 232, 237, 239, 240, 244, 246, 248, 250, 251, 253, 257, 260, 261, 263, 265, 266, 269, 270, 271, 273, 275, 281, 282, 283, 285, 294, 295, 296, 300, 302, 310, 311, 312, 320, 322, 323, 324, 325, 326, 328, 329, 330, 335, 337, 338, 339, 340, 341, 343, 345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 486, 524, 581, 586, 587, 589, 593, 625, 633, 634, 635, 638, 640, 642, 643], "domain": [14, 16, 27, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 182, 204, 229, 237, 263, 271, 295, 296, 311, 312, 337, 339, 340, 341, 342, 343, 623, 628, 633, 636, 637, 638, 642, 643], "influenti": 15, "latenc": [15, 22, 614], "especi": [15, 17, 26, 27, 220, 324, 330, 335], "larger": [15, 23, 300, 302, 353, 360, 642], "volum": 15, "advis": [15, 30, 77, 630, 643], "due": [15, 22, 24, 32, 41, 42, 44, 52, 347, 364, 415, 588, 628, 639, 640, 643], "memorymappedtensor": [15, 75, 76, 77, 78, 79, 80, 81, 82, 92, 390, 629], "file": [15, 25, 26, 27, 75, 76, 77, 78, 80, 81, 82, 83, 84, 90, 161, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 387, 388, 390, 410, 414, 415, 470, 582, 583, 584, 591, 614, 620, 622, 636, 640, 641], "improv": [15, 23, 30, 50, 175, 190, 235, 345, 414, 625, 636, 637, 640], "failur": [15, 23, 175, 322, 347, 364, 375, 593], "recoveri": 15, "wrapper": [16, 17, 21, 40, 51, 69, 70, 83, 84, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 167, 168, 169, 170, 173, 174, 176, 177, 178, 183, 187, 276, 280, 285, 321, 323, 324, 325, 326, 327, 328, 329, 330, 332, 335, 338, 341, 372, 374, 376, 377, 380, 381, 393, 394, 395, 561, 589, 591, 600, 620, 623, 624, 626, 632, 633, 636, 637, 639, 641, 642, 643], "popular": [16, 22, 624, 628, 637], "framework": [16, 18, 23, 28, 47, 117, 118, 119, 120, 123, 127, 133, 134, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 593, 614, 633, 634, 642, 643], "jumanji": [16, 18, 117, 120, 123, 127, 133, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 446], "envbas": [16, 17, 18, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 85, 117, 120, 124, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 213, 216, 227, 230, 243, 250, 251, 269, 270, 277, 300, 302, 338, 378, 404, 551, 552, 553, 557, 559, 560, 561, 626], "foundat": [16, 18, 24, 149, 150, 421, 595, 623, 637], "unifi": [16, 322, 335, 593, 597, 634, 643], "output": [16, 17, 18, 19, 20, 21, 22, 23, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 64, 67, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 99, 105, 106, 117, 120, 121, 122, 123, 126, 127, 128, 129, 134, 135, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 200, 211, 216, 217, 219, 222, 223, 225, 226, 227, 228, 230, 232, 234, 237, 239, 242, 244, 248, 250, 251, 256, 257, 260, 261, 264, 265, 267, 269, 270, 271, 273, 275, 276, 278, 281, 284, 286, 287, 288, 289, 292, 294, 295, 296, 297, 300, 302, 303, 310, 311, 312, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 400, 593, 595, 597, 600, 607, 621, 622, 623, 624, 625, 626, 627, 630, 633, 634, 635, 636, 637, 638, 639, 642, 643], "transformedenv": [16, 21, 22, 30, 31, 85, 117, 120, 123, 124, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 212, 213, 216, 219, 222, 223, 225, 227, 230, 231, 232, 238, 239, 240, 243, 244, 246, 250, 251, 252, 253, 256, 257, 258, 261, 262, 263, 264, 268, 269, 277, 300, 302, 338, 378, 388, 399, 439, 593, 621, 622, 623, 624, 625, 626, 630, 631, 635, 636, 637, 638, 639, 640, 642, 643], "rewardsum": [16, 21, 85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 210, 269, 378, 514, 636, 637], "stepcount": [16, 85, 117, 120, 123, 127, 135, 139, 140, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 224, 225, 268, 269, 270, 285, 378, 519, 593, 621, 622, 623, 624, 625, 626, 631, 636, 637, 642], "parallel_env": [16, 150, 621, 642, 643], "100": [16, 34, 35, 37, 40, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 92, 94, 105, 106, 111, 117, 118, 119, 120, 123, 127, 133, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 222, 224, 231, 244, 253, 258, 261, 296, 304, 322, 324, 330, 335, 338, 373, 375, 378, 379, 388, 401, 415, 542, 557, 614, 622, 623, 625, 626, 628, 631, 635, 636, 637, 638, 640, 642, 643], "lock": [16, 56, 58, 83, 84, 117, 120, 123, 127, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 216, 225, 263, 277, 278, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 638], "partial": [16, 17, 34, 35, 37, 40, 48, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 218, 219, 262, 263, 264, 339, 410, 624], "invers": [16, 23, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 219, 227, 230, 232, 237, 241, 244, 251, 253, 265, 267, 269, 271, 347, 353, 360, 364, 375, 378, 638], "marlgroupmaptyp": [16, 139, 140, 145, 146, 149, 150, 159, 160, 161, 162, 164, 636], "check_marl_group": 16, "dynam": [16, 26, 34, 35, 37, 77, 80, 82, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 204, 353, 360, 396, 595, 600, 605, 623, 626, 638], "record": [16, 30, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 205, 212, 239, 324, 330, 335, 364, 373, 375, 378, 379, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 404, 415, 457, 459, 460, 557, 591, 615, 622, 623, 627, 631, 636], "dm": [17, 621, 643], "simul": [17, 18, 19, 20, 24, 26, 27, 71, 118, 119, 120, 129, 133, 134, 153, 161, 162, 168, 206, 315, 593, 621, 623, 625, 626, 630, 634, 636, 637], "box": [17, 19, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 126, 128, 362, 373, 375, 379, 633], "lib": [17, 18, 19, 24, 25, 26, 28, 29, 34, 35, 37, 40, 46, 47, 48, 49, 65, 85, 117, 120, 123, 124, 127, 132, 135, 139, 140, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 219, 222, 231, 238, 239, 244, 246, 251, 253, 256, 263, 269, 276, 277, 378, 386, 440, 441, 442, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 557, 621, 622, 623, 624, 635, 637, 639, 640, 642, 643], "hope": [17, 30], "imit": [17, 359], "parent": [17, 20, 21, 46, 62, 68, 71, 85, 109, 116, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 216, 219, 220, 223, 224, 225, 228, 231, 234, 235, 242, 244, 248, 256, 261, 262, 263, 264, 268, 269, 272, 273, 281, 300, 302, 324, 330, 335, 362, 364, 373, 375, 378, 379, 385, 386, 388, 417, 463, 464, 621, 629, 638, 642, 643], "subclass": [17, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 54, 56, 68, 72, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 214, 215, 269, 276, 284, 285, 287, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 312, 313, 314, 335, 336, 338, 340, 341, 342, 344, 362, 364, 587, 614, 622, 624, 629, 638, 640], "organis": [17, 81, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 270, 622], "attribut": [17, 19, 21, 22, 23, 26, 34, 35, 37, 40, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 117, 120, 123, 126, 127, 128, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 231, 242, 248, 270, 273, 277, 278, 323, 324, 325, 326, 328, 329, 330, 335, 341, 345, 346, 348, 349, 350, 352, 354, 355, 356, 359, 360, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 582, 621, 624, 638], "togeth": [17, 21, 30, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 93, 117, 120, 123, 127, 135, 138, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 219, 249, 260, 269, 281, 282, 283, 300, 302, 321, 588, 593, 622, 624, 626, 636], "live": [17, 22, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 231, 324, 330, 335, 373, 375, 378, 379, 490], "doe": [17, 18, 21, 22, 38, 41, 64, 69, 75, 76, 80, 83, 84, 85, 89, 90, 97, 99, 105, 107, 109, 116, 117, 120, 123, 127, 135, 139, 140, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 278, 292, 293, 300, 302, 323, 324, 325, 326, 328, 329, 330, 335, 342, 343, 345, 347, 355, 361, 362, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 410, 621, 622, 623, 624, 626, 629, 636, 638, 640, 643], "respons": [17, 20, 22, 27, 34, 35, 37, 39, 41, 44, 46, 48, 49, 99, 105, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 172, 173, 175, 176, 177, 178, 181, 184, 185, 188, 191, 201, 323, 325, 327, 328, 329, 330, 335, 375, 379, 410, 593, 595, 628, 629, 633, 634, 643], "just": [17, 22, 23, 83, 84, 109, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 132, 133, 134, 135, 138, 142, 143, 145, 146, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 168, 169, 170, 173, 174, 176, 177, 178, 211, 215, 222, 263, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 400, 593, 614, 621, 622, 623, 624, 625, 626, 627, 629, 633, 636, 637, 638, 640, 642, 643], "care": [17, 20, 21, 27, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 312, 313, 314, 336, 338, 344, 388, 621, 623, 625, 636, 637, 638, 640], "map": [17, 21, 27, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 92, 97, 98, 99, 117, 120, 123, 127, 135, 138, 139, 140, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 161, 162, 164, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 212, 216, 217, 219, 220, 221, 222, 223, 226, 227, 228, 229, 230, 231, 232, 234, 236, 237, 238, 239, 240, 241, 242, 244, 246, 250, 251, 252, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 276, 277, 278, 281, 282, 283, 295, 305, 311, 320, 321, 323, 324, 325, 326, 328, 329, 330, 335, 337, 339, 340, 341, 343, 344, 347, 348, 361, 364, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 404, 413, 414, 422, 470, 575, 576, 581, 582, 583, 586, 587, 589, 601, 621, 622, 623, 624, 627, 628, 639], "desir": [17, 18, 30, 34, 35, 37, 40, 48, 55, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 208, 214, 216, 223, 225, 244, 246, 248, 249, 263, 269, 270, 273, 275, 286, 293, 295, 296, 303, 311, 312, 323, 324, 325, 326, 328, 329, 330, 335, 337, 339, 340, 341, 372, 373, 374, 375, 376, 377, 378, 379, 380, 621, 625, 633, 636, 637, 638, 640], "parametr": [17, 305, 341, 346, 348, 353, 360, 367, 621, 623], "pair": [17, 22, 51, 76, 83, 84, 117, 120, 121, 122, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 253, 263, 268, 281, 300, 323, 325, 326, 328, 329, 339, 341, 354, 362, 367, 372, 373, 374, 375, 376, 377, 379, 380, 381, 382, 383, 384, 385, 580, 602, 621, 622, 623, 627, 628, 635, 638, 643], "state_spec": [17, 85, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 213, 223, 228, 241, 244, 269, 271, 272, 378, 638, 643], "empti": [17, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 95, 117, 120, 123, 127, 134, 135, 144, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 204, 227, 230, 248, 250, 264, 270, 273, 275, 278, 322, 323, 324, 325, 326, 328, 329, 330, 335, 340, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 392, 397, 575, 576, 614, 621, 638], "reward_spec": [17, 18, 19, 85, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 213, 216, 217, 222, 223, 227, 228, 230, 240, 241, 250, 254, 255, 256, 258, 260, 267, 269, 271, 272, 278, 378, 593, 623, 633, 636, 637, 638, 643], "done_spec": [17, 18, 19, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 211, 227, 228, 230, 231, 241, 250, 260, 267, 269, 271, 378, 636, 637, 638, 643], "termin": [17, 18, 19, 22, 26, 34, 35, 37, 40, 48, 65, 75, 76, 77, 78, 79, 80, 81, 82, 89, 90, 97, 105, 117, 120, 121, 122, 123, 126, 127, 128, 133, 134, 135, 139, 140, 145, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 161, 162, 168, 169, 170, 173, 176, 177, 178, 183, 211, 212, 215, 216, 231, 237, 250, 263, 271, 300, 302, 338, 342, 345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 381, 382, 383, 384, 385, 396, 397, 593, 614, 621, 622, 623, 633, 636, 637, 638, 642, 643], "input_spec": [17, 85, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 216, 223, 227, 228, 229, 242, 246, 250, 251, 256, 257, 260, 261, 262, 263, 267, 269, 270, 271, 274, 378, 623, 638], "full_action_spec": [17, 117, 120, 123, 127, 135, 145, 146, 147, 148, 151, 156, 157, 158, 159, 160, 168, 169, 170, 173, 176, 177, 178, 212, 228, 636, 637], "full_state_spec": [17, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 212, 228], "output_spec": [17, 19, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 223, 227, 228, 232, 239, 242, 250, 251, 257, 261, 267, 269, 270, 271, 278, 378, 638], "full_observation_spec": [17, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 176, 177, 178], "full_reward_spec": [17, 18, 19, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 216, 228, 250, 636, 637], "full_done_spec": [17, 18, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 211, 216, 228, 250, 636, 637], "carri": [17, 19, 46, 61, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 263, 278, 362, 373, 375, 379, 622, 624, 636, 637, 638, 640], "spec_lock": [17, 123], "arg": [17, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 54, 56, 57, 58, 60, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 92, 93, 94, 95, 99, 105, 106, 107, 109, 113, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 200, 201, 206, 212, 213, 214, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 237, 238, 239, 241, 242, 247, 248, 249, 250, 251, 253, 256, 257, 259, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 272, 273, 274, 275, 276, 277, 281, 282, 283, 284, 285, 286, 293, 294, 295, 296, 299, 300, 302, 303, 310, 311, 312, 315, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 335, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 395, 396, 397, 402, 406, 410, 414, 415, 561, 577, 614, 622, 625, 633], "modif": [17, 19, 22, 24, 56, 58, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 211, 234, 237, 324, 330, 335, 362, 373, 375, 378, 379, 593, 623, 638], "children": [17, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 56, 58, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "unlock": [17, 22, 56, 58, 83, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "set_spec_lock_": [17, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "reason": [17, 21, 22, 23, 27, 80, 85, 117, 120, 123, 127, 135, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 248, 273, 302, 324, 330, 335, 373, 375, 378, 379, 593, 621, 622, 623, 628, 629, 636, 638, 640], "cach": [17, 20, 34, 35, 40, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 99, 105, 117, 118, 119, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 192, 210, 215, 227, 230, 248, 269, 270, 275, 322, 401, 563, 565, 566, 568, 571, 574, 576, 580, 582, 588, 593], "modifi": [17, 18, 22, 26, 27, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 219, 223, 225, 234, 237, 239, 241, 248, 263, 269, 270, 273, 275, 278, 310, 323, 324, 325, 326, 328, 329, 330, 335, 340, 341, 372, 373, 374, 375, 376, 377, 378, 379, 380, 550, 593, 621, 622, 623, 625, 626, 636, 637, 638], "often": [17, 22, 27, 347, 362, 364, 373, 375, 379, 410, 621, 622, 626, 628, 638, 640, 643], "principl": [17, 593], "new_spec": 17, "eras": [17, 21, 22, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 99, 105, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 270], "relock": 17, "wa": [17, 22, 24, 26, 56, 58, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 88, 99, 104, 105, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 174, 176, 177, 178, 183, 211, 219, 237, 270, 323, 324, 325, 326, 328, 329, 330, 335, 345, 347, 361, 364, 366, 372, 374, 375, 376, 377, 380, 397, 564, 622, 623, 626, 627, 635, 636, 640, 642], "previous": [17, 23, 78, 397, 623, 643], "importantli": [17, 339, 341], "action_s": 17, "prealloc": [17, 22, 147, 156, 638], "With": [17, 83, 84, 133, 134, 138, 174, 262, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 396, 398, 576, 588, 622, 633, 635, 636, 637, 640, 643], "necessarili": [17, 22, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 643], "present": [17, 18, 19, 22, 48, 64, 65, 67, 68, 71, 75, 76, 80, 83, 84, 85, 98, 99, 104, 117, 120, 123, 126, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 211, 232, 253, 257, 263, 268, 270, 286, 287, 288, 289, 290, 291, 298, 300, 302, 309, 310, 323, 324, 325, 326, 328, 329, 330, 335, 338, 340, 341, 342, 343, 345, 346, 347, 348, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 561, 562, 621, 631, 635, 636, 637, 640, 642], "0s": [17, 75, 80, 263, 624], "stateless": [17, 22, 49, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 216, 225, 278, 333, 334, 362, 373, 375, 379, 386, 621, 626, 638, 643], "step_and_maybe_reset": [17, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 593, 626, 633], "next": [17, 18, 19, 23, 27, 34, 35, 37, 49, 52, 56, 58, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 89, 90, 97, 99, 105, 106, 111, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 133, 134, 135, 139, 140, 141, 145, 146, 147, 148, 151, 154, 155, 156, 157, 158, 159, 161, 162, 168, 169, 170, 173, 176, 177, 178, 181, 183, 186, 188, 190, 191, 193, 204, 210, 212, 215, 216, 218, 219, 224, 225, 227, 230, 231, 232, 237, 238, 239, 240, 242, 246, 250, 251, 253, 256, 257, 261, 263, 265, 268, 271, 276, 277, 278, 300, 302, 314, 315, 321, 338, 345, 346, 348, 349, 350, 352, 353, 354, 355, 360, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 381, 382, 383, 384, 385, 388, 403, 404, 407, 431, 432, 572, 579, 585, 587, 593, 614, 622, 624, 625, 627, 631, 633, 638, 639, 642, 643], "step_mdp": [17, 56, 58, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 300, 302, 624, 626, 638, 642, 643], "done_kei": [17, 18, 19, 52, 85, 89, 90, 97, 105, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 210, 215, 219, 231, 253, 261, 378, 490, 636, 637], "_reset": [17, 18, 22, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 211, 213, 215, 216, 219, 227, 230, 238, 250, 265, 636], "signal": [17, 34, 35, 37, 40, 52, 75, 76, 78, 80, 81, 82, 99, 105, 106, 111, 117, 120, 123, 127, 135, 139, 140, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 173, 175, 176, 177, 178, 211, 219, 225, 231, 240, 261, 264, 562, 586, 587, 621, 623, 636, 637, 640, 643], "stop": [17, 34, 35, 37, 40, 46, 48, 82, 99, 105, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 184, 324, 330, 335, 623, 629, 636, 637, 642, 643], "data_": [17, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "append": [17, 19, 20, 21, 27, 30, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 84, 86, 117, 120, 123, 124, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 180, 183, 193, 215, 222, 223, 242, 253, 263, 270, 276, 295, 300, 302, 311, 593, 595, 621, 622, 623, 624, 625, 633, 636, 637, 638, 639, 640, 642], "set_se": [17, 18, 34, 35, 37, 40, 46, 48, 49, 117, 118, 119, 120, 123, 127, 133, 134, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 215, 224, 225, 244, 251, 256, 262, 264, 270, 593, 625, 629, 631, 638, 642, 643], "seed": [17, 18, 34, 35, 37, 40, 46, 48, 49, 67, 68, 69, 70, 81, 117, 120, 123, 127, 135, 141, 147, 148, 149, 150, 151, 156, 157, 158, 161, 162, 163, 168, 169, 170, 173, 176, 177, 178, 179, 213, 216, 227, 230, 237, 250, 270, 386, 410, 414, 415, 470, 636], "determinist": [17, 34, 35, 37, 40, 41, 42, 44, 46, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 208, 223, 248, 263, 269, 270, 273, 275, 287, 297, 306, 314, 315, 324, 330, 335, 337, 339, 340, 341, 344, 346, 347, 362, 364, 373, 375, 378, 379, 404, 601, 621, 622, 623, 624, 625, 627, 628, 631, 636, 638, 642, 643], "preced": [17, 120, 219, 413, 624], "without": [17, 18, 19, 22, 26, 28, 33, 34, 35, 36, 37, 43, 45, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 76, 80, 83, 84, 85, 105, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 213, 215, 227, 230, 266, 269, 282, 283, 323, 324, 325, 326, 328, 329, 330, 333, 334, 335, 345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 396, 430, 432, 557, 562, 564, 567, 569, 572, 573, 575, 576, 579, 585, 587, 592, 614, 621, 622, 623, 625, 626, 627, 628, 629, 633, 634, 636, 637, 638, 640, 643], "risk": [17, 249], "overlap": [17, 69, 111], "mark": [17, 37, 82, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 265, 300, 302, 381, 383, 384, 629, 640], "trail": [17, 62, 175, 277, 633], "treat": [17, 21, 627, 628], "figur": [17, 21, 621, 623, 624, 637, 638, 643], "brief": [17, 623, 626, 628, 640], "entri": [17, 19, 21, 22, 34, 35, 40, 52, 56, 58, 76, 77, 78, 79, 81, 82, 83, 84, 85, 105, 106, 117, 120, 121, 122, 123, 126, 127, 128, 129, 135, 139, 140, 147, 148, 151, 153, 156, 157, 158, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 211, 215, 219, 221, 222, 225, 226, 227, 228, 230, 231, 234, 238, 240, 242, 244, 246, 248, 251, 253, 256, 258, 260, 261, 262, 263, 265, 268, 270, 272, 275, 277, 295, 300, 304, 311, 312, 322, 323, 324, 325, 326, 328, 329, 330, 335, 338, 346, 348, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 621, 623, 624, 626, 627, 628, 630, 636, 637, 638, 639, 640, 642, 643], "metaclass": [17, 123, 128], "flank": [17, 624], "dual": 17, "strictli": [17, 27, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 240, 268, 270, 324, 330, 335, 348, 367, 373, 375, 378, 379, 621, 623], "union": [17, 34, 37, 40, 44, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 248, 273, 275, 286, 287, 288, 289, 290, 291, 298, 303, 309, 322, 324, 330, 335, 340, 352, 354, 365, 373, 375, 378, 379, 406, 558, 561], "interpret": [17, 64, 65, 67, 68, 190, 191, 593, 614, 622], "truncat": [17, 18, 19, 22, 34, 35, 37, 40, 75, 76, 77, 78, 79, 80, 81, 82, 84, 89, 90, 97, 99, 105, 106, 117, 120, 121, 122, 123, 126, 127, 128, 135, 139, 140, 147, 148, 149, 150, 151, 156, 157, 158, 159, 161, 162, 168, 169, 170, 173, 176, 177, 178, 183, 211, 212, 231, 232, 237, 243, 250, 253, 257, 261, 263, 270, 271, 300, 302, 319, 328, 338, 381, 431, 432, 519, 621, 623, 626, 636, 643], "look": [17, 19, 22, 24, 26, 27, 83, 84, 85, 99, 117, 120, 123, 127, 135, 138, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 224, 237, 248, 249, 273, 323, 324, 325, 326, 328, 329, 330, 335, 339, 341, 342, 343, 372, 373, 374, 375, 376, 377, 378, 379, 380, 623, 624, 625, 626, 627, 628, 629, 630, 631, 636, 637, 638, 639, 640, 642, 643], "assess": [17, 22, 34, 35, 37, 40, 41, 42, 44, 46, 56, 58, 139, 140, 164, 173, 621], "split_trajectori": [17, 34, 35, 37, 40, 41, 42, 44, 46, 75, 80, 99, 105, 106], "adjac": [17, 52, 234, 338], "junction": 17, "miss": [17, 22, 23, 25, 26, 56, 85, 117, 120, 123, 127, 128, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 237, 268, 270, 276, 280, 324, 330, 335, 342, 343, 345, 348, 364, 367, 373, 375, 378, 379, 592, 614, 621, 624, 634], "context": [17, 19, 21, 24, 27, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 106, 117, 120, 123, 124, 127, 135, 144, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 263, 272, 300, 302, 324, 330, 335, 373, 375, 378, 379, 381, 382, 383, 384, 388, 399, 404, 563, 565, 566, 568, 571, 572, 574, 576, 579, 580, 582, 585, 587, 588, 593, 614, 621, 622, 623, 624, 625, 636, 637, 638, 639, 640, 642], "inittrack": [17, 300, 302, 338, 497, 621, 624], "our": [17, 18, 21, 26, 27, 30, 41, 67, 219, 224, 388, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 635, 636, 637, 639, 640, 642], "tutori": [17, 21, 148, 182, 590, 620, 621, 622, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 638, 639, 640, 641, 643], "inform": [17, 18, 19, 21, 23, 34, 35, 37, 40, 41, 42, 44, 45, 46, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 80, 83, 84, 85, 98, 99, 117, 120, 123, 124, 127, 130, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 285, 286, 303, 323, 324, 325, 326, 328, 329, 330, 335, 372, 373, 374, 375, 376, 377, 378, 379, 380, 410, 414, 470, 621, 622, 623, 624, 625, 626, 633, 636, 637, 638, 640, 642], "scratch": [17, 27, 622, 638], "mission": 18, "irrespect": [18, 340, 341], "statu": [18, 43, 123, 187, 188], "mostli": [18, 22, 40, 388, 630, 640, 643], "Its": [18, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 277, 324, 330, 335, 340, 373, 375, 378, 379, 385], "success": [18, 75, 76, 77, 78, 79, 80, 81, 82, 170, 172, 175, 176, 183, 188, 190, 219, 265, 299, 348, 368, 593, 622, 629, 631, 634, 638, 640, 642], "inspir": [18, 625, 638], "howev": [18, 24, 26, 50, 85, 105, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 237, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 273, 274, 276, 277, 324, 330, 335, 345, 347, 348, 361, 364, 366, 367, 373, 375, 378, 379, 593, 621, 622, 624, 625, 628, 638, 640, 643], "gone": [18, 23, 24, 338], "sometim": [18, 71, 624, 643], "hard": [18, 26, 111, 121, 122, 147, 622, 643], "extern": [18, 227, 230, 278, 322, 333, 334, 614, 633, 636, 643], "adopt": [18, 24, 621, 643], "moreov": 18, "now": [18, 21, 26, 64, 67, 68, 69, 70, 86, 145, 146, 147, 183, 187, 219, 257, 322, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 633, 635, 636, 637, 639, 640, 643], "instal": [18, 24, 29, 41, 42, 44, 76, 79, 117, 120, 123, 127, 132, 135, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 168, 169, 170, 173, 175, 176, 177, 178, 188, 390, 398, 410, 592, 621, 623, 624, 625, 626, 627, 628, 629, 630, 631, 636, 637, 643], "virtual": [18, 126], "concomittantli": 18, "fortun": [18, 21, 624, 625, 626, 627, 630], "decor": [18, 27, 207, 209, 280, 300, 302, 362, 381, 382, 383, 384, 399, 593, 624, 642], "set_gym_backend": [18, 34, 35, 37, 40, 48, 117, 120, 123, 126, 127, 135, 147, 148, 151, 156, 157, 158, 167, 168, 169, 170, 173, 176, 177, 178, 215, 626, 642], "relev": [18, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 381, 382, 383, 384, 385, 395, 625, 638], "gym_backend": [18, 209], "env1": [18, 285, 635], "venv": 18, "python3": [18, 25, 26, 29], "site": [18, 25, 26, 81, 120, 209], "env2": [18, 635], "_env": [18, 25, 126, 643], "classic_control": 18, "pendulumenv": [18, 638], "0x15147e190": 18, "0x1629916a0": 18, "further": [18, 22, 24, 379, 621, 623, 625, 626], "mo_gymnasium": [18, 137, 167, 240], "handi": [18, 34, 35, 37, 40, 41, 42, 44, 46, 48, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 630], "v0": [18, 34, 35, 56, 58, 83, 84, 117, 120, 123, 127, 129, 132, 133, 134, 135, 136, 137, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 223, 240, 270, 277, 278, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 399, 557], "26": [18, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 193, 194, 224], "none": [18, 21, 22, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 103, 105, 106, 107, 109, 111, 113, 117, 120, 123, 124, 126, 127, 135, 139, 140, 141, 145, 146, 147, 148, 149, 150, 151, 156, 157, 158, 159, 160, 161, 162, 163, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 204, 205, 207, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 230, 234, 236, 237, 239, 240, 241, 244, 245, 246, 248, 249, 250, 251, 252, 253, 254, 255, 256, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 316, 318, 320, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 393, 394, 396, 397, 403, 404, 405, 406, 407, 408, 410, 412, 413, 414, 415, 416, 418, 419, 420, 422, 423, 424, 425, 426, 428, 431, 432, 435, 436, 437, 439, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 460, 461, 462, 463, 465, 466, 467, 469, 470, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 491, 492, 493, 494, 495, 496, 497, 498, 499, 501, 503, 504, 505, 506, 507, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 540, 542, 544, 546, 547, 548, 551, 552, 553, 554, 556, 557, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 614, 621, 622, 624, 625, 634, 638, 640, 642], "fun": [18, 209, 280, 623, 636, 637], "effect": [18, 22, 37, 48, 49, 56, 64, 65, 67, 68, 69, 70, 75, 80, 83, 84, 85, 98, 99, 103, 105, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 200, 215, 219, 225, 270, 323, 324, 325, 326, 328, 329, 330, 335, 347, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 410, 415, 593, 621, 627, 636, 640, 643], "autoresettransform": [18, 474], "skip": [18, 20, 22, 36, 75, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 225, 235, 237, 242, 268, 270, 324, 329, 330, 335, 339, 341, 348, 362, 367, 373, 375, 378, 379, 381, 382, 383, 384, 387, 388, 402, 404, 414, 415, 470, 621, 622, 634, 638], "fine": [18, 67, 68, 69, 70, 99, 105, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 216, 239, 379, 593, 625, 629, 639], "grain": [18, 67, 68, 69, 70, 99, 105, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 216], "invalid": [18, 85, 111, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 164, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 304, 324, 330, 331, 335, 373, 375, 378, 379, 634], "nan": [18, 215, 276, 474], "auto_reset": [18, 117, 120, 123, 127, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 183, 215, 638], "auto_reset_replac": [18, 215], "replac": [18, 21, 25, 26, 75, 80, 85, 105, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 215, 229, 231, 238, 277, 278, 299, 322, 324, 330, 335, 346, 348, 354, 360, 365, 367, 368, 369, 373, 375, 378, 379, 381, 382, 383, 384, 430, 432, 474, 636, 640, 642], "placehold": [18, 128, 129, 173, 231, 270, 276], "manual_se": [18, 53, 59, 60, 64, 67, 69, 70, 77, 81, 82, 83, 84, 93, 105, 106, 117, 118, 119, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 213, 215, 224, 225, 229, 244, 253, 256, 262, 264, 278, 296, 299, 304, 308, 310, 323, 325, 326, 328, 329, 337, 341, 344, 345, 346, 348, 349, 353, 360, 367, 372, 374, 376, 377, 380, 625, 629, 631, 636, 637, 638, 642, 643], "autoresettinggymenv": [18, 215], "_step": [18, 21, 22, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 213, 215, 216, 218, 219, 220, 223, 224, 225, 227, 228, 230, 231, 232, 233, 234, 235, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 378], "td_reset": [18, 215], "exclud": [18, 27, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 76, 81, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 193, 194, 210, 215, 219, 232, 327, 335, 347, 361, 364, 375, 636, 637, 640], "r": [18, 20, 23, 83, 84, 86, 120, 170, 173, 174, 188, 191, 195, 212, 213, 215, 222, 224, 225, 244, 258, 265, 268, 277, 278, 285, 323, 325, 326, 328, 329, 341, 364, 372, 374, 376, 377, 380, 386, 593, 622, 638, 643], "break_when_any_don": [18, 22, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 215, 268, 285, 338, 637], "squeez": [18, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 85, 215, 216, 219, 224, 259, 262, 286, 621, 625, 638, 640], "creation": [18, 19, 147, 156, 194, 330, 375, 470, 588, 643], "imposs": [18, 20, 67, 69, 70, 111, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 345, 347, 361, 364, 366], "forecast": 18, "awar": [18, 26, 56, 58, 85, 87, 92, 93, 94, 95, 107, 109, 113, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 269, 300, 302, 322, 378, 622, 624], "note": [18, 19, 20, 21, 22, 23, 34, 35, 37, 40, 41, 42, 44, 46, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 207, 211, 227, 230, 268, 277, 278, 300, 302, 310, 322, 323, 324, 325, 326, 328, 329, 330, 335, 339, 341, 347, 355, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 562, 567, 570, 572, 573, 578, 579, 584, 585, 586, 587, 588, 614, 622, 625, 627, 633, 635, 636, 637, 643], "detect": [18, 20, 82, 84, 86, 172, 176, 362, 371, 373, 375, 379, 396, 593, 595], "return_contigu": [18, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 635], "tensordictbas": [18, 21, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 111, 117, 120, 123, 125, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 202, 203, 210, 211, 213, 215, 216, 218, 219, 220, 223, 224, 225, 227, 228, 231, 232, 233, 234, 235, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 273, 274, 276, 277, 278, 284, 296, 299, 300, 302, 310, 312, 323, 324, 325, 326, 328, 329, 330, 335, 338, 340, 341, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 410, 575, 576, 621, 636, 638], "envwithdynamicspec": 18, "max_count": 18, "bool": [18, 19, 22, 31, 32, 34, 35, 37, 40, 41, 42, 43, 44, 46, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 91, 92, 93, 94, 95, 98, 99, 101, 103, 104, 105, 106, 107, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 204, 210, 211, 212, 213, 215, 216, 219, 220, 224, 225, 227, 229, 230, 231, 232, 234, 237, 239, 241, 242, 243, 244, 246, 248, 250, 251, 253, 255, 256, 257, 260, 261, 263, 266, 267, 268, 270, 271, 272, 273, 275, 277, 278, 280, 284, 285, 286, 288, 289, 295, 296, 300, 301, 302, 303, 304, 311, 312, 317, 318, 319, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 337, 338, 339, 340, 341, 342, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 388, 395, 396, 399, 402, 403, 404, 406, 407, 410, 414, 415, 416, 418, 419, 420, 422, 423, 424, 425, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 472, 474, 475, 500, 502, 503, 513, 519, 524, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 561, 562, 563, 567, 569, 570, 573, 575, 576, 577, 578, 581, 583, 584, 586, 593, 622, 623, 625, 633, 634, 638, 642, 643], "full": [18, 19, 83, 84, 85, 98, 99, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 186, 188, 193, 194, 195, 296, 300, 302, 323, 325, 326, 328, 329, 330, 335, 341, 364, 372, 373, 374, 375, 376, 377, 380, 400, 593, 614, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "_set_se": [18, 213, 216, 227, 230, 250, 638], "int": [18, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 91, 92, 93, 94, 95, 98, 99, 100, 101, 103, 105, 106, 107, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 133, 134, 135, 139, 140, 141, 142, 143, 147, 148, 149, 150, 151, 153, 156, 157, 158, 161, 162, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 199, 203, 204, 212, 214, 215, 216, 218, 219, 220, 221, 223, 226, 229, 234, 235, 237, 241, 242, 243, 244, 246, 248, 249, 252, 259, 260, 261, 264, 267, 268, 270, 272, 273, 275, 284, 286, 287, 288, 289, 290, 291, 292, 293, 295, 296, 297, 298, 299, 301, 303, 304, 306, 307, 309, 310, 312, 313, 314, 317, 318, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 345, 346, 347, 354, 356, 357, 361, 362, 363, 364, 365, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 387, 388, 390, 393, 395, 396, 400, 401, 402, 404, 406, 410, 413, 414, 415, 416, 418, 419, 420, 422, 423, 424, 425, 426, 428, 431, 432, 435, 436, 437, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 460, 461, 462, 469, 470, 472, 474, 475, 477, 478, 479, 480, 485, 488, 494, 500, 501, 502, 504, 507, 510, 517, 518, 519, 522, 525, 526, 529, 542, 559, 560, 561, 563, 568, 572, 579, 580, 581, 582, 583, 585, 587, 588, 625, 638, 640], "lazystackedtensordict": [18, 48, 75, 83, 84, 93, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 183, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 635], "field": [18, 19, 22, 34, 35, 37, 40, 48, 49, 52, 56, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 92, 93, 94, 98, 105, 113, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 133, 134, 135, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 212, 216, 227, 230, 231, 232, 237, 246, 250, 251, 253, 257, 260, 261, 263, 268, 270, 271, 281, 282, 283, 285, 294, 295, 296, 300, 302, 310, 311, 312, 320, 323, 324, 325, 326, 328, 329, 330, 335, 337, 338, 339, 340, 343, 345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 470, 551, 592, 593, 622, 634, 638], "float32": [18, 21, 34, 35, 37, 54, 56, 64, 69, 70, 71, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 92, 93, 94, 98, 99, 105, 113, 117, 118, 119, 120, 123, 126, 127, 128, 133, 134, 135, 141, 144, 145, 146, 147, 148, 151, 154, 155, 156, 157, 158, 159, 161, 162, 168, 169, 170, 173, 174, 176, 177, 178, 204, 210, 212, 216, 227, 230, 231, 232, 237, 240, 244, 246, 250, 251, 253, 257, 260, 261, 263, 266, 271, 281, 282, 283, 285, 294, 295, 300, 302, 310, 311, 312, 320, 323, 324, 325, 326, 328, 329, 330, 335, 337, 338, 339, 340, 343, 345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 379, 380, 486, 633, 638], "is_shar": [18, 22, 34, 35, 37, 48, 52, 56, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 92, 93, 94, 98, 105, 113, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 133, 134, 135, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 161, 162, 168, 169, 170, 173, 174, 176, 177, 178, 183, 210, 212, 216, 227, 230, 231, 232, 237, 246, 250, 251, 253, 257, 260, 261, 263, 271, 277, 281, 282, 283, 285, 294, 295, 296, 300, 302, 310, 311, 312, 320, 323, 324, 325, 326, 328, 329, 330, 335, 337, 338, 339, 340, 343, 345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 379, 380, 638], "exclusive_field": [18, 48, 75, 83, 84, 93, 117, 170, 173, 174, 183, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "stack_dim": [18, 48, 75, 83, 84, 93, 117, 170, 173, 174, 183, 203, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 423], "absenc": [18, 22], "dramat": 18, "carefulli": [18, 181, 636, 637, 643], "against": [18, 24, 26, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 295, 296, 311, 312, 324, 330, 335, 337, 339, 340, 341, 346, 348, 360, 365, 367, 368, 369, 373, 375, 378, 379, 623, 636, 637], "plain": [18, 27, 346, 348, 354, 360, 365, 367, 368, 369, 382, 383, 384, 626], "deseri": 18, "larg": [18, 23, 55, 83, 84, 98, 99, 105, 106, 174, 227, 230, 273, 322, 323, 325, 326, 328, 329, 330, 345, 347, 361, 364, 366, 372, 374, 375, 376, 377, 380, 622, 623, 634, 636, 637, 640], "expens": [18, 20, 49, 99, 105, 106, 386, 640], "check_env_spec": [18, 20, 22, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 212, 237, 250, 271, 386, 623, 636, 637, 638], "vari": [18, 19, 126, 128, 129, 149, 150, 153, 161, 249, 625, 637], "absent": [18, 56, 58, 76, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 257, 270], "view": [19, 27, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 71, 72, 73, 74, 80, 81, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 213, 303, 324, 330, 335, 373, 375, 378, 379, 593, 626, 638, 640, 642, 643], "act": [19, 22, 23, 105, 106, 149, 150, 270, 294, 346, 348, 349, 360, 365, 367, 368, 369, 624, 625, 636, 637, 640, 642], "paradigm": [19, 40, 637], "decpodp": 19, "markov": [19, 626, 643], "game": [19, 20, 23, 24, 75, 120, 139, 140, 145, 146, 224, 286, 388, 625, 630], "thank": [19, 168, 193, 194, 379, 621, 625, 626, 642], "carrier": [19, 623, 624, 626, 640], "particular": [19, 76, 77, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 270, 324, 330, 335, 373, 375, 378, 379, 622, 624, 626, 635, 637, 640], "thu": [19, 361, 637], "kept": [19, 22, 43, 45, 52, 104, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 210, 229, 257, 301, 318, 319, 582, 583, 584, 586, 588, 628, 636], "vma": [19, 161, 162, 386, 456, 636, 637], "robot": [19, 24, 26, 80, 248, 273, 275, 364, 625, 637], "vmasenv": [19, 386, 456, 636, 637], "balanc": [19, 98, 99, 121, 122, 322, 621, 622], "num_env": [19, 34, 35, 40, 46, 117, 126, 130, 143, 161, 162, 169, 170, 173, 179, 386, 443, 447, 614, 636, 637], "n_agent": [19, 161, 162, 386, 636, 637], "td": [19, 21, 34, 35, 37, 40, 41, 42, 44, 46, 56, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 92, 98, 99, 111, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 133, 134, 135, 136, 137, 145, 146, 147, 148, 151, 152, 156, 157, 158, 159, 160, 168, 169, 170, 173, 174, 176, 177, 178, 181, 183, 184, 188, 210, 213, 216, 218, 220, 224, 225, 227, 228, 229, 230, 238, 239, 240, 242, 244, 253, 256, 260, 263, 266, 270, 277, 281, 282, 283, 285, 294, 295, 299, 310, 311, 320, 323, 324, 325, 326, 328, 329, 330, 335, 337, 339, 340, 343, 354, 367, 372, 373, 374, 375, 376, 377, 379, 380, 382, 383, 384, 387, 400, 408, 593, 607, 621, 622, 624, 637, 638, 639, 642], "info": [19, 34, 35, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 98, 99, 103, 105, 106, 117, 120, 121, 122, 123, 126, 127, 128, 129, 135, 139, 140, 145, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 173, 176, 177, 178, 188, 237, 271, 273, 276, 279, 395, 626, 631, 633, 636, 637, 640, 642], "ground_rew": 19, "pos_rew": 19, "16": [19, 20, 34, 35, 40, 48, 81, 85, 99, 106, 117, 118, 119, 120, 123, 127, 133, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 322, 324, 327, 330, 335, 373, 375, 378, 379, 614, 624, 640], "style": [19, 64, 67, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 185, 195, 201, 415], "info_spec": [19, 147], "agent_i_action_spec": 19, "agent_i_reward_spec": 19, "agent_i_observation_spec": 19, "prefix": [19, 52, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 265, 268, 270, 322, 323, 324, 325, 326, 328, 329, 330, 335, 339, 348, 362, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 387, 396, 410, 414, 470, 624, 628, 633, 643], "exactli": [19, 85, 117, 120, 123, 127, 129, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 268, 270, 308, 324, 330, 335, 348, 367, 373, 375, 378, 379, 621, 624, 629, 636, 637], "action_kei": [19, 21, 34, 35, 37, 40, 41, 42, 44, 46, 117, 120, 123, 127, 135, 147, 148, 151, 152, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 210, 212, 213, 229, 239, 242, 284, 299, 310, 338, 472, 636, 637], "reward_kei": [19, 89, 90, 97, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 210, 403, 407, 636, 637], "right": [19, 22, 25, 26, 52, 99, 105, 178, 224, 330, 335, 622, 623, 625, 637, 638, 643], "set_kei": [19, 231, 345, 347, 348, 350, 353, 354, 355, 360, 361, 362, 364, 365, 366, 367, 373, 375, 379, 385, 621, 636, 637], "awai": [19, 623, 626, 636, 637, 642], "eas": [19, 636, 637], "access": [19, 21, 26, 27, 30, 34, 35, 37, 40, 48, 49, 64, 77, 78, 79, 85, 93, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 207, 219, 248, 269, 273, 322, 324, 330, 335, 373, 375, 378, 379, 396, 397, 398, 561, 591, 592, 607, 621, 626, 636, 637, 638, 640, 642], "leaf": [19, 21, 34, 35, 37, 39, 40, 41, 42, 44, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 238, 261, 263, 269, 341], "abov": [19, 21, 22, 26, 50, 72, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 269, 301, 318, 319, 324, 330, 335, 373, 375, 378, 379, 593, 621, 623, 625, 626, 627, 636, 637, 638, 643], "would": [19, 21, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 300, 302, 303, 324, 330, 335, 341, 373, 375, 378, 379, 622, 623, 624, 626, 628, 629, 638, 640, 642, 643], "ey": 20, "report": [20, 118, 119, 133, 134, 414, 630], "foremost": 20, "callback": [20, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 637], "callabl": [20, 21, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 86, 87, 117, 120, 123, 124, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 200, 209, 214, 216, 223, 224, 225, 231, 237, 241, 263, 270, 271, 280, 286, 303, 324, 330, 335, 341, 362, 373, 375, 378, 379, 386, 413, 414, 415, 552, 553, 559, 560, 561, 622, 640], "upon": [20, 27, 39, 636, 638], "intern": [20, 22, 117, 118, 119, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 278, 322, 324, 330, 335, 396, 581, 586, 619], "ad": [20, 23, 34, 35, 37, 40, 48, 52, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 98, 99, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 237, 256, 268, 270, 310, 323, 324, 325, 326, 328, 329, 330, 335, 345, 347, 348, 350, 355, 361, 364, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 593, 622, 624, 625, 627, 633, 636, 640, 642, 643], "save": [20, 27, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 97, 107, 108, 109, 113, 114, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 276, 323, 324, 325, 326, 328, 329, 330, 335, 372, 373, 374, 375, 376, 377, 378, 379, 380, 387, 388, 390, 395, 410, 414, 415, 470, 614, 615, 625, 629, 630, 631, 636, 637], "disk": [20, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 88, 92, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 410, 621, 622, 624, 625, 629, 630, 636, 640], "tensordictrecord": 20, "imag": [20, 23, 26, 30, 80, 83, 87, 219, 221, 224, 226, 248, 266, 275, 303, 386, 388, 621, 622, 625, 626, 630, 637, 639, 643], "pixel": [20, 21, 22, 26, 56, 68, 82, 120, 121, 122, 126, 128, 129, 153, 219, 221, 226, 231, 234, 236, 244, 246, 248, 252, 266, 273, 275, 288, 306, 307, 386, 388, 621, 622, 624, 625, 630, 636, 639, 640, 642, 643], "alreadi": [20, 21, 27, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 75, 83, 84, 85, 92, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 211, 241, 263, 280, 323, 324, 325, 326, 327, 328, 329, 330, 335, 341, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 396, 397, 575, 614, 621, 623, 630, 636, 637], "atari": [20, 22, 23, 75, 76, 77, 78, 80, 81, 82, 87, 219, 286, 388, 625, 630, 643], "videorecord": [20, 30, 386, 623, 630, 631, 636], "csvlogger": [20, 30, 386, 388, 457, 615, 622, 630, 631, 636], "wandblogg": [20, 460, 615, 630], "tensorboardlogg": [20, 459, 557, 615, 630], "tag": [20, 26, 30, 172, 173, 175, 185, 198, 201, 386, 388, 390, 393, 561, 593, 630, 631, 633, 636], "mp4": [20, 386, 388, 390, 631, 636], "video_format": [20, 386, 388, 390, 457, 631, 636], "whc": 20, "cwh": 20, "dummi": [20, 158, 183, 386, 621, 625, 629, 643], "exp": [20, 305], "al": [20, 34, 35, 37, 40, 48, 126, 128, 231, 246, 490, 625, 643], "pong": [20, 34, 35, 37, 40, 48, 75, 143, 246, 625, 643], "v5": [20, 34, 35, 37, 40, 48, 126, 128, 143, 231, 246, 625, 643], "append_transform": [20, 21, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 205, 212, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 237, 238, 239, 241, 247, 248, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 273, 274, 276, 277, 278, 285, 300, 302, 378, 386, 593, 614, 621, 624, 633, 636, 638, 640, 642, 643], "clear": [20, 30, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 71, 72, 73, 74, 77, 85, 117, 118, 119, 120, 123, 127, 131, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 396, 401, 614, 626, 629, 634], "grow": [20, 93], "until": [20, 26, 46, 48, 85, 134, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 264, 269, 378, 399, 572, 579, 585, 587, 623, 624, 631, 636, 637], "tediou": [20, 626], "workspac": [20, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 237], "pixelrendertransform": [20, 636], "stream": [20, 80, 87], "alik": [20, 386], "envcreat": [20, 37, 46, 47, 147, 156, 268, 278, 386, 557, 558, 561, 621, 622, 642, 643], "render_mod": [20, 386, 443, 447, 638], "rgb_arrai": [20, 386, 636, 637, 638], "uncom": [20, 630], "line": [20, 26, 75, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 622, 630, 636, 637], "__name__": [20, 34, 35, 37, 40, 47, 48, 65, 124, 278, 386, 622, 642], "__main__": [20, 34, 35, 37, 40, 47, 48, 65, 124, 278, 386, 642], "comment": [20, 622, 642], "pixels_record": [20, 386], "close": [20, 22, 32, 34, 35, 37, 40, 41, 42, 44, 48, 65, 85, 117, 127, 142, 171, 172, 175, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 239, 269, 278, 345, 347, 361, 364, 375, 378, 386, 564, 621, 622, 626, 633, 635, 636, 638, 642], "purpos": [20, 21, 22, 26, 30, 83, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 195, 219, 323, 325, 326, 328, 329, 345, 347, 359, 361, 364, 366, 372, 374, 375, 376, 377, 380, 557, 614, 621, 623, 624, 625, 628, 630, 636, 637, 639, 643], "raw": [21, 23, 87, 197, 237, 267, 271, 301, 318, 319, 563, 565, 566, 568, 571, 574, 576, 580, 582, 588, 622, 625, 629, 638], "torchvis": [21, 30, 248, 275, 390, 636, 642, 643], "primit": [21, 23, 80, 345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 563], "from_pixel": [21, 22, 30, 118, 119, 121, 122, 126, 128, 129, 133, 134, 153, 219, 252, 386, 388, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 621, 622, 624, 626, 630, 631, 639, 640, 642, 643], "totensorimag": [21, 68, 82, 219, 252, 524, 622, 624, 625, 640, 642, 643], "resiz": [21, 68, 82, 219, 510, 622, 624, 625, 626, 640, 643], "appar": [21, 402], "bring": [21, 623, 626, 643], "speedup": [21, 22, 27, 636, 643], "kind": [21, 67, 71, 628, 636, 640], "great": [21, 22, 26, 27, 625, 634, 636, 642], "consult": 21, "interest": [21, 22, 339, 341, 622, 623, 626, 637, 638, 643], "resize_par": 21, "inv": [21, 85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 222, 229, 232, 237, 246, 253, 258, 260, 265, 269, 272, 378, 638], "revers": 21, "order": [21, 30, 37, 39, 48, 49, 63, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 104, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 220, 227, 230, 237, 246, 260, 268, 270, 295, 320, 322, 324, 330, 335, 337, 340, 342, 343, 345, 346, 348, 349, 353, 354, 360, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 622, 636, 637], "chain": [21, 64, 67, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 135, 168, 174, 176, 177, 192, 193, 223, 229, 286, 315, 323, 325, 326, 328, 329, 343, 372, 374, 376, 377, 380, 593, 643], "taken": [21, 49, 53, 55, 57, 59, 60, 61, 63, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 212, 252, 304, 621, 623, 624, 627, 636, 637, 638], "in_keys_inv": [21, 192, 197, 205, 222, 227, 228, 230, 237, 244, 245, 246, 250, 251, 253, 258, 267, 269, 271, 272, 481, 486, 487, 489, 621, 635, 638, 643], "doubletofloat": [21, 489, 621, 623, 635], "float64": [21, 75, 76, 77, 78, 79, 80, 81, 82, 85, 117, 120, 121, 122, 123, 127, 135, 139, 140, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 212, 223, 227, 230, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "paragraph": [21, 22], "in_": 21, "out_": 21, "perspect": [21, 181, 296, 355, 623, 625], "inner": [21, 22, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 229, 270, 563, 568, 580, 582, 588, 615, 622, 623, 637, 643], "outer": [21, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 270, 615, 621, 622, 643], "ob": [21, 23, 27, 52, 56, 58, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 87, 98, 105, 106, 111, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 204, 210, 213, 215, 224, 227, 228, 230, 244, 258, 260, 266, 288, 289, 290, 291, 311, 320, 346, 348, 349, 354, 360, 365, 367, 368, 369, 381, 382, 383, 384, 622, 625, 635, 636, 638, 640, 642, 643], "obs_standard": 21, "similarli": [21, 46, 85, 104, 109, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 242, 324, 330, 335, 342, 343, 353, 360, 373, 375, 378, 379, 381, 593, 643], "seen": [21, 41, 42, 44, 46, 56, 58, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 228, 621, 622, 624, 628, 636, 637, 640], "out_keys_inv": [21, 192, 197, 205, 222, 227, 228, 230, 237, 244, 245, 246, 250, 251, 258, 260, 267, 269, 271, 272, 481, 486, 487, 489, 638], "produc": [21, 37, 56, 58, 105, 212, 215, 216, 281, 283, 286, 303, 308, 341, 381, 388, 623, 624, 625, 626, 627, 629, 640, 643], "illustr": [21, 621, 622, 627, 640], "renametransform": [21, 68, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 219, 509], "renam": [21, 56, 58, 68, 83, 84, 169, 174, 210, 251, 253, 270, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 621], "schemat": 21, "outermost": 21, "innermost": 21, "similar": [21, 62, 67, 80, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 274, 275, 277, 278, 281, 283, 322, 323, 324, 325, 326, 328, 329, 330, 335, 339, 340, 341, 372, 373, 374, 375, 376, 377, 378, 379, 380, 584, 621, 622, 623, 624, 625, 627, 628, 629, 630, 638, 640, 642, 643], "transform_action_spec": [21, 85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 228, 241, 244, 269, 271, 272, 378], "pseudocod": 21, "could": [21, 22, 23, 25, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 341, 373, 375, 378, 379, 614, 622, 623, 630, 636, 637, 639, 643], "spec_from_random_valu": 21, "_apply_transform": [21, 85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 378, 638, 643], "rand": [21, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 93, 118, 119, 133, 134, 141, 145, 146, 152, 159, 160, 213, 216, 227, 230, 250, 260, 339, 345, 346, 348, 349, 350, 352, 353, 354, 360, 362, 364, 365, 367, 368, 369, 373, 375, 379, 638, 642, 643], "did": [21, 67, 276, 622, 623, 629, 640, 643], "_inv_apply_transform": [21, 85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 212, 269, 378, 638, 643], "actiondiscret": [21, 472], "rand_act": [21, 117, 120, 123, 127, 135, 138, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 183, 216, 270, 626], "action_discret": 21, "counterpart": [21, 219], "obtain": [21, 26, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 75, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 194, 218, 248, 262, 275, 285, 406, 621, 623, 626, 627, 628, 636, 637], "addonetoob": 21, "There": [21, 29, 68, 83, 84, 170, 174, 269, 300, 302, 323, 325, 326, 328, 329, 345, 364, 372, 374, 376, 377, 380, 623, 624, 625, 627, 629, 636, 637, 638, 640, 642, 643], "Is": [21, 269], "ident": [21, 34, 35, 37, 67, 68, 69, 70, 83, 84, 92, 105, 117, 120, 123, 126, 127, 128, 135, 142, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 175, 176, 177, 178, 231, 260, 269, 278, 323, 325, 326, 328, 329, 346, 348, 360, 365, 367, 368, 369, 372, 374, 376, 377, 380, 381, 382, 383, 384, 559, 560, 622, 626, 636, 637], "rewrit": [21, 269], "otherwis": [21, 31, 34, 35, 37, 46, 47, 48, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 99, 105, 106, 117, 118, 119, 120, 123, 126, 127, 128, 129, 132, 133, 134, 135, 138, 139, 140, 142, 143, 145, 146, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 220, 224, 225, 229, 237, 244, 262, 263, 264, 268, 269, 270, 277, 280, 295, 301, 311, 318, 319, 323, 324, 325, 326, 328, 329, 330, 335, 341, 344, 346, 348, 357, 362, 363, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 404, 406, 562, 584, 621, 622, 623, 624, 633, 638, 643], "_call": [21, 85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 229, 231, 232, 233, 234, 235, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 378, 633, 638], "_inv_cal": [21, 85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 212, 269, 378], "overwrit": [21, 269], "till": [21, 269, 276], "encapsul": [21, 269, 626, 627, 628], "don": [21, 22, 23, 25, 26, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 168, 195, 219, 269, 304, 322, 562, 567, 573, 614, 622, 623, 625, 629, 640, 642, 643], "forget": [21, 269], "edit": [21, 181, 269, 629], "transform_output_spec": [21, 85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 223, 227, 228, 232, 239, 242, 250, 251, 257, 261, 267, 269, 271, 278, 378], "transform_input_spec": [21, 85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 212, 216, 223, 227, 228, 229, 242, 246, 250, 251, 256, 260, 261, 262, 263, 267, 269, 271, 274, 378], "transform_observation_spec": [21, 85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 219, 220, 221, 222, 223, 226, 227, 228, 231, 232, 234, 236, 238, 239, 241, 242, 244, 246, 250, 251, 252, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 276, 277, 278, 378, 638], "transform_state_spec": [21, 85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 228, 241, 244, 269, 271, 272, 378], "transform_reward_spec": [21, 85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 217, 222, 223, 227, 228, 232, 239, 240, 241, 242, 250, 251, 254, 255, 256, 257, 258, 260, 261, 267, 269, 271, 272, 278, 378, 593, 633], "undo": [21, 181], "addonetoact": 21, "subtract": [21, 186, 262], "properti": [21, 33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 215, 268, 269, 270, 277, 278, 293, 301, 304, 308, 317, 318, 319, 323, 324, 325, 326, 327, 328, 329, 330, 335, 338, 345, 348, 362, 364, 366, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 627, 629, 638, 640], "manipul": [21, 23, 27, 121, 122, 248, 269, 273], "third_transform": 21, "assert": [21, 22, 25, 37, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 111, 117, 120, 123, 127, 130, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 174, 176, 177, 178, 181, 204, 209, 212, 216, 219, 222, 227, 230, 239, 251, 258, 270, 277, 285, 305, 323, 325, 326, 328, 329, 372, 374, 376, 377, 379, 380, 381, 382, 383, 384, 399, 400, 408, 461, 462, 465, 466, 467, 614, 629, 635, 640, 643], "lead": [21, 23, 27, 29, 48, 52, 56, 58, 64, 67, 76, 98, 104, 117, 120, 121, 122, 123, 126, 127, 128, 129, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 263, 280, 301, 318, 319, 621, 624, 625, 636, 637, 638, 640, 642], "unexpect": [21, 34, 35, 37, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 643], "behviour": 21, "rais": [21, 22, 32, 34, 35, 37, 40, 41, 42, 43, 44, 46, 47, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 78, 80, 83, 84, 85, 92, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 159, 163, 164, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 219, 233, 243, 253, 262, 263, 264, 268, 270, 277, 284, 299, 310, 323, 324, 325, 326, 328, 329, 330, 331, 335, 348, 362, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 396, 397, 398, 399, 563, 565, 566, 568, 571, 572, 574, 575, 576, 579, 580, 582, 585, 587, 588, 614, 621, 623, 636, 637, 640], "catfram": [21, 338, 478, 622], "hold": [21, 22, 269, 378, 638, 640], "notic": [21, 111, 219, 623, 631, 638], "parenthood": 21, "henc": [21, 49, 64, 211, 249, 621, 623, 636, 637, 638], "transform2": 21, "transform3": 21, "last_two": 21, "isinst": [21, 147, 156, 270, 386, 399, 466, 638], "discret": [21, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 117, 120, 123, 126, 127, 128, 135, 139, 140, 147, 148, 149, 150, 151, 156, 157, 158, 161, 162, 168, 169, 170, 173, 176, 177, 178, 212, 229, 237, 308, 352, 353, 354, 355, 622, 627, 637], "might": [21, 83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 392, 592, 621, 626, 643], "throughout": [21, 345, 346, 347, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 373, 375, 379, 623, 636, 643], "action_mask": [21, 120, 133, 134, 149, 150, 154, 155, 213, 473, 634], "unavail": [21, 149, 150], "probabl": [21, 23, 27, 68, 98, 99, 103, 186, 187, 193, 194, 285, 293, 299, 300, 302, 303, 304, 308, 315, 318, 319, 324, 327, 330, 335, 339, 341, 348, 354, 364, 367, 373, 375, 379, 622, 625, 627, 642], "probabilistictensordictmodul": [21, 239, 341, 342, 642], "tensordictsequenti": [21, 285, 295, 299, 300, 302, 310, 324, 330, 335, 338, 342, 343, 373, 375, 379, 621, 622, 624, 625, 627, 631, 635, 636, 639, 642], "maskedcategor": [21, 600], "in_feat": 21, "out_feat": 21, "logit": [21, 294, 296, 304, 308, 324, 327, 330, 335, 339, 353, 354, 593], "dist": [21, 29, 304, 308, 341, 627], "distribution_class": [21, 239, 281, 282, 283, 339, 341, 343, 345, 346, 348, 353, 354, 360, 364, 365, 366, 367, 600, 621, 623, 627, 636, 637, 642], "actor": [21, 23, 34, 35, 37, 40, 46, 48, 49, 50, 65, 152, 169, 170, 173, 183, 187, 190, 191, 192, 193, 239, 241, 281, 282, 283, 287, 288, 290, 295, 296, 297, 299, 309, 310, 311, 312, 322, 327, 332, 335, 338, 339, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 373, 375, 379, 396, 397, 398, 415, 469, 470, 569, 570, 571, 572, 573, 574, 587, 588, 591, 600, 607, 614, 622, 624, 626, 628, 631, 636, 639, 642], "wrap": [21, 24, 34, 35, 37, 40, 41, 42, 44, 46, 78, 85, 117, 118, 119, 120, 123, 127, 128, 132, 133, 134, 135, 140, 143, 145, 146, 147, 148, 149, 150, 151, 156, 157, 158, 160, 162, 163, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 207, 225, 241, 268, 270, 280, 281, 282, 283, 300, 302, 311, 321, 324, 327, 330, 335, 338, 341, 362, 373, 375, 378, 379, 593, 621, 622, 623, 624, 628, 631, 633, 636, 637, 643], "actionmask": [21, 120, 473], "know": [21, 22, 23, 28, 64, 67, 69, 70, 126, 128, 284, 362, 365, 373, 375, 379, 404, 621, 622, 623, 624, 625, 626, 627, 628, 629, 636, 637, 640], "your_base_env": 21, "mask_kei": [21, 52, 213, 249, 324, 330, 335, 473], "intens": [22, 27], "gym3": 22, "envpool": [22, 142, 143, 449], "simultan": [22, 44, 134, 142, 143, 147, 156, 581, 588, 614, 638], "scale": [22, 23, 76, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 175, 176, 177, 178, 219, 239, 244, 255, 262, 266, 277, 278, 281, 282, 283, 297, 301, 305, 313, 314, 318, 319, 339, 341, 343, 345, 346, 348, 360, 364, 365, 366, 367, 407, 503, 513, 551, 561, 600, 621, 622, 623, 624, 627, 637, 642], "varieti": [22, 30], "serialenv": [22, 117, 120, 123, 127, 135, 147, 148, 151, 157, 158, 168, 169, 170, 173, 176, 177, 178, 263, 278, 285, 338, 642, 643], "exact": [22, 52, 147, 614], "Of": [22, 26, 592, 638, 643], "cours": [22, 23, 592, 638, 643], "send": [22, 27, 39, 50, 83, 84, 151, 157, 174, 322, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 395, 562, 563, 564, 565, 566, 567, 568, 569, 571, 572, 573, 574, 575, 576, 577, 579, 580, 582, 585, 587, 588, 642], "spawn": [22, 23, 41, 47, 131, 142, 147, 156, 268, 622, 636, 637], "saniti": [22, 26, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 623], "9": [22, 26, 52, 64, 67, 69, 81, 82, 83, 84, 99, 106, 111, 121, 122, 138, 149, 150, 158, 174, 212, 215, 224, 225, 262, 265, 270, 277, 278, 304, 323, 325, 326, 328, 329, 330, 335, 345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 379, 380, 399, 414, 537, 539, 540, 541, 543, 544, 545, 549, 621, 622, 636, 637], "81": [22, 83, 84, 105, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "c": [22, 25, 26, 34, 35, 37, 40, 48, 56, 67, 69, 70, 79, 83, 84, 93, 174, 244, 266, 271, 323, 324, 325, 326, 328, 329, 330, 335, 372, 373, 374, 375, 376, 377, 379, 380, 622, 640], "d": [22, 56, 58, 64, 67, 69, 70, 77, 79, 81, 82, 98, 99, 324, 330, 335, 339, 341, 373, 375, 379, 642], "forc": [22, 25, 26, 34, 35, 40, 41, 42, 44, 46, 75, 77, 78, 80, 81, 82, 148, 330, 622, 636, 637, 638], "launch": [22, 34, 35, 40, 41, 42, 44, 47, 75, 77, 147, 156, 188, 322, 331], "bottleneck": [22, 27, 99, 105, 106], "precis": [22, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 210, 227, 230, 621, 623], "misspecifi": 22, "caus": [22, 26, 27, 34, 35, 37, 92, 94, 98, 99, 113, 117, 120, 123, 127, 131, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 249, 375, 643], "breakag": 22, "mismatch": [22, 347, 364, 375, 622], "subprocess": [22, 34, 35, 40, 124, 147, 156], "multithreadedenv": [22, 449], "underneath": 22, "higher": [22, 23, 98, 99, 175, 186, 194, 222, 322, 324, 330, 335, 344, 373, 375, 379, 621, 622, 623, 636, 640, 643], "cover": [22, 126, 128, 592, 623, 626, 629, 630, 638, 642], "classic": [22, 132, 141, 150, 622], "benchmark_batched_env": 22, "distinguish": [22, 67, 69, 70, 139, 140, 161, 162], "mere": [22, 40, 625], "element": [22, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 52, 53, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 92, 93, 94, 95, 98, 99, 105, 106, 111, 113, 117, 120, 123, 127, 135, 144, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 175, 176, 177, 178, 183, 212, 219, 224, 225, 249, 258, 262, 263, 278, 284, 286, 295, 320, 323, 325, 326, 328, 329, 337, 338, 340, 341, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 379, 380, 381, 400, 621, 623, 627, 629, 633, 640, 643], "batch_lock": [22, 117, 120, 123, 125, 127, 135, 147, 151, 156, 157, 168, 169, 170, 173, 176, 177, 178, 216, 263, 270, 638], "contrast": [22, 640], "notabl": 22, "braxenv": [22, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 251, 440, 626], "jumanjienv": [22, 446], "straightforward": [22, 38, 621, 622, 626, 627, 628, 629, 640], "merg": [22, 64, 67, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 638], "deal": [22, 64, 65, 67, 68, 362, 373, 375, 379, 621, 623, 637, 640], "silent": [22, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 312, 313, 314, 324, 336, 338, 344], "temporari": [22, 92, 94, 614, 621], "arm": 22, "unbatch": 22, "captur": [22, 188, 195, 284, 299, 310, 540, 593, 625], "content": [22, 27, 37, 56, 58, 64, 67, 69, 70, 83, 84, 86, 104, 105, 106, 117, 120, 123, 126, 127, 128, 135, 142, 147, 148, 151, 156, 157, 158, 168, 169, 170, 172, 173, 174, 176, 177, 178, 182, 188, 193, 194, 250, 286, 303, 323, 325, 326, 328, 329, 330, 335, 339, 362, 372, 373, 374, 375, 376, 377, 379, 380, 593, 623, 633, 634, 638, 642], "found": [22, 25, 26, 29, 34, 35, 37, 40, 46, 52, 56, 58, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 105, 106, 117, 120, 121, 122, 123, 126, 127, 128, 131, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 211, 213, 219, 240, 253, 256, 264, 277, 278, 299, 323, 324, 325, 326, 328, 329, 330, 335, 339, 341, 361, 362, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 396, 397, 595, 614, 621, 622, 624, 625, 626, 628, 630, 633, 638, 640, 642], "essenti": [22, 32, 41, 42, 44, 345, 346, 347, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 373, 375, 379, 593, 622, 626, 636, 638, 640], "break_when_all_don": [22, 117, 120, 123, 127, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "conditionalskip": [22, 484], "programmat": 22, "pretti": [22, 621, 626, 630, 640], "likewis": 22, "te": 22, "dive": 22, "privat": [22, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 276, 638, 643], "distinct": [22, 64, 65, 67, 68, 83, 84, 174, 216, 219, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 628, 635], "convent": [22, 75, 76, 77, 78, 79, 80, 81, 82, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 173, 176, 177, 178, 324, 607, 621, 624, 636, 637, 638], "total": [22, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 53, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 106, 111, 170, 174, 181, 224, 323, 325, 326, 328, 329, 333, 334, 347, 361, 364, 372, 374, 375, 376, 377, 380, 400, 402, 404, 410, 412, 414, 415, 470, 550, 551, 581, 607, 620, 621, 622, 623, 624, 628, 636, 637, 639, 640, 641, 642], "accord": [22, 34, 35, 37, 40, 41, 42, 44, 46, 56, 58, 68, 83, 84, 103, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 159, 160, 168, 169, 170, 173, 174, 176, 177, 178, 244, 255, 301, 313, 315, 318, 319, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 627, 628, 636, 638, 640], "nevertheless": [22, 623, 626, 640], "wherev": 22, "expos": [22, 153, 227, 230, 342, 347, 364, 622], "lost": [22, 27, 276], "face": [22, 24, 27, 28, 327, 330, 626, 634, 643], "word": [22, 30, 75, 76, 78, 80, 81, 82, 362, 373, 375, 379, 621, 629, 638, 643], "NOT": [22, 89, 90, 97, 106, 249, 588], "preliminari": 22, "warranti": 22, "long": [22, 34, 35, 37, 40, 41, 42, 44, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 92, 99, 145, 146, 229, 268, 322, 353, 375, 624, 625, 629, 640], "assumpt": [22, 71, 638, 640], "preclud": 22, "presenc": [22, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 324, 330, 335, 373, 375, 379, 628], "annihil": 22, "known": [22, 24, 26, 27, 127, 178, 263, 621, 622, 626], "supersed": [22, 52], "pettingzoowrapp": 22, "associ": [22, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 56, 58, 65, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 268, 269, 313, 323, 324, 325, 326, 327, 328, 329, 330, 335, 372, 373, 374, 375, 376, 377, 378, 379, 380, 397, 561, 621, 640], "__not__": [22, 339, 346, 348, 360, 365, 367, 368, 369], "constrain": [22, 239, 300, 302, 364, 643], "li": 22, "fact": [22, 26, 27, 593, 621, 623, 626, 636, 637, 638, 639, 640, 643], "predict": [22, 294, 297, 321, 345, 347, 352, 355, 357, 358, 361, 364, 366, 375, 621, 622, 628], "meaning": [22, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 175, 412], "perfectli": [22, 621, 625, 638], "meaningless": 22, "discard": [22, 76, 78, 127, 210, 273, 387, 640, 643], "val": [22, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 169, 278, 399, 628, 642], "agent0": [22, 364, 625], "agent1": [22, 364], "elimin": [22, 626], "500": [22, 621, 622], "uint8": [22, 56, 75, 80, 83, 84, 121, 122, 139, 140, 174, 231, 237, 246, 266, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 622, 640], "significantli": [22, 32, 41, 42, 44, 87, 105, 106, 219, 347, 364, 375, 621, 622, 628, 637], "asyncenvpool": [22, 48, 151, 157], "thread": [22, 34, 35, 37, 40, 46, 48, 49, 83, 84, 117, 118, 119, 133, 134, 147, 156, 157, 174, 188, 278, 322, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 582, 583], "pool": [22, 75, 76, 77, 78, 79, 80, 81, 82, 117, 151, 157, 190, 264, 614], "concurr": [22, 117, 322, 327, 412, 614, 636, 637], "contrari": 22, "permit": [22, 222, 234, 260, 272, 345, 347, 361, 364, 366], "job": [22, 26, 41, 42, 44, 47, 67, 68, 69, 70, 640, 642], "famili": [22, 84, 86, 595], "pleas": [22, 39, 78, 85, 117, 120, 123, 126, 127, 135, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 219, 237, 264, 268, 270, 324, 330, 335, 348, 367, 373, 375, 378, 379, 414, 592, 593], "lifecycl": [22, 322], "processorasyncenvpool": 22, "inter": [22, 147, 151], "threadingasyncenvpool": 22, "functool": [22, 34, 35, 37, 40, 48, 117], "s0": [22, 117], "clamp": [22, 117, 341, 344, 357, 410, 636, 638], "env_index": [22, 117], "async_step_send": [22, 117, 151, 157], "s0_result": [22, 117], "async_step_recv": [22, 117, 151, 157], "reveal": 23, "bug": 23, "curv": 23, "exploit": [23, 627], "cv": 23, "flip": [23, 134], "correspondingli": 23, "prescript": 23, "tune": [23, 239, 379, 593, 636, 637, 639], "coeffici": [23, 186, 193, 239, 347, 354, 361, 364, 367, 375, 379, 637], "bonu": [23, 175, 345, 347, 361, 364, 375, 593], "altern": [23, 34, 35, 37, 40, 48, 55, 83, 84, 142, 168, 174, 195, 224, 268, 292, 304, 322, 323, 325, 326, 328, 329, 348, 372, 374, 376, 377, 380, 386, 563, 565, 568, 571, 574, 576, 580, 582, 588, 614, 621, 623, 625, 636, 637], "reduc": [23, 25, 55, 98, 99, 111, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 190, 210, 219, 225, 262, 278, 318, 379, 520, 622, 636], "downstream": [23, 375, 621], "formul": [23, 636, 637], "gradient": [23, 64, 67, 68, 69, 70, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 241, 270, 301, 308, 318, 319, 324, 330, 335, 341, 345, 347, 348, 349, 353, 354, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 381, 382, 383, 384, 410, 414, 415, 470, 591, 607, 621, 623, 636, 637, 638], "norm": [23, 27, 83, 84, 118, 119, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 403, 410, 414, 415, 470, 621, 622, 623, 636, 637, 638], "easier": [23, 621, 642], "local": [23, 26, 29, 32, 34, 35, 37, 38, 40, 41, 42, 44, 46, 48, 49, 50, 66, 78, 83, 85, 99, 105, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 270, 278, 324, 330, 332, 335, 373, 375, 378, 379, 393, 395, 562, 567, 570, 573, 575, 582, 583, 614, 625, 630, 631, 636, 637], "optima": 23, "sens": [23, 83, 84, 174, 183, 219, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 629, 638], "product": [23, 28, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 559, 560, 614, 634], "sum": [23, 34, 35, 46, 61, 63, 83, 84, 111, 118, 119, 121, 122, 126, 128, 129, 133, 134, 142, 143, 153, 174, 175, 218, 240, 256, 304, 318, 323, 325, 326, 328, 329, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 372, 374, 375, 376, 377, 379, 380, 403, 593, 607, 621, 622, 623, 625, 628, 631, 636, 637, 638, 643], "stat": [23, 244, 277, 278, 551, 561, 622, 623], "w": [23, 68, 120, 145, 146, 188, 219, 221, 226, 252, 266, 310, 364, 388, 510, 622, 640], "yield": [23, 34, 35, 37, 46, 48, 49, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 322, 324, 330, 335, 362, 373, 375, 378, 379, 621, 624, 628], "insight": [23, 169, 412, 614, 625], "auxiliari": [23, 628], "credit": 23, "past": [23, 219, 338, 622, 640], "difficult": [23, 147, 630], "spars": [23, 593, 624], "instrument": 23, "greatli": 23, "soccer": 23, "kick": 23, "ball": [23, 170], "likelihood": [23, 621], "score": [23, 175, 330, 364, 593], "undesir": 23, "though": [23, 30, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 303, 330, 614, 623, 636, 637], "unintention": 23, "valuabl": 23, "idiosyncrat": 23, "subtask": 23, "hierarch": 23, "fall": [23, 33, 36, 39, 43, 45, 50, 51, 76, 83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "explicit": [23, 34, 35, 37, 169, 170, 173, 183, 192, 193, 280, 327, 396, 575, 576, 614, 640], "curios": 23, "magnitudin": 23, "domin": 23, "smaller": [23, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 353, 360, 623, 637], "addition": [23, 293], "timestep": [23, 76, 253, 636, 637], "realli": 23, "huge": [23, 593, 624], "std": [23, 244, 277, 284, 305, 309, 414, 621, 643], "estim": [23, 75, 99, 105, 106, 168, 169, 170, 173, 176, 183, 231, 239, 281, 282, 283, 288, 318, 345, 346, 347, 348, 349, 350, 352, 354, 355, 356, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 373, 375, 379, 381, 382, 383, 384, 385, 602, 607, 622, 623, 627, 628, 636, 637], "encount": [23, 80, 242, 338, 592, 622, 627, 638], "unseen": 23, "extrins": 23, "wrong": [23, 99, 105, 181], "goe": [23, 149, 150, 621, 623, 636, 637, 643], "bonus": 23, "denser": 23, "prior": [23, 314, 315, 357, 637], "freshli": 23, "drop": [23, 104, 106, 210, 278, 322, 347, 364, 375], "meant": [23, 141, 176], "encourag": [23, 147, 181, 354, 364, 367, 415, 621, 622, 640], "measur": [23, 85, 92, 94, 98, 113, 118, 119, 133, 134, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 347, 364, 375, 378, 412, 415, 623, 629], "novelti": 23, "revisit": 23, "diminish": 23, "decreas": [23, 627], "distil": 23, "nois": [23, 279, 310, 365, 368, 369, 404, 561, 604, 621, 636], "exploratori": [23, 345, 347, 361, 364, 375], "misalign": 23, "trade": [23, 627], "unavoid": 23, "prioriti": [23, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 87, 92, 93, 94, 95, 98, 99, 107, 109, 113, 348, 349, 350, 352, 353, 354, 355, 360, 365, 367, 368, 369, 621, 622, 640], "schedul": [23, 26, 322, 404, 623, 638], "bootstrap": [23, 355, 381, 382, 621, 624], "noisi": 23, "unstabl": [23, 98, 99, 301, 318, 319], "inher": [23, 345, 364], "stochast": [23, 239, 297, 306, 314, 346, 348, 351, 353, 354, 359, 360, 363, 365, 367, 415, 600, 601, 623, 627, 637], "enemi": 23, "pomdp": [23, 640], "loos": [23, 341, 586, 622, 623], "nonexist": 23, "sequenc": [23, 34, 35, 37, 40, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 68, 71, 72, 73, 74, 80, 83, 84, 91, 101, 103, 109, 112, 115, 116, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 133, 134, 135, 142, 143, 147, 148, 151, 153, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 197, 199, 205, 217, 218, 219, 220, 221, 226, 227, 229, 230, 234, 236, 237, 240, 244, 245, 249, 250, 251, 252, 253, 254, 255, 256, 260, 262, 264, 265, 266, 267, 269, 271, 277, 278, 286, 293, 303, 304, 308, 315, 322, 323, 324, 325, 326, 327, 328, 329, 330, 335, 342, 343, 351, 372, 373, 374, 375, 376, 377, 379, 380, 387, 388, 404, 405, 406, 408, 410, 593, 621, 623, 624, 625, 635, 636, 637, 643], "rather": [23, 64, 67, 68, 69, 70, 109, 145, 146, 176, 183, 251, 278, 569, 572, 621, 622, 623, 624, 626, 628, 636, 637, 640], "lstm": [23, 263, 302, 305, 625], "rel": [23, 68, 263, 293, 317, 621, 622, 636, 637, 640], "tend": 23, "stabl": [23, 28, 29, 98, 99, 144], "compens": 23, "descent": 23, "minimum": [23, 72, 117, 147, 156, 254, 297, 305, 317, 318, 319, 324, 330, 335, 344, 346, 348, 354, 362, 363, 367, 373, 375, 379, 400, 621, 623, 631, 636, 637], "manual": [23, 30, 41, 44, 46, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 127, 128, 178, 189, 414, 621, 624, 640], "deviat": [23, 244, 277, 278, 284, 297, 309, 364, 368, 369, 379, 403, 621, 627, 637], "radic": 23, "stabil": [23, 98, 99, 235, 322, 331, 332, 345, 347, 361, 364, 366, 375], "stage": [23, 621, 638], "never": [23, 34, 35, 40, 48, 54, 72, 98, 99, 265, 629, 642], "prevent": [23, 53, 55, 56, 57, 58, 59, 60, 61, 63, 65, 90, 98, 99, 118, 119, 277, 278, 301, 318, 319, 322, 330, 335, 345, 347, 361, 364, 366, 375, 407, 593, 630, 640], "solv": [23, 26, 28, 29, 64, 65, 67, 68, 181, 575, 592, 621, 622, 623, 629, 631, 636, 637, 638, 640], "entir": [23, 34, 35, 37, 46, 56, 80, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 219, 278, 566, 593, 623, 626, 638, 640], "submit": [23, 126, 216, 592, 642], "adequ": [23, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 623, 636, 637], "infeas": 23, "allevi": 23, "prune": [23, 135, 177], "fire": [23, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "certain": [23, 41, 42, 44, 46, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 209, 224, 225, 235, 261, 270, 299, 324, 330, 331, 332, 335, 361, 373, 375, 378, 379, 621, 622, 623, 625, 631, 636, 637, 643], "illeg": 23, "move": [23, 71, 82, 85, 93, 95, 117, 120, 123, 127, 128, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 212, 223, 228, 248, 263, 269, 270, 273, 275, 277, 278, 303, 324, 330, 335, 340, 373, 375, 378, 379, 407, 621, 622, 624, 626, 643], "chess": [23, 120, 145, 146], "grasp": 23, "wherein": 23, "cumul": [23, 256, 262, 623], "q": [23, 28, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 283, 288, 289, 290, 291, 294, 296, 298, 311, 312, 315, 346, 348, 349, 350, 352, 353, 354, 355, 360, 365, 367, 368, 369, 600, 621, 628, 633], "flow": [23, 381, 621, 623, 636, 637, 638, 640], "reparameter": [23, 293, 308], "soft": [23, 367, 415, 636], "critic": [23, 27, 175, 281, 345, 347, 348, 349, 353, 354, 360, 361, 364, 365, 366, 367, 368, 369, 375, 415, 469, 470, 591, 600, 607, 614, 621, 628], "clip": [23, 181, 222, 254, 345, 347, 361, 364, 366, 368, 369, 373, 375, 410, 414, 415, 469, 470, 623, 637, 638], "oppos": 23, "incorrect": [23, 105, 181, 364], "thought": [23, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 593], "region": [23, 99, 375], "squash": [23, 336, 624, 642], "tanh": [23, 286, 301, 303, 317, 318, 319, 344, 623, 627, 636, 637, 638, 639], "correct": [23, 83, 84, 98, 99, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 180, 181, 186, 219, 239, 323, 325, 326, 328, 329, 372, 374, 375, 376, 377, 380, 550, 614, 623, 624, 633], "prob": [23, 186, 187, 193, 194, 304, 308, 322, 324, 327, 330, 335, 623, 634, 637], "rememb": [23, 83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 636], "remap": 23, "origin": [23, 27, 83, 84, 87, 131, 168, 174, 228, 229, 239, 248, 270, 275, 323, 324, 325, 326, 328, 329, 330, 335, 339, 340, 341, 346, 348, 360, 362, 364, 365, 367, 368, 369, 372, 373, 374, 375, 376, 377, 379, 380, 593, 621, 625, 633, 635, 638, 643], "real": [24, 34, 35, 80, 324, 330, 335, 341, 624, 625, 638, 639], "histor": 24, "ceas": 24, "fork": [24, 75, 76, 77, 78, 79, 80, 81, 82, 621, 622, 623, 624, 636, 637, 639, 642], "farama": [24, 78, 136, 137, 149, 150, 623, 638], "bc": [24, 368], "break": [24, 34, 35, 37, 40, 46, 48, 50, 65, 67, 70, 75, 77, 78, 80, 81, 82, 85, 99, 105, 106, 111, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 219, 253, 277, 278, 300, 302, 318, 324, 330, 335, 373, 375, 378, 379, 388, 622, 625, 629, 631, 640, 642], "13": [24, 105, 106, 153, 224, 276, 278, 280], "gymwrapp": [24, 117, 120, 123, 127, 132, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 232, 257, 261, 276, 623, 642], "feel": [24, 592, 631, 642], "free": [24, 26, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 83, 84, 174, 210, 227, 230, 323, 325, 326, 328, 329, 345, 357, 364, 372, 374, 376, 377, 380, 614, 623, 631, 637, 642], "gladli": 24, "prepar": [25, 77, 168, 171, 193, 194, 379, 563, 565, 566, 568, 571, 572, 574, 576, 579, 580, 582, 585, 587, 588, 593, 623], "conda": [25, 26, 592], "cmake": 25, "14": [25, 75, 76, 77, 78, 79, 80, 81, 82, 105, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 224, 244, 280, 364], "sim": 25, "bullet": 25, "headless": [25, 26, 132, 182, 633], "cluster": [25, 26, 27, 41, 46, 77, 396, 397, 398, 592], "withbullet": 25, "forg": [25, 26], "aihabitat": [25, 129], "y": [25, 26, 67, 83, 84, 144, 174, 298, 323, 324, 325, 326, 328, 329, 330, 335, 372, 373, 374, 375, 376, 377, 379, 380, 461, 462, 465, 467, 621, 637, 640], "facebookresearch": [25, 77, 129], "subdirectori": 25, "verbos": [25, 48, 49, 85, 175, 322, 331, 378, 631, 633], "magnum_log": 25, "quiet": 25, "habitat_sim_log": 25, "remov": [25, 34, 35, 37, 39, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 250, 259, 270, 323, 324, 325, 326, 328, 329, 330, 335, 362, 372, 373, 374, 375, 376, 377, 378, 379, 380, 396, 397, 593, 636, 637, 642, 643], "readm": [25, 26, 161, 642], "md": [25, 26], "habitatenv": [25, 444], "_has_habitat": 25, "available_env": [25, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 133, 134, 135, 136, 139, 140, 144, 145, 146, 147, 148, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 168, 169, 170, 173, 176, 177, 178, 643], "startswith": [25, 285, 607, 621, 628], "oserror": 25, "libllvmlit": 25, "ionstal": 25, "pointer": [25, 124, 362, 621], "llvmlite": 25, "var": [25, 26, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 268, 270, 278, 324, 330, 335, 348, 362, 367, 373, 375, 378, 379], "ld_preload": [25, 26], "bind": 25, "deactiv": [25, 26, 118, 119, 295, 346, 348, 354, 360, 362, 365, 367, 368, 369, 382, 383, 384], "importerror": [25, 26, 29, 398, 634], "usr": [25, 26, 29], "x86_64": [25, 26], "linux": [25, 26], "gnu": [25, 26], "libopengl": [25, 26], "undefin": [25, 26, 29, 55, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 268, 270, 324, 330, 335, 348, 362, 367, 373, 375, 378, 379, 625, 640], "symbol": [25, 26, 29], "_glapi_tls_curr": [25, 26], "link": [25, 26, 123, 622, 631], "mujoco_env": [25, 26], "libglvnd": [25, 26], "glx": [25, 26], "cos7": [25, 26], "reinstal": [25, 26], "xvfbwrapper": [25, 26], "sysroot": [25, 26], "lib64": [25, 26], "libgldispatch": [25, 26], "offici": [26, 76, 188, 625], "stand": [26, 121, 122, 147, 156, 635, 638], "joint": [26, 622], "contact": [26, 636], "biomechan": 26, "graphic": 26, "anim": [26, 637], "area": 26, "demand": [26, 630, 643], "accur": [26, 76, 82, 593, 622, 638, 640], "articul": 26, "acquir": [26, 623], "deepmind": [26, 27, 28, 80, 117, 120, 121, 122, 123, 127, 135, 139, 140, 145, 146, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 231, 623, 626], "whomev": 26, "licenc": 26, "incorpor": [26, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 284, 299, 310, 368, 415, 624, 627, 638], "relianc": 26, "obsolet": 26, "pro": [26, 592], "tip": [26, 592], "glfw": [26, 621], "osmesa": 26, "egl": 26, "advic": [26, 80, 643], "sudo": [26, 592], "apt": [26, 637], "libglfw3": 26, "libglew2": 26, "libgl1": 26, "mesa": 26, "libosmesa6": 26, "workflow": [26, 281, 282, 283, 322, 593, 634], "glew": 26, "mesalib": 26, "anaconda": 26, "libgl": 26, "cos6": 26, "menpo": 26, "glfw3": 26, "mujoco_gl": 26, "pyopengl_platform": 26, "pre": [26, 47, 51, 80, 85, 94, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 248, 267, 273, 275, 324, 330, 335, 373, 375, 378, 379, 576, 643], "mkdir": 26, "earlier": [26, 621, 623, 624, 636, 637, 640], "roboti": 26, "download": [26, 29, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 75, 76, 77, 78, 80, 81, 82, 131, 248, 275, 388, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "html": [26, 34, 35, 142, 144, 145, 146, 633], "wget": 26, "mujoco210": 26, "tar": [26, 77], "gz": 26, "xf": 26, "charg": [26, 34, 35, 40, 147, 156], "mjkei": 26, "txt": [26, 379], "mjlib_path": 26, "home": 26, "bin": [26, 188, 296], "libmujoco210": 26, "ld_library_path": 26, "mujoco_py_mujoco_path": 26, "too": [26, 34, 35, 37, 40, 41, 42, 44, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 85, 98, 99, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 238, 239, 241, 243, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 301, 318, 319, 324, 330, 335, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 381, 382, 383, 384, 622, 627, 630, 638, 640, 643], "mujoco_py_mjkey_path": 26, "reload": 26, "later": [26, 98, 99, 291, 339, 341, 397, 576, 621, 623, 625, 640], "nvidia": [26, 131, 625], "older": [26, 280], "hack": [26, 621], "adatp": 26, "unnot": [26, 249], "mujoco_pi": 26, "trigger": [26, 176, 278, 324, 330, 335, 373, 375, 379, 575, 624], "cymj": 26, "linuxgpuextensionbuild": 26, "filenam": [26, 83, 84, 90, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 622, 640], "troubleshoot": [26, 347, 361, 364], "gl": 26, "h": [26, 68, 219, 221, 226, 252, 266, 300, 302, 388, 510, 622, 640], "eglshim": 26, "fatal": 26, "No": [26, 34, 35, 37, 40, 41, 42, 44, 46, 48, 50, 53, 55, 57, 61, 63, 175, 396, 566, 569, 575], "directori": [26, 75, 76, 77, 78, 80, 81, 82, 83, 84, 88, 92, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 393, 395, 582, 583, 584, 585, 621, 627, 630, 636], "devel": 26, "ubuntu": [26, 131], "libglew": 26, "dev": 26, "cento": 26, "yum": 26, "glu": 26, "38": 26, "disappear": [26, 622, 624, 635], "libstdc": 26, "6": [26, 34, 35, 37, 40, 48, 49, 52, 56, 58, 67, 75, 81, 82, 98, 99, 106, 121, 122, 127, 147, 154, 155, 170, 178, 212, 215, 224, 225, 244, 246, 262, 268, 278, 285, 286, 288, 289, 290, 293, 298, 303, 306, 317, 320, 338, 339, 622, 625, 642], "glibcxx_3": 26, "29": [26, 105, 106], "compil": [26, 34, 35, 37, 52, 67, 69, 70, 83, 84, 85, 87, 91, 92, 93, 94, 95, 99, 101, 105, 106, 107, 112, 113, 115, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 280, 318, 322, 323, 324, 325, 326, 328, 329, 330, 331, 335, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 422, 423, 424, 425, 429, 431, 432, 436], "libosmesa": 26, "libgcc": 26, "Then": [26, 34, 35, 37, 40, 41, 42, 44, 46, 173, 181, 276, 586, 587, 623, 635], "filenotfounderror": [26, 78], "errno": 26, "patchelf": 26, "fatalerror": 26, "gladloadgl": 26, "mj_env": 26, "912": 26, "glfwerror": 26, "65537": 26, "myscript": 26, "runtimeerror": [26, 27, 34, 35, 37, 40, 43, 48, 55, 56, 58, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 243, 268, 270, 324, 330, 331, 335, 348, 367, 373, 375, 378, 379, 563, 565, 566, 568, 571, 572, 574, 576, 579, 580, 582, 585, 587, 588, 643], "slurm": 26, "mjrendercontext": 26, "pyx": 26, "46": [26, 105, 118, 119], "114": 26, "_setup_opengl_context": 26, "opengl_context": 26, "130": 26, "offscreenopenglcontext": 26, "fail": [26, 34, 35, 37, 40, 47, 48, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 193, 213, 324, 330, 335], "opengl": [26, 636, 637], "global": [26, 67, 68, 69, 70, 85, 86, 117, 120, 123, 127, 135, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 224, 268, 324, 330, 333, 334, 335, 339, 341, 373, 375, 378, 379, 396, 397, 621, 636, 637], "cuda_visible_devic": [26, 588], "slurm_step_gpu": 26, "black": [26, 120, 636], "onscreen": 26, "101": 26, "lgl": 26, "libegl": 26, "x11": [26, 637], "xlib": 26, "libx11": 26, "xorg": 26, "attributeerror": [26, 34, 35, 40, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "nonetyp": 26, "glgeterror": 26, "this_dir": 26, "pwd": 26, "ln": 26, "libglut": 26, "12": [26, 29, 34, 35, 81, 83, 84, 92, 94, 106, 113, 133, 134, 147, 154, 155, 156, 170, 174, 188, 224, 270, 278, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 388, 640], "sketch": 27, "_": [27, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 93, 120, 124, 131, 161, 162, 174, 183, 220, 227, 229, 230, 239, 244, 251, 266, 277, 320, 323, 325, 326, 328, 329, 337, 340, 341, 345, 346, 348, 349, 353, 354, 360, 364, 365, 367, 368, 369, 372, 374, 376, 377, 380, 381, 382, 383, 384, 390, 621, 622, 623, 624, 625, 631, 636, 637, 638, 640, 642], "n_training_step": 27, "datapoint": [27, 640], "onlin": [27, 34, 40, 219, 292, 309, 345, 351, 363, 364, 400, 561, 623, 624, 637, 640], "n_data_per_train": 27, "no_grad": [27, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 239, 241, 324, 330, 335, 373, 375, 378, 379, 381, 382, 383, 384, 623, 624, 625, 637], "loss_fn": [27, 624, 628, 629, 642], "zero_grad": [27, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 323, 324, 325, 326, 328, 329, 330, 335, 372, 373, 374, 375, 376, 377, 378, 379, 380, 621, 623, 624, 625, 628, 631, 636, 637, 638], "backpropag": [27, 118, 119, 133, 134, 147, 345, 346, 347, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 373, 375, 379, 628, 637, 638], "differenti": [27, 118, 119, 239, 348, 368, 381, 382, 383, 384, 536, 537, 538, 540, 546, 547, 548, 624, 627, 628, 636, 637, 638], "pai": [27, 219, 621, 624], "denomin": 27, "artifact": 27, "numer": [27, 67, 98, 99, 127, 178, 277, 295, 296, 301, 311, 312, 318, 319, 322, 331, 332, 337, 339, 340, 341, 407, 623, 640, 643], "misconcept": 27, "freed": 27, "appear": [27, 30, 54, 63, 72, 75, 80, 99, 105, 106, 123, 176, 183, 184, 638, 640], "compuat": 27, "twice": [27, 106], "retain_graph": [27, 118, 119], "discuss": [27, 28, 629, 636, 637], "inplac": [27, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 323, 324, 325, 326, 327, 328, 329, 330, 335, 340, 372, 373, 374, 375, 376, 377, 378, 379, 380, 621], "accumul": [27, 315], "onto": [27, 63, 83, 84, 174, 187, 193, 204, 228, 284, 295, 296, 305, 310, 311, 312, 323, 325, 326, 328, 329, 337, 339, 340, 341, 372, 374, 376, 377, 380, 381, 624, 638], "submodul": [27, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 167, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 263, 300, 302, 324, 330, 335, 362, 373, 375, 378, 379], "param": [27, 83, 84, 85, 117, 120, 123, 127, 135, 141, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 223, 227, 228, 232, 239, 242, 250, 251, 257, 261, 267, 269, 271, 278, 293, 317, 323, 324, 325, 326, 328, 329, 330, 335, 339, 340, 343, 362, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 581, 586, 587, 621, 625, 631, 636, 637, 638, 639, 642], "grad": [27, 83, 84, 85, 117, 118, 119, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 323, 324, 325, 326, 328, 329, 330, 335, 341, 372, 373, 374, 375, 376, 377, 378, 379, 380, 621, 623], "whose": [27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 85, 117, 120, 123, 127, 135, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379, 575], "neg": [27, 34, 35, 37, 40, 41, 42, 44, 46, 64, 69, 71, 98, 99, 180, 219, 234, 249, 260, 272, 324, 347, 356, 361, 364, 381, 383, 384, 623, 636, 637, 638], "fit": [27, 244, 263, 280, 322, 621], "jax": [27, 118, 119, 133, 134, 280], "improperli": 27, "underli": [27, 117, 120, 123, 124, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 324, 330, 362, 614, 624, 626, 628, 630, 638], "tedeiou": 27, "amount": [27, 147, 310, 381, 622, 640], "costli": [27, 638], "concaten": [27, 34, 35, 46, 59, 61, 80, 83, 84, 174, 176, 219, 220, 244, 260, 303, 323, 325, 326, 328, 329, 343, 372, 374, 376, 377, 380, 621, 622, 627, 636, 637, 638, 640, 643], "constitut": [27, 622, 637, 638], "profil": 27, "techniqu": [27, 147, 156, 622, 625, 629, 640], "program": [27, 353, 360, 625, 643], "functorch": [27, 29], "incl": 27, "suit": [27, 122, 614, 623, 626, 642, 643], "mujoco_instal": 27, "valueerror": [27, 32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 328, 329, 330, 331, 335, 373, 375, 378, 379, 396, 397, 398, 575, 634], "bad": 27, "fds_to_keep": 27, "new_shap": 27, "permut": [27, 104, 246, 266, 625, 642, 643], "idea": [28, 98, 99, 365, 615, 624, 627, 636, 637], "introductori": 28, "intro": [28, 623, 624], "dai": [28, 642], "2022": [28, 29, 642], "spin": [28, 121, 122], "hug": [28, 327, 330, 634], "syllabu": 28, "lectur": 28, "awesom": 28, "curat": 28, "succinct": [28, 627], "summari": [28, 244, 277, 278, 621, 622, 623, 624], "reddit": 28, "reagent": 28, "orient": [28, 82, 643], "baselines3": 28, "tf": 28, "bandit": [28, 144], "tensorflow": [28, 304], "kera": 28, "acm": 28, "dopamin": 28, "prototyp": [28, 414, 415, 625, 631], "salina": 28, "sequenti": [28, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 218, 239, 281, 282, 283, 324, 330, 335, 339, 342, 343, 345, 346, 348, 354, 360, 364, 365, 366, 367, 368, 373, 375, 378, 379, 600, 623, 624, 627, 637, 638, 639, 642, 643], "tianshou": 28, "eleg": 28, "rlpyt": 28, "rllib": 28, "industri": [28, 642], "grade": 28, "throughput": [28, 134, 322, 331, 335, 621], "cherri": 28, "jaxrl": 28, "space": [28, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 84, 89, 90, 97, 117, 120, 123, 126, 127, 128, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 204, 207, 212, 222, 229, 237, 240, 263, 271, 284, 286, 292, 295, 296, 307, 310, 311, 312, 315, 320, 335, 337, 339, 340, 341, 343, 344, 345, 350, 352, 353, 354, 364, 368, 369, 570, 622, 623, 624, 625, 626, 627, 628, 636, 637, 638, 643], "mbrl": [28, 141], "rlmeta": 28, "light": 28, "elegantrl": 28, "cloud": 28, "mtrl": 28, "baselin": 28, "689": 29, "_torchrl": 29, "_zn8pybind116detail11type_casterin2at6tensoreve4loadens_6handleeb": 29, "colab": [29, 623, 624, 636, 637], "notebook": [29, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "24": [29, 81, 106, 126, 142, 143, 170, 181, 336, 338, 388, 636], "pip3": [29, 621, 623, 624, 636, 637], "extra": [29, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 210, 219, 277, 278, 323, 324, 325, 326, 328, 329, 330, 335, 372, 373, 374, 375, 376, 377, 378, 379, 380, 395, 623, 624, 640], "url": [29, 83, 129, 184, 633], "org": [29, 34, 35, 64, 77, 78, 80, 82, 98, 99, 118, 119, 121, 122, 129, 133, 134, 139, 140, 142, 143, 144, 153, 161, 162, 219, 248, 273, 287, 288, 289, 290, 291, 292, 296, 297, 298, 304, 306, 307, 310, 313, 314, 315, 345, 346, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 363, 364, 366, 367, 368, 381, 590, 632, 639], "whl": 29, "u": [29, 79, 638], "upgrad": 29, "lib_version_her": 29, "heavili": 30, "pyav": 30, "conveni": [30, 219, 322, 396, 623, 636, 637, 638, 640], "knob": 30, "dispos": 30, "guid": [30, 149, 150, 154, 155, 262, 322, 592, 621, 637, 642], "clarifi": 30, "behind": [30, 257], "adjust": [30, 263, 621, 636, 637, 638], "ultim": [30, 301, 318, 319], "ffmpeg": 30, "whatev": [30, 324, 330, 335, 621], "fed": [30, 637, 640], "feed": [30, 248, 275, 362, 373, 375, 379, 621, 636, 637, 640], "suppos": [30, 147, 404, 643], "snippet": [30, 248, 273, 621], "gave": 30, "blurri": [30, 625], "stitch": 30, "my_exp": [30, 630], "pixels_onli": [30, 121, 122, 126, 128, 129, 153, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 621, 622, 630, 631, 642, 643], "my_video": [30, 630], "record_env": [30, 630, 631], "codec": 30, "h264": 30, "constant": [30, 98, 99, 219, 244, 262, 621, 623, 624, 643], "crf": 30, "17": [30, 81, 105, 106, 127, 147, 178, 212, 224], "preset": 30, "allow_non": 31, "unwrap": [31, 231, 270, 399, 490], "seealso": 31, "close_env": [32, 34, 35, 37, 40, 41, 42, 44, 48], "init_updat": [32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49], "init": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 65, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 269, 277, 322, 324, 327, 330, 335, 373, 375, 378, 379, 381, 395, 396, 398, 581, 586, 588, 614, 622, 623], "posit": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 99, 117, 120, 121, 122, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 224, 234, 235, 237, 259, 260, 261, 264, 268, 270, 272, 305, 324, 330, 335, 348, 367, 373, 375, 378, 379, 396, 397, 623, 636, 637, 638, 640], "implic": [32, 41, 42, 44], "notimplementederror": [32, 41, 42, 44, 621], "policy_or_weight": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50], "tensordictmodulebas": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 218, 241, 295, 311, 324, 330, 335, 338, 373, 375, 379, 463, 624], "worker_id": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 572, 579, 585, 587], "weights_dict": [32, 34, 35, 37, 40, 41, 42, 44, 46, 48], "upload": [32, 34, 35, 37, 40, 41, 42, 44, 46, 48], "extract": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 56, 58, 77, 99, 168, 182, 184, 188, 191, 195, 197, 215, 237, 267, 271, 563, 565, 566, 568, 571, 572, 574, 576, 579, 580, 582, 585, 587, 588, 589, 593, 621, 623, 642], "Will": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 83, 84, 99, 105, 142, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 388, 614], "_get_server_weight": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50], "identifi": [32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 175, 176, 177, 178, 193, 194, 396, 397, 563, 565, 566, 568, 571, 574, 575, 576, 580, 582, 583, 588, 595, 614, 633], "atom": [32, 34, 35, 37, 40, 41, 42, 44, 46, 48], "typeerror": [32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "weight_updat": [32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 416, 418, 419, 420, 622], "conflict": [32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 169, 324, 330, 335], "overwritten": [32, 34, 35, 37, 40, 41, 42, 44, 46, 48, 75, 77, 78, 80, 81, 82, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 234], "localweightsupdaterbas": [32, 34, 35, 37, 40, 41, 42, 44, 46, 48], "remoteweightsupdaterbas": [32, 34, 35, 37, 40, 41, 42, 44, 46, 48], "get_server_weight": 33, "abc": [33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 46, 48, 49, 50, 51, 56, 58, 59, 64, 66, 67, 68, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 87, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 175, 176, 177, 178, 193, 195, 216, 217, 218, 219, 220, 221, 223, 226, 227, 230, 234, 236, 240, 244, 245, 250, 252, 253, 254, 255, 256, 260, 262, 263, 264, 266, 269, 270, 271, 277, 278, 280, 286, 293, 303, 304, 308, 405, 406, 413, 559, 560], "policy_weight": [33, 36, 38, 43, 45, 575, 576], "datacollectorbas": [33, 34, 36, 38, 39, 42, 43, 45, 50, 51, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 269, 339, 341, 378, 413, 414, 415, 552, 553, 557], "all_worker_id": [33, 36, 38, 39, 43, 45, 50, 51], "scope": [33, 36, 38, 39, 43, 45, 50, 51, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 625, 643], "classmethod": [33, 36, 38, 39, 43, 45, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 237, 273, 280, 286, 287, 309, 322, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "from_polici": [33, 36, 38, 39, 43, 45, 50, 51], "back": [33, 36, 39, 43, 45, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 71, 72, 73, 74, 76, 83, 84, 86, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 174, 176, 177, 178, 197, 267, 276, 295, 296, 311, 312, 323, 325, 326, 328, 329, 337, 339, 340, 341, 372, 374, 376, 377, 380, 562, 564, 583, 623, 625, 636, 637, 638, 640], "increment_vers": [33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 48, 49, 50, 51, 189], "increment": [33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 48, 49, 50, 51, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 176, 177, 178, 189, 244, 361, 593], "post_hook": [33, 36, 38, 39, 43, 45, 50, 51], "post": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 78, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 593], "push_weight": [33, 36, 38, 39, 43, 45, 50, 51], "noth": [33, 36, 38, 39, 43, 45, 50, 135, 177, 621, 623], "register_collector": [33, 36, 38, 39, 43, 45, 50, 51, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 324, 330, 335], "register_post_hook": [33, 36, 38, 39, 43, 45, 50, 51], "policy_factori": [34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 416, 418, 419, 420], "env_devic": [34, 35, 37, 40, 41, 42, 44, 46, 416, 418, 419, 420, 622], "create_env_kwarg": [34, 35, 37, 40, 46, 117, 124, 142, 147, 156, 268, 416, 418, 419, 420, 437, 621, 643], "collector_class": [34, 35, 41, 42, 44, 45, 46, 567, 568], "postproc": [34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 253, 416, 418, 419, 420, 622, 640], "interactiontyp": [34, 37, 40, 41, 42, 44, 46, 165, 208, 339, 341, 404], "preemptive_threshold": [34, 35, 40], "num_thread": [34, 35, 40, 83, 84, 127, 147, 156, 174, 178, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 582, 583], "num_sub_thread": [34, 35, 40, 147, 156], "set_trunc": [34, 35, 37, 40, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 416, 418, 419, 420], "use_buff": [34, 35, 37, 147, 156, 416, 418, 419, 420], "extend_buff": [34, 35, 37, 416, 418, 419, 420], "replay_buffer_chunk": 34, "local_init_rb": [34, 35, 37, 416, 418, 419, 420], "trust_polici": [34, 35, 37, 46, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 416, 418, 419, 420], "compile_polici": [34, 35, 37, 416, 418, 419, 420], "cudagraph_polici": [34, 35, 37, 416, 418, 419, 420], "no_cuda_sync": [34, 35, 37, 46, 416, 418, 419, 420], "weightsyncschem": [34, 35, 37, 39, 41, 44, 46, 578, 579], "track_policy_vers": [34, 35, 37, 40, 48, 49, 189, 416, 418, 419, 420, 593], "recept": 34, "safe": [34, 35, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 99, 105, 174, 284, 295, 296, 310, 311, 312, 317, 318, 323, 325, 326, 328, 329, 337, 339, 340, 341, 343, 372, 374, 376, 377, 380, 600, 642], "guard": [34, 35], "doc": [34, 35, 129, 132, 133, 134, 144, 153, 184, 395, 593, 622, 636, 637, 640], "env_mak": [34, 35, 37, 46, 65, 117, 557, 643], "2000": [34, 35, 37, 130, 388, 640], "del": [34, 35, 37, 48, 621, 622, 623, 635, 636, 640, 642, 643], "int64": [34, 35, 37, 48, 52, 53, 55, 57, 59, 60, 61, 63, 69, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 98, 105, 117, 120, 123, 127, 135, 138, 139, 140, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 183, 212, 216, 224, 231, 246, 253, 261, 295, 296, 310, 311, 312, 323, 325, 326, 328, 329, 339, 372, 374, 376, 377, 380, 638], "randompolici": [34, 35, 37, 40, 41, 42, 44, 46, 47, 48, 219, 253, 629, 640], "signatur": [34, 35, 37, 40, 41, 42, 44, 46, 64, 65, 67, 68, 85, 86, 109, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 207, 216, 223, 237, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379, 621, 625, 626, 638], "undergon": [34, 35, 37, 40, 41, 42, 44, 46], "env_obs_kei": [34, 35, 37, 40, 41, 42, 44, 46], "mustn": [34, 35, 37, 40, 41, 42, 44, 46], "pickl": [34, 35, 37, 40, 41, 42, 44, 46, 64, 67, 68, 69, 70, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 277, 278, 324, 330, 335, 373, 375, 378, 379], "exclus": [34, 35, 37, 40, 41, 42, 44, 46, 48, 49, 62, 67, 69, 70, 75, 80, 83, 84, 99, 105, 106, 174, 180, 216, 232, 234, 241, 295, 296, 300, 302, 304, 311, 312, 323, 325, 326, 328, 329, 332, 368, 369, 372, 374, 376, 377, 380, 381, 382, 383, 384, 385, 395, 561], "ignor": [34, 35, 37, 40, 41, 42, 44, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 85, 90, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 229, 232, 257, 266, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 304, 305, 306, 307, 309, 310, 312, 313, 314, 323, 324, 325, 326, 328, 329, 330, 335, 336, 338, 344, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 564, 633, 634, 640], "lifespan": [34, 35, 37, 40, 41, 42, 44, 48, 49, 622], "divis": [34, 35, 37, 40, 41, 42, 44, 75, 80, 99, 105, 106, 278, 637], "endless": [34, 35, 37, 40, 41, 42, 44, 183, 593], "sit": [34, 35, 37, 40, 41, 42, 44, 46, 413, 622], "deriv": [34, 35, 41, 42, 44, 46, 83, 84, 174, 293, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 410], "span": [34, 35, 37, 40, 41, 42, 44, 46, 80, 99, 105, 106, 431, 432], "n_step": [34, 35, 37, 40, 41, 42, 44, 46, 338, 501, 622, 623, 636, 637], "independ": [34, 35, 37, 40, 41, 42, 44, 46, 48, 77, 147, 156, 184, 234, 242, 263, 272, 322, 345, 364, 396, 586, 614, 621, 622, 624, 637, 640, 642], "mainli": [34, 35, 37, 40, 41, 42, 44, 46, 168, 169, 170, 173, 395, 636, 637, 638], "round": [34, 35, 37, 40, 41, 42, 44, 46, 75, 120, 190, 322, 429, 614], "closest": [34, 35, 37, 40, 41, 42, 44, 46], "multistep": [34, 35, 37, 40, 41, 42, 44, 46, 48, 622], "explorationtyp": [34, 35, 37, 40, 41, 42, 44, 46, 339, 362, 404, 621, 622, 623, 624, 627, 636, 642], "boolm": [34, 35, 40], "ratio": [34, 35, 40, 347, 364, 410, 412, 621, 623], "finish": [34, 35, 37, 40, 46, 48, 127, 178, 253, 569, 573, 643], "earli": [34, 35, 40, 98, 99, 127, 178, 261, 324, 330, 335, 642], "plu": [34, 35, 40, 147, 156, 593, 638], "harm": [34, 35, 40, 147, 156], "add_truncated_kei": [34, 35, 37, 40, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 270], "fake": [34, 35, 83, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 621, 622, 625], "coordin": [34, 35, 46, 92, 94, 226, 581, 582, 584, 586, 587, 614], "trust": [34, 35, 37, 46, 117, 120, 123, 127, 135, 139, 140, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 225, 302, 375], "cudagraphmodul": [34, 35, 37, 46, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "behaviour": [34, 35, 37, 324, 330, 335, 373, 375, 379, 624, 625, 642], "bypass": [34, 35, 37, 78, 627], "isaaclab": [34, 35, 37, 128, 132], "maniskil": [34, 35, 37], "crash": [34, 35, 37, 253], "multiprocessedweightupdat": [34, 35], "policyvers": [34, 35, 37, 40, 48, 49, 593], "mediat": [34, 35, 37, 40, 48], "get_cached_weight": [34, 35, 40, 563, 568, 580, 582, 588], "get_model": [34, 35, 37, 40, 48, 49, 563, 568, 572, 579, 580, 582, 585, 587, 588], "value_net": [34, 35, 37, 40, 48, 49, 350, 352, 366, 381, 382, 383, 384, 623, 625, 627, 628, 631], "recogn": [34, 35, 37, 40, 48, 49, 396], "get_policy_vers": [34, 35, 37, 40, 48, 49], "uuid": [34, 35, 37, 40, 48, 49, 189, 391, 622, 643], "disabl": [34, 35, 37, 40, 48, 49, 53, 55, 57, 59, 60, 61, 63, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 270, 301, 319, 324, 330, 335, 373, 375, 378, 379, 386, 414, 566, 621, 636, 637], "getattr_env": [34, 35, 37, 40, 48, 49], "attr": [34, 35, 37, 40, 48, 49], "getattr_polici": [34, 35, 37, 40, 48, 49], "getattr_rb": [34, 35, 37, 40, 48, 49], "load_state_dict": [34, 35, 37, 40, 46, 48, 49, 83, 84, 85, 87, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 268, 270, 277, 278, 323, 324, 325, 326, 328, 329, 330, 335, 348, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 412, 621], "ordereddict": [34, 35, 37, 40, 46, 48, 49, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 268, 270, 277, 278, 324, 330, 335, 348, 367, 373, 375, 378, 379], "form": [34, 35, 40, 64, 67, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 89, 90, 97, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 277, 278, 300, 302, 315, 324, 330, 335, 341, 345, 347, 361, 364, 373, 375, 378, 379, 410, 415, 627], "worker0": [34, 35, 40], "state_dict0": [34, 35, 40], "worker1": [34, 35, 40, 614], "state_dict1": [34, 35, 40], "policy_vers": [34, 35, 37, 40, 48, 49, 189, 593], "reset_idx": [34, 35, 40], "static_se": [34, 35, 37, 40, 46, 48, 49, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 270], "integ": [34, 35, 37, 40, 48, 49, 52, 59, 61, 63, 99, 105, 106, 107, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 176, 177, 178, 189, 212, 215, 231, 235, 244, 261, 278, 286, 303, 348, 353, 360, 367, 625, 640], "env_fn": [34, 35, 37, 40, 48, 49, 124, 559, 560], "env_fn_parallel": [34, 35, 37, 40, 48, 49], "300": [34, 35, 37, 40, 48, 49, 105, 106, 290, 291], "out_se": [34, 35, 37, 40, 48, 49, 643], "raise_on_error": [34, 35, 37, 40, 48, 396], "irrevers": [34, 35, 40], "tqdm": [34, 35, 37, 40, 48, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 410, 621, 623, 624, 636, 637, 638], "ale_pi": [34, 35, 37, 40, 48, 625], "progress": [34, 35, 37, 40, 48, 49, 322, 402, 403, 404, 410, 412, 414, 415, 470, 622, 624, 643], "bar": [34, 35, 37, 40, 48, 92, 94, 113, 322, 402, 403, 404, 410, 414, 415, 470, 622], "pbar": [34, 35, 37, 40, 48, 75, 76, 77, 78, 79, 80, 81, 82, 621, 623, 624, 636, 637, 638], "100_000": [34, 35, 37, 40, 48, 625, 631], "prec_wc": [34, 35, 37, 40, 48], "wc": [34, 35, 37, 40, 48], "write_count": [34, 35, 37, 40, 48, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 412], "set_descript": [34, 35, 37, 40, 48, 621, 623, 624, 636, 637, 638], "f": [34, 35, 37, 40, 48, 81, 85, 118, 119, 127, 133, 134, 178, 186, 188, 191, 193, 194, 265, 280, 379, 381, 382, 383, 384, 385, 614, 621, 622, 623, 624, 631, 634, 636, 637, 638, 640, 643], "remote_collector": [36, 46, 573, 574], "max_interv": 36, "_maybe_map_weight": [36, 39, 43, 45, 50], "_sync_weights_with_work": [36, 39, 43, 45, 50], "_skip_upd": 36, "interv": [36, 212, 265, 387, 388, 401, 413, 414, 415, 470, 622, 638], "env_creat": [37, 124, 621], "return_same_td": [37, 420], "interruptor": [37, 420], "cautious": [37, 364], "whole": [37, 56, 58, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 268, 270, 324, 330, 335, 339, 348, 367, 373, 375, 378, 379, 400, 621, 623], "_interruptor": 37, "start_collect": 37, "stop_collect": 37, "preeptiv": 37, "chunk": [37, 48, 49, 85, 627], "policy_state_dict": [37, 48, 49], "env_state_dict": [37, 48, 49], "weight_gett": 38, "vanillaweightsend": 38, "update_weight": [38, 43, 45, 322, 413, 569, 572, 579, 585, 587, 588, 593], "piec": [39, 91, 101, 112, 115, 116, 621, 622, 623, 630, 636, 637, 638, 640], "_push_weight": 39, "unchang": [39, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 229, 241, 248, 263, 269, 270, 273, 275, 299, 324, 330, 335, 340, 373, 375, 378, 379, 388, 406, 586, 587, 621, 640], "__call__": [39, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 199, 324, 330, 335, 341, 373, 375, 378, 379], "proxi": [39, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 174, 308, 323, 325, 326, 328, 329, 339, 372, 374, 376, 377, 380], "weakref": 39, "exporationtyp": [41, 42, 44], "collector_kwarg": [41, 42, 44, 46], "num_workers_per_collector": [41, 42, 44, 46], "slurm_kwarg": [41, 42, 44], "update_after_each_batch": [41, 42, 44, 46], "max_weight_update_interv": [41, 42, 44, 46], "tcp_port": [41, 42, 44, 47], "string": [41, 42, 44, 62, 85, 86, 93, 117, 120, 123, 127, 135, 139, 145, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 209, 237, 248, 261, 267, 275, 295, 300, 302, 311, 322, 323, 324, 327, 330, 335, 338, 339, 373, 375, 378, 379, 387, 403, 408, 593, 621, 623, 624, 633, 640], "respect": [41, 42, 44, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 213, 217, 223, 227, 230, 242, 248, 249, 258, 263, 269, 270, 273, 275, 314, 320, 324, 330, 335, 340, 345, 347, 361, 364, 366, 373, 375, 378, 379, 381, 383, 384, 405, 623, 624, 636, 637], "subnod": [41, 42, 44, 46], "readi": [41, 44, 46, 48, 49, 168, 322, 563, 565, 566, 568, 571, 574, 575, 576, 580, 582, 583, 586, 588, 592, 622, 623, 625, 627, 630, 640, 642], "fashion": [41, 44, 46, 83, 84, 106, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "distributed_back": [41, 42], "ucc": [41, 42], "turn": [41, 42, 44, 46, 49, 56, 58, 83, 84, 85, 120, 134, 147, 158, 168, 174, 224, 236, 269, 272, 276, 295, 323, 325, 326, 328, 329, 372, 374, 375, 376, 377, 380, 381, 386, 404, 593, 621, 622, 624, 627, 638, 639], "submitit_delai": [41, 47], "former": [41, 42, 44, 52, 64, 67, 69, 70, 76, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 312, 313, 314, 336, 338, 344, 621], "whilst": [41, 42, 44, 83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "latter": [41, 42, 44, 76, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 312, 313, 314, 324, 330, 335, 336, 338, 344, 364, 373, 375, 378, 379, 559, 560], "homonym": [41, 42, 44, 638], "visit": [41, 42, 44, 173], "facebookincub": [41, 42, 44], "tcp": [41, 42, 44, 47], "port": [41, 42, 44, 47, 50, 159, 322, 333, 334, 581, 588], "10003": [41, 42, 44, 47], "distributedweightupdat": 41, "liter": [42, 83, 117, 163, 168, 169, 170, 172, 173, 176, 180, 181, 183, 189, 322, 323, 325, 326, 328, 329, 330, 335, 375, 379, 565, 566, 568, 569, 573, 574, 580, 582, 588], "update_interv": 42, "frequenc": [42, 335, 415, 621], "restart": 43, "rank": [43, 83, 84, 111, 174, 322, 323, 325, 326, 328, 329, 333, 334, 372, 374, 376, 377, 380, 562, 563, 581, 586, 587, 588], "less": [43, 83, 84, 98, 99, 142, 174, 323, 325, 326, 328, 329, 330, 372, 374, 376, 377, 380, 559, 560, 623, 624, 640, 642], "visible_devic": 44, "tensorpipe_opt": 44, "experiment": [44, 50, 52, 63, 75, 339, 341, 414, 415], "tensorpiperpcbackendopt": 44, "rpcweightupdat": 44, "collector_info": [45, 567, 568], "collector_rref": [45, 567, 568], "_td": [46, 85, 124, 356, 364], "ray_init_config": [46, 49, 65, 396, 398], "remote_config": [46, 48, 49, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82], "num_collector": [46, 559, 560, 621, 622], "use_env_cr": [46, 561], "autodetect": 46, "num_cpu": [46, 49, 65, 190, 191, 192, 241, 327, 396, 397, 398, 614], "num_gpu": [46, 49, 65, 192, 241, 327, 396, 397, 614], "equat": [46, 80, 127, 178, 277, 278, 310, 347, 623, 626, 638], "exce": [46, 640], "indefinit": 46, "rayreplaybuff": [46, 64, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82], "enfoc": 46, "rayweightupdat": 46, "rayweightsyncschem": 46, "distributed_collector": [46, 65], "add_collector": 46, "shutdown_rai": [46, 65], "kill": [46, 396], "local_polici": 46, "stop_remote_collector": 46, "num_job": 47, "tcpport": 47, "submitit_main_conf": 47, "slurm_cpus_per_task": 47, "slurm_gpus_per_nod": 47, "slurm_partit": 47, "timeout_min": 47, "submitit_collection_conf": 47, "delai": [47, 368, 628], "jump": [47, 626], "host": [47, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379, 569, 571, 572], "satellit": 47, "rendezv": 47, "hang": 47, "forev": 47, "default_config": [47, 287, 292, 309], "default_slurm_conf_main": 47, "default_slurm_conf": 47, "boundedcontinu": [47, 54, 56, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 237, 240, 271], "dialog_turns_per_batch": [48, 49, 593], "yield_only_last_step": [48, 49], "yield_completed_trajectori": [48, 49], "total_dialog_turn": [48, 49, 85], "async_env": [48, 49], "flatten_data": [48, 49], "queue": [48, 151, 277, 324, 330, 335, 378, 614, 640, 642], "vllm": [48, 50, 51, 176, 322, 331, 332, 333, 334, 335, 581, 582, 583, 584, 585, 586, 587, 588, 593, 633], "vllmwrapper": [48, 168, 176, 324, 330, 593, 634], "mocking_class": [48, 268], "dummystrdataload": 48, "llmenv": [48, 171, 179, 183], "llm_model": 48, "gpt2": [48, 135, 177, 287, 292, 309, 327, 330, 335, 614], "token": [48, 84, 85, 86, 135, 168, 169, 170, 172, 173, 175, 176, 177, 179, 180, 181, 182, 186, 187, 191, 193, 194, 196, 322, 323, 324, 327, 328, 330, 335, 373, 375, 379, 396, 397, 398, 525, 593, 595, 614, 633, 634], "get_token": 48, "pad_token": [48, 193, 194, 379], "eos_token": [48, 172, 193, 194, 379], "from_dataload": [48, 168, 169, 170, 173, 176, 183], "from_text": [48, 84, 86, 176, 183, 379], "group_repeat": [48, 168, 169, 170, 173, 176, 179, 183], "attention_mask": [48, 176, 330, 335], "22": [48, 80, 87, 105, 106, 276], "text": [48, 78, 83, 84, 85, 86, 135, 168, 169, 170, 172, 173, 175, 176, 177, 185, 187, 188, 191, 193, 194, 201, 310, 322, 323, 324, 327, 329, 330, 331, 335, 378, 379, 593, 595, 623, 633], "nontensorstack": [48, 62, 84, 93, 117, 120, 135, 170, 173, 177, 183, 197, 237, 267, 271], "plsgqejeyd": 48, "text_respons": [48, 170, 173, 175, 176, 178, 181, 191, 379, 593, 633], "ec": 48, "tjbjz3perwhz": 48, "tokens_respons": [48, 176], "as_remot": [48, 49, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82], "cl": [48, 49, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 622], "quantiti": [48, 49, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82], "reserv": [48, 49, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "alia": [48, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 85, 87, 92, 93, 94, 95, 107, 109, 113, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 345, 346, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 363, 364, 365, 366, 367, 368, 369, 373, 375, 378, 379, 385], "get_policy_model": [48, 49], "rayllmcollector": [48, 593], "is_initi": [48, 49, 327, 614], "sync_it": 49, "lightweight": [49, 195, 625, 630], "dialog": [49, 85], "yeild": 49, "idl": [49, 147], "somehwat": 49, "serializ": [49, 327], "v2": [50, 51, 83, 84, 133, 134, 154, 155, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 624], "master_address": [50, 322, 333, 334, 581, 588], "master": [50, 322, 333, 334, 581, 588, 636, 637], "address": [50, 322, 333, 334, 396, 398, 581, 588, 593, 640], "localhost": [50, 159, 333, 334, 588], "master_port": [50, 322, 333, 334, 581, 588, 593], "model_metadata": [50, 51, 581, 586, 587], "tupl": [50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 90, 95, 99, 105, 109, 111, 117, 120, 121, 122, 123, 126, 127, 128, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 219, 237, 239, 244, 285, 288, 294, 295, 296, 300, 302, 303, 305, 309, 311, 312, 322, 323, 324, 325, 326, 328, 329, 330, 335, 344, 345, 346, 347, 348, 349, 353, 354, 356, 360, 361, 362, 364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 403, 404, 407, 469, 539, 540, 541, 543, 544, 545, 547, 549, 554, 562, 563, 564, 567, 568, 569, 573, 575, 577, 581, 586, 587, 589, 633, 640, 642], "metadata": [50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 75, 76, 83, 84, 88, 117, 120, 123, 124, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 322, 323, 325, 326, 328, 329, 348, 354, 367, 368, 372, 374, 376, 377, 380, 586, 588, 589, 593, 623, 626, 628, 629, 636, 637, 643], "vllm_tp_size": 50, "vllmupdaterv2": [50, 593], "asyncvllm": [50, 331, 335, 581, 584, 593], "vllm_engin": [50, 51, 581, 582, 584, 586, 587, 588, 593], "Not": [50, 59, 60, 67, 118, 119, 133, 268, 300, 302, 330, 582, 583, 584, 588], "reliabl": [50, 593], "get_model_metadata": [50, 51, 322, 591, 593], "transformerswrapp": [50, 51, 168, 193, 194, 324, 327, 335, 379, 585, 593, 634], "rlvllmengin": [51, 332, 588], "vllmupdat": [51, 593], "get_tp_siz": [51, 322], "push_weights_from_transform": 51, "transformers_model": [51, 634], "pretrainedmodel": 51, "push_weights_from_transformers_optim": 51, "rollout_tensordict": 52, "_nestedkei": [52, 58, 99, 105, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 176, 177, 178, 210, 217, 218, 219, 220, 221, 226, 227, 230, 234, 236, 239, 240, 244, 245, 249, 250, 252, 253, 254, 255, 256, 260, 262, 263, 264, 266, 269, 271, 278, 324, 330, 335], "nestedkei": [52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 85, 99, 105, 106, 117, 120, 123, 127, 135, 147, 148, 151, 152, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 186, 193, 194, 197, 205, 210, 211, 212, 213, 217, 218, 219, 220, 221, 222, 226, 227, 228, 229, 230, 231, 232, 234, 236, 237, 238, 239, 240, 244, 245, 246, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 277, 278, 284, 285, 299, 310, 323, 324, 325, 326, 328, 329, 330, 335, 338, 341, 347, 350, 361, 364, 372, 374, 376, 377, 378, 380, 386, 388, 403], "as_nest": 52, "x": [52, 67, 80, 83, 84, 106, 135, 174, 177, 237, 239, 266, 271, 280, 285, 286, 295, 298, 300, 302, 303, 311, 323, 324, 325, 326, 328, 329, 330, 335, 336, 339, 372, 373, 374, 375, 376, 377, 379, 380, 386, 388, 410, 593, 621, 625, 636, 638, 640, 642], "max": [52, 63, 69, 98, 99, 111, 134, 175, 229, 264, 310, 346, 347, 348, 354, 363, 365, 367, 375, 403, 414, 593, 621, 623, 624, 625, 631], "durat": [52, 637], "meta": [52, 71, 76, 83, 84, 86, 125, 129, 174, 188, 323, 325, 326, 328, 329, 345, 347, 361, 364, 366, 372, 374, 376, 377, 380, 623, 636, 637, 640], "aren": [52, 262, 575, 624], "eventu": [52, 624, 638], "recov": [52, 76, 78, 80, 81, 82, 83, 84, 105, 106, 174, 323, 325, 326, 328, 329, 342, 353, 360, 372, 374, 376, 377, 380, 635], "layout": [52, 324, 327, 330, 335], "to_padded_tensor": 52, "nested_tensor": [52, 126, 128], "stride": [52, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 286, 288, 289, 298, 324, 330, 335, 373, 375, 378, 379, 461, 622, 636, 642], "jag": 52, "focu": [52, 621, 622, 623, 625, 627, 628, 629, 636], "team": [52, 636, 637, 642], "cat": [52, 83, 84, 174, 183, 320, 323, 325, 326, 328, 329, 346, 348, 349, 360, 365, 367, 368, 369, 372, 374, 376, 377, 380, 636, 640, 642], "arang": [52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 99, 105, 106, 212, 295, 304, 400, 640], "obs_": 52, "15": [52, 75, 76, 77, 78, 79, 80, 81, 82, 106, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 188, 224, 310, 356, 640], "trajectory_id": 52, "int32": [52, 54, 70, 72, 75, 80, 105, 133, 134, 145, 146, 158, 204, 338], "data_split": 52, "got": [52, 629], "int8": [53, 123, 138, 149, 150, 217], "encod": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 71, 72, 73, 74, 83, 84, 118, 119, 123, 126, 127, 128, 129, 132, 133, 134, 142, 143, 145, 146, 153, 159, 160, 174, 178, 212, 229, 307, 308, 313, 315, 323, 324, 325, 326, 328, 329, 330, 335, 372, 374, 376, 377, 380, 396, 614, 622, 623, 624, 627, 638, 640], "unlik": [53, 67, 69, 70, 104, 127, 139, 140, 161, 162, 178, 338, 355, 364, 388, 572, 622, 625, 627, 629, 642], "null": [53, 54, 56, 58, 62, 64, 69, 71, 72, 73, 74, 168, 176, 217, 237], "denot": [53, 637], "clariti": [53, 270], "assert_is_in": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "belong": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 75, 80, 276, 277, 341, 621, 629, 637], "cardin": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 295, 296, 312, 623], "outcom": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 293, 304, 317, 362, 373, 375, 379, 636], "cartesian": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "clear_device_": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "is_in": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 643], "ndarrai": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 127, 174, 178, 310, 323, 325, 326, 328, 329, 344, 372, 374, 376, 377, 380, 386, 625, 636], "ignore_devic": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "arrai": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 71, 72, 73, 74, 83, 84, 87, 98, 117, 120, 123, 127, 128, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 183, 231, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 621, 636], "np": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 87, 127, 174, 178, 276, 323, 325, 326, 328, 329, 344, 372, 374, 376, 377, 380, 386, 625, 636, 638], "use_mask": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 149, 150], "erase_memoize_cach": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "memoiz": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 127, 178], "memoize_encod": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "broadcast": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 293, 322, 354, 367, 579, 581, 586, 587, 588, 589, 593], "least": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 99, 105, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 222, 241, 630, 643], "compliant": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "singleton": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 175, 286, 303, 633], "start_dim": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "end_dim": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "implements_for_spec": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "torch_funct": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "tensor_to_index": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "represent": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 85, 93, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 248, 273, 275, 323, 324, 325, 326, 328, 329, 330, 335, 345, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 595, 621, 638, 639, 643], "exanpl": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "one_hot": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "categ": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 339], "to_categorical_spec": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "idx_one_hot": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "idx_categ": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "to_categor": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "make_neg_dim": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "convert": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 85, 87, 117, 118, 119, 120, 123, 126, 127, 128, 129, 132, 133, 134, 135, 142, 143, 145, 146, 147, 148, 151, 153, 156, 157, 158, 159, 160, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 227, 230, 248, 263, 269, 270, 273, 275, 277, 278, 323, 324, 325, 326, 328, 329, 330, 335, 340, 362, 372, 373, 374, 375, 376, 377, 378, 379, 380, 563, 565, 566, 568, 571, 572, 574, 576, 579, 580, 582, 585, 587, 588, 595, 621, 622, 623, 638, 640], "shortcut": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 638, 643], "len": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 92, 94, 113, 183, 246, 286, 303, 379, 621, 624, 625, 629, 631, 636, 638, 639, 640, 642], "ndimens": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 621], "violat": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "primari": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 135, 177, 614, 629], "project": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 229, 284, 295, 296, 310, 311, 312, 337, 339, 340, 341, 395, 460, 600, 642, 643], "uniformli": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 98, 99, 100, 362, 373, 375, 379, 643], "normal": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 66, 71, 72, 73, 74, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 244, 277, 278, 284, 286, 301, 303, 304, 318, 319, 339, 341, 347, 348, 361, 364, 378, 379, 404, 407, 561, 588, 624, 627, 637, 643], "drawn": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 263, 299, 339, 341, 623, 636, 637], "set_provisional_n": [53, 55, 57, 59, 60], "temporarili": [53, 55, 57, 59, 60, 90, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 629, 640], "dest": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 248, 273, 275, 340], "to_numpi": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "transformed_in": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 317, 561], "check_spec_encod": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "to_one_hot": [53, 55, 57, 59, 60, 61, 63], "hot": [53, 55, 57, 59, 60, 61, 63, 118, 119, 126, 128, 129, 132, 133, 134, 139, 140, 142, 143, 145, 146, 149, 150, 153, 159, 160, 161, 162, 212, 229, 295, 296, 308, 311, 312, 345, 346, 348, 349, 350, 352, 353, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 373, 375, 379, 624], "categ_sampl": [53, 55, 57, 61, 63], "onehot_sampl": [53, 55, 57, 61], "to_one_hot_spec": [53, 55, 57, 59, 60, 61, 63], "categoricalbox": [53, 55, 57, 61, 63, 148], "type_check": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74], "unflatten": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 83, 84, 174, 216, 323, 325, 326, 328, 329, 338, 372, 374, 376, 377, 380], "unsqueez": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72, 73, 74, 99, 188, 204, 213, 216, 219, 220, 266, 272, 524, 593, 621, 625, 636, 637, 638], "update_mask": [53, 55, 57, 59, 60, 61, 63], "unmask": [53, 55, 57, 59, 60, 61, 63, 304], "ts": [53, 55, 57, 59, 60, 61, 63], "three": [53, 55, 57, 59, 60, 61, 63, 168, 348, 593, 623, 625, 626, 627, 636, 637, 638, 640, 643], "boundeddiscret": [54, 56], "upper": [54, 103, 243], "continuousbox": [54, 56, 72, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 204, 237, 240, 263, 271], "provision": [55, 335], "descript": [56, 132, 161, 215, 375, 614, 622, 623], "akin": 56, "unnam": [56, 58], "compositespec": [56, 633, 638, 643], "constraint": [56, 141, 318, 600, 623, 636, 637], "data_cl": 56, "tensorclass": [56, 83, 84, 92, 94, 113, 174, 323, 324, 325, 326, 328, 329, 335, 372, 374, 376, 377, 380, 595], "enforc": [56, 85, 104, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 268, 270, 324, 330, 332, 335, 342, 347, 348, 364, 367, 373, 375, 378, 379, 638], "step_mdp_stat": 56, "pixels_spec": 56, "observation_vector_spec": 56, "33": [56, 68, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 286, 303, 324, 330, 335, 373, 375, 378, 379], "composite_spec": 56, "observation_vector": [56, 220, 621], "_nodefault": [56, 58], "is_empti": [56, 58, 638], "recurs": [56, 58, 83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 323, 324, 325, 326, 328, 329, 330, 335, 362, 372, 373, 374, 375, 376, 377, 378, 379, 380, 625], "include_nest": [56, 58], "leaves_onli": [56, 58], "is_leaf": [56, 58], "step_mdp_static_onli": [56, 58], "_compositespecitemsview": [56, 58], "immedi": [56, 58, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 396, 397, 398, 570, 572, 578, 579, 584, 585, 586, 587, 614, 636, 637], "_compositespeckeysview": [56, 58], "reflect": [56, 58, 128, 149, 150, 210, 237, 276, 362, 373, 375, 379, 550, 622, 623, 624, 637], "lock_": [56, 58], "propag": [56, 58, 345, 347, 348, 349, 353, 354, 360, 361, 364, 365, 366, 367, 368, 369, 381, 382, 383, 384, 623, 624, 636, 637], "succeed": [56, 58, 237, 271], "ones_upd": [56, 58], "pop": [56, 58, 193, 223], "keyerror": [56, 58, 169, 170, 173, 199, 270, 364, 396, 397, 575, 614], "rand_upd": [56, 58], "refine_nam": [56, 58], "refin": [56, 58, 80, 345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 373, 375, 379, 593], "lift": [56, 58, 80], "coexist": [56, 58], "nice": [56, 58, 623, 626, 629], "ellipsi": [56, 58], "greedili": [56, 58, 627], "spec_refin": [56, 58], "selected_kei": [56, 58, 257, 621], "unlock_": [56, 58], "_compositespecvaluesview": [56, 58], "zeros_upd": [56, 58], "stackedcomposit": 58, "nvec": [59, 61], "remove_singleton": 59, "ax": [59, 636], "m": [59, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 229, 285, 324, 330, 335, 341, 373, 375, 378, 379, 622, 638], "tensor_spec": [59, 60, 63, 71, 152, 211, 213, 263, 353, 354, 364, 366], "neither": [59, 60, 61, 80, 159, 638], "use_regist": [61, 63], "mone_hot": 61, "boxlist": 61, "example_data": [62, 84, 173, 176, 183], "feature_dim": 62, "conform": 62, "nontensordata": [62, 75, 80, 83, 84, 120, 145, 146, 174, 183, 197, 237, 267, 271, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 386], "left": [62, 75, 76, 80, 85, 99, 105, 171, 172, 175, 176, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 216, 223, 224, 226, 227, 228, 232, 239, 242, 248, 250, 251, 257, 261, 264, 267, 269, 271, 273, 275, 278, 299, 304, 324, 330, 335, 378, 485, 622, 623, 625, 629, 630], "device_typ": [62, 555], "templat": [62, 84, 86, 168, 169, 170, 173, 193, 194, 196, 323, 328, 329, 330, 335, 389, 593, 595], "randomli": [62, 80, 104, 158, 181, 213, 243, 244, 263, 299, 339, 341, 627, 636, 637, 638, 640], "unidimension": 63, "action_valu": [63, 294, 295, 296, 311, 312, 348, 354, 362, 373, 375, 379, 624, 625, 627, 631], "keepdim": [63, 593], "chosen_action_valu": [63, 311, 312, 624, 627], "priori": 63, "definit": [63, 107, 633], "uniqu": [63, 105, 106, 135, 139, 140, 175, 177, 219, 231, 262, 263, 264, 268, 338, 395, 396, 397, 593, 614, 629, 640], "one_hot_sampl": 63, "ep": [64, 69, 98, 99, 244, 277, 278, 310, 347, 375, 407, 426, 503, 513, 534, 535, 537, 538, 539, 540, 541, 544, 545, 546, 549, 621, 622, 624, 625, 628, 631], "1e": [64, 69, 98, 99, 244, 277, 278, 293, 297, 305, 317, 503, 513, 534, 535, 537, 538, 540, 541, 542, 544, 545, 546, 547, 549, 621, 622, 623, 637], "08": [64, 69, 98, 99, 503, 513, 534, 535, 540, 541, 544, 545, 546, 549], "pin_memori": [64, 67, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 247, 621, 642], "prefetch": [64, 67, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 621, 622, 624, 640], "dim_extend": [64, 67, 69, 70], "delayed_init": [64, 65, 67, 68, 69, 70], "schaul": [64, 98, 99], "quan": [64, 98, 99], "j": [64, 85, 98, 99, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379, 624, 628], "antonogl": [64, 98, 99], "silver": [64, 98, 99], "2015": [64, 98, 99, 224], "arxiv": [64, 77, 80, 82, 98, 99, 118, 119, 121, 122, 133, 134, 139, 140, 142, 143, 153, 161, 162, 219, 248, 273, 287, 288, 289, 290, 291, 292, 296, 297, 298, 306, 307, 310, 313, 314, 315, 345, 346, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 363, 364, 367, 368, 381, 639], "ab": [64, 77, 80, 82, 98, 99, 118, 119, 121, 122, 133, 134, 139, 140, 142, 143, 153, 161, 162, 218, 248, 273, 277, 287, 292, 297, 298, 306, 307, 313, 314, 315, 345, 346, 350, 351, 352, 353, 356, 357, 358, 360, 363, 364, 367, 639], "1511": [64, 98, 99, 298], "05952": [64, 98, 99], "expon": [64, 69, 98, 99], "\u03b1": [64, 69], "uniform": [64, 69, 98, 99, 324, 330, 335, 636], "delta": [64, 69, 317, 339, 341, 600, 636], "1_000": [64, 67, 69, 70, 636, 640], "mini": [64, 67, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 637], "decid": [64, 67, 69, 70, 614, 636, 642], "incompat": [64, 67, 69, 70, 366, 640], "drop_last": [64, 67, 69, 70, 104, 106, 430], "notion": [64, 67, 69, 70], "capac": [64, 67, 69, 70, 92, 94, 98, 99, 105, 113, 623, 629], "caution": [64, 67, 69, 70, 104, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 396, 643], "codebas": [64, 67, 69, 70, 638], "unbind": [64, 67, 69, 70, 83, 84, 174, 242, 323, 325, 326, 328, 329, 338, 372, 374, 376, 377, 379, 380, 593], "sent": [64, 67, 68, 69, 70, 83, 84, 87, 92, 94, 113, 174, 277, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 570, 575, 578, 584, 586], "transform_factori": [64, 65, 67, 68, 69, 70], "return_info": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 98, 99, 640], "tensordictprioritizedreplaybuff": [64, 642], "_weight": [64, 69, 98, 99], "update_prior": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 98, 99, 406, 622, 640, 642], "36278465": 64, "invert": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 84, 623], "default_remote_class_config": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82], "overriden": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82], "tempfil": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 92, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 557, 621, 622, 624, 625, 629, 636, 639, 640], "tensordictreplaybuff": [64, 65, 66, 67, 68, 69, 75, 76, 77, 78, 79, 80, 81, 82, 98, 99, 105, 106, 111, 218, 219, 406, 435, 557, 621, 622, 624, 640], "1_000_000": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 105, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 621, 624, 636], "td_error": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 348, 349, 350, 352, 353, 354, 355, 360, 362, 365, 367, 368, 369, 373, 375, 379, 621, 640, 642], "update_tensordict_prior": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 621, 640, 642], "temporarydirectori": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 621, 622, 624, 625, 629, 636, 639, 640], "tmpdir": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 621, 622, 625, 636], "rb_load": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82], "empty_write_count": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82], "cursor": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82], "ambigu": [64, 65, 67, 68], "pytre": [64, 65, 67, 68, 69, 70, 83, 84, 95, 114, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "put": [64, 65, 67, 68, 127, 139, 140, 158, 161, 162, 277, 395, 561, 622, 623, 624, 626, 633, 636, 638], "cut": [64, 65, 67, 68], "insert_transform": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 169, 170, 173, 214, 270], "insert": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 91, 101, 111, 112, 115, 116, 169, 170, 173, 193, 214, 219, 223, 260, 270, 272, 593], "__iter__": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 183], "register_load_hook": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82], "register_save_hook": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82], "set_sampl": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82], "set_storag": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82], "set_writ": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82], "far": [64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 173, 301, 318, 319, 375, 593, 631, 638, 643], "replay_buffer_cl": 65, "optiona": 65, "asyncio": [65, 117], "ray_buff": 65, "object_store_memori": 65, "600": 65, "await": 65, "invoc": 66, "friendli": [66, 621], "public": [66, 79, 108, 248, 275], "invok": [66, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 200, 324, 330, 335, 373, 375, 378, 379], "include_info": [66, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82], "checkpoint": [67, 88, 90, 92, 96, 107, 108, 110, 114, 396, 412, 615, 640], "roundrobinwrit": [67, 75, 76, 77, 78, 79, 80, 81, 82, 429], "depth": [67, 71, 117, 120, 123, 127, 135, 141, 147, 148, 151, 153, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 286, 288, 289, 290, 291, 295, 297, 298, 303, 306, 307, 461, 462, 465, 466, 467, 622, 626, 628, 629, 635, 636, 637, 640], "_pytre": [67, 83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 640], "tree_map": [67, 83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 640], "assert0": [67, 640], "writerensembl": [68, 109], "sample_from_al": [68, 75, 103], "num_buffer_sampl": [68, 103], "_c": [68, 69], "ensembl": [68, 103, 109, 110, 116, 340, 365, 433, 434], "forbidden": 68, "collat": [68, 169, 170, 173], "rb0": 68, "rb1": 68, "another_kei": 68, "pixels33": 68, "0x13a2ef430": 68, "0x13a2f9310": 68, "interpolationmod": 68, "bilinear": [68, 252, 510], "0x13a2f9220": 68, "0x13a2f9f70": 68, "tensordictroundrobinwrit": [68, 70], "0x13a2d9b50": 68, "0x13a2f95b0": 68, "0x128648260": 68, "data0": [68, 93], "randint": [68, 83, 84, 174, 183, 266, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 640], "255": [68, 266, 640], "244": [68, 248, 275], "data1": [68, 93, 642], "priority_kei": [69, 70, 98, 348, 350, 353, 354, 355, 360, 362, 365, 367, 368, 369, 373, 375, 379, 640, 642], "reduct": [69, 98, 99, 111, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 375, 379, 403, 426, 469], "prioritizedreplaybuff": [69, 642], "min": [69, 98, 99, 111, 310, 346, 347, 348, 354, 363, 365, 367, 375, 403, 622, 623], "median": [69, 98, 99, 111, 127, 133, 134, 178, 212, 339, 341], "_encode_memo_dict": 71, "primarili": [71, 249, 570, 627], "possess": [71, 76], "describ": [71, 83, 84, 152, 174, 200, 220, 317, 318, 323, 325, 326, 328, 329, 350, 372, 374, 376, 377, 380, 391, 621, 623, 636, 637, 638, 643], "make_composite_from_td": [71, 638], "educ": 71, "guess": 71, "knowledg": [71, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 628, 630], "dataset_id": [75, 76, 77, 78, 80, 81, 82], "num_proc": 75, "slice_len": [75, 80, 99, 105, 106, 388, 431, 432, 624], "strict_len": 75, "mp_start_method": [75, 76, 77, 78, 79, 80, 81, 82, 147, 156, 268, 622, 642], "arari": 75, "2600": 75, "million": 75, "consequ": [75, 90, 629], "50x10": 75, "available_dataset": [75, 76, 77, 78, 79, 80, 81, 82, 105, 106], "ataridqn": 75, "greater": [75, 99, 105, 106, 224, 240, 242, 300, 302, 348, 621, 622], "strict_length": [75, 80, 99, 105, 106, 388, 431, 432, 624], "shorter": [75, 80, 99, 105, 106], "Be": [75, 80, 99, 105, 106], "game_nam": 75, "krull": 75, "1d": [75, 98, 99, 105, 106, 111], "1m": [75, 80, 550, 621, 623, 624], "cheapli": 75, "invalid_rang": 75, "999998": 75, "999999": 75, "add_count": 75, "84": [75, 87, 105, 252, 480, 485, 510, 624, 625], "valueestim": [75, 345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 373, 375, 379, 621, 636, 637], "convolut": [75, 286, 288, 289, 461, 625, 627], "2657628": 75, "2657629": 75, "2657630": 75, "2657631": 75, "2657632": 75, "2657633": 75, "2657634": 75, "2657635": 75, "2657636": 75, "2657637": 75, "2657638": 75, "2657639": 75, "2657640": 75, "2657641": 75, "2657642": 75, "2657643": 75, "2657644": 75, "2657645": 75, "2657646": 75, "2657647": 75, "2657648": 75, "2657649": 75, "2657650": 75, "2657651": 75, "2657652": 75, "2657653": 75, "2657654": 75, "2657655": 75, "2657656": 75, "2657657": 75, "2657658": 75, "2657659": 75, "2657660": 75, "2657661": 75, "2657662": 75, "2657663": 75, "2657664": 75, "2657665": 75, "2657666": 75, "2657667": 75, "2657668": 75, "2657669": 75, "2657670": 75, "2657671": 75, "2657672": 75, "2657673": 75, "2657674": 75, "2657675": 75, "2657676": 75, "2657677": 75, "2657678": 75, "2657679": 75, "2657680": 75, "2657681": 75, "2657682": 75, "2657683": 75, "2657684": 75, "2657685": 75, "2657686": 75, "2657687": 75, "2657688": 75, "2657689": 75, "2657690": 75, "2657691": 75, "1995687": 75, "1995688": 75, "1995689": 75, "1995690": 75, "1995691": 75, "1995692": 75, "1995693": 75, "1995694": 75, "1995695": 75, "1995696": 75, "1995697": 75, "1995698": 75, "1995699": 75, "1995700": 75, "1995701": 75, "1995702": 75, "1995703": 75, "1995704": 75, "1995705": 75, "1995706": 75, "1995707": 75, "1995708": 75, "1995709": 75, "1995710": 75, "1995711": 75, "1995712": 75, "1995713": 75, "1995714": 75, "1995715": 75, "1995716": 75, "1995717": 75, "1995718": 75, "1995719": 75, "1995720": 75, "1995721": 75, "1995722": 75, "1995723": 75, "1995724": 75, "1995725": 75, "1995726": 75, "1995727": 75, "1995728": 75, "1995729": 75, "1995730": 75, "1995731": 75, "1995732": 75, "1995733": 75, "1995734": 75, "1995735": 75, "1995736": 75, "1995737": 75, "1995738": 75, "1995739": 75, "1995740": 75, "1995741": 75, "1995742": 75, "1995743": 75, "1995744": 75, "1995745": 75, "1995746": 75, "1995747": 75, "1995748": 75, "1995749": 75, "1995750": 75, "replaybufferensembl": [75, 103, 109, 116], "_max_run": 75, "dataset_asterix": 75, "asterix": 75, "dataset_pong": 75, "buffer_id": [75, 103, 109], "hidden": [75, 147, 156, 218, 281, 282, 283, 288, 297, 300, 302, 306, 307, 313, 314, 340, 343, 347, 361, 364, 624, 635, 642], "data_path": [75, 76, 77, 78, 79, 80, 81, 82], "data_path_root": [75, 76, 77, 78, 79, 80, 81, 82], "delet": [75, 76, 77, 78, 79, 80, 81, 82, 94, 220, 260, 395], "fn": [75, 76, 77, 78, 79, 80, 81, 82, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 271, 305, 324, 330, 335, 373, 375, 378, 379, 528, 559, 560], "chunksiz": [75, 76, 77, 78, 79, 80, 81, 82], "num_chunk": [75, 76, 77, 78, 79, 80, 81, 82], "max_tasks_per_child": [75, 76, 77, 78, 79, 80, 81, 82], "worker_thread": [75, 76, 77, 78, 79, 80, 81, 82], "index_with_gener": [75, 76, 77, 78, 79, 80, 81, 82], "num_fram": [75, 76, 77, 78, 79, 80, 81, 82], "unitari": [75, 76, 77, 78, 79, 80, 81, 82, 638], "subsequ": [75, 76, 77, 78, 79, 80, 81, 82, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 215, 324, 330, 335, 373, 375, 378, 379, 572, 575, 579, 585, 587, 624, 636], "distance_from_origin": [75, 76, 77, 78, 79, 80, 81, 82], "forward_reward": [75, 76, 77, 78, 79, 80, 81, 82], "qpo": [75, 76, 77, 78, 79, 80, 81, 82], "qvel": [75, 76, 77, 78, 79, 80, 81, 82], "reward_ctrl": [75, 76, 77, 78, 79, 80, 81, 82, 127, 147, 178], "reward_forward": [75, 76, 77, 78, 79, 80, 81, 82], "reward_surv": [75, 76, 77, 78, 79, 80, 81, 82], "x_posit": [75, 76, 77, 78, 79, 80, 81, 82, 127, 147, 178], "x_veloc": [75, 76, 77, 78, 79, 80, 81, 82, 127, 147, 178], "y_posit": [75, 76, 77, 78, 79, 80, 81, 82], "y_veloc": [75, 76, 77, 78, 79, 80, 81, 82], "achieved_go": [75, 76, 77, 78, 79, 80, 81, 82], "desired_go": [75, 76, 77, 78, 79, 80, 81, 82], "27": [75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 105, 106, 118, 119, 147, 156, 174, 224, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "_collate_id": [75, 76, 77, 78, 79, 80, 81, 82], "0x120e21dc0": [75, 76, 77, 78, 79, 80, 81, 82], "cattensor": [75, 76, 77, 78, 79, 80, 81, 82, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 479, 621, 635, 638, 643], "cat_tensor": [75, 76, 77, 78, 79, 80, 81, 82], "cat_next_tensor": [75, 76, 77, 78, 79, 80, 81, 82], "func": [75, 76, 77, 78, 79, 80, 81, 82, 279], "new_storag": [75, 76, 77, 78, 79, 80, 81, 82], "31": [75, 76, 77, 78, 79, 80, 81, 82, 105, 133, 134], "full_storag": [75, 76, 77, 78, 79, 80, 81, 82], "0x168406fc0": [75, 76, 77, 78, 79, 80, 81, 82], "from_env": 76, "use_truncated_as_don": 76, "direct_download": 76, "terminate_on_end": 76, "env_kwarg": [76, 81, 82, 216, 475, 559, 560, 621], "d4rl": [76, 82], "reconstruct": [76, 105, 106, 357, 621, 643], "regard": [76, 82, 296, 345, 355, 364, 621, 623, 638], "get_dataset": 76, "qlearning_dataset": 76, "fewer": [76, 99, 105], "unexpectedli": 76, "traj_split": 76, "observationnorm": [76, 277, 278, 503, 561, 621, 622, 623, 624, 642], "maze2d": 76, "umaz": 76, "loc": [76, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 176, 177, 178, 239, 244, 255, 277, 278, 281, 282, 283, 301, 305, 318, 319, 339, 341, 343, 345, 346, 348, 360, 364, 365, 366, 367, 503, 513, 551, 561, 600, 621, 622, 623, 624, 627, 637, 642], "gen": 77, "dgrl": 77, "accompani": [77, 216, 261], "gap": 77, "2312": 77, "05742": 77, "gen_dgrl": 77, "procgen": 77, "bigfish": 77, "bossfight": 77, "1m_e": 77, "1m_": 77, "comma": [77, 625], "npy": 77, "mmap": [77, 81, 82], "minut": 77, "huggingfac": [77, 82, 175, 330], "internet": [77, 82], "connect": [77, 82, 159, 188, 563, 564, 568, 575, 577, 580, 582, 588], "load_from_local_minari": 78, "minari": 78, "websit": [78, 80, 633], "currenrtli": 78, "minari_data": 78, "door": 78, "human": [78, 169, 638], "torchrl_logg": [78, 631, 633], "28": [78, 105, 106, 373, 375], "39": [78, 133, 134], "door_body_po": 78, "openml": [79, 144, 450], "dua": 79, "graff": 79, "2017": 79, "uci": [79, 120], "archiv": 79, "ic": 79, "edu": 79, "ml": [79, 159, 160, 322], "scikit": [79, 144], "sklearn": [79, 144], "panda": 79, "adult_num": [79, 144], "adult_onehot": [79, 144], "mushroom_num": [79, 144], "mushroom_onehot": [79, 144], "covertyp": [79, 144], "shuttl": [79, 144], "magic": [79, 144, 625, 626], "shuffl": [80, 104, 106, 169, 170, 173, 430, 637], "embodi": [80, 639], "collabor": 80, "21": [80, 81, 105, 106, 147, 149, 150, 156, 224, 620, 641], "institut": 80, "demonstr": [80, 593, 623, 625, 629, 633, 634, 636, 637, 638, 640, 643], "527": 80, "skill": 80, "160266": 80, "googl": [80, 81, 118, 119, 139, 140, 145, 146, 173, 175, 623, 624, 633, 636, 637], "open_x_embodi": 80, "2310": [80, 153], "08864": 80, "language_instruct": 80, "get_non_tensor": 80, "nor": [80, 159], "insuffici": 80, "chosen": [80, 161, 162, 262, 263, 312, 388, 614, 630], "openx": 80, "__will": 80, "change__": 80, "crop": [80, 221, 249, 388, 485], "compli": 80, "modal": [80, 324, 330, 335, 621], "cmu_stretch": [80, 388], "discount": [80, 124, 253, 346, 352, 355, 356, 358, 381, 382, 383, 384, 414, 622, 623, 636, 637], "is_init": [80, 82, 218, 238, 300, 302, 310, 338, 381, 624, 625], "language_embed": 80, "512": [80, 298], "green": [80, 636], "garbag": 80, "lid": 80, "roboset": 81, "h5": [81, 82, 83, 84, 90, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "roboh": [81, 153, 453], "excludetransform": [81, 257, 491, 640], "fk1": 81, "v4": [81, 127, 147, 178, 212, 252, 621, 623, 639, 642], "expert": 81, "fk1_microopenrandom_v2d": 81, "concis": [81, 628], "20": [81, 105, 106, 111, 117, 120, 123, 127, 131, 135, 145, 146, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 262, 298, 373, 375, 396, 400, 542, 634, 640, 643], "18": [81, 105, 106, 154, 155, 161, 162, 268], "23": [81, 106, 224, 280], "19": [81, 105, 106, 111, 224], "75": [81, 105, 536], "totensor": 82, "image_s": 82, "v": [82, 277, 281, 353, 360, 367, 607, 621, 622], "npz": 82, "2206": [82, 142, 143], "04779": [82, 346, 352], "vd4rl": 82, "squar": [82, 221, 226, 301, 318, 319, 347, 364, 375, 388, 593], "rectangular": [82, 286], "walker_walk": 82, "64px": 82, "height": [82, 221, 226, 252, 480, 485], "veloc": [82, 117, 120, 121, 122, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 219, 636, 637, 638, 643], "audio": 83, "function_cal": 83, "_wrap_td_method": 83, "wrapped_func": 83, "0x7f078e1ccea0": 83, "mime_typ": 83, "function_nam": 83, "function_arg": 83, "copy_exist": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "return_earli": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "share_non_tensor": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "robust_kei": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "from_ani": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "auto_batch_s": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "batch_dim": [83, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 561], "incur": [83, 84, 118, 119, 133, 134, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "overhead": [83, 84, 117, 118, 119, 120, 123, 127, 133, 134, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 210, 323, 325, 326, 328, 329, 341, 372, 374, 376, 377, 380], "opinion": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "term": [83, 84, 93, 174, 186, 193, 239, 323, 325, 326, 328, 329, 345, 354, 364, 372, 374, 376, 377, 380, 413, 622, 623, 626, 627, 637], "obj": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "from_dataclass": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "namedtupl": [83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 268, 270, 323, 324, 325, 326, 328, 329, 330, 335, 348, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380], "from_namedtupl": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "from_dict": [83, 84, 174, 183, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "from_tupl": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "from_struct_arrai": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "hdf5": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "from_h5": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "dest_cl": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "as_tensorclass": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "deleg": [83, 84, 174, 192, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 638], "convers": [83, 84, 118, 119, 133, 134, 168, 170, 173, 174, 184, 193, 194, 207, 323, 325, 326, 328, 329, 372, 374, 375, 376, 377, 380, 563, 565, 566, 568, 571, 574, 580, 582, 588, 593, 595, 633, 634], "applic": [83, 84, 147, 156, 168, 174, 323, 325, 326, 328, 329, 367, 372, 374, 376, 377, 380, 581, 614, 626, 627, 638], "persistenttensordict": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "key1": [83, 84, 174, 220, 260, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 400, 408, 642], "key2": [83, 84, 174, 220, 260, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 400, 408, 642], "as_modul": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "use_state_dict": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "lazy_stack": [83, 84, 85, 86, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 379, 380, 593, 635], "expand_ident": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "ensebml": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "vmap": [83, 84, 174, 323, 325, 326, 328, 329, 340, 343, 346, 348, 354, 360, 362, 365, 367, 368, 369, 372, 373, 374, 375, 376, 377, 379, 380, 381, 382, 383, 384, 607], "tensordictparam": [83, 84, 174, 323, 325, 326, 328, 329, 341, 372, 374, 376, 377, 380], "densli": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "lazili": [83, 84, 93, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 638], "dens": [83, 84, 117, 174, 304, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 593], "reinstanti": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "tempt": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "orign": [83, 84, 174, 323, 324, 325, 326, 328, 329, 330, 335, 372, 373, 374, 375, 376, 377, 379, 380], "longer": [83, 84, 174, 187, 280, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 593, 622, 624, 631, 636, 637, 640], "empty_modul": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "n_model": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "bia": [83, 84, 85, 98, 99, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 237, 248, 263, 268, 269, 270, 273, 275, 286, 288, 289, 290, 291, 297, 298, 299, 300, 302, 303, 305, 310, 323, 324, 325, 326, 328, 329, 330, 335, 340, 348, 362, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 621, 622, 623, 624, 637], "exec_modul": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "to_modul": [83, 84, 174, 323, 325, 326, 328, 329, 340, 343, 372, 374, 376, 377, 380, 621, 642], "backprop": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "named_tupl": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "a_tensor": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "a_str": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "nt": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "to_namedtupl": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "genericdict": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "from_pytre": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "biject": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "castabl": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "surject": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "weird": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "weirdlookingclass": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "weird_kei": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "pytree_recon": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "to_pytre": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "from_remote_init": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "processgroup": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "init_remot": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "src": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "struct_arrai": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "rex": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "fido": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "u10": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "ag": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "i4": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "f4": [83, 84, 120, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "x_recon": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "to_struct_arrai": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "from_tensordict": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "non_tensordict": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "my_tupl": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "fromkei": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "getattr": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "load_memmap": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "load_": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "pathlib": [83, 84, 92, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 410, 414, 415, 625], "load_memmap_": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "non_block": [83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 323, 324, 325, 326, 328, 329, 330, 335, 340, 372, 373, 374, 375, 376, 377, 378, 379, 380], "robust": [83, 84, 174, 249, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 593], "decod": [83, 84, 135, 174, 177, 205, 306, 322, 323, 324, 325, 326, 328, 329, 330, 335, 372, 374, 376, 377, 380, 593], "emit": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "saved_td": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "td_load": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "_subclass": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "faketensormod": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "faketensor": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "strict": [83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 268, 270, 323, 324, 325, 326, 328, 329, 330, 335, 348, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380, 614, 625], "from_flatten": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "attemptedli": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "maybe_dense_stack": [83, 84, 174, 183, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "existsok": [83, 84, 92, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "mimic": [83, 84, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 174, 176, 177, 178, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 576], "non_tensor": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "charact": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 623, 625], "throw": [83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 323, 324, 325, 326, 328, 329, 330, 335, 372, 373, 374, 375, 376, 377, 378, 379, 380, 643], "cross": [83, 84, 174, 323, 324, 325, 326, 328, 329, 330, 335, 372, 374, 376, 377, 380, 591], "anymor": [83, 84, 174, 270, 323, 325, 326, 328, 329, 340, 372, 374, 376, 377, 380], "tensordictfutur": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "serialis": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "deepli": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "memmap_": [83, 84, 174, 277, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "memmap_lik": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "contentless": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "alloc": [83, 84, 94, 174, 192, 293, 304, 322, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 593, 614, 621], "memmap_refresh_": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "refresh": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380, 631, 636, 637], "saved_path": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "setattr": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "tent": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "keep_var": [83, 84, 85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 268, 270, 323, 324, 325, 326, 328, 329, 330, 335, 348, 367, 372, 373, 374, 375, 376, 377, 378, 379, 380], "to_tensordict": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "retain_non": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "discrard": [83, 84, 174, 323, 325, 326, 328, 329, 372, 374, 376, 377, 380], "contentbas": 84, "is_complet": 84, "tool_cal": 84, "tool_respons": [84, 191, 593], "apply_chat_templ": [84, 86, 168, 191, 379, 593, 633], "autotoken": [84, 86, 168, 169, 170, 172, 173, 180, 181, 187, 191, 193, 194, 323, 328, 329, 330, 335, 379, 593, 633, 634], "autoprocessor": 84, "add_generation_prompt": [84, 86, 193, 194, 323, 379], "chat_templ": [84, 196, 323, 330, 335, 379], "chat_template_nam": [84, 86, 323, 328, 329, 330, 335, 379], "continue_final_messag": 84, "return_tensor": [84, 193, 328], "return_dict": [84, 86, 194], "return_assistant_tokens_mask": [84, 86, 193, 194], "chat": [84, 86, 168, 169, 170, 173, 182, 191, 193, 194, 196, 323, 328, 329, 330, 335, 379, 593, 595, 634], "pretrainedtoken": [84, 168, 179, 330, 335], "prompt": [84, 85, 168, 169, 170, 171, 173, 175, 176, 181, 183, 188, 191, 322, 323, 325, 327, 328, 329, 330, 335, 375, 378, 593, 634], "im_start": [84, 170, 173, 191, 593], "assist": [84, 86, 168, 170, 173, 181, 187, 188, 191, 193, 194, 330, 335, 375, 379, 593, 595, 624, 633, 634], "preval": 84, "messag": [84, 86, 168, 181, 185, 562, 563, 564, 568, 569, 575, 576, 580, 582, 588, 593, 634], "pt": [84, 193, 328, 390, 457], "assistant_mask": 84, "qwen": [84, 170, 173, 181, 191, 322, 330, 331, 332, 335, 379, 593, 633, 634], "dialogpt": 84, "falcon": 84, "deepseek": 84, "chatml_format": [84, 330, 335, 379], "default_spec": [84, 323, 325, 326, 328, 329], "set_list_to_stack": [84, 173, 188, 191, 193, 194, 195, 593, 633], "foo": [84, 92, 94, 113, 640, 643], "from_chat": [84, 86, 168, 193, 194, 330, 335, 379, 634], "from_pretrain": [84, 86, 135, 170, 173, 177, 181, 191, 193, 194, 322, 327, 330, 335, 379, 593, 633, 634], "qwen2": [84, 170, 173, 181, 191, 322, 331, 332, 335, 593, 633, 634], "7b": [84, 86, 322, 593, 633], "nyou": [84, 173], "im_end": [84, 170, 181, 191, 593, 633], "nwrite": 84, "capit": [84, 633, 634], "franc": [84, 633, 634], "germani": 84, "pari": [84, 173, 633], "berlin": 84, "answer": [84, 170, 172, 173, 175, 181, 593, 633], "topk_siz": 85, "prompt_kei": [85, 175, 378], "rewards_kei": [85, 378], "k": [85, 285, 324, 330, 335, 607], "topk": 85, "selector": [85, 633], "25": [85, 224, 469, 614, 621], "wrote": 85, "top3": 85, "r3": 85, "as_padded_tensor": [85, 176, 183, 194, 324, 330, 335], "add_modul": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "init_weight": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "fill_": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 622, 624], "net": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 289, 291, 294, 298, 324, 330, 335, 345, 346, 348, 354, 360, 364, 365, 366, 367, 373, 375, 378, 379, 461, 462, 465, 467, 557, 622, 638, 639, 642], "requires_grad": [85, 117, 118, 119, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 239, 268, 270, 324, 330, 335, 341, 348, 367, 373, 375, 378, 379, 440], "bfloat16": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "datatyp": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 640], "member": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 362, 373, 375, 378, 379, 388], "xdoctest": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 237, 248, 263, 268, 269, 270, 273, 275, 324, 330, 335, 340, 348, 362, 367, 373, 375, 378, 379], "buf": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "20l": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 362, 373, 375, 378, 379], "1l": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 362, 373, 375, 378, 379], "5l": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 362, 373, 375, 378, 379], "doubl": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 227, 228, 230, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 350, 355, 365, 373, 375, 378, 379, 582, 583, 584, 585, 621, 622, 623, 624, 643], "eval": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 270, 277, 324, 330, 335, 347, 364, 373, 375, 378, 379, 621, 622, 623], "evalu": [85, 117, 120, 123, 127, 128, 135, 139, 140, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 224, 270, 293, 304, 308, 319, 324, 330, 335, 365, 373, 375, 378, 379, 552, 553, 614, 622, 623, 631], "batchnorm": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 270, 324, 330, 335, 373, 375, 378, 379], "comparison": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 270, 324, 330, 335, 362, 373, 375, 378, 379, 621, 622], "extra_repr": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "transformthatmeasuresbyt": [85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 378], "byte": [85, 87, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 378], "bytes_in_td": [85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 213, 215, 216, 218, 219, 220, 223, 224, 225, 228, 231, 232, 233, 235, 238, 239, 241, 247, 249, 250, 251, 253, 256, 257, 260, 261, 262, 263, 264, 265, 267, 268, 269, 273, 274, 276, 277, 378], "get_buff": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "docstr": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 626, 627], "get_submodul": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "explan": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "qualifi": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "referenc": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "resolv": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 413], "get_extra_st": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 277, 278, 324, 330, 335, 373, 375, 378, 379], "set_extra_st": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 277, 278, 324, 330, 335, 373, 375, 378, 379], "picklabl": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 277, 278, 324, 330, 335, 373, 375, 378, 379], "get_paramet": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "sai": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 636, 639, 643], "net_b": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "net_c": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "conv": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 286, 324, 330, 335, 373, 375, 378, 379, 622], "conv2d": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 286, 288, 289, 298, 324, 330, 335, 373, 375, 378, 379], "kernel_s": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 286, 288, 289, 298, 306, 324, 330, 335, 373, 375, 378, 379, 461, 622, 642], "diagram": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "degre": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 225, 324, 330, 335, 373, 375, 378, 379], "named_modul": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "o": [85, 88, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "half": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379, 621], "ipu": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "descend": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 268, 270, 324, 330, 335, 348, 367, 373, 375, 378, 379], "get_swap_module_params_on_convers": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 268, 270, 324, 330, 335, 348, 367, 373, 375, 378, 379], "persist": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 210, 237, 268, 270, 324, 330, 335, 348, 367, 373, 375, 378, 379, 396, 614], "preserv": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 268, 270, 324, 330, 335, 340, 348, 367, 373, 375, 378, 379], "missing_kei": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 268, 270, 324, 330, 335, 348, 367, 373, 375, 378, 379], "unexpected_kei": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 268, 270, 324, 330, 335, 348, 367, 373, 375, 378, 379], "l": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 623, 638], "idx": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "mtia": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "named_buff": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "remove_dupl": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 362, 373, 375, 378, 379], "prepend": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 362, 373, 375, 378, 379, 625], "running_var": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "named_children": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "conv4": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "conv5": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "memo": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "named_paramet": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 239, 324, 330, 335, 362, 373, 375, 378, 379], "register_backward_hook": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "removablehandl": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "favor": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 277, 324, 330, 335, 373, 375, 378, 379, 593, 623], "register_full_backward_hook": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "register_buff": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "running_mean": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "alongsid": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 593, 614, 630], "num_featur": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "register_forward_hook": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "with_kwarg": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "always_cal": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "register_module_forward_hook": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "regardless": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 347, 361, 364, 373, 375, 378, 379], "register_forward_pre_hook": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "And": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 628], "forward_pr": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "register_module_forward_pre_hook": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "rule": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 227, 230, 324, 330, 335, 341, 373, 375, 378, 379, 623], "ordinarili": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "grad_input": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "grad_output": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "technic": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 622, 624, 625, 627], "caller": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 322, 324, 330, 335, 373, 375, 378, 379, 581], "register_module_full_backward_hook": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "register_full_backward_pre_hook": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "backward_pr": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "register_module_full_backward_pre_hook": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "register_load_state_dict_post_hook": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "incompatible_kei": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "thrown": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 640], "register_load_state_dict_pre_hook": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "local_metadata": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "error_msg": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "noqa": [85, 117, 120, 123, 127, 132, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 625], "b950": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "register_modul": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "register_paramet": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "register_state_dict_post_hook": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "register_state_dict_pre_hook": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "requires_grad_": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 625], "autograd": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 268, 270, 324, 330, 335, 348, 367, 373, 375, 378, 379], "freez": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 277, 278, 324, 330, 335, 373, 375, 378, 379], "finetun": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "gan": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "set_submodul": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "share_memori": [85, 117, 120, 123, 124, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 621], "share_memory_": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379, 576, 642], "averag": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 268, 270, 277, 278, 310, 324, 330, 335, 348, 356, 357, 367, 373, 375, 378, 379, 407, 593, 621, 623], "shallow": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 268, 270, 324, 330, 335, 348, 367, 373, 375, 378, 379, 624], "detach": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 237, 268, 270, 324, 330, 335, 348, 359, 362, 367, 368, 373, 375, 378, 379, 381, 382, 383, 384, 621], "memory_format": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "channels_last": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "pin": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "4d": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "ignore_w": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "1913": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "3420": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "5113": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "2325": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "torch_doctest_cuda1": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "gpu1": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "1914": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "5112": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "2324": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "float16": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "cdoubl": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "3741": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "2382": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "5593": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "4443": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "complex128": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "6122": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "1150": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 223, 248, 263, 269, 270, 273, 275, 324, 330, 335, 340, 373, 375, 378, 379], "to_empti": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "transform_done_spec": [85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 228, 241, 260, 267, 269, 271, 378], "transform_env_batch_s": [85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 216, 223, 269, 378], "transform_env_devic": [85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 223, 228, 269, 378], "transform_full_done_spec": [85, 171, 172, 175, 181, 182, 183, 184, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 216, 223, 227, 228, 232, 239, 242, 250, 251, 257, 261, 267, 269, 271, 278, 378], "dst_type": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "xpu": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "set_to_non": [85, 117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 324, 330, 335, 373, 375, 378, 379], "template_nam": 86, "inverse_pars": 86, "model_family_keyword": 86, "llama": 86, "mistral": 86, "histori": [86, 168, 169, 170, 172, 173, 176, 181, 182, 184, 187, 188, 191, 193, 194, 195, 323, 324, 327, 328, 329, 330, 335, 379, 593, 633], "jinja2": 86, "pars": [86, 172, 184, 196, 198, 201, 328, 329, 593, 595, 633, 640], "parser": [86, 132, 172, 184, 185, 195, 201, 558, 561, 593], "llama_templ": 86, "inst": 86, "elif": [86, 593, 621, 622, 633], "endgener": 86, "endif": 86, "endfor": 86, "parse_llama_text": 86, "pattern": [86, 188, 195, 562, 563, 567, 568, 573, 574, 581, 591, 593], "findal": 86, "dotal": 86, "user_cont": 86, "assistant_cont": 86, "strip": [86, 622], "hf": 86, "hello": [86, 168, 193, 194, 322, 330, 331, 335, 379, 396, 614], "Or": [86, 154, 155], "compression_fn": 87, "decompression_fn": 87, "compression_level": 87, "decompress": 87, "sensori": 87, "zstd": 87, "verifi": [87, 169, 364], "attach": [87, 92, 93, 94, 95, 107, 109, 113, 622], "entiti": [87, 92, 93, 94, 95, 107, 109, 113], "to_bytestream": 87, "data_to_bytestream": 87, "compact": [89, 90, 97], "shift": [89, 90, 97, 381, 382, 383, 384, 623], "checkpoint_fil": 90, "h5_kwarg": 90, "iff": 90, "suffix": [90, 404], "h5py": 90, "create_dataset": 90, "increas": [90, 219, 264, 310, 347, 364, 375, 379, 636, 637], "immut": [91, 117, 120, 123, 127, 135, 147, 151, 156, 157, 168, 169, 170, 173, 176, 177, 178, 251, 270], "scratch_dir": [92, 621, 622, 624, 629, 636, 639, 640], "shared_init": [92, 94, 422, 424], "mistak": [92, 94, 113], "overewritten": 92, "main_ckpt_dir": 92, "rb_memmap": 92, "10_000_000": 92, "myclass": [92, 94, 113], "lazystacktensordict": 93, "heterougen": 93, "heterogen": [93, 117, 120, 123, 127, 135, 138, 147, 148, 149, 150, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 621, 622], "linearli": 93, "densifi": 93, "unlimit": [93, 95], "st": 93, "consolid": 94, "cleanup_memmap": 94, "expans": [94, 362, 373, 375, 379], "ram": [94, 126, 128, 630, 640], "zero_": [94, 113, 204], "liststoag": 96, "max_priority_within_buff": [98, 99], "proport": [98, 640], "magnitud": [98, 99, 621, 636], "tempor": [98, 300, 302, 382, 383], "focus": [98, 99, 614, 621, 628], "p_i": [98, 99], "delta_i": [98, 99], "epsilon": [98, 99, 244, 284, 299, 310, 407, 622, 623, 624, 627], "frac": [98, 99, 623], "sum_j": [98, 99], "p_j": [98, 99], "w_i": [98, 99], "cdot": [98, 99, 379], "aggress": [98, 99, 379], "bias": [98, 99, 621], "toward": [98, 99, 275], "unbias": [98, 99], "anneal": [98, 99, 310, 622, 627, 636], "small": [98, 99, 106, 273, 278, 621, 623, 625, 636, 637, 643], "guidelin": [98, 99], "math": [98, 99, 188], "benefit": [98, 99, 592, 626, 634, 636, 637, 640], "data_0": 98, "data_1": 98, "smoothen": 98, "tdrb": 98, "pack": [98, 330, 623, 626, 643], "nd": [98, 99], "sum_tre": [98, 99], "min_tre": [98, 99], "end_kei": [99, 105, 106, 431, 432, 624], "traj_kei": [99, 105, 106, 431, 432, 640], "cache_valu": [99, 105, 106, 431, 432, 624], "truncated_kei": [99, 105, 106, 253, 261, 431, 432, 519], "closer": [99, 642], "commonli": [99, 105, 106, 643], "readili": [99, 105, 106, 341], "conjunct": [99, 105, 106, 622], "buffer0": [99, 105], "immutablewrit": [99, 105], "buffer1": [99, 105], "other_sampl": [99, 105], "short": [99, 105, 106, 117, 118, 119, 120, 123, 127, 133, 134, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 330, 622, 623, 626, 627, 637, 640], "tolist": [99, 593], "120110917137936e": 99, "06": [99, 293, 317, 537, 547], "roundrobin": [101, 112], "consum": [104, 106, 338, 622, 623, 629, 637, 640], "incomplet": [104, 106, 181], "fresh": [104, 183, 576], "haven": [104, 639], "remain": [104, 181, 189, 218, 228, 229, 239, 241, 262, 593, 614, 628], "draw": [104, 299], "use_gpu": [105, 106, 431, 432], "acceler": [105, 106, 127, 178, 636, 637], "ep_1": [105, 106], "ep_2": [105, 106], "73": 105, "74": 105, "76": 105, "77": 105, "41": 105, "42": [105, 303, 345, 346, 348, 349, 353, 360, 367], "43": 105, "44": 105, "45": 105, "67": [105, 635], "68": 105, "69": 105, "70": 105, "71": 105, "80": [105, 118, 119], "82": 105, "83": 105, "78": 105, "79": 105, "320": [105, 106, 121, 122], "550": [105, 106], "700": [105, 106], "dataid": [105, 106], "counter": [106, 189, 224, 268, 338, 402, 625], "request": [106, 199, 216, 249, 322, 328, 614], "51": 106, "__len__": 107, "rank_kei": 111, "flat": [111, 381], "get_insert_index": 111, "themselv": [117, 622], "maybe_dens": 117, "maker": [117, 561, 622], "min_get": [117, 151, 157], "sort": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 220, 310], "another_act": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "discretebox": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "mutabl": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "action_spec_unbatch": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 623, 637], "had": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 627, 629], "all_act": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "any_don": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "_callabletransform": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 176, 177, 178], "auto_specs_": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "observation_kei": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "action_spac": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 231, 295, 296, 311, 312, 345, 346, 348, 349, 350, 352, 353, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 373, 375, 379, 624, 625, 627, 631], "discrep": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 345, 347, 349, 350, 361, 364, 366], "broken": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178], "check_dtyp": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178], "rng": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 638], "revert": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 324, 330, 335, 373, 375, 379, 627, 640], "accomplish": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 163, 168, 169, 170, 173, 176, 177, 178, 626, 633], "done_keys_group": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "another_don": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "done_spec_unbatch": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "empty_cach": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 192, 270], "env_batch_s": [117, 151, 157], "fake_tensordict": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 622, 625], "recip": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 312, 313, 314, 336, 338, 344], "afterward": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 284, 285, 287, 288, 289, 290, 291, 292, 294, 296, 297, 298, 299, 300, 302, 305, 306, 307, 309, 310, 312, 313, 314, 336, 338, 344, 636, 643], "envnam": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "full_action_spec_unbatch": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 636, 637], "full_done_spec_unbatch": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "full_observation_spec_unbatch": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "full_reward_spec_unbatch": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "pipeline_st": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "full_state_spec_unbatch": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "input_spec_unbatch": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "is_spec_lock": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "maybe_reset": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "speak": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 225, 341, 621], "observation_spec_unbatch": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "output_spec_unbatch": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "register_gym": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 626], "entry_point": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "info_kei": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "reward_threshold": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "nondeterminist": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "max_episode_step": [117, 120, 123, 126, 127, 128, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "order_enforc": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "autoreset": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "disable_env_check": [117, 120, 123, 126, 127, 135, 142, 143, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 443, 447], "apply_api_compat": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "nasium": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 207], "dmcontrolenv": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 388, 441, 621, 626, 635, 643], "dmc": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "cheetah": [117, 120, 121, 122, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 388, 621], "removeemptyspec": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 508], "threshold": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 299, 346, 347, 373, 375, 593, 623], "learnt": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 557], "checker": [117, 120, 123, 126, 127, 135, 142, 143, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "stepapicompat": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "deem": [117, 120, 123, 127, 135, 139, 140, 147, 148, 151, 156, 157, 158, 161, 162, 168, 169, 170, 173, 176, 177, 178], "task_nam": [117, 120, 121, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 441], "envgym": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0855": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0215": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0881": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0412": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "1101": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0080": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0254": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0424": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "9609e": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "02": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 215, 278, 622, 631], "9776e": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "04": [117, 120, 123, 127, 131, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 265, 278], "6347e": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "03": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 215, 244, 265], "3842e": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "5338e": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "3064e": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0381e": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "6656e": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "05": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 265, 364, 638], "0204e": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0833": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0275": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0612": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0770": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "1256": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0082": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0186": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0476": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "2221": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "2256": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "5930": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "6937": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "5865": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "5479": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0187": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "6825": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "5224": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0018": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "1005": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0335": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 225], "0268": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0133": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0627": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0074": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0488": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0353": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0075": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0069": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0098": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0058": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0033": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0157": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0004": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 265], "0381": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0452": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "11355747": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "04257728": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "00408397": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "04155852": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0389733": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "01409826": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0978704": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "08808327": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "03970837": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "00535434": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "02353762": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "05116226": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "02788907": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "06848346": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "05154399": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "0371798": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "05128025": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "selecttransform": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 515], "dydact": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "ant": [117, 118, 119, 120, 123, 127, 130, 132, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 639], "gym_env": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 642], "reset_kei": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 219, 256, 262, 263, 264, 520, 636], "multitask": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "multiag": [117, 120, 123, 127, 135, 138, 147, 148, 149, 150, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 211, 347, 361, 364], "another_reward": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "reward_spec_unbatch": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "auto_cast_to_devic": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 637], "__sort": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "as__": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "categorical_action_encod": [117, 118, 119, 120, 123, 126, 127, 128, 129, 132, 133, 134, 135, 142, 143, 147, 148, 151, 153, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 207, 224, 440, 443, 447, 625], "argmaxmodul": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "argmax": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 296, 312, 625, 627], "n_ob": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 239, 338, 345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 628], "n_act": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 239, 345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 628], "ourselv": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 623, 643], "emul": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "epoch": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 410, 414, 470, 623, 636, 637], "input_td": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "rollout_td": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "state_kei": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "state_spec_unbatch": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "prevail": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 211, 220, 256, 324], "newli": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "next_tensordict": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 210, 216, 220, 232, 233, 234, 247, 250, 251, 257, 260, 273, 277, 593], "precomput": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "_stepmdp": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 210], "exclude_act": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 210], "retain": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "next_data": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178], "reset_data": [117, 120, 123, 127, 135, 147, 148, 151, 156, 157, 158, 168, 169, 170, 173, 176, 177, 178, 188, 593, 643], "2106": [118, 119, 351, 368], "13281": [118, 119], "cache_clear_frequ": [118, 119, 440], "leak": [118, 119, 322], "frame_skip": [118, 119, 121, 122, 126, 127, 128, 129, 133, 134, 136, 137, 142, 143, 153, 178, 235, 402, 404, 414, 415, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 470, 494, 550, 621, 622, 623, 642], "allow_done_after_reset": [118, 119, 121, 122, 123, 126, 128, 129, 132, 133, 134, 142, 143, 145, 146, 153, 159, 160, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456], "toler": [118, 119, 121, 122, 126, 128, 129, 132, 133, 134, 142, 143, 145, 146, 153, 159, 160, 192, 293, 317, 322], "is_avail": [118, 119, 621, 622, 623, 624, 636, 637, 639], "87": [118, 119], "acrobot": [118, 119, 121, 122, 643], "advant": [118, 119, 133, 134], "timer": [118, 119, 127, 133, 134, 178, 523], "timeit": [118, 119, 133, 134, 625], "310": [118, 119], "00": [118, 119, 215, 620, 641], "ms": [118, 119, 133, 134], "268": [118, 119], "433": [118, 119], "213": [118, 119], "8605": [118, 119], "pipelineenv": 119, "get_environ": 119, "san": 120, "fen": [120, 145, 146], "pgn": 120, "legal": [120, 213], "board": [120, 158], "include_san": 120, "algebra": [120, 638], "notat": 120, "include_fen": 120, "forsyth": 120, "edward": 120, "include_pgn": 120, "portabl": [120, 614, 630], "include_legal_mov": 120, "include_hash": 120, "hash": [120, 135, 177, 496], "mask_act": 120, "subset": [120, 638, 639], "29275": 120, "rnbqkbnr": [120, 145, 146], "pppppppp": [120, 145, 146], "kqkq": [120, 145, 146], "legal_mov": 120, "219": 120, "5p2": 120, "ppppp1pp": 120, "event": [120, 304, 308, 315, 640], "white": 120, "96": 120, "kq": 120, "5n2": 120, "rnbqkb1r": 120, "nf3": 120, "na6": 120, "c4": 120, "f6": 120, "h4": 120, "rb8": 120, "na3": 120, "ra": 120, "get_legal_mov": 120, "dm_control": [121, 122, 441, 621, 635, 643], "2006": [121, 122, 224, 346, 352], "12983": [121, 122], "240": [121, 122, 642], "swingup": [121, 122, 643], "swingup_spars": [121, 122], "ball_in_cup": [121, 122], "catch": [121, 122, 625], "balance_spars": [121, 122], "three_pol": [121, 122], "two_pol": [121, 122], "finger": [121, 122], "turn_easi": [121, 122], "turn_hard": [121, 122], "fish": [121, 122], "upright": [121, 122, 622], "swim": [121, 122], "hopper": [121, 122], "hop": [121, 122], "humanoid": [121, 122, 147, 156, 635], "walk": [121, 122, 147, 156, 622, 635], "run_pure_st": [121, 122], "bring_bal": [121, 122], "bring_peg": [121, 122], "insert_bal": [121, 122], "insert_peg": [121, 122], "point_mass": [121, 122], "reacher": [121, 122], "swimmer": [121, 122], "swimmer6": [121, 122], "swimmer15": [121, 122], "walker": [121, 122], "dog": [121, 122], "trot": [121, 122], "humanoid_cmu": [121, 122], "lqr": [121, 122], "lqr_2_1": [121, 122], "lqr_6_2": [121, 122], "quadrup": [121, 122], "escap": [121, 122], "stacker": [121, 122], "stack_2": [121, 122], "stack_4": [121, 122], "deviceless": 123, "run_type_check": [123, 141], "hint": 123, "counterenv": 123, "creator": [124, 552, 553, 559, 560, 561], "substitut": [124, 262, 277, 627], "vecnorm": [124, 278, 534, 535, 561], "test_env1": 124, "observation_count": [124, 643], "test_env2": 124, "ps": 124, "p1": 124, "p2": 124, "join": [124, 183, 622, 623, 625, 636], "9934": 124, "make_vari": [124, 268], "variant": [124, 268], "trajcount": [124, 526], "env_creator_pendulum": 124, "env_creator_cartpol": 124, "env_str": 125, "device_map": 125, "asyncvectorenv": 126, "pixel_observ": [126, 128, 129, 153], "pixelobservationwrapp": [126, 128, 129, 153], "adventur": [126, 128], "airraid": [126, 128, 643], "alien": [126, 128], "time_limit": 126, "timelimit": [126, 139, 140, 161, 162], "default_info_dict_read": [126, 127, 128, 147, 178], "reader": [126, 127, 128, 147, 178, 622], "set_info_dict_read": [126, 127, 128, 147, 178, 626], "info_dict": [126, 127, 128, 147, 178], "gymlikeenv": [126, 128, 178], "auto_register_info_dict": [126, 127, 128, 147, 178], "multibinari": [126, 128], "multidiscret": [126, 128], "semant": [126, 128, 639], "rag": [126, 128], "gym_conversion_exampl": [126, 128], "info_dict_read": [127, 147, 178], "ignore_priv": [127, 178], "baseinfodictread": [127, 178], "tensordictprim": [127, 147, 178, 285, 300, 302, 521, 624], "succe": [127, 147, 178, 588], "underscor": [127, 178], "primer": [127, 168, 169, 170, 173, 176, 178, 183, 192, 263, 285, 300, 302, 315, 624], "halfcheetah": [127, 147, 178, 212, 252, 621, 642], "reward_run": [127, 147, 178], "raise_if_clos": [127, 178], "fast_encod": [127, 178], "memoize_cach": [127, 178], "adaptive_autorang": [127, 178], "4f": [127, 178, 379, 623, 624, 638], "fp": [127, 178, 388, 393, 395], "10141": [127, 178], "5742fp": [127, 178], "10576": [127, 178], "8388fp": [127, 178], "read_act": [127, 178], "read_don": [127, 178], "nonsens": [127, 178], "fallback": [127, 178, 322], "read_ob": [127, 178], "dictat": [127, 178, 240, 339, 341, 364, 621, 638], "read_reward": [127, 178], "gym_lik": [127, 178], "hoc": [127, 147, 178, 627], "dict_read": [127, 178], "my_info_kei": [127, 178], "some_env": [127, 178], "vecenv": 128, "vectorenv": 128, "convert_actions_to_numpi": [128, 443, 447], "missing_obs_valu": [128, 276, 443, 447], "vecgymenvtransform": [128, 533], "secur": [129, 633], "habitat3": 129, "ai": [129, 639], "habitatrenderpick": 129, "isaacgym": [130, 131, 445], "isaacgymwrapp": 130, "isaacgymenv": [131, 445], "webpag": 131, "isaac": [131, 132], "essenc": [131, 626], "scripts_isaaclab": 132, "managerbasedrlenv": 132, "app": 132, "applaunch": 132, "argpars": [132, 558, 561], "argumentpars": 132, "add_app_launcher_arg": 132, "args_cli": 132, "hydra_arg": 132, "parse_known_arg": 132, "app_launch": 132, "isaaclab_task": 132, "f401": 132, "manager_bas": 132, "ant_env_cfg": 132, "antenvcfg": 132, "isaac_lab": 132, "cfg": [132, 461, 462, 465, 466, 467, 550, 551, 552, 553, 554, 555, 556, 557, 558, 561], "instadeepai": [133, 134], "2306": [133, 134, 278], "09884": [133, 134], "snake": [133, 134, 170], "grid": [133, 134, 388], "bodi": [133, 134], "body_st": [133, 134], "fruit_posit": [133, 134], "col": [133, 134], "row": [133, 134, 240], "head_posit": [133, 134], "tail": [133, 134], "game2048": [133, 134], "maze": [133, 134], "cleaner": [133, 134, 593, 634], "cvrp": [133, 134], "multicvrp": [133, 134], "minesweep": [133, 134], "rubikscub": [133, 134], "knapsack": [133, 134], "sudoku": [133, 134], "tsp": [133, 134], "connector": [133, 134], "mmst": [133, 134], "graphcolor": [133, 134], "partli": [133, 134], "scrambl": [133, 134], "robotwarehous": [133, 134], "tetri": [133, 134], "binpack": [133, 134], "jobshop": [133, 134], "0x1fca91910": 133, "122": [133, 134, 643], "40": [133, 134], "0x1ff9baee0": 133, "134": [133, 134], "0x1ff9ba7c0": 133, "172": [133, 134], "jit": 134, "eager": [134, 332], "tdreset": [134, 635], "whichev": 134, "mctsforest": [135, 177], "vocab_s": [135, 176, 177, 525, 614], "vocabulari": [135, 176, 177, 197, 267], "omit": [135, 177, 183, 284, 299, 310, 405, 623, 628, 638, 640], "hashing_modul": [135, 177], "siphash": [135, 177], "text_output": [135, 177], "batch_decod": [135, 177], "text_kei": [135, 177, 324, 327, 330, 335], "gpt2token": [135, 177], "input_id": [135, 176, 177], "make_tensordict": [135, 177], "mo": [136, 137], "minecart": [136, 137], "mo_gym": [137, 240], "marl": [138, 164, 219, 260, 264, 354, 367, 626, 636, 637], "group_map": [138, 139, 140, 145, 146, 149, 150, 159, 160, 161, 162, 164, 636], "constructiuon": [138, 149, 150], "premad": [138, 139, 140, 149, 150, 161, 162], "all_in_one_group": [138, 145, 146, 164], "agent_0": [138, 149, 150, 159, 164, 260], "agent_1": [138, 149, 150, 159, 164, 260], "agent_2": [138, 149, 150, 159, 164], "agent_3": [138, 159], "one_group_per_ag": [138, 149, 150], "meltingpot": [139, 140, 448], "2211": [139, 140], "13746": [139, 140], "melt": [139, 140], "pot": [139, 140], "novel": [139, 140, 628], "social": [139, 140], "situat": [139, 140, 176, 183], "familiar": [139, 140, 622, 633, 637, 643], "unfamiliar": [139, 140], "broad": [139, 140], "cooper": [139, 140, 636, 637], "decept": [139, 140], "reciproc": [139, 140], "stubborn": [139, 140], "substrat": [139, 140], "ml_collect": 139, "config_dict": 139, "configdict": 139, "horizon": [139, 140, 161, 162, 623], "infinit": [139, 140, 161, 162, 169, 170, 173, 183, 278, 629, 640], "categorical_act": [139, 140, 145, 146, 149, 150, 154, 155, 159, 160, 161, 162], "agent_nam": [139, 140, 161, 162, 164], "agent_names_to_indices_map": [139, 140, 161, 162], "env_torchrl": [139, 140], "commons_harvest__open": [139, 140], "rgb": [139, 140], "144": [139, 140, 188], "collective_reward": [139, 140], "ready_to_shoot": [139, 140], "88": [139, 140, 154, 155], "substrate_config": 140, "get_config": 140, "mp_env": 140, "build_from_config": 140, "default_player_rol": 140, "mymbenv": 141, "world_model": [141, 357], "hidden_observ": 141, "worldmodelwrapp": [141, 600], "activation_class": [141, 286, 288, 289, 290, 291, 297, 298, 303, 461, 462, 622, 627, 636, 637, 642], "relu": [141, 292, 305, 324, 330, 335, 600], "activate_last_lay": [141, 291, 303, 462], "sail": [142, 143], "sg": [142, 143], "10558": [142, 143], "readthedoc": [142, 145, 146], "en": [142, 145, 146], "python_interfac": 142, "envpoolmixin": 143, "env_bas": 143, "task_id": 143, "env_typ": 143, "gym_reset_return_info": 143, "envpool_env": 143, "www": [144, 304], "fetch_openml": 144, "dataset_nam": 144, "106": 144, "openspiel": [145, 146, 451], "open_spiel": [145, 146], "game_str": 145, "return_st": [145, 146, 149, 150], "4672": [145, 146], "current_play": [145, 146], "674": 145, "2048": [145, 146], "add_nois": [145, 146], "amazon": [145, 146], "backgammon": [145, 146], "restor": [145, 146, 593, 615], "td_restor": [145, 146], "pyspiel": 146, "load_gam": 146, "new_initial_st": 146, "3009": 146, "my_env_fun": [147, 156], "custom_attribute_list": [147, 156], "custom_attribut": [147, 156], "custom_method_list": [147, 156], "custom_method": [147, 156], "deploi": [147, 156, 216, 625], "slight": [147, 156, 622], "share_individual_td": [147, 156], "shared_memori": [147, 156], "policy_proof": [147, 156], "ll": [147, 156, 224, 575, 621, 622, 623, 624, 626, 627, 628, 629, 631, 633, 637, 643], "serial_for_singl": [147, 156, 622], "circular": [147, 156, 621], "daemon": [147, 156], "list_of_kwarg": [147, 156], "sharabl": [147, 156], "com_veloc": [147, 156], "head_height": [147, 156], "joint_angl": [147, 156], "torso_vert": [147, 156], "batched_pipe_timeout": 147, "stringent": [147, 623, 636, 637], "penv": [147, 268], "env_fix": 147, "influenc": 147, "thumb": [147, 623], "update_kwarg": [147, 156], "th": [148, 234, 272, 638], "thdot": [148, 638], "max_spe": [148, 638], "max_torqu": [148, 638], "dt": [148, 310, 638], "gen_param": [148, 638], "gravit": [148, 638], "torqu": [148, 638], "pettingzoo": [149, 150, 452, 636, 637], "pet": [149, 150], "zoo": [149, 150], "__": [149, 150], "aecenv": [149, 150], "dead": [149, 150], "done_on_ani": [149, 150, 636], "compulsori": [149, 150], "adversary_0": [149, 150], "adversari": [149, 150, 359, 636], "sisl": 149, "multiwalker_v9": 149, "aec": [149, 150], "n_piston": [149, 150], "pistonball_v6": [149, 150], "piston": [149, 150], "piston_0": [149, 150], "piston_1": [149, 150], "piston_20": [149, 150], "tictactoe_v3": [149, 150], "player": [149, 150, 158], "player_1": [149, 150], "player_2": [149, 150], "butterfli": 150, "_setup": [151, 157], "async_reset_send": [151, 157], "async_reset_recv": [151, 157], "cube": 152, "vikashplu": 153, "wiki": 153, "06828": 153, "from_depth": 153, "smacv2": [154, 155, 454], "starcraft": [154, 155], "challeng": [154, 155, 626, 638, 639], "10gen_terran": [154, 155], "10gen_zerg": [154, 155], "10gen_protoss": [154, 155], "3m": [154, 155], "8m": [154, 155], "25m": [154, 155], "5m_vs_6m": [154, 155], "8m_vs_9m": [154, 155], "10m_vs_11m": [154, 155], "27m_vs_30m": [154, 155], "mmm": [154, 155], "mmm2": [154, 155], "2s3z": [154, 155], "3s5z": [154, 155], "3s5z_vs_3s6z": [154, 155], "3s_vs_3z": [154, 155], "3s_vs_4z": [154, 155], "3s_vs_5z": [154, 155], "1c3s5z": [154, 155], "2m_vs_1z": [154, 155], "corridor": [154, 155], "6h_vs_8z": [154, 155], "2s_vs_1sc": [154, 155], "so_many_banel": [154, 155], "bane_vs_ban": [154, 155], "2c_vs_64zg": [154, 155], "old": [154, 155, 270, 278, 361, 576, 643], "smac": [154, 155], "map_nam": [154, 155], "176": [154, 155], "battle_won": [154, 155], "dead_al": [154, 155], "dead_enemi": [154, 155], "episode_limit": [154, 155], "322": [154, 155, 181], "procedur": [154, 155, 322], "distribution_config": [154, 155], "n_unit": [154, 155], "n_enemi": [154, 155], "team_gen": [154, 155], "dist_typ": [154, 155], "weighted_team": [154, 155], "unit_typ": [154, 155], "marin": [154, 155], "maraud": [154, 155], "medivac": [154, 155], "exception_unit_typ": [154, 155], "start_posit": [154, 155], "surrounded_and_reflect": [154, 155], "map_x": [154, 155], "map_i": [154, 155], "capability_config": [154, 155], "131": [154, 155], "starcraft2env": 155, "tic": 158, "tac": 158, "toe": 158, "single_play": 158, "player1": 158, "desired_batch_s": 158, "player0": 158, "uniti": [159, 160], "technolog": [159, 160], "llapi": [159, 160], "mlagents_env": [159, 160], "unityenviron": [159, 160], "file_nam": 159, "registered_nam": 159, "3dball": 159, "group_0": 159, "vectorsensor_size8": 159, "continuous_act": [159, 161, 162, 386, 636, 637], "agent_10": 159, "agent_11": 159, "agent_4": 159, "agent_5": 159, "agent_6": 159, "agent_7": 159, "agent_8": 159, "agent_9": 159, "group_reward": 159, "proroklab": [161, 162], "vectorizedmultiagentsimul": [161, 162], "2207": [161, 162], "03530": [161, 162], "basescenario": 161, "defaultt": 161, "sparsiti": 161, "unbatched_action_spec": [161, 162], "unbatched_observation_spec": [161, 162], "unbatched_reward_spec": [161, 162], "het_spec": [161, 162], "het_specs_map": [161, 162], "flock": [161, 162, 386], "agent_collision_rew": [161, 162], "agent_distance_rew": [161, 162], "ca": 164, "environment4": 164, "get_group_map": 164, "probabilist": [165, 239, 339, 345, 364, 600, 623, 642], "sumbodul": 167, "blank": [168, 593], "canva": [168, 593], "fundament": [168, 593, 629], "intention": [168, 593], "data_kei": [168, 169, 170, 173, 176, 192], "dialogu": 168, "klrewardtransform": [168, 186, 193, 194, 498, 593], "kl": [168, 186, 187, 193, 194, 239, 357, 361, 375, 379, 593], "diverg": [168, 186, 187, 193, 194, 239, 339, 341, 357, 361, 375, 379, 593], "pythoninterpret": [168, 190, 593, 614], "dataloadingprim": [168, 169, 176, 192, 263, 593], "addthinkingprompt": [168, 593], "input_mod": [168, 169, 170, 172, 173, 193, 194, 324, 327, 330, 335, 593, 634], "system_prompt": [168, 169, 170, 173, 191, 593, 614, 633], "template_kwarg": [168, 169, 170, 173], "system_rol": [168, 593], "user_rol": [168, 593], "policy_rol": 168, "response_kei": 168, "datasetchatenv": 168, "gsm8kenv": [168, 169, 172, 179, 181, 593], "ifevalenv": [168, 169, 593], "response_data": 168, "next_ob": [168, 244, 381, 382, 383, 384, 642], "mont": [168, 169, 170, 173, 176, 183, 345, 347, 361, 364, 375, 378, 621], "carlo": [168, 169, 170, 173, 176, 183, 345, 347, 361, 364, 375, 378, 621], "pull": [169, 640], "rlhf": [169, 239, 375], "feedback": [169, 414, 593, 631, 642], "rlvr": 169, "batch_size_dl": [169, 170, 173, 179], "apply_templ": [169, 170, 173, 191, 633], "ray_backend": [169, 170, 173], "dataloader_actor_nam": [169, 170, 173], "thin": [169, 178], "chatenv": [169, 170, 173, 178, 184, 188, 191, 195, 591, 614, 633], "reset_dataload": [169, 170, 173, 183, 192], "set_missing_toler": [169, 170, 173, 192, 270], "gsm8k": [170, 171, 179, 593], "compute_reward": [170, 173], "gsm8k_dataload": 170, "3b": [170, 173, 181, 191, 322, 331, 332, 335], "question": [170, 173, 633, 640, 642], "bought": 170, "sandwich": 170, "he": 170, "paid": 170, "calcul": [170, 188, 195, 253, 345, 347, 352, 361, 364, 366, 368, 375, 381, 412], "breed": 170, "36": 170, "mari": 170, "saw": [170, 630, 638, 640], "reward_answ": [170, 172, 593], "reward_contain": [170, 172, 593], "reward_right": [170, 172, 593], "reward_think": [170, 172, 593], "snak": 170, "set_done_if_answ": [172, 175, 593], "make_gsm8k_env": 172, "sentenc": 172, "extract_tag": [172, 593], "xml": [172, 195, 201, 593], "ifev": [173, 175, 593], "ifeval_dataload": 173, "pprint": [173, 593], "instruction_id_list": [173, 175], "detectable_cont": 173, "number_placehold": 173, "num_highlight": 173, "num_": 173, "respond": 173, "plan": [173, 614], "week": 173, "europ": 173, "trip": 173, "london": 173, "rome": 173, "cap": [173, 623, 640], "restaur": 173, "prompt_level_strict_acc": [174, 175], "inst_level_strict_acc": [174, 175], "prompt_level_loose_acc": [174, 175], "inst_level_loose_acc": [174, 175], "instruction_ids_kei": 175, "keyword_args_kei": 175, "id_kei": 175, "response_column": 175, "score_kei": 175, "ifeval_scor": 175, "aggregate_reward": 175, "_scorer": 175, "ifevalscoredata": [175, 593], "format_weight": 175, "scorer": 175, "IF": 175, "co": [175, 231, 322, 638], "column": 175, "builder": [175, 179, 615, 622, 643], "think_block": 175, "answer_block": [175, 593], "langdetect": 175, "nltk": 175, "immutabledict": 175, "default_reward_aggreg": [175, 593], "tier": 175, "eo": [175, 335], "metric": [175, 347, 364, 375, 397, 403, 410, 412, 414, 415, 470, 621], "multipli": [175, 176, 183, 345, 346, 347, 348, 354, 361, 363, 364, 365, 367, 375, 407, 621, 636], "penalti": [175, 180, 186, 324, 330, 335, 359, 361], "formula": [175, 239, 301, 318, 319, 345, 347, 361, 364, 375, 623], "format_scor": [175, 593], "quality_bonu": 175, "structure_multipli": 175, "complexity_scal": 175, "everyth": [175, 622, 623, 624, 630, 631], "incent": 175, "languag": [176, 593, 634], "cot": [176, 593], "token_kei": 176, "str_kei": 176, "attention_kei": 176, "assign_reward": 176, "has_attent": 176, "assign_don": 176, "batchless": 176, "eos_token_id": [176, 330], "pretrainedtokenizerbas": [176, 197, 267], "stack_method": [176, 183, 192], "as_nested_tensor": [176, 183, 324, 330, 335], "bert": [176, 197, 267], "uncas": [176, 197, 267], "tokens_in": 176, "tokens_out": 176, "grpo": [176, 183, 373, 375], "mlgym": [178, 180, 593], "get_library_nam": 178, "prisonersdilemma": 180, "reward_wrong_format": 180, "mlgymenv": [180, 593], "wrongli": 180, "cond": [181, 224, 225, 484], "random_prompt": 181, "edit_last_turn": 181, "zero_reward": 181, "undo_don": 181, "egocentr": 181, "reconsid": 181, "But": [181, 614, 635], "me": [181, 185, 188, 633], "wrong_answ": 181, "natalia": 181, "sold": 181, "48": 181, "friend": 181, "april": 181, "she": [181, 640], "72": 181, "altogeth": [181, 225], "undon": 181, "correct_answ": 181, "allowed_domain": [182, 633], "tool_nam": [182, 188, 191, 195, 201], "web": [182, 625, 633], "brows": [182, 633], "browser": [182, 188, 633], "click": [182, 633], "llm_tool": 182, "clean": [182, 322, 327, 397, 562, 593, 614], "use_ray_servic": [183, 187, 193, 241], "mappabl": 183, "dataloader_factori": [183, 192], "unrel": 183, "dl": 183, "raydataloadingprim": 183, "endless_dataload": [183, 192], "set_capture_non_tensor_stack": 183, "dummydataload": 183, "generate_random_str": 183, "ascii_lowercas": 183, "__next__": 183, "zxwvupirska": 183, "stringa": 183, "zxwvupirsk": 183, "roll": 183, "init_st": 183, "nngcmflsana": 183, "vrrbnhzpmga": 183, "nngcmflsan": 183, "vrrb": 183, "dummytensordataload": 183, "max_length": [183, 197, 267, 625, 631], "generate_random_tensor": 183, "pad_tensor": 183, "padding_length": 183, "data_spec": 183, "toolregistri": 184, "llmtoolpars": [184, 195], "stop_on_error": 184, "pass_state_to_tool": 184, "pluggabl": 184, "xmlblockpars": [184, 195], "websearch": 184, "schema_in": [184, 199, 200], "schema_out": [184, 199, 200], "titl": [184, 623, 624, 625, 637, 638], "json": [185, 188, 633], "gen_log_probs_full_kei": [186, 193], "log_prob": [186, 193, 293, 304, 308, 319, 324, 327, 330, 335, 341, 348, 354, 367, 373, 375, 379, 634], "ref_log_probs_full_kei": [186, 193], "ref_log_prob": [186, 193, 194, 373, 375, 379], "kl_kei": [186, 193], "kl_penalti": [186, 193], "add_to_reward": [186, 193], "coeff": [186, 193, 347, 361, 364], "padding_sid": [186, 187, 193, 194, 304, 324, 330, 335], "retrievelogprob": [186, 187, 193, 379], "retrievekl": [186, 187, 194], "pad_output": [186, 193, 194, 324, 327, 330, 335, 634], "gen_log_prob": [186, 193], "pad_sequ": [186, 187, 193, 194], "next_td": [186, 193], "kl_transform": 186, "gen_log_probs_kei": 186, "ref_log_probs_kei": 186, "coef": [186, 239], "chathistori": [187, 193, 194, 328, 329, 330, 335], "ref_model": [187, 193, 194], "llmwrapperbas": [187, 193, 194, 330, 335, 375], "ref_model_factori": [187, 193], "assistant_onli": [187, 193, 194, 379], "upcom": [187, 193, 362, 373, 375, 379, 621], "actor_nam": [187, 192, 193, 241, 327], "gen_model": [187, 193], "klcomput": [187, 193, 194], "tool_call_pattern": [188, 195], "protocol": [188, 195, 200], "mcp": 188, "npx": 188, "uvx": 188, "browsermcp": 188, "regex": [188, 195, 593], "tool_name_with_serv": 188, "args_json": [188, 195], "os": [188, 622, 634], "deno": 188, "deno_path": 188, "expandus": 188, "stdio": 188, "sqrt": [188, 310], "pi": [188, 625, 636, 637, 638], "run_python_cod": 188, "python_cod": 188, "linkedlist": 188, "successfulli": [188, 191, 584, 593, 633, 634], "textcont": 188, "nresult": 188, "141592653589793": 188, "return_valu": 188, "n15": 188, "annot": [188, 633], "curl": 188, "fssl": 188, "land": 188, "sh": 188, "version_typ": 189, "llmcollector": [189, 193, 324, 330, 335, 593], "tracker": [189, 238], "current_vers": 189, "uuid4": 189, "pool_siz": [190, 191, 614], "get_servic": [190, 191, 614], "python_executor": [190, 191, 614], "max_concurr": [190, 191, 327, 396, 614], "cleanup": [190, 322, 335, 591], "robin": [190, 322, 429, 614], "stdout": 190, "stderr": 190, "returncod": 190, "service_nam": [191, 398, 614], "namespac": [191, 396, 398, 558, 561, 591], "tooltransformbas": 191, "boilerpl": 191, "inject": 191, "nprint": 191, "pythonexecutorservic": [191, 593, 614], "reus": [192, 288, 395, 593], "create_dataload": 192, "primer1": 192, "primer2": 192, "travers": 192, "missing_toler": [192, 197, 267], "reset_par": [192, 269], "set_contain": [192, 269], "ahead": [193, 643], "from_collector": 193, "get_new_vers": [193, 324, 327, 330, 335], "gen_model_factori": 193, "consciou": [193, 194], "identif": [193, 194], "history_kei": [193, 330, 335], "tokenizer_kwarg": [193, 194, 324, 330, 335, 379], "assit": [193, 194, 379], "rayretrievekl": 193, "optconfig": [193, 194, 379], "optforcausallm": [193, 194, 379], "weather": [193, 194, 379], "facebook": [193, 194, 379], "opt": [193, 194, 379], "125m": [193, 194, 379], "return_log_prob": [193, 194, 239, 281, 282, 283, 330, 335, 339, 341, 343, 366, 379, 465, 623, 627, 634, 636, 637, 642], "log_probs_kei": [193, 194, 324, 327, 330, 335], "chat_histori": [193, 194, 330, 335], "log_probs_full_kei": 194, "batchabl": 194, "tool_schema": 195, "mcptooltransform": [195, 593], "schema": [195, 200], "unknown": [195, 621], "use_raw_nontensor": [197, 237, 267, 271], "additional_token": [197, 267], "skip_special_token": [197, 267, 324, 329, 330, 335], "add_special_token": [197, 267], "return_attention_mask": [197, 267], "call_before_reset": [197, 267], "test_input_spec": [197, 271], "visibl": [198, 396, 397, 398, 575, 591, 637], "label": [198, 621, 636, 640], "correl": [198, 310], "toolservic": 199, "addservic": 199, "optional_tag": 201, "nsome": 201, "list_of_tensordict": [202, 203], "unsqueeze_null_shap": 204, "dynamic_shap": 204, "model_bas": [205, 206], "dreamer": [205, 206, 297, 356, 357, 358], "model_based_env": [205, 356], "dreamerenv": [205, 356], "model_based_env_ev": 205, "spec_typ": 207, "convert_specnam": 207, "remap_state_to_observ": 207, "spectyp": 207, "unus": 207, "probabilistictdmodul": [208, 303, 339, 341, 404], "keep_oth": [210, 638], "exclude_reward": 210, "exclude_don": 210, "next_": 210, "mdp": [210, 626, 638], "write_full_fals": 211, "_terminated_or_trunc": 211, "num_interv": [212, 472], "out_action_kei": [212, 472], "samplingstrategi": 212, "optino": 212, "intenum": 212, "action_disc": 212, "qualnam": [212, 316, 370], "boundari": [212, 316, 344, 370, 623, 625, 636, 637], "masker": 213, "finit": [213, 233, 627, 640], "maskedenv": 213, "ones_lik": [213, 304], "scatter": 213, "fill_float": [215, 474], "fill_int": [215, 474], "fill_bool": [215, 474], "someenvclass": 215, "autoresetenv": 215, "fooenv": 215, "sign": [215, 258, 381, 636], "envtyp": 215, "3633e": 215, "4877e": 215, "2849e": 215, "7584e": 215, "6609e": 215, "6166e": 215, "8366e": 215, "2761e": 215, "5685e": 215, "4102e": 215, "8111e": 215, "9959e": 215, "0865e": 215, "5644e": 215, "2119e": 215, "2542e": 215, "9952e": 215, "4059e": 215, "2094e": 215, "9009e": 215, "5140e": 215, "3554e": 215, "2920e": 215, "7893e": 215, "6429e": 215, "3057e": 215, "2867e": 215, "6963e": 215, "3818e": 215, "2576e": 215, "2679e": 215, "1640e": 215, "6972e": 215, "0212e": 215, "5959e": 215, "4637e": 215, "3121e": 215, "2168e": 215, "5232e": 215, "7704e": 215, "7457e": 215, "4127e": 215, "1064e": 215, "0854e": 215, "5712e": 215, "2189e": 215, "5235e": 215, "8289e": 215, "0009e": 215, "0257e": 215, "8893e": 215, "5872e": 215, "9405e": 215, "7766e": 215, "0403e": 215, "0626e": 215, "2959e": 215, "7263e": 215, "2775e": 215, "9564e": 215, "0411e": 215, "6769e": 215, "6354e": 215, "8698e": 215, "1765e": 215, "6292e": 215, "5375e": 215, "1820e": 215, "7023e": 215, "5836e": 215, "9016e": 215, "4826e": 215, "6191e": 215, "6387e": 215, "8667e": 215, "2056e": 215, "1147e": 215, "5991e": 215, "0278e": 215, "5219e": 215, "3067e": 215, "6617e": 215, "3322e": 215, "2629e": 215, "4599e": 215, "7298e": 215, "5848e": 215, "0148e": 215, "5745e": 215, "6982e": 215, "7877e": 215, "3527e": 215, "7285e": 215, "6668e": 215, "0583e": 215, "6956e": 215, "3962e": 215, "9845e": 215, "5015e": 215, "5903e": 215, "9993e": 215, "9418e": 215, "0196e": 215, "6557e": 215, "2109e": 215, "8997e": 215, "1507e": 215, "7363e": 215, "0310e": 215, "9574e": 215, "8980e": 215, "0090e": 215, "reshape_fn": [216, 475, 625], "reset_func": [216, 475], "tensordict_batch_s": 216, "tensordict_reset": [216, 638], "biner": 217, "burn_in": [218, 477], "burn": 218, "burnt": 218, "grumodul": [218, 263, 600, 624], "gru_modul": [218, 300], "input_s": [218, 263, 300, 302, 624, 625], "hidden_s": [218, 263, 300, 302, 624, 625], "default_recurrent_mod": [218, 300, 302], "burn_in_transform": 218, "gru": [218, 263, 300, 625], "num_lay": [218, 300, 302, 306, 307, 625], "86": 218, "3008": 218, "37": 218, "0344": 218, "padding_valu": [219, 304, 324, 330, 335], "as_invers": 219, "movement": [219, 364], "propos": [219, 231, 624, 640], "pdf": [219, 287, 288, 289, 290, 291, 296, 310, 348, 355, 359, 365, 368, 381], "1312": 219, "5602": 219, "unsqueezetransform": [219, 529, 638, 640], "consumpt": 219, "pictur": 219, "pixels_trsf": [219, 640], "grayscal": [219, 495, 622, 624, 625, 640, 643], "data_exclud": [219, 640], "mitig": 219, "make_rb_transform_and_sampl": 219, "sampler_kwarg": 219, "redund": [219, 593, 624], "fly": [219, 277, 361, 593, 623, 638, 640, 643], "del_kei": [220, 260, 273, 635, 638], "unsqueeze_if_oor": 220, "observation_posit": 220, "observation_veloc": 220, "center": [221, 388, 546], "width": [221, 226, 252, 480, 485], "scalar": [222, 254, 284, 289, 291, 299, 310, 345, 346, 347, 353, 354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 369, 373, 375, 379, 381, 382, 383, 384, 403, 622, 628, 638], "rewardsc": [223, 270, 513, 621, 622, 624], "rewardclip": [223, 512], "transform_list": 223, "condition": 224, "switch": [224, 270, 278, 301, 319, 386, 614, 634], "unalt": 224, "criteria": [224, 330], "mod": [224, 239, 285, 300, 302, 324, 330, 335, 338, 341, 344, 373, 375, 379, 624, 625, 631], "policy_switch": 224, "step_count_tot": 224, "step_count_main": 224, "0322": 224, "1540": 224, "0111": 224, "3190": 224, "0299": 224, "1544": 224, "0181": 224, "3280": 224, "0276": 224, "1550": 224, "0255": 224, "3414": 224, "0253": 224, "1558": 224, "0334": 224, "3596": 224, "0230": 224, "1569": 224, "0422": 224, "3828": 224, "0206": 224, "1582": 224, "0519": 224, "4117": 224, "1598": 224, "0629": 224, "4469": 224, "0156": 224, "1617": 224, "0753": 224, "4891": 224, "0130": 224, "1639": 224, "0895": 224, "5394": 224, "0104": 224, "1665": 224, "1058": 224, "5987": 224, "0076": 224, "1696": 224, "1246": 224, "6685": 224, "0047": 224, "1732": 224, "1463": 224, "7504": 224, "0016": 224, "1774": 224, "1715": 224, "8459": 224, "0020": 224, "0150": 224, "1884": 224, "6117": 224, "0017": 224, "2071": 224, "3838": 224, "0105": 224, "2115": 224, "5110": 224, "exectu": 225, "palliat": [225, 627], "inner_count": 225, "middle_env": 225, "middle_count": 225, "auto_unwrap": [225, 270, 399, 439], "9670": 225, "2546": 225, "9669": 225, "9802": 225, "1981": 225, "1601": 225, "9926": 225, "1214": 225, "5556": 225, "9994": 225, "7622": 225, "9984": 225, "0561": 225, "7933": 225, "9895": 225, "1445": 225, "7779": 225, "dtype_in": 227, "dtype_out": 227, "scan": [227, 230, 342, 343], "resp": [227, 230], "anticip": [227, 230], "not_transform": [227, 230], "orig_devic": 228, "unspecifi": 228, "num_actions_effect": 229, "max_act": 229, "include_forward": 229, "num_act": [229, 286, 354, 488, 625, 627], "action_out": 229, "inde": [229, 623, 625, 638], "eol_kei": [231, 490], "life": [231, 490, 639], "lives_kei": [231, 490], "eol_attribut": [231, 490], "breakout": 231, "210": [231, 246], "160": [231, 246], "eol_transform": 231, "eol": 231, "dqnloss": [231, 345, 346, 348, 349, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 370, 373, 375, 379, 554, 607, 622, 624, 625, 631], "register_kei": 231, "loss_or_advantag": 231, "lossmodul": [231, 410, 414, 415, 556, 557, 607], "valueestimatorbas": [231, 362, 373, 375, 379], "excluded_kei": 232, "first_dim": 234, "last_dim": 234, "allow_positive_dim": [234, 260, 272], "frameskip": 234, "repeatedli": [235, 623, 637], "hash_fn": 237, "repertoir": 237, "reproducible_hash": 237, "unarytransform": [237, 528], "observation_str": 237, "tobyt": [237, 271], "observation_hash": 237, "x08": 237, "x8b": 237, "xbexav": 237, "xbf": 237, "x00": 237, "xee": 237, "xb5": 237, "x17": 237, "x8f": 237, "xbe": [237, 271], "x88": 237, "xccu": 237, "xc0vr": 237, "get_input_from_hash": 237, "hash_tensor": 237, "bit": [237, 623, 624, 626, 636, 637, 640], "init_kei": [238, 338], "log_prob_kei": [239, 327, 341], "sample_log_prob": [239, 281, 282, 283, 339, 341, 343, 364, 373, 375], "pi_curr": 239, "pi_0": 239, "overfit": 239, "get_dist": [239, 324, 327, 330, 335, 341, 342], "frozen": [239, 277, 278], "normalparamextractor": [239, 281, 282, 283, 339, 343, 345, 346, 348, 354, 360, 364, 365, 366, 367, 368, 369, 600, 623, 627, 637, 642], "probabilisticactor": [239, 281, 282, 283, 345, 346, 348, 351, 353, 354, 360, 363, 364, 365, 366, 367, 368, 369, 600, 621, 623, 627, 636, 637], "tanhnorm": [239, 281, 282, 283, 339, 343, 345, 346, 348, 360, 364, 365, 366, 367, 368, 369, 465, 600, 623, 637, 642], "reward_kl": 239, "apply_": 239, "copy_": [239, 621], "mogymwrapp": 240, "mo_env": 240, "sea": 240, "treasur": 240, "so_env": 240, "module_factori": 241, "At": [241, 265, 299, 315, 622, 623, 624, 629, 635, 638, 639], "observation_spec_transform": 241, "done_spec_transform": 241, "reward_spec_transform": 241, "state_spec_transform": 241, "action_spec_transform": 241, "stack_reward": [242, 500], "stack_observ": [242, 500], "auto_batch_size_": 242, "macro": [242, 338], "trial": 243, "standard_norm": [244, 255, 277, 278, 503, 513, 621, 622, 624], "affin": [244, 255, 277, 278], "recover": 244, "set_default_tensor_typ": 244, "doubletensor": 244, "isclos": 244, "rubric": [244, 324, 330, 335, 343, 373, 375, 379], "init_stat": [244, 621, 622, 623, 624], "3752e": 244, "5087e": 244, "9294e": 244, "9636": 244, "5608": 244, "6408": 244, "num_it": [244, 622, 623], "reduce_dim": [244, 621, 622, 623, 624], "cat_dim": [244, 621, 622, 623, 624], "keep_dim": [244, 338, 622, 624], "statist": [244, 277, 278, 322, 331, 366, 414, 415, 561, 621, 622, 623, 643], "gaussian": [244, 263, 284, 309, 623, 625, 636], "empir": [244, 339, 341, 621, 623, 637], "3d": 244, "reorder": 246, "in_keys_in": [246, 272], "channel": [246, 266, 306, 307, 622], "r3m": [248, 506, 639], "resnet": [248, 273, 275], "visual": [248, 273, 275, 388, 618, 623, 636, 638], "embed": [248, 273, 274, 275, 281, 282, 283, 288, 320, 337, 340, 341, 639], "ego4d": [248, 273, 275], "univers": [248, 273, 275, 330, 626], "suraj": [248, 273], "nair": [248, 273], "aravind": [248, 273], "rajeswaran": [248, 273], "vikash": [248, 273, 275], "kumar": [248, 273, 275], "chelsea": [248, 273], "finn": [248, 273], "abhinav": [248, 273], "gupta": [248, 273], "2203": [248, 273, 639], "12601": [248, 273, 639], "_init": [248, 273, 621], "resnet50": [248, 275, 639], "model_nam": [248, 273, 275, 322, 331, 332, 391, 506, 614], "resnet34": 248, "resnet18": [248, 506], "r3m_vec": [248, 639], "stack_imag": [248, 275], "tread": [248, 275], "hub": [248, 275, 626], "resnet50_weight": [248, 275], "imagenet1k_v1": [248, 275], "download_path": [248, 275], "tensor_pixels_kei": [248, 275], "sub_seq_len": 249, "sample_dim": [249, 621], "hesit": 249, "improp": 249, "dummyenv": 250, "another_oth": 250, "other_reward": 250, "create_copi": 251, "stuff": [251, 629], "newnam": 251, "gamma": [253, 345, 346, 348, 349, 350, 352, 354, 355, 356, 358, 360, 362, 364, 365, 366, 367, 368, 369, 370, 373, 375, 379, 381, 382, 383, 384, 414, 469, 501, 511, 557, 607, 621, 622, 623, 636, 637, 642], "r2g": 253, "99": [253, 277, 358, 414, 501, 511, 534, 535, 543, 546, 557, 607, 621, 622, 623, 625, 628, 631, 636, 637, 642], "reward_to_go": 253, "bernoulli_": 253, "9010": 253, "9404": 253, "9701": 253, "9900": 253, "0000": [253, 264, 265, 299, 344], "clamp_min": [254, 512], "clamp_max": [254, 512], "clip_min": 254, "clip_max": 254, "episode_": 256, "reward1": 256, "reward2": 256, "episode_reward": [256, 636, 637], "keep_reward": 257, "keep_don": 257, "logical_or": 258, "in_key_inv": 260, "unstack": 260, "update_don": [261, 519], "disjunct": 261, "recognis": 261, "target_return": [262, 520], "default_valu": 263, "expand_spec": 263, "single_default_valu": 263, "call_before_env_reset": 263, "unit": [263, 297, 306, 307, 313, 314, 623], "scala": 263, "mykei": 263, "__unless": 263, "exists__": 263, "get_primers_from_modul": [263, 285, 300, 302], "recurrent_st": [263, 300, 302, 624], "10th": 264, "0216": 264, "1149": 264, "1990": 264, "2749": 264, "3281": 264, "9290": 264, "3702": 264, "8978": 264, "time_kei": [265, 523], "elaps": [265, 630], "monitor": [265, 322, 324, 330, 335, 347, 364, 412, 414, 626], "expend": 265, "_polici": 265, "time_reset": 265, "time_polici": 265, "time_step": [265, 338], "0882": 265, "0002": 265, "5797e": 265, "6289e": 265, "7990e": 265, "0824e": 265, "0837e": 265, "6056e": 265, "2016e": 265, "1062e": 265, "7009e": 265, "from_int": [266, 524], "shape_toler": [266, 524], "ri": 266, "traj_count": [268, 526], "traj": 268, "countingenv": 268, "make_env_c0": 268, "make_env_c1": 268, "smoothli": 270, "add_1": 270, "cache_spec": [270, 439], "shown": [270, 593, 625, 633, 635, 636, 637, 640], "inv_fn": 271, "unari": 271, "durin": 271, "ommit": 271, "observation_trsf": 271, "xbc": 271, "x7f": 271, "x859": 271, "x81": 271, "x9a": 271, "xbd": 271, "xb8t8": 271, "test_output_spec": 271, "danger": 272, "vc1": [273, 530], "vc1_vec": 273, "untrain": 273, "make_noload_model": 273, "naiv": [273, 626], "vip": [274, 275, 531, 532, 639], "implicit": [275, 353, 360, 587, 640], "jason": 275, "ma": 275, "shagun": 275, "sodhani": 275, "dinesh": 275, "jayaraman": 275, "osbert": 275, "bastani": 275, "ami": 275, "zhang": 275, "vip_vec": 275, "final_nam": 276, "sb3": 276, "terminal_obs_read": 276, "vecnormv2": [277, 535], "new_api": [277, 278], "to_observation_norm": [277, 278], "frozen_copi": [277, 278], "shared_td": 277, "race": 277, "decai": [277, 278, 284, 299, 407, 534, 535, 621, 622, 624, 643], "underflow": [277, 407], "build_td_for_shared_vecnorm": 277, "memmori": 277, "td_share": 277, "unfreez": [277, 278], "train_env": 277, "eval_env": 277, "9999": 278, "shared_data": 278, "reduce_batch_dim": 278, "varianc": [278, 301, 305, 318, 319, 364, 621, 623, 637], "weigh": 278, "_cast_int_to_float": 278, "env_trsf": 278, "observation_norm": 278, "reward_norm": [278, 407], "unnorm": [278, 304, 308], "7967": 278, "1238": 278, "5911": 278, "5275": 278, "8585": 278, "5028": 278, "2505": 278, "3169": [278, 344], "1332": 278, "1235": 278, "6596e": 278, "3072e": 278, "9170e": 278, "9255e": 278, "9131e": 278, "4671e": 278, "3760e": 278, "2058e": 278, "3484e": 278, "6185e": 278, "1456": 278, "1862": 278, "2053": 278, "2605": 278, "4046": 278, "5185": 278, "8023": 278, "1364": 278, "6183": 278, "5406": 278, "0920": 278, "1492": 278, "2702": 278, "3917": 278, "5001": 278, "7947": 278, "0160": 278, "3347": 278, "9082": 278, "9679": 278, "2199": 278, "2918": 278, "1668": 278, "2083": 278, "4981": 278, "5046": 278, "7950": 278, "9791": 278, "1484": 278, "4182": 278, "2201": 278, "0403": 278, "5206": 278, "7791": 278, "8282": 278, "2279": 278, "2907": 278, "4929": 278, "7793": 278, "8626": 278, "1832": 278, "local_env": 278, "testifi": 278, "4307": 278, "9613": 278, "state_dim": [279, 287, 292, 309, 313, 314], "action_dim": [279, 287, 288, 290, 292, 309, 621, 635], "gsde": [279, 365, 561], "gsdemodul": 279, "module_nam": [280, 362, 373, 375, 379], "from_vers": 280, "to_vers": 280, "class_method": 280, "intersect": 280, "import_modul": 280, "get_class_that_defined_method": 280, "module_set": 280, "setters_dict": 280, "pyver": 280, "setter": 280, "setter_dict": 280, "actorvalueoper": [281, 347, 361, 364, 600, 627], "get_policy_oper": [281, 282, 283, 347, 361, 364], "tdmodul": [281, 282, 283, 557], "get_critic_oper": 281, "common_oper": [281, 283], "policy_oper": [281, 282, 283], "value_oper": [281, 282, 283], "valueoper": [281, 282, 283, 345, 346, 347, 348, 349, 354, 360, 361, 364, 365, 366, 367, 368, 369, 467, 557, 600, 607, 621, 623, 628], "module_hidden": [281, 283], "td_module_hidden": [281, 283], "safemodul": [281, 283, 341, 345, 346, 348, 353, 354, 360, 364, 365, 366, 367, 368, 369, 552, 553, 557, 600, 642], "module_act": [281, 283], "td_module_act": [281, 282, 283], "module_valu": [281, 282, 283], "td_module_valu": [281, 282, 283], "state_action_valu": [281, 320, 346, 348, 353, 360, 367, 557, 621, 636, 642], "td_modul": [281, 282, 283, 320, 337, 339, 340, 341, 343, 627, 642], "td_clone": [281, 282, 283], "tensordictmodulewrapp": [281, 552, 553, 557], "get_policy_head": [281, 282, 283], "safesequenti": [281, 282, 283], "head": [281, 283, 341, 347, 361, 364, 593], "get_value_head": [281, 282, 283], "get_value_oper": [281, 282, 283, 347, 361, 364], "action_modul": 282, "actorcriticoper": [283, 600, 627], "actorcriticwrapp": [283, 600, 621], "po": 284, "sigma_init": [284, 636], "sigma_end": [284, 636], "annealing_num_step": [284, 299, 310, 621, 622, 624, 625, 627, 631, 636], "sigma": [284, 301, 310, 318, 319, 379, 623, 636], "omiss": [284, 299, 310], "consistentdropout": 285, "input_shap": 285, "batcht": 285, "make_tensordict_prim": [285, 300, 302, 624], "input_dtyp": 285, "get_default_dtyp": [285, 407], "mask_6127171760": 285, "seq": [285, 300, 302, 324, 330, 335, 338, 373, 375, 379, 624, 625, 631, 635], "env0": [285, 643], "elu": [286, 288, 289, 290, 291, 297, 298, 622, 642], "activation_kwarg": [286, 303, 461, 462], "norm_class": [286, 288, 289, 303, 461, 462], "norm_kwarg": [286, 303, 461, 462], "bias_last_lay": [286, 288, 289, 290, 291, 298, 303, 461, 462], "aggregator_class": [286, 288, 289, 461, 622, 624, 642], "squashdim": [286, 288, 298, 600, 642], "aggregator_kwarg": [286, 288, 289, 461, 622, 624], "squeeze_output": [286, 288, 289, 461, 622, 624], "lazyconv2d": [286, 288, 289, 298], "cell": [286, 300, 302, 303, 623, 625, 626, 627, 628, 629, 630, 631], "cnet": 286, "34": [286, 303, 364], "35": [286, 303, 634], "default_atari_dqn": [286, 625], "semin": 286, "transformer_config": [287, 309], "decision_transform": [287, 309], "decisiontransform": [287, 309, 600], "dtconfig": [287, 292, 309], "2202": [287, 292, 363], "05607": [287, 292, 363], "return_to_go": [287, 292, 309], "conv_net_kwarg": [288, 289], "mlp_net_kwarg": [288, 289, 290], "use_avg_pool": [288, 289], "WITH": [288, 289, 290, 291, 310], "1509": [288, 289, 290, 291, 310, 350], "02971": [288, 289, 290, 291, 310], "maximis": [288, 290, 622, 623, 637], "ndims_in": [288, 336], "avgpool": [288, 289], "lazylinear": [288, 289, 290, 291, 298, 303, 623, 627, 638, 639], "2304": 288, "adaptiveavgpool2d": [289, 622, 624], "output_s": [289, 622, 624], "squeeze2dlay": 289, "400": [290, 291, 637], "mlp_net_kwargs_net1": 291, "mlp_net_kwargs_net2": 291, "mlp1": 291, "mlp2": 291, "desdescrib": 292, "n_embd": 292, "n_layer": 292, "n_head": 292, "n_inner": 292, "n_posit": 292, "resid_pdrop": 292, "attn_pdrop": 292, "gpt2config": 292, "atol": [293, 317], "rtol": [293, 317], "batch_shap": [293, 308, 317], "event_shap": [293, 317], "absolut": [293, 317, 621], "_instanc": 293, "densiti": [293, 304, 308, 319], "mass": [293, 304, 308, 319, 638], "rsampl": [293, 308, 341], "sample_shap": [293, 304, 308], "softmax": [294, 295, 296, 308], "qvaluemodul": [295, 311, 624, 625, 627, 631], "distributionaldqnnet": [295, 600], "make_log_softmax": 295, "character": [295, 311, 337, 339, 340, 640], "overflow": [295, 296, 311, 312, 318, 337, 339, 340, 341], "var_num": [295, 296, 312], "mult": [295, 296, 311, 312], "action_value_kei": [295, 296, 311, 312, 348, 362, 373, 375, 379], "action_mask_kei": [295, 296, 299, 311, 312], "nbin": 295, "log_softmax": 295, "qvalue_actor": [295, 311], "greedi": [296, 299, 312, 324, 330, 335, 600, 622, 624, 625, 627], "1707": [296, 355, 364], "06887": [296, 355], "my_action_valu": [296, 312], "chanc": 296, "std_bia": 297, "std_min_val": 297, "belief": [297, 306, 313, 314, 315], "1912": [297, 356, 357, 358], "01603": [297, 356, 357, 358], "softplu": [297, 305], "out_features_valu": 298, "cnn_kwarg": [298, 622], "mlp_kwarg": [298, 622], "duel": [298, 600], "cnn": [298, 622, 625, 627, 642], "06581": 298, "eps_init": [299, 310, 622, 624, 625, 627, 631], "eps_end": [299, 310, 622], "explorative_polici": [299, 310], "9055": 299, "9277": 299, "6295": 299, "2532": 299, "grad_fn": [299, 337, 341], "addbackward0": 299, "embedd": [300, 302], "grucel": [300, 340], "python_bas": [300, 302], "custom_kei": [300, 302], "hasn": [300, 302, 563, 565, 566, 568, 571, 574, 575, 576, 580, 582, 588], "set_recurrent_mod": [300, 302, 624], "recurrent_mod": [300, 302], "rnn": [300, 302, 354, 367, 381, 624, 625, 627], "rs": [300, 621], "gru_module_train": 300, "policy_train": [300, 379], "traj_td": 300, "make_cudnn_bas": [300, 302], "make_python_bas": [300, 302, 625], "supplementari": [300, 302, 623, 643], "That": [300, 302, 623, 636], "dealt": [300, 302], "poorli": [300, 302], "meth": [300, 302, 362, 638], "lstmmodul": [300, 600, 624, 625], "data_collector": [300, 302, 622], "upscal": [301, 318, 319], "tanh_loc": [301, 318, 319], "event_dim": [301, 317, 318], "poor": [301, 318, 319], "explos": [301, 318, 319], "lstmcell": [302, 625], "b_ih": 302, "b_hh": 302, "recurrent_state_h": 302, "recurrent_state_c": 302, "triplet": [302, 311, 312], "lstm_modul": 302, "rs_h": 302, "rs_c": 302, "single_bias_last_lay": [303, 462], "layer_class": [303, 462], "layer_kwarg": [303, 462], "perceptron": [303, 462, 627], "noisylinear": [303, 622], "noisylazylinear": 303, "neg_inf": 304, "inf": 304, "use_cross_entropi": 304, "api_doc": 304, "tf_agent": 304, "sparse_mask": 304, "cross_entropi": 304, "1203": 304, "0928": 304, "0831": 304, "1972": 304, "entropi": [304, 308, 345, 346, 347, 348, 353, 354, 360, 361, 363, 364, 365, 367, 368, 369, 372, 374, 375, 376, 377, 414, 415, 637], "scale_map": [305, 465], "biased_softplus_1": [305, 465], "scale_lb": [305, 313, 314, 465], "normal_param": 305, "1803": [306, 307], "10122": [306, 307], "rnn_hidden": 306, "latent": [307, 315], "grad_method": 308, "reparamgradientstrategi": [308, 600], "passthrough": 308, "relaxedonehot": 308, "inres": 309, "mu": [309, 310, 623], "ornstein": [310, 600, 621, 625], "uhlenbeck": [310, 600, 621, 625], "ou": [310, 621], "noise_t": 310, "noise_": 310, "theta": [310, 623, 638], "sigma_t": 310, "sigma_": 310, "ou_prev_nois": 310, "ou_step": 310, "x0": 310, "sigma_min": 310, "n_steps_ann": 310, "is_init_kei": 310, "_ou_prev_nois": 310, "_ou_step": 310, "tensordict_modul": [311, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 349, 353, 354, 360, 364, 365, 366, 367, 368, 369], "chose": 312, "hidden_dim": [313, 314], "posterior": [313, 315, 357], "rssm": [313, 314, 315, 357], "1811": [313, 314, 315], "04551": [313, 314, 315], "obs_embed": 313, "rnn_hidden_dim": 314, "dream": 314, "rssm_prior": 315, "rssm_posterior": 315, "s_": [315, 593, 633], "s_t": 315, "a_t": 315, "b_t": 315, "a_": 315, "evid": 315, "o_t": 315, "b_": 315, "o_": 315, "amend": 315, "safe_tanh": 318, "tanhtransform": 318, "get_mod": [318, 341], "custommodul": 320, "imaginari": 321, "imagin": 321, "transition_model": 321, "reward_model": 321, "get_reward_oper": 321, "get_transition_model_oper": 321, "engine_arg": 322, "asyncenginearg": [322, 331], "num_replica": [322, 331, 335, 581, 588, 593], "actor_class": 322, "enable_prefix_cach": 322, "replica": [322, 331, 335, 588], "placement": 322, "samplingparam": 322, "num_devic": [322, 331, 332], "max_model_len": 322, "4096": 322, "sampling_param": [322, 331], "temperatur": [322, 324, 330, 335, 346, 353, 360], "max_token": [322, 324, 330, 335], "tensor_parallel_s": [322, 331], "actor_index": 322, "grace": 322, "fault": 322, "resili": 322, "collective_rpc": [322, 584], "create_load_balanc": 322, "kv": 322, "loadbalanc": 322, "rout": 322, "smart": 322, "lb": 322, "selected_actor_index": 322, "select_actor": 322, "hierarchi": 322, "prefix_length": 322, "overload_threshold": 322, "enable_fp32_output": [322, 331, 332], "fp32": [322, 331, 332], "prompt_token_id": 322, "use_tqdm": 322, "lora_request": 322, "prompt_adapter_request": 322, "guided_options_request": 322, "timeout_second": 322, "requestoutput": 322, "tokensprompt": 322, "lora": 322, "get_cache_usag": 322, "fraction": [322, 345, 347, 364], "get_master_address": 322, "get_master_port": 322, "get_num_unfinished_request": 322, "unfinish": 322, "get_random_actor_index": 322, "init_weight_update_group": 322, "ref": 322, "asyncvllmengineservic": 322, "asyncllmengin": 322, "parameter_nam": 322, "to_text": [323, 329], "to_token": [323, 328], "logprob": [324, 330, 335, 634], "input_kei": [324, 330, 335, 634], "attention_mask_kei": [324, 330, 335], "generate_kwarg": [324, 327, 330, 335, 634], "max_new_token": [324, 327, 330, 335, 634], "num_return_sequ": [324, 330, 335], "top_p": [324, 330, 335], "nucleu": [324, 330, 335], "top_k": [324, 330, 335], "repetition_penalti": [324, 330, 335], "do_sampl": [324, 330, 335], "num_beam": [324, 330, 335], "beam": [324, 330, 335], "length_penalti": [324, 330, 335], "early_stop": [324, 330, 335], "stop_sequ": [324, 330, 335], "resolut": [324, 330, 335, 344, 563, 565, 566, 568, 571, 574, 580, 582, 588], "win": 324, "pad_model_input": [324, 330, 335], "num_sampl": [324, 327, 330, 335], "tokens_kei": [324, 327, 330, 335], "masks_kei": [324, 327, 330, 335], "ref_batch": [324, 330, 335], "min_batch_s": [324, 330, 335], "max_batch_s": [324, 330, 335], "batching_timeout": [324, 330, 335], "ref_transformers_wrapp": [324, 335], "ref_vllm_wrapp": [324, 330], "cleanup_batch": [324, 327, 330, 335], "flush": [324, 330, 335], "cancel": [324, 330, 335], "pend": [324, 330, 335, 572, 579, 585, 587], "_batch_queu": [324, 330, 335], "tensordict_out": [324, 330, 335, 643], "logits_onli": [324, 330, 335], "get_batching_st": [324, 327, 330, 335], "logits_kei": [324, 330, 335], "llmmaskedcategor": 324, "alter": [324, 327, 330, 335, 338, 362], "is_tdmodule_compat": [324, 330, 335, 373, 375, 379], "weak": [324, 330, 335], "reset_out_kei": [324, 330, 335, 373, 375, 379], "select_out_kei": [324, 330, 335, 345, 346, 348, 349, 353, 354, 360, 364, 365, 367, 368, 369, 373, 375, 379, 625], "reset_parameters_recurs": [324, 330, 335, 362, 373, 375, 379], "old_param": [324, 330, 335], "bork": [324, 330, 335], "dork": [324, 330, 335], "reset_paramet": [324, 330, 335], "complic": [324, 330, 335, 373, 375, 379, 638, 640, 643], "out_keys_sourc": [324, 330, 335, 373, 375, 379], "z": [324, 330, 335, 373, 375, 379], "all_attention_mask": [326, 330, 335, 634], "all_assistant_mask": [326, 330, 335, 634], "validate_model": 327, "automodelforcausallm": [327, 330, 634], "remote_wrapp": 327, "tensordict_input": 327, "dist_params_kei": 327, "dist_sample_kei": 327, "get_dist_with_prompt_mask": [327, 335], "to_histori": [328, 329], "wast": 330, "simpler": [330, 582, 622, 626, 634], "unsur": 330, "overlong": 330, "tokenization_util": [330, 335], "output_scor": 330, "discourag": [330, 335, 623, 638], "pad_token_id": 330, "bad_words_id": 330, "force_words_id": 330, "no_repeat_ngram_s": 330, "gram": 330, "encoder_repetition_penalti": 330, "repetit": [330, 623, 626, 629], "num_beam_group": 330, "diversity_penalti": 330, "return_dict_in_gener": 330, "ref_categorical_sequenti": [330, 335], "repeat_interleave_caus": 330, "sequence_length": 330, "_create_block_diagonal_attention_mask": 330, "causal": 330, "data_parallel_s": 331, "pipeline_parallel_s": 331, "_model": [331, 332], "make_ray_work": 332, "enforce_eag": 332, "rayllmwork": 332, "localllmwrapp": 332, "world_siz": [333, 334, 581, 588], "statelessprocessgroup": [333, 334], "plane": [333, 334], "pyncclcommun": [333, 334], "async_engin": 335, "presence_penalti": 335, "frequency_penalti": 335, "ignore_eo": 335, "prompt_logprob": 335, "detoken": 335, "include_stop_str_in_output": 335, "spaces_between_special_token": 335, "sampling_typ": 335, "temperature_last": 335, "top_p_last": 335, "top_k_last": 335, "assistant_mask_kei": 335, "set_token": 335, "defer": 335, "translat": [337, 339], "3635": 337, "0340": 337, "1476": 337, "3911": 337, "1664": 337, "5455": 337, "2247": 337, "4583": 337, "2916": 337, "2160": 337, "5337": 337, "5193": 337, "addmmbackward0": 337, "lookahead": 338, "window": [338, 636, 640, 642], "n_action": [338, 346, 348, 350, 352, 363, 367], "reshape_cat": 338, "actor_bas": 338, "obs_cat": 338, "obs_cat_reshap": 338, "action_orig": 338, "multistepenvwrapp": 338, "ego": 338, "default_interaction_typ": [339, 341, 627], "interaction_typ": [339, 341], "set_interaction_typ": [339, 341], "compositedistribut": [339, 341, 345, 364, 627], "distribution_map": [339, 341], "name_map": [339, 341], "distribution_kwarg": [339, 341, 623, 636, 637], "cache_dist": [339, 341], "n_empirical_estim": [339, 341], "compound": [339, 627], "functionalmodul": 340, "functionalmodulewithbuff": 340, "td_fmodul": 340, "td_function": 340, "td_state": 340, "params_repeat": 340, "td_vmap": [340, 343], "random_sampl": [340, 341], "suppli": 341, "paliat": 341, "get_median": 341, "get_mean": 341, "sample_key_nam": 341, "_log_prob": 341, "composite_lp_aggreg": 341, "induc": 341, "clampbackward0": 341, "anihil": 341, "probabilistictensordictsequenti": [342, 345, 347, 361, 364, 366, 552, 553, 642], "partial_toler": [342, 343, 635], "AND": [342, 343, 348], "tensordictsequ": 343, "safeprobabilisticmodul": 343, "spec1": 343, "net1": 343, "module1": 343, "td_module1": 343, "spec2": 343, "module2": 343, "td_module2": 343, "9944": 344, "9991": 344, "3020": 344, "2299": 344, "5418": 344, "2989": 344, "6849": 344, "2690": 344, "9649": 344, "5686": 344, "8602": 344, "0315": 344, "8455": 344, "6027": 344, "4746": 344, "7843": 344, "7782": 344, "2111": 344, "5115": 344, "4687": 344, "5760": 344, "a2c": 345, "1602": 345, "01783v2": 345, "entropy_bonu": [345, 347, 361, 364, 375, 469, 623], "favour": [345, 347, 361, 364, 375], "samples_mc_entropi": [345, 347, 361, 363, 364, 375, 469], "entropy_coeff": [345, 347, 361, 364, 375, 469], "critic_coeff": [345, 347, 361, 364, 469], "loss_critic_typ": [345, 347, 361, 364, 366, 469, 623], "l1": [345, 347, 349, 350, 354, 361, 364, 365, 366, 368, 369, 621], "l2": [345, 347, 349, 350, 351, 352, 354, 357, 358, 361, 364, 365, 366, 368, 369, 621, 636], "smooth_l1": [345, 346, 347, 348, 349, 350, 353, 354, 360, 361, 364, 365, 366, 367, 368, 369, 469, 623], "separate_loss": [345, 347, 348, 349, 353, 354, 360, 361, 364, 365, 366, 367, 368, 369, 469], "advantage_kei": [345, 347, 361, 364, 366, 375, 378, 381, 382, 383, 384, 469], "value_target_kei": [345, 347, 361, 364, 366, 381, 382, 383, 384, 469], "value_target": [345, 347, 361, 364, 366, 381, 382, 383, 384, 623, 637], "ddp": [345, 347, 361, 364, 366], "fsdp": [345, 347, 361, 364, 366], "divid": [345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 375, 550, 621, 636, 637, 638], "clip_valu": [345, 347, 361, 364, 366, 375, 469], "loss_crit": [345, 364, 623, 637], "loss_entropi": [345, 364, 372, 374, 376, 377, 623, 637], "loss_object": [345, 364, 372, 374, 376, 377, 623, 637], "recur": [345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 381, 382, 383, 384, 385, 627], "next_reward": [345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 381, 382, 383, 384], "next_don": [345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 381, 382, 383, 384], "next_termin": [345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 381, 382, 383, 384], "loss_obj": 345, "next_observ": [345, 346, 348, 349, 350, 352, 353, 354, 360, 364, 365, 366, 367, 368, 369, 635], "sacloss": [345, 409, 415, 607], "default_kei": [345, 346, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 363, 364, 365, 366, 367, 368, 369, 379, 385], "_acceptedkei": [345, 346, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 362, 363, 364, 365, 366, 367, 368, 369, 373, 375, 379, 385], "make_value_estim": [345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 370, 373, 375, 379, 621, 622, 636, 637, 642], "value_typ": [345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 373, 375, 379, 621], "hyperparam": [345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 373, 375, 379, 621], "enum": [345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 373, 375, 379, 621], "default_value_estim": [345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 373, 375, 379, 621, 642], "default_value_kwarg": [345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 373, 375, 379, 621], "dqn_loss": [345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 370, 373, 375, 379], "td1": [345, 346, 348, 349, 350, 352, 354, 355, 356, 360, 362, 364, 365, 366, 367, 368, 369, 373, 375, 379, 621], "cql": [346, 352], "conserv": [346, 352], "qvalue_network": [346, 348, 353, 354, 360, 365, 367, 368, 369, 409, 415], "unti": [346, 348, 360, 365, 367, 368, 369], "loss_funct": [346, 348, 349, 350, 351, 352, 353, 354, 360, 365, 367, 368, 369, 379, 621, 636], "alpha_init": [346, 348, 354, 363, 365, 367], "min_alpha": [346, 348, 354, 363, 365, 367], "max_alpha": [346, 348, 354, 363, 365, 367], "fixed_alpha": [346, 348, 354, 363, 365, 367], "target_entropi": [346, 348, 354, 363, 365, 367], "prod": [346, 348, 363, 367], "delay_actor": [346, 349, 367, 368, 369], "delay_qvalu": [346, 354, 365, 367, 368, 369], "min_q_weight": 346, "max_q_backup": 346, "backup": 346, "deterministic_backup": 346, "num_random": 346, "with_lagrang": 346, "lagrang": 346, "lagrange_thresh": 346, "deactivate_vmap": [346, 348, 354, 360, 365, 367, 368, 369, 381, 382, 383, 384], "valueclass": [346, 348, 349, 354, 365, 367, 368, 369], "qvalu": [346, 348, 353, 354, 360, 365, 367, 368, 369], "loss_actor": [346, 348, 349, 353, 354, 360, 365, 366, 367, 368, 369, 405, 621, 636], "loss_actor_bc": 346, "loss_alpha": [346, 348, 354, 365, 367], "loss_cql": [346, 352], "loss_qvalu": [346, 348, 352, 353, 354, 360, 365, 367, 368, 369], "loss_alpha_prim": 346, "ess": [347, 364, 372, 374, 375, 376, 377], "coupl": [347, 364, 586, 624, 627, 628, 638, 640], "clip_epsilon": [347, 375, 623, 637], "head_nam": [347, 361, 364], "ppo_entropy_coeffici": [347, 361, 364], "normalize_advantag": [347, 361, 364, 469, 637], "normalize_advantage_exclude_dim": [347, 361, 364, 469], "multiobject": [347, 361, 364], "value_kei": [347, 361, 364, 381, 382, 383, 384, 469, 621], "somemodul": [347, 361, 364], "actor_head": [347, 361, 364], "someactor": [347, 361, 364], "value_head": [347, 361, 364], "somevalu": [347, 361, 364], "crossq": 348, "IN": 348, "FOR": 348, "simplic": [348, 622, 623, 629, 639, 640, 642], "openreview": [348, 365], "pczqttstix": 348, "qvalue_loss": [348, 354, 367, 368], "actor_loss": [348, 354, 367, 368], "alpha_loss": [348, 354, 367], "num_qvalue_net": [348, 353, 354, 360, 365, 367, 368, 369], "maybe_init_target_entropi": 348, "fault_toler": 348, "target_entropy_buff": 348, "delay_valu": [349, 350, 352, 355, 366, 367, 622, 624, 625, 631, 636], "loss_valu": [349, 353, 360, 366, 367, 621, 623, 636, 637], "pred_valu": [349, 352, 368, 369, 621], "pred_value_max": [349, 621], "target_valu": [349, 352, 365, 368, 369, 621], "target_value_max": [349, 621], "qvalueactor": [350, 352, 622, 624], "double_dqn": 350, "06461": 350, "mult_one_hot": [350, 353, 354], "loss_val": [350, 352, 379, 607, 621, 623, 624, 625, 628, 629, 631, 636, 637, 640], "01345": 351, "distanc": [352, 361, 381, 637], "dcql_loss": 352, "iql": [353, 360, 621, 636, 637], "2110": [353, 360], "06169": [353, 360], "expectil": [353, 360], "tau": [353, 360, 621, 622, 636], "antmaz": [353, 360], "sticht": [353, 360], "onehotcategor": [353, 354, 600], "target_entropy_weight": 354, "skip_done_st": [354, 367], "maxim": [354, 367, 536, 537, 538, 540, 546, 547, 548, 621, 628, 638], "disctount": 355, "distributionalqvalueactor": 355, "input_tensordict": [355, 621], "actor_model": 356, "imagination_horizon": 356, "unrol": 356, "discount_loss": [356, 358], "lambda_kl": 357, "lambda_reco": 357, "lambda_reward": 357, "reco_loss": 357, "reward_loss": 357, "free_nat": 357, "nat": 357, "delayed_clamp": 357, "global_averag": 357, "value_loss": [358, 367], "fake_data": 358, "gail": 359, "1606": 359, "03476": 359, "discriminator_network": 359, "use_grad_penalti": 359, "gp_lambda": 359, "discrimin": 359, "qvalueclass": 360, "loss_value_diff": 360, "diff": 360, "old_polici": 361, "new_polici": 361, "apart": [361, 637], "dtarg": 361, "samples_mc_kl": 361, "analyt": 361, "decrement": 361, "loss_": [362, 405, 607, 621, 628], "equip": [362, 624, 625, 627], "gh": 362, "_forward_value_estimator_kei": 362, "value_estim": [362, 373, 375, 379, 381, 382, 383, 384, 385, 621, 637], "myloss": 362, "action2": 362, "augment": [362, 593, 629, 631, 640], "set_exploration_typ": [362, 404, 623, 624, 625, 627, 636, 642], "deterministic_sampling_mod": 362, "convert_to_funct": [362, 373, 375, 379, 621], "expand_dim": [362, 373, 375, 379], "create_target_param": [362, 373, 375, 379, 621], "compare_against": [362, 373, 375, 379, 621], "isol": [362, 373, 375, 379, 396, 398, 588, 591, 625], "_param": [362, 373, 375, 379], "resampl": [362, 373, 375, 379], "_target_param": [362, 373, 375, 379], "from_stateful_net": [362, 373, 375, 379], "network_nam": [362, 373, 375, 379], "stateful_net": [362, 373, 375, 379], "get_stateful_net": [362, 373, 375, 379], "Such": [362, 373, 375, 379], "blend": [362, 373, 375, 379], "vmap_random": [362, 371, 373, 375, 379], "add_random_modul": [362, 373, 375, 379, 607], "proxim": [364, 414, 470, 623, 637], "flavor": [364, 621, 636, 637, 642], "clipppoloss": [364, 607, 623, 637], "klpenppoloss": [364, 607], "06347": 364, "log_explained_vari": [364, 469], "explain": [364, 625, 639], "explained_vari": 364, "wors": 364, "gae": [364, 414, 470, 607, 621, 623, 637], "ppo_loss": 364, "tdlambda": [364, 621], "base_lay": 364, "action_log_prob": 364, "randn_lik": 364, "kl_approx": [364, 372, 374, 376, 377], "samplelogprob": 364, "gripper": 364, "composite_entropi": 364, "0234": 364, "set_composite_lp_aggreg": [364, 637], "redq": 365, "ay8zfzm0tdd": 365, "sub_sample_len": 365, "subsampl": [365, 400], "action_log_prob_actor": 365, "state_action_value_actor": [365, 368, 369], "connectionist": 366, "william": 366, "1992": 366, "doi": 366, "1007": 366, "bf00992696": 366, "actor_net": [366, 621, 623], "1801": 367, "01290": 367, "1812": 367, "05905": 367, "minimalist": 368, "06860": 368, "policy_nois": [368, 369], "noise_clip": [368, 369], "td3_bc": 368, "bc_loss": 368, "lmbd": 368, "next_state_valu": [368, 369], "td0": [370, 621, 636], "clip_fract": [372, 374, 376, 377], "loss_kl_to_ref": [372, 374, 376, 377, 379, 380], "kl_to_ref": [372, 374, 376, 377, 380], "loss_kl_to_infer": [372, 374, 376, 377], "kl_to_infer": [372, 374, 376, 377], "asymmetr": [373, 375], "eq": [373, 375], "llmoutputtyp": [373, 375], "output_typ": [373, 375], "dapolossoutput": [373, 591], "tensor_kei": [373, 375, 381, 382, 383, 384, 385], "grpoloss": [373, 591, 593], "my_advantage_kei": [373, 375], "instabl": 375, "diagnost": 375, "masking_strategi": 375, "sft": [375, 379], "surrog": 375, "symmetr": 375, "eps_low": 375, "eps_high": 375, "dapo": [375, 591], "kl_mask_threshold": 375, "pi_theta": 375, "pi_ref": 375, "drift": 375, "token_mean": 375, "prompt_mean": 375, "kl_to_ref_coeff": [375, 379], "kl_to_inference_coeff": 375, "grpolossoutput": [375, 378, 591], "grpo_siz": 378, "hit": 378, "supervis": [379, 628, 629, 640, 643], "normalize_by_seq_length": 379, "minor_sft": 379, "minorsft": 379, "shime": 379, "xie": 379, "hong": 379, "chen": 379, "fred": 379, "yu": 379, "zey": 379, "sun": 379, "xiuyu": 379, "wu": 379, "2024": 379, "minor": [379, 636], "_chat_templ": 379, "policy_ref": 379, "txt_start": 379, "zip": [379, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "loss_sft": [379, 380], "1506": 381, "02438": 381, "exponenti": [381, 382, 383, 384, 407], "lmbda": [381, 384, 414, 621, 623, 637], "average_ga": [381, 623], "skip_exist": [381, 382, 383, 384], "get_default_devic": [381, 382, 383, 384, 385], "time_dim": [381, 383, 384], "auto_reset_env": 381, "next_valu": [381, 382, 383, 384, 385], "gradient_mod": 381, "value_error": [381, 382, 383, 384, 385], "marker": [381, 621], "trajecotri": 381, "fair": 381, "target_param": [381, 382, 383, 384, 385, 621, 637], "98": [381, 382, 383, 384], "94": [381, 384], "unpack": [381, 382, 383, 384], "aka": [382, 622, 636], "average_reward": [382, 383, 384], "tdestim": [382, 383, 385], "infti": 383, "valuefunctionbas": 385, "preproc": [386, 625, 636], "as_non_tensor": [386, 636], "render_method": 386, "pass_tensordict": 386, "syntact": 386, "sugar": 386, "relax": 386, "out_file_bas": 387, "skip_reset": 387, "center_crop": 388, "make_grid": 388, "log_video": 388, "csv": [388, 390, 392, 457, 622, 630, 631], "tensorboard": [388, 392, 394, 410, 414, 459, 470, 630, 642], "log_dir": [388, 389, 390, 392, 394, 395, 457, 459, 460, 622, 631], "cheetah_video": 388, "run_video": 388, "sec": [388, 638], "video_fp": [388, 390, 393, 457, 460], "run_video_0": 388, "cur_dir": 390, "csv_log": 390, "add_video": 390, "video_": 390, "experiment_nam": [391, 392], "logger_typ": 392, "logger_nam": 392, "mlflow": [392, 393], "wandb_kwarg": 392, "mlflow_kwarg": 392, "tracking_uri": 393, "uri": 393, "datastor": 393, "tb_log": [394, 459], "tensoarboard": 394, "td_log": 394, "save_dir": [395, 460], "resum": 395, "uncategor": 395, "torchrl_servic": [396, 398], "discoveri": 396, "instantli": 396, "tokenizerclass": [396, 398], "modelclass": 396, "tok": 396, "service_factori": [396, 397, 614], "max_restart": 396, "register_with_opt": [396, 614], "actor_opt": [396, 614], "constructor_kwarg": 396, "readabl": 396, "concern": [396, 581, 593, 628], "model_path": 396, "ongo": [396, 397], "destruct": [396, 397], "init_kwarg": 398, "servicebas": [398, 614], "unsupport": [398, 575], "my_funct": 399, "sub_traj_len": 400, "min_sub_traj_len": 400, "register_op": [400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 411, 413, 622], "process_optim_batch": [400, 406, 407], "td_out": [400, 408], "_process_optim_batch_hook": 400, "batch_subsampl": 400, "clear_cuda": 401, "pre_optim_step": 401, "log_pbar": [402, 403, 404, 407, 622], "count_fram": 402, "pre_steps_log": [402, 403], "count_frames_log": 402, "lognam": 403, "include_std": 403, "log_reward": [403, 414, 415, 622], "r_train": 403, "log_action_norm": 403, "action_norm": 403, "percentag": 403, "log_don": 403, "done_percentag": 403, "record_interv": [404, 621, 622], "record_fram": [404, 550, 621, 622], "policy_explor": [404, 557, 621, 622, 625, 627, 631], "log_kei": [404, 622], "underestim": 404, "r_evalu": [404, 621], "loss_compon": 405, "appl": 405, "optimizer_hook": 405, "flatten_tensordict": [406, 622], "max_dim": 406, "rb_trainer": 406, "batch_process": [406, 407, 408], "post_loss": 406, "999": [407, 539, 540, 541, 544, 545, 549, 622], "jitter": 407, "finfo": 407, "default_dtyp": 407, "update_reward_stat": 407, "normalize_reward": 407, "make_train": 408, "_process_batch_hook": 408, "select_kei": 408, "target_params_updat": 409, "targetnetupdat": [409, 415, 554, 556, 557], "target_net_updat": [409, 415, 557, 621, 622], "softupd": [409, 621, 622, 624, 625, 628, 631, 636], "target_net_updater_hook": 409, "post_optim": [409, 622], "versatil": [410, 626], "optim_steps_per_batch": [410, 414, 415, 470, 622], "clip_grad_norm": [410, 414, 415, 470], "clip_norm": [410, 414, 415, 470], "progress_bar": [410, 414, 415, 470], "save_trainer_interv": [410, 414, 415, 470], "log_interv": [410, 414, 415, 470, 622], "save_trainer_fil": [410, 414, 415, 470], "async_collect": [410, 412, 414, 470], "utd": [410, 412, 621, 624], "utd_ratio": 410, "log_tim": [410, 414, 470], "logtim": [410, 414], "updateweight": [410, 414, 470, 615, 622], "load_from_fil": [410, 414, 415], "update_count": 412, "utdr_hook": 412, "update_weights_interv": [413, 622], "policy_weights_gett": 413, "weight_update_map": [413, 414, 470], "post_step": [413, 622], "num_epoch": [414, 470, 623, 637], "enable_log": [414, 415], "log_act": [414, 415], "log_observ": [414, 415], "add_ga": [414, 470], "ppotrainerconfig": 414, "welcom": [414, 593, 626], "elsewher": 415, "3e": [415, 623, 624, 636, 637], "configbas": [416, 418, 419, 420], "asyncdatacollector": 416, "storageensemblewrit": 434, "batched_env_typ": 437, "make_batched_env": 437, "make_gym_env": 443, "mogymenv": 447, "meltingpotenv": 448, "openmlenv": 450, "openspielenv": 451, "pettingzooenv": [452, 636], "robohiveenv": 453, "smacv2env": 454, "unity_mlag": 455, "unitymlagentsenv": 455, "activationconfig": [461, 462], "normconfig": 461, "aggregatorconfig": 461, "layerconfig": 462, "valuemodelconfig": 463, "mlpconfig": [465, 466, 467], "eval_mod": 465, "extract_normal_param": 465, "param_kei": 465, "_make_tanh_normal_model": 465, "_make_tensordict_modul": 466, "_make_value_model": 467, "networkconfig": 467, "loss_typ": [468, 469], "_make_ppo_loss": 469, "_make_ppo_train": 470, "sensibl": 470, "batchsizetransform": [475, 625], "binarizereward": 476, "burnintransform": 477, "centercrop": 480, "cliptransform": 481, "conditionalpolicyswitch": 483, "dtypecasttransform": 486, "devicecasttransform": 487, "discreteactionproject": 488, "gym_transform": 490, "endoflifetransform": 490, "exclude_kei": 491, "finitetensordictcheck": 492, "flattenobserv": 493, "frameskiptransform": 494, "linearisereward": 499, "multiact": 500, "rb_transform": 501, "multisteptransform": 501, "noopresetenv": [502, 642, 643], "permutetransform": 504, "pinmemorytransform": 505, "r3mtransform": [506, 639], "crop_siz": 507, "randomcroptensordict": [507, 621], "key_map": 509, "reward2gotransform": 511, "include_kei": 515, "signtransform": 516, "squeezetransform": 517, "targetreturn": 520, "primer_spec": 521, "timemaxpool": 522, "vc1transform": 530, "viprewardtransform": 531, "viptransform": 532, "lambd": 536, "t0": [536, 625, 631], "weight_decai": [536, 537, 538, 539, 540, 541, 543, 544, 545, 546, 548, 621, 622], "foreach": [536, 537, 538, 540, 544, 546, 547, 548], "asgd": 536, "rho": 537, "adadelta": 537, "lr_decai": 538, "initial_accumulator_valu": 538, "adagrad": 538, "amsgrad": [539, 540], "fuse": 540, "adamw": 540, "002": [541, 544], "adamax": 541, "max_it": 542, "max_ev": 542, "tolerance_grad": 542, "07": 542, "tolerance_chang": 542, "09": 542, "history_s": 542, "line_search_fn": 542, "lbfg": 542, "lion": 543, "momentum_decai": 544, "004": 544, "nadam": 544, "radam": 545, "momentum": [546, 548], "rmsprop": 546, "eta": 547, "step_siz": 547, "rprop": 547, "dampen": 548, "nesterov": 548, "sgd": 548, "sparseadam": 549, "dictconfig": [550, 551, 552, 553, 555, 556, 557, 558, 561], "unknowingli": 550, "annealing_fram": [550, 621], "init_env_step": [550, 551, 621], "proof_environ": [551, 621], "sta": 551, "ot": 551, "actor_model_explor": [552, 553, 621], "make_env_kwarg": [552, 553], "replayargsconfig": 555, "constitu": 557, "egreedywrapp": 557, "ddpgloss": [557, 607, 621, 628, 636, 642], "env_proof": 557, "obs_spec": 557, "net_valu": 557, "dir": [557, 622], "gettempdir": 557, "transformed_env_constructor": 558, "num_env_per_collector": [559, 560], "video_tag": 561, "norm_obs_onli": 561, "custom_env_mak": 561, "custom_env": 561, "return_transformed_env": 561, "action_dim_gsd": 561, "state_dim_gsd": 561, "obs_norm_state_dict": 561, "ONE": [562, 567, 573, 578, 579, 580], "recv": [562, 563], "check_connect": [562, 567, 569, 573, 575, 577, 581, 583], "receive_weight": [562, 564, 567, 569, 573, 575, 577, 581, 583], "tcpstore": 562, "acknowledg": [562, 564, 569, 572, 575, 579, 585, 587], "send_ack": [562, 564, 569, 575], "send_weight": [562, 564, 567, 569, 573, 575, 577, 581, 583], "send_weights_async": [562, 564, 567, 569, 573], "wait_ack": [562, 564, 567, 569, 573], "create_receiv": [563, 565, 566, 568, 571, 574, 576, 580, 582, 584, 588], "weightreceiv": [563, 565, 566, 568, 571, 574, 576, 580, 582, 588], "create_send": [563, 565, 566, 568, 571, 574, 576, 580, 582, 585, 588], "weightsend": [563, 565, 566, 568, 571, 572, 574, 576, 580, 582, 588], "create_transport": [563, 565, 566, 568, 571, 574, 576, 580, 582, 588], "pipe_or_context": [563, 566, 568, 571, 574, 576, 580, 582, 588], "transportbackend": [563, 565, 566, 568, 571, 574, 576, 580], "distributedtransport": 563, "_run_process": [563, 568, 580, 582, 588], "cached_weight": [563, 568, 576, 580, 582, 588], "prepare_weight": [563, 565, 566, 568, 571, 574, 576, 580, 582, 588], "weightstrategi": [563, 565, 566, 568, 571, 574, 576, 580, 582, 588, 589], "lookup": [563, 565, 566, 568, 571, 574, 576, 580, 582, 588, 622], "pipe_connect": 564, "check_ack": [564, 569, 575], "mptransport": 565, "rpctransport": 568, "actor_ref": [569, 571], "update_method": 569, "tensor_transport": [569, 573], "object_stor": [569, 573], "nixl": [569, 573], "raymoduletransform": [569, 570, 571, 572], "set_actor": 569, "raymoduletransformschem": [570, 572], "apply_weight": [570, 578, 584, 586], "transmiss": [571, 576], "raymoduletransformreceiv": 571, "raymoduletransformsend": 571, "rayactortransport": 571, "source_model": [571, 574], "raytransport": 574, "pure": 575, "hybrid": 575, "chicken": 575, "egg": 575, "register_weight": 575, "register_pip": 575, "weightupdat": 576, "register_shared_weight": 576, "shared_weight": 576, "deadlock": 576, "aliv": [577, 622], "gpus_per_replica": [581, 588, 593], "init_all_workers_group": [581, 586, 587, 588, 593], "mono": 581, "remote_addr": [582, 583], "local_addr": [582, 583], "tmp": 582, "mnt": 582, "nf": 582, "mount": 582, "vllmdoublebufferweightreceiv": [582, 591], "llm_engin": 582, "model_executor": 582, "vllmdoublebufferweightsend": [582, 591], "vllmdoublebuffertransport": [582, 591], "vllmdoublebuffersyncschem": [584, 585, 591, 593], "load_weight": 584, "poll": [584, 586], "poll_and_appli": [584, 586], "_update_weights_with_nccl_broadcast_simpl": 584, "180": 584, "register_model": [585, 587, 588, 593], "vllmweightsyncschem": [586, 587, 591, 593], "get_actor": 586, "particip": [586, 588], "torchrpcvllmreceiv": 586, "rpc_sync": 586, "get_metadata": 586, "grpc": 587, "vllmcollectivetransport": [587, 588, 591], "bandwidth": 587, "torchrpcvllmsend": 587, "rpc_async": 587, "prepare_rec": 587, "tp_size": 588, "dp_size": 588, "pp_size": 588, "approxim": [588, 637, 643], "handshak": 588, "12345": 588, "vllmweightsend": [588, 591], "vllmweightreceiv": [588, 591], "init_send": 588, "sender_actor": 588, "init_receiv": 588, "receiver_actor": 588, "extract_weight": 589, "llmlossoutput": 591, "cispolossoutput": 591, "mcadvantag": 591, "sftloss": [591, 593], "sftlossoutput": 591, "topkrewardselector": 591, "sweep": 591, "journei": 592, "textbook": 592, "highlight": [592, 636], "ever": [592, 637], "bump": 592, "pr": [592, 593], "five": [593, 622], "make_polici": 593, "29500": 593, "_weight_send": 593, "training_model": 593, "policy_version_track": 593, "migrat": 593, "orchestr": [593, 596, 622, 628, 630], "ref_servic": 593, "step_data": 593, "gsm8krewardpars": 593, "ifevalscor": 593, "excel": 593, "bsz": 593, "num_token": 593, "predetermin": 593, "hasattr": [593, 621], "text_complet": 593, "sophist": [593, 623, 637], "format_compon": 593, "structure_scor": 593, "think_scor": 593, "answer_scor": 593, "completion_bonu": 593, "potential_answ": 593, "compl": 593, "et": 593, "parseerror": 593, "unnecessari": 593, "characterist": [593, 621, 638], "llms_env": 593, "llms_transform": 593, "llms_collector": 593, "llms_object": 593, "571142f4e": 593, "refactor": 593, "\u03b5": 600, "satisfi": 600, "additivegaussianmodul": [600, 627, 636], "consistentdropoutmodul": 600, "egreedymodul": [600, 622, 624, 625, 627, 631], "ornsteinuhlenbeckprocessmodul": [600, 621, 627], "duelingcnndqnet": [600, 622], "ddpgcnnactor": 600, "ddpgcnnqnet": 600, "ddpgmlpactor": [600, 621], "ddpgmlpqnet": [600, 621], "onlinedtactor": 600, "dtactor": 600, "dreameractor": 600, "obsencod": 600, "obsdecod": 600, "rssmposterior": 600, "rssmprior": 600, "rssmrollout": 600, "independentnorm": 600, "tanhdelta": [600, 621, 636], "truncatednorm": 600, "reusabl": [607, 621, 640], "trainabl": [607, 621, 628, 639], "\u03bb": 607, "customiz": [607, 624], "total_loss": [607, 628], "distributionaldqnloss": [607, 622], "iqlloss": 607, "discreteiqlloss": 607, "cqlloss": 607, "discretecqlloss": 607, "ppoloss": 607, "a2closs": 607, "reinforceloss": 607, "discretesacloss": 607, "td3loss": 607, "redqloss": 607, "crossqloss": 607, "td3bcloss": 607, "gailloss": 607, "dtloss": 607, "onlinedtloss": 607, "dreameractorloss": 607, "dreamermodelloss": 607, "dreamervalueloss": 607, "agnost": [614, 633], "monarch": 614, "anywher": 614, "tenant": 614, "my_namespac": 614, "tokenizerservic": 614, "50000": 614, "my_servic": 614, "myserviceclass": 614, "arg1": 614, "value1": 614, "arg2": 614, "value2": 614, "gpu_servic": 614, "gpuservic": 614, "collid": [614, 625, 637], "register_servic": 614, "shared_token": 614, "use_servic": 614, "worker2": 614, "train_servic": 614, "eval_servic": 614, "30000": 614, "busi": 614, "infrequ": 614, "use_distributed_servic": 614, "queu": 614, "persistentpythonprocess": 614, "_lock": 614, "next_idx": 614, "temp": 614, "python_executor_fast": 614, "python_executor_heavi": 614, "fast_env": 614, "heavy_env": 614, "mycustomservic": 614, "param1": 614, "tokenizer_servic": 614, "servicecontext": 614, "__enter__": 614, "__exit__": 614, "myservic": 614, "stick": [614, 625], "distributed_servic": 614, "python_executor_servic": 614, "test_servic": 614, "test_python_executor_servic": 614, "ref_llm": [614, 633], "torchsnapshot": 615, "logscalar": [615, 622], "mlflowlogg": 615, "get_logg": 615, "generate_exp_nam": 615, "batchsubsampl": 615, "clearcudacach": 615, "countframeslog": 615, "optimizerhook": [615, 622], "logvalidationreward": [615, 621, 622], "replaybuffertrain": [615, 622], "rewardnorm": 615, "selectkei": 615, "targetnetupdaterhook": 615, "utdrhook": 615, "000": [620, 624, 641], "galleri": [620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "mem": [620, 641], "mb": [620, 641], "coding_ddpg": [620, 621, 641], "coding_dqn": [620, 622, 641], "coding_ppo": [620, 623, 641], "dqn_with_rnn": [620, 624, 641], "llm_browser": [620, 633, 641], "llm_wrapper": [620, 634, 641], "multi_task": [620, 635, 641], "multiagent_competitive_ddpg": [620, 636, 641], "multiagent_ppo": [620, 637, 641], "pretrained_model": [620, 639, 641], "rb_tutori": [620, 640, 641], "torchrl_demo": [620, 641, 642], "torchrl_env": [620, 641, 643], "author": [621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 636, 637, 638, 640, 643], "vincent": [621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 638, 640, 643], "moen": [621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 638, 640, 643], "assembl": 621, "ground": [621, 638], "transpar": [621, 624], "bash": 621, "is_fork": [621, 622, 623, 624, 636, 637, 639], "get_start_method": [621, 622, 623, 624, 636, 637, 639], "collector_devic": 621, "swappabl": 621, "smth": 621, "loss_dict": 621, "oblivi": [621, 623, 640], "elementari": 621, "didact": [621, 625], "dilut": 621, "pessimist": [621, 622, 623], "target_actor_network_param": 621, "actor_in_kei": 621, "actor_crit": 621, "compromis": 621, "td0estim": 621, "td1estim": 621, "tdlambdaestim": 621, "hp": 621, "_value_estim": 621, "hold_out_param": 621, "_loss_actor": 621, "td_copi": 621, "actor_network_param": [621, 636], "value_network_param": [621, 636], "distance_loss": 621, "_loss_valu": 621, "pred_val": 621, "target_value_network_param": 621, "smooth": [621, 622, 628], "pow": 621, "glue": 621, "_forward": 621, "remaind": 621, "env_librari": 621, "env_task": 621, "env_arg": [621, 622], "torchr": 621, "rescal": 621, "presum": 621, "make_transformed_env": 621, "reward_sc": 621, "parallel_env_constructor": 621, "env_per_collector": 621, "transform_state_dict": 621, "make_t_env": 621, "seem": [621, 624, 626], "cheat": 621, "10m": 621, "nutshel": 621, "cautiou": 621, "thousand": [621, 624], "get_env_stat": 621, "proof_env": 621, "5000": [621, 625, 631], "recal": [621, 623, 633, 640], "materi": 621, "make_ddpg_actor": 621, "q_net": 621, "qnet": 621, "suggest": [621, 637], "tight": 621, "10_000": [621, 623], "traj_len": [621, 624], "make_record": 621, "recorder_obj": 621, "pick": [621, 622, 627, 633], "make_replay_buff": 621, "buffer_s": [621, 622, 624], "random_crop_len": 621, "prb": 621, "buffer_scratch_dir": [621, 622, 624, 629, 639], "dataflow": 621, "ceil_div": 621, "update_to_data": 621, "realiz": 621, "ve": [621, 624, 631, 633], "_must_": 621, "outdat": 621, "trick": [621, 622], "despit": 621, "hardupd": [621, 628], "optimizer_actor": 621, "optimizer_valu": 621, "total_collection_step": 621, "rewards_ev": 621, "collected_fram": 621, "r0": 621, "numel": [621, 623, 625, 631, 636, 639, 640], "current_fram": [621, 636], "sampled_tensordict": 621, "gn1": 621, "clip_grad_norm_": [621, 623, 636, 637, 638], "gn2": 621, "gn": [621, 638], "td_record": 621, "rn": 621, "2f": 621, "plot": [621, 623, 624, 636, 637, 638], "mention": [621, 624, 640, 643], "matplotlib": [621, 623, 624, 625, 636, 637, 638, 640, 643], "pyplot": [621, 623, 624, 625, 636, 637, 638, 640, 643], "plt": [621, 623, 624, 625, 636, 637, 638, 640, 643], "legend": [621, 636], "xlabel": [621, 624, 637, 638], "ylabel": [621, 637], "tight_layout": 621, "concret": [621, 623, 633], "takeawai": [621, 622, 625, 633], "distpatch": 621, "jupyt": [621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "ipynb": [621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "sphinx": [621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 642, 643], "road": 622, "aspect": [622, 628], "highest": [622, 627], "prerequisit": [622, 624, 633], "amort": [622, 623], "cart": 622, "pole": 622, "un": 622, "actuat": 622, "frictionless": 622, "is_notebook": 622, "shell": 622, "get_ipython": 622, "__class__": [622, 634], "zmqinteractiveshel": 622, "qtconsol": 622, "terminalinteractiveshel": 622, "ipython": [622, 637, 638], "nameerror": [622, 634, 636], "umbrella": 622, "misplac": 622, "misus": 622, "64x64": 622, "motion": [622, 638], "obs_norm_sd": 622, "mp_context": 622, "get_norm_stat": 622, "test_env": 622, "mathbb": 622, "rightarrow": 622, "make_model": 622, "dummy_env": 622, "init_bia": 622, "exploration_modul": [622, 624, 625, 627, 631], "eps_greedy_v": 622, "eps_greedy_val_env": 622, "actor_explor": 622, "get_replay_buff": 622, "n_optim": [622, 628, 629], "parametriz": 622, "get_collector": 622, "bunch": 622, "ubiquit": [622, 626], "get_loss_modul": 622, "target_updat": [622, 636], "995": 622, "hopefulli": 622, "sensit": [622, 624], "variat": 622, "2e": [622, 638], "wd": 622, "upd": 622, "harder": [622, 642], "5_000": 622, "500000": 622, "005": [622, 636], "mandatori": [622, 623, 637, 638], "fairer": 622, "budget": 622, "dqn_exp_": 622, "uuid1": [622, 643], "cumbersom": 622, "buffer_hook": 622, "trainerhookbas": 622, "total_reward": 622, "ti": 622, "print_csv_files_in_fold": 622, "folder_path": 622, "csv_file": 622, "output_str": 622, "dirpath": 622, "endswith": 622, "qvaluenetwork": 622, "worst": 622, "accuraci": 622, "fanci": [622, 629], "talk": 623, "six": 623, "invent": 623, "wheel": 623, "theta_k": 623, "pi_": 623, "exceed": 623, "indispens": 623, "loader": 623, "analyz": 623, "lingua": 623, "franca": 623, "defaultdict": [623, 638], "max_grad_norm": [623, 636, 637], "sub_batch_s": 623, "95": [623, 624], "entropy_ep": [623, 637], "inverteddoublependulum": 623, "transmit": 623, "stai": 623, "told": 623, "confid": [623, 636, 637], "ran": 623, "f_": 623, "mu_": 623, "difficulti": [623, 643], "brought": [623, 624, 627], "d_ob": 623, "d_action": 623, "policy_modul": [623, 636, 637], "said": 623, "value_modul": [623, 642], "briefli": [623, 636, 637], "refil": [623, 637], "easiest": [623, 628, 636, 637], "hide": [623, 636, 637], "mathemat": [623, 636, 637], "tradeoff": [623, 637], "advantage_modul": 623, "entropy_coef": [623, 637], "critic_coef": 623, "lr_schedul": [623, 638], "cosineannealinglr": [623, 638], "eval_str": 623, "tensordict_data": [623, 637], "data_view": [623, 637], "subdata": [623, 636, 637], "cum_reward_str": 623, "stepcount_str": 623, "param_group": [623, 636], "lr_str": 623, "eval_rollout": 623, "figsiz": [623, 638], "subplot": [623, 636, 638, 643], "84x84": [624, 625], "accessori": 624, "stamp": 624, "backbon": [624, 627, 635, 642], "emb": 624, "n_cell": 624, "bidirect": 624, "wouldn": 624, "qval": 624, "stoch_polici": 624, "opportun": [624, 636], "uniniti": 624, "again": [624, 625, 626, 627, 629, 637, 639, 640, 643], "strongli": 624, "sake": [624, 639, 640], "longest": 624, "enough": [624, 640], "strong": 625, "impress": 625, "edg": 625, "arduino": 625, "raspberri": 625, "alon": 625, "examplifi": 625, "ship": 625, "nearest": 625, "value_mlp": [625, 631], "init_rand_step": [625, 631], "total_count": [625, 631], "total_episod": [625, 631], "screen": [625, 636], "color": [625, 636], "clearer": [625, 627], "unblock": 625, "policy_transform": 625, "fake_td": 625, "exported_polici": 625, "div": 625, "graph_modul": 625, "print_read": 625, "group0": 625, "group0_agent0_ob": 625, "group0_agent0": 625, "agent0_ob": 625, "obvious": 625, "digress": 625, "exported_stochastic_polici": 625, "trace": 625, "hidden0": 625, "hidden1": 625, "recurrent_polici": 625, "happi": 625, "fake_ob": 625, "fake_hidden0": 625, "fake_hidden1": 625, "fake_is_init": 625, "exported_recurrent_polici": 625, "platform": [625, 642], "aoti": 625, "_inductor": 625, "aoti_compile_and_packag": 625, "aoti_load_packag": 625, "pt2": 625, "pkg_path": 625, "package_path": 625, "compiled_modul": 625, "onnxruntim": 625, "showcas": [625, 638], "plenti": 625, "tensorrt": 625, "android": 625, "aleinterfac": 625, "rom": [625, 643], "loadrom": 625, "reset_gam": 625, "screen_ob": 625, "getscreenrgb": 625, "tick_param": 625, "bottom": 625, "labelleft": 625, "labelbottom": 625, "imshow": [625, 643], "dynamo_export": 625, "as_tensor": 625, "onnx_policy_export": 625, "onnx_file_path": 625, "ort_sess": 625, "inferencesess": 625, "cpuexecutionprovid": 625, "onnxruntime_input": 625, "get_input": 625, "onnx_polici": 625, "f811": 625, "onnxruntime_output": 625, "num_step": 625, "topic": [626, 627, 628], "straight": 626, "backtrack": 626, "reset_with_act": 626, "stepped_data": 626, "spatial": 626, "useless": 626, "policyless": 626, "glanc": 626, "appreci": 626, "examin": [626, 636], "tackl": 627, "intric": 627, "delv": 627, "extractor": 627, "analog": 627, "realm": 627, "exploration_polici": [627, 636], "2d": [627, 636, 637], "innov": [627, 628], "rollout_explor": 627, "sole": 628, "n_collect": 628, "get_next_batch": 628, "ddpg_loss": 628, "prove": 628, "reliev": 628, "accustom": 629, "surprisingli": 629, "matter": 629, "art": [629, 636, 637], "pseudo": [629, 638], "countless": 629, "yourself": [629, 636, 637], "chapter": 630, "everywher": 630, "log_scalar": 630, "my_scalar": 630, "excess": 630, "lesson": 631, "voluntarili": 631, "training_loop": 631, "video_record": 631, "arbitrarili": 631, "num": 631, "t1": 631, "conclud": [631, 639], "tutorials_python": 632, "tutorials_jupyt": 632, "playwright": 633, "autom": 633, "__future__": 633, "browsertransform": 633, "filterwarn": [633, 634], "browser_transform": 633, "rewardtransform": 633, "last_item": 633, "execute_tool_act": 633, "current_st": 633, "nllm": 633, "nenviron": 633, "button": 633, "css": 633, "btnk": 633, "extract_typ": 633, "suppress": 634, "vllm_use_v1": 634, "5b": 634, "canada": 634, "vllm_wrapper": 634, "return_text": 634, "return_token": 634, "return_mask": 634, "data_histori": 634, "nload": 634, "transformers_token": 634, "transformers_wrapp": 634, "result_tf": 634, "data_text": 634, "vllm_text_wrapp": 634, "result_vllm_text": 634, "nvllm": 634, "transformers_text_wrapp": 634, "result_tf_text": 634, "vllm_logprobs_wrapp": 634, "result_vllm_lp": 634, "transformers_logprobs_wrapp": 634, "result_tf_lp": 634, "ntensorclass": 634, "analysi": 634, "ntext": 634, "__annotations__": 634, "ntoken": 634, "nlogprob": 634, "nmask": 634, "nerror": 634, "invalid_mod": 634, "nrl": 634, "env_stat": 634, "action_output": 634, "60": [634, 642], "env1_obs_kei": 635, "observation_stand": 635, "env2_obs_kei": 635, "observation_walk": 635, "tdreset1": 635, "tdreset2": 635, "policy_common": 635, "policy_stand": 635, "policy_walk": 635, "env1_mak": 635, "env2_mak": 635, "_single_task": 635, "td_rollout": 635, "matteo": [636, 637], "bettini": [636, 637], "benchmarl": [636, 637], "simple_tag": 636, "maddpg": [636, 637], "multiagentparticleenviron": 636, "mpe": 636, "centralis": [636, 637], "tie": [636, 637], "iddpg": [636, 637], "optimis": [636, 637], "sutton": [636, 637], "richard": 636, "andrew": 636, "barto": [636, 637], "mit": 636, "press": 636, "2018": 636, "mathbf": [636, 637], "decentralis": [636, 637], "literatur": [636, 637], "overcom": [636, 637], "stationari": [636, 637], "establish": 636, "gui": [636, 637], "multiagentmlp": [636, 637], "is_sphinx": 636, "__sphinx_build__": 636, "n_iter": [636, 637, 638], "evad": 636, "iteration_when_stop_training_evad": 636, "memory_s": 636, "n_optimiser_step": 636, "train_batch_s": 636, "polyak_tau": 636, "furthermor": [636, 637], "chaser": 636, "red": 636, "circl": [636, 637], "touch": [636, 638], "penal": [636, 637], "obstacl": 636, "drag": [636, 637], "elast": [636, 637], "collis": [636, 637], "Their": [636, 637], "imped": 636, "n_chaser": 636, "n_evad": 636, "n_obstacl": 636, "use_vma": 636, "simple_tag_v3": 636, "num_good": 636, "num_adversari": 636, "num_obstacl": 636, "max_cycl": 636, "num_vmas_env": [636, 637], "num_good_ag": 636, "num_landmark": 636, "n_agents_in_that_group": 636, "stress": [636, 637], "paramount": [636, 637], "n_rollout_step": [636, 637], "evolut": [636, 637], "group_nam": 636, "n_agents_in_group": 636, "signifi": [636, 637], "agents_exploration_polici": 636, "utilis": [636, 637], "homogen": [636, 637], "n_obs_per_ag": [636, 637], "n_actions_per_ag": [636, 637], "share_parameters_polici": [636, 637], "policy_net": [636, 637], "n_agent_input": [636, 637], "n_agent_output": [636, 637], "share_param": [636, 637], "_agent": 636, "grant": [636, 637], "converg": [636, 637], "share_parameters_crit": [636, 637], "obs_act": 636, "cat_modul": 636, "critic_modul": 636, "fantast": [636, 637], "reset_td": 636, "interfer": 636, "subject": [636, 638], "flatten_kei": 636, "process_batch": 636, "group_shap": 636, "get_item_shap": [636, 637], "nested_done_kei": 636, "nested_terminated_kei": 636, "desc": [636, 637], "episode_reward_mean_": 636, "episode_reward_mean_map": 636, "train_group_map": 636, "group_batch": 636, "_group": 636, "loss_nam": 636, "episode_reward_mean": [636, 637], "proce": 636, "fig": [636, 640], "set_ylabel": 636, "axvlin": 636, "orang": 636, "set_xlabel": 636, "video_logg": 636, "vmas_log": 636, "env_with_rend": 636, "vmas_rend": 636, "print_log_dir": 636, "profici": [636, 637], "qmix": [636, 637], "lidar": 637, "sensor": 637, "mappo": 637, "ippo": 637, "phase": [637, 640], "_t": [637, 638], "analys": 637, "visualis": 637, "vmas_devic": 637, "6_000": 637, "minibatch_s": 637, "generalis": 637, "simd": 637, "warp": 637, "todai": 637, "surround": 637, "dot": [637, 638], "scenario_nam": 637, "critic_net": 637, "minibatch": 637, "episode_reward_mean_list": 637, "critic_network_param": 637, "target_critic_network_param": 637, "xvfb": 637, "pyvirtualdisplai": 637, "1400": 637, "900": 637, "pil": 637, "rendering_callback": 637, "fromarrai": 637, "gif": 637, "save_al": 637, "append_imag": 637, "freeli": 638, "undertaken": 638, "broader": 638, "wider": 638, "acquaint": 638, "avenu": 638, "_apply_to_composit": 638, "default_x": 638, "default_i": 638, "upward": 638, "angular": 638, "sin": 638, "theta_t": 638, "rad": 638, "theta_": 638, "angl": 638, "new_th": 638, "new_thdot": 638, "g_forc": 638, "angle_norm": 638, "zeros_lik": 638, "albeit": 638, "high_th": 638, "high_thdot": 638, "low_th": 638, "low_thdot": 638, "trivial": 638, "irrelev": 638, "_make_spec": 638, "td_param": 638, "render_fp": 638, "random_": 638, "_make_step": 638, "staticmethod": 638, "skeleton": 638, "sine": 638, "cosin": 638, "sintransform": 638, "costransform": 638, "t_sin": 638, "t_co": 638, "cat_transform": 638, "simple_rollout": 638, "_data": 638, "unexplor": 638, "recreat": 638, "20_000": 638, "init_td": 638, "traj_return": 638, "last_reward": 638, "is_ipython": 638, "inlin": 638, "get_backend": 638, "ion": 638, "gcf": 638, "clear_output": 638, "env_transform": [639, 643], "wiser": 639, "_storag": [639, 640], "batteri": 640, "gc": 640, "filesystem": 640, "buffer_list": 640, "lowest": 640, "medium": 640, "buffer_lazytensor": 640, "tempdir": 640, "buffer_lazymemmap": 640, "fullest": 640, "mydata": 640, "buffer_lazi": 640, "_i": 640, "artifici": 640, "hamper": 640, "hist": 640, "recycl": 640, "reappear": 640, "unfold": 640, "problemat": 640, "4th": 640, "tensordictmaxvaluewrit": 640, "demo": 642, "icml": 642, "vmoen": 642, "fb": 642, "invest": 642, "media": 642, "predominantli": 642, "data2": 642, "sub_key1": 642, "scturctur": 642, "data_stack": 642, "data_sampl": 642, "_sampler": 642, "_sum_tre": 642, "modulenotfounderror": 642, "backbone_modul": 642, "actor_modul": 642, "params_expand": 642, "exec_sequ": 642, "tensordict_exp": 642, "base_modul": 642, "roughli": 642, "tensordicts_prealloc": 642, "tensordicts_stack": 642, "tensordict_rollout": [642, 643], "automatical": 642, "particularili": 642, "concatmodul": 642, "loss_td": 642, "contributor": 642, "curiou": 642, "nascent": 642, "unsupervis": 643, "licens": 643, "pygam": 643, "_build_env": 643, "deserv": 643, "__episode__": 643, "__trajectory__": 643, "void": 643, "reproduct": 643, "tensordict_tprim": 643, "inconsist": 643, "wrapper1": 643, "wrapper2": 643, "obviou": 643, "truth": 643, "env_transformed_bi": 643, "stanc": 643, "transformeddistribut": 643, "base_dist": 643, "concat": 643, "mofidi": 643, "transformedenviron": 643, "moderet": 643, "computation": 643, "incom": 643, "amongst": 643, "has_cuda": 643, "device_count": 643, "worri": 643, "convention": 643, "markovian": 643, "bar_": 643, "get_someth": 643, "aargh": 643, "is_clos": 643, "foo_list": 643, "121": 643, "evolv": 643, "steadi": 643, "approx": 643, "sd": 643, "absor": 643, "_extra_st": 643}, "objects": {"torchrl": [[31, 0, 1, "", "auto_unwrap_transformed_env"], [280, 0, 1, "", "implement_for"], [399, 0, 1, "", "set_auto_unwrap_transformed_env"]], "torchrl.collectors": [[32, 0, 1, "", "DataCollectorBase"], [33, 0, 1, "", "MultiProcessedWeightUpdater"], [34, 0, 1, "", "MultiSyncDataCollector"], [35, 0, 1, "", "MultiaSyncDataCollector"], [36, 0, 1, "", "RayWeightUpdater"], [37, 0, 1, "", "SyncDataCollector"], [38, 0, 1, "", "VanillaWeightUpdater"], [39, 0, 1, "", "WeightUpdaterBase"], [40, 0, 1, "", "aSyncDataCollector"]], "torchrl.collectors.DataCollectorBase": [[32, 1, 1, "", "async_shutdown"], [32, 1, 1, "", "init_updater"], [32, 1, 1, "", "pause"], [32, 1, 1, "", "start"], [32, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.MultiProcessedWeightUpdater": [[33, 1, 1, "", "all_worker_ids"], [33, 2, 1, "", "collector"], [33, 2, 1, "", "collectors"], [33, 1, 1, "", "from_policy"], [33, 1, 1, "", "increment_version"], [33, 1, 1, "", "init"], [33, 2, 1, "", "post_hooks"], [33, 1, 1, "", "push_weights"], [33, 1, 1, "", "register_collector"], [33, 1, 1, "", "register_post_hook"]], "torchrl.collectors.MultiSyncDataCollector": [[34, 1, 1, "", "async_shutdown"], [34, 1, 1, "", "get_cached_weights"], [34, 1, 1, "", "get_model"], [34, 1, 1, "", "get_policy_version"], [34, 1, 1, "", "getattr_env"], [34, 1, 1, "", "getattr_policy"], [34, 1, 1, "", "getattr_rb"], [34, 1, 1, "", "increment_version"], [34, 1, 1, "", "init_updater"], [34, 1, 1, "", "load_state_dict"], [34, 1, 1, "", "pause"], [34, 2, 1, "", "policy_version"], [34, 1, 1, "", "reset"], [34, 1, 1, "", "set_seed"], [34, 1, 1, "", "shutdown"], [34, 1, 1, "", "start"], [34, 1, 1, "", "state_dict"], [34, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.MultiaSyncDataCollector": [[35, 1, 1, "", "async_shutdown"], [35, 1, 1, "", "get_cached_weights"], [35, 1, 1, "", "get_model"], [35, 1, 1, "", "get_policy_version"], [35, 1, 1, "", "getattr_env"], [35, 1, 1, "", "getattr_policy"], [35, 1, 1, "", "getattr_rb"], [35, 1, 1, "", "increment_version"], [35, 1, 1, "", "init_updater"], [35, 1, 1, "", "load_state_dict"], [35, 1, 1, "", "pause"], [35, 2, 1, "", "policy_version"], [35, 1, 1, "", "reset"], [35, 1, 1, "", "set_seed"], [35, 1, 1, "", "shutdown"], [35, 1, 1, "", "start"], [35, 1, 1, "", "state_dict"], [35, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.RayWeightUpdater": [[36, 1, 1, "", "_get_server_weights"], [36, 1, 1, "", "_maybe_map_weights"], [36, 1, 1, "", "_skip_update"], [36, 1, 1, "", "_sync_weights_with_worker"], [36, 1, 1, "id0", "all_worker_ids"], [36, 2, 1, "", "collector"], [36, 2, 1, "", "collectors"], [36, 1, 1, "", "from_policy"], [36, 1, 1, "", "increment_version"], [36, 1, 1, "", "init"], [36, 2, 1, "", "post_hooks"], [36, 1, 1, "", "push_weights"], [36, 1, 1, "", "register_collector"], [36, 1, 1, "", "register_post_hook"]], "torchrl.collectors.SyncDataCollector": [[37, 1, 1, "", "async_shutdown"], [37, 1, 1, "", "get_model"], [37, 1, 1, "", "get_policy_version"], [37, 1, 1, "", "getattr_env"], [37, 1, 1, "", "getattr_policy"], [37, 1, 1, "", "getattr_rb"], [37, 1, 1, "", "increment_version"], [37, 1, 1, "", "init_updater"], [37, 1, 1, "", "iterator"], [37, 1, 1, "", "load_state_dict"], [37, 1, 1, "", "pause"], [37, 2, 1, "", "policy_version"], [37, 1, 1, "", "reset"], [37, 1, 1, "", "rollout"], [37, 1, 1, "", "set_seed"], [37, 1, 1, "", "shutdown"], [37, 1, 1, "", "start"], [37, 1, 1, "", "state_dict"], [37, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.VanillaWeightUpdater": [[38, 1, 1, "", "all_worker_ids"], [38, 2, 1, "", "collector"], [38, 2, 1, "", "collectors"], [38, 1, 1, "", "from_policy"], [38, 1, 1, "", "increment_version"], [38, 1, 1, "", "init"], [38, 2, 1, "", "post_hooks"], [38, 1, 1, "", "push_weights"], [38, 1, 1, "", "register_collector"], [38, 1, 1, "", "register_post_hook"]], "torchrl.collectors.WeightUpdaterBase": [[39, 1, 1, "", "all_worker_ids"], [39, 2, 1, "", "collector"], [39, 2, 1, "", "collectors"], [39, 1, 1, "id0", "from_policy"], [39, 1, 1, "", "increment_version"], [39, 1, 1, "", "init"], [39, 2, 1, "", "post_hooks"], [39, 1, 1, "id1", "push_weights"], [39, 1, 1, "id2", "register_collector"], [39, 1, 1, "", "register_post_hook"]], "torchrl.collectors.aSyncDataCollector": [[40, 1, 1, "", "async_shutdown"], [40, 1, 1, "", "get_cached_weights"], [40, 1, 1, "", "get_model"], [40, 1, 1, "", "get_policy_version"], [40, 1, 1, "", "getattr_env"], [40, 1, 1, "", "getattr_policy"], [40, 1, 1, "", "getattr_rb"], [40, 1, 1, "", "increment_version"], [40, 1, 1, "", "init_updater"], [40, 1, 1, "", "load_state_dict"], [40, 1, 1, "", "pause"], [40, 2, 1, "", "policy_version"], [40, 1, 1, "", "reset"], [40, 1, 1, "", "set_seed"], [40, 1, 1, "", "shutdown"], [40, 1, 1, "", "start"], [40, 1, 1, "", "state_dict"], [40, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed": [[41, 0, 1, "", "DistributedDataCollector"], [42, 0, 1, "", "DistributedSyncDataCollector"], [43, 0, 1, "", "DistributedWeightUpdater"], [44, 0, 1, "", "RPCDataCollector"], [45, 0, 1, "", "RPCWeightUpdater"], [46, 0, 1, "", "RayCollector"], [47, 0, 1, "", "submitit_delayed_launcher"]], "torchrl.collectors.distributed.DistributedDataCollector": [[41, 1, 1, "", "async_shutdown"], [41, 1, 1, "", "init_updater"], [41, 1, 1, "", "pause"], [41, 1, 1, "", "start"], [41, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed.DistributedSyncDataCollector": [[42, 1, 1, "", "async_shutdown"], [42, 1, 1, "", "init_updater"], [42, 1, 1, "", "pause"], [42, 1, 1, "", "start"], [42, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed.DistributedWeightUpdater": [[43, 1, 1, "", "_get_server_weights"], [43, 1, 1, "", "_maybe_map_weights"], [43, 1, 1, "", "_sync_weights_with_worker"], [43, 1, 1, "id0", "all_worker_ids"], [43, 2, 1, "", "collector"], [43, 2, 1, "", "collectors"], [43, 1, 1, "", "from_policy"], [43, 1, 1, "", "increment_version"], [43, 1, 1, "", "init"], [43, 2, 1, "", "post_hooks"], [43, 1, 1, "", "push_weights"], [43, 1, 1, "", "register_collector"], [43, 1, 1, "", "register_post_hook"], [43, 1, 1, "", "update_weights"]], "torchrl.collectors.distributed.RPCDataCollector": [[44, 1, 1, "", "async_shutdown"], [44, 1, 1, "", "init_updater"], [44, 1, 1, "", "pause"], [44, 1, 1, "", "start"], [44, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed.RPCWeightUpdater": [[45, 1, 1, "", "_get_server_weights"], [45, 1, 1, "", "_maybe_map_weights"], [45, 1, 1, "", "_sync_weights_with_worker"], [45, 1, 1, "id0", "all_worker_ids"], [45, 2, 1, "", "collector"], [45, 2, 1, "", "collectors"], [45, 1, 1, "", "from_policy"], [45, 1, 1, "", "increment_version"], [45, 1, 1, "", "init"], [45, 2, 1, "", "post_hooks"], [45, 1, 1, "", "push_weights"], [45, 1, 1, "", "register_collector"], [45, 1, 1, "", "register_post_hook"], [45, 1, 1, "", "update_weights"]], "torchrl.collectors.distributed.RayCollector": [[46, 1, 1, "", "add_collectors"], [46, 1, 1, "", "async_shutdown"], [46, 1, 1, "", "init_updater"], [46, 1, 1, "", "load_state_dict"], [46, 1, 1, "", "local_policy"], [46, 1, 1, "", "pause"], [46, 2, 1, "", "remote_collectors"], [46, 1, 1, "", "set_seed"], [46, 1, 1, "", "shutdown"], [46, 1, 1, "", "start"], [46, 1, 1, "", "state_dict"], [46, 1, 1, "", "stop_remote_collectors"], [46, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.llm": [[48, 0, 1, "", "LLMCollector"], [49, 0, 1, "", "RayLLMCollector"], [50, 0, 1, "", "vLLMUpdater"], [51, 0, 1, "", "vLLMUpdaterV2"]], "torchrl.collectors.llm.LLMCollector": [[48, 1, 1, "", "as_remote"], [48, 1, 1, "", "async_shutdown"], [48, 2, 1, "", "dialog_turns_per_batch"], [48, 1, 1, "", "get_model"], [48, 1, 1, "", "get_policy_model"], [48, 1, 1, "", "get_policy_version"], [48, 1, 1, "", "getattr_env"], [48, 1, 1, "", "getattr_policy"], [48, 1, 1, "", "getattr_rb"], [48, 1, 1, "", "increment_version"], [48, 1, 1, "", "init_updater"], [48, 1, 1, "", "is_initialized"], [48, 1, 1, "", "iterator"], [48, 1, 1, "", "load_state_dict"], [48, 1, 1, "", "pause"], [48, 2, 1, "", "policy_version"], [48, 1, 1, "", "reset"], [48, 2, 1, "", "rollout"], [48, 1, 1, "", "set_seed"], [48, 1, 1, "", "shutdown"], [48, 1, 1, "", "start"], [48, 1, 1, "", "state_dict"], [48, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.llm.RayLLMCollector": [[49, 1, 1, "", "as_remote"], [49, 1, 1, "", "async_shutdown"], [49, 2, 1, "", "dialog_turns_per_batch"], [49, 1, 1, "", "get_model"], [49, 1, 1, "", "get_policy_model"], [49, 1, 1, "", "get_policy_version"], [49, 1, 1, "", "getattr_env"], [49, 1, 1, "", "getattr_policy"], [49, 1, 1, "", "getattr_rb"], [49, 1, 1, "", "increment_version"], [49, 1, 1, "", "init_updater"], [49, 1, 1, "", "is_initialized"], [49, 1, 1, "", "iterator"], [49, 1, 1, "", "load_state_dict"], [49, 1, 1, "", "next"], [49, 1, 1, "", "pause"], [49, 2, 1, "", "policy_version"], [49, 1, 1, "", "reset"], [49, 2, 1, "", "rollout"], [49, 1, 1, "", "set_seed"], [49, 1, 1, "", "shutdown"], [49, 1, 1, "", "start"], [49, 1, 1, "", "state_dict"], [49, 2, 1, "", "total_dialog_turns"], [49, 1, 1, "", "update_policy_weights_"], [49, 2, 1, "", "weight_updater"]], "torchrl.collectors.llm.vLLMUpdater": [[50, 1, 1, "", "_get_server_weights"], [50, 1, 1, "", "_maybe_map_weights"], [50, 1, 1, "", "_sync_weights_with_worker"], [50, 1, 1, "id0", "all_worker_ids"], [50, 2, 1, "", "collector"], [50, 2, 1, "", "collectors"], [50, 1, 1, "", "from_policy"], [50, 1, 1, "", "get_model_metadata"], [50, 1, 1, "", "increment_version"], [50, 1, 1, "id1", "init"], [50, 2, 1, "", "post_hooks"], [50, 1, 1, "", "push_weights"], [50, 1, 1, "", "register_collector"], [50, 1, 1, "", "register_post_hook"]], "torchrl.collectors.llm.vLLMUpdaterV2": [[51, 1, 1, "", "all_worker_ids"], [51, 2, 1, "", "collector"], [51, 2, 1, "", "collectors"], [51, 1, 1, "", "from_policy"], [51, 1, 1, "", "get_model_metadata"], [51, 1, 1, "", "get_tp_size"], [51, 1, 1, "", "increment_version"], [51, 1, 1, "", "init"], [51, 2, 1, "", "post_hooks"], [51, 1, 1, "", "push_weights"], [51, 1, 1, "", "push_weights_from_transformers"], [51, 1, 1, "", "push_weights_from_transformers_optimized"], [51, 1, 1, "", "register_collector"], [51, 1, 1, "", "register_post_hook"]], "torchrl.collectors.utils": [[52, 3, 1, "", "split_trajectories"]], "torchrl.data": [[53, 0, 1, "", "Binary"], [54, 0, 1, "", "Bounded"], [55, 0, 1, "", "Categorical"], [56, 0, 1, "", "Composite"], [57, 0, 1, "", "DiscreteTensorSpec"], [58, 0, 1, "", "LazyStackedCompositeSpec"], [59, 0, 1, "", "MultiCategorical"], [60, 0, 1, "", "MultiDiscreteTensorSpec"], [61, 0, 1, "", "MultiOneHot"], [62, 0, 1, "", "NonTensor"], [63, 0, 1, "", "OneHot"], [64, 0, 1, "", "PrioritizedReplayBuffer"], [65, 0, 1, "", "RayReplayBuffer"], [66, 0, 1, "", "RemoteTensorDictReplayBuffer"], [67, 0, 1, "", "ReplayBuffer"], [68, 0, 1, "", "ReplayBufferEnsemble"], [69, 0, 1, "", "TensorDictPrioritizedReplayBuffer"], [70, 0, 1, "", "TensorDictReplayBuffer"], [71, 0, 1, "", "TensorSpec"], [72, 0, 1, "", "Unbounded"], [73, 0, 1, "", "UnboundedContinuous"], [74, 0, 1, "", "UnboundedDiscrete"]], "torchrl.data.Binary": [[53, 1, 1, "", "assert_is_in"], [53, 1, 1, "", "cardinality"], [53, 1, 1, "", "clear_device_"], [53, 1, 1, "", "clone"], [53, 1, 1, "", "contains"], [53, 1, 1, "", "cpu"], [53, 1, 1, "", "cuda"], [53, 4, 1, "", "device"], [53, 1, 1, "", "encode"], [53, 1, 1, "", "enumerate"], [53, 1, 1, "", "erase_memoize_cache"], [53, 1, 1, "", "expand"], [53, 1, 1, "", "flatten"], [53, 1, 1, "", "implements_for_spec"], [53, 1, 1, "", "index"], [53, 1, 1, "", "is_in"], [53, 1, 1, "", "make_neg_dim"], [53, 1, 1, "", "memoize_encode"], [53, 2, 1, "", "ndim"], [53, 1, 1, "", "ndimension"], [53, 1, 1, "", "one"], [53, 1, 1, "", "ones"], [53, 1, 1, "", "project"], [53, 1, 1, "", "rand"], [53, 1, 1, "", "reshape"], [53, 1, 1, "", "sample"], [53, 1, 1, "", "set_provisional_n"], [53, 1, 1, "", "squeeze"], [53, 1, 1, "", "to"], [53, 1, 1, "", "to_categorical"], [53, 1, 1, "", "to_categorical_spec"], [53, 1, 1, "", "to_numpy"], [53, 1, 1, "", "to_one_hot"], [53, 1, 1, "", "to_one_hot_spec"], [53, 1, 1, "", "type_check"], [53, 1, 1, "", "unflatten"], [53, 1, 1, "", "unsqueeze"], [53, 1, 1, "", "update_mask"], [53, 1, 1, "", "view"], [53, 1, 1, "", "zero"], [53, 1, 1, "", "zeros"]], "torchrl.data.Bounded": [[54, 1, 1, "", "assert_is_in"], [54, 1, 1, "", "cardinality"], [54, 1, 1, "", "clear_device_"], [54, 1, 1, "", "clone"], [54, 1, 1, "", "contains"], [54, 1, 1, "", "cpu"], [54, 1, 1, "", "cuda"], [54, 2, 1, "", "device"], [54, 1, 1, "", "encode"], [54, 1, 1, "", "enumerate"], [54, 1, 1, "", "erase_memoize_cache"], [54, 1, 1, "", "expand"], [54, 1, 1, "", "flatten"], [54, 1, 1, "", "implements_for_spec"], [54, 1, 1, "", "index"], [54, 1, 1, "", "is_in"], [54, 1, 1, "", "make_neg_dim"], [54, 1, 1, "", "memoize_encode"], [54, 2, 1, "", "ndim"], [54, 1, 1, "", "ndimension"], [54, 1, 1, "", "one"], [54, 1, 1, "", "ones"], [54, 1, 1, "", "project"], [54, 1, 1, "", "rand"], [54, 1, 1, "", "reshape"], [54, 1, 1, "", "sample"], [54, 1, 1, "", "squeeze"], [54, 1, 1, "", "to"], [54, 1, 1, "", "to_numpy"], [54, 1, 1, "", "type_check"], [54, 1, 1, "", "unflatten"], [54, 1, 1, "", "unsqueeze"], [54, 1, 1, "", "view"], [54, 1, 1, "", "zero"], [54, 1, 1, "", "zeros"]], "torchrl.data.Categorical": [[55, 1, 1, "", "assert_is_in"], [55, 1, 1, "", "cardinality"], [55, 1, 1, "", "clear_device_"], [55, 1, 1, "", "clone"], [55, 1, 1, "", "contains"], [55, 1, 1, "", "cpu"], [55, 1, 1, "", "cuda"], [55, 4, 1, "", "device"], [55, 1, 1, "", "encode"], [55, 1, 1, "", "enumerate"], [55, 1, 1, "", "erase_memoize_cache"], [55, 1, 1, "", "expand"], [55, 1, 1, "", "flatten"], [55, 1, 1, "", "implements_for_spec"], [55, 1, 1, "", "index"], [55, 1, 1, "", "is_in"], [55, 1, 1, "", "make_neg_dim"], [55, 1, 1, "", "memoize_encode"], [55, 2, 1, "", "ndim"], [55, 1, 1, "", "ndimension"], [55, 1, 1, "", "one"], [55, 1, 1, "", "ones"], [55, 1, 1, "", "project"], [55, 1, 1, "", "rand"], [55, 1, 1, "", "reshape"], [55, 1, 1, "", "sample"], [55, 1, 1, "", "set_provisional_n"], [55, 1, 1, "", "squeeze"], [55, 1, 1, "", "to"], [55, 1, 1, "", "to_categorical"], [55, 1, 1, "", "to_categorical_spec"], [55, 1, 1, "", "to_numpy"], [55, 1, 1, "", "to_one_hot"], [55, 1, 1, "", "to_one_hot_spec"], [55, 1, 1, "", "type_check"], [55, 1, 1, "", "unflatten"], [55, 1, 1, "", "unsqueeze"], [55, 1, 1, "", "update_mask"], [55, 1, 1, "", "view"], [55, 1, 1, "", "zero"], [55, 1, 1, "", "zeros"]], "torchrl.data.Composite": [[56, 1, 1, "", "assert_is_in"], [56, 1, 1, "", "cardinality"], [56, 1, 1, "", "clear_device_"], [56, 1, 1, "", "clone"], [56, 1, 1, "", "contains"], [56, 1, 1, "", "cpu"], [56, 1, 1, "", "cuda"], [56, 2, 1, "", "device"], [56, 1, 1, "", "empty"], [56, 1, 1, "", "encode"], [56, 1, 1, "", "enumerate"], [56, 1, 1, "", "erase_memoize_cache"], [56, 1, 1, "", "expand"], [56, 1, 1, "", "flatten"], [56, 1, 1, "", "get"], [56, 1, 1, "", "implements_for_spec"], [56, 1, 1, "", "index"], [56, 1, 1, "", "is_empty"], [56, 1, 1, "", "is_in"], [56, 1, 1, "", "items"], [56, 1, 1, "", "keys"], [56, 1, 1, "", "lock_"], [56, 1, 1, "", "make_neg_dim"], [56, 1, 1, "", "memoize_encode"], [56, 2, 1, "", "names"], [56, 2, 1, "", "ndim"], [56, 1, 1, "", "ndimension"], [56, 1, 1, "", "one"], [56, 1, 1, "", "ones"], [56, 1, 1, "", "ones_update"], [56, 1, 1, "", "pop"], [56, 1, 1, "", "project"], [56, 1, 1, "", "rand"], [56, 1, 1, "", "rand_update"], [56, 1, 1, "", "refine_names"], [56, 1, 1, "", "reshape"], [56, 1, 1, "", "sample"], [56, 1, 1, "", "separates"], [56, 1, 1, "", "set"], [56, 1, 1, "", "squeeze"], [56, 1, 1, "", "to"], [56, 1, 1, "", "to_numpy"], [56, 1, 1, "", "type_check"], [56, 1, 1, "", "unflatten"], [56, 1, 1, "", "unlock_"], [56, 1, 1, "", "unsqueeze"], [56, 1, 1, "", "values"], [56, 1, 1, "", "view"], [56, 1, 1, "", "zero"], [56, 1, 1, "", "zeros"], [56, 1, 1, "", "zeros_update"]], "torchrl.data.DiscreteTensorSpec": [[57, 1, 1, "", "assert_is_in"], [57, 1, 1, "", "cardinality"], [57, 1, 1, "", "clear_device_"], [57, 1, 1, "", "clone"], [57, 1, 1, "", "contains"], [57, 1, 1, "", "cpu"], [57, 1, 1, "", "cuda"], [57, 4, 1, "", "device"], [57, 1, 1, "", "encode"], [57, 1, 1, "", "enumerate"], [57, 1, 1, "", "erase_memoize_cache"], [57, 1, 1, "", "expand"], [57, 1, 1, "", "flatten"], [57, 1, 1, "", "implements_for_spec"], [57, 1, 1, "", "index"], [57, 1, 1, "", "is_in"], [57, 1, 1, "", "make_neg_dim"], [57, 1, 1, "", "memoize_encode"], [57, 2, 1, "", "ndim"], [57, 1, 1, "", "ndimension"], [57, 1, 1, "", "one"], [57, 1, 1, "", "ones"], [57, 1, 1, "", "project"], [57, 1, 1, "", "rand"], [57, 1, 1, "", "reshape"], [57, 1, 1, "", "sample"], [57, 1, 1, "", "set_provisional_n"], [57, 1, 1, "", "squeeze"], [57, 1, 1, "", "to"], [57, 1, 1, "", "to_categorical"], [57, 1, 1, "", "to_categorical_spec"], [57, 1, 1, "", "to_numpy"], [57, 1, 1, "", "to_one_hot"], [57, 1, 1, "", "to_one_hot_spec"], [57, 1, 1, "", "type_check"], [57, 1, 1, "", "unflatten"], [57, 1, 1, "", "unsqueeze"], [57, 1, 1, "", "update_mask"], [57, 1, 1, "", "view"], [57, 1, 1, "", "zero"], [57, 1, 1, "", "zeros"]], "torchrl.data.LazyStackedCompositeSpec": [[58, 1, 1, "", "assert_is_in"], [58, 1, 1, "", "cardinality"], [58, 1, 1, "", "clear_device_"], [58, 1, 1, "", "clone"], [58, 1, 1, "", "contains"], [58, 1, 1, "", "cpu"], [58, 1, 1, "", "cuda"], [58, 2, 1, "", "device"], [58, 1, 1, "", "empty"], [58, 1, 1, "", "encode"], [58, 1, 1, "", "enumerate"], [58, 1, 1, "", "erase_memoize_cache"], [58, 1, 1, "", "expand"], [58, 1, 1, "", "flatten"], [58, 1, 1, "", "get"], [58, 1, 1, "", "implements_for_spec"], [58, 1, 1, "", "index"], [58, 1, 1, "", "is_empty"], [58, 1, 1, "", "is_in"], [58, 1, 1, "", "items"], [58, 1, 1, "", "keys"], [58, 1, 1, "", "lock_"], [58, 1, 1, "", "make_neg_dim"], [58, 1, 1, "", "memoize_encode"], [58, 2, 1, "", "names"], [58, 2, 1, "", "ndim"], [58, 1, 1, "", "ndimension"], [58, 1, 1, "", "one"], [58, 1, 1, "", "ones"], [58, 1, 1, "", "ones_update"], [58, 1, 1, "", "pop"], [58, 1, 1, "", "project"], [58, 1, 1, "", "rand"], [58, 1, 1, "", "rand_update"], [58, 1, 1, "", "refine_names"], [58, 1, 1, "", "reshape"], [58, 1, 1, "", "sample"], [58, 1, 1, "", "separates"], [58, 1, 1, "", "set"], [58, 1, 1, "", "squeeze"], [58, 1, 1, "", "to"], [58, 1, 1, "", "to_numpy"], [58, 1, 1, "", "type_check"], [58, 1, 1, "", "unflatten"], [58, 1, 1, "", "unlock_"], [58, 1, 1, "", "unsqueeze"], [58, 1, 1, "", "values"], [58, 1, 1, "", "view"], [58, 1, 1, "", "zero"], [58, 1, 1, "", "zeros"], [58, 1, 1, "", "zeros_update"]], "torchrl.data.MultiCategorical": [[59, 1, 1, "", "assert_is_in"], [59, 1, 1, "", "cardinality"], [59, 1, 1, "", "clear_device_"], [59, 1, 1, "", "clone"], [59, 1, 1, "", "contains"], [59, 1, 1, "", "cpu"], [59, 1, 1, "", "cuda"], [59, 4, 1, "", "device"], [59, 1, 1, "", "encode"], [59, 1, 1, "", "enumerate"], [59, 1, 1, "", "erase_memoize_cache"], [59, 1, 1, "", "expand"], [59, 1, 1, "", "flatten"], [59, 1, 1, "", "implements_for_spec"], [59, 1, 1, "", "index"], [59, 1, 1, "", "is_in"], [59, 1, 1, "", "make_neg_dim"], [59, 1, 1, "", "memoize_encode"], [59, 2, 1, "", "ndim"], [59, 1, 1, "", "ndimension"], [59, 1, 1, "", "one"], [59, 1, 1, "", "ones"], [59, 1, 1, "", "project"], [59, 1, 1, "", "rand"], [59, 1, 1, "", "reshape"], [59, 1, 1, "", "sample"], [59, 1, 1, "", "set_provisional_n"], [59, 1, 1, "", "squeeze"], [59, 1, 1, "", "to"], [59, 1, 1, "", "to_categorical"], [59, 1, 1, "", "to_categorical_spec"], [59, 1, 1, "", "to_numpy"], [59, 1, 1, "", "to_one_hot"], [59, 1, 1, "", "to_one_hot_spec"], [59, 1, 1, "", "type_check"], [59, 1, 1, "", "unflatten"], [59, 1, 1, "", "unsqueeze"], [59, 1, 1, "", "update_mask"], [59, 1, 1, "", "view"], [59, 1, 1, "", "zero"], [59, 1, 1, "", "zeros"]], "torchrl.data.MultiDiscreteTensorSpec": [[60, 1, 1, "", "assert_is_in"], [60, 1, 1, "", "cardinality"], [60, 1, 1, "", "clear_device_"], [60, 1, 1, "", "clone"], [60, 1, 1, "", "contains"], [60, 1, 1, "", "cpu"], [60, 1, 1, "", "cuda"], [60, 4, 1, "", "device"], [60, 1, 1, "", "encode"], [60, 1, 1, "", "enumerate"], [60, 1, 1, "", "erase_memoize_cache"], [60, 1, 1, "", "expand"], [60, 1, 1, "", "flatten"], [60, 1, 1, "", "implements_for_spec"], [60, 1, 1, "", "index"], [60, 1, 1, "", "is_in"], [60, 1, 1, "", "make_neg_dim"], [60, 1, 1, "", "memoize_encode"], [60, 2, 1, "", "ndim"], [60, 1, 1, "", "ndimension"], [60, 1, 1, "", "one"], [60, 1, 1, "", "ones"], [60, 1, 1, "", "project"], [60, 1, 1, "", "rand"], [60, 1, 1, "", "reshape"], [60, 1, 1, "", "sample"], [60, 1, 1, "", "set_provisional_n"], [60, 1, 1, "", "squeeze"], [60, 1, 1, "", "to"], [60, 1, 1, "", "to_categorical"], [60, 1, 1, "", "to_categorical_spec"], [60, 1, 1, "", "to_numpy"], [60, 1, 1, "", "to_one_hot"], [60, 1, 1, "", "to_one_hot_spec"], [60, 1, 1, "", "type_check"], [60, 1, 1, "", "unflatten"], [60, 1, 1, "", "unsqueeze"], [60, 1, 1, "", "update_mask"], [60, 1, 1, "", "view"], [60, 1, 1, "", "zero"], [60, 1, 1, "", "zeros"]], "torchrl.data.MultiOneHot": [[61, 1, 1, "", "assert_is_in"], [61, 1, 1, "", "cardinality"], [61, 1, 1, "", "clear_device_"], [61, 1, 1, "", "clone"], [61, 1, 1, "", "contains"], [61, 1, 1, "", "cpu"], [61, 1, 1, "", "cuda"], [61, 4, 1, "", "device"], [61, 1, 1, "", "encode"], [61, 1, 1, "", "enumerate"], [61, 1, 1, "", "erase_memoize_cache"], [61, 1, 1, "", "expand"], [61, 1, 1, "", "flatten"], [61, 1, 1, "", "implements_for_spec"], [61, 1, 1, "", "index"], [61, 1, 1, "", "is_in"], [61, 1, 1, "", "make_neg_dim"], [61, 1, 1, "", "memoize_encode"], [61, 2, 1, "", "ndim"], [61, 1, 1, "", "ndimension"], [61, 1, 1, "", "one"], [61, 1, 1, "", "ones"], [61, 1, 1, "", "project"], [61, 1, 1, "", "rand"], [61, 1, 1, "", "reshape"], [61, 1, 1, "", "sample"], [61, 1, 1, "", "squeeze"], [61, 1, 1, "", "to"], [61, 1, 1, "", "to_categorical"], [61, 1, 1, "", "to_categorical_spec"], [61, 1, 1, "", "to_numpy"], [61, 1, 1, "", "to_one_hot"], [61, 1, 1, "", "to_one_hot_spec"], [61, 1, 1, "", "type_check"], [61, 1, 1, "", "unflatten"], [61, 1, 1, "", "unsqueeze"], [61, 1, 1, "", "update_mask"], [61, 1, 1, "", "view"], [61, 1, 1, "", "zero"], [61, 1, 1, "", "zeros"]], "torchrl.data.NonTensor": [[62, 1, 1, "", "assert_is_in"], [62, 1, 1, "", "cardinality"], [62, 1, 1, "", "clear_device_"], [62, 1, 1, "", "clone"], [62, 1, 1, "", "contains"], [62, 1, 1, "", "cpu"], [62, 1, 1, "", "cuda"], [62, 2, 1, "", "device"], [62, 1, 1, "", "encode"], [62, 1, 1, "", "enumerate"], [62, 1, 1, "", "erase_memoize_cache"], [62, 1, 1, "", "expand"], [62, 1, 1, "", "flatten"], [62, 1, 1, "", "implements_for_spec"], [62, 1, 1, "", "index"], [62, 1, 1, "", "is_in"], [62, 1, 1, "", "make_neg_dim"], [62, 1, 1, "", "memoize_encode"], [62, 2, 1, "", "ndim"], [62, 1, 1, "", "ndimension"], [62, 1, 1, "", "one"], [62, 1, 1, "", "ones"], [62, 1, 1, "", "project"], [62, 1, 1, "", "rand"], [62, 1, 1, "", "reshape"], [62, 1, 1, "", "sample"], [62, 1, 1, "", "squeeze"], [62, 1, 1, "", "to"], [62, 1, 1, "", "to_numpy"], [62, 1, 1, "", "type_check"], [62, 1, 1, "", "unflatten"], [62, 1, 1, "", "unsqueeze"], [62, 1, 1, "", "view"], [62, 1, 1, "", "zero"], [62, 1, 1, "", "zeros"]], "torchrl.data.OneHot": [[63, 1, 1, "", "assert_is_in"], [63, 1, 1, "", "cardinality"], [63, 1, 1, "", "clear_device_"], [63, 1, 1, "", "clone"], [63, 1, 1, "", "contains"], [63, 1, 1, "", "cpu"], [63, 1, 1, "", "cuda"], [63, 4, 1, "", "device"], [63, 1, 1, "", "encode"], [63, 1, 1, "", "enumerate"], [63, 1, 1, "", "erase_memoize_cache"], [63, 1, 1, "", "expand"], [63, 1, 1, "", "flatten"], [63, 1, 1, "", "implements_for_spec"], [63, 1, 1, "", "index"], [63, 1, 1, "", "is_in"], [63, 1, 1, "", "make_neg_dim"], [63, 1, 1, "", "memoize_encode"], [63, 2, 1, "", "ndim"], [63, 1, 1, "", "ndimension"], [63, 1, 1, "", "one"], [63, 1, 1, "", "ones"], [63, 1, 1, "", "project"], [63, 1, 1, "", "rand"], [63, 1, 1, "", "reshape"], [63, 1, 1, "", "sample"], [63, 1, 1, "", "squeeze"], [63, 1, 1, "", "to"], [63, 1, 1, "", "to_categorical"], [63, 1, 1, "", "to_categorical_spec"], [63, 1, 1, "", "to_numpy"], [63, 1, 1, "", "to_one_hot"], [63, 1, 1, "", "to_one_hot_spec"], [63, 1, 1, "", "type_check"], [63, 1, 1, "", "unflatten"], [63, 1, 1, "", "unsqueeze"], [63, 1, 1, "", "update_mask"], [63, 1, 1, "", "view"], [63, 1, 1, "", "zero"], [63, 1, 1, "", "zeros"]], "torchrl.data.PrioritizedReplayBuffer": [[64, 1, 1, "", "add"], [64, 1, 1, "", "append_transform"], [64, 1, 1, "", "as_remote"], [64, 2, 1, "", "batch_size"], [64, 1, 1, "", "dump"], [64, 1, 1, "", "dumps"], [64, 1, 1, "", "empty"], [64, 1, 1, "", "extend"], [64, 2, 1, "", "initialized"], [64, 1, 1, "", "insert_transform"], [64, 1, 1, "", "load"], [64, 1, 1, "", "loads"], [64, 1, 1, "", "next"], [64, 1, 1, "", "register_load_hook"], [64, 1, 1, "", "register_save_hook"], [64, 1, 1, "", "sample"], [64, 2, 1, "", "sampler"], [64, 1, 1, "", "save"], [64, 1, 1, "", "set_sampler"], [64, 1, 1, "", "set_storage"], [64, 1, 1, "", "set_writer"], [64, 2, 1, "", "storage"], [64, 2, 1, "", "transform"], [64, 2, 1, "", "write_count"], [64, 2, 1, "", "writer"]], "torchrl.data.RayReplayBuffer": [[65, 1, 1, "", "add"], [65, 1, 1, "", "append_transform"], [65, 1, 1, "", "as_remote"], [65, 2, 1, "", "batch_size"], [65, 1, 1, "", "close"], [65, 1, 1, "", "dump"], [65, 1, 1, "", "dumps"], [65, 1, 1, "", "empty"], [65, 1, 1, "", "extend"], [65, 2, 1, "", "initialized"], [65, 1, 1, "", "insert_transform"], [65, 1, 1, "", "load"], [65, 1, 1, "", "loads"], [65, 1, 1, "", "next"], [65, 1, 1, "", "register_load_hook"], [65, 1, 1, "", "register_save_hook"], [65, 1, 1, "", "sample"], [65, 2, 1, "", "sampler"], [65, 1, 1, "", "save"], [65, 1, 1, "", "set_sampler"], [65, 1, 1, "", "set_storage"], [65, 1, 1, "", "set_writer"], [65, 2, 1, "", "storage"], [65, 2, 1, "", "transform"], [65, 2, 1, "", "write_count"], [65, 2, 1, "", "writer"]], "torchrl.data.RemoteTensorDictReplayBuffer": [[66, 1, 1, "", "add"], [66, 1, 1, "", "append_transform"], [66, 1, 1, "", "as_remote"], [66, 2, 1, "", "batch_size"], [66, 1, 1, "", "dump"], [66, 1, 1, "", "dumps"], [66, 1, 1, "", "empty"], [66, 1, 1, "", "extend"], [66, 2, 1, "", "initialized"], [66, 1, 1, "", "insert_transform"], [66, 1, 1, "", "load"], [66, 1, 1, "", "loads"], [66, 1, 1, "", "next"], [66, 1, 1, "", "register_load_hook"], [66, 1, 1, "", "register_save_hook"], [66, 1, 1, "", "sample"], [66, 2, 1, "", "sampler"], [66, 1, 1, "", "save"], [66, 1, 1, "", "set_sampler"], [66, 1, 1, "", "set_storage"], [66, 1, 1, "", "set_writer"], [66, 2, 1, "", "storage"], [66, 2, 1, "", "transform"], [66, 2, 1, "", "write_count"], [66, 2, 1, "", "writer"]], "torchrl.data.ReplayBuffer": [[67, 1, 1, "", "add"], [67, 1, 1, "", "append_transform"], [67, 1, 1, "", "as_remote"], [67, 2, 1, "", "batch_size"], [67, 1, 1, "", "dump"], [67, 1, 1, "", "dumps"], [67, 1, 1, "", "empty"], [67, 1, 1, "", "extend"], [67, 2, 1, "", "initialized"], [67, 1, 1, "", "insert_transform"], [67, 1, 1, "", "load"], [67, 1, 1, "", "loads"], [67, 1, 1, "", "next"], [67, 1, 1, "", "register_load_hook"], [67, 1, 1, "", "register_save_hook"], [67, 1, 1, "", "sample"], [67, 2, 1, "", "sampler"], [67, 1, 1, "", "save"], [67, 1, 1, "", "set_sampler"], [67, 1, 1, "", "set_storage"], [67, 1, 1, "", "set_writer"], [67, 2, 1, "", "storage"], [67, 2, 1, "", "transform"], [67, 2, 1, "", "write_count"], [67, 2, 1, "", "writer"]], "torchrl.data.ReplayBufferEnsemble": [[68, 1, 1, "", "add"], [68, 1, 1, "", "append_transform"], [68, 1, 1, "", "as_remote"], [68, 2, 1, "", "batch_size"], [68, 1, 1, "", "dump"], [68, 1, 1, "", "dumps"], [68, 1, 1, "", "empty"], [68, 1, 1, "", "extend"], [68, 2, 1, "", "initialized"], [68, 1, 1, "", "insert_transform"], [68, 1, 1, "", "load"], [68, 1, 1, "", "loads"], [68, 1, 1, "", "next"], [68, 1, 1, "", "register_load_hook"], [68, 1, 1, "", "register_save_hook"], [68, 1, 1, "", "sample"], [68, 2, 1, "", "sampler"], [68, 1, 1, "", "save"], [68, 1, 1, "", "set_sampler"], [68, 1, 1, "", "set_storage"], [68, 1, 1, "", "set_writer"], [68, 2, 1, "", "storage"], [68, 2, 1, "", "transform"], [68, 2, 1, "", "write_count"], [68, 2, 1, "", "writer"]], "torchrl.data.TensorDictPrioritizedReplayBuffer": [[69, 1, 1, "", "add"], [69, 1, 1, "", "append_transform"], [69, 1, 1, "", "as_remote"], [69, 2, 1, "", "batch_size"], [69, 1, 1, "", "dump"], [69, 1, 1, "", "dumps"], [69, 1, 1, "", "empty"], [69, 1, 1, "", "extend"], [69, 2, 1, "", "initialized"], [69, 1, 1, "", "insert_transform"], [69, 1, 1, "", "load"], [69, 1, 1, "", "loads"], [69, 1, 1, "", "next"], [69, 1, 1, "", "register_load_hook"], [69, 1, 1, "", "register_save_hook"], [69, 1, 1, "", "sample"], [69, 2, 1, "", "sampler"], [69, 1, 1, "", "save"], [69, 1, 1, "", "set_sampler"], [69, 1, 1, "", "set_storage"], [69, 1, 1, "", "set_writer"], [69, 2, 1, "", "storage"], [69, 2, 1, "", "transform"], [69, 2, 1, "", "write_count"], [69, 2, 1, "", "writer"]], "torchrl.data.TensorDictReplayBuffer": [[70, 1, 1, "", "add"], [70, 1, 1, "", "append_transform"], [70, 1, 1, "", "as_remote"], [70, 2, 1, "", "batch_size"], [70, 1, 1, "", "dump"], [70, 1, 1, "", "dumps"], [70, 1, 1, "", "empty"], [70, 1, 1, "", "extend"], [70, 2, 1, "", "initialized"], [70, 1, 1, "", "insert_transform"], [70, 1, 1, "", "load"], [70, 1, 1, "", "loads"], [70, 1, 1, "", "next"], [70, 1, 1, "", "register_load_hook"], [70, 1, 1, "", "register_save_hook"], [70, 1, 1, "", "sample"], [70, 2, 1, "", "sampler"], [70, 1, 1, "", "save"], [70, 1, 1, "", "set_sampler"], [70, 1, 1, "", "set_storage"], [70, 1, 1, "", "set_writer"], [70, 2, 1, "", "storage"], [70, 2, 1, "", "transform"], [70, 2, 1, "", "write_count"], [70, 2, 1, "", "writer"]], "torchrl.data.TensorSpec": [[71, 1, 1, "", "assert_is_in"], [71, 1, 1, "", "cardinality"], [71, 1, 1, "", "clear_device_"], [71, 1, 1, "", "clone"], [71, 1, 1, "", "contains"], [71, 1, 1, "", "cpu"], [71, 1, 1, "", "cuda"], [71, 2, 1, "", "device"], [71, 1, 1, "", "encode"], [71, 1, 1, "", "enumerate"], [71, 1, 1, "", "erase_memoize_cache"], [71, 1, 1, "", "expand"], [71, 1, 1, "", "flatten"], [71, 1, 1, "", "implements_for_spec"], [71, 1, 1, "", "index"], [71, 1, 1, "", "is_in"], [71, 1, 1, "", "make_neg_dim"], [71, 1, 1, "", "memoize_encode"], [71, 2, 1, "", "ndim"], [71, 1, 1, "", "ndimension"], [71, 1, 1, "", "one"], [71, 1, 1, "", "ones"], [71, 1, 1, "", "project"], [71, 1, 1, "", "rand"], [71, 1, 1, "", "reshape"], [71, 1, 1, "", "sample"], [71, 1, 1, "", "squeeze"], [71, 1, 1, "", "to"], [71, 1, 1, "", "to_numpy"], [71, 1, 1, "", "type_check"], [71, 1, 1, "", "unflatten"], [71, 1, 1, "", "unsqueeze"], [71, 1, 1, "", "view"], [71, 1, 1, "", "zero"], [71, 1, 1, "", "zeros"]], "torchrl.data.Unbounded": [[72, 1, 1, "", "assert_is_in"], [72, 1, 1, "", "cardinality"], [72, 1, 1, "", "clear_device_"], [72, 1, 1, "", "clone"], [72, 1, 1, "", "contains"], [72, 1, 1, "", "cpu"], [72, 1, 1, "", "cuda"], [72, 2, 1, "", "device"], [72, 1, 1, "", "encode"], [72, 1, 1, "", "enumerate"], [72, 1, 1, "", "erase_memoize_cache"], [72, 1, 1, "", "expand"], [72, 1, 1, "", "flatten"], [72, 1, 1, "", "implements_for_spec"], [72, 1, 1, "", "index"], [72, 1, 1, "", "is_in"], [72, 1, 1, "", "make_neg_dim"], [72, 1, 1, "", "memoize_encode"], [72, 2, 1, "", "ndim"], [72, 1, 1, "", "ndimension"], [72, 1, 1, "", "one"], [72, 1, 1, "", "ones"], [72, 1, 1, "", "project"], [72, 1, 1, "", "rand"], [72, 1, 1, "", "reshape"], [72, 1, 1, "", "sample"], [72, 1, 1, "", "squeeze"], [72, 1, 1, "", "to"], [72, 1, 1, "", "to_numpy"], [72, 1, 1, "", "type_check"], [72, 1, 1, "", "unflatten"], [72, 1, 1, "", "unsqueeze"], [72, 1, 1, "", "view"], [72, 1, 1, "", "zero"], [72, 1, 1, "", "zeros"]], "torchrl.data.UnboundedContinuous": [[73, 1, 1, "", "assert_is_in"], [73, 1, 1, "", "cardinality"], [73, 1, 1, "", "clear_device_"], [73, 1, 1, "", "clone"], [73, 1, 1, "", "contains"], [73, 1, 1, "", "cpu"], [73, 1, 1, "", "cuda"], [73, 2, 1, "", "device"], [73, 1, 1, "", "encode"], [73, 1, 1, "", "enumerate"], [73, 1, 1, "", "erase_memoize_cache"], [73, 1, 1, "", "expand"], [73, 1, 1, "", "flatten"], [73, 1, 1, "", "implements_for_spec"], [73, 1, 1, "", "index"], [73, 1, 1, "", "is_in"], [73, 1, 1, "", "make_neg_dim"], [73, 1, 1, "", "memoize_encode"], [73, 2, 1, "", "ndim"], [73, 1, 1, "", "ndimension"], [73, 1, 1, "", "one"], [73, 1, 1, "", "ones"], [73, 1, 1, "", "project"], [73, 1, 1, "", "rand"], [73, 1, 1, "", "reshape"], [73, 1, 1, "", "sample"], [73, 1, 1, "", "squeeze"], [73, 1, 1, "", "to"], [73, 1, 1, "", "to_numpy"], [73, 1, 1, "", "type_check"], [73, 1, 1, "", "unflatten"], [73, 1, 1, "", "unsqueeze"], [73, 1, 1, "", "view"], [73, 1, 1, "", "zero"], [73, 1, 1, "", "zeros"]], "torchrl.data.UnboundedDiscrete": [[74, 1, 1, "", "assert_is_in"], [74, 1, 1, "", "cardinality"], [74, 1, 1, "", "clear_device_"], [74, 1, 1, "", "clone"], [74, 1, 1, "", "contains"], [74, 1, 1, "", "cpu"], [74, 1, 1, "", "cuda"], [74, 2, 1, "", "device"], [74, 1, 1, "", "encode"], [74, 1, 1, "", "enumerate"], [74, 1, 1, "", "erase_memoize_cache"], [74, 1, 1, "", "expand"], [74, 1, 1, "", "flatten"], [74, 1, 1, "", "implements_for_spec"], [74, 1, 1, "", "index"], [74, 1, 1, "", "is_in"], [74, 1, 1, "", "make_neg_dim"], [74, 1, 1, "", "memoize_encode"], [74, 2, 1, "", "ndim"], [74, 1, 1, "", "ndimension"], [74, 1, 1, "", "one"], [74, 1, 1, "", "ones"], [74, 1, 1, "", "project"], [74, 1, 1, "", "rand"], [74, 1, 1, "", "reshape"], [74, 1, 1, "", "sample"], [74, 1, 1, "", "squeeze"], [74, 1, 1, "", "to"], [74, 1, 1, "", "to_numpy"], [74, 1, 1, "", "type_check"], [74, 1, 1, "", "unflatten"], [74, 1, 1, "", "unsqueeze"], [74, 1, 1, "", "view"], [74, 1, 1, "", "zero"], [74, 1, 1, "", "zeros"]], "torchrl.data.datasets": [[75, 0, 1, "", "AtariDQNExperienceReplay"], [76, 0, 1, "", "D4RLExperienceReplay"], [77, 0, 1, "", "GenDGRLExperienceReplay"], [78, 0, 1, "", "MinariExperienceReplay"], [79, 0, 1, "", "OpenMLExperienceReplay"], [80, 0, 1, "", "OpenXExperienceReplay"], [81, 0, 1, "", "RobosetExperienceReplay"], [82, 0, 1, "", "VD4RLExperienceReplay"]], "torchrl.data.datasets.AtariDQNExperienceReplay": [[75, 1, 1, "", "add"], [75, 1, 1, "", "append_transform"], [75, 1, 1, "", "as_remote"], [75, 2, 1, "", "batch_size"], [75, 2, 1, "", "data_path"], [75, 2, 1, "", "data_path_root"], [75, 1, 1, "", "delete"], [75, 1, 1, "", "dump"], [75, 1, 1, "", "dumps"], [75, 1, 1, "", "empty"], [75, 1, 1, "", "extend"], [75, 2, 1, "", "initialized"], [75, 1, 1, "", "insert_transform"], [75, 1, 1, "", "load"], [75, 1, 1, "", "loads"], [75, 1, 1, "", "next"], [75, 1, 1, "", "preprocess"], [75, 1, 1, "", "register_load_hook"], [75, 1, 1, "", "register_save_hook"], [75, 1, 1, "", "sample"], [75, 2, 1, "", "sampler"], [75, 1, 1, "", "save"], [75, 1, 1, "", "set_sampler"], [75, 1, 1, "", "set_storage"], [75, 1, 1, "", "set_writer"], [75, 2, 1, "", "storage"], [75, 2, 1, "", "transform"], [75, 2, 1, "", "write_count"], [75, 2, 1, "", "writer"]], "torchrl.data.datasets.D4RLExperienceReplay": [[76, 1, 1, "", "add"], [76, 1, 1, "", "append_transform"], [76, 1, 1, "", "as_remote"], [76, 2, 1, "", "batch_size"], [76, 2, 1, "", "data_path"], [76, 2, 1, "", "data_path_root"], [76, 1, 1, "", "delete"], [76, 1, 1, "", "dump"], [76, 1, 1, "", "dumps"], [76, 1, 1, "", "empty"], [76, 1, 1, "", "extend"], [76, 2, 1, "", "initialized"], [76, 1, 1, "", "insert_transform"], [76, 1, 1, "", "load"], [76, 1, 1, "", "loads"], [76, 1, 1, "", "next"], [76, 1, 1, "", "preprocess"], [76, 1, 1, "", "register_load_hook"], [76, 1, 1, "", "register_save_hook"], [76, 1, 1, "", "sample"], [76, 2, 1, "", "sampler"], [76, 1, 1, "", "save"], [76, 1, 1, "", "set_sampler"], [76, 1, 1, "", "set_storage"], [76, 1, 1, "", "set_writer"], [76, 2, 1, "", "storage"], [76, 2, 1, "", "transform"], [76, 2, 1, "", "write_count"], [76, 2, 1, "", "writer"]], "torchrl.data.datasets.GenDGRLExperienceReplay": [[77, 1, 1, "", "add"], [77, 1, 1, "", "append_transform"], [77, 1, 1, "", "as_remote"], [77, 2, 1, "", "batch_size"], [77, 2, 1, "", "data_path"], [77, 2, 1, "", "data_path_root"], [77, 1, 1, "", "delete"], [77, 1, 1, "", "dump"], [77, 1, 1, "", "dumps"], [77, 1, 1, "", "empty"], [77, 1, 1, "", "extend"], [77, 2, 1, "", "initialized"], [77, 1, 1, "", "insert_transform"], [77, 1, 1, "", "load"], [77, 1, 1, "", "loads"], [77, 1, 1, "", "next"], [77, 1, 1, "", "preprocess"], [77, 1, 1, "", "register_load_hook"], [77, 1, 1, "", "register_save_hook"], [77, 1, 1, "", "sample"], [77, 2, 1, "", "sampler"], [77, 1, 1, "", "save"], [77, 1, 1, "", "set_sampler"], [77, 1, 1, "", "set_storage"], [77, 1, 1, "", "set_writer"], [77, 2, 1, "", "storage"], [77, 2, 1, "", "transform"], [77, 2, 1, "", "write_count"], [77, 2, 1, "", "writer"]], "torchrl.data.datasets.MinariExperienceReplay": [[78, 1, 1, "", "add"], [78, 1, 1, "", "append_transform"], [78, 1, 1, "", "as_remote"], [78, 2, 1, "", "batch_size"], [78, 2, 1, "", "data_path"], [78, 2, 1, "", "data_path_root"], [78, 1, 1, "", "delete"], [78, 1, 1, "", "dump"], [78, 1, 1, "", "dumps"], [78, 1, 1, "", "empty"], [78, 1, 1, "", "extend"], [78, 2, 1, "", "initialized"], [78, 1, 1, "", "insert_transform"], [78, 1, 1, "", "load"], [78, 1, 1, "", "loads"], [78, 1, 1, "", "next"], [78, 1, 1, "", "preprocess"], [78, 1, 1, "", "register_load_hook"], [78, 1, 1, "", "register_save_hook"], [78, 1, 1, "", "sample"], [78, 2, 1, "", "sampler"], [78, 1, 1, "", "save"], [78, 1, 1, "", "set_sampler"], [78, 1, 1, "", "set_storage"], [78, 1, 1, "", "set_writer"], [78, 2, 1, "", "storage"], [78, 2, 1, "", "transform"], [78, 2, 1, "", "write_count"], [78, 2, 1, "", "writer"]], "torchrl.data.datasets.OpenMLExperienceReplay": [[79, 1, 1, "", "add"], [79, 1, 1, "", "append_transform"], [79, 1, 1, "", "as_remote"], [79, 2, 1, "", "batch_size"], [79, 2, 1, "", "data_path"], [79, 2, 1, "", "data_path_root"], [79, 1, 1, "", "delete"], [79, 1, 1, "", "dump"], [79, 1, 1, "", "dumps"], [79, 1, 1, "", "empty"], [79, 1, 1, "", "extend"], [79, 2, 1, "", "initialized"], [79, 1, 1, "", "insert_transform"], [79, 1, 1, "", "load"], [79, 1, 1, "", "loads"], [79, 1, 1, "", "next"], [79, 1, 1, "", "preprocess"], [79, 1, 1, "", "register_load_hook"], [79, 1, 1, "", "register_save_hook"], [79, 1, 1, "", "sample"], [79, 2, 1, "", "sampler"], [79, 1, 1, "", "save"], [79, 1, 1, "", "set_sampler"], [79, 1, 1, "", "set_storage"], [79, 1, 1, "", "set_writer"], [79, 2, 1, "", "storage"], [79, 2, 1, "", "transform"], [79, 2, 1, "", "write_count"], [79, 2, 1, "", "writer"]], "torchrl.data.datasets.OpenXExperienceReplay": [[80, 1, 1, "", "add"], [80, 1, 1, "", "append_transform"], [80, 1, 1, "", "as_remote"], [80, 2, 1, "", "batch_size"], [80, 2, 1, "", "data_path"], [80, 2, 1, "", "data_path_root"], [80, 1, 1, "", "delete"], [80, 1, 1, "", "dump"], [80, 1, 1, "", "dumps"], [80, 1, 1, "", "empty"], [80, 1, 1, "", "extend"], [80, 2, 1, "", "initialized"], [80, 1, 1, "", "insert_transform"], [80, 1, 1, "", "load"], [80, 1, 1, "", "loads"], [80, 1, 1, "", "next"], [80, 1, 1, "", "preprocess"], [80, 1, 1, "", "register_load_hook"], [80, 1, 1, "", "register_save_hook"], [80, 1, 1, "", "sample"], [80, 2, 1, "", "sampler"], [80, 1, 1, "", "save"], [80, 1, 1, "", "set_sampler"], [80, 1, 1, "", "set_storage"], [80, 1, 1, "", "set_writer"], [80, 2, 1, "", "storage"], [80, 2, 1, "", "transform"], [80, 2, 1, "", "write_count"], [80, 2, 1, "", "writer"]], "torchrl.data.datasets.RobosetExperienceReplay": [[81, 1, 1, "", "add"], [81, 1, 1, "", "append_transform"], [81, 1, 1, "", "as_remote"], [81, 2, 1, "", "batch_size"], [81, 2, 1, "", "data_path"], [81, 2, 1, "", "data_path_root"], [81, 1, 1, "", "delete"], [81, 1, 1, "", "dump"], [81, 1, 1, "", "dumps"], [81, 1, 1, "", "empty"], [81, 1, 1, "", "extend"], [81, 2, 1, "", "initialized"], [81, 1, 1, "", "insert_transform"], [81, 1, 1, "", "load"], [81, 1, 1, "", "loads"], [81, 1, 1, "", "next"], [81, 1, 1, "", "preprocess"], [81, 1, 1, "", "register_load_hook"], [81, 1, 1, "", "register_save_hook"], [81, 1, 1, "", "sample"], [81, 2, 1, "", "sampler"], [81, 1, 1, "", "save"], [81, 1, 1, "", "set_sampler"], [81, 1, 1, "", "set_storage"], [81, 1, 1, "", "set_writer"], [81, 2, 1, "", "storage"], [81, 2, 1, "", "transform"], [81, 2, 1, "", "write_count"], [81, 2, 1, "", "writer"]], "torchrl.data.datasets.VD4RLExperienceReplay": [[82, 1, 1, "", "add"], [82, 1, 1, "", "append_transform"], [82, 1, 1, "", "as_remote"], [82, 2, 1, "", "batch_size"], [82, 2, 1, "", "data_path"], [82, 2, 1, "", "data_path_root"], [82, 1, 1, "", "delete"], [82, 1, 1, "", "dump"], [82, 1, 1, "", "dumps"], [82, 1, 1, "", "empty"], [82, 1, 1, "", "extend"], [82, 2, 1, "", "initialized"], [82, 1, 1, "", "insert_transform"], [82, 1, 1, "", "load"], [82, 1, 1, "", "loads"], [82, 1, 1, "", "next"], [82, 1, 1, "", "preprocess"], [82, 1, 1, "", "register_load_hook"], [82, 1, 1, "", "register_save_hook"], [82, 1, 1, "", "sample"], [82, 2, 1, "", "sampler"], [82, 1, 1, "", "save"], [82, 1, 1, "", "set_sampler"], [82, 1, 1, "", "set_storage"], [82, 1, 1, "", "set_writer"], [82, 2, 1, "", "storage"], [82, 2, 1, "", "transform"], [82, 2, 1, "", "write_count"], [82, 2, 1, "", "writer"]], "torchrl.data.llm": [[83, 0, 1, "", "ContentBase"], [84, 0, 1, "", "History"], [85, 0, 1, "", "TopKRewardSelector"], [86, 0, 1, "", "add_chat_template"]], "torchrl.data.llm.ContentBase": [[83, 1, 1, "", "cat"], [83, 2, 1, "", "device"], [83, 1, 1, "", "dumps"], [83, 1, 1, "", "fields"], [83, 1, 1, "", "from_any"], [83, 1, 1, "", "from_dataclass"], [83, 1, 1, "", "from_h5"], [83, 1, 1, "", "from_modules"], [83, 1, 1, "", "from_namedtuple"], [83, 1, 1, "", "from_pytree"], [83, 1, 1, "", "from_remote_init"], [83, 1, 1, "", "from_struct_array"], [83, 1, 1, "", "from_tensordict"], [83, 1, 1, "", "from_tuple"], [83, 1, 1, "", "fromkeys"], [83, 1, 1, "", "get"], [83, 1, 1, "", "lazy_stack"], [83, 1, 1, "", "load"], [83, 1, 1, "", "load_"], [83, 1, 1, "", "load_memmap"], [83, 1, 1, "", "load_state_dict"], [83, 1, 1, "", "maybe_dense_stack"], [83, 1, 1, "", "memmap"], [83, 1, 1, "", "memmap_"], [83, 1, 1, "", "memmap_like"], [83, 1, 1, "", "memmap_refresh_"], [83, 1, 1, "", "save"], [83, 1, 1, "", "set"], [83, 1, 1, "", "stack"], [83, 1, 1, "", "state_dict"], [83, 1, 1, "", "to_tensordict"], [83, 1, 1, "", "unbind"]], "torchrl.data.llm.History": [[84, 1, 1, "", "append"], [84, 1, 1, "", "apply_chat_template"], [84, 1, 1, "", "cat"], [84, 1, 1, "", "default_spec"], [84, 2, 1, "", "device"], [84, 1, 1, "", "dumps"], [84, 1, 1, "", "fields"], [84, 1, 1, "", "from_any"], [84, 1, 1, "", "from_chats"], [84, 1, 1, "", "from_dataclass"], [84, 1, 1, "", "from_h5"], [84, 1, 1, "", "from_modules"], [84, 1, 1, "", "from_namedtuple"], [84, 1, 1, "", "from_pytree"], [84, 1, 1, "", "from_remote_init"], [84, 1, 1, "", "from_struct_array"], [84, 1, 1, "", "from_tensordict"], [84, 1, 1, "", "from_text"], [84, 1, 1, "", "from_tuple"], [84, 1, 1, "", "fromkeys"], [84, 1, 1, "", "get"], [84, 1, 1, "", "lazy_stack"], [84, 1, 1, "", "load"], [84, 1, 1, "", "load_"], [84, 1, 1, "", "load_memmap"], [84, 1, 1, "", "load_state_dict"], [84, 1, 1, "", "maybe_dense_stack"], [84, 1, 1, "", "memmap"], [84, 1, 1, "", "memmap_"], [84, 1, 1, "", "memmap_like"], [84, 1, 1, "", "memmap_refresh_"], [84, 1, 1, "", "save"], [84, 1, 1, "", "set"], [84, 1, 1, "", "stack"], [84, 1, 1, "", "state_dict"], [84, 1, 1, "", "to_tensordict"], [84, 1, 1, "", "unbind"]], "torchrl.data.llm.TopKRewardSelector": [[85, 1, 1, "", "add_module"], [85, 1, 1, "", "apply"], [85, 1, 1, "", "bfloat16"], [85, 1, 1, "", "buffers"], [85, 1, 1, "", "children"], [85, 1, 1, "", "close"], [85, 2, 1, "", "collector"], [85, 1, 1, "", "compile"], [85, 2, 1, "", "container"], [85, 1, 1, "", "cpu"], [85, 1, 1, "", "cuda"], [85, 1, 1, "", "double"], [85, 1, 1, "", "eval"], [85, 1, 1, "", "extra_repr"], [85, 1, 1, "", "float"], [85, 1, 1, "", "forward"], [85, 1, 1, "", "get_buffer"], [85, 1, 1, "", "get_extra_state"], [85, 1, 1, "", "get_parameter"], [85, 1, 1, "", "get_submodule"], [85, 1, 1, "", "half"], [85, 1, 1, "", "init"], [85, 1, 1, "", "inv"], [85, 1, 1, "", "ipu"], [85, 1, 1, "", "load_state_dict"], [85, 1, 1, "", "modules"], [85, 1, 1, "", "mtia"], [85, 1, 1, "", "named_buffers"], [85, 1, 1, "", "named_children"], [85, 1, 1, "", "named_modules"], [85, 1, 1, "", "named_parameters"], [85, 1, 1, "", "parameters"], [85, 2, 1, "", "parent"], [85, 1, 1, "", "register_backward_hook"], [85, 1, 1, "", "register_buffer"], [85, 1, 1, "", "register_forward_hook"], [85, 1, 1, "", "register_forward_pre_hook"], [85, 1, 1, "", "register_full_backward_hook"], [85, 1, 1, "", "register_full_backward_pre_hook"], [85, 1, 1, "", "register_load_state_dict_post_hook"], [85, 1, 1, "", "register_load_state_dict_pre_hook"], [85, 1, 1, "", "register_module"], [85, 1, 1, "", "register_parameter"], [85, 1, 1, "", "register_state_dict_post_hook"], [85, 1, 1, "", "register_state_dict_pre_hook"], [85, 1, 1, "", "requires_grad_"], [85, 1, 1, "", "set_extra_state"], [85, 1, 1, "", "set_submodule"], [85, 1, 1, "", "share_memory"], [85, 1, 1, "", "state_dict"], [85, 1, 1, "", "to"], [85, 1, 1, "", "to_empty"], [85, 1, 1, "", "train"], [85, 1, 1, "", "transform_action_spec"], [85, 1, 1, "", "transform_done_spec"], [85, 1, 1, "", "transform_env_batch_size"], [85, 1, 1, "", "transform_env_device"], [85, 1, 1, "", "transform_input_spec"], [85, 1, 1, "", "transform_observation_spec"], [85, 1, 1, "", "transform_output_spec"], [85, 1, 1, "", "transform_reward_spec"], [85, 1, 1, "", "transform_state_spec"], [85, 1, 1, "", "type"], [85, 1, 1, "", "xpu"], [85, 1, 1, "", "zero_grad"]], "torchrl.data.replay_buffers": [[87, 0, 1, "", "CompressedListStorage"], [88, 0, 1, "", "CompressedListStorageCheckpointer"], [89, 0, 1, "", "FlatStorageCheckpointer"], [90, 0, 1, "", "H5StorageCheckpointer"], [91, 0, 1, "", "ImmutableDatasetWriter"], [92, 0, 1, "", "LazyMemmapStorage"], [93, 0, 1, "", "LazyStackStorage"], [94, 0, 1, "", "LazyTensorStorage"], [95, 0, 1, "", "ListStorage"], [96, 0, 1, "", "ListStorageCheckpointer"], [97, 0, 1, "", "NestedStorageCheckpointer"], [98, 0, 1, "", "PrioritizedSampler"], [99, 0, 1, "", "PrioritizedSliceSampler"], [100, 0, 1, "", "RandomSampler"], [101, 0, 1, "", "RoundRobinWriter"], [102, 0, 1, "", "Sampler"], [103, 0, 1, "", "SamplerEnsemble"], [104, 0, 1, "", "SamplerWithoutReplacement"], [105, 0, 1, "", "SliceSampler"], [106, 0, 1, "", "SliceSamplerWithoutReplacement"], [107, 0, 1, "", "Storage"], [108, 0, 1, "", "StorageCheckpointerBase"], [109, 0, 1, "", "StorageEnsemble"], [110, 0, 1, "", "StorageEnsembleCheckpointer"], [111, 0, 1, "", "TensorDictMaxValueWriter"], [112, 0, 1, "", "TensorDictRoundRobinWriter"], [113, 0, 1, "", "TensorStorage"], [114, 0, 1, "", "TensorStorageCheckpointer"], [115, 0, 1, "", "Writer"], [116, 0, 1, "", "WriterEnsemble"]], "torchrl.data.replay_buffers.CompressedListStorage": [[87, 1, 1, "", "attach"], [87, 1, 1, "", "bytes"], [87, 1, 1, "", "dump"], [87, 1, 1, "", "load"], [87, 1, 1, "", "load_state_dict"], [87, 1, 1, "", "save"], [87, 1, 1, "", "state_dict"], [87, 1, 1, "", "to_bytestream"]], "torchrl.data.replay_buffers.CompressedListStorageCheckpointer": [[88, 1, 1, "", "dumps"], [88, 1, 1, "", "loads"]], "torchrl.data.replay_buffers.ImmutableDatasetWriter": [[91, 1, 1, "", "add"], [91, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.LazyMemmapStorage": [[92, 1, 1, "", "attach"], [92, 1, 1, "", "dump"], [92, 1, 1, "", "load"], [92, 1, 1, "", "save"]], "torchrl.data.replay_buffers.LazyStackStorage": [[93, 1, 1, "", "attach"], [93, 1, 1, "", "dump"], [93, 1, 1, "", "load"], [93, 1, 1, "", "save"]], "torchrl.data.replay_buffers.LazyTensorStorage": [[94, 1, 1, "", "attach"], [94, 1, 1, "", "dump"], [94, 1, 1, "", "load"], [94, 1, 1, "", "save"]], "torchrl.data.replay_buffers.ListStorage": [[95, 1, 1, "", "attach"], [95, 1, 1, "", "dump"], [95, 1, 1, "", "load"], [95, 1, 1, "", "save"]], "torchrl.data.replay_buffers.PrioritizedSampler": [[98, 1, 1, "", "update_priority"]], "torchrl.data.replay_buffers.PrioritizedSliceSampler": [[99, 1, 1, "", "update_priority"]], "torchrl.data.replay_buffers.RoundRobinWriter": [[101, 1, 1, "", "add"], [101, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.Storage": [[107, 1, 1, "", "attach"], [107, 1, 1, "", "dump"], [107, 1, 1, "", "load"], [107, 1, 1, "", "save"]], "torchrl.data.replay_buffers.StorageEnsemble": [[109, 1, 1, "", "attach"], [109, 1, 1, "", "dump"], [109, 1, 1, "", "load"], [109, 1, 1, "", "save"]], "torchrl.data.replay_buffers.TensorDictMaxValueWriter": [[111, 1, 1, "", "add"], [111, 1, 1, "", "extend"], [111, 1, 1, "", "get_insert_index"]], "torchrl.data.replay_buffers.TensorDictRoundRobinWriter": [[112, 1, 1, "", "add"], [112, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.TensorStorage": [[113, 1, 1, "", "attach"], [113, 1, 1, "", "dump"], [113, 1, 1, "", "load"], [113, 1, 1, "", "save"]], "torchrl.data.replay_buffers.Writer": [[115, 1, 1, "", "add"], [115, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.WriterEnsemble": [[116, 1, 1, "", "add"], [116, 1, 1, "", "extend"]], "torchrl.envs": [[117, 0, 1, "", "AsyncEnvPool"], [118, 3, 1, "", "BraxEnv"], [119, 3, 1, "", "BraxWrapper"], [120, 0, 1, "", "ChessEnv"], [121, 3, 1, "", "DMControlEnv"], [122, 3, 1, "", "DMControlWrapper"], [123, 0, 1, "", "EnvBase"], [124, 0, 1, "", "EnvCreator"], [125, 0, 1, "", "EnvMetaData"], [126, 3, 1, "", "GymEnv"], [127, 0, 1, "", "GymLikeEnv"], [128, 3, 1, "", "GymWrapper"], [129, 3, 1, "", "HabitatEnv"], [130, 3, 1, "", "IsaacGymEnv"], [131, 3, 1, "", "IsaacGymWrapper"], [132, 3, 1, "", "IsaacLabWrapper"], [133, 3, 1, "", "JumanjiEnv"], [134, 3, 1, "", "JumanjiWrapper"], [135, 0, 1, "", "LLMHashingEnv"], [136, 3, 1, "", "MOGymEnv"], [137, 3, 1, "", "MOGymWrapper"], [138, 3, 1, "", "MarlGroupMapType"], [139, 3, 1, "", "MeltingpotEnv"], [140, 3, 1, "", "MeltingpotWrapper"], [141, 3, 1, "", "ModelBasedEnvBase"], [142, 3, 1, "", "MultiThreadedEnv"], [143, 3, 1, "", "MultiThreadedEnvWrapper"], [144, 3, 1, "", "OpenMLEnv"], [145, 3, 1, "", "OpenSpielEnv"], [146, 3, 1, "", "OpenSpielWrapper"], [147, 0, 1, "", "ParallelEnv"], [148, 0, 1, "", "PendulumEnv"], [149, 3, 1, "", "PettingZooEnv"], [150, 3, 1, "", "PettingZooWrapper"], [151, 0, 1, "", "ProcessorAsyncEnvPool"], [152, 3, 1, "", "RandomPolicy"], [153, 3, 1, "", "RoboHiveEnv"], [154, 3, 1, "", "SMACv2Env"], [155, 3, 1, "", "SMACv2Wrapper"], [156, 0, 1, "", "SerialEnv"], [157, 0, 1, "", "ThreadingAsyncEnvPool"], [158, 0, 1, "", "TicTacToeEnv"], [159, 3, 1, "", "UnityMLAgentsEnv"], [160, 3, 1, "", "UnityMLAgentsWrapper"], [161, 3, 1, "", "VmasEnv"], [162, 3, 1, "", "VmasWrapper"], [163, 3, 1, "", "check_env_specs"], [164, 3, 1, "", "check_marl_grouping"], [165, 3, 1, "", "exploration_type"], [166, 3, 1, "", "get_available_libraries"], [167, 3, 1, "", "gym_backend"], [204, 3, 1, "", "make_composite_from_td"], [141, 1, 1, "", "rand_step"], [207, 3, 1, "", "register_gym_spec_conversion"], [141, 1, 1, "", "reset"], [141, 1, 1, "", "rollout"], [208, 3, 1, "", "set_exploration_type"], [209, 3, 1, "", "set_gym_backend"], [141, 1, 1, "", "set_seed"], [141, 1, 1, "", "step"], [210, 3, 1, "", "step_mdp"], [211, 3, 1, "", "terminated_or_truncated"]], "torchrl.envs.AsyncEnvPool": [[117, 2, 1, "", "action_key"], [117, 2, 1, "", "action_keys"], [117, 2, 1, "", "action_spec"], [117, 2, 1, "", "action_spec_unbatched"], [117, 1, 1, "", "add_module"], [117, 1, 1, "", "add_truncated_keys"], [117, 1, 1, "", "all_actions"], [117, 1, 1, "", "any_done"], [117, 1, 1, "", "append_transform"], [117, 1, 1, "", "apply"], [117, 1, 1, "", "auto_specs_"], [117, 2, 1, "", "batch_dims"], [117, 2, 1, "", "batch_locked"], [117, 2, 1, "", "batch_size"], [117, 1, 1, "", "bfloat16"], [117, 1, 1, "", "buffers"], [117, 1, 1, "", "cardinality"], [117, 1, 1, "", "check_env_specs"], [117, 1, 1, "", "children"], [117, 2, 1, "", "collector"], [117, 1, 1, "", "compile"], [117, 1, 1, "", "cpu"], [117, 1, 1, "", "cuda"], [117, 2, 1, "", "done_key"], [117, 2, 1, "", "done_keys"], [117, 2, 1, "", "done_keys_groups"], [117, 2, 1, "", "done_spec"], [117, 2, 1, "", "done_spec_unbatched"], [117, 1, 1, "", "double"], [117, 1, 1, "", "empty_cache"], [117, 2, 1, "", "env_batch_sizes"], [117, 1, 1, "", "eval"], [117, 1, 1, "", "extra_repr"], [117, 1, 1, "", "fake_tensordict"], [117, 1, 1, "", "float"], [117, 1, 1, "", "forward"], [117, 2, 1, "", "full_action_spec"], [117, 2, 1, "", "full_action_spec_unbatched"], [117, 2, 1, "", "full_done_spec"], [117, 2, 1, "", "full_done_spec_unbatched"], [117, 2, 1, "", "full_observation_spec_unbatched"], [117, 2, 1, "", "full_reward_spec"], [117, 2, 1, "", "full_reward_spec_unbatched"], [117, 2, 1, "", "full_state_spec"], [117, 2, 1, "", "full_state_spec_unbatched"], [117, 1, 1, "", "get_buffer"], [117, 1, 1, "", "get_extra_state"], [117, 1, 1, "", "get_parameter"], [117, 1, 1, "", "get_submodule"], [117, 1, 1, "", "half"], [117, 2, 1, "", "input_spec"], [117, 2, 1, "", "input_spec_unbatched"], [117, 1, 1, "", "ipu"], [117, 2, 1, "", "is_spec_locked"], [117, 1, 1, "", "load_state_dict"], [117, 1, 1, "", "maybe_reset"], [117, 1, 1, "", "modules"], [117, 1, 1, "", "mtia"], [117, 1, 1, "", "named_buffers"], [117, 1, 1, "", "named_children"], [117, 1, 1, "", "named_modules"], [117, 1, 1, "", "named_parameters"], [117, 2, 1, "", "observation_keys"], [117, 2, 1, "", "observation_spec"], [117, 2, 1, "", "observation_spec_unbatched"], [117, 2, 1, "", "output_spec"], [117, 2, 1, "", "output_spec_unbatched"], [117, 1, 1, "", "parameters"], [117, 1, 1, "", "rand_action"], [117, 1, 1, "", "rand_step"], [117, 1, 1, "", "register_backward_hook"], [117, 1, 1, "", "register_buffer"], [117, 1, 1, "", "register_collector"], [117, 1, 1, "", "register_forward_hook"], [117, 1, 1, "", "register_forward_pre_hook"], [117, 1, 1, "", "register_full_backward_hook"], [117, 1, 1, "", "register_full_backward_pre_hook"], [117, 1, 1, "", "register_gym"], [117, 1, 1, "", "register_load_state_dict_post_hook"], [117, 1, 1, "", "register_load_state_dict_pre_hook"], [117, 1, 1, "", "register_module"], [117, 1, 1, "", "register_parameter"], [117, 1, 1, "", "register_state_dict_post_hook"], [117, 1, 1, "", "register_state_dict_pre_hook"], [117, 1, 1, "", "requires_grad_"], [117, 1, 1, "", "reset"], [117, 2, 1, "", "reset_keys"], [117, 2, 1, "", "reward_key"], [117, 2, 1, "", "reward_keys"], [117, 2, 1, "", "reward_spec"], [117, 2, 1, "", "reward_spec_unbatched"], [117, 1, 1, "", "rollout"], [117, 1, 1, "", "set_extra_state"], [117, 1, 1, "", "set_seed"], [117, 1, 1, "", "set_spec_lock_"], [117, 1, 1, "", "set_submodule"], [117, 2, 1, "", "shape"], [117, 1, 1, "", "share_memory"], [117, 2, 1, "", "specs"], [117, 1, 1, "", "state_dict"], [117, 2, 1, "", "state_keys"], [117, 2, 1, "", "state_spec"], [117, 2, 1, "", "state_spec_unbatched"], [117, 1, 1, "", "step"], [117, 1, 1, "", "step_and_maybe_reset"], [117, 1, 1, "", "step_mdp"], [117, 1, 1, "", "to"], [117, 1, 1, "", "to_empty"], [117, 1, 1, "", "train"], [117, 1, 1, "", "type"], [117, 1, 1, "", "xpu"], [117, 1, 1, "", "zero_grad"]], "torchrl.envs.ChessEnv": [[120, 2, 1, "", "action_key"], [120, 2, 1, "", "action_keys"], [120, 2, 1, "", "action_spec"], [120, 2, 1, "", "action_spec_unbatched"], [120, 1, 1, "", "add_module"], [120, 1, 1, "", "add_truncated_keys"], [120, 1, 1, "", "all_actions"], [120, 1, 1, "", "any_done"], [120, 1, 1, "", "append_transform"], [120, 1, 1, "", "apply"], [120, 1, 1, "", "auto_specs_"], [120, 2, 1, "", "batch_dims"], [120, 2, 1, "", "batch_locked"], [120, 2, 1, "", "batch_size"], [120, 1, 1, "", "bfloat16"], [120, 1, 1, "", "buffers"], [120, 1, 1, "", "cardinality"], [120, 1, 1, "", "check_env_specs"], [120, 1, 1, "", "children"], [120, 2, 1, "", "collector"], [120, 1, 1, "", "compile"], [120, 1, 1, "", "cpu"], [120, 1, 1, "", "cuda"], [120, 2, 1, "", "done_key"], [120, 2, 1, "", "done_keys"], [120, 2, 1, "", "done_keys_groups"], [120, 2, 1, "", "done_spec"], [120, 2, 1, "", "done_spec_unbatched"], [120, 1, 1, "", "double"], [120, 1, 1, "", "empty_cache"], [120, 1, 1, "", "eval"], [120, 1, 1, "", "extra_repr"], [120, 1, 1, "", "fake_tensordict"], [120, 1, 1, "", "float"], [120, 1, 1, "", "forward"], [120, 2, 1, "", "full_action_spec"], [120, 2, 1, "", "full_action_spec_unbatched"], [120, 2, 1, "", "full_done_spec"], [120, 2, 1, "", "full_done_spec_unbatched"], [120, 2, 1, "", "full_observation_spec_unbatched"], [120, 2, 1, "", "full_reward_spec"], [120, 2, 1, "", "full_reward_spec_unbatched"], [120, 2, 1, "", "full_state_spec"], [120, 2, 1, "", "full_state_spec_unbatched"], [120, 1, 1, "", "get_buffer"], [120, 1, 1, "", "get_extra_state"], [120, 1, 1, "", "get_legal_moves"], [120, 1, 1, "", "get_parameter"], [120, 1, 1, "", "get_submodule"], [120, 1, 1, "", "half"], [120, 2, 1, "", "input_spec"], [120, 2, 1, "", "input_spec_unbatched"], [120, 1, 1, "", "ipu"], [120, 2, 1, "", "is_spec_locked"], [120, 1, 1, "", "load_state_dict"], [120, 1, 1, "", "maybe_reset"], [120, 1, 1, "", "modules"], [120, 1, 1, "", "mtia"], [120, 1, 1, "", "named_buffers"], [120, 1, 1, "", "named_children"], [120, 1, 1, "", "named_modules"], [120, 1, 1, "", "named_parameters"], [120, 2, 1, "", "observation_keys"], [120, 2, 1, "", "observation_spec"], [120, 2, 1, "", "observation_spec_unbatched"], [120, 2, 1, "", "output_spec"], [120, 2, 1, "", "output_spec_unbatched"], [120, 1, 1, "", "parameters"], [120, 1, 1, "", "rand_action"], [120, 1, 1, "", "rand_step"], [120, 1, 1, "", "register_backward_hook"], [120, 1, 1, "", "register_buffer"], [120, 1, 1, "", "register_collector"], [120, 1, 1, "", "register_forward_hook"], [120, 1, 1, "", "register_forward_pre_hook"], [120, 1, 1, "", "register_full_backward_hook"], [120, 1, 1, "", "register_full_backward_pre_hook"], [120, 1, 1, "", "register_gym"], [120, 1, 1, "", "register_load_state_dict_post_hook"], [120, 1, 1, "", "register_load_state_dict_pre_hook"], [120, 1, 1, "", "register_module"], [120, 1, 1, "", "register_parameter"], [120, 1, 1, "", "register_state_dict_post_hook"], [120, 1, 1, "", "register_state_dict_pre_hook"], [120, 1, 1, "", "requires_grad_"], [120, 1, 1, "", "reset"], [120, 2, 1, "", "reset_keys"], [120, 2, 1, "", "reward_key"], [120, 2, 1, "", "reward_keys"], [120, 2, 1, "", "reward_spec"], [120, 2, 1, "", "reward_spec_unbatched"], [120, 1, 1, "", "rollout"], [120, 1, 1, "", "set_extra_state"], [120, 1, 1, "", "set_seed"], [120, 1, 1, "", "set_spec_lock_"], [120, 1, 1, "", "set_submodule"], [120, 2, 1, "", "shape"], [120, 1, 1, "", "share_memory"], [120, 2, 1, "", "specs"], [120, 1, 1, "", "state_dict"], [120, 2, 1, "", "state_keys"], [120, 2, 1, "", "state_spec"], [120, 2, 1, "", "state_spec_unbatched"], [120, 1, 1, "", "step"], [120, 1, 1, "", "step_and_maybe_reset"], [120, 1, 1, "", "step_mdp"], [120, 1, 1, "", "to"], [120, 1, 1, "", "to_empty"], [120, 1, 1, "", "train"], [120, 1, 1, "", "type"], [120, 1, 1, "", "xpu"], [120, 1, 1, "", "zero_grad"]], "torchrl.envs.EnvBase": [[123, 2, 1, "", "action_key"], [123, 2, 1, "", "action_keys"], [123, 2, 1, "", "action_spec"], [123, 2, 1, "", "action_spec_unbatched"], [123, 1, 1, "", "add_module"], [123, 1, 1, "", "add_truncated_keys"], [123, 1, 1, "", "all_actions"], [123, 1, 1, "", "any_done"], [123, 1, 1, "", "append_transform"], [123, 1, 1, "", "apply"], [123, 1, 1, "", "auto_specs_"], [123, 2, 1, "", "batch_dims"], [123, 2, 1, "", "batch_locked"], [123, 2, 1, "", "batch_size"], [123, 1, 1, "", "bfloat16"], [123, 1, 1, "", "buffers"], [123, 1, 1, "", "cardinality"], [123, 1, 1, "", "check_env_specs"], [123, 1, 1, "", "children"], [123, 2, 1, "", "collector"], [123, 1, 1, "", "compile"], [123, 1, 1, "", "cpu"], [123, 1, 1, "", "cuda"], [123, 2, 1, "", "done_key"], [123, 2, 1, "", "done_keys"], [123, 2, 1, "", "done_keys_groups"], [123, 2, 1, "", "done_spec"], [123, 2, 1, "", "done_spec_unbatched"], [123, 1, 1, "", "double"], [123, 1, 1, "", "empty_cache"], [123, 1, 1, "", "eval"], [123, 1, 1, "", "extra_repr"], [123, 1, 1, "", "fake_tensordict"], [123, 1, 1, "", "float"], [123, 1, 1, "", "forward"], [123, 2, 1, "", "full_action_spec"], [123, 2, 1, "", "full_action_spec_unbatched"], [123, 2, 1, "", "full_done_spec"], [123, 2, 1, "", "full_done_spec_unbatched"], [123, 2, 1, "", "full_observation_spec_unbatched"], [123, 2, 1, "", "full_reward_spec"], [123, 2, 1, "", "full_reward_spec_unbatched"], [123, 2, 1, "", "full_state_spec"], [123, 2, 1, "", "full_state_spec_unbatched"], [123, 1, 1, "", "get_buffer"], [123, 1, 1, "", "get_extra_state"], [123, 1, 1, "", "get_parameter"], [123, 1, 1, "", "get_submodule"], [123, 1, 1, "", "half"], [123, 2, 1, "", "input_spec"], [123, 2, 1, "", "input_spec_unbatched"], [123, 1, 1, "", "ipu"], [123, 2, 1, "", "is_spec_locked"], [123, 1, 1, "", "load_state_dict"], [123, 1, 1, "", "maybe_reset"], [123, 1, 1, "", "modules"], [123, 1, 1, "", "mtia"], [123, 1, 1, "", "named_buffers"], [123, 1, 1, "", "named_children"], [123, 1, 1, "", "named_modules"], [123, 1, 1, "", "named_parameters"], [123, 2, 1, "", "observation_keys"], [123, 2, 1, "", "observation_spec"], [123, 2, 1, "", "observation_spec_unbatched"], [123, 2, 1, "", "output_spec"], [123, 2, 1, "", "output_spec_unbatched"], [123, 1, 1, "", "parameters"], [123, 1, 1, "", "rand_action"], [123, 1, 1, "id0", "rand_step"], [123, 1, 1, "", "register_backward_hook"], [123, 1, 1, "", "register_buffer"], [123, 1, 1, "", "register_collector"], [123, 1, 1, "", "register_forward_hook"], [123, 1, 1, "", "register_forward_pre_hook"], [123, 1, 1, "", "register_full_backward_hook"], [123, 1, 1, "", "register_full_backward_pre_hook"], [123, 1, 1, "", "register_gym"], [123, 1, 1, "", "register_load_state_dict_post_hook"], [123, 1, 1, "", "register_load_state_dict_pre_hook"], [123, 1, 1, "", "register_module"], [123, 1, 1, "", "register_parameter"], [123, 1, 1, "", "register_state_dict_post_hook"], [123, 1, 1, "", "register_state_dict_pre_hook"], [123, 1, 1, "", "requires_grad_"], [123, 1, 1, "id1", "reset"], [123, 2, 1, "", "reset_keys"], [123, 2, 1, "", "reward_key"], [123, 2, 1, "", "reward_keys"], [123, 2, 1, "", "reward_spec"], [123, 2, 1, "", "reward_spec_unbatched"], [123, 1, 1, "id2", "rollout"], [123, 1, 1, "", "set_extra_state"], [123, 1, 1, "id3", "set_seed"], [123, 1, 1, "", "set_spec_lock_"], [123, 1, 1, "", "set_submodule"], [123, 2, 1, "", "shape"], [123, 1, 1, "", "share_memory"], [123, 2, 1, "", "specs"], [123, 1, 1, "", "state_dict"], [123, 2, 1, "", "state_keys"], [123, 2, 1, "", "state_spec"], [123, 2, 1, "", "state_spec_unbatched"], [123, 1, 1, "id4", "step"], [123, 1, 1, "", "step_and_maybe_reset"], [123, 1, 1, "", "step_mdp"], [123, 1, 1, "", "to"], [123, 1, 1, "", "to_empty"], [123, 1, 1, "", "train"], [123, 1, 1, "", "type"], [123, 1, 1, "", "xpu"], [123, 1, 1, "", "zero_grad"]], "torchrl.envs.EnvCreator": [[124, 1, 1, "", "make_variant"]], "torchrl.envs.GymLikeEnv": [[127, 2, 1, "", "action_key"], [127, 2, 1, "", "action_keys"], [127, 2, 1, "", "action_spec"], [127, 2, 1, "", "action_spec_unbatched"], [127, 1, 1, "", "add_module"], [127, 1, 1, "", "add_truncated_keys"], [127, 1, 1, "", "all_actions"], [127, 1, 1, "", "any_done"], [127, 1, 1, "", "append_transform"], [127, 1, 1, "", "apply"], [127, 1, 1, "", "auto_register_info_dict"], [127, 1, 1, "", "auto_specs_"], [127, 2, 1, "", "batch_dims"], [127, 2, 1, "", "batch_locked"], [127, 2, 1, "", "batch_size"], [127, 1, 1, "", "bfloat16"], [127, 1, 1, "", "buffers"], [127, 1, 1, "", "cardinality"], [127, 1, 1, "", "check_env_specs"], [127, 1, 1, "", "children"], [127, 1, 1, "", "close"], [127, 2, 1, "", "collector"], [127, 1, 1, "", "compile"], [127, 1, 1, "", "cpu"], [127, 1, 1, "", "cuda"], [127, 2, 1, "", "done_key"], [127, 2, 1, "", "done_keys"], [127, 2, 1, "", "done_keys_groups"], [127, 2, 1, "", "done_spec"], [127, 2, 1, "", "done_spec_unbatched"], [127, 1, 1, "", "double"], [127, 1, 1, "", "empty_cache"], [127, 1, 1, "", "eval"], [127, 1, 1, "", "extra_repr"], [127, 1, 1, "", "fake_tensordict"], [127, 1, 1, "", "fast_encoding"], [127, 1, 1, "", "float"], [127, 1, 1, "", "forward"], [127, 2, 1, "", "full_action_spec"], [127, 2, 1, "", "full_action_spec_unbatched"], [127, 2, 1, "", "full_done_spec"], [127, 2, 1, "", "full_done_spec_unbatched"], [127, 2, 1, "", "full_observation_spec_unbatched"], [127, 2, 1, "", "full_reward_spec"], [127, 2, 1, "", "full_reward_spec_unbatched"], [127, 2, 1, "", "full_state_spec"], [127, 2, 1, "", "full_state_spec_unbatched"], [127, 1, 1, "", "get_buffer"], [127, 1, 1, "", "get_extra_state"], [127, 1, 1, "", "get_parameter"], [127, 1, 1, "", "get_submodule"], [127, 1, 1, "", "half"], [127, 2, 1, "", "input_spec"], [127, 2, 1, "", "input_spec_unbatched"], [127, 1, 1, "", "ipu"], [127, 2, 1, "", "is_spec_locked"], [127, 1, 1, "", "load_state_dict"], [127, 1, 1, "", "maybe_reset"], [127, 1, 1, "", "modules"], [127, 1, 1, "", "mtia"], [127, 1, 1, "", "named_buffers"], [127, 1, 1, "", "named_children"], [127, 1, 1, "", "named_modules"], [127, 1, 1, "", "named_parameters"], [127, 2, 1, "", "observation_keys"], [127, 2, 1, "", "observation_spec"], [127, 2, 1, "", "observation_spec_unbatched"], [127, 2, 1, "", "output_spec"], [127, 2, 1, "", "output_spec_unbatched"], [127, 1, 1, "", "parameters"], [127, 1, 1, "", "rand_action"], [127, 1, 1, "", "rand_step"], [127, 1, 1, "", "read_action"], [127, 1, 1, "", "read_done"], [127, 1, 1, "", "read_obs"], [127, 1, 1, "", "read_reward"], [127, 1, 1, "", "register_backward_hook"], [127, 1, 1, "", "register_buffer"], [127, 1, 1, "", "register_collector"], [127, 1, 1, "", "register_forward_hook"], [127, 1, 1, "", "register_forward_pre_hook"], [127, 1, 1, "", "register_full_backward_hook"], [127, 1, 1, "", "register_full_backward_pre_hook"], [127, 1, 1, "", "register_gym"], [127, 1, 1, "", "register_load_state_dict_post_hook"], [127, 1, 1, "", "register_load_state_dict_pre_hook"], [127, 1, 1, "", "register_module"], [127, 1, 1, "", "register_parameter"], [127, 1, 1, "", "register_state_dict_post_hook"], [127, 1, 1, "", "register_state_dict_pre_hook"], [127, 1, 1, "", "requires_grad_"], [127, 1, 1, "", "reset"], [127, 2, 1, "", "reset_keys"], [127, 2, 1, "", "reward_key"], [127, 2, 1, "", "reward_keys"], [127, 2, 1, "", "reward_spec"], [127, 2, 1, "", "reward_spec_unbatched"], [127, 1, 1, "", "rollout"], [127, 1, 1, "", "set_extra_state"], [127, 1, 1, "", "set_info_dict_reader"], [127, 1, 1, "", "set_seed"], [127, 1, 1, "", "set_spec_lock_"], [127, 1, 1, "", "set_submodule"], [127, 2, 1, "", "shape"], [127, 1, 1, "", "share_memory"], [127, 2, 1, "", "specs"], [127, 1, 1, "", "state_dict"], [127, 2, 1, "", "state_keys"], [127, 2, 1, "", "state_spec"], [127, 2, 1, "", "state_spec_unbatched"], [127, 1, 1, "", "step"], [127, 1, 1, "", "step_and_maybe_reset"], [127, 1, 1, "", "step_mdp"], [127, 1, 1, "", "to"], [127, 1, 1, "", "to_empty"], [127, 1, 1, "", "train"], [127, 1, 1, "", "type"], [127, 1, 1, "", "xpu"], [127, 1, 1, "", "zero_grad"]], "torchrl.envs.LLMHashingEnv": [[135, 2, 1, "", "action_key"], [135, 2, 1, "", "action_keys"], [135, 2, 1, "", "action_spec"], [135, 2, 1, "", "action_spec_unbatched"], [135, 1, 1, "", "add_module"], [135, 1, 1, "", "add_truncated_keys"], [135, 1, 1, "", "all_actions"], [135, 1, 1, "", "any_done"], [135, 1, 1, "", "append_transform"], [135, 1, 1, "", "apply"], [135, 1, 1, "", "auto_specs_"], [135, 2, 1, "", "batch_dims"], [135, 2, 1, "", "batch_locked"], [135, 2, 1, "", "batch_size"], [135, 1, 1, "", "bfloat16"], [135, 1, 1, "", "buffers"], [135, 1, 1, "", "cardinality"], [135, 1, 1, "", "check_env_specs"], [135, 1, 1, "", "children"], [135, 2, 1, "", "collector"], [135, 1, 1, "", "compile"], [135, 1, 1, "", "cpu"], [135, 1, 1, "", "cuda"], [135, 2, 1, "", "done_key"], [135, 2, 1, "", "done_keys"], [135, 2, 1, "", "done_keys_groups"], [135, 2, 1, "", "done_spec"], [135, 2, 1, "", "done_spec_unbatched"], [135, 1, 1, "", "double"], [135, 1, 1, "", "empty_cache"], [135, 1, 1, "", "eval"], [135, 1, 1, "", "extra_repr"], [135, 1, 1, "", "fake_tensordict"], [135, 1, 1, "", "float"], [135, 1, 1, "", "forward"], [135, 2, 1, "", "full_action_spec"], [135, 2, 1, "", "full_action_spec_unbatched"], [135, 2, 1, "", "full_done_spec"], [135, 2, 1, "", "full_done_spec_unbatched"], [135, 2, 1, "", "full_observation_spec_unbatched"], [135, 2, 1, "", "full_reward_spec"], [135, 2, 1, "", "full_reward_spec_unbatched"], [135, 2, 1, "", "full_state_spec"], [135, 2, 1, "", "full_state_spec_unbatched"], [135, 1, 1, "", "get_buffer"], [135, 1, 1, "", "get_extra_state"], [135, 1, 1, "", "get_parameter"], [135, 1, 1, "", "get_submodule"], [135, 1, 1, "", "half"], [135, 2, 1, "", "input_spec"], [135, 2, 1, "", "input_spec_unbatched"], [135, 1, 1, "", "ipu"], [135, 2, 1, "", "is_spec_locked"], [135, 1, 1, "", "load_state_dict"], [135, 1, 1, "", "make_tensordict"], [135, 1, 1, "", "maybe_reset"], [135, 1, 1, "", "modules"], [135, 1, 1, "", "mtia"], [135, 1, 1, "", "named_buffers"], [135, 1, 1, "", "named_children"], [135, 1, 1, "", "named_modules"], [135, 1, 1, "", "named_parameters"], [135, 2, 1, "", "observation_keys"], [135, 2, 1, "", "observation_spec"], [135, 2, 1, "", "observation_spec_unbatched"], [135, 2, 1, "", "output_spec"], [135, 2, 1, "", "output_spec_unbatched"], [135, 1, 1, "", "parameters"], [135, 1, 1, "", "rand_action"], [135, 1, 1, "", "rand_step"], [135, 1, 1, "", "register_backward_hook"], [135, 1, 1, "", "register_buffer"], [135, 1, 1, "", "register_collector"], [135, 1, 1, "", "register_forward_hook"], [135, 1, 1, "", "register_forward_pre_hook"], [135, 1, 1, "", "register_full_backward_hook"], [135, 1, 1, "", "register_full_backward_pre_hook"], [135, 1, 1, "", "register_gym"], [135, 1, 1, "", "register_load_state_dict_post_hook"], [135, 1, 1, "", "register_load_state_dict_pre_hook"], [135, 1, 1, "", "register_module"], [135, 1, 1, "", "register_parameter"], [135, 1, 1, "", "register_state_dict_post_hook"], [135, 1, 1, "", "register_state_dict_pre_hook"], [135, 1, 1, "", "requires_grad_"], [135, 1, 1, "", "reset"], [135, 2, 1, "", "reset_keys"], [135, 2, 1, "", "reward_key"], [135, 2, 1, "", "reward_keys"], [135, 2, 1, "", "reward_spec"], [135, 2, 1, "", "reward_spec_unbatched"], [135, 1, 1, "", "rollout"], [135, 1, 1, "", "set_extra_state"], [135, 1, 1, "", "set_seed"], [135, 1, 1, "", "set_spec_lock_"], [135, 1, 1, "", "set_submodule"], [135, 2, 1, "", "shape"], [135, 1, 1, "", "share_memory"], [135, 2, 1, "", "specs"], [135, 1, 1, "", "state_dict"], [135, 2, 1, "", "state_keys"], [135, 2, 1, "", "state_spec"], [135, 2, 1, "", "state_spec_unbatched"], [135, 1, 1, "", "step"], [135, 1, 1, "", "step_and_maybe_reset"], [135, 1, 1, "", "step_mdp"], [135, 1, 1, "", "to"], [135, 1, 1, "", "to_empty"], [135, 1, 1, "", "train"], [135, 1, 1, "", "type"], [135, 1, 1, "", "xpu"], [135, 1, 1, "", "zero_grad"]], "torchrl.envs.ParallelEnv": [[147, 2, 1, "", "action_key"], [147, 2, 1, "", "action_keys"], [147, 2, 1, "", "action_spec"], [147, 2, 1, "", "action_spec_unbatched"], [147, 1, 1, "", "add_module"], [147, 1, 1, "", "add_truncated_keys"], [147, 1, 1, "", "all_actions"], [147, 1, 1, "", "any_done"], [147, 1, 1, "", "append_transform"], [147, 1, 1, "", "apply"], [147, 1, 1, "", "auto_specs_"], [147, 2, 1, "", "batch_dims"], [147, 2, 1, "", "batch_locked"], [147, 2, 1, "", "batch_size"], [147, 1, 1, "", "bfloat16"], [147, 1, 1, "", "buffers"], [147, 1, 1, "", "cardinality"], [147, 1, 1, "", "check_env_specs"], [147, 1, 1, "", "children"], [147, 2, 1, "", "collector"], [147, 1, 1, "", "compile"], [147, 1, 1, "", "cpu"], [147, 1, 1, "", "cuda"], [147, 2, 1, "", "done_key"], [147, 2, 1, "", "done_keys"], [147, 2, 1, "", "done_keys_groups"], [147, 2, 1, "", "done_spec"], [147, 2, 1, "", "done_spec_unbatched"], [147, 1, 1, "", "double"], [147, 1, 1, "", "empty_cache"], [147, 1, 1, "", "eval"], [147, 1, 1, "", "extra_repr"], [147, 1, 1, "", "fake_tensordict"], [147, 1, 1, "", "float"], [147, 1, 1, "", "forward"], [147, 2, 1, "", "full_action_spec"], [147, 2, 1, "", "full_action_spec_unbatched"], [147, 2, 1, "", "full_done_spec"], [147, 2, 1, "", "full_done_spec_unbatched"], [147, 2, 1, "", "full_observation_spec_unbatched"], [147, 2, 1, "", "full_reward_spec"], [147, 2, 1, "", "full_reward_spec_unbatched"], [147, 2, 1, "", "full_state_spec"], [147, 2, 1, "", "full_state_spec_unbatched"], [147, 1, 1, "", "get_buffer"], [147, 1, 1, "", "get_extra_state"], [147, 1, 1, "", "get_parameter"], [147, 1, 1, "", "get_submodule"], [147, 1, 1, "", "half"], [147, 2, 1, "", "input_spec"], [147, 2, 1, "", "input_spec_unbatched"], [147, 1, 1, "", "ipu"], [147, 2, 1, "", "is_spec_locked"], [147, 1, 1, "", "load_state_dict"], [147, 1, 1, "", "maybe_reset"], [147, 1, 1, "", "modules"], [147, 1, 1, "", "mtia"], [147, 1, 1, "", "named_buffers"], [147, 1, 1, "", "named_children"], [147, 1, 1, "", "named_modules"], [147, 1, 1, "", "named_parameters"], [147, 2, 1, "", "observation_keys"], [147, 2, 1, "", "observation_spec"], [147, 2, 1, "", "observation_spec_unbatched"], [147, 2, 1, "", "output_spec"], [147, 2, 1, "", "output_spec_unbatched"], [147, 1, 1, "", "parameters"], [147, 1, 1, "", "rand_action"], [147, 1, 1, "", "rand_step"], [147, 1, 1, "", "register_backward_hook"], [147, 1, 1, "", "register_buffer"], [147, 1, 1, "", "register_collector"], [147, 1, 1, "", "register_forward_hook"], [147, 1, 1, "", "register_forward_pre_hook"], [147, 1, 1, "", "register_full_backward_hook"], [147, 1, 1, "", "register_full_backward_pre_hook"], [147, 1, 1, "", "register_gym"], [147, 1, 1, "", "register_load_state_dict_post_hook"], [147, 1, 1, "", "register_load_state_dict_pre_hook"], [147, 1, 1, "", "register_module"], [147, 1, 1, "", "register_parameter"], [147, 1, 1, "", "register_state_dict_post_hook"], [147, 1, 1, "", "register_state_dict_pre_hook"], [147, 1, 1, "", "requires_grad_"], [147, 1, 1, "", "reset"], [147, 2, 1, "", "reset_keys"], [147, 2, 1, "", "reward_key"], [147, 2, 1, "", "reward_keys"], [147, 2, 1, "", "reward_spec"], [147, 2, 1, "", "reward_spec_unbatched"], [147, 1, 1, "", "rollout"], [147, 1, 1, "", "set_extra_state"], [147, 1, 1, "", "set_seed"], [147, 1, 1, "", "set_spec_lock_"], [147, 1, 1, "", "set_submodule"], [147, 2, 1, "", "shape"], [147, 1, 1, "", "share_memory"], [147, 2, 1, "", "specs"], [147, 1, 1, "", "state_dict"], [147, 2, 1, "", "state_keys"], [147, 2, 1, "", "state_spec"], [147, 2, 1, "", "state_spec_unbatched"], [147, 1, 1, "", "step"], [147, 1, 1, "", "step_and_maybe_reset"], [147, 1, 1, "", "step_mdp"], [147, 1, 1, "", "to"], [147, 1, 1, "", "to_empty"], [147, 1, 1, "", "train"], [147, 1, 1, "", "type"], [147, 1, 1, "", "update_kwargs"], [147, 1, 1, "", "xpu"], [147, 1, 1, "", "zero_grad"]], "torchrl.envs.PendulumEnv": [[148, 2, 1, "", "action_key"], [148, 2, 1, "", "action_keys"], [148, 2, 1, "", "action_spec"], [148, 2, 1, "", "action_spec_unbatched"], [148, 1, 1, "", "add_module"], [148, 1, 1, "", "add_truncated_keys"], [148, 1, 1, "", "all_actions"], [148, 1, 1, "", "any_done"], [148, 1, 1, "", "append_transform"], [148, 1, 1, "", "apply"], [148, 1, 1, "", "auto_specs_"], [148, 2, 1, "", "batch_dims"], [148, 2, 1, "", "batch_size"], [148, 1, 1, "", "bfloat16"], [148, 1, 1, "", "buffers"], [148, 1, 1, "", "cardinality"], [148, 1, 1, "", "check_env_specs"], [148, 1, 1, "", "children"], [148, 2, 1, "", "collector"], [148, 1, 1, "", "compile"], [148, 1, 1, "", "cpu"], [148, 1, 1, "", "cuda"], [148, 2, 1, "", "done_key"], [148, 2, 1, "", "done_keys"], [148, 2, 1, "", "done_keys_groups"], [148, 2, 1, "", "done_spec"], [148, 2, 1, "", "done_spec_unbatched"], [148, 1, 1, "", "double"], [148, 1, 1, "", "empty_cache"], [148, 1, 1, "", "eval"], [148, 1, 1, "", "extra_repr"], [148, 1, 1, "", "fake_tensordict"], [148, 1, 1, "", "float"], [148, 1, 1, "", "forward"], [148, 2, 1, "", "full_action_spec"], [148, 2, 1, "", "full_action_spec_unbatched"], [148, 2, 1, "", "full_done_spec"], [148, 2, 1, "", "full_done_spec_unbatched"], [148, 2, 1, "", "full_observation_spec_unbatched"], [148, 2, 1, "", "full_reward_spec"], [148, 2, 1, "", "full_reward_spec_unbatched"], [148, 2, 1, "", "full_state_spec"], [148, 2, 1, "", "full_state_spec_unbatched"], [148, 1, 1, "", "gen_params"], [148, 1, 1, "", "get_buffer"], [148, 1, 1, "", "get_extra_state"], [148, 1, 1, "", "get_parameter"], [148, 1, 1, "", "get_submodule"], [148, 1, 1, "", "half"], [148, 2, 1, "", "input_spec"], [148, 2, 1, "", "input_spec_unbatched"], [148, 1, 1, "", "ipu"], [148, 2, 1, "", "is_spec_locked"], [148, 1, 1, "", "load_state_dict"], [148, 1, 1, "", "maybe_reset"], [148, 1, 1, "", "modules"], [148, 1, 1, "", "mtia"], [148, 1, 1, "", "named_buffers"], [148, 1, 1, "", "named_children"], [148, 1, 1, "", "named_modules"], [148, 1, 1, "", "named_parameters"], [148, 2, 1, "", "observation_keys"], [148, 2, 1, "", "observation_spec"], [148, 2, 1, "", "observation_spec_unbatched"], [148, 2, 1, "", "output_spec"], [148, 2, 1, "", "output_spec_unbatched"], [148, 1, 1, "", "parameters"], [148, 1, 1, "", "rand_action"], [148, 1, 1, "", "rand_step"], [148, 1, 1, "", "register_backward_hook"], [148, 1, 1, "", "register_buffer"], [148, 1, 1, "", "register_collector"], [148, 1, 1, "", "register_forward_hook"], [148, 1, 1, "", "register_forward_pre_hook"], [148, 1, 1, "", "register_full_backward_hook"], [148, 1, 1, "", "register_full_backward_pre_hook"], [148, 1, 1, "", "register_gym"], [148, 1, 1, "", "register_load_state_dict_post_hook"], [148, 1, 1, "", "register_load_state_dict_pre_hook"], [148, 1, 1, "", "register_module"], [148, 1, 1, "", "register_parameter"], [148, 1, 1, "", "register_state_dict_post_hook"], [148, 1, 1, "", "register_state_dict_pre_hook"], [148, 1, 1, "", "requires_grad_"], [148, 1, 1, "", "reset"], [148, 2, 1, "", "reset_keys"], [148, 2, 1, "", "reward_key"], [148, 2, 1, "", "reward_keys"], [148, 2, 1, "", "reward_spec"], [148, 2, 1, "", "reward_spec_unbatched"], [148, 1, 1, "", "rollout"], [148, 1, 1, "", "set_extra_state"], [148, 1, 1, "", "set_seed"], [148, 1, 1, "", "set_spec_lock_"], [148, 1, 1, "", "set_submodule"], [148, 2, 1, "", "shape"], [148, 1, 1, "", "share_memory"], [148, 2, 1, "", "specs"], [148, 1, 1, "", "state_dict"], [148, 2, 1, "", "state_keys"], [148, 2, 1, "", "state_spec"], [148, 2, 1, "", "state_spec_unbatched"], [148, 1, 1, "", "step"], [148, 1, 1, "", "step_and_maybe_reset"], [148, 1, 1, "", "step_mdp"], [148, 1, 1, "", "to"], [148, 1, 1, "", "to_empty"], [148, 1, 1, "", "train"], [148, 1, 1, "", "type"], [148, 1, 1, "", "xpu"], [148, 1, 1, "", "zero_grad"]], "torchrl.envs.ProcessorAsyncEnvPool": [[151, 1, 1, "", "_setup"], [151, 2, 1, "", "action_key"], [151, 2, 1, "", "action_keys"], [151, 2, 1, "", "action_spec"], [151, 2, 1, "", "action_spec_unbatched"], [151, 1, 1, "", "add_module"], [151, 1, 1, "", "add_truncated_keys"], [151, 1, 1, "", "all_actions"], [151, 1, 1, "", "any_done"], [151, 1, 1, "", "append_transform"], [151, 1, 1, "", "apply"], [151, 1, 1, "", "async_reset_recv"], [151, 1, 1, "", "async_reset_send"], [151, 1, 1, "", "async_step_recv"], [151, 1, 1, "", "async_step_send"], [151, 1, 1, "", "auto_specs_"], [151, 2, 1, "", "batch_dims"], [151, 2, 1, "", "batch_locked"], [151, 2, 1, "", "batch_size"], [151, 1, 1, "", "bfloat16"], [151, 1, 1, "", "buffers"], [151, 1, 1, "", "cardinality"], [151, 1, 1, "", "check_env_specs"], [151, 1, 1, "", "children"], [151, 2, 1, "", "collector"], [151, 1, 1, "", "compile"], [151, 1, 1, "", "cpu"], [151, 1, 1, "", "cuda"], [151, 2, 1, "", "done_key"], [151, 2, 1, "", "done_keys"], [151, 2, 1, "", "done_keys_groups"], [151, 2, 1, "", "done_spec"], [151, 2, 1, "", "done_spec_unbatched"], [151, 1, 1, "", "double"], [151, 1, 1, "", "empty_cache"], [151, 2, 1, "", "env_batch_sizes"], [151, 1, 1, "", "eval"], [151, 1, 1, "", "extra_repr"], [151, 1, 1, "", "fake_tensordict"], [151, 1, 1, "", "float"], [151, 1, 1, "", "forward"], [151, 2, 1, "", "full_action_spec"], [151, 2, 1, "", "full_action_spec_unbatched"], [151, 2, 1, "", "full_done_spec"], [151, 2, 1, "", "full_done_spec_unbatched"], [151, 2, 1, "", "full_observation_spec_unbatched"], [151, 2, 1, "", "full_reward_spec"], [151, 2, 1, "", "full_reward_spec_unbatched"], [151, 2, 1, "", "full_state_spec"], [151, 2, 1, "", "full_state_spec_unbatched"], [151, 1, 1, "", "get_buffer"], [151, 1, 1, "", "get_extra_state"], [151, 1, 1, "", "get_parameter"], [151, 1, 1, "", "get_submodule"], [151, 1, 1, "", "half"], [151, 2, 1, "", "input_spec"], [151, 2, 1, "", "input_spec_unbatched"], [151, 1, 1, "", "ipu"], [151, 2, 1, "", "is_spec_locked"], [151, 1, 1, "", "load_state_dict"], [151, 1, 1, "", "maybe_reset"], [151, 1, 1, "", "modules"], [151, 1, 1, "", "mtia"], [151, 1, 1, "", "named_buffers"], [151, 1, 1, "", "named_children"], [151, 1, 1, "", "named_modules"], [151, 1, 1, "", "named_parameters"], [151, 2, 1, "", "observation_keys"], [151, 2, 1, "", "observation_spec"], [151, 2, 1, "", "observation_spec_unbatched"], [151, 2, 1, "", "output_spec"], [151, 2, 1, "", "output_spec_unbatched"], [151, 1, 1, "", "parameters"], [151, 1, 1, "", "rand_action"], [151, 1, 1, "", "rand_step"], [151, 1, 1, "", "register_backward_hook"], [151, 1, 1, "", "register_buffer"], [151, 1, 1, "", "register_collector"], [151, 1, 1, "", "register_forward_hook"], [151, 1, 1, "", "register_forward_pre_hook"], [151, 1, 1, "", "register_full_backward_hook"], [151, 1, 1, "", "register_full_backward_pre_hook"], [151, 1, 1, "", "register_gym"], [151, 1, 1, "", "register_load_state_dict_post_hook"], [151, 1, 1, "", "register_load_state_dict_pre_hook"], [151, 1, 1, "", "register_module"], [151, 1, 1, "", "register_parameter"], [151, 1, 1, "", "register_state_dict_post_hook"], [151, 1, 1, "", "register_state_dict_pre_hook"], [151, 1, 1, "", "requires_grad_"], [151, 1, 1, "", "reset"], [151, 2, 1, "", "reset_keys"], [151, 2, 1, "", "reward_key"], [151, 2, 1, "", "reward_keys"], [151, 2, 1, "", "reward_spec"], [151, 2, 1, "", "reward_spec_unbatched"], [151, 1, 1, "", "rollout"], [151, 1, 1, "", "set_extra_state"], [151, 1, 1, "", "set_seed"], [151, 1, 1, "", "set_spec_lock_"], [151, 1, 1, "", "set_submodule"], [151, 2, 1, "", "shape"], [151, 1, 1, "", "share_memory"], [151, 1, 1, "", "shutdown"], [151, 2, 1, "", "specs"], [151, 1, 1, "", "state_dict"], [151, 2, 1, "", "state_keys"], [151, 2, 1, "", "state_spec"], [151, 2, 1, "", "state_spec_unbatched"], [151, 1, 1, "", "step"], [151, 1, 1, "", "step_and_maybe_reset"], [151, 1, 1, "", "step_mdp"], [151, 1, 1, "", "to"], [151, 1, 1, "", "to_empty"], [151, 1, 1, "", "train"], [151, 1, 1, "", "type"], [151, 1, 1, "", "xpu"], [151, 1, 1, "", "zero_grad"]], "torchrl.envs.SerialEnv": [[156, 2, 1, "", "action_key"], [156, 2, 1, "", "action_keys"], [156, 2, 1, "", "action_spec"], [156, 2, 1, "", "action_spec_unbatched"], [156, 1, 1, "", "add_module"], [156, 1, 1, "", "add_truncated_keys"], [156, 1, 1, "", "all_actions"], [156, 1, 1, "", "any_done"], [156, 1, 1, "", "append_transform"], [156, 1, 1, "", "apply"], [156, 1, 1, "", "auto_specs_"], [156, 2, 1, "", "batch_dims"], [156, 2, 1, "", "batch_locked"], [156, 2, 1, "", "batch_size"], [156, 1, 1, "", "bfloat16"], [156, 1, 1, "", "buffers"], [156, 1, 1, "", "cardinality"], [156, 1, 1, "", "check_env_specs"], [156, 1, 1, "", "children"], [156, 2, 1, "", "collector"], [156, 1, 1, "", "compile"], [156, 1, 1, "", "cpu"], [156, 1, 1, "", "cuda"], [156, 2, 1, "", "done_key"], [156, 2, 1, "", "done_keys"], [156, 2, 1, "", "done_keys_groups"], [156, 2, 1, "", "done_spec"], [156, 2, 1, "", "done_spec_unbatched"], [156, 1, 1, "", "double"], [156, 1, 1, "", "empty_cache"], [156, 1, 1, "", "eval"], [156, 1, 1, "", "extra_repr"], [156, 1, 1, "", "fake_tensordict"], [156, 1, 1, "", "float"], [156, 1, 1, "", "forward"], [156, 2, 1, "", "full_action_spec"], [156, 2, 1, "", "full_action_spec_unbatched"], [156, 2, 1, "", "full_done_spec"], [156, 2, 1, "", "full_done_spec_unbatched"], [156, 2, 1, "", "full_observation_spec_unbatched"], [156, 2, 1, "", "full_reward_spec"], [156, 2, 1, "", "full_reward_spec_unbatched"], [156, 2, 1, "", "full_state_spec"], [156, 2, 1, "", "full_state_spec_unbatched"], [156, 1, 1, "", "get_buffer"], [156, 1, 1, "", "get_extra_state"], [156, 1, 1, "", "get_parameter"], [156, 1, 1, "", "get_submodule"], [156, 1, 1, "", "half"], [156, 2, 1, "", "input_spec"], [156, 2, 1, "", "input_spec_unbatched"], [156, 1, 1, "", "ipu"], [156, 2, 1, "", "is_spec_locked"], [156, 1, 1, "", "load_state_dict"], [156, 1, 1, "", "maybe_reset"], [156, 1, 1, "", "modules"], [156, 1, 1, "", "mtia"], [156, 1, 1, "", "named_buffers"], [156, 1, 1, "", "named_children"], [156, 1, 1, "", "named_modules"], [156, 1, 1, "", "named_parameters"], [156, 2, 1, "", "observation_keys"], [156, 2, 1, "", "observation_spec"], [156, 2, 1, "", "observation_spec_unbatched"], [156, 2, 1, "", "output_spec"], [156, 2, 1, "", "output_spec_unbatched"], [156, 1, 1, "", "parameters"], [156, 1, 1, "", "rand_action"], [156, 1, 1, "", "rand_step"], [156, 1, 1, "", "register_backward_hook"], [156, 1, 1, "", "register_buffer"], [156, 1, 1, "", "register_collector"], [156, 1, 1, "", "register_forward_hook"], [156, 1, 1, "", "register_forward_pre_hook"], [156, 1, 1, "", "register_full_backward_hook"], [156, 1, 1, "", "register_full_backward_pre_hook"], [156, 1, 1, "", "register_gym"], [156, 1, 1, "", "register_load_state_dict_post_hook"], [156, 1, 1, "", "register_load_state_dict_pre_hook"], [156, 1, 1, "", "register_module"], [156, 1, 1, "", "register_parameter"], [156, 1, 1, "", "register_state_dict_post_hook"], [156, 1, 1, "", "register_state_dict_pre_hook"], [156, 1, 1, "", "requires_grad_"], [156, 1, 1, "", "reset"], [156, 2, 1, "", "reset_keys"], [156, 2, 1, "", "reward_key"], [156, 2, 1, "", "reward_keys"], [156, 2, 1, "", "reward_spec"], [156, 2, 1, "", "reward_spec_unbatched"], [156, 1, 1, "", "rollout"], [156, 1, 1, "", "set_extra_state"], [156, 1, 1, "", "set_seed"], [156, 1, 1, "", "set_spec_lock_"], [156, 1, 1, "", "set_submodule"], [156, 2, 1, "", "shape"], [156, 1, 1, "", "share_memory"], [156, 2, 1, "", "specs"], [156, 1, 1, "", "state_dict"], [156, 2, 1, "", "state_keys"], [156, 2, 1, "", "state_spec"], [156, 2, 1, "", "state_spec_unbatched"], [156, 1, 1, "", "step"], [156, 1, 1, "", "step_and_maybe_reset"], [156, 1, 1, "", "step_mdp"], [156, 1, 1, "", "to"], [156, 1, 1, "", "to_empty"], [156, 1, 1, "", "train"], [156, 1, 1, "", "type"], [156, 1, 1, "", "update_kwargs"], [156, 1, 1, "", "xpu"], [156, 1, 1, "", "zero_grad"]], "torchrl.envs.ThreadingAsyncEnvPool": [[157, 1, 1, "", "_setup"], [157, 2, 1, "", "action_key"], [157, 2, 1, "", "action_keys"], [157, 2, 1, "", "action_spec"], [157, 2, 1, "", "action_spec_unbatched"], [157, 1, 1, "", "add_module"], [157, 1, 1, "", "add_truncated_keys"], [157, 1, 1, "", "all_actions"], [157, 1, 1, "", "any_done"], [157, 1, 1, "", "append_transform"], [157, 1, 1, "", "apply"], [157, 1, 1, "", "async_reset_recv"], [157, 1, 1, "", "async_reset_send"], [157, 1, 1, "", "async_step_recv"], [157, 1, 1, "", "async_step_send"], [157, 1, 1, "", "auto_specs_"], [157, 2, 1, "", "batch_dims"], [157, 2, 1, "", "batch_locked"], [157, 2, 1, "", "batch_size"], [157, 1, 1, "", "bfloat16"], [157, 1, 1, "", "buffers"], [157, 1, 1, "", "cardinality"], [157, 1, 1, "", "check_env_specs"], [157, 1, 1, "", "children"], [157, 2, 1, "", "collector"], [157, 1, 1, "", "compile"], [157, 1, 1, "", "cpu"], [157, 1, 1, "", "cuda"], [157, 2, 1, "", "done_key"], [157, 2, 1, "", "done_keys"], [157, 2, 1, "", "done_keys_groups"], [157, 2, 1, "", "done_spec"], [157, 2, 1, "", "done_spec_unbatched"], [157, 1, 1, "", "double"], [157, 1, 1, "", "empty_cache"], [157, 2, 1, "", "env_batch_sizes"], [157, 1, 1, "", "eval"], [157, 1, 1, "", "extra_repr"], [157, 1, 1, "", "fake_tensordict"], [157, 1, 1, "", "float"], [157, 1, 1, "", "forward"], [157, 2, 1, "", "full_action_spec"], [157, 2, 1, "", "full_action_spec_unbatched"], [157, 2, 1, "", "full_done_spec"], [157, 2, 1, "", "full_done_spec_unbatched"], [157, 2, 1, "", "full_observation_spec_unbatched"], [157, 2, 1, "", "full_reward_spec"], [157, 2, 1, "", "full_reward_spec_unbatched"], [157, 2, 1, "", "full_state_spec"], [157, 2, 1, "", "full_state_spec_unbatched"], [157, 1, 1, "", "get_buffer"], [157, 1, 1, "", "get_extra_state"], [157, 1, 1, "", "get_parameter"], [157, 1, 1, "", "get_submodule"], [157, 1, 1, "", "half"], [157, 2, 1, "", "input_spec"], [157, 2, 1, "", "input_spec_unbatched"], [157, 1, 1, "", "ipu"], [157, 2, 1, "", "is_spec_locked"], [157, 1, 1, "", "load_state_dict"], [157, 1, 1, "", "maybe_reset"], [157, 1, 1, "", "modules"], [157, 1, 1, "", "mtia"], [157, 1, 1, "", "named_buffers"], [157, 1, 1, "", "named_children"], [157, 1, 1, "", "named_modules"], [157, 1, 1, "", "named_parameters"], [157, 2, 1, "", "observation_keys"], [157, 2, 1, "", "observation_spec"], [157, 2, 1, "", "observation_spec_unbatched"], [157, 2, 1, "", "output_spec"], [157, 2, 1, "", "output_spec_unbatched"], [157, 1, 1, "", "parameters"], [157, 1, 1, "", "rand_action"], [157, 1, 1, "", "rand_step"], [157, 1, 1, "", "register_backward_hook"], [157, 1, 1, "", "register_buffer"], [157, 1, 1, "", "register_collector"], [157, 1, 1, "", "register_forward_hook"], [157, 1, 1, "", "register_forward_pre_hook"], [157, 1, 1, "", "register_full_backward_hook"], [157, 1, 1, "", "register_full_backward_pre_hook"], [157, 1, 1, "", "register_gym"], [157, 1, 1, "", "register_load_state_dict_post_hook"], [157, 1, 1, "", "register_load_state_dict_pre_hook"], [157, 1, 1, "", "register_module"], [157, 1, 1, "", "register_parameter"], [157, 1, 1, "", "register_state_dict_post_hook"], [157, 1, 1, "", "register_state_dict_pre_hook"], [157, 1, 1, "", "requires_grad_"], [157, 1, 1, "", "reset"], [157, 2, 1, "", "reset_keys"], [157, 2, 1, "", "reward_key"], [157, 2, 1, "", "reward_keys"], [157, 2, 1, "", "reward_spec"], [157, 2, 1, "", "reward_spec_unbatched"], [157, 1, 1, "", "rollout"], [157, 1, 1, "", "set_extra_state"], [157, 1, 1, "", "set_seed"], [157, 1, 1, "", "set_spec_lock_"], [157, 1, 1, "", "set_submodule"], [157, 2, 1, "", "shape"], [157, 1, 1, "", "share_memory"], [157, 1, 1, "", "shutdown"], [157, 2, 1, "", "specs"], [157, 1, 1, "", "state_dict"], [157, 2, 1, "", "state_keys"], [157, 2, 1, "", "state_spec"], [157, 2, 1, "", "state_spec_unbatched"], [157, 1, 1, "", "step"], [157, 1, 1, "", "step_and_maybe_reset"], [157, 1, 1, "", "step_mdp"], [157, 1, 1, "", "to"], [157, 1, 1, "", "to_empty"], [157, 1, 1, "", "train"], [157, 1, 1, "", "type"], [157, 1, 1, "", "xpu"], [157, 1, 1, "", "zero_grad"]], "torchrl.envs.TicTacToeEnv": [[158, 2, 1, "", "action_key"], [158, 2, 1, "", "action_keys"], [158, 2, 1, "", "action_spec"], [158, 2, 1, "", "action_spec_unbatched"], [158, 1, 1, "", "add_module"], [158, 1, 1, "", "add_truncated_keys"], [158, 1, 1, "", "all_actions"], [158, 1, 1, "", "any_done"], [158, 1, 1, "", "append_transform"], [158, 1, 1, "", "apply"], [158, 1, 1, "", "auto_specs_"], [158, 2, 1, "", "batch_dims"], [158, 2, 1, "", "batch_size"], [158, 1, 1, "", "bfloat16"], [158, 1, 1, "", "buffers"], [158, 1, 1, "", "cardinality"], [158, 1, 1, "", "check_env_specs"], [158, 1, 1, "", "children"], [158, 2, 1, "", "collector"], [158, 1, 1, "", "compile"], [158, 1, 1, "", "cpu"], [158, 1, 1, "", "cuda"], [158, 2, 1, "", "done_key"], [158, 2, 1, "", "done_keys"], [158, 2, 1, "", "done_keys_groups"], [158, 2, 1, "", "done_spec"], [158, 2, 1, "", "done_spec_unbatched"], [158, 1, 1, "", "double"], [158, 1, 1, "", "empty_cache"], [158, 1, 1, "", "eval"], [158, 1, 1, "", "extra_repr"], [158, 1, 1, "", "fake_tensordict"], [158, 1, 1, "", "float"], [158, 1, 1, "", "forward"], [158, 2, 1, "", "full_action_spec"], [158, 2, 1, "", "full_action_spec_unbatched"], [158, 2, 1, "", "full_done_spec"], [158, 2, 1, "", "full_done_spec_unbatched"], [158, 2, 1, "", "full_observation_spec_unbatched"], [158, 2, 1, "", "full_reward_spec"], [158, 2, 1, "", "full_reward_spec_unbatched"], [158, 2, 1, "", "full_state_spec"], [158, 2, 1, "", "full_state_spec_unbatched"], [158, 1, 1, "", "get_buffer"], [158, 1, 1, "", "get_extra_state"], [158, 1, 1, "", "get_parameter"], [158, 1, 1, "", "get_submodule"], [158, 1, 1, "", "half"], [158, 2, 1, "", "input_spec"], [158, 2, 1, "", "input_spec_unbatched"], [158, 1, 1, "", "ipu"], [158, 2, 1, "", "is_spec_locked"], [158, 1, 1, "", "load_state_dict"], [158, 1, 1, "", "maybe_reset"], [158, 1, 1, "", "modules"], [158, 1, 1, "", "mtia"], [158, 1, 1, "", "named_buffers"], [158, 1, 1, "", "named_children"], [158, 1, 1, "", "named_modules"], [158, 1, 1, "", "named_parameters"], [158, 2, 1, "", "observation_keys"], [158, 2, 1, "", "observation_spec"], [158, 2, 1, "", "observation_spec_unbatched"], [158, 2, 1, "", "output_spec"], [158, 2, 1, "", "output_spec_unbatched"], [158, 1, 1, "", "parameters"], [158, 1, 1, "", "rand_action"], [158, 1, 1, "", "rand_step"], [158, 1, 1, "", "register_backward_hook"], [158, 1, 1, "", "register_buffer"], [158, 1, 1, "", "register_collector"], [158, 1, 1, "", "register_forward_hook"], [158, 1, 1, "", "register_forward_pre_hook"], [158, 1, 1, "", "register_full_backward_hook"], [158, 1, 1, "", "register_full_backward_pre_hook"], [158, 1, 1, "", "register_gym"], [158, 1, 1, "", "register_load_state_dict_post_hook"], [158, 1, 1, "", "register_load_state_dict_pre_hook"], [158, 1, 1, "", "register_module"], [158, 1, 1, "", "register_parameter"], [158, 1, 1, "", "register_state_dict_post_hook"], [158, 1, 1, "", "register_state_dict_pre_hook"], [158, 1, 1, "", "requires_grad_"], [158, 1, 1, "", "reset"], [158, 2, 1, "", "reset_keys"], [158, 2, 1, "", "reward_key"], [158, 2, 1, "", "reward_keys"], [158, 2, 1, "", "reward_spec"], [158, 2, 1, "", "reward_spec_unbatched"], [158, 1, 1, "", "rollout"], [158, 1, 1, "", "set_extra_state"], [158, 1, 1, "", "set_seed"], [158, 1, 1, "", "set_spec_lock_"], [158, 1, 1, "", "set_submodule"], [158, 2, 1, "", "shape"], [158, 1, 1, "", "share_memory"], [158, 2, 1, "", "specs"], [158, 1, 1, "", "state_dict"], [158, 2, 1, "", "state_keys"], [158, 2, 1, "", "state_spec"], [158, 2, 1, "", "state_spec_unbatched"], [158, 1, 1, "", "step"], [158, 1, 1, "", "step_and_maybe_reset"], [158, 1, 1, "", "step_mdp"], [158, 1, 1, "", "to"], [158, 1, 1, "", "to_empty"], [158, 1, 1, "", "train"], [158, 1, 1, "", "type"], [158, 1, 1, "", "xpu"], [158, 1, 1, "", "zero_grad"]], "torchrl.envs.llm": [[168, 0, 1, "", "ChatEnv"], [169, 0, 1, "", "DatasetChatEnv"], [170, 0, 1, "", "GSM8KEnv"], [171, 0, 1, "", "GSM8KPrepareQuestion"], [172, 0, 1, "", "GSM8KRewardParser"], [173, 0, 1, "", "IFEvalEnv"], [174, 0, 1, "", "IFEvalScoreData"], [175, 0, 1, "", "IfEvalScorer"], [176, 0, 1, "", "LLMEnv"], [177, 0, 1, "", "LLMHashingEnv"], [178, 0, 1, "", "MLGymWrapper"], [179, 0, 1, "", "make_gsm8k_env"], [180, 0, 1, "", "make_mlgym"]], "torchrl.envs.llm.ChatEnv": [[168, 2, 1, "", "action_key"], [168, 2, 1, "", "action_keys"], [168, 2, 1, "", "action_spec"], [168, 2, 1, "", "action_spec_unbatched"], [168, 1, 1, "", "add_module"], [168, 1, 1, "", "add_truncated_keys"], [168, 1, 1, "", "all_actions"], [168, 1, 1, "", "any_done"], [168, 1, 1, "", "append_transform"], [168, 1, 1, "", "apply"], [168, 1, 1, "", "auto_specs_"], [168, 2, 1, "", "batch_dims"], [168, 2, 1, "", "batch_locked"], [168, 2, 1, "", "batch_size"], [168, 1, 1, "", "bfloat16"], [168, 1, 1, "", "buffers"], [168, 1, 1, "", "cardinality"], [168, 1, 1, "", "check_env_specs"], [168, 1, 1, "", "children"], [168, 2, 1, "", "collector"], [168, 1, 1, "", "compile"], [168, 1, 1, "", "cpu"], [168, 1, 1, "", "cuda"], [168, 2, 1, "", "done_key"], [168, 2, 1, "", "done_keys"], [168, 2, 1, "", "done_keys_groups"], [168, 2, 1, "", "done_spec"], [168, 2, 1, "", "done_spec_unbatched"], [168, 1, 1, "", "double"], [168, 1, 1, "", "empty_cache"], [168, 1, 1, "", "eval"], [168, 1, 1, "", "extra_repr"], [168, 1, 1, "", "fake_tensordict"], [168, 1, 1, "", "float"], [168, 1, 1, "", "forward"], [168, 1, 1, "", "from_dataloader"], [168, 2, 1, "", "full_action_spec"], [168, 2, 1, "", "full_action_spec_unbatched"], [168, 2, 1, "", "full_done_spec"], [168, 2, 1, "", "full_done_spec_unbatched"], [168, 2, 1, "", "full_observation_spec_unbatched"], [168, 2, 1, "", "full_reward_spec"], [168, 2, 1, "", "full_reward_spec_unbatched"], [168, 2, 1, "", "full_state_spec"], [168, 2, 1, "", "full_state_spec_unbatched"], [168, 1, 1, "", "get_buffer"], [168, 1, 1, "", "get_extra_state"], [168, 1, 1, "", "get_parameter"], [168, 1, 1, "", "get_submodule"], [168, 1, 1, "", "half"], [168, 2, 1, "", "input_spec"], [168, 2, 1, "", "input_spec_unbatched"], [168, 1, 1, "", "ipu"], [168, 2, 1, "", "is_spec_locked"], [168, 1, 1, "", "load_state_dict"], [168, 1, 1, "", "maybe_reset"], [168, 1, 1, "", "modules"], [168, 1, 1, "", "mtia"], [168, 1, 1, "", "named_buffers"], [168, 1, 1, "", "named_children"], [168, 1, 1, "", "named_modules"], [168, 1, 1, "", "named_parameters"], [168, 2, 1, "", "observation_keys"], [168, 2, 1, "", "observation_spec"], [168, 2, 1, "", "observation_spec_unbatched"], [168, 2, 1, "", "output_spec"], [168, 2, 1, "", "output_spec_unbatched"], [168, 1, 1, "", "parameters"], [168, 1, 1, "", "rand_action"], [168, 1, 1, "", "rand_step"], [168, 1, 1, "", "register_backward_hook"], [168, 1, 1, "", "register_buffer"], [168, 1, 1, "", "register_collector"], [168, 1, 1, "", "register_forward_hook"], [168, 1, 1, "", "register_forward_pre_hook"], [168, 1, 1, "", "register_full_backward_hook"], [168, 1, 1, "", "register_full_backward_pre_hook"], [168, 1, 1, "", "register_gym"], [168, 1, 1, "", "register_load_state_dict_post_hook"], [168, 1, 1, "", "register_load_state_dict_pre_hook"], [168, 1, 1, "", "register_module"], [168, 1, 1, "", "register_parameter"], [168, 1, 1, "", "register_state_dict_post_hook"], [168, 1, 1, "", "register_state_dict_pre_hook"], [168, 1, 1, "", "requires_grad_"], [168, 1, 1, "id0", "reset"], [168, 2, 1, "", "reset_keys"], [168, 2, 1, "", "reward_key"], [168, 2, 1, "", "reward_keys"], [168, 2, 1, "", "reward_spec"], [168, 2, 1, "", "reward_spec_unbatched"], [168, 1, 1, "", "rollout"], [168, 1, 1, "", "set_extra_state"], [168, 1, 1, "", "set_seed"], [168, 1, 1, "", "set_spec_lock_"], [168, 1, 1, "", "set_submodule"], [168, 2, 1, "", "shape"], [168, 1, 1, "", "share_memory"], [168, 2, 1, "", "specs"], [168, 1, 1, "", "state_dict"], [168, 2, 1, "", "state_keys"], [168, 2, 1, "", "state_spec"], [168, 2, 1, "", "state_spec_unbatched"], [168, 1, 1, "id1", "step"], [168, 1, 1, "", "step_and_maybe_reset"], [168, 1, 1, "", "step_mdp"], [168, 1, 1, "", "to"], [168, 1, 1, "", "to_empty"], [168, 1, 1, "", "train"], [168, 1, 1, "", "type"], [168, 1, 1, "", "xpu"], [168, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.DatasetChatEnv": [[169, 2, 1, "", "action_key"], [169, 2, 1, "", "action_keys"], [169, 2, 1, "", "action_spec"], [169, 2, 1, "", "action_spec_unbatched"], [169, 1, 1, "", "add_module"], [169, 1, 1, "", "add_truncated_keys"], [169, 1, 1, "", "all_actions"], [169, 1, 1, "", "any_done"], [169, 1, 1, "", "append_transform"], [169, 1, 1, "", "apply"], [169, 1, 1, "", "auto_specs_"], [169, 2, 1, "", "batch_dims"], [169, 2, 1, "", "batch_locked"], [169, 2, 1, "", "batch_size"], [169, 1, 1, "", "bfloat16"], [169, 1, 1, "", "buffers"], [169, 1, 1, "", "cardinality"], [169, 1, 1, "", "check_env_specs"], [169, 1, 1, "", "children"], [169, 2, 1, "", "collector"], [169, 1, 1, "", "compile"], [169, 1, 1, "", "cpu"], [169, 1, 1, "", "cuda"], [169, 2, 1, "", "done_key"], [169, 2, 1, "", "done_keys"], [169, 2, 1, "", "done_keys_groups"], [169, 2, 1, "", "done_spec"], [169, 2, 1, "", "done_spec_unbatched"], [169, 1, 1, "", "double"], [169, 1, 1, "", "empty_cache"], [169, 1, 1, "", "eval"], [169, 1, 1, "", "extra_repr"], [169, 1, 1, "", "fake_tensordict"], [169, 1, 1, "", "float"], [169, 1, 1, "", "forward"], [169, 1, 1, "", "from_dataloader"], [169, 2, 1, "", "full_action_spec"], [169, 2, 1, "", "full_action_spec_unbatched"], [169, 2, 1, "", "full_done_spec"], [169, 2, 1, "", "full_done_spec_unbatched"], [169, 2, 1, "", "full_observation_spec_unbatched"], [169, 2, 1, "", "full_reward_spec"], [169, 2, 1, "", "full_reward_spec_unbatched"], [169, 2, 1, "", "full_state_spec"], [169, 2, 1, "", "full_state_spec_unbatched"], [169, 1, 1, "", "get_buffer"], [169, 1, 1, "", "get_extra_state"], [169, 1, 1, "", "get_parameter"], [169, 1, 1, "", "get_submodule"], [169, 1, 1, "", "half"], [169, 2, 1, "", "input_spec"], [169, 2, 1, "", "input_spec_unbatched"], [169, 1, 1, "", "insert_transform"], [169, 1, 1, "", "ipu"], [169, 2, 1, "", "is_spec_locked"], [169, 1, 1, "", "load_state_dict"], [169, 1, 1, "", "maybe_reset"], [169, 1, 1, "", "modules"], [169, 1, 1, "", "mtia"], [169, 1, 1, "", "named_buffers"], [169, 1, 1, "", "named_children"], [169, 1, 1, "", "named_modules"], [169, 1, 1, "", "named_parameters"], [169, 2, 1, "", "observation_keys"], [169, 2, 1, "", "observation_spec"], [169, 2, 1, "", "observation_spec_unbatched"], [169, 2, 1, "", "output_spec"], [169, 2, 1, "", "output_spec_unbatched"], [169, 1, 1, "", "parameters"], [169, 1, 1, "", "rand_action"], [169, 1, 1, "", "rand_step"], [169, 1, 1, "", "register_backward_hook"], [169, 1, 1, "", "register_buffer"], [169, 1, 1, "", "register_collector"], [169, 1, 1, "", "register_forward_hook"], [169, 1, 1, "", "register_forward_pre_hook"], [169, 1, 1, "", "register_full_backward_hook"], [169, 1, 1, "", "register_full_backward_pre_hook"], [169, 1, 1, "", "register_gym"], [169, 1, 1, "", "register_load_state_dict_post_hook"], [169, 1, 1, "", "register_load_state_dict_pre_hook"], [169, 1, 1, "", "register_module"], [169, 1, 1, "", "register_parameter"], [169, 1, 1, "", "register_state_dict_post_hook"], [169, 1, 1, "", "register_state_dict_pre_hook"], [169, 1, 1, "", "requires_grad_"], [169, 1, 1, "", "reset"], [169, 1, 1, "", "reset_dataloader"], [169, 2, 1, "", "reset_keys"], [169, 2, 1, "", "reward_key"], [169, 2, 1, "", "reward_keys"], [169, 2, 1, "", "reward_spec"], [169, 2, 1, "", "reward_spec_unbatched"], [169, 1, 1, "", "rollout"], [169, 1, 1, "", "set_extra_state"], [169, 1, 1, "", "set_missing_tolerance"], [169, 1, 1, "", "set_seed"], [169, 1, 1, "", "set_spec_lock_"], [169, 1, 1, "", "set_submodule"], [169, 2, 1, "", "shape"], [169, 1, 1, "", "share_memory"], [169, 2, 1, "", "specs"], [169, 1, 1, "", "state_dict"], [169, 2, 1, "", "state_keys"], [169, 2, 1, "", "state_spec"], [169, 2, 1, "", "state_spec_unbatched"], [169, 1, 1, "", "step"], [169, 1, 1, "", "step_and_maybe_reset"], [169, 1, 1, "", "step_mdp"], [169, 1, 1, "", "to"], [169, 1, 1, "", "to_empty"], [169, 1, 1, "", "train"], [169, 1, 1, "", "type"], [169, 1, 1, "", "xpu"], [169, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KEnv": [[170, 2, 1, "", "action_key"], [170, 2, 1, "", "action_keys"], [170, 2, 1, "", "action_spec"], [170, 2, 1, "", "action_spec_unbatched"], [170, 1, 1, "", "add_module"], [170, 1, 1, "", "add_truncated_keys"], [170, 1, 1, "", "all_actions"], [170, 1, 1, "", "any_done"], [170, 1, 1, "", "append_transform"], [170, 1, 1, "", "apply"], [170, 1, 1, "", "auto_specs_"], [170, 2, 1, "", "batch_dims"], [170, 2, 1, "", "batch_locked"], [170, 2, 1, "", "batch_size"], [170, 1, 1, "", "bfloat16"], [170, 1, 1, "", "buffers"], [170, 1, 1, "", "cardinality"], [170, 1, 1, "", "check_env_specs"], [170, 1, 1, "", "children"], [170, 2, 1, "", "collector"], [170, 1, 1, "", "compile"], [170, 1, 1, "", "cpu"], [170, 1, 1, "", "cuda"], [170, 2, 1, "", "done_key"], [170, 2, 1, "", "done_keys"], [170, 2, 1, "", "done_keys_groups"], [170, 2, 1, "", "done_spec"], [170, 2, 1, "", "done_spec_unbatched"], [170, 1, 1, "", "double"], [170, 1, 1, "", "empty_cache"], [170, 1, 1, "", "eval"], [170, 1, 1, "", "extra_repr"], [170, 1, 1, "", "fake_tensordict"], [170, 1, 1, "", "float"], [170, 1, 1, "", "forward"], [170, 1, 1, "", "from_dataloader"], [170, 2, 1, "", "full_action_spec"], [170, 2, 1, "", "full_action_spec_unbatched"], [170, 2, 1, "", "full_done_spec"], [170, 2, 1, "", "full_done_spec_unbatched"], [170, 2, 1, "", "full_observation_spec_unbatched"], [170, 2, 1, "", "full_reward_spec"], [170, 2, 1, "", "full_reward_spec_unbatched"], [170, 2, 1, "", "full_state_spec"], [170, 2, 1, "", "full_state_spec_unbatched"], [170, 1, 1, "", "get_buffer"], [170, 1, 1, "", "get_extra_state"], [170, 1, 1, "", "get_parameter"], [170, 1, 1, "", "get_submodule"], [170, 1, 1, "", "half"], [170, 2, 1, "", "input_spec"], [170, 2, 1, "", "input_spec_unbatched"], [170, 1, 1, "", "insert_transform"], [170, 1, 1, "", "ipu"], [170, 2, 1, "", "is_spec_locked"], [170, 1, 1, "", "load_state_dict"], [170, 1, 1, "", "maybe_reset"], [170, 1, 1, "", "modules"], [170, 1, 1, "", "mtia"], [170, 1, 1, "", "named_buffers"], [170, 1, 1, "", "named_children"], [170, 1, 1, "", "named_modules"], [170, 1, 1, "", "named_parameters"], [170, 2, 1, "", "observation_keys"], [170, 2, 1, "", "observation_spec"], [170, 2, 1, "", "observation_spec_unbatched"], [170, 2, 1, "", "output_spec"], [170, 2, 1, "", "output_spec_unbatched"], [170, 1, 1, "", "parameters"], [170, 1, 1, "", "rand_action"], [170, 1, 1, "", "rand_step"], [170, 1, 1, "", "register_backward_hook"], [170, 1, 1, "", "register_buffer"], [170, 1, 1, "", "register_collector"], [170, 1, 1, "", "register_forward_hook"], [170, 1, 1, "", "register_forward_pre_hook"], [170, 1, 1, "", "register_full_backward_hook"], [170, 1, 1, "", "register_full_backward_pre_hook"], [170, 1, 1, "", "register_gym"], [170, 1, 1, "", "register_load_state_dict_post_hook"], [170, 1, 1, "", "register_load_state_dict_pre_hook"], [170, 1, 1, "", "register_module"], [170, 1, 1, "", "register_parameter"], [170, 1, 1, "", "register_state_dict_post_hook"], [170, 1, 1, "", "register_state_dict_pre_hook"], [170, 1, 1, "", "requires_grad_"], [170, 1, 1, "", "reset"], [170, 1, 1, "", "reset_dataloader"], [170, 2, 1, "", "reset_keys"], [170, 2, 1, "", "reward_key"], [170, 2, 1, "", "reward_keys"], [170, 2, 1, "", "reward_spec"], [170, 2, 1, "", "reward_spec_unbatched"], [170, 1, 1, "", "rollout"], [170, 1, 1, "", "set_extra_state"], [170, 1, 1, "", "set_missing_tolerance"], [170, 1, 1, "", "set_seed"], [170, 1, 1, "", "set_spec_lock_"], [170, 1, 1, "", "set_submodule"], [170, 2, 1, "", "shape"], [170, 1, 1, "", "share_memory"], [170, 2, 1, "", "specs"], [170, 1, 1, "", "state_dict"], [170, 2, 1, "", "state_keys"], [170, 2, 1, "", "state_spec"], [170, 2, 1, "", "state_spec_unbatched"], [170, 1, 1, "", "step"], [170, 1, 1, "", "step_and_maybe_reset"], [170, 1, 1, "", "step_mdp"], [170, 1, 1, "", "to"], [170, 1, 1, "", "to_empty"], [170, 1, 1, "", "train"], [170, 1, 1, "", "type"], [170, 1, 1, "", "xpu"], [170, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KPrepareQuestion": [[171, 1, 1, "", "add_module"], [171, 1, 1, "", "apply"], [171, 1, 1, "", "bfloat16"], [171, 1, 1, "", "buffers"], [171, 1, 1, "", "children"], [171, 1, 1, "", "close"], [171, 2, 1, "", "collector"], [171, 1, 1, "", "compile"], [171, 2, 1, "", "container"], [171, 1, 1, "", "cpu"], [171, 1, 1, "", "cuda"], [171, 1, 1, "", "double"], [171, 1, 1, "", "eval"], [171, 1, 1, "", "extra_repr"], [171, 1, 1, "", "float"], [171, 1, 1, "", "forward"], [171, 1, 1, "", "get_buffer"], [171, 1, 1, "", "get_extra_state"], [171, 1, 1, "", "get_parameter"], [171, 1, 1, "", "get_submodule"], [171, 1, 1, "", "half"], [171, 1, 1, "", "init"], [171, 1, 1, "", "inv"], [171, 1, 1, "", "ipu"], [171, 1, 1, "", "load_state_dict"], [171, 1, 1, "", "modules"], [171, 1, 1, "", "mtia"], [171, 1, 1, "", "named_buffers"], [171, 1, 1, "", "named_children"], [171, 1, 1, "", "named_modules"], [171, 1, 1, "", "named_parameters"], [171, 1, 1, "", "parameters"], [171, 2, 1, "", "parent"], [171, 1, 1, "", "register_backward_hook"], [171, 1, 1, "", "register_buffer"], [171, 1, 1, "", "register_forward_hook"], [171, 1, 1, "", "register_forward_pre_hook"], [171, 1, 1, "", "register_full_backward_hook"], [171, 1, 1, "", "register_full_backward_pre_hook"], [171, 1, 1, "", "register_load_state_dict_post_hook"], [171, 1, 1, "", "register_load_state_dict_pre_hook"], [171, 1, 1, "", "register_module"], [171, 1, 1, "", "register_parameter"], [171, 1, 1, "", "register_state_dict_post_hook"], [171, 1, 1, "", "register_state_dict_pre_hook"], [171, 1, 1, "", "requires_grad_"], [171, 1, 1, "", "set_extra_state"], [171, 1, 1, "", "set_submodule"], [171, 1, 1, "", "share_memory"], [171, 1, 1, "", "state_dict"], [171, 1, 1, "", "to"], [171, 1, 1, "", "to_empty"], [171, 1, 1, "", "train"], [171, 1, 1, "", "transform_action_spec"], [171, 1, 1, "", "transform_done_spec"], [171, 1, 1, "", "transform_env_batch_size"], [171, 1, 1, "", "transform_env_device"], [171, 1, 1, "", "transform_input_spec"], [171, 1, 1, "", "transform_observation_spec"], [171, 1, 1, "", "transform_output_spec"], [171, 1, 1, "", "transform_reward_spec"], [171, 1, 1, "", "transform_state_spec"], [171, 1, 1, "", "type"], [171, 1, 1, "", "xpu"], [171, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KRewardParser": [[172, 1, 1, "", "add_module"], [172, 1, 1, "", "apply"], [172, 1, 1, "", "bfloat16"], [172, 1, 1, "", "buffers"], [172, 1, 1, "", "children"], [172, 1, 1, "", "close"], [172, 2, 1, "", "collector"], [172, 1, 1, "", "compile"], [172, 2, 1, "", "container"], [172, 1, 1, "", "cpu"], [172, 1, 1, "", "cuda"], [172, 1, 1, "", "double"], [172, 1, 1, "", "eval"], [172, 1, 1, "", "extra_repr"], [172, 1, 1, "", "extract_tags"], [172, 1, 1, "", "float"], [172, 1, 1, "", "forward"], [172, 1, 1, "", "get_buffer"], [172, 1, 1, "", "get_extra_state"], [172, 1, 1, "", "get_parameter"], [172, 1, 1, "", "get_submodule"], [172, 1, 1, "", "half"], [172, 1, 1, "", "init"], [172, 1, 1, "", "inv"], [172, 1, 1, "", "ipu"], [172, 1, 1, "", "load_state_dict"], [172, 1, 1, "", "modules"], [172, 1, 1, "", "mtia"], [172, 1, 1, "", "named_buffers"], [172, 1, 1, "", "named_children"], [172, 1, 1, "", "named_modules"], [172, 1, 1, "", "named_parameters"], [172, 1, 1, "", "parameters"], [172, 2, 1, "", "parent"], [172, 1, 1, "", "register_backward_hook"], [172, 1, 1, "", "register_buffer"], [172, 1, 1, "", "register_forward_hook"], [172, 1, 1, "", "register_forward_pre_hook"], [172, 1, 1, "", "register_full_backward_hook"], [172, 1, 1, "", "register_full_backward_pre_hook"], [172, 1, 1, "", "register_load_state_dict_post_hook"], [172, 1, 1, "", "register_load_state_dict_pre_hook"], [172, 1, 1, "", "register_module"], [172, 1, 1, "", "register_parameter"], [172, 1, 1, "", "register_state_dict_post_hook"], [172, 1, 1, "", "register_state_dict_pre_hook"], [172, 1, 1, "", "requires_grad_"], [172, 1, 1, "", "set_extra_state"], [172, 1, 1, "", "set_submodule"], [172, 1, 1, "", "share_memory"], [172, 1, 1, "", "state_dict"], [172, 1, 1, "", "to"], [172, 1, 1, "", "to_empty"], [172, 1, 1, "", "train"], [172, 1, 1, "", "transform_action_spec"], [172, 1, 1, "", "transform_done_spec"], [172, 1, 1, "", "transform_env_batch_size"], [172, 1, 1, "", "transform_env_device"], [172, 1, 1, "", "transform_input_spec"], [172, 1, 1, "", "transform_observation_spec"], [172, 1, 1, "", "transform_output_spec"], [172, 1, 1, "", "transform_reward_spec"], [172, 1, 1, "", "transform_state_spec"], [172, 1, 1, "", "type"], [172, 1, 1, "", "xpu"], [172, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.IFEvalEnv": [[173, 2, 1, "", "action_key"], [173, 2, 1, "", "action_keys"], [173, 2, 1, "", "action_spec"], [173, 2, 1, "", "action_spec_unbatched"], [173, 1, 1, "", "add_module"], [173, 1, 1, "", "add_truncated_keys"], [173, 1, 1, "", "all_actions"], [173, 1, 1, "", "any_done"], [173, 1, 1, "", "append_transform"], [173, 1, 1, "", "apply"], [173, 1, 1, "", "auto_specs_"], [173, 2, 1, "", "batch_dims"], [173, 2, 1, "", "batch_locked"], [173, 2, 1, "", "batch_size"], [173, 1, 1, "", "bfloat16"], [173, 1, 1, "", "buffers"], [173, 1, 1, "", "cardinality"], [173, 1, 1, "", "check_env_specs"], [173, 1, 1, "", "children"], [173, 2, 1, "", "collector"], [173, 1, 1, "", "compile"], [173, 1, 1, "", "cpu"], [173, 1, 1, "", "cuda"], [173, 2, 1, "", "done_key"], [173, 2, 1, "", "done_keys"], [173, 2, 1, "", "done_keys_groups"], [173, 2, 1, "", "done_spec"], [173, 2, 1, "", "done_spec_unbatched"], [173, 1, 1, "", "double"], [173, 1, 1, "", "empty_cache"], [173, 1, 1, "", "eval"], [173, 1, 1, "", "extra_repr"], [173, 1, 1, "", "fake_tensordict"], [173, 1, 1, "", "float"], [173, 1, 1, "", "forward"], [173, 1, 1, "", "from_dataloader"], [173, 2, 1, "", "full_action_spec"], [173, 2, 1, "", "full_action_spec_unbatched"], [173, 2, 1, "", "full_done_spec"], [173, 2, 1, "", "full_done_spec_unbatched"], [173, 2, 1, "", "full_observation_spec_unbatched"], [173, 2, 1, "", "full_reward_spec"], [173, 2, 1, "", "full_reward_spec_unbatched"], [173, 2, 1, "", "full_state_spec"], [173, 2, 1, "", "full_state_spec_unbatched"], [173, 1, 1, "", "get_buffer"], [173, 1, 1, "", "get_extra_state"], [173, 1, 1, "", "get_parameter"], [173, 1, 1, "", "get_submodule"], [173, 1, 1, "", "half"], [173, 2, 1, "", "input_spec"], [173, 2, 1, "", "input_spec_unbatched"], [173, 1, 1, "", "insert_transform"], [173, 1, 1, "", "ipu"], [173, 2, 1, "", "is_spec_locked"], [173, 1, 1, "", "load_state_dict"], [173, 1, 1, "", "maybe_reset"], [173, 1, 1, "", "modules"], [173, 1, 1, "", "mtia"], [173, 1, 1, "", "named_buffers"], [173, 1, 1, "", "named_children"], [173, 1, 1, "", "named_modules"], [173, 1, 1, "", "named_parameters"], [173, 2, 1, "", "observation_keys"], [173, 2, 1, "", "observation_spec"], [173, 2, 1, "", "observation_spec_unbatched"], [173, 2, 1, "", "output_spec"], [173, 2, 1, "", "output_spec_unbatched"], [173, 1, 1, "", "parameters"], [173, 1, 1, "", "rand_action"], [173, 1, 1, "", "rand_step"], [173, 1, 1, "", "register_backward_hook"], [173, 1, 1, "", "register_buffer"], [173, 1, 1, "", "register_collector"], [173, 1, 1, "", "register_forward_hook"], [173, 1, 1, "", "register_forward_pre_hook"], [173, 1, 1, "", "register_full_backward_hook"], [173, 1, 1, "", "register_full_backward_pre_hook"], [173, 1, 1, "", "register_gym"], [173, 1, 1, "", "register_load_state_dict_post_hook"], [173, 1, 1, "", "register_load_state_dict_pre_hook"], [173, 1, 1, "", "register_module"], [173, 1, 1, "", "register_parameter"], [173, 1, 1, "", "register_state_dict_post_hook"], [173, 1, 1, "", "register_state_dict_pre_hook"], [173, 1, 1, "", "requires_grad_"], [173, 1, 1, "", "reset"], [173, 1, 1, "", "reset_dataloader"], [173, 2, 1, "", "reset_keys"], [173, 2, 1, "", "reward_key"], [173, 2, 1, "", "reward_keys"], [173, 2, 1, "", "reward_spec"], [173, 2, 1, "", "reward_spec_unbatched"], [173, 1, 1, "", "rollout"], [173, 1, 1, "", "set_extra_state"], [173, 1, 1, "", "set_missing_tolerance"], [173, 1, 1, "", "set_seed"], [173, 1, 1, "", "set_spec_lock_"], [173, 1, 1, "", "set_submodule"], [173, 2, 1, "", "shape"], [173, 1, 1, "", "share_memory"], [173, 2, 1, "", "specs"], [173, 1, 1, "", "state_dict"], [173, 2, 1, "", "state_keys"], [173, 2, 1, "", "state_spec"], [173, 2, 1, "", "state_spec_unbatched"], [173, 1, 1, "", "step"], [173, 1, 1, "", "step_and_maybe_reset"], [173, 1, 1, "", "step_mdp"], [173, 1, 1, "", "to"], [173, 1, 1, "", "to_empty"], [173, 1, 1, "", "train"], [173, 1, 1, "", "type"], [173, 1, 1, "", "xpu"], [173, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.IFEvalScoreData": [[174, 1, 1, "", "cat"], [174, 2, 1, "", "device"], [174, 1, 1, "", "dumps"], [174, 1, 1, "", "fields"], [174, 1, 1, "", "from_any"], [174, 1, 1, "", "from_dataclass"], [174, 1, 1, "", "from_h5"], [174, 1, 1, "", "from_modules"], [174, 1, 1, "", "from_namedtuple"], [174, 1, 1, "", "from_pytree"], [174, 1, 1, "", "from_remote_init"], [174, 1, 1, "", "from_struct_array"], [174, 1, 1, "", "from_tensordict"], [174, 1, 1, "", "from_tuple"], [174, 1, 1, "", "fromkeys"], [174, 1, 1, "", "get"], [174, 1, 1, "", "lazy_stack"], [174, 1, 1, "", "load"], [174, 1, 1, "", "load_"], [174, 1, 1, "", "load_memmap"], [174, 1, 1, "", "load_state_dict"], [174, 1, 1, "", "maybe_dense_stack"], [174, 1, 1, "", "memmap"], [174, 1, 1, "", "memmap_"], [174, 1, 1, "", "memmap_like"], [174, 1, 1, "", "memmap_refresh_"], [174, 1, 1, "", "save"], [174, 1, 1, "", "set"], [174, 1, 1, "", "stack"], [174, 1, 1, "", "state_dict"], [174, 1, 1, "", "to_tensordict"], [174, 1, 1, "", "unbind"]], "torchrl.envs.llm.IfEvalScorer": [[175, 1, 1, "", "add_module"], [175, 1, 1, "", "apply"], [175, 1, 1, "", "bfloat16"], [175, 1, 1, "", "buffers"], [175, 1, 1, "", "children"], [175, 1, 1, "", "close"], [175, 2, 1, "", "collector"], [175, 1, 1, "", "compile"], [175, 2, 1, "", "container"], [175, 1, 1, "", "cpu"], [175, 1, 1, "", "cuda"], [175, 1, 1, "", "default_reward_aggregator"], [175, 1, 1, "", "double"], [175, 1, 1, "", "eval"], [175, 1, 1, "", "extra_repr"], [175, 1, 1, "", "float"], [175, 1, 1, "", "forward"], [175, 1, 1, "", "get_buffer"], [175, 1, 1, "", "get_extra_state"], [175, 1, 1, "", "get_parameter"], [175, 1, 1, "", "get_submodule"], [175, 1, 1, "", "half"], [175, 1, 1, "", "init"], [175, 1, 1, "", "inv"], [175, 1, 1, "", "ipu"], [175, 1, 1, "", "load_state_dict"], [175, 1, 1, "", "modules"], [175, 1, 1, "", "mtia"], [175, 1, 1, "", "named_buffers"], [175, 1, 1, "", "named_children"], [175, 1, 1, "", "named_modules"], [175, 1, 1, "", "named_parameters"], [175, 1, 1, "", "parameters"], [175, 2, 1, "", "parent"], [175, 1, 1, "", "register_backward_hook"], [175, 1, 1, "", "register_buffer"], [175, 1, 1, "", "register_forward_hook"], [175, 1, 1, "", "register_forward_pre_hook"], [175, 1, 1, "", "register_full_backward_hook"], [175, 1, 1, "", "register_full_backward_pre_hook"], [175, 1, 1, "", "register_load_state_dict_post_hook"], [175, 1, 1, "", "register_load_state_dict_pre_hook"], [175, 1, 1, "", "register_module"], [175, 1, 1, "", "register_parameter"], [175, 1, 1, "", "register_state_dict_post_hook"], [175, 1, 1, "", "register_state_dict_pre_hook"], [175, 1, 1, "", "requires_grad_"], [175, 1, 1, "", "set_extra_state"], [175, 1, 1, "", "set_submodule"], [175, 1, 1, "", "share_memory"], [175, 1, 1, "", "state_dict"], [175, 1, 1, "", "to"], [175, 1, 1, "", "to_empty"], [175, 1, 1, "", "train"], [175, 1, 1, "", "transform_action_spec"], [175, 1, 1, "", "transform_done_spec"], [175, 1, 1, "", "transform_env_batch_size"], [175, 1, 1, "", "transform_env_device"], [175, 1, 1, "", "transform_input_spec"], [175, 1, 1, "", "transform_observation_spec"], [175, 1, 1, "", "transform_output_spec"], [175, 1, 1, "", "transform_reward_spec"], [175, 1, 1, "", "transform_state_spec"], [175, 1, 1, "", "type"], [175, 1, 1, "", "xpu"], [175, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.LLMEnv": [[176, 2, 1, "", "action_key"], [176, 2, 1, "", "action_keys"], [176, 2, 1, "", "action_spec"], [176, 2, 1, "", "action_spec_unbatched"], [176, 1, 1, "", "add_module"], [176, 1, 1, "", "add_truncated_keys"], [176, 1, 1, "", "all_actions"], [176, 1, 1, "", "any_done"], [176, 1, 1, "", "append_transform"], [176, 1, 1, "", "apply"], [176, 1, 1, "", "auto_specs_"], [176, 2, 1, "", "batch_dims"], [176, 2, 1, "", "batch_locked"], [176, 2, 1, "", "batch_size"], [176, 1, 1, "", "bfloat16"], [176, 1, 1, "", "buffers"], [176, 1, 1, "", "cardinality"], [176, 1, 1, "", "check_env_specs"], [176, 1, 1, "", "children"], [176, 2, 1, "", "collector"], [176, 1, 1, "", "compile"], [176, 1, 1, "", "cpu"], [176, 1, 1, "", "cuda"], [176, 2, 1, "", "done_key"], [176, 2, 1, "", "done_keys"], [176, 2, 1, "", "done_keys_groups"], [176, 2, 1, "", "done_spec"], [176, 2, 1, "", "done_spec_unbatched"], [176, 1, 1, "", "double"], [176, 1, 1, "", "empty_cache"], [176, 1, 1, "", "eval"], [176, 1, 1, "", "extra_repr"], [176, 1, 1, "", "fake_tensordict"], [176, 1, 1, "", "float"], [176, 1, 1, "", "forward"], [176, 1, 1, "id0", "from_dataloader"], [176, 2, 1, "", "full_action_spec"], [176, 2, 1, "", "full_action_spec_unbatched"], [176, 2, 1, "", "full_done_spec"], [176, 2, 1, "", "full_done_spec_unbatched"], [176, 2, 1, "", "full_observation_spec_unbatched"], [176, 2, 1, "", "full_reward_spec"], [176, 2, 1, "", "full_reward_spec_unbatched"], [176, 2, 1, "", "full_state_spec"], [176, 2, 1, "", "full_state_spec_unbatched"], [176, 1, 1, "", "get_buffer"], [176, 1, 1, "", "get_extra_state"], [176, 1, 1, "", "get_parameter"], [176, 1, 1, "", "get_submodule"], [176, 1, 1, "", "half"], [176, 2, 1, "", "input_spec"], [176, 2, 1, "", "input_spec_unbatched"], [176, 1, 1, "", "ipu"], [176, 2, 1, "", "is_spec_locked"], [176, 1, 1, "", "load_state_dict"], [176, 1, 1, "", "maybe_reset"], [176, 1, 1, "", "modules"], [176, 1, 1, "", "mtia"], [176, 1, 1, "", "named_buffers"], [176, 1, 1, "", "named_children"], [176, 1, 1, "", "named_modules"], [176, 1, 1, "", "named_parameters"], [176, 2, 1, "", "observation_keys"], [176, 2, 1, "", "observation_spec"], [176, 2, 1, "", "observation_spec_unbatched"], [176, 2, 1, "", "output_spec"], [176, 2, 1, "", "output_spec_unbatched"], [176, 1, 1, "", "parameters"], [176, 1, 1, "", "rand_action"], [176, 1, 1, "", "rand_step"], [176, 1, 1, "", "register_backward_hook"], [176, 1, 1, "", "register_buffer"], [176, 1, 1, "", "register_collector"], [176, 1, 1, "", "register_forward_hook"], [176, 1, 1, "", "register_forward_pre_hook"], [176, 1, 1, "", "register_full_backward_hook"], [176, 1, 1, "", "register_full_backward_pre_hook"], [176, 1, 1, "", "register_gym"], [176, 1, 1, "", "register_load_state_dict_post_hook"], [176, 1, 1, "", "register_load_state_dict_pre_hook"], [176, 1, 1, "", "register_module"], [176, 1, 1, "", "register_parameter"], [176, 1, 1, "", "register_state_dict_post_hook"], [176, 1, 1, "", "register_state_dict_pre_hook"], [176, 1, 1, "", "requires_grad_"], [176, 1, 1, "", "reset"], [176, 2, 1, "", "reset_keys"], [176, 2, 1, "", "reward_key"], [176, 2, 1, "", "reward_keys"], [176, 2, 1, "", "reward_spec"], [176, 2, 1, "", "reward_spec_unbatched"], [176, 1, 1, "", "rollout"], [176, 1, 1, "", "set_extra_state"], [176, 1, 1, "", "set_seed"], [176, 1, 1, "", "set_spec_lock_"], [176, 1, 1, "", "set_submodule"], [176, 2, 1, "", "shape"], [176, 1, 1, "", "share_memory"], [176, 2, 1, "", "specs"], [176, 1, 1, "", "state_dict"], [176, 2, 1, "", "state_keys"], [176, 2, 1, "", "state_spec"], [176, 2, 1, "", "state_spec_unbatched"], [176, 1, 1, "", "step"], [176, 1, 1, "", "step_and_maybe_reset"], [176, 1, 1, "", "step_mdp"], [176, 1, 1, "", "to"], [176, 1, 1, "", "to_empty"], [176, 1, 1, "", "train"], [176, 1, 1, "", "type"], [176, 1, 1, "", "xpu"], [176, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.LLMHashingEnv": [[177, 2, 1, "", "action_key"], [177, 2, 1, "", "action_keys"], [177, 2, 1, "", "action_spec"], [177, 2, 1, "", "action_spec_unbatched"], [177, 1, 1, "", "add_module"], [177, 1, 1, "", "add_truncated_keys"], [177, 1, 1, "", "all_actions"], [177, 1, 1, "", "any_done"], [177, 1, 1, "", "append_transform"], [177, 1, 1, "", "apply"], [177, 1, 1, "", "auto_specs_"], [177, 2, 1, "", "batch_dims"], [177, 2, 1, "", "batch_locked"], [177, 2, 1, "", "batch_size"], [177, 1, 1, "", "bfloat16"], [177, 1, 1, "", "buffers"], [177, 1, 1, "", "cardinality"], [177, 1, 1, "", "check_env_specs"], [177, 1, 1, "", "children"], [177, 2, 1, "", "collector"], [177, 1, 1, "", "compile"], [177, 1, 1, "", "cpu"], [177, 1, 1, "", "cuda"], [177, 2, 1, "", "done_key"], [177, 2, 1, "", "done_keys"], [177, 2, 1, "", "done_keys_groups"], [177, 2, 1, "", "done_spec"], [177, 2, 1, "", "done_spec_unbatched"], [177, 1, 1, "", "double"], [177, 1, 1, "", "empty_cache"], [177, 1, 1, "", "eval"], [177, 1, 1, "", "extra_repr"], [177, 1, 1, "", "fake_tensordict"], [177, 1, 1, "", "float"], [177, 1, 1, "", "forward"], [177, 2, 1, "", "full_action_spec"], [177, 2, 1, "", "full_action_spec_unbatched"], [177, 2, 1, "", "full_done_spec"], [177, 2, 1, "", "full_done_spec_unbatched"], [177, 2, 1, "", "full_observation_spec_unbatched"], [177, 2, 1, "", "full_reward_spec"], [177, 2, 1, "", "full_reward_spec_unbatched"], [177, 2, 1, "", "full_state_spec"], [177, 2, 1, "", "full_state_spec_unbatched"], [177, 1, 1, "", "get_buffer"], [177, 1, 1, "", "get_extra_state"], [177, 1, 1, "", "get_parameter"], [177, 1, 1, "", "get_submodule"], [177, 1, 1, "", "half"], [177, 2, 1, "", "input_spec"], [177, 2, 1, "", "input_spec_unbatched"], [177, 1, 1, "", "ipu"], [177, 2, 1, "", "is_spec_locked"], [177, 1, 1, "", "load_state_dict"], [177, 1, 1, "", "make_tensordict"], [177, 1, 1, "", "maybe_reset"], [177, 1, 1, "", "modules"], [177, 1, 1, "", "mtia"], [177, 1, 1, "", "named_buffers"], [177, 1, 1, "", "named_children"], [177, 1, 1, "", "named_modules"], [177, 1, 1, "", "named_parameters"], [177, 2, 1, "", "observation_keys"], [177, 2, 1, "", "observation_spec"], [177, 2, 1, "", "observation_spec_unbatched"], [177, 2, 1, "", "output_spec"], [177, 2, 1, "", "output_spec_unbatched"], [177, 1, 1, "", "parameters"], [177, 1, 1, "", "rand_action"], [177, 1, 1, "", "rand_step"], [177, 1, 1, "", "register_backward_hook"], [177, 1, 1, "", "register_buffer"], [177, 1, 1, "", "register_collector"], [177, 1, 1, "", "register_forward_hook"], [177, 1, 1, "", "register_forward_pre_hook"], [177, 1, 1, "", "register_full_backward_hook"], [177, 1, 1, "", "register_full_backward_pre_hook"], [177, 1, 1, "", "register_gym"], [177, 1, 1, "", "register_load_state_dict_post_hook"], [177, 1, 1, "", "register_load_state_dict_pre_hook"], [177, 1, 1, "", "register_module"], [177, 1, 1, "", "register_parameter"], [177, 1, 1, "", "register_state_dict_post_hook"], [177, 1, 1, "", "register_state_dict_pre_hook"], [177, 1, 1, "", "requires_grad_"], [177, 1, 1, "", "reset"], [177, 2, 1, "", "reset_keys"], [177, 2, 1, "", "reward_key"], [177, 2, 1, "", "reward_keys"], [177, 2, 1, "", "reward_spec"], [177, 2, 1, "", "reward_spec_unbatched"], [177, 1, 1, "", "rollout"], [177, 1, 1, "", "set_extra_state"], [177, 1, 1, "", "set_seed"], [177, 1, 1, "", "set_spec_lock_"], [177, 1, 1, "", "set_submodule"], [177, 2, 1, "", "shape"], [177, 1, 1, "", "share_memory"], [177, 2, 1, "", "specs"], [177, 1, 1, "", "state_dict"], [177, 2, 1, "", "state_keys"], [177, 2, 1, "", "state_spec"], [177, 2, 1, "", "state_spec_unbatched"], [177, 1, 1, "", "step"], [177, 1, 1, "", "step_and_maybe_reset"], [177, 1, 1, "", "step_mdp"], [177, 1, 1, "", "to"], [177, 1, 1, "", "to_empty"], [177, 1, 1, "", "train"], [177, 1, 1, "", "type"], [177, 1, 1, "", "xpu"], [177, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.MLGymWrapper": [[178, 2, 1, "", "action_key"], [178, 2, 1, "", "action_keys"], [178, 2, 1, "", "action_spec"], [178, 2, 1, "", "action_spec_unbatched"], [178, 1, 1, "", "add_module"], [178, 1, 1, "", "add_truncated_keys"], [178, 1, 1, "", "all_actions"], [178, 1, 1, "", "any_done"], [178, 1, 1, "", "append_transform"], [178, 1, 1, "", "apply"], [178, 1, 1, "", "auto_register_info_dict"], [178, 1, 1, "", "auto_specs_"], [178, 2, 1, "", "batch_dims"], [178, 2, 1, "", "batch_locked"], [178, 2, 1, "", "batch_size"], [178, 1, 1, "", "bfloat16"], [178, 1, 1, "", "buffers"], [178, 1, 1, "", "cardinality"], [178, 1, 1, "", "check_env_specs"], [178, 1, 1, "", "children"], [178, 1, 1, "", "close"], [178, 2, 1, "", "collector"], [178, 1, 1, "", "compile"], [178, 1, 1, "", "cpu"], [178, 1, 1, "", "cuda"], [178, 2, 1, "", "done_key"], [178, 2, 1, "", "done_keys"], [178, 2, 1, "", "done_keys_groups"], [178, 2, 1, "", "done_spec"], [178, 2, 1, "", "done_spec_unbatched"], [178, 1, 1, "", "double"], [178, 1, 1, "", "empty_cache"], [178, 1, 1, "", "eval"], [178, 1, 1, "", "extra_repr"], [178, 1, 1, "", "fake_tensordict"], [178, 1, 1, "", "fast_encoding"], [178, 1, 1, "", "float"], [178, 1, 1, "", "forward"], [178, 2, 1, "", "full_action_spec"], [178, 2, 1, "", "full_action_spec_unbatched"], [178, 2, 1, "", "full_done_spec"], [178, 2, 1, "", "full_done_spec_unbatched"], [178, 2, 1, "", "full_observation_spec_unbatched"], [178, 2, 1, "", "full_reward_spec"], [178, 2, 1, "", "full_reward_spec_unbatched"], [178, 2, 1, "", "full_state_spec"], [178, 2, 1, "", "full_state_spec_unbatched"], [178, 1, 1, "", "get_buffer"], [178, 1, 1, "", "get_extra_state"], [178, 1, 1, "", "get_library_name"], [178, 1, 1, "", "get_parameter"], [178, 1, 1, "", "get_submodule"], [178, 1, 1, "", "half"], [178, 2, 1, "", "input_spec"], [178, 2, 1, "", "input_spec_unbatched"], [178, 1, 1, "", "ipu"], [178, 2, 1, "", "is_spec_locked"], [178, 1, 1, "", "load_state_dict"], [178, 1, 1, "", "maybe_reset"], [178, 1, 1, "", "modules"], [178, 1, 1, "", "mtia"], [178, 1, 1, "", "named_buffers"], [178, 1, 1, "", "named_children"], [178, 1, 1, "", "named_modules"], [178, 1, 1, "", "named_parameters"], [178, 2, 1, "", "observation_keys"], [178, 2, 1, "", "observation_spec"], [178, 2, 1, "", "observation_spec_unbatched"], [178, 2, 1, "", "output_spec"], [178, 2, 1, "", "output_spec_unbatched"], [178, 1, 1, "", "parameters"], [178, 1, 1, "", "rand_action"], [178, 1, 1, "", "rand_step"], [178, 1, 1, "", "read_action"], [178, 1, 1, "", "read_done"], [178, 1, 1, "", "read_obs"], [178, 1, 1, "", "read_reward"], [178, 1, 1, "", "register_backward_hook"], [178, 1, 1, "", "register_buffer"], [178, 1, 1, "", "register_collector"], [178, 1, 1, "", "register_forward_hook"], [178, 1, 1, "", "register_forward_pre_hook"], [178, 1, 1, "", "register_full_backward_hook"], [178, 1, 1, "", "register_full_backward_pre_hook"], [178, 1, 1, "", "register_gym"], [178, 1, 1, "", "register_load_state_dict_post_hook"], [178, 1, 1, "", "register_load_state_dict_pre_hook"], [178, 1, 1, "", "register_module"], [178, 1, 1, "", "register_parameter"], [178, 1, 1, "", "register_state_dict_post_hook"], [178, 1, 1, "", "register_state_dict_pre_hook"], [178, 1, 1, "", "requires_grad_"], [178, 1, 1, "", "reset"], [178, 2, 1, "", "reset_keys"], [178, 2, 1, "", "reward_key"], [178, 2, 1, "", "reward_keys"], [178, 2, 1, "", "reward_spec"], [178, 2, 1, "", "reward_spec_unbatched"], [178, 1, 1, "", "rollout"], [178, 1, 1, "", "set_extra_state"], [178, 1, 1, "", "set_info_dict_reader"], [178, 1, 1, "", "set_seed"], [178, 1, 1, "", "set_spec_lock_"], [178, 1, 1, "", "set_submodule"], [178, 2, 1, "", "shape"], [178, 1, 1, "", "share_memory"], [178, 2, 1, "", "specs"], [178, 1, 1, "", "state_dict"], [178, 2, 1, "", "state_keys"], [178, 2, 1, "", "state_spec"], [178, 2, 1, "", "state_spec_unbatched"], [178, 1, 1, "", "step"], [178, 1, 1, "", "step_and_maybe_reset"], [178, 1, 1, "", "step_mdp"], [178, 1, 1, "", "to"], [178, 1, 1, "", "to_empty"], [178, 1, 1, "", "train"], [178, 1, 1, "", "type"], [178, 1, 1, "", "xpu"], [178, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms": [[181, 0, 1, "", "AddThinkingPrompt"], [182, 0, 1, "", "BrowserTransform"], [183, 0, 1, "", "DataLoadingPrimer"], [184, 0, 1, "", "ExecuteToolsInOrder"], [185, 0, 1, "", "JSONCallParser"], [186, 0, 1, "", "KLComputation"], [187, 0, 1, "", "KLRewardTransform"], [188, 0, 1, "", "MCPToolTransform"], [189, 0, 1, "", "PolicyVersion"], [190, 0, 1, "", "PythonExecutorService"], [191, 0, 1, "", "PythonInterpreter"], [192, 0, 1, "", "RayDataLoadingPrimer"], [193, 0, 1, "", "RetrieveKL"], [194, 0, 1, "", "RetrieveLogProb"], [195, 0, 1, "", "SimpleToolTransform"], [196, 0, 1, "", "TemplateTransform"], [197, 0, 1, "", "Tokenizer"], [198, 0, 1, "", "ToolCall"], [199, 0, 1, "", "ToolRegistry"], [200, 0, 1, "", "ToolService"], [201, 0, 1, "", "XMLBlockParser"], [202, 0, 1, "", "as_nested_tensor"], [203, 0, 1, "", "as_padded_tensor"]], "torchrl.envs.llm.transforms.AddThinkingPrompt": [[181, 1, 1, "", "add_module"], [181, 1, 1, "", "apply"], [181, 1, 1, "", "bfloat16"], [181, 1, 1, "", "buffers"], [181, 1, 1, "", "children"], [181, 1, 1, "", "close"], [181, 2, 1, "", "collector"], [181, 1, 1, "", "compile"], [181, 2, 1, "", "container"], [181, 1, 1, "", "cpu"], [181, 1, 1, "", "cuda"], [181, 1, 1, "", "double"], [181, 1, 1, "", "eval"], [181, 1, 1, "", "extra_repr"], [181, 1, 1, "", "float"], [181, 1, 1, "", "forward"], [181, 1, 1, "", "get_buffer"], [181, 1, 1, "", "get_extra_state"], [181, 1, 1, "", "get_parameter"], [181, 1, 1, "", "get_submodule"], [181, 1, 1, "", "half"], [181, 1, 1, "", "init"], [181, 1, 1, "", "inv"], [181, 1, 1, "", "ipu"], [181, 1, 1, "", "load_state_dict"], [181, 1, 1, "", "modules"], [181, 1, 1, "", "mtia"], [181, 1, 1, "", "named_buffers"], [181, 1, 1, "", "named_children"], [181, 1, 1, "", "named_modules"], [181, 1, 1, "", "named_parameters"], [181, 1, 1, "", "parameters"], [181, 2, 1, "", "parent"], [181, 1, 1, "", "register_backward_hook"], [181, 1, 1, "", "register_buffer"], [181, 1, 1, "", "register_forward_hook"], [181, 1, 1, "", "register_forward_pre_hook"], [181, 1, 1, "", "register_full_backward_hook"], [181, 1, 1, "", "register_full_backward_pre_hook"], [181, 1, 1, "", "register_load_state_dict_post_hook"], [181, 1, 1, "", "register_load_state_dict_pre_hook"], [181, 1, 1, "", "register_module"], [181, 1, 1, "", "register_parameter"], [181, 1, 1, "", "register_state_dict_post_hook"], [181, 1, 1, "", "register_state_dict_pre_hook"], [181, 1, 1, "", "requires_grad_"], [181, 1, 1, "", "set_extra_state"], [181, 1, 1, "", "set_submodule"], [181, 1, 1, "", "share_memory"], [181, 1, 1, "", "state_dict"], [181, 1, 1, "", "to"], [181, 1, 1, "", "to_empty"], [181, 1, 1, "", "train"], [181, 1, 1, "", "transform_action_spec"], [181, 1, 1, "", "transform_done_spec"], [181, 1, 1, "", "transform_env_batch_size"], [181, 1, 1, "", "transform_env_device"], [181, 1, 1, "", "transform_input_spec"], [181, 1, 1, "", "transform_observation_spec"], [181, 1, 1, "", "transform_output_spec"], [181, 1, 1, "", "transform_reward_spec"], [181, 1, 1, "", "transform_state_spec"], [181, 1, 1, "", "type"], [181, 1, 1, "", "xpu"], [181, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.BrowserTransform": [[182, 1, 1, "", "add_module"], [182, 1, 1, "", "apply"], [182, 1, 1, "", "bfloat16"], [182, 1, 1, "", "buffers"], [182, 1, 1, "", "children"], [182, 1, 1, "", "clone"], [182, 1, 1, "", "close"], [182, 2, 1, "", "collector"], [182, 1, 1, "", "compile"], [182, 2, 1, "", "container"], [182, 1, 1, "", "cpu"], [182, 1, 1, "", "cuda"], [182, 1, 1, "", "double"], [182, 1, 1, "", "eval"], [182, 1, 1, "", "extra_repr"], [182, 1, 1, "", "float"], [182, 1, 1, "", "forward"], [182, 1, 1, "", "get_buffer"], [182, 1, 1, "", "get_extra_state"], [182, 1, 1, "", "get_parameter"], [182, 1, 1, "", "get_submodule"], [182, 1, 1, "", "half"], [182, 1, 1, "", "init"], [182, 1, 1, "", "inv"], [182, 1, 1, "", "ipu"], [182, 1, 1, "", "load_state_dict"], [182, 1, 1, "", "modules"], [182, 1, 1, "", "mtia"], [182, 1, 1, "", "named_buffers"], [182, 1, 1, "", "named_children"], [182, 1, 1, "", "named_modules"], [182, 1, 1, "", "named_parameters"], [182, 1, 1, "", "parameters"], [182, 2, 1, "", "parent"], [182, 1, 1, "", "register_backward_hook"], [182, 1, 1, "", "register_buffer"], [182, 1, 1, "", "register_forward_hook"], [182, 1, 1, "", "register_forward_pre_hook"], [182, 1, 1, "", "register_full_backward_hook"], [182, 1, 1, "", "register_full_backward_pre_hook"], [182, 1, 1, "", "register_load_state_dict_post_hook"], [182, 1, 1, "", "register_load_state_dict_pre_hook"], [182, 1, 1, "", "register_module"], [182, 1, 1, "", "register_parameter"], [182, 1, 1, "", "register_state_dict_post_hook"], [182, 1, 1, "", "register_state_dict_pre_hook"], [182, 1, 1, "", "requires_grad_"], [182, 1, 1, "", "set_extra_state"], [182, 1, 1, "", "set_submodule"], [182, 1, 1, "", "share_memory"], [182, 1, 1, "", "state_dict"], [182, 1, 1, "", "to"], [182, 1, 1, "", "to_empty"], [182, 1, 1, "", "train"], [182, 1, 1, "", "transform_action_spec"], [182, 1, 1, "", "transform_done_spec"], [182, 1, 1, "", "transform_env_batch_size"], [182, 1, 1, "", "transform_env_device"], [182, 1, 1, "", "transform_input_spec"], [182, 1, 1, "", "transform_observation_spec"], [182, 1, 1, "", "transform_output_spec"], [182, 1, 1, "", "transform_reward_spec"], [182, 1, 1, "", "transform_state_spec"], [182, 1, 1, "", "type"], [182, 1, 1, "", "xpu"], [182, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.DataLoadingPrimer": [[183, 1, 1, "", "add_module"], [183, 1, 1, "", "apply"], [183, 1, 1, "", "bfloat16"], [183, 1, 1, "", "buffers"], [183, 1, 1, "", "children"], [183, 1, 1, "", "close"], [183, 2, 1, "", "collector"], [183, 1, 1, "", "compile"], [183, 2, 1, "", "container"], [183, 1, 1, "", "cpu"], [183, 1, 1, "", "cuda"], [183, 1, 1, "", "double"], [183, 1, 1, "", "eval"], [183, 1, 1, "", "extra_repr"], [183, 1, 1, "", "float"], [183, 1, 1, "", "forward"], [183, 1, 1, "", "get_buffer"], [183, 1, 1, "", "get_extra_state"], [183, 1, 1, "", "get_parameter"], [183, 1, 1, "", "get_submodule"], [183, 1, 1, "", "half"], [183, 1, 1, "", "init"], [183, 1, 1, "", "inv"], [183, 1, 1, "", "ipu"], [183, 1, 1, "", "load_state_dict"], [183, 1, 1, "", "modules"], [183, 1, 1, "", "mtia"], [183, 1, 1, "", "named_buffers"], [183, 1, 1, "", "named_children"], [183, 1, 1, "", "named_modules"], [183, 1, 1, "", "named_parameters"], [183, 1, 1, "", "parameters"], [183, 2, 1, "", "parent"], [183, 1, 1, "", "register_backward_hook"], [183, 1, 1, "", "register_buffer"], [183, 1, 1, "", "register_forward_hook"], [183, 1, 1, "", "register_forward_pre_hook"], [183, 1, 1, "", "register_full_backward_hook"], [183, 1, 1, "", "register_full_backward_pre_hook"], [183, 1, 1, "", "register_load_state_dict_post_hook"], [183, 1, 1, "", "register_load_state_dict_pre_hook"], [183, 1, 1, "", "register_module"], [183, 1, 1, "", "register_parameter"], [183, 1, 1, "", "register_state_dict_post_hook"], [183, 1, 1, "", "register_state_dict_pre_hook"], [183, 1, 1, "", "requires_grad_"], [183, 1, 1, "", "reset_dataloader"], [183, 1, 1, "", "set_extra_state"], [183, 1, 1, "", "set_submodule"], [183, 1, 1, "", "share_memory"], [183, 1, 1, "", "state_dict"], [183, 1, 1, "", "to"], [183, 1, 1, "", "to_empty"], [183, 1, 1, "", "train"], [183, 1, 1, "", "transform_action_spec"], [183, 1, 1, "", "transform_done_spec"], [183, 1, 1, "", "transform_env_batch_size"], [183, 1, 1, "", "transform_env_device"], [183, 1, 1, "", "transform_input_spec"], [183, 1, 1, "", "transform_observation_spec"], [183, 1, 1, "", "transform_output_spec"], [183, 1, 1, "", "transform_reward_spec"], [183, 1, 1, "", "transform_state_spec"], [183, 1, 1, "", "type"], [183, 1, 1, "", "xpu"], [183, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.ExecuteToolsInOrder": [[184, 1, 1, "", "add_module"], [184, 1, 1, "", "apply"], [184, 1, 1, "", "bfloat16"], [184, 1, 1, "", "buffers"], [184, 1, 1, "", "children"], [184, 1, 1, "", "close"], [184, 2, 1, "", "collector"], [184, 1, 1, "", "compile"], [184, 2, 1, "", "container"], [184, 1, 1, "", "cpu"], [184, 1, 1, "", "cuda"], [184, 1, 1, "", "double"], [184, 1, 1, "", "eval"], [184, 1, 1, "", "extra_repr"], [184, 1, 1, "", "float"], [184, 1, 1, "", "forward"], [184, 1, 1, "", "get_buffer"], [184, 1, 1, "", "get_extra_state"], [184, 1, 1, "", "get_parameter"], [184, 1, 1, "", "get_submodule"], [184, 1, 1, "", "half"], [184, 1, 1, "", "init"], [184, 1, 1, "", "inv"], [184, 1, 1, "", "ipu"], [184, 1, 1, "", "load_state_dict"], [184, 1, 1, "", "modules"], [184, 1, 1, "", "mtia"], [184, 1, 1, "", "named_buffers"], [184, 1, 1, "", "named_children"], [184, 1, 1, "", "named_modules"], [184, 1, 1, "", "named_parameters"], [184, 1, 1, "", "parameters"], [184, 2, 1, "", "parent"], [184, 1, 1, "", "register_backward_hook"], [184, 1, 1, "", "register_buffer"], [184, 1, 1, "", "register_forward_hook"], [184, 1, 1, "", "register_forward_pre_hook"], [184, 1, 1, "", "register_full_backward_hook"], [184, 1, 1, "", "register_full_backward_pre_hook"], [184, 1, 1, "", "register_load_state_dict_post_hook"], [184, 1, 1, "", "register_load_state_dict_pre_hook"], [184, 1, 1, "", "register_module"], [184, 1, 1, "", "register_parameter"], [184, 1, 1, "", "register_state_dict_post_hook"], [184, 1, 1, "", "register_state_dict_pre_hook"], [184, 1, 1, "", "requires_grad_"], [184, 1, 1, "", "set_extra_state"], [184, 1, 1, "", "set_submodule"], [184, 1, 1, "", "share_memory"], [184, 1, 1, "", "state_dict"], [184, 1, 1, "", "to"], [184, 1, 1, "", "to_empty"], [184, 1, 1, "", "train"], [184, 1, 1, "", "transform_action_spec"], [184, 1, 1, "", "transform_done_spec"], [184, 1, 1, "", "transform_env_batch_size"], [184, 1, 1, "", "transform_env_device"], [184, 1, 1, "", "transform_input_spec"], [184, 1, 1, "", "transform_observation_spec"], [184, 1, 1, "", "transform_output_spec"], [184, 1, 1, "", "transform_reward_spec"], [184, 1, 1, "", "transform_state_spec"], [184, 1, 1, "", "type"], [184, 1, 1, "", "xpu"], [184, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.KLComputation": [[186, 1, 1, "", "add_module"], [186, 1, 1, "", "apply"], [186, 1, 1, "", "bfloat16"], [186, 1, 1, "", "buffers"], [186, 1, 1, "", "children"], [186, 1, 1, "", "close"], [186, 2, 1, "", "collector"], [186, 1, 1, "", "compile"], [186, 2, 1, "", "container"], [186, 1, 1, "", "cpu"], [186, 1, 1, "", "cuda"], [186, 1, 1, "", "double"], [186, 1, 1, "", "eval"], [186, 1, 1, "", "extra_repr"], [186, 1, 1, "", "float"], [186, 1, 1, "", "forward"], [186, 1, 1, "", "get_buffer"], [186, 1, 1, "", "get_extra_state"], [186, 1, 1, "", "get_parameter"], [186, 1, 1, "", "get_submodule"], [186, 1, 1, "", "half"], [186, 1, 1, "", "init"], [186, 1, 1, "", "inv"], [186, 1, 1, "", "ipu"], [186, 1, 1, "", "load_state_dict"], [186, 1, 1, "", "modules"], [186, 1, 1, "", "mtia"], [186, 1, 1, "", "named_buffers"], [186, 1, 1, "", "named_children"], [186, 1, 1, "", "named_modules"], [186, 1, 1, "", "named_parameters"], [186, 1, 1, "", "parameters"], [186, 2, 1, "", "parent"], [186, 1, 1, "", "register_backward_hook"], [186, 1, 1, "", "register_buffer"], [186, 1, 1, "", "register_forward_hook"], [186, 1, 1, "", "register_forward_pre_hook"], [186, 1, 1, "", "register_full_backward_hook"], [186, 1, 1, "", "register_full_backward_pre_hook"], [186, 1, 1, "", "register_load_state_dict_post_hook"], [186, 1, 1, "", "register_load_state_dict_pre_hook"], [186, 1, 1, "", "register_module"], [186, 1, 1, "", "register_parameter"], [186, 1, 1, "", "register_state_dict_post_hook"], [186, 1, 1, "", "register_state_dict_pre_hook"], [186, 1, 1, "", "requires_grad_"], [186, 1, 1, "", "set_extra_state"], [186, 1, 1, "", "set_submodule"], [186, 1, 1, "", "share_memory"], [186, 1, 1, "", "state_dict"], [186, 1, 1, "", "to"], [186, 1, 1, "", "to_empty"], [186, 1, 1, "", "train"], [186, 1, 1, "", "transform_action_spec"], [186, 1, 1, "", "transform_done_spec"], [186, 1, 1, "", "transform_env_batch_size"], [186, 1, 1, "", "transform_env_device"], [186, 1, 1, "", "transform_input_spec"], [186, 1, 1, "", "transform_observation_spec"], [186, 1, 1, "", "transform_output_spec"], [186, 1, 1, "", "transform_reward_spec"], [186, 1, 1, "", "transform_state_spec"], [186, 1, 1, "", "type"], [186, 1, 1, "", "xpu"], [186, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.KLRewardTransform": [[187, 1, 1, "", "add_module"], [187, 1, 1, "", "apply"], [187, 1, 1, "", "bfloat16"], [187, 1, 1, "", "buffers"], [187, 1, 1, "", "children"], [187, 1, 1, "", "close"], [187, 2, 1, "", "collector"], [187, 1, 1, "", "compile"], [187, 2, 1, "", "container"], [187, 1, 1, "", "cpu"], [187, 1, 1, "", "cuda"], [187, 1, 1, "", "double"], [187, 1, 1, "", "eval"], [187, 1, 1, "", "extra_repr"], [187, 1, 1, "", "float"], [187, 1, 1, "", "forward"], [187, 1, 1, "", "get_buffer"], [187, 1, 1, "", "get_extra_state"], [187, 1, 1, "", "get_parameter"], [187, 1, 1, "", "get_submodule"], [187, 1, 1, "", "half"], [187, 1, 1, "", "init"], [187, 1, 1, "", "inv"], [187, 1, 1, "", "ipu"], [187, 1, 1, "", "load_state_dict"], [187, 1, 1, "", "modules"], [187, 1, 1, "", "mtia"], [187, 1, 1, "", "named_buffers"], [187, 1, 1, "", "named_children"], [187, 1, 1, "", "named_modules"], [187, 1, 1, "", "named_parameters"], [187, 1, 1, "", "parameters"], [187, 2, 1, "", "parent"], [187, 1, 1, "", "register_backward_hook"], [187, 1, 1, "", "register_buffer"], [187, 1, 1, "", "register_forward_hook"], [187, 1, 1, "", "register_forward_pre_hook"], [187, 1, 1, "", "register_full_backward_hook"], [187, 1, 1, "", "register_full_backward_pre_hook"], [187, 1, 1, "", "register_load_state_dict_post_hook"], [187, 1, 1, "", "register_load_state_dict_pre_hook"], [187, 1, 1, "", "register_module"], [187, 1, 1, "", "register_parameter"], [187, 1, 1, "", "register_state_dict_post_hook"], [187, 1, 1, "", "register_state_dict_pre_hook"], [187, 1, 1, "", "requires_grad_"], [187, 1, 1, "", "set_extra_state"], [187, 1, 1, "", "set_submodule"], [187, 1, 1, "", "share_memory"], [187, 1, 1, "", "state_dict"], [187, 1, 1, "", "to"], [187, 1, 1, "", "to_empty"], [187, 1, 1, "", "train"], [187, 1, 1, "", "transform_action_spec"], [187, 1, 1, "", "transform_done_spec"], [187, 1, 1, "", "transform_env_batch_size"], [187, 1, 1, "", "transform_env_device"], [187, 1, 1, "", "transform_input_spec"], [187, 1, 1, "", "transform_observation_spec"], [187, 1, 1, "", "transform_output_spec"], [187, 1, 1, "", "transform_reward_spec"], [187, 1, 1, "", "transform_state_spec"], [187, 1, 1, "", "type"], [187, 1, 1, "", "xpu"], [187, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.MCPToolTransform": [[188, 1, 1, "", "add_module"], [188, 1, 1, "", "apply"], [188, 1, 1, "", "bfloat16"], [188, 1, 1, "", "buffers"], [188, 1, 1, "", "children"], [188, 1, 1, "", "close"], [188, 2, 1, "", "collector"], [188, 1, 1, "", "compile"], [188, 2, 1, "", "container"], [188, 1, 1, "", "cpu"], [188, 1, 1, "", "cuda"], [188, 1, 1, "", "double"], [188, 1, 1, "", "eval"], [188, 1, 1, "", "extra_repr"], [188, 1, 1, "", "float"], [188, 1, 1, "", "forward"], [188, 1, 1, "", "get_buffer"], [188, 1, 1, "", "get_extra_state"], [188, 1, 1, "", "get_parameter"], [188, 1, 1, "", "get_submodule"], [188, 1, 1, "", "half"], [188, 1, 1, "", "init"], [188, 1, 1, "", "inv"], [188, 1, 1, "", "ipu"], [188, 1, 1, "", "load_state_dict"], [188, 1, 1, "", "modules"], [188, 1, 1, "", "mtia"], [188, 1, 1, "", "named_buffers"], [188, 1, 1, "", "named_children"], [188, 1, 1, "", "named_modules"], [188, 1, 1, "", "named_parameters"], [188, 1, 1, "", "parameters"], [188, 2, 1, "", "parent"], [188, 1, 1, "", "register_backward_hook"], [188, 1, 1, "", "register_buffer"], [188, 1, 1, "", "register_forward_hook"], [188, 1, 1, "", "register_forward_pre_hook"], [188, 1, 1, "", "register_full_backward_hook"], [188, 1, 1, "", "register_full_backward_pre_hook"], [188, 1, 1, "", "register_load_state_dict_post_hook"], [188, 1, 1, "", "register_load_state_dict_pre_hook"], [188, 1, 1, "", "register_module"], [188, 1, 1, "", "register_parameter"], [188, 1, 1, "", "register_state_dict_post_hook"], [188, 1, 1, "", "register_state_dict_pre_hook"], [188, 1, 1, "", "requires_grad_"], [188, 1, 1, "", "set_extra_state"], [188, 1, 1, "", "set_submodule"], [188, 1, 1, "", "share_memory"], [188, 1, 1, "", "state_dict"], [188, 1, 1, "", "to"], [188, 1, 1, "", "to_empty"], [188, 1, 1, "", "train"], [188, 1, 1, "", "transform_action_spec"], [188, 1, 1, "", "transform_done_spec"], [188, 1, 1, "", "transform_env_batch_size"], [188, 1, 1, "", "transform_env_device"], [188, 1, 1, "", "transform_input_spec"], [188, 1, 1, "", "transform_observation_spec"], [188, 1, 1, "", "transform_output_spec"], [188, 1, 1, "", "transform_reward_spec"], [188, 1, 1, "", "transform_state_spec"], [188, 1, 1, "", "type"], [188, 1, 1, "", "xpu"], [188, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.PolicyVersion": [[189, 1, 1, "", "add_module"], [189, 1, 1, "", "apply"], [189, 1, 1, "", "bfloat16"], [189, 1, 1, "", "buffers"], [189, 1, 1, "", "children"], [189, 1, 1, "", "close"], [189, 2, 1, "", "collector"], [189, 1, 1, "", "compile"], [189, 2, 1, "", "container"], [189, 1, 1, "", "cpu"], [189, 1, 1, "", "cuda"], [189, 1, 1, "", "double"], [189, 1, 1, "", "eval"], [189, 1, 1, "", "extra_repr"], [189, 1, 1, "", "float"], [189, 1, 1, "", "forward"], [189, 1, 1, "", "get_buffer"], [189, 1, 1, "", "get_extra_state"], [189, 1, 1, "", "get_parameter"], [189, 1, 1, "", "get_submodule"], [189, 1, 1, "", "half"], [189, 1, 1, "", "increment_version"], [189, 1, 1, "", "init"], [189, 1, 1, "", "inv"], [189, 1, 1, "", "ipu"], [189, 1, 1, "", "load_state_dict"], [189, 1, 1, "", "modules"], [189, 1, 1, "", "mtia"], [189, 1, 1, "", "named_buffers"], [189, 1, 1, "", "named_children"], [189, 1, 1, "", "named_modules"], [189, 1, 1, "", "named_parameters"], [189, 1, 1, "", "parameters"], [189, 2, 1, "", "parent"], [189, 1, 1, "", "register_backward_hook"], [189, 1, 1, "", "register_buffer"], [189, 1, 1, "", "register_forward_hook"], [189, 1, 1, "", "register_forward_pre_hook"], [189, 1, 1, "", "register_full_backward_hook"], [189, 1, 1, "", "register_full_backward_pre_hook"], [189, 1, 1, "", "register_load_state_dict_post_hook"], [189, 1, 1, "", "register_load_state_dict_pre_hook"], [189, 1, 1, "", "register_module"], [189, 1, 1, "", "register_parameter"], [189, 1, 1, "", "register_state_dict_post_hook"], [189, 1, 1, "", "register_state_dict_pre_hook"], [189, 1, 1, "", "requires_grad_"], [189, 1, 1, "", "set_extra_state"], [189, 1, 1, "", "set_submodule"], [189, 1, 1, "", "share_memory"], [189, 1, 1, "", "state_dict"], [189, 1, 1, "", "to"], [189, 1, 1, "", "to_empty"], [189, 1, 1, "", "train"], [189, 1, 1, "", "transform_action_spec"], [189, 1, 1, "", "transform_done_spec"], [189, 1, 1, "", "transform_env_batch_size"], [189, 1, 1, "", "transform_env_device"], [189, 1, 1, "", "transform_input_spec"], [189, 1, 1, "", "transform_observation_spec"], [189, 1, 1, "", "transform_output_spec"], [189, 1, 1, "", "transform_reward_spec"], [189, 1, 1, "", "transform_state_spec"], [189, 1, 1, "", "type"], [189, 2, 1, "", "version"], [189, 1, 1, "", "xpu"], [189, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.PythonExecutorService": [[190, 1, 1, "", "cleanup"], [190, 1, 1, "", "execute"]], "torchrl.envs.llm.transforms.PythonInterpreter": [[191, 1, 1, "", "add_module"], [191, 1, 1, "", "apply"], [191, 1, 1, "", "bfloat16"], [191, 1, 1, "", "buffers"], [191, 1, 1, "", "children"], [191, 1, 1, "", "clone"], [191, 1, 1, "", "close"], [191, 2, 1, "", "collector"], [191, 1, 1, "", "compile"], [191, 2, 1, "", "container"], [191, 1, 1, "", "cpu"], [191, 1, 1, "", "cuda"], [191, 1, 1, "", "double"], [191, 1, 1, "", "eval"], [191, 1, 1, "", "extra_repr"], [191, 1, 1, "", "float"], [191, 1, 1, "", "forward"], [191, 1, 1, "", "get_buffer"], [191, 1, 1, "", "get_extra_state"], [191, 1, 1, "", "get_parameter"], [191, 1, 1, "", "get_submodule"], [191, 1, 1, "", "half"], [191, 1, 1, "", "init"], [191, 1, 1, "", "inv"], [191, 1, 1, "", "ipu"], [191, 1, 1, "", "load_state_dict"], [191, 1, 1, "", "modules"], [191, 1, 1, "", "mtia"], [191, 1, 1, "", "named_buffers"], [191, 1, 1, "", "named_children"], [191, 1, 1, "", "named_modules"], [191, 1, 1, "", "named_parameters"], [191, 1, 1, "", "parameters"], [191, 2, 1, "", "parent"], [191, 1, 1, "", "register_backward_hook"], [191, 1, 1, "", "register_buffer"], [191, 1, 1, "", "register_forward_hook"], [191, 1, 1, "", "register_forward_pre_hook"], [191, 1, 1, "", "register_full_backward_hook"], [191, 1, 1, "", "register_full_backward_pre_hook"], [191, 1, 1, "", "register_load_state_dict_post_hook"], [191, 1, 1, "", "register_load_state_dict_pre_hook"], [191, 1, 1, "", "register_module"], [191, 1, 1, "", "register_parameter"], [191, 1, 1, "", "register_state_dict_post_hook"], [191, 1, 1, "", "register_state_dict_pre_hook"], [191, 1, 1, "", "requires_grad_"], [191, 1, 1, "", "set_extra_state"], [191, 1, 1, "", "set_submodule"], [191, 1, 1, "", "share_memory"], [191, 1, 1, "", "state_dict"], [191, 1, 1, "", "to"], [191, 1, 1, "", "to_empty"], [191, 1, 1, "", "train"], [191, 1, 1, "", "transform_action_spec"], [191, 1, 1, "", "transform_done_spec"], [191, 1, 1, "", "transform_env_batch_size"], [191, 1, 1, "", "transform_env_device"], [191, 1, 1, "", "transform_input_spec"], [191, 1, 1, "", "transform_observation_spec"], [191, 1, 1, "", "transform_output_spec"], [191, 1, 1, "", "transform_reward_spec"], [191, 1, 1, "", "transform_state_spec"], [191, 1, 1, "", "type"], [191, 1, 1, "", "xpu"], [191, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.RayDataLoadingPrimer": [[192, 1, 1, "", "add_module"], [192, 1, 1, "", "apply"], [192, 2, 1, "", "base_env"], [192, 1, 1, "", "bfloat16"], [192, 1, 1, "", "buffers"], [192, 1, 1, "", "children"], [192, 1, 1, "", "clone"], [192, 1, 1, "", "close"], [192, 2, 1, "", "collector"], [192, 1, 1, "", "compile"], [192, 2, 1, "", "container"], [192, 1, 1, "", "cpu"], [192, 1, 1, "", "cuda"], [192, 2, 1, "", "data_keys"], [192, 2, 1, "", "dataloader"], [192, 2, 1, "", "device"], [192, 1, 1, "", "double"], [192, 1, 1, "", "dump"], [192, 1, 1, "", "empty_cache"], [192, 2, 1, "", "endless_dataloader"], [192, 1, 1, "", "eval"], [192, 1, 1, "", "extra_repr"], [192, 1, 1, "", "float"], [192, 1, 1, "", "forward"], [192, 1, 1, "", "get_buffer"], [192, 1, 1, "", "get_extra_state"], [192, 1, 1, "", "get_parameter"], [192, 1, 1, "", "get_submodule"], [192, 1, 1, "", "half"], [192, 2, 1, "", "in_keys"], [192, 2, 1, "", "in_keys_inv"], [192, 1, 1, "", "init"], [192, 1, 1, "", "inv"], [192, 1, 1, "", "ipu"], [192, 1, 1, "", "load_state_dict"], [192, 2, 1, "", "missing_tolerance"], [192, 1, 1, "", "modules"], [192, 1, 1, "", "mtia"], [192, 1, 1, "", "named_buffers"], [192, 1, 1, "", "named_children"], [192, 1, 1, "", "named_modules"], [192, 1, 1, "", "named_parameters"], [192, 2, 1, "", "out_keys"], [192, 2, 1, "", "out_keys_inv"], [192, 1, 1, "", "parameters"], [192, 2, 1, "", "parent"], [192, 2, 1, "", "primers"], [192, 1, 1, "", "register_backward_hook"], [192, 1, 1, "", "register_buffer"], [192, 1, 1, "", "register_forward_hook"], [192, 1, 1, "", "register_forward_pre_hook"], [192, 1, 1, "", "register_full_backward_hook"], [192, 1, 1, "", "register_full_backward_pre_hook"], [192, 1, 1, "", "register_load_state_dict_post_hook"], [192, 1, 1, "", "register_load_state_dict_pre_hook"], [192, 1, 1, "", "register_module"], [192, 1, 1, "", "register_parameter"], [192, 1, 1, "", "register_state_dict_post_hook"], [192, 1, 1, "", "register_state_dict_pre_hook"], [192, 2, 1, "", "repeats"], [192, 1, 1, "", "requires_grad_"], [192, 1, 1, "", "reset_dataloader"], [192, 1, 1, "", "reset_parent"], [192, 1, 1, "", "set_container"], [192, 1, 1, "", "set_extra_state"], [192, 1, 1, "", "set_missing_tolerance"], [192, 1, 1, "", "set_submodule"], [192, 1, 1, "", "share_memory"], [192, 2, 1, "", "stack_method"], [192, 1, 1, "", "state_dict"], [192, 1, 1, "", "to"], [192, 1, 1, "", "to_empty"], [192, 1, 1, "", "train"], [192, 1, 1, "", "transform_action_spec"], [192, 1, 1, "", "transform_done_spec"], [192, 1, 1, "", "transform_env_batch_size"], [192, 1, 1, "", "transform_env_device"], [192, 1, 1, "", "transform_input_spec"], [192, 1, 1, "", "transform_observation_spec"], [192, 1, 1, "", "transform_output_spec"], [192, 1, 1, "", "transform_reward_spec"], [192, 1, 1, "", "transform_state_spec"], [192, 1, 1, "", "type"], [192, 1, 1, "", "xpu"], [192, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.RetrieveKL": [[193, 1, 1, "", "add_module"], [193, 1, 1, "", "append"], [193, 1, 1, "", "apply"], [193, 1, 1, "", "bfloat16"], [193, 1, 1, "", "buffers"], [193, 1, 1, "", "children"], [193, 1, 1, "", "close"], [193, 2, 1, "", "collector"], [193, 1, 1, "", "compile"], [193, 2, 1, "", "container"], [193, 1, 1, "", "cpu"], [193, 1, 1, "", "cuda"], [193, 1, 1, "", "double"], [193, 1, 1, "", "eval"], [193, 1, 1, "", "extra_repr"], [193, 1, 1, "", "float"], [193, 1, 1, "", "forward"], [193, 1, 1, "", "get_buffer"], [193, 1, 1, "", "get_extra_state"], [193, 1, 1, "", "get_parameter"], [193, 1, 1, "", "get_submodule"], [193, 1, 1, "", "half"], [193, 1, 1, "", "init"], [193, 1, 1, "", "insert"], [193, 1, 1, "", "inv"], [193, 1, 1, "", "ipu"], [193, 1, 1, "", "load_state_dict"], [193, 1, 1, "", "modules"], [193, 1, 1, "", "mtia"], [193, 1, 1, "", "named_buffers"], [193, 1, 1, "", "named_children"], [193, 1, 1, "", "named_modules"], [193, 1, 1, "", "named_parameters"], [193, 1, 1, "", "parameters"], [193, 2, 1, "", "parent"], [193, 1, 1, "", "pop"], [193, 1, 1, "", "register_backward_hook"], [193, 1, 1, "", "register_buffer"], [193, 1, 1, "", "register_forward_hook"], [193, 1, 1, "", "register_forward_pre_hook"], [193, 1, 1, "", "register_full_backward_hook"], [193, 1, 1, "", "register_full_backward_pre_hook"], [193, 1, 1, "", "register_load_state_dict_post_hook"], [193, 1, 1, "", "register_load_state_dict_pre_hook"], [193, 1, 1, "", "register_module"], [193, 1, 1, "", "register_parameter"], [193, 1, 1, "", "register_state_dict_post_hook"], [193, 1, 1, "", "register_state_dict_pre_hook"], [193, 1, 1, "", "requires_grad_"], [193, 1, 1, "", "set_extra_state"], [193, 1, 1, "", "set_submodule"], [193, 1, 1, "", "share_memory"], [193, 1, 1, "", "state_dict"], [193, 1, 1, "", "to"], [193, 1, 1, "", "to_empty"], [193, 1, 1, "", "train"], [193, 1, 1, "", "transform_action_spec"], [193, 1, 1, "", "transform_done_spec"], [193, 1, 1, "", "transform_env_batch_size"], [193, 1, 1, "", "transform_env_device"], [193, 1, 1, "", "transform_input_spec"], [193, 1, 1, "", "transform_observation_spec"], [193, 1, 1, "", "transform_output_spec"], [193, 1, 1, "", "transform_reward_spec"], [193, 1, 1, "", "transform_state_spec"], [193, 1, 1, "", "type"], [193, 1, 1, "", "xpu"], [193, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.RetrieveLogProb": [[194, 1, 1, "", "add_module"], [194, 1, 1, "", "apply"], [194, 1, 1, "", "bfloat16"], [194, 1, 1, "", "buffers"], [194, 1, 1, "", "children"], [194, 1, 1, "", "close"], [194, 2, 1, "", "collector"], [194, 1, 1, "", "compile"], [194, 2, 1, "", "container"], [194, 1, 1, "", "cpu"], [194, 1, 1, "", "cuda"], [194, 1, 1, "", "double"], [194, 1, 1, "", "eval"], [194, 1, 1, "", "extra_repr"], [194, 1, 1, "", "float"], [194, 1, 1, "", "forward"], [194, 1, 1, "", "get_buffer"], [194, 1, 1, "", "get_extra_state"], [194, 1, 1, "", "get_parameter"], [194, 1, 1, "", "get_submodule"], [194, 1, 1, "", "half"], [194, 1, 1, "", "init"], [194, 1, 1, "", "inv"], [194, 1, 1, "", "ipu"], [194, 1, 1, "", "load_state_dict"], [194, 1, 1, "", "modules"], [194, 1, 1, "", "mtia"], [194, 1, 1, "", "named_buffers"], [194, 1, 1, "", "named_children"], [194, 1, 1, "", "named_modules"], [194, 1, 1, "", "named_parameters"], [194, 1, 1, "", "parameters"], [194, 2, 1, "", "parent"], [194, 1, 1, "", "register_backward_hook"], [194, 1, 1, "", "register_buffer"], [194, 1, 1, "", "register_forward_hook"], [194, 1, 1, "", "register_forward_pre_hook"], [194, 1, 1, "", "register_full_backward_hook"], [194, 1, 1, "", "register_full_backward_pre_hook"], [194, 1, 1, "", "register_load_state_dict_post_hook"], [194, 1, 1, "", "register_load_state_dict_pre_hook"], [194, 1, 1, "", "register_module"], [194, 1, 1, "", "register_parameter"], [194, 1, 1, "", "register_state_dict_post_hook"], [194, 1, 1, "", "register_state_dict_pre_hook"], [194, 1, 1, "", "requires_grad_"], [194, 1, 1, "", "set_extra_state"], [194, 1, 1, "", "set_submodule"], [194, 1, 1, "", "share_memory"], [194, 1, 1, "", "state_dict"], [194, 1, 1, "", "to"], [194, 1, 1, "", "to_empty"], [194, 1, 1, "", "train"], [194, 1, 1, "", "transform_action_spec"], [194, 1, 1, "", "transform_done_spec"], [194, 1, 1, "", "transform_env_batch_size"], [194, 1, 1, "", "transform_env_device"], [194, 1, 1, "", "transform_input_spec"], [194, 1, 1, "", "transform_observation_spec"], [194, 1, 1, "", "transform_output_spec"], [194, 1, 1, "", "transform_reward_spec"], [194, 1, 1, "", "transform_state_spec"], [194, 1, 1, "", "type"], [194, 1, 1, "", "xpu"], [194, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.SimpleToolTransform": [[195, 1, 1, "", "add_module"], [195, 1, 1, "", "apply"], [195, 1, 1, "", "bfloat16"], [195, 1, 1, "", "buffers"], [195, 1, 1, "", "children"], [195, 1, 1, "", "close"], [195, 2, 1, "", "collector"], [195, 1, 1, "", "compile"], [195, 2, 1, "", "container"], [195, 1, 1, "", "cpu"], [195, 1, 1, "", "cuda"], [195, 1, 1, "", "double"], [195, 1, 1, "", "eval"], [195, 1, 1, "", "extra_repr"], [195, 1, 1, "", "float"], [195, 1, 1, "", "forward"], [195, 1, 1, "", "get_buffer"], [195, 1, 1, "", "get_extra_state"], [195, 1, 1, "", "get_parameter"], [195, 1, 1, "", "get_submodule"], [195, 1, 1, "", "half"], [195, 1, 1, "", "init"], [195, 1, 1, "", "inv"], [195, 1, 1, "", "ipu"], [195, 1, 1, "", "load_state_dict"], [195, 1, 1, "", "modules"], [195, 1, 1, "", "mtia"], [195, 1, 1, "", "named_buffers"], [195, 1, 1, "", "named_children"], [195, 1, 1, "", "named_modules"], [195, 1, 1, "", "named_parameters"], [195, 1, 1, "", "parameters"], [195, 2, 1, "", "parent"], [195, 1, 1, "", "register_backward_hook"], [195, 1, 1, "", "register_buffer"], [195, 1, 1, "", "register_forward_hook"], [195, 1, 1, "", "register_forward_pre_hook"], [195, 1, 1, "", "register_full_backward_hook"], [195, 1, 1, "", "register_full_backward_pre_hook"], [195, 1, 1, "", "register_load_state_dict_post_hook"], [195, 1, 1, "", "register_load_state_dict_pre_hook"], [195, 1, 1, "", "register_module"], [195, 1, 1, "", "register_parameter"], [195, 1, 1, "", "register_state_dict_post_hook"], [195, 1, 1, "", "register_state_dict_pre_hook"], [195, 1, 1, "", "requires_grad_"], [195, 1, 1, "", "set_extra_state"], [195, 1, 1, "", "set_submodule"], [195, 1, 1, "", "share_memory"], [195, 1, 1, "", "state_dict"], [195, 1, 1, "", "to"], [195, 1, 1, "", "to_empty"], [195, 1, 1, "", "train"], [195, 1, 1, "", "transform_action_spec"], [195, 1, 1, "", "transform_done_spec"], [195, 1, 1, "", "transform_env_batch_size"], [195, 1, 1, "", "transform_env_device"], [195, 1, 1, "", "transform_input_spec"], [195, 1, 1, "", "transform_observation_spec"], [195, 1, 1, "", "transform_output_spec"], [195, 1, 1, "", "transform_reward_spec"], [195, 1, 1, "", "transform_state_spec"], [195, 1, 1, "", "type"], [195, 1, 1, "", "xpu"], [195, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.TemplateTransform": [[196, 1, 1, "", "add_module"], [196, 1, 1, "", "apply"], [196, 1, 1, "", "bfloat16"], [196, 1, 1, "", "buffers"], [196, 1, 1, "", "children"], [196, 1, 1, "", "close"], [196, 2, 1, "", "collector"], [196, 1, 1, "", "compile"], [196, 2, 1, "", "container"], [196, 1, 1, "", "cpu"], [196, 1, 1, "", "cuda"], [196, 1, 1, "", "double"], [196, 1, 1, "", "eval"], [196, 1, 1, "", "extra_repr"], [196, 1, 1, "", "float"], [196, 1, 1, "", "forward"], [196, 1, 1, "", "get_buffer"], [196, 1, 1, "", "get_extra_state"], [196, 1, 1, "", "get_parameter"], [196, 1, 1, "", "get_submodule"], [196, 1, 1, "", "half"], [196, 1, 1, "", "init"], [196, 1, 1, "", "inv"], [196, 1, 1, "", "ipu"], [196, 1, 1, "", "load_state_dict"], [196, 1, 1, "", "modules"], [196, 1, 1, "", "mtia"], [196, 1, 1, "", "named_buffers"], [196, 1, 1, "", "named_children"], [196, 1, 1, "", "named_modules"], [196, 1, 1, "", "named_parameters"], [196, 1, 1, "", "parameters"], [196, 2, 1, "", "parent"], [196, 1, 1, "", "register_backward_hook"], [196, 1, 1, "", "register_buffer"], [196, 1, 1, "", "register_forward_hook"], [196, 1, 1, "", "register_forward_pre_hook"], [196, 1, 1, "", "register_full_backward_hook"], [196, 1, 1, "", "register_full_backward_pre_hook"], [196, 1, 1, "", "register_load_state_dict_post_hook"], [196, 1, 1, "", "register_load_state_dict_pre_hook"], [196, 1, 1, "", "register_module"], [196, 1, 1, "", "register_parameter"], [196, 1, 1, "", "register_state_dict_post_hook"], [196, 1, 1, "", "register_state_dict_pre_hook"], [196, 1, 1, "", "requires_grad_"], [196, 1, 1, "", "set_extra_state"], [196, 1, 1, "", "set_submodule"], [196, 1, 1, "", "share_memory"], [196, 1, 1, "", "state_dict"], [196, 1, 1, "", "to"], [196, 1, 1, "", "to_empty"], [196, 1, 1, "", "train"], [196, 1, 1, "", "transform_action_spec"], [196, 1, 1, "", "transform_done_spec"], [196, 1, 1, "", "transform_env_batch_size"], [196, 1, 1, "", "transform_env_device"], [196, 1, 1, "", "transform_input_spec"], [196, 1, 1, "", "transform_observation_spec"], [196, 1, 1, "", "transform_output_spec"], [196, 1, 1, "", "transform_reward_spec"], [196, 1, 1, "", "transform_state_spec"], [196, 1, 1, "", "type"], [196, 1, 1, "", "xpu"], [196, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.Tokenizer": [[197, 1, 1, "", "add_module"], [197, 1, 1, "", "apply"], [197, 1, 1, "", "bfloat16"], [197, 1, 1, "", "buffers"], [197, 1, 1, "", "children"], [197, 1, 1, "", "close"], [197, 2, 1, "", "collector"], [197, 1, 1, "", "compile"], [197, 2, 1, "", "container"], [197, 1, 1, "", "cpu"], [197, 1, 1, "", "cuda"], [197, 1, 1, "", "double"], [197, 1, 1, "", "eval"], [197, 1, 1, "", "extra_repr"], [197, 1, 1, "", "float"], [197, 1, 1, "", "forward"], [197, 1, 1, "", "get_buffer"], [197, 1, 1, "", "get_extra_state"], [197, 1, 1, "", "get_parameter"], [197, 1, 1, "", "get_submodule"], [197, 1, 1, "", "half"], [197, 1, 1, "", "init"], [197, 1, 1, "", "inv"], [197, 1, 1, "", "ipu"], [197, 1, 1, "", "load_state_dict"], [197, 1, 1, "", "modules"], [197, 1, 1, "", "mtia"], [197, 1, 1, "", "named_buffers"], [197, 1, 1, "", "named_children"], [197, 1, 1, "", "named_modules"], [197, 1, 1, "", "named_parameters"], [197, 1, 1, "", "parameters"], [197, 2, 1, "", "parent"], [197, 1, 1, "", "register_backward_hook"], [197, 1, 1, "", "register_buffer"], [197, 1, 1, "", "register_forward_hook"], [197, 1, 1, "", "register_forward_pre_hook"], [197, 1, 1, "", "register_full_backward_hook"], [197, 1, 1, "", "register_full_backward_pre_hook"], [197, 1, 1, "", "register_load_state_dict_post_hook"], [197, 1, 1, "", "register_load_state_dict_pre_hook"], [197, 1, 1, "", "register_module"], [197, 1, 1, "", "register_parameter"], [197, 1, 1, "", "register_state_dict_post_hook"], [197, 1, 1, "", "register_state_dict_pre_hook"], [197, 1, 1, "", "requires_grad_"], [197, 1, 1, "", "set_extra_state"], [197, 1, 1, "", "set_submodule"], [197, 1, 1, "", "share_memory"], [197, 1, 1, "", "state_dict"], [197, 1, 1, "", "to"], [197, 1, 1, "", "to_empty"], [197, 1, 1, "", "train"], [197, 1, 1, "", "transform_action_spec"], [197, 1, 1, "", "transform_done_spec"], [197, 1, 1, "", "transform_env_batch_size"], [197, 1, 1, "", "transform_env_device"], [197, 1, 1, "", "transform_input_spec"], [197, 1, 1, "", "transform_observation_spec"], [197, 1, 1, "", "transform_output_spec"], [197, 1, 1, "", "transform_reward_spec"], [197, 1, 1, "", "transform_state_spec"], [197, 1, 1, "", "type"], [197, 1, 1, "", "xpu"], [197, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.ToolRegistry": [[199, 1, 1, "", "get"], [199, 1, 1, "", "register"]], "torchrl.envs.model_based.dreamer": [[205, 3, 1, "", "DreamerDecoder"], [206, 3, 1, "", "DreamerEnv"]], "torchrl.envs.transforms": [[212, 0, 1, "", "ActionDiscretizer"], [213, 0, 1, "", "ActionMask"], [214, 0, 1, "", "AutoResetEnv"], [215, 0, 1, "", "AutoResetTransform"], [216, 0, 1, "", "BatchSizeTransform"], [217, 0, 1, "", "BinarizeReward"], [218, 0, 1, "", "BurnInTransform"], [219, 0, 1, "", "CatFrames"], [220, 0, 1, "", "CatTensors"], [221, 0, 1, "", "CenterCrop"], [222, 0, 1, "", "ClipTransform"], [223, 0, 1, "", "Compose"], [224, 0, 1, "", "ConditionalPolicySwitch"], [225, 0, 1, "", "ConditionalSkip"], [226, 0, 1, "", "Crop"], [227, 0, 1, "", "DTypeCastTransform"], [228, 0, 1, "", "DeviceCastTransform"], [229, 0, 1, "", "DiscreteActionProjection"], [230, 0, 1, "", "DoubleToFloat"], [231, 0, 1, "", "EndOfLifeTransform"], [232, 0, 1, "", "ExcludeTransform"], [233, 0, 1, "", "FiniteTensorDictCheck"], [234, 0, 1, "", "FlattenObservation"], [235, 0, 1, "", "FrameSkipTransform"], [236, 0, 1, "", "GrayScale"], [237, 0, 1, "", "Hash"], [238, 0, 1, "", "InitTracker"], [239, 0, 1, "", "KLRewardTransform"], [240, 0, 1, "", "LineariseRewards"], [241, 0, 1, "", "ModuleTransform"], [242, 0, 1, "", "MultiAction"], [243, 0, 1, "", "NoopResetEnv"], [244, 0, 1, "", "ObservationNorm"], [245, 0, 1, "", "ObservationTransform"], [246, 0, 1, "", "PermuteTransform"], [247, 0, 1, "", "PinMemoryTransform"], [248, 0, 1, "", "R3MTransform"], [249, 0, 1, "", "RandomCropTensorDict"], [250, 0, 1, "", "RemoveEmptySpecs"], [251, 0, 1, "", "RenameTransform"], [252, 0, 1, "", "Resize"], [253, 0, 1, "", "Reward2GoTransform"], [254, 0, 1, "", "RewardClipping"], [255, 0, 1, "", "RewardScaling"], [256, 0, 1, "", "RewardSum"], [257, 0, 1, "", "SelectTransform"], [258, 0, 1, "", "SignTransform"], [259, 0, 1, "", "SqueezeTransform"], [260, 0, 1, "", "Stack"], [261, 0, 1, "", "StepCounter"], [262, 0, 1, "", "TargetReturn"], [263, 0, 1, "", "TensorDictPrimer"], [264, 0, 1, "", "TimeMaxPool"], [265, 0, 1, "", "Timer"], [266, 0, 1, "", "ToTensorImage"], [267, 0, 1, "", "Tokenizer"], [268, 0, 1, "", "TrajCounter"], [269, 0, 1, "", "Transform"], [270, 0, 1, "", "TransformedEnv"], [271, 0, 1, "", "UnaryTransform"], [272, 0, 1, "", "UnsqueezeTransform"], [273, 0, 1, "", "VC1Transform"], [274, 0, 1, "", "VIPRewardTransform"], [275, 0, 1, "", "VIPTransform"], [276, 0, 1, "", "VecGymEnvTransform"], [277, 0, 1, "", "VecNorm"], [278, 0, 1, "", "VecNormV2"], [279, 0, 1, "", "gSDENoise"]], "torchrl.envs.transforms.ActionDiscretizer": [[212, 0, 1, "", "SamplingStrategy"], [212, 1, 1, "", "inv"], [212, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.ActionMask": [[213, 1, 1, "", "forward"]], "torchrl.envs.transforms.AutoResetEnv": [[214, 1, 1, "", "insert_transform"]], "torchrl.envs.transforms.AutoResetTransform": [[215, 1, 1, "", "forward"]], "torchrl.envs.transforms.BatchSizeTransform": [[216, 1, 1, "", "forward"], [216, 1, 1, "", "transform_env_batch_size"], [216, 1, 1, "", "transform_input_spec"], [216, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.BinarizeReward": [[217, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.BurnInTransform": [[218, 1, 1, "", "forward"]], "torchrl.envs.transforms.CatFrames": [[219, 1, 1, "", "forward"], [219, 1, 1, "", "make_rb_transform_and_sampler"], [219, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CatTensors": [[220, 1, 1, "", "forward"], [220, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CenterCrop": [[221, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ClipTransform": [[222, 1, 1, "", "transform_observation_spec"], [222, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.Compose": [[223, 1, 1, "", "append"], [223, 1, 1, "", "close"], [223, 1, 1, "", "forward"], [223, 1, 1, "", "init"], [223, 1, 1, "", "insert"], [223, 1, 1, "", "pop"], [223, 1, 1, "", "to"], [223, 1, 1, "", "transform_action_spec"], [223, 1, 1, "", "transform_env_batch_size"], [223, 1, 1, "", "transform_env_device"], [223, 1, 1, "", "transform_input_spec"], [223, 1, 1, "", "transform_observation_spec"], [223, 1, 1, "", "transform_output_spec"], [223, 1, 1, "", "transform_reward_spec"], [223, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.ConditionalPolicySwitch": [[224, 1, 1, "", "forward"]], "torchrl.envs.transforms.ConditionalSkip": [[225, 1, 1, "", "forward"]], "torchrl.envs.transforms.Crop": [[226, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.DTypeCastTransform": [[227, 1, 1, "", "forward"], [227, 1, 1, "", "transform_input_spec"], [227, 1, 1, "", "transform_observation_spec"], [227, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.DeviceCastTransform": [[228, 1, 1, "", "forward"], [228, 1, 1, "", "transform_action_spec"], [228, 1, 1, "", "transform_done_spec"], [228, 1, 1, "", "transform_env_device"], [228, 1, 1, "", "transform_input_spec"], [228, 1, 1, "", "transform_observation_spec"], [228, 1, 1, "", "transform_output_spec"], [228, 1, 1, "", "transform_reward_spec"], [228, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.DiscreteActionProjection": [[229, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.EndOfLifeTransform": [[231, 1, 1, "", "forward"], [231, 1, 1, "", "register_keys"], [231, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ExcludeTransform": [[232, 1, 1, "", "forward"], [232, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.FiniteTensorDictCheck": [[233, 1, 1, "", "forward"]], "torchrl.envs.transforms.FlattenObservation": [[234, 1, 1, "", "forward"], [234, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.FrameSkipTransform": [[235, 1, 1, "", "forward"]], "torchrl.envs.transforms.GrayScale": [[236, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Hash": [[237, 1, 1, "", "get_input_from_hash"], [237, 1, 1, "", "reproducible_hash"], [237, 1, 1, "", "state_dict"]], "torchrl.envs.transforms.InitTracker": [[238, 1, 1, "", "forward"], [238, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.KLRewardTransform": [[239, 1, 1, "", "forward"], [239, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.LineariseRewards": [[240, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.ModuleTransform": [[241, 1, 1, "", "forward"], [241, 1, 1, "", "transform_action_spec"], [241, 1, 1, "", "transform_done_spec"], [241, 1, 1, "", "transform_observation_spec"], [241, 1, 1, "", "transform_reward_spec"], [241, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.MultiAction": [[242, 1, 1, "", "transform_input_spec"], [242, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.ObservationNorm": [[244, 1, 1, "", "init_stats"], [244, 1, 1, "", "transform_action_spec"], [244, 1, 1, "", "transform_observation_spec"], [244, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.PermuteTransform": [[246, 1, 1, "", "transform_input_spec"], [246, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.PinMemoryTransform": [[247, 1, 1, "", "forward"]], "torchrl.envs.transforms.R3MTransform": [[248, 1, 1, "", "to"]], "torchrl.envs.transforms.RandomCropTensorDict": [[249, 1, 1, "", "forward"]], "torchrl.envs.transforms.RemoveEmptySpecs": [[250, 1, 1, "", "forward"], [250, 1, 1, "", "transform_input_spec"], [250, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.RenameTransform": [[251, 1, 1, "", "forward"], [251, 1, 1, "", "transform_input_spec"], [251, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.Resize": [[252, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Reward2GoTransform": [[253, 1, 1, "", "forward"]], "torchrl.envs.transforms.RewardClipping": [[254, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardScaling": [[255, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardSum": [[256, 1, 1, "", "forward"], [256, 1, 1, "", "transform_input_spec"], [256, 1, 1, "", "transform_observation_spec"], [256, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.SelectTransform": [[257, 1, 1, "", "forward"], [257, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.SignTransform": [[258, 1, 1, "", "transform_observation_spec"], [258, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.Stack": [[260, 1, 1, "", "forward"], [260, 1, 1, "", "transform_done_spec"], [260, 1, 1, "", "transform_input_spec"], [260, 1, 1, "", "transform_observation_spec"], [260, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.StepCounter": [[261, 1, 1, "", "forward"], [261, 1, 1, "", "transform_input_spec"], [261, 1, 1, "", "transform_observation_spec"], [261, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.TargetReturn": [[262, 1, 1, "", "forward"], [262, 1, 1, "", "transform_input_spec"], [262, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TensorDictPrimer": [[263, 1, 1, "", "forward"], [263, 1, 1, "", "to"], [263, 1, 1, "", "transform_input_spec"], [263, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TimeMaxPool": [[264, 1, 1, "", "forward"], [264, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Timer": [[265, 1, 1, "", "forward"], [265, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ToTensorImage": [[266, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Tokenizer": [[267, 1, 1, "", "forward"], [267, 1, 1, "", "transform_done_spec"], [267, 1, 1, "", "transform_input_spec"], [267, 1, 1, "", "transform_observation_spec"], [267, 1, 1, "", "transform_output_spec"], [267, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.TrajCounter": [[268, 1, 1, "", "forward"], [268, 1, 1, "", "load_state_dict"], [268, 1, 1, "", "state_dict"], [268, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Transform": [[269, 1, 1, "", "clone"], [269, 1, 1, "", "close"], [269, 2, 1, "", "collector"], [269, 2, 1, "", "container"], [269, 1, 1, "", "forward"], [269, 1, 1, "", "init"], [269, 1, 1, "", "inv"], [269, 2, 1, "", "parent"], [269, 1, 1, "", "reset_parent"], [269, 1, 1, "", "set_container"], [269, 1, 1, "", "to"], [269, 1, 1, "", "transform_action_spec"], [269, 1, 1, "", "transform_done_spec"], [269, 1, 1, "", "transform_env_batch_size"], [269, 1, 1, "", "transform_env_device"], [269, 1, 1, "", "transform_input_spec"], [269, 1, 1, "", "transform_observation_spec"], [269, 1, 1, "", "transform_output_spec"], [269, 1, 1, "", "transform_reward_spec"], [269, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.TransformedEnv": [[270, 1, 1, "", "add_truncated_keys"], [270, 1, 1, "", "append_transform"], [270, 2, 1, "", "batch_locked"], [270, 2, 1, "", "batch_size"], [270, 1, 1, "", "empty_cache"], [270, 1, 1, "", "eval"], [270, 2, 1, "", "input_spec"], [270, 1, 1, "", "insert_transform"], [270, 1, 1, "", "load_state_dict"], [270, 2, 1, "", "output_spec"], [270, 1, 1, "", "rand_action"], [270, 1, 1, "", "set_missing_tolerance"], [270, 1, 1, "", "set_seed"], [270, 1, 1, "", "state_dict"], [270, 1, 1, "", "to"], [270, 1, 1, "", "train"]], "torchrl.envs.transforms.UnaryTransform": [[271, 1, 1, "", "transform_action_spec"], [271, 1, 1, "", "transform_done_spec"], [271, 1, 1, "", "transform_input_spec"], [271, 1, 1, "", "transform_observation_spec"], [271, 1, 1, "", "transform_output_spec"], [271, 1, 1, "", "transform_reward_spec"], [271, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.UnsqueezeTransform": [[272, 1, 1, "", "transform_action_spec"], [272, 1, 1, "", "transform_observation_spec"], [272, 1, 1, "", "transform_reward_spec"], [272, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.VC1Transform": [[273, 1, 1, "", "forward"], [273, 1, 1, "", "make_noload_model"], [273, 1, 1, "", "to"], [273, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VIPRewardTransform": [[274, 1, 1, "", "forward"], [274, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.VIPTransform": [[275, 1, 1, "", "to"]], "torchrl.envs.transforms.VecGymEnvTransform": [[276, 1, 1, "", "forward"], [276, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VecNorm": [[277, 1, 1, "", "build_td_for_shared_vecnorm"], [277, 1, 1, "", "forward"], [277, 1, 1, "", "freeze"], [277, 1, 1, "", "frozen_copy"], [277, 1, 1, "", "get_extra_state"], [277, 2, 1, "", "loc"], [277, 2, 1, "", "scale"], [277, 1, 1, "", "set_extra_state"], [277, 2, 1, "", "standard_normal"], [277, 1, 1, "", "to_observation_norm"], [277, 1, 1, "", "transform_observation_spec"], [277, 1, 1, "", "unfreeze"]], "torchrl.envs.transforms.VecNormV2": [[278, 1, 1, "", "clone"], [278, 1, 1, "id0", "freeze"], [278, 1, 1, "id1", "frozen_copy"], [278, 1, 1, "id2", "get_extra_state"], [278, 2, 1, "id3", "loc"], [278, 2, 1, "id4", "scale"], [278, 1, 1, "id5", "set_extra_state"], [278, 2, 1, "id6", "standard_normal"], [278, 1, 1, "", "to_observation_norm"], [278, 1, 1, "id7", "transform_observation_spec"], [278, 1, 1, "id8", "transform_output_spec"], [278, 1, 1, "id9", "transform_reward_spec"], [278, 1, 1, "id10", "unfreeze"]], "torchrl.implement_for": [[280, 1, 1, "", "get_class_that_defined_method"], [280, 1, 1, "", "import_module"], [280, 1, 1, "", "module_set"], [280, 1, 1, "", "reset"]], "torchrl.modules": [[281, 0, 1, "", "ActorCriticOperator"], [282, 0, 1, "", "ActorCriticWrapper"], [283, 0, 1, "", "ActorValueOperator"], [284, 0, 1, "", "AdditiveGaussianModule"], [285, 0, 1, "", "ConsistentDropoutModule"], [286, 0, 1, "", "ConvNet"], [287, 0, 1, "", "DTActor"], [288, 0, 1, "", "DdpgCnnActor"], [289, 0, 1, "", "DdpgCnnQNet"], [290, 0, 1, "", "DdpgMlpActor"], [291, 0, 1, "", "DdpgMlpQNet"], [292, 0, 1, "", "DecisionTransformer"], [293, 0, 1, "", "Delta"], [294, 0, 1, "", "DistributionalDQNnet"], [295, 0, 1, "", "DistributionalQValueActor"], [296, 0, 1, "", "DistributionalQValueModule"], [297, 0, 1, "", "DreamerActor"], [298, 0, 1, "", "DuelingCnnDQNet"], [299, 0, 1, "", "EGreedyModule"], [300, 0, 1, "", "GRUModule"], [301, 0, 1, "", "IndependentNormal"], [302, 0, 1, "", "LSTMModule"], [303, 0, 1, "", "MLP"], [304, 0, 1, "", "MaskedCategorical"], [305, 0, 1, "", "NormalParamExtractor"], [306, 0, 1, "", "ObsDecoder"], [307, 0, 1, "", "ObsEncoder"], [308, 0, 1, "", "OneHotCategorical"], [309, 0, 1, "", "OnlineDTActor"], [310, 0, 1, "", "OrnsteinUhlenbeckProcessModule"], [311, 0, 1, "", "QValueActor"], [312, 0, 1, "", "QValueModule"], [313, 0, 1, "", "RSSMPosterior"], [314, 0, 1, "", "RSSMPrior"], [315, 0, 1, "", "RSSMRollout"], [316, 0, 1, "", "ReparamGradientStrategy"], [317, 0, 1, "", "TanhDelta"], [318, 0, 1, "", "TanhNormal"], [319, 0, 1, "", "TruncatedNormal"], [320, 0, 1, "", "ValueOperator"], [321, 0, 1, "", "WorldModelWrapper"]], "torchrl.modules.ActorCriticOperator": [[281, 1, 1, "", "get_critic_operator"], [281, 1, 1, "", "get_policy_head"], [281, 1, 1, "", "get_value_head"], [281, 1, 1, "", "get_value_operator"]], "torchrl.modules.ActorCriticWrapper": [[282, 1, 1, "", "get_policy_head"], [282, 1, 1, "", "get_policy_operator"], [282, 1, 1, "", "get_value_head"], [282, 1, 1, "", "get_value_operator"]], "torchrl.modules.ActorValueOperator": [[283, 1, 1, "", "get_policy_head"], [283, 1, 1, "", "get_policy_operator"], [283, 1, 1, "", "get_value_head"], [283, 1, 1, "", "get_value_operator"]], "torchrl.modules.AdditiveGaussianModule": [[284, 1, 1, "", "forward"], [284, 1, 1, "", "step"]], "torchrl.modules.ConsistentDropoutModule": [[285, 1, 1, "", "forward"], [285, 1, 1, "", "make_tensordict_primer"]], "torchrl.modules.ConvNet": [[286, 1, 1, "", "default_atari_dqn"], [286, 1, 1, "", "forward"]], "torchrl.modules.DTActor": [[287, 1, 1, "", "default_config"], [287, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnActor": [[288, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnQNet": [[289, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpActor": [[290, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpQNet": [[291, 1, 1, "", "forward"]], "torchrl.modules.DecisionTransformer": [[292, 0, 1, "", "DTConfig"], [292, 1, 1, "", "forward"]], "torchrl.modules.Delta": [[293, 1, 1, "", "expand"], [293, 1, 1, "", "log_prob"], [293, 2, 1, "", "mean"], [293, 2, 1, "", "mode"], [293, 1, 1, "", "rsample"], [293, 1, 1, "", "sample"]], "torchrl.modules.DistributionalDQNnet": [[294, 1, 1, "", "forward"]], "torchrl.modules.DistributionalQValueModule": [[296, 1, 1, "", "forward"]], "torchrl.modules.DreamerActor": [[297, 1, 1, "", "forward"]], "torchrl.modules.DuelingCnnDQNet": [[298, 1, 1, "", "forward"]], "torchrl.modules.EGreedyModule": [[299, 1, 1, "", "forward"], [299, 1, 1, "", "step"]], "torchrl.modules.GRUModule": [[300, 1, 1, "", "forward"], [300, 1, 1, "", "make_cudnn_based"], [300, 1, 1, "", "make_python_based"], [300, 1, 1, "id0", "make_tensordict_primer"], [300, 1, 1, "", "set_recurrent_mode"]], "torchrl.modules.IndependentNormal": [[301, 2, 1, "", "mode"]], "torchrl.modules.LSTMModule": [[302, 1, 1, "", "forward"], [302, 1, 1, "", "make_cudnn_based"], [302, 1, 1, "", "make_python_based"], [302, 1, 1, "id0", "make_tensordict_primer"], [302, 1, 1, "", "set_recurrent_mode"]], "torchrl.modules.MLP": [[303, 1, 1, "", "forward"]], "torchrl.modules.MaskedCategorical": [[304, 1, 1, "", "entropy"], [304, 1, 1, "", "log_prob"], [304, 2, 1, "", "padding_value"], [304, 1, 1, "", "sample"]], "torchrl.modules.NormalParamExtractor": [[305, 1, 1, "", "forward"]], "torchrl.modules.ObsDecoder": [[306, 1, 1, "", "forward"]], "torchrl.modules.ObsEncoder": [[307, 1, 1, "", "forward"]], "torchrl.modules.OneHotCategorical": [[308, 1, 1, "", "entropy"], [308, 1, 1, "", "log_prob"], [308, 2, 1, "", "mode"], [308, 1, 1, "", "rsample"], [308, 1, 1, "", "sample"]], "torchrl.modules.OnlineDTActor": [[309, 1, 1, "", "default_config"], [309, 1, 1, "", "forward"]], "torchrl.modules.OrnsteinUhlenbeckProcessModule": [[310, 1, 1, "", "forward"], [310, 1, 1, "", "step"]], "torchrl.modules.QValueModule": [[312, 1, 1, "", "forward"]], "torchrl.modules.RSSMPosterior": [[313, 1, 1, "", "forward"]], "torchrl.modules.RSSMPrior": [[314, 1, 1, "", "forward"]], "torchrl.modules.RSSMRollout": [[315, 1, 1, "", "forward"]], "torchrl.modules.TanhDelta": [[317, 2, 1, "", "mean"], [317, 2, 1, "", "mode"]], "torchrl.modules.TanhNormal": [[318, 1, 1, "", "get_mode"], [318, 2, 1, "", "mean"], [318, 2, 1, "", "mode"], [318, 2, 1, "", "support"]], "torchrl.modules.TruncatedNormal": [[319, 1, 1, "", "log_prob"], [319, 2, 1, "", "mode"]], "torchrl.modules.WorldModelWrapper": [[321, 1, 1, "", "get_reward_operator"], [321, 1, 1, "", "get_transition_model_operator"]], "torchrl.modules.llm": [[322, 0, 1, "", "AsyncVLLM"], [323, 0, 1, "", "ChatHistory"], [324, 0, 1, "", "LLMWrapperBase"], [325, 0, 1, "", "LogProbs"], [326, 0, 1, "", "Masks"], [327, 0, 1, "", "RemoteTransformersWrapper"], [328, 0, 1, "", "Text"], [329, 0, 1, "", "Tokens"], [330, 0, 1, "", "TransformersWrapper"], [331, 0, 1, "", "make_async_vllm_engine"], [332, 0, 1, "", "make_vllm_worker"], [333, 0, 1, "", "stateless_init_process_group"], [334, 0, 1, "", "stateless_init_process_group_async"], [335, 0, 1, "", "vLLMWrapper"]], "torchrl.modules.llm.AsyncVLLM": [[322, 1, 1, "", "collective_rpc"], [322, 1, 1, "", "create_load_balancer"], [322, 1, 1, "", "from_pretrained"], [322, 1, 1, "", "generate"], [322, 1, 1, "", "get_cache_usage"], [322, 1, 1, "", "get_master_address"], [322, 1, 1, "", "get_master_port"], [322, 1, 1, "", "get_model_metadata"], [322, 1, 1, "", "get_num_unfinished_requests"], [322, 1, 1, "", "get_random_actor_index"], [322, 1, 1, "", "get_tp_size"], [322, 1, 1, "", "init_weight_update_group"], [322, 1, 1, "", "launch"], [322, 1, 1, "", "shutdown"], [322, 1, 1, "", "update_weights"]], "torchrl.modules.llm.ChatHistory": [[323, 1, 1, "", "cat"], [323, 1, 1, "", "default_spec"], [323, 2, 1, "", "device"], [323, 1, 1, "", "dumps"], [323, 1, 1, "", "fields"], [323, 1, 1, "", "from_any"], [323, 1, 1, "", "from_dataclass"], [323, 1, 1, "", "from_h5"], [323, 1, 1, "", "from_modules"], [323, 1, 1, "", "from_namedtuple"], [323, 1, 1, "", "from_pytree"], [323, 1, 1, "", "from_remote_init"], [323, 1, 1, "", "from_struct_array"], [323, 1, 1, "", "from_tensordict"], [323, 1, 1, "", "from_tuple"], [323, 1, 1, "", "fromkeys"], [323, 1, 1, "", "get"], [323, 1, 1, "", "lazy_stack"], [323, 1, 1, "", "load"], [323, 1, 1, "", "load_"], [323, 1, 1, "", "load_memmap"], [323, 1, 1, "", "load_state_dict"], [323, 1, 1, "", "maybe_dense_stack"], [323, 1, 1, "", "memmap"], [323, 1, 1, "", "memmap_"], [323, 1, 1, "", "memmap_like"], [323, 1, 1, "", "memmap_refresh_"], [323, 1, 1, "", "save"], [323, 1, 1, "", "set"], [323, 1, 1, "", "stack"], [323, 1, 1, "", "state_dict"], [323, 1, 1, "", "to_tensordict"], [323, 1, 1, "", "to_text"], [323, 1, 1, "", "to_tokens"], [323, 1, 1, "", "unbind"]], "torchrl.modules.llm.LLMWrapperBase": [[324, 1, 1, "", "add_module"], [324, 1, 1, "", "apply"], [324, 2, 1, "", "batching"], [324, 1, 1, "", "bfloat16"], [324, 1, 1, "", "buffers"], [324, 1, 1, "", "children"], [324, 1, 1, "", "cleanup_batching"], [324, 2, 1, "", "collector"], [324, 1, 1, "", "compile"], [324, 1, 1, "", "cpu"], [324, 1, 1, "", "cuda"], [324, 1, 1, "", "double"], [324, 1, 1, "", "eval"], [324, 1, 1, "", "extra_repr"], [324, 1, 1, "", "float"], [324, 1, 1, "", "forward"], [324, 1, 1, "", "get_batching_state"], [324, 1, 1, "", "get_buffer"], [324, 1, 1, "", "get_dist"], [324, 1, 1, "", "get_extra_state"], [324, 1, 1, "", "get_new_version"], [324, 1, 1, "", "get_parameter"], [324, 1, 1, "", "get_submodule"], [324, 1, 1, "", "half"], [324, 1, 1, "", "ipu"], [324, 1, 1, "", "is_tdmodule_compatible"], [324, 1, 1, "", "load_state_dict"], [324, 1, 1, "", "modules"], [324, 1, 1, "", "mtia"], [324, 1, 1, "", "named_buffers"], [324, 1, 1, "", "named_children"], [324, 1, 1, "", "named_modules"], [324, 1, 1, "", "named_parameters"], [324, 1, 1, "", "parameters"], [324, 1, 1, "", "register_backward_hook"], [324, 1, 1, "", "register_buffer"], [324, 1, 1, "", "register_collector"], [324, 1, 1, "", "register_forward_hook"], [324, 1, 1, "", "register_forward_pre_hook"], [324, 1, 1, "", "register_full_backward_hook"], [324, 1, 1, "", "register_full_backward_pre_hook"], [324, 1, 1, "", "register_load_state_dict_post_hook"], [324, 1, 1, "", "register_load_state_dict_pre_hook"], [324, 1, 1, "", "register_module"], [324, 1, 1, "", "register_parameter"], [324, 1, 1, "", "register_state_dict_post_hook"], [324, 1, 1, "", "register_state_dict_pre_hook"], [324, 1, 1, "", "requires_grad_"], [324, 1, 1, "", "reset_out_keys"], [324, 1, 1, "", "reset_parameters_recursive"], [324, 1, 1, "", "select_out_keys"], [324, 1, 1, "", "set_extra_state"], [324, 1, 1, "", "set_submodule"], [324, 1, 1, "", "share_memory"], [324, 1, 1, "", "state_dict"], [324, 1, 1, "", "to"], [324, 1, 1, "", "to_empty"], [324, 1, 1, "", "train"], [324, 1, 1, "", "type"], [324, 1, 1, "", "xpu"], [324, 1, 1, "", "zero_grad"]], "torchrl.modules.llm.LogProbs": [[325, 1, 1, "", "cat"], [325, 1, 1, "", "default_spec"], [325, 2, 1, "", "device"], [325, 1, 1, "", "dumps"], [325, 1, 1, "", "fields"], [325, 1, 1, "", "from_any"], [325, 1, 1, "", "from_dataclass"], [325, 1, 1, "", "from_h5"], [325, 1, 1, "", "from_modules"], [325, 1, 1, "", "from_namedtuple"], [325, 1, 1, "", "from_pytree"], [325, 1, 1, "", "from_remote_init"], [325, 1, 1, "", "from_struct_array"], [325, 1, 1, "", "from_tensordict"], [325, 1, 1, "", "from_tuple"], [325, 1, 1, "", "fromkeys"], [325, 1, 1, "", "get"], [325, 1, 1, "", "lazy_stack"], [325, 1, 1, "", "load"], [325, 1, 1, "", "load_"], [325, 1, 1, "", "load_memmap"], [325, 1, 1, "", "load_state_dict"], [325, 1, 1, "", "maybe_dense_stack"], [325, 1, 1, "", "memmap"], [325, 1, 1, "", "memmap_"], [325, 1, 1, "", "memmap_like"], [325, 1, 1, "", "memmap_refresh_"], [325, 1, 1, "", "save"], [325, 1, 1, "", "set"], [325, 1, 1, "", "stack"], [325, 1, 1, "", "state_dict"], [325, 1, 1, "", "to_tensordict"], [325, 1, 1, "", "unbind"]], "torchrl.modules.llm.Masks": [[326, 1, 1, "", "cat"], [326, 1, 1, "", "default_spec"], [326, 2, 1, "", "device"], [326, 1, 1, "", "dumps"], [326, 1, 1, "", "fields"], [326, 1, 1, "", "from_any"], [326, 1, 1, "", "from_dataclass"], [326, 1, 1, "", "from_h5"], [326, 1, 1, "", "from_modules"], [326, 1, 1, "", "from_namedtuple"], [326, 1, 1, "", "from_pytree"], [326, 1, 1, "", "from_remote_init"], [326, 1, 1, "", "from_struct_array"], [326, 1, 1, "", "from_tensordict"], [326, 1, 1, "", "from_tuple"], [326, 1, 1, "", "fromkeys"], [326, 1, 1, "", "get"], [326, 1, 1, "", "lazy_stack"], [326, 1, 1, "", "load"], [326, 1, 1, "", "load_"], [326, 1, 1, "", "load_memmap"], [326, 1, 1, "", "load_state_dict"], [326, 1, 1, "", "maybe_dense_stack"], [326, 1, 1, "", "memmap"], [326, 1, 1, "", "memmap_"], [326, 1, 1, "", "memmap_like"], [326, 1, 1, "", "memmap_refresh_"], [326, 1, 1, "", "save"], [326, 1, 1, "", "set"], [326, 1, 1, "", "stack"], [326, 1, 1, "", "state_dict"], [326, 1, 1, "", "to_tensordict"], [326, 1, 1, "", "unbind"]], "torchrl.modules.llm.RemoteTransformersWrapper": [[327, 2, 1, "", "batching"], [327, 1, 1, "", "cleanup_batching"], [327, 2, 1, "", "collector"], [327, 2, 1, "", "device"], [327, 2, 1, "", "dist_params_keys"], [327, 2, 1, "", "dist_sample_keys"], [327, 2, 1, "", "generate"], [327, 1, 1, "", "get_batching_state"], [327, 1, 1, "", "get_dist"], [327, 1, 1, "", "get_dist_with_prompt_mask"], [327, 1, 1, "", "get_new_version"], [327, 2, 1, "", "in_keys"], [327, 2, 1, "", "inplace"], [327, 2, 1, "", "layout"], [327, 1, 1, "", "log_prob"], [327, 2, 1, "", "log_prob_keys"], [327, 2, 1, "", "log_probs_key"], [327, 2, 1, "", "masks_key"], [327, 2, 1, "", "num_samples"], [327, 2, 1, "", "out_keys"], [327, 2, 1, "", "pad_output"], [327, 2, 1, "", "text_key"], [327, 2, 1, "", "tokens_key"]], "torchrl.modules.llm.Text": [[328, 1, 1, "", "cat"], [328, 1, 1, "", "default_spec"], [328, 2, 1, "", "device"], [328, 1, 1, "", "dumps"], [328, 1, 1, "", "fields"], [328, 1, 1, "", "from_any"], [328, 1, 1, "", "from_dataclass"], [328, 1, 1, "", "from_h5"], [328, 1, 1, "", "from_modules"], [328, 1, 1, "", "from_namedtuple"], [328, 1, 1, "", "from_pytree"], [328, 1, 1, "", "from_remote_init"], [328, 1, 1, "", "from_struct_array"], [328, 1, 1, "", "from_tensordict"], [328, 1, 1, "", "from_tuple"], [328, 1, 1, "", "fromkeys"], [328, 1, 1, "", "get"], [328, 1, 1, "", "lazy_stack"], [328, 1, 1, "", "load"], [328, 1, 1, "", "load_"], [328, 1, 1, "", "load_memmap"], [328, 1, 1, "", "load_state_dict"], [328, 1, 1, "", "maybe_dense_stack"], [328, 1, 1, "", "memmap"], [328, 1, 1, "", "memmap_"], [328, 1, 1, "", "memmap_like"], [328, 1, 1, "", "memmap_refresh_"], [328, 1, 1, "", "save"], [328, 1, 1, "", "set"], [328, 1, 1, "", "stack"], [328, 1, 1, "", "state_dict"], [328, 1, 1, "", "to_history"], [328, 1, 1, "", "to_tensordict"], [328, 1, 1, "", "to_tokens"], [328, 1, 1, "", "unbind"]], "torchrl.modules.llm.Tokens": [[329, 1, 1, "", "cat"], [329, 1, 1, "", "default_spec"], [329, 2, 1, "", "device"], [329, 1, 1, "", "dumps"], [329, 1, 1, "", "fields"], [329, 1, 1, "", "from_any"], [329, 1, 1, "", "from_dataclass"], [329, 1, 1, "", "from_h5"], [329, 1, 1, "", "from_modules"], [329, 1, 1, "", "from_namedtuple"], [329, 1, 1, "", "from_pytree"], [329, 1, 1, "", "from_remote_init"], [329, 1, 1, "", "from_struct_array"], [329, 1, 1, "", "from_tensordict"], [329, 1, 1, "", "from_tuple"], [329, 1, 1, "", "fromkeys"], [329, 1, 1, "", "get"], [329, 1, 1, "", "lazy_stack"], [329, 1, 1, "", "load"], [329, 1, 1, "", "load_"], [329, 1, 1, "", "load_memmap"], [329, 1, 1, "", "load_state_dict"], [329, 1, 1, "", "maybe_dense_stack"], [329, 1, 1, "", "memmap"], [329, 1, 1, "", "memmap_"], [329, 1, 1, "", "memmap_like"], [329, 1, 1, "", "memmap_refresh_"], [329, 1, 1, "", "save"], [329, 1, 1, "", "set"], [329, 1, 1, "", "stack"], [329, 1, 1, "", "state_dict"], [329, 1, 1, "", "to_history"], [329, 1, 1, "", "to_tensordict"], [329, 1, 1, "", "to_text"], [329, 1, 1, "", "unbind"]], "torchrl.modules.llm.TransformersWrapper": [[330, 1, 1, "", "add_module"], [330, 1, 1, "", "apply"], [330, 2, 1, "", "batching"], [330, 1, 1, "", "bfloat16"], [330, 1, 1, "", "buffers"], [330, 1, 1, "", "children"], [330, 1, 1, "", "cleanup_batching"], [330, 2, 1, "", "collector"], [330, 1, 1, "", "compile"], [330, 1, 1, "", "cpu"], [330, 1, 1, "", "cuda"], [330, 1, 1, "", "double"], [330, 1, 1, "", "eval"], [330, 1, 1, "", "extra_repr"], [330, 1, 1, "", "float"], [330, 1, 1, "", "forward"], [330, 1, 1, "", "get_batching_state"], [330, 1, 1, "", "get_buffer"], [330, 1, 1, "", "get_dist"], [330, 1, 1, "", "get_extra_state"], [330, 1, 1, "", "get_new_version"], [330, 1, 1, "", "get_parameter"], [330, 1, 1, "", "get_submodule"], [330, 1, 1, "", "half"], [330, 1, 1, "", "ipu"], [330, 1, 1, "", "is_tdmodule_compatible"], [330, 1, 1, "", "load_state_dict"], [330, 1, 1, "", "modules"], [330, 1, 1, "", "mtia"], [330, 1, 1, "", "named_buffers"], [330, 1, 1, "", "named_children"], [330, 1, 1, "", "named_modules"], [330, 1, 1, "", "named_parameters"], [330, 1, 1, "", "parameters"], [330, 1, 1, "", "register_backward_hook"], [330, 1, 1, "", "register_buffer"], [330, 1, 1, "", "register_collector"], [330, 1, 1, "", "register_forward_hook"], [330, 1, 1, "", "register_forward_pre_hook"], [330, 1, 1, "", "register_full_backward_hook"], [330, 1, 1, "", "register_full_backward_pre_hook"], [330, 1, 1, "", "register_load_state_dict_post_hook"], [330, 1, 1, "", "register_load_state_dict_pre_hook"], [330, 1, 1, "", "register_module"], [330, 1, 1, "", "register_parameter"], [330, 1, 1, "", "register_state_dict_post_hook"], [330, 1, 1, "", "register_state_dict_pre_hook"], [330, 1, 1, "", "repeat_interleave_causal"], [330, 1, 1, "", "requires_grad_"], [330, 1, 1, "", "reset_out_keys"], [330, 1, 1, "", "reset_parameters_recursive"], [330, 1, 1, "", "select_out_keys"], [330, 1, 1, "", "set_extra_state"], [330, 1, 1, "", "set_submodule"], [330, 1, 1, "", "share_memory"], [330, 1, 1, "", "state_dict"], [330, 1, 1, "", "to"], [330, 1, 1, "", "to_empty"], [330, 1, 1, "", "train"], [330, 1, 1, "", "type"], [330, 1, 1, "", "xpu"], [330, 1, 1, "", "zero_grad"]], "torchrl.modules.llm.vLLMWrapper": [[335, 1, 1, "", "add_module"], [335, 1, 1, "", "apply"], [335, 2, 1, "", "batching"], [335, 1, 1, "", "bfloat16"], [335, 1, 1, "", "buffers"], [335, 1, 1, "", "children"], [335, 1, 1, "", "cleanup_batching"], [335, 2, 1, "", "collector"], [335, 1, 1, "", "compile"], [335, 1, 1, "", "cpu"], [335, 1, 1, "", "cuda"], [335, 1, 1, "", "double"], [335, 1, 1, "", "eval"], [335, 1, 1, "", "extra_repr"], [335, 1, 1, "", "float"], [335, 1, 1, "", "forward"], [335, 1, 1, "", "get_batching_state"], [335, 1, 1, "", "get_buffer"], [335, 1, 1, "", "get_dist"], [335, 1, 1, "", "get_dist_with_prompt_mask"], [335, 1, 1, "", "get_extra_state"], [335, 1, 1, "", "get_new_version"], [335, 1, 1, "", "get_parameter"], [335, 1, 1, "", "get_submodule"], [335, 1, 1, "", "half"], [335, 1, 1, "", "ipu"], [335, 1, 1, "", "is_tdmodule_compatible"], [335, 1, 1, "", "load_state_dict"], [335, 1, 1, "", "modules"], [335, 1, 1, "", "mtia"], [335, 1, 1, "", "named_buffers"], [335, 1, 1, "", "named_children"], [335, 1, 1, "", "named_modules"], [335, 1, 1, "", "named_parameters"], [335, 1, 1, "", "parameters"], [335, 1, 1, "", "register_backward_hook"], [335, 1, 1, "", "register_buffer"], [335, 1, 1, "", "register_collector"], [335, 1, 1, "", "register_forward_hook"], [335, 1, 1, "", "register_forward_pre_hook"], [335, 1, 1, "", "register_full_backward_hook"], [335, 1, 1, "", "register_full_backward_pre_hook"], [335, 1, 1, "", "register_load_state_dict_post_hook"], [335, 1, 1, "", "register_load_state_dict_pre_hook"], [335, 1, 1, "", "register_module"], [335, 1, 1, "", "register_parameter"], [335, 1, 1, "", "register_state_dict_post_hook"], [335, 1, 1, "", "register_state_dict_pre_hook"], [335, 1, 1, "", "requires_grad_"], [335, 1, 1, "", "reset_out_keys"], [335, 1, 1, "", "reset_parameters_recursive"], [335, 1, 1, "", "select_out_keys"], [335, 1, 1, "", "set_extra_state"], [335, 1, 1, "", "set_submodule"], [335, 1, 1, "", "set_tokenizer"], [335, 1, 1, "", "share_memory"], [335, 1, 1, "", "state_dict"], [335, 1, 1, "", "to"], [335, 1, 1, "", "to_empty"], [335, 1, 1, "", "train"], [335, 1, 1, "", "type"], [335, 1, 1, "", "xpu"], [335, 1, 1, "", "zero_grad"]], "torchrl.modules.models.utils": [[336, 0, 1, "", "SquashDims"]], "torchrl.modules.models.utils.SquashDims": [[336, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module": [[337, 0, 1, "", "Actor"], [338, 0, 1, "", "MultiStepActorWrapper"], [339, 0, 1, "", "ProbabilisticActor"], [340, 0, 1, "", "SafeModule"], [341, 0, 1, "", "SafeProbabilisticModule"], [342, 0, 1, "", "SafeProbabilisticTensorDictSequential"], [343, 0, 1, "", "SafeSequential"], [344, 0, 1, "", "TanhModule"]], "torchrl.modules.tensordict_module.MultiStepActorWrapper": [[338, 1, 1, "", "forward"], [338, 2, 1, "", "init_key"]], "torchrl.modules.tensordict_module.SafeModule": [[340, 1, 1, "", "random"], [340, 1, 1, "", "random_sample"], [340, 1, 1, "", "to"]], "torchrl.modules.tensordict_module.SafeProbabilisticModule": [[341, 1, 1, "", "random"], [341, 1, 1, "", "random_sample"]], "torchrl.modules.tensordict_module.TanhModule": [[344, 1, 1, "", "forward"]], "torchrl.objectives": [[345, 0, 1, "", "A2CLoss"], [346, 0, 1, "", "CQLLoss"], [347, 0, 1, "", "ClipPPOLoss"], [348, 0, 1, "", "CrossQLoss"], [349, 0, 1, "", "DDPGLoss"], [350, 0, 1, "", "DQNLoss"], [351, 0, 1, "", "DTLoss"], [352, 0, 1, "", "DiscreteCQLLoss"], [353, 0, 1, "", "DiscreteIQLLoss"], [354, 0, 1, "", "DiscreteSACLoss"], [355, 0, 1, "", "DistributionalDQNLoss"], [356, 0, 1, "", "DreamerActorLoss"], [357, 0, 1, "", "DreamerModelLoss"], [358, 0, 1, "", "DreamerValueLoss"], [359, 0, 1, "", "GAILLoss"], [360, 0, 1, "", "IQLLoss"], [361, 0, 1, "", "KLPENPPOLoss"], [362, 0, 1, "", "LossModule"], [363, 0, 1, "", "OnlineDTLoss"], [364, 0, 1, "", "PPOLoss"], [365, 0, 1, "", "REDQLoss"], [366, 0, 1, "", "ReinforceLoss"], [367, 0, 1, "", "SACLoss"], [368, 0, 1, "", "TD3BCLoss"], [369, 0, 1, "", "TD3Loss"], [370, 0, 1, "", "ValueEstimators"], [371, 0, 1, "", "add_random_module"]], "torchrl.objectives.A2CLoss": [[345, 4, 1, "", "default_keys"], [345, 1, 1, "", "forward"], [345, 2, 1, "", "functional"], [345, 1, 1, "", "loss_critic"], [345, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.CQLLoss": [[346, 4, 1, "", "default_keys"], [346, 1, 1, "", "forward"], [346, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ClipPPOLoss": [[347, 1, 1, "", "forward"]], "torchrl.objectives.CrossQLoss": [[348, 1, 1, "", "actor_loss"], [348, 1, 1, "", "alpha_loss"], [348, 4, 1, "", "default_keys"], [348, 1, 1, "", "forward"], [348, 1, 1, "", "load_state_dict"], [348, 1, 1, "", "make_value_estimator"], [348, 1, 1, "", "maybe_init_target_entropy"], [348, 1, 1, "", "qvalue_loss"], [348, 1, 1, "", "set_keys"], [348, 1, 1, "", "state_dict"], [348, 2, 1, "", "target_entropy_buffer"]], "torchrl.objectives.DDPGLoss": [[349, 4, 1, "", "default_keys"], [349, 1, 1, "", "forward"], [349, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DQNLoss": [[350, 4, 1, "", "default_keys"], [350, 1, 1, "", "forward"], [350, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DTLoss": [[351, 4, 1, "", "default_keys"], [351, 1, 1, "", "forward"]], "torchrl.objectives.DiscreteCQLLoss": [[352, 4, 1, "", "default_keys"], [352, 1, 1, "", "forward"], [352, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DiscreteIQLLoss": [[353, 4, 1, "", "default_keys"], [353, 1, 1, "", "forward"]], "torchrl.objectives.DiscreteSACLoss": [[354, 1, 1, "", "actor_loss"], [354, 1, 1, "", "alpha_loss"], [354, 4, 1, "", "default_keys"], [354, 1, 1, "", "forward"], [354, 1, 1, "", "make_value_estimator"], [354, 1, 1, "", "qvalue_loss"]], "torchrl.objectives.DistributionalDQNLoss": [[355, 4, 1, "", "default_keys"], [355, 1, 1, "", "forward"], [355, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerActorLoss": [[356, 4, 1, "", "default_keys"], [356, 1, 1, "", "forward"], [356, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerModelLoss": [[357, 4, 1, "", "default_keys"], [357, 1, 1, "", "forward"]], "torchrl.objectives.DreamerValueLoss": [[358, 4, 1, "", "default_keys"], [358, 1, 1, "", "forward"]], "torchrl.objectives.GAILLoss": [[359, 4, 1, "", "default_keys"], [359, 1, 1, "", "forward"]], "torchrl.objectives.IQLLoss": [[360, 4, 1, "", "default_keys"], [360, 1, 1, "", "forward"], [360, 1, 1, "", "loss_value_diff"], [360, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.KLPENPPOLoss": [[361, 1, 1, "", "forward"]], "torchrl.objectives.LossModule": [[362, 1, 1, "", "convert_to_functional"], [362, 1, 1, "", "forward"], [362, 1, 1, "", "from_stateful_net"], [362, 2, 1, "", "functional"], [362, 1, 1, "", "get_stateful_net"], [362, 1, 1, "", "make_value_estimator"], [362, 1, 1, "", "named_parameters"], [362, 1, 1, "", "parameters"], [362, 1, 1, "", "reset_parameters_recursive"], [362, 1, 1, "", "set_keys"], [362, 2, 1, "", "value_estimator"], [362, 2, 1, "", "vmap_randomness"]], "torchrl.objectives.OnlineDTLoss": [[363, 4, 1, "", "default_keys"], [363, 1, 1, "", "forward"]], "torchrl.objectives.PPOLoss": [[364, 4, 1, "", "default_keys"], [364, 1, 1, "", "forward"], [364, 2, 1, "", "functional"], [364, 1, 1, "", "loss_critic"], [364, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.REDQLoss": [[365, 4, 1, "", "default_keys"], [365, 1, 1, "", "forward"], [365, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ReinforceLoss": [[366, 4, 1, "", "default_keys"], [366, 1, 1, "", "forward"], [366, 2, 1, "", "functional"], [366, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.SACLoss": [[367, 1, 1, "", "actor_loss"], [367, 1, 1, "", "alpha_loss"], [367, 4, 1, "", "default_keys"], [367, 1, 1, "", "forward"], [367, 1, 1, "", "load_state_dict"], [367, 1, 1, "", "make_value_estimator"], [367, 1, 1, "", "qvalue_loss"], [367, 1, 1, "", "state_dict"], [367, 1, 1, "", "value_loss"]], "torchrl.objectives.TD3BCLoss": [[368, 1, 1, "", "actor_loss"], [368, 4, 1, "", "default_keys"], [368, 1, 1, "", "forward"], [368, 1, 1, "", "make_value_estimator"], [368, 1, 1, "", "qvalue_loss"]], "torchrl.objectives.TD3Loss": [[369, 4, 1, "", "default_keys"], [369, 1, 1, "", "forward"], [369, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.llm": [[372, 0, 1, "", "CISPOLossOutput"], [373, 0, 1, "", "DAPO"], [374, 0, 1, "", "DAPOLossOutput"], [375, 0, 1, "", "GRPOLoss"], [376, 0, 1, "", "GRPOLossOutput"], [377, 0, 1, "", "LLMLossOutput"], [378, 0, 1, "", "MCAdvantage"], [379, 0, 1, "", "SFTLoss"], [380, 0, 1, "", "SFTLossOutput"]], "torchrl.objectives.llm.CISPOLossOutput": [[372, 1, 1, "", "cat"], [372, 2, 1, "", "device"], [372, 1, 1, "", "dumps"], [372, 1, 1, "", "fields"], [372, 1, 1, "", "from_any"], [372, 1, 1, "", "from_dataclass"], [372, 1, 1, "", "from_h5"], [372, 1, 1, "", "from_modules"], [372, 1, 1, "", "from_namedtuple"], [372, 1, 1, "", "from_pytree"], [372, 1, 1, "", "from_remote_init"], [372, 1, 1, "", "from_struct_array"], [372, 1, 1, "", "from_tensordict"], [372, 1, 1, "", "from_tuple"], [372, 1, 1, "", "fromkeys"], [372, 1, 1, "", "get"], [372, 1, 1, "", "lazy_stack"], [372, 1, 1, "", "load"], [372, 1, 1, "", "load_"], [372, 1, 1, "", "load_memmap"], [372, 1, 1, "", "load_state_dict"], [372, 1, 1, "", "maybe_dense_stack"], [372, 1, 1, "", "memmap"], [372, 1, 1, "", "memmap_"], [372, 1, 1, "", "memmap_like"], [372, 1, 1, "", "memmap_refresh_"], [372, 1, 1, "", "save"], [372, 1, 1, "", "set"], [372, 1, 1, "", "stack"], [372, 1, 1, "", "state_dict"], [372, 1, 1, "", "to_tensordict"], [372, 1, 1, "", "unbind"]], "torchrl.objectives.llm.DAPO": [[373, 1, 1, "", "add_module"], [373, 1, 1, "", "apply"], [373, 1, 1, "", "bfloat16"], [373, 1, 1, "", "buffers"], [373, 1, 1, "", "children"], [373, 1, 1, "", "compile"], [373, 1, 1, "", "convert_to_functional"], [373, 1, 1, "", "cpu"], [373, 1, 1, "", "cuda"], [373, 1, 1, "", "double"], [373, 1, 1, "", "eval"], [373, 1, 1, "", "extra_repr"], [373, 1, 1, "", "float"], [373, 1, 1, "", "forward"], [373, 1, 1, "", "from_stateful_net"], [373, 2, 1, "", "functional"], [373, 1, 1, "", "get_buffer"], [373, 1, 1, "", "get_extra_state"], [373, 1, 1, "", "get_parameter"], [373, 1, 1, "", "get_stateful_net"], [373, 1, 1, "", "get_submodule"], [373, 1, 1, "", "half"], [373, 1, 1, "", "ipu"], [373, 1, 1, "", "is_tdmodule_compatible"], [373, 1, 1, "", "load_state_dict"], [373, 1, 1, "", "make_value_estimator"], [373, 1, 1, "", "modules"], [373, 1, 1, "", "mtia"], [373, 1, 1, "", "named_buffers"], [373, 1, 1, "", "named_children"], [373, 1, 1, "", "named_modules"], [373, 1, 1, "", "named_parameters"], [373, 4, 1, "", "output_type"], [373, 1, 1, "", "parameters"], [373, 1, 1, "", "register_backward_hook"], [373, 1, 1, "", "register_buffer"], [373, 1, 1, "", "register_forward_hook"], [373, 1, 1, "", "register_forward_pre_hook"], [373, 1, 1, "", "register_full_backward_hook"], [373, 1, 1, "", "register_full_backward_pre_hook"], [373, 1, 1, "", "register_load_state_dict_post_hook"], [373, 1, 1, "", "register_load_state_dict_pre_hook"], [373, 1, 1, "", "register_module"], [373, 1, 1, "", "register_parameter"], [373, 1, 1, "", "register_state_dict_post_hook"], [373, 1, 1, "", "register_state_dict_pre_hook"], [373, 1, 1, "", "requires_grad_"], [373, 1, 1, "", "reset_out_keys"], [373, 1, 1, "", "reset_parameters_recursive"], [373, 1, 1, "", "select_out_keys"], [373, 1, 1, "", "set_extra_state"], [373, 1, 1, "", "set_keys"], [373, 1, 1, "", "set_submodule"], [373, 1, 1, "", "share_memory"], [373, 1, 1, "", "state_dict"], [373, 2, 1, "", "tensor_keys"], [373, 1, 1, "", "to"], [373, 1, 1, "", "to_empty"], [373, 1, 1, "", "train"], [373, 1, 1, "", "type"], [373, 2, 1, "", "value_estimator"], [373, 2, 1, "", "vmap_randomness"], [373, 1, 1, "", "xpu"], [373, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.DAPOLossOutput": [[374, 1, 1, "", "cat"], [374, 2, 1, "", "device"], [374, 1, 1, "", "dumps"], [374, 1, 1, "", "fields"], [374, 1, 1, "", "from_any"], [374, 1, 1, "", "from_dataclass"], [374, 1, 1, "", "from_h5"], [374, 1, 1, "", "from_modules"], [374, 1, 1, "", "from_namedtuple"], [374, 1, 1, "", "from_pytree"], [374, 1, 1, "", "from_remote_init"], [374, 1, 1, "", "from_struct_array"], [374, 1, 1, "", "from_tensordict"], [374, 1, 1, "", "from_tuple"], [374, 1, 1, "", "fromkeys"], [374, 1, 1, "", "get"], [374, 1, 1, "", "lazy_stack"], [374, 1, 1, "", "load"], [374, 1, 1, "", "load_"], [374, 1, 1, "", "load_memmap"], [374, 1, 1, "", "load_state_dict"], [374, 1, 1, "", "maybe_dense_stack"], [374, 1, 1, "", "memmap"], [374, 1, 1, "", "memmap_"], [374, 1, 1, "", "memmap_like"], [374, 1, 1, "", "memmap_refresh_"], [374, 1, 1, "", "save"], [374, 1, 1, "", "set"], [374, 1, 1, "", "stack"], [374, 1, 1, "", "state_dict"], [374, 1, 1, "", "to_tensordict"], [374, 1, 1, "", "unbind"]], "torchrl.objectives.llm.GRPOLoss": [[375, 1, 1, "", "add_module"], [375, 1, 1, "", "apply"], [375, 1, 1, "", "bfloat16"], [375, 1, 1, "", "buffers"], [375, 1, 1, "", "children"], [375, 1, 1, "", "compile"], [375, 1, 1, "", "convert_to_functional"], [375, 1, 1, "", "cpu"], [375, 1, 1, "", "cuda"], [375, 1, 1, "", "double"], [375, 1, 1, "", "eval"], [375, 1, 1, "", "extra_repr"], [375, 1, 1, "", "float"], [375, 1, 1, "", "forward"], [375, 1, 1, "", "from_stateful_net"], [375, 2, 1, "", "functional"], [375, 1, 1, "", "get_buffer"], [375, 1, 1, "", "get_extra_state"], [375, 1, 1, "", "get_parameter"], [375, 1, 1, "", "get_stateful_net"], [375, 1, 1, "", "get_submodule"], [375, 1, 1, "", "half"], [375, 1, 1, "", "ipu"], [375, 1, 1, "", "is_tdmodule_compatible"], [375, 1, 1, "", "load_state_dict"], [375, 1, 1, "", "make_value_estimator"], [375, 1, 1, "", "modules"], [375, 1, 1, "", "mtia"], [375, 1, 1, "", "named_buffers"], [375, 1, 1, "", "named_children"], [375, 1, 1, "", "named_modules"], [375, 1, 1, "", "named_parameters"], [375, 4, 1, "", "output_type"], [375, 1, 1, "", "parameters"], [375, 1, 1, "", "register_backward_hook"], [375, 1, 1, "", "register_buffer"], [375, 1, 1, "", "register_forward_hook"], [375, 1, 1, "", "register_forward_pre_hook"], [375, 1, 1, "", "register_full_backward_hook"], [375, 1, 1, "", "register_full_backward_pre_hook"], [375, 1, 1, "", "register_load_state_dict_post_hook"], [375, 1, 1, "", "register_load_state_dict_pre_hook"], [375, 1, 1, "", "register_module"], [375, 1, 1, "", "register_parameter"], [375, 1, 1, "", "register_state_dict_post_hook"], [375, 1, 1, "", "register_state_dict_pre_hook"], [375, 1, 1, "", "requires_grad_"], [375, 1, 1, "", "reset_out_keys"], [375, 1, 1, "", "reset_parameters_recursive"], [375, 1, 1, "", "select_out_keys"], [375, 1, 1, "", "set_extra_state"], [375, 1, 1, "", "set_keys"], [375, 1, 1, "", "set_submodule"], [375, 1, 1, "", "share_memory"], [375, 1, 1, "", "state_dict"], [375, 2, 1, "", "tensor_keys"], [375, 1, 1, "", "to"], [375, 1, 1, "", "to_empty"], [375, 1, 1, "", "train"], [375, 1, 1, "", "type"], [375, 2, 1, "", "value_estimator"], [375, 2, 1, "", "vmap_randomness"], [375, 1, 1, "", "xpu"], [375, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.GRPOLossOutput": [[376, 1, 1, "", "cat"], [376, 2, 1, "", "device"], [376, 1, 1, "", "dumps"], [376, 1, 1, "", "fields"], [376, 1, 1, "", "from_any"], [376, 1, 1, "", "from_dataclass"], [376, 1, 1, "", "from_h5"], [376, 1, 1, "", "from_modules"], [376, 1, 1, "", "from_namedtuple"], [376, 1, 1, "", "from_pytree"], [376, 1, 1, "", "from_remote_init"], [376, 1, 1, "", "from_struct_array"], [376, 1, 1, "", "from_tensordict"], [376, 1, 1, "", "from_tuple"], [376, 1, 1, "", "fromkeys"], [376, 1, 1, "", "get"], [376, 1, 1, "", "lazy_stack"], [376, 1, 1, "", "load"], [376, 1, 1, "", "load_"], [376, 1, 1, "", "load_memmap"], [376, 1, 1, "", "load_state_dict"], [376, 1, 1, "", "maybe_dense_stack"], [376, 1, 1, "", "memmap"], [376, 1, 1, "", "memmap_"], [376, 1, 1, "", "memmap_like"], [376, 1, 1, "", "memmap_refresh_"], [376, 1, 1, "", "save"], [376, 1, 1, "", "set"], [376, 1, 1, "", "stack"], [376, 1, 1, "", "state_dict"], [376, 1, 1, "", "to_tensordict"], [376, 1, 1, "", "unbind"]], "torchrl.objectives.llm.LLMLossOutput": [[377, 1, 1, "", "cat"], [377, 2, 1, "", "device"], [377, 1, 1, "", "dumps"], [377, 1, 1, "", "fields"], [377, 1, 1, "", "from_any"], [377, 1, 1, "", "from_dataclass"], [377, 1, 1, "", "from_h5"], [377, 1, 1, "", "from_modules"], [377, 1, 1, "", "from_namedtuple"], [377, 1, 1, "", "from_pytree"], [377, 1, 1, "", "from_remote_init"], [377, 1, 1, "", "from_struct_array"], [377, 1, 1, "", "from_tensordict"], [377, 1, 1, "", "from_tuple"], [377, 1, 1, "", "fromkeys"], [377, 1, 1, "", "get"], [377, 1, 1, "", "lazy_stack"], [377, 1, 1, "", "load"], [377, 1, 1, "", "load_"], [377, 1, 1, "", "load_memmap"], [377, 1, 1, "", "load_state_dict"], [377, 1, 1, "", "maybe_dense_stack"], [377, 1, 1, "", "memmap"], [377, 1, 1, "", "memmap_"], [377, 1, 1, "", "memmap_like"], [377, 1, 1, "", "memmap_refresh_"], [377, 1, 1, "", "save"], [377, 1, 1, "", "set"], [377, 1, 1, "", "stack"], [377, 1, 1, "", "state_dict"], [377, 1, 1, "", "to_tensordict"], [377, 1, 1, "", "unbind"]], "torchrl.objectives.llm.MCAdvantage": [[378, 1, 1, "", "add_module"], [378, 1, 1, "", "apply"], [378, 1, 1, "", "bfloat16"], [378, 1, 1, "", "buffers"], [378, 1, 1, "", "children"], [378, 1, 1, "", "close"], [378, 2, 1, "", "collector"], [378, 1, 1, "", "compile"], [378, 2, 1, "", "container"], [378, 1, 1, "", "cpu"], [378, 1, 1, "", "cuda"], [378, 1, 1, "", "double"], [378, 1, 1, "", "eval"], [378, 1, 1, "", "extra_repr"], [378, 1, 1, "", "float"], [378, 1, 1, "", "forward"], [378, 1, 1, "", "get_buffer"], [378, 1, 1, "", "get_extra_state"], [378, 1, 1, "", "get_parameter"], [378, 1, 1, "", "get_submodule"], [378, 1, 1, "", "half"], [378, 1, 1, "", "init"], [378, 1, 1, "", "inv"], [378, 1, 1, "", "ipu"], [378, 1, 1, "", "load_state_dict"], [378, 1, 1, "", "modules"], [378, 1, 1, "", "mtia"], [378, 1, 1, "", "named_buffers"], [378, 1, 1, "", "named_children"], [378, 1, 1, "", "named_modules"], [378, 1, 1, "", "named_parameters"], [378, 1, 1, "", "parameters"], [378, 2, 1, "", "parent"], [378, 1, 1, "", "register_backward_hook"], [378, 1, 1, "", "register_buffer"], [378, 1, 1, "", "register_forward_hook"], [378, 1, 1, "", "register_forward_pre_hook"], [378, 1, 1, "", "register_full_backward_hook"], [378, 1, 1, "", "register_full_backward_pre_hook"], [378, 1, 1, "", "register_load_state_dict_post_hook"], [378, 1, 1, "", "register_load_state_dict_pre_hook"], [378, 1, 1, "", "register_module"], [378, 1, 1, "", "register_parameter"], [378, 1, 1, "", "register_state_dict_post_hook"], [378, 1, 1, "", "register_state_dict_pre_hook"], [378, 1, 1, "", "requires_grad_"], [378, 1, 1, "", "set_extra_state"], [378, 1, 1, "", "set_submodule"], [378, 1, 1, "", "share_memory"], [378, 1, 1, "", "state_dict"], [378, 1, 1, "", "to"], [378, 1, 1, "", "to_empty"], [378, 1, 1, "", "train"], [378, 1, 1, "", "transform_action_spec"], [378, 1, 1, "", "transform_done_spec"], [378, 1, 1, "", "transform_env_batch_size"], [378, 1, 1, "", "transform_env_device"], [378, 1, 1, "", "transform_input_spec"], [378, 1, 1, "", "transform_observation_spec"], [378, 1, 1, "", "transform_output_spec"], [378, 1, 1, "", "transform_reward_spec"], [378, 1, 1, "", "transform_state_spec"], [378, 1, 1, "", "type"], [378, 1, 1, "", "xpu"], [378, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.SFTLoss": [[379, 1, 1, "", "add_module"], [379, 1, 1, "", "apply"], [379, 1, 1, "", "bfloat16"], [379, 1, 1, "", "buffers"], [379, 1, 1, "", "children"], [379, 1, 1, "", "compile"], [379, 1, 1, "", "convert_to_functional"], [379, 1, 1, "", "cpu"], [379, 1, 1, "", "cuda"], [379, 4, 1, "", "default_keys"], [379, 1, 1, "", "double"], [379, 1, 1, "", "eval"], [379, 1, 1, "", "extra_repr"], [379, 1, 1, "", "float"], [379, 1, 1, "", "forward"], [379, 1, 1, "", "from_stateful_net"], [379, 2, 1, "", "functional"], [379, 1, 1, "", "get_buffer"], [379, 1, 1, "", "get_extra_state"], [379, 1, 1, "", "get_parameter"], [379, 1, 1, "", "get_stateful_net"], [379, 1, 1, "", "get_submodule"], [379, 1, 1, "", "half"], [379, 1, 1, "", "ipu"], [379, 1, 1, "", "is_tdmodule_compatible"], [379, 1, 1, "", "load_state_dict"], [379, 1, 1, "", "make_value_estimator"], [379, 1, 1, "", "modules"], [379, 1, 1, "", "mtia"], [379, 1, 1, "", "named_buffers"], [379, 1, 1, "", "named_children"], [379, 1, 1, "", "named_modules"], [379, 1, 1, "", "named_parameters"], [379, 1, 1, "", "parameters"], [379, 1, 1, "", "register_backward_hook"], [379, 1, 1, "", "register_buffer"], [379, 1, 1, "", "register_forward_hook"], [379, 1, 1, "", "register_forward_pre_hook"], [379, 1, 1, "", "register_full_backward_hook"], [379, 1, 1, "", "register_full_backward_pre_hook"], [379, 1, 1, "", "register_load_state_dict_post_hook"], [379, 1, 1, "", "register_load_state_dict_pre_hook"], [379, 1, 1, "", "register_module"], [379, 1, 1, "", "register_parameter"], [379, 1, 1, "", "register_state_dict_post_hook"], [379, 1, 1, "", "register_state_dict_pre_hook"], [379, 1, 1, "", "requires_grad_"], [379, 1, 1, "", "reset_out_keys"], [379, 1, 1, "", "reset_parameters_recursive"], [379, 1, 1, "", "select_out_keys"], [379, 1, 1, "", "set_extra_state"], [379, 1, 1, "", "set_keys"], [379, 1, 1, "", "set_submodule"], [379, 1, 1, "", "share_memory"], [379, 1, 1, "", "state_dict"], [379, 1, 1, "", "to"], [379, 1, 1, "", "to_empty"], [379, 1, 1, "", "train"], [379, 1, 1, "", "type"], [379, 2, 1, "", "value_estimator"], [379, 2, 1, "", "vmap_randomness"], [379, 1, 1, "", "xpu"], [379, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.SFTLossOutput": [[380, 1, 1, "", "cat"], [380, 2, 1, "", "device"], [380, 1, 1, "", "dumps"], [380, 1, 1, "", "fields"], [380, 1, 1, "", "from_any"], [380, 1, 1, "", "from_dataclass"], [380, 1, 1, "", "from_h5"], [380, 1, 1, "", "from_modules"], [380, 1, 1, "", "from_namedtuple"], [380, 1, 1, "", "from_pytree"], [380, 1, 1, "", "from_remote_init"], [380, 1, 1, "", "from_struct_array"], [380, 1, 1, "", "from_tensordict"], [380, 1, 1, "", "from_tuple"], [380, 1, 1, "", "fromkeys"], [380, 1, 1, "", "get"], [380, 1, 1, "", "lazy_stack"], [380, 1, 1, "", "load"], [380, 1, 1, "", "load_"], [380, 1, 1, "", "load_memmap"], [380, 1, 1, "", "load_state_dict"], [380, 1, 1, "", "maybe_dense_stack"], [380, 1, 1, "", "memmap"], [380, 1, 1, "", "memmap_"], [380, 1, 1, "", "memmap_like"], [380, 1, 1, "", "memmap_refresh_"], [380, 1, 1, "", "save"], [380, 1, 1, "", "set"], [380, 1, 1, "", "stack"], [380, 1, 1, "", "state_dict"], [380, 1, 1, "", "to_tensordict"], [380, 1, 1, "", "unbind"]], "torchrl.objectives.value": [[381, 0, 1, "", "GAE"], [382, 0, 1, "", "TD0Estimator"], [383, 0, 1, "", "TD1Estimator"], [384, 0, 1, "", "TDLambdaEstimator"], [385, 0, 1, "", "ValueEstimatorBase"]], "torchrl.objectives.value.GAE": [[381, 1, 1, "", "forward"], [381, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD0Estimator": [[382, 1, 1, "", "forward"], [382, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD1Estimator": [[383, 1, 1, "", "forward"], [383, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TDLambdaEstimator": [[384, 1, 1, "", "forward"], [384, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.ValueEstimatorBase": [[385, 4, 1, "", "default_keys"], [385, 1, 1, "", "forward"], [385, 1, 1, "", "set_keys"], [385, 1, 1, "", "value_estimate"]], "torchrl.record": [[386, 3, 1, "", "PixelRenderTransform"], [387, 3, 1, "", "TensorDictRecorder"], [388, 3, 1, "", "VideoRecorder"]], "torchrl.record.loggers": [[389, 3, 1, "", "Logger"], [391, 3, 1, "", "generate_exp_name"], [392, 3, 1, "", "get_logger"]], "torchrl.record.loggers.csv": [[390, 3, 1, "", "CSVLogger"]], "torchrl.record.loggers.mlflow": [[393, 3, 1, "", "MLFlowLogger"]], "torchrl.record.loggers.tensorboard": [[394, 3, 1, "", "TensorboardLogger"]], "torchrl.record.loggers.wandb": [[395, 3, 1, "", "WandbLogger"]], "torchrl.services": [[396, 0, 1, "", "RayService"], [397, 0, 1, "", "ServiceBase"], [398, 0, 1, "", "get_services"]], "torchrl.services.RayService": [[396, 1, 1, "", "get"], [396, 1, 1, "", "list"], [396, 1, 1, "", "register"], [396, 1, 1, "", "register_with_options"], [396, 1, 1, "", "reset"], [396, 1, 1, "", "shutdown"]], "torchrl.services.ServiceBase": [[397, 1, 1, "", "get"], [397, 1, 1, "", "list"], [397, 1, 1, "", "register"], [397, 1, 1, "", "reset"]], "torchrl.trainers": [[400, 0, 1, "", "BatchSubSampler"], [401, 0, 1, "", "ClearCudaCache"], [402, 0, 1, "", "CountFramesLog"], [403, 0, 1, "", "LogScalar"], [404, 0, 1, "", "LogValidationReward"], [405, 0, 1, "", "OptimizerHook"], [406, 0, 1, "", "ReplayBufferTrainer"], [407, 0, 1, "", "RewardNormalizer"], [408, 0, 1, "", "SelectKeys"], [409, 0, 1, "", "TargetNetUpdaterHook"], [410, 0, 1, "", "Trainer"], [411, 0, 1, "", "TrainerHookBase"], [412, 0, 1, "", "UTDRHook"], [413, 0, 1, "", "UpdateWeights"]], "torchrl.trainers.BatchSubSampler": [[400, 1, 1, "", "register"]], "torchrl.trainers.ClearCudaCache": [[401, 1, 1, "", "register"]], "torchrl.trainers.CountFramesLog": [[402, 1, 1, "", "register"]], "torchrl.trainers.LogScalar": [[403, 1, 1, "", "register"]], "torchrl.trainers.LogValidationReward": [[404, 1, 1, "", "register"]], "torchrl.trainers.OptimizerHook": [[405, 1, 1, "", "register"]], "torchrl.trainers.ReplayBufferTrainer": [[406, 1, 1, "", "register"]], "torchrl.trainers.RewardNormalizer": [[407, 1, 1, "", "register"]], "torchrl.trainers.SelectKeys": [[408, 1, 1, "", "register"]], "torchrl.trainers.TargetNetUpdaterHook": [[409, 1, 1, "", "register"]], "torchrl.trainers.Trainer": [[410, 1, 1, "", "load_from_file"]], "torchrl.trainers.TrainerHookBase": [[411, 1, 1, "", "register"]], "torchrl.trainers.UTDRHook": [[412, 1, 1, "", "load_state_dict"], [412, 1, 1, "", "register"], [412, 1, 1, "", "state_dict"]], "torchrl.trainers.UpdateWeights": [[413, 1, 1, "", "register"]], "torchrl.trainers.algorithms": [[414, 0, 1, "", "PPOTrainer"], [415, 0, 1, "", "SACTrainer"]], "torchrl.trainers.algorithms.PPOTrainer": [[414, 1, 1, "", "load_from_file"]], "torchrl.trainers.algorithms.SACTrainer": [[415, 1, 1, "", "load_from_file"]], "torchrl.trainers.algorithms.configs.collectors": [[416, 0, 1, "", "AsyncDataCollectorConfig"], [417, 0, 1, "", "DataCollectorConfig"], [418, 0, 1, "", "MultiSyncDataCollectorConfig"], [419, 0, 1, "", "MultiaSyncDataCollectorConfig"], [420, 0, 1, "", "SyncDataCollectorConfig"]], "torchrl.trainers.algorithms.configs.common": [[421, 0, 1, "", "ConfigBase"]], "torchrl.trainers.algorithms.configs.data": [[422, 0, 1, "", "LazyMemmapStorageConfig"], [423, 0, 1, "", "LazyStackStorageConfig"], [424, 0, 1, "", "LazyTensorStorageConfig"], [425, 0, 1, "", "ListStorageConfig"], [426, 0, 1, "", "PrioritizedSamplerConfig"], [427, 0, 1, "", "RandomSamplerConfig"], [428, 0, 1, "", "ReplayBufferConfig"], [429, 0, 1, "", "RoundRobinWriterConfig"], [430, 0, 1, "", "SamplerWithoutReplacementConfig"], [431, 0, 1, "", "SliceSamplerConfig"], [432, 0, 1, "", "SliceSamplerWithoutReplacementConfig"], [433, 0, 1, "", "StorageEnsembleConfig"], [434, 0, 1, "", "StorageEnsembleWriterConfig"], [435, 0, 1, "", "TensorDictReplayBufferConfig"], [436, 0, 1, "", "TensorStorageConfig"]], "torchrl.trainers.algorithms.configs.envs": [[437, 0, 1, "", "BatchedEnvConfig"], [438, 0, 1, "", "EnvConfig"], [439, 0, 1, "", "TransformedEnvConfig"]], "torchrl.trainers.algorithms.configs.envs_libs": [[440, 0, 1, "", "BraxEnvConfig"], [441, 0, 1, "", "DMControlEnvConfig"], [442, 0, 1, "", "EnvLibsConfig"], [443, 0, 1, "", "GymEnvConfig"], [444, 0, 1, "", "HabitatEnvConfig"], [445, 0, 1, "", "IsaacGymEnvConfig"], [446, 0, 1, "", "JumanjiEnvConfig"], [447, 0, 1, "", "MOGymEnvConfig"], [448, 0, 1, "", "MeltingpotEnvConfig"], [449, 0, 1, "", "MultiThreadedEnvConfig"], [450, 0, 1, "", "OpenMLEnvConfig"], [451, 0, 1, "", "OpenSpielEnvConfig"], [452, 0, 1, "", "PettingZooEnvConfig"], [453, 0, 1, "", "RoboHiveEnvConfig"], [454, 0, 1, "", "SMACv2EnvConfig"], [455, 0, 1, "", "UnityMLAgentsEnvConfig"], [456, 0, 1, "", "VmasEnvConfig"]], "torchrl.trainers.algorithms.configs.logging": [[457, 0, 1, "", "CSVLoggerConfig"], [458, 0, 1, "", "LoggerConfig"], [459, 0, 1, "", "TensorboardLoggerConfig"], [460, 0, 1, "", "WandbLoggerConfig"]], "torchrl.trainers.algorithms.configs.modules": [[461, 0, 1, "", "ConvNetConfig"], [462, 0, 1, "", "MLPConfig"], [463, 0, 1, "", "ModelConfig"], [464, 0, 1, "", "NetworkConfig"], [465, 0, 1, "", "TanhNormalModelConfig"], [466, 0, 1, "", "TensorDictModuleConfig"], [467, 0, 1, "", "ValueModelConfig"]], "torchrl.trainers.algorithms.configs.objectives": [[468, 0, 1, "", "LossConfig"], [469, 0, 1, "", "PPOLossConfig"]], "torchrl.trainers.algorithms.configs.trainers": [[470, 0, 1, "", "PPOTrainerConfig"], [471, 0, 1, "", "TrainerConfig"]], "torchrl.trainers.algorithms.configs.transforms": [[472, 0, 1, "", "ActionDiscretizerConfig"], [473, 0, 1, "", "ActionMaskConfig"], [474, 0, 1, "", "AutoResetTransformConfig"], [475, 0, 1, "", "BatchSizeTransformConfig"], [476, 0, 1, "", "BinarizeRewardConfig"], [477, 0, 1, "", "BurnInTransformConfig"], [478, 0, 1, "", "CatFramesConfig"], [479, 0, 1, "", "CatTensorsConfig"], [480, 0, 1, "", "CenterCropConfig"], [481, 0, 1, "", "ClipTransformConfig"], [482, 0, 1, "", "ComposeConfig"], [483, 0, 1, "", "ConditionalPolicySwitchConfig"], [484, 0, 1, "", "ConditionalSkipConfig"], [485, 0, 1, "", "CropConfig"], [486, 0, 1, "", "DTypeCastTransformConfig"], [487, 0, 1, "", "DeviceCastTransformConfig"], [488, 0, 1, "", "DiscreteActionProjectionConfig"], [489, 0, 1, "", "DoubleToFloatConfig"], [490, 0, 1, "", "EndOfLifeTransformConfig"], [491, 0, 1, "", "ExcludeTransformConfig"], [492, 0, 1, "", "FiniteTensorDictCheckConfig"], [493, 0, 1, "", "FlattenObservationConfig"], [494, 0, 1, "", "FrameSkipTransformConfig"], [495, 0, 1, "", "GrayScaleConfig"], [496, 0, 1, "", "HashConfig"], [497, 0, 1, "", "InitTrackerConfig"], [498, 0, 1, "", "KLRewardTransformConfig"], [499, 0, 1, "", "LineariseRewardsConfig"], [500, 0, 1, "", "MultiActionConfig"], [501, 0, 1, "", "MultiStepTransformConfig"], [502, 0, 1, "", "NoopResetEnvConfig"], [503, 0, 1, "", "ObservationNormConfig"], [504, 0, 1, "", "PermuteTransformConfig"], [505, 0, 1, "", "PinMemoryTransformConfig"], [506, 0, 1, "", "R3MTransformConfig"], [507, 0, 1, "", "RandomCropTensorDictConfig"], [508, 0, 1, "", "RemoveEmptySpecsConfig"], [509, 0, 1, "", "RenameTransformConfig"], [510, 0, 1, "", "ResizeConfig"], [511, 0, 1, "", "Reward2GoTransformConfig"], [512, 0, 1, "", "RewardClippingConfig"], [513, 0, 1, "", "RewardScalingConfig"], [514, 0, 1, "", "RewardSumConfig"], [515, 0, 1, "", "SelectTransformConfig"], [516, 0, 1, "", "SignTransformConfig"], [517, 0, 1, "", "SqueezeTransformConfig"], [518, 0, 1, "", "StackConfig"], [519, 0, 1, "", "StepCounterConfig"], [520, 0, 1, "", "TargetReturnConfig"], [521, 0, 1, "", "TensorDictPrimerConfig"], [522, 0, 1, "", "TimeMaxPoolConfig"], [523, 0, 1, "", "TimerConfig"], [524, 0, 1, "", "ToTensorImageConfig"], [525, 0, 1, "", "TokenizerConfig"], [526, 0, 1, "", "TrajCounterConfig"], [527, 0, 1, "", "TransformConfig"], [528, 0, 1, "", "UnaryTransformConfig"], [529, 0, 1, "", "UnsqueezeTransformConfig"], [530, 0, 1, "", "VC1TransformConfig"], [531, 0, 1, "", "VIPRewardTransformConfig"], [532, 0, 1, "", "VIPTransformConfig"], [533, 0, 1, "", "VecGymEnvTransformConfig"], [534, 0, 1, "", "VecNormConfig"], [535, 0, 1, "", "VecNormV2Config"]], "torchrl.trainers.algorithms.configs.utils": [[536, 0, 1, "", "ASGDConfig"], [537, 0, 1, "", "AdadeltaConfig"], [538, 0, 1, "", "AdagradConfig"], [539, 0, 1, "", "AdamConfig"], [540, 0, 1, "", "AdamWConfig"], [541, 0, 1, "", "AdamaxConfig"], [542, 0, 1, "", "LBFGSConfig"], [543, 0, 1, "", "LionConfig"], [544, 0, 1, "", "NAdamConfig"], [545, 0, 1, "", "RAdamConfig"], [546, 0, 1, "", "RMSpropConfig"], [547, 0, 1, "", "RpropConfig"], [548, 0, 1, "", "SGDConfig"], [549, 0, 1, "", "SparseAdamConfig"]], "torchrl.trainers.helpers": [[550, 3, 1, "", "correct_for_frame_skip"], [551, 3, 1, "", "get_stats_random_rollout"], [552, 3, 1, "", "make_collector_offpolicy"], [553, 3, 1, "", "make_collector_onpolicy"], [554, 3, 1, "", "make_dqn_loss"], [555, 3, 1, "", "make_replay_buffer"], [556, 3, 1, "", "make_target_updater"], [557, 3, 1, "", "make_trainer"], [558, 3, 1, "", "parallel_env_constructor"], [559, 3, 1, "", "sync_async_collector"], [560, 3, 1, "", "sync_sync_collector"], [561, 3, 1, "", "transformed_env_constructor"]], "torchrl.weight_update": [[562, 0, 1, "", "DistributedTransport"], [563, 0, 1, "", "DistributedWeightSyncScheme"], [564, 0, 1, "", "MPTransport"], [565, 0, 1, "", "MultiProcessWeightSyncScheme"], [566, 0, 1, "", "NoWeightSyncScheme"], [567, 0, 1, "", "RPCTransport"], [568, 0, 1, "", "RPCWeightSyncScheme"], [569, 0, 1, "", "RayActorTransport"], [570, 0, 1, "", "RayModuleTransformReceiver"], [571, 0, 1, "", "RayModuleTransformScheme"], [572, 0, 1, "", "RayModuleTransformSender"], [573, 0, 1, "", "RayTransport"], [574, 0, 1, "", "RayWeightSyncScheme"], [575, 0, 1, "", "SharedMemTransport"], [576, 0, 1, "", "SharedMemWeightSyncScheme"], [577, 0, 1, "", "TransportBackend"], [578, 0, 1, "", "WeightReceiver"], [579, 0, 1, "", "WeightSender"], [580, 0, 1, "", "WeightSyncScheme"]], "torchrl.weight_update.DistributedTransport": [[562, 1, 1, "", "check_connection"], [562, 1, 1, "", "receive_weights"], [562, 1, 1, "", "send_ack"], [562, 1, 1, "", "send_weights"], [562, 1, 1, "", "send_weights_async"], [562, 1, 1, "", "wait_ack"]], "torchrl.weight_update.DistributedWeightSyncScheme": [[563, 1, 1, "", "create_receiver"], [563, 1, 1, "", "create_sender"], [563, 1, 1, "", "create_transport"], [563, 1, 1, "", "get_receiver"], [563, 1, 1, "", "get_sender"], [563, 1, 1, "", "init_on_sender"], [563, 1, 1, "", "init_on_worker"], [563, 1, 1, "", "prepare_weights"]], "torchrl.weight_update.MPTransport": [[564, 1, 1, "", "check_ack"], [564, 1, 1, "", "receive_weights"], [564, 1, 1, "", "send_ack"], [564, 1, 1, "", "send_weights"], [564, 1, 1, "", "send_weights_async"], [564, 1, 1, "", "wait_ack"]], "torchrl.weight_update.MultiProcessWeightSyncScheme": [[565, 1, 1, "", "create_receiver"], [565, 1, 1, "", "create_sender"], [565, 1, 1, "", "create_transport"], [565, 1, 1, "", "get_receiver"], [565, 1, 1, "", "get_sender"], [565, 1, 1, "", "init_on_sender"], [565, 1, 1, "", "init_on_worker"], [565, 1, 1, "", "prepare_weights"]], "torchrl.weight_update.NoWeightSyncScheme": [[566, 1, 1, "", "create_receiver"], [566, 1, 1, "", "create_sender"], [566, 1, 1, "", "create_transport"], [566, 1, 1, "", "get_receiver"], [566, 1, 1, "", "get_sender"], [566, 1, 1, "", "init_on_sender"], [566, 1, 1, "", "init_on_worker"], [566, 1, 1, "", "prepare_weights"]], "torchrl.weight_update.RPCTransport": [[567, 1, 1, "", "check_connection"], [567, 1, 1, "", "receive_weights"], [567, 1, 1, "", "send_weights"], [567, 1, 1, "", "send_weights_async"], [567, 1, 1, "", "wait_ack"]], "torchrl.weight_update.RPCWeightSyncScheme": [[568, 1, 1, "", "create_receiver"], [568, 1, 1, "", "create_sender"], [568, 1, 1, "", "create_transport"], [568, 1, 1, "", "get_receiver"], [568, 1, 1, "", "get_sender"], [568, 1, 1, "", "init_on_sender"], [568, 1, 1, "", "init_on_worker"], [568, 1, 1, "", "prepare_weights"]], "torchrl.weight_update.RayActorTransport": [[569, 1, 1, "", "check_ack"], [569, 1, 1, "", "check_connection"], [569, 1, 1, "", "receive_weights"], [569, 1, 1, "", "send_ack"], [569, 1, 1, "", "send_weights"], [569, 1, 1, "", "send_weights_async"], [569, 1, 1, "", "set_actor"], [569, 1, 1, "", "wait_ack"]], "torchrl.weight_update.RayModuleTransformReceiver": [[570, 1, 1, "", "apply_weights"], [570, 1, 1, "", "receive"]], "torchrl.weight_update.RayModuleTransformScheme": [[571, 1, 1, "", "create_receiver"], [571, 1, 1, "", "create_sender"], [571, 1, 1, "", "create_transport"], [571, 1, 1, "", "get_receiver"], [571, 1, 1, "", "get_sender"], [571, 1, 1, "", "init_on_sender"], [571, 1, 1, "", "init_on_worker"], [571, 1, 1, "", "prepare_weights"]], "torchrl.weight_update.RayModuleTransformSender": [[572, 1, 1, "", "send"], [572, 1, 1, "", "send_async"], [572, 1, 1, "", "update_weights"], [572, 1, 1, "", "wait_async"]], "torchrl.weight_update.RayTransport": [[573, 1, 1, "", "check_connection"], [573, 1, 1, "", "receive_weights"], [573, 1, 1, "", "send_weights"], [573, 1, 1, "", "send_weights_async"], [573, 1, 1, "", "wait_ack"]], "torchrl.weight_update.RayWeightSyncScheme": [[574, 1, 1, "", "create_receiver"], [574, 1, 1, "", "create_sender"], [574, 1, 1, "", "create_transport"], [574, 1, 1, "", "get_receiver"], [574, 1, 1, "", "get_sender"], [574, 1, 1, "", "init_on_sender"], [574, 1, 1, "", "init_on_worker"], [574, 1, 1, "", "prepare_weights"]], "torchrl.weight_update.SharedMemTransport": [[575, 1, 1, "", "check_ack"], [575, 1, 1, "", "check_connection"], [575, 1, 1, "", "receive_weights"], [575, 1, 1, "", "register_pipe"], [575, 1, 1, "", "register_weights"], [575, 1, 1, "", "send_ack"], [575, 1, 1, "", "send_weights"]], "torchrl.weight_update.SharedMemWeightSyncScheme": [[576, 1, 1, "", "create_receiver"], [576, 1, 1, "", "create_sender"], [576, 1, 1, "", "create_transport"], [576, 1, 1, "", "get_receiver"], [576, 1, 1, "", "get_sender"], [576, 1, 1, "", "init_on_sender"], [576, 1, 1, "", "init_on_worker"], [576, 1, 1, "", "prepare_weights"], [576, 1, 1, "", "register_shared_weights"]], "torchrl.weight_update.TransportBackend": [[577, 1, 1, "", "check_connection"], [577, 1, 1, "", "receive_weights"], [577, 1, 1, "", "send_weights"]], "torchrl.weight_update.WeightReceiver": [[578, 1, 1, "", "apply_weights"], [578, 1, 1, "", "receive"]], "torchrl.weight_update.WeightSender": [[579, 1, 1, "", "send"], [579, 1, 1, "", "send_async"], [579, 1, 1, "", "update_weights"], [579, 1, 1, "", "wait_async"]], "torchrl.weight_update.WeightSyncScheme": [[580, 1, 1, "", "create_receiver"], [580, 1, 1, "", "create_sender"], [580, 1, 1, "", "create_transport"], [580, 1, 1, "", "get_receiver"], [580, 1, 1, "", "get_sender"], [580, 1, 1, "", "init_on_sender"], [580, 1, 1, "", "init_on_worker"], [580, 1, 1, "", "prepare_weights"]], "torchrl.weight_update.llm": [[581, 0, 1, "", "VLLMCollectiveTransport"], [582, 0, 1, "", "VLLMDoubleBufferSyncScheme"], [583, 0, 1, "", "VLLMDoubleBufferTransport"], [584, 0, 1, "", "VLLMDoubleBufferWeightReceiver"], [585, 0, 1, "", "VLLMDoubleBufferWeightSender"], [586, 0, 1, "", "VLLMWeightReceiver"], [587, 0, 1, "", "VLLMWeightSender"], [588, 0, 1, "", "VLLMWeightSyncScheme"], [589, 0, 1, "", "get_model_metadata"]], "torchrl.weight_update.llm.VLLMCollectiveTransport": [[581, 1, 1, "", "check_connection"], [581, 1, 1, "", "init_all_workers_group"], [581, 1, 1, "", "receive_weights"], [581, 1, 1, "", "send_weights"]], "torchrl.weight_update.llm.VLLMDoubleBufferSyncScheme": [[582, 1, 1, "", "create_receiver"], [582, 1, 1, "", "create_sender"], [582, 1, 1, "", "create_transport"], [582, 1, 1, "", "get_receiver"], [582, 1, 1, "", "get_sender"], [582, 1, 1, "", "init_on_sender"], [582, 1, 1, "", "init_on_worker"], [582, 1, 1, "", "prepare_weights"]], "torchrl.weight_update.llm.VLLMDoubleBufferTransport": [[583, 1, 1, "", "check_connection"], [583, 1, 1, "", "receive_weights"], [583, 1, 1, "", "send_weights"]], "torchrl.weight_update.llm.VLLMDoubleBufferWeightReceiver": [[584, 1, 1, "", "apply_weights"], [584, 1, 1, "", "poll_and_apply"], [584, 1, 1, "", "receive"]], "torchrl.weight_update.llm.VLLMDoubleBufferWeightSender": [[585, 1, 1, "", "register_model"], [585, 1, 1, "", "send"], [585, 1, 1, "", "send_async"], [585, 1, 1, "", "update_weights"], [585, 1, 1, "", "wait_async"]], "torchrl.weight_update.llm.VLLMWeightReceiver": [[586, 1, 1, "", "apply_weights"], [586, 1, 1, "", "init_all_workers_group"], [586, 1, 1, "", "poll_and_apply"], [586, 1, 1, "", "receive"]], "torchrl.weight_update.llm.VLLMWeightSender": [[587, 1, 1, "", "init_all_workers_group"], [587, 1, 1, "", "register_model"], [587, 1, 1, "", "send"], [587, 1, 1, "", "send_async"], [587, 1, 1, "", "update_weights"], [587, 1, 1, "", "wait_async"]], "torchrl.weight_update.llm.VLLMWeightSyncScheme": [[588, 1, 1, "", "create_receiver"], [588, 1, 1, "", "create_sender"], [588, 1, 1, "", "create_transport"], [588, 1, 1, "", "get_receiver"], [588, 1, 1, "", "get_sender"], [588, 1, 1, "", "init_on_sender"], [588, 1, 1, "", "init_on_worker"], [588, 1, 1, "", "prepare_weights"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:property", "3": "py:function", "4": "py:attribute"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "property", "Python property"], "3": ["py", "function", "Python function"], "4": ["py", "attribute", "Python attribute"]}, "titleterms": {"torchrl": [0, 1, 7, 10, 16, 17, 25, 28, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 600, 607, 615, 619, 621, 622, 623, 625, 627, 633, 634, 636, 637, 638, 642, 643], "instal": [0, 25, 26, 633, 642], "get": [0, 7, 614, 626, 627, 628, 629, 630, 631], "start": [0, 7, 614, 626, 627, 628, 629, 630, 631, 633], "tutori": [0, 623, 636, 637], "basic": [0, 2, 7, 614, 616, 633, 640], "intermedi": [0, 27], "advanc": [0, 614], "refer": [0, 591, 614], "knowledg": [0, 592], "base": [0, 7, 17, 26, 592, 593, 605, 613, 625], "indic": 0, "tabl": 0, "collector": [1, 2, 3, 4, 5, 6, 416, 417, 418, 419, 420, 594, 621, 622, 623, 624, 629, 631, 636, 637, 642], "packag": [1, 10, 16, 600, 607, 615, 619], "kei": [1, 10, 16, 21, 593, 600, 607, 614, 615], "featur": [1, 10, 16, 600, 607, 614, 615], "quick": [1, 7, 10, 16, 593, 600, 607, 615], "exampl": [1, 6, 7, 10, 16, 22, 30, 593, 600, 607, 614, 615, 622, 634, 640], "document": [1, 10, 16, 28, 593, 600, 607, 615], "section": [1, 10, 16, 593, 600, 607, 615], "batch": [2, 17, 22, 621, 638, 640], "size": [2, 17, 621, 640], "polici": [2, 23, 612, 621, 623, 624, 625, 627, 631, 635, 636, 637, 638], "copi": 2, "distribut": [3, 603], "replai": [4, 7, 12, 21, 621, 622, 623, 624, 629, 631, 636, 637, 640, 642], "buffer": [4, 7, 12, 21, 621, 622, 623, 624, 629, 631, 636, 637, 640, 642], "interoper": 4, "helper": [4, 17, 606, 633], "function": [4, 23, 593, 622, 623, 628, 636, 637, 642], "singl": [5, 23], "node": 5, "data": [5, 7, 10, 12, 23, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 595, 597, 621, 622, 623, 629, 631, 636, 637, 642], "run": [5, 7, 625, 626, 643], "asynchron": 5, "weight": [6, 593, 594], "synchron": [6, 594], "usag": [6, 7, 614], "us": [6, 21, 23, 25, 28, 624, 639, 640, 642], "updat": [6, 593, 621], "scheme": [6, 594], "independ": 6, "sender": 6, "receiv": 6, "transport": 6, "legaci": [6, 593], "send": 6, "model": [6, 7, 23, 605, 621, 622, 624, 625, 628, 639, 642], "weightupdat": 6, "extend": 6, "class": [6, 7, 12, 17, 22, 595, 597, 603, 638, 642], "configur": [7, 614, 633], "system": [7, 14], "simpl": [7, 625, 638], "categori": 7, "group": [7, 636], "more": [7, 640], "complex": [7, 640], "parallel": [7, 22, 621, 635, 643], "environ": [7, 17, 18, 19, 21, 22, 23, 25, 26, 593, 596, 621, 622, 623, 624, 626, 631, 633, 634, 635, 636, 637, 638, 642, 643], "transform": [7, 21, 269, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 593, 599, 621, 623, 626, 634, 636, 637, 638, 640, 642, 643], "avail": [7, 18, 21], "option": [7, 26, 614], "complet": 7, "train": [7, 23, 27, 617, 621, 623, 624, 625, 628, 631, 636, 637, 638], "experi": [7, 621, 638], "hyperparamet": [7, 622, 623, 636, 637], "sweep": 7, "custom": [7, 17, 30, 614, 638, 640], "file": 7, "store": [7, 622, 640], "implement": [7, 23], "detail": [7, 22], "librari": [7, 18, 642], "network": [7, 602, 621, 622, 623, 624, 627, 636, 637], "collect": [7, 622, 623, 629], "storag": [7, 12, 15, 107, 621, 629, 640], "optim": [7, 23, 621, 622, 628, 631], "log": [7, 457, 458, 459, 460, 630, 634], "creat": [7, 626], "best": [7, 614], "practic": [7, 614], "futur": 7, "extens": 7, "dataset": 11, "core": [12, 593], "compos": [12, 223], "support": 12, "type": 12, "choos": 12, "sampl": [12, 13, 640], "index": 12, "strategi": [13, 604], "writer": [13, 115], "tensorspec": [14, 71], "backend": 15, "perform": [15, 614, 633], "env": [16, 17, 437, 438, 439, 638, 642, 643], "api": [17, 591, 614], "spec": [17, 18, 21, 638, 643], "lock": [17, 22], "method": [17, 608, 610, 612, 613, 621], "nativ": 17, "domain": 17, "specif": [17, 593, 616, 635], "wrapper": [18, 593, 597, 627, 634], "auto": 18, "reset": [18, 22, 638, 643], "dynam": [18, 23, 640], "multi": [19, 635, 636, 637], "agent": [19, 23, 636, 637], "record": [20, 618, 621, 630], "video": [20, 30, 630], "forward": [21, 23, 621], "invers": 21, "understand": 21, "tensor": [21, 640], "expos": 21, "outsid": 21, "world": [21, 605], "design": [21, 593, 631], "your": [21, 23, 25, 621, 625, 631, 638], "own": [21, 631], "tip": 21, "subclass": 21, "clone": [21, 26], "mask": [21, 326], "action": [21, 23, 624, 638], "vector": [22, 642], "partial": 22, "step": [22, 621, 623, 626, 629, 633, 636, 637, 640, 643], "async": [22, 642], "thing": [23, 621, 638], "consid": 23, "when": [23, 26], "debug": 23, "rl": [23, 28, 605, 610, 626, 628, 634, 642], "gener": [23, 30], "have": 23, "you": 23, "valid": [23, 634], "algorithm": [23, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 616], "few": 23, "small": 23, "toi": 23, "problem": 23, "known": 23, "return": 23, "e": 23, "g": 23, "gridworld": 23, "mountaincar": 23, "visual": 23, "Be": 23, "veri": 23, "care": 23, "ani": 23, "augment": 23, "doe": 23, "entropi": 23, "converg": 23, "too": [23, 27], "quickli": 23, "slowli": 23, "chang": [23, 642], "drastic": 23, "reward": [23, 593, 595], "beyond": 23, "go": 23, "up": [23, 25], "Is": 23, "favor": 23, "compon": [23, 593, 609], "i": 23, "veloc": 23, "vs": 23, "l2": 23, "magnitud": 23, "task": [23, 593, 635], "horizon": 23, "extrem": 23, "long": 23, "ar": 23, "normal": [23, 621, 622, 623], "standard": 23, "explor": [23, 604, 621, 622, 627, 634], "valu": [23, 601, 602, 609, 613, 621, 623, 624, 627], "loss": [23, 611, 621, 622, 623, 624, 631, 636, 637], "earli": 23, "roughli": 23, "uniformli": 23, "random": [23, 636, 637], "intrins": 23, "decai": 23, "learn": [23, 623, 636, 637], "progress": 23, "singleton": 23, "episod": 23, "remain": 23, "constant": [23, 622], "increas": 23, "an": [23, 623, 624, 626, 638], "can": 23, "low": 23, "also": [23, 614], "offlin": [23, 610], "observ": [23, 621], "space": 23, "effect": [23, 638], "dramat": 23, "dure": [23, 26], "high": 23, "dimension": 23, "work": [24, 25, 26, 614, 625], "gym": [24, 642, 643], "what": 24, "openai": 24, "version": [24, 26, 29], "habitat": 25, "lab": 25, "set": [25, 30], "from": [25, 26], "pip": [25, 26], "common": [25, 26, 27, 421, 609], "issu": [25, 26, 29], "mujoco": 26, "prerequisit": [26, 621], "render": [26, 30, 631, 636, 637, 643], "all": 26, "new": 26, "bindindg": 26, "2": [26, 633, 634], "1": [26, 633, 634], "old": 26, "bind": 26, "py": 26, "repo": [26, 28], "import": [26, 621, 634], "pytorch": [27, 28, 29, 625], "error": [27, 634], "solut": 27, "gradient": [27, 612], "relat": 27, "newcom": 27, "my": 27, "slow": 27, "bug": 27, "resourc": 28, "paper": 28, "functorch": 28, "blog": 28, "websit": 28, "educ": 28, "forum": 28, "how": [29, 614], "reproduc": [29, 638], "workaround": 29, "customis": 30, "tweak": 30, "principl": 30, "auto_unwrap_transformed_env": 31, "datacollectorbas": 32, "multiprocessedweightupdat": 33, "multisyncdatacollector": 34, "multiasyncdatacollector": 35, "rayweightupdat": 36, "syncdatacollector": 37, "vanillaweightupdat": 38, "weightupdaterbas": 39, "asyncdatacollector": 40, "distributeddatacollector": 41, "distributedsyncdatacollector": 42, "distributedweightupdat": 43, "rpcdatacollector": 44, "rpcweightupdat": 45, "raycollector": 46, "submitit_delayed_launch": 47, "llmcollector": 48, "rayllmcollector": 49, "vllmupdat": 50, "vllmupdaterv2": 51, "split_trajectori": 52, "binari": [53, 625], "bound": 54, "categor": 55, "composit": 56, "discretetensorspec": 57, "lazystackedcompositespec": 58, "multicategor": 59, "multidiscretetensorspec": 60, "multionehot": 61, "nontensor": 62, "onehot": 63, "prioritizedreplaybuff": 64, "rayreplaybuff": 65, "remotetensordictreplaybuff": 66, "replaybuff": 67, "replaybufferensembl": 68, "tensordictprioritizedreplaybuff": 69, "tensordictreplaybuff": 70, "unbound": 72, "unboundedcontinu": 73, "unboundeddiscret": 74, "ataridqnexperiencereplai": 75, "d4rlexperiencereplai": 76, "gendgrlexperiencereplai": 77, "minariexperiencereplai": 78, "openmlexperiencereplai": 79, "openxexperiencereplai": 80, "robosetexperiencereplai": 81, "vd4rlexperiencereplai": 82, "contentbas": 83, "histori": [84, 595, 634], "topkrewardselector": 85, "add_chat_templ": 86, "compressedliststorag": 87, "compressedliststoragecheckpoint": 88, "flatstoragecheckpoint": 89, "h5storagecheckpoint": 90, "immutabledatasetwrit": 91, "lazymemmapstorag": 92, "lazystackstorag": 93, "lazytensorstorag": 94, "liststorag": 95, "liststoragecheckpoint": 96, "nestedstoragecheckpoint": 97, "prioritizedsampl": 98, "prioritizedslicesampl": 99, "randomsampl": 100, "roundrobinwrit": 101, "sampler": 102, "samplerensembl": 103, "samplerwithoutreplac": 104, "slicesampl": 105, "slicesamplerwithoutreplac": 106, "storagecheckpointerbas": 108, "storageensembl": 109, "storageensemblecheckpoint": 110, "tensordictmaxvaluewrit": 111, "tensordictroundrobinwrit": 112, "tensorstorag": 113, "tensorstoragecheckpoint": 114, "writerensembl": 116, "asyncenvpool": 117, "braxenv": 118, "braxwrapp": 119, "chessenv": 120, "dmcontrolenv": 121, "dmcontrolwrapp": 122, "envbas": [123, 638], "envcreat": 124, "envmetadata": 125, "gymenv": 126, "gymlikeenv": 127, "gymwrapp": 128, "habitatenv": 129, "isaacgymenv": 130, "isaacgymwrapp": 131, "isaaclabwrapp": 132, "jumanjienv": 133, "jumanjiwrapp": 134, "llmhashingenv": [135, 177], "mogymenv": 136, "mogymwrapp": 137, "marlgroupmaptyp": 138, "meltingpotenv": 139, "meltingpotwrapp": 140, "modelbasedenvbas": 141, "multithreadedenv": 142, "multithreadedenvwrapp": 143, "openmlenv": 144, "openspielenv": 145, "openspielwrapp": 146, "parallelenv": 147, "pendulumenv": 148, "pettingzooenv": 149, "pettingzoowrapp": 150, "processorasyncenvpool": 151, "randompolici": 152, "robohiveenv": 153, "smacv2env": 154, "smacv2wrapp": 155, "serialenv": 156, "threadingasyncenvpool": 157, "tictactoeenv": 158, "unitymlagentsenv": 159, "unitymlagentswrapp": 160, "vmasenv": 161, "vmaswrapp": 162, "check_env_spec": 163, "check_marl_group": 164, "exploration_typ": 165, "get_available_librari": 166, "gym_backend": 167, "chatenv": [168, 593], "datasetchatenv": 169, "gsm8kenv": 170, "gsm8kpreparequest": 171, "gsm8krewardpars": 172, "ifevalenv": 173, "ifevalscoredata": 174, "ifevalscor": 175, "llmenv": 176, "mlgymwrapp": 178, "make_gsm8k_env": 179, "make_mlgym": 180, "addthinkingprompt": 181, "browsertransform": 182, "dataloadingprim": 183, "executetoolsinord": 184, "jsoncallpars": 185, "klcomput": 186, "klrewardtransform": [187, 239], "mcptooltransform": 188, "policyvers": 189, "pythonexecutorservic": 190, "pythoninterpret": 191, "raydataloadingprim": 192, "retrievekl": 193, "retrievelogprob": 194, "simpletooltransform": 195, "templatetransform": 196, "token": [197, 267, 329], "toolcal": 198, "toolregistri": 199, "toolservic": 200, "xmlblockpars": 201, "as_nested_tensor": 202, "as_padded_tensor": 203, "make_composite_from_td": 204, "dreamerdecod": 205, "dreamerenv": 206, "register_gym_spec_convers": 207, "set_exploration_typ": 208, "set_gym_backend": 209, "step_mdp": 210, "terminated_or_trunc": 211, "actiondiscret": 212, "actionmask": 213, "autoresetenv": 214, "autoresettransform": 215, "batchsizetransform": 216, "binarizereward": 217, "burnintransform": 218, "catfram": [219, 640], "cattensor": 220, "centercrop": 221, "cliptransform": 222, "conditionalpolicyswitch": 224, "conditionalskip": 225, "crop": 226, "dtypecasttransform": 227, "devicecasttransform": 228, "discreteactionproject": 229, "doubletofloat": 230, "endoflifetransform": 231, "excludetransform": 232, "finitetensordictcheck": 233, "flattenobserv": 234, "frameskiptransform": 235, "grayscal": 236, "hash": 237, "inittrack": 238, "linearisereward": 240, "moduletransform": 241, "multiact": 242, "noopresetenv": 243, "observationnorm": 244, "observationtransform": 245, "permutetransform": 246, "pinmemorytransform": 247, "r3mtransform": 248, "randomcroptensordict": 249, "removeemptyspec": 250, "renametransform": 251, "resiz": 252, "reward2gotransform": 253, "rewardclip": 254, "rewardsc": 255, "rewardsum": 256, "selecttransform": 257, "signtransform": 258, "squeezetransform": 259, "stack": 260, "stepcount": 261, "targetreturn": 262, "tensordictprim": 263, "timemaxpool": 264, "timer": 265, "totensorimag": 266, "trajcount": 268, "transformedenv": 270, "unarytransform": 271, "unsqueezetransform": 272, "vc1transform": 273, "viprewardtransform": 274, "viptransform": 275, "vecgymenvtransform": 276, "vecnorm": [277, 643], "vecnormv2": 278, "gsdenois": 279, "implement_for": 280, "actorcriticoper": 281, "actorcriticwrapp": 282, "actorvalueoper": 283, "additivegaussianmodul": 284, "consistentdropoutmodul": 285, "convnet": 286, "dtactor": 287, "ddpgcnnactor": 288, "ddpgcnnqnet": 289, "ddpgmlpactor": 290, "ddpgmlpqnet": 291, "decisiontransform": 292, "delta": 293, "distributionaldqnnet": 294, "distributionalqvalueactor": 295, "distributionalqvaluemodul": 296, "dreameractor": 297, "duelingcnndqnet": 298, "egreedymodul": 299, "grumodul": 300, "independentnorm": 301, "lstmmodul": 302, "mlp": [303, 624], "maskedcategor": 304, "normalparamextractor": 305, "obsdecod": 306, "obsencod": 307, "onehotcategor": 308, "onlinedtactor": 309, "ornsteinuhlenbeckprocessmodul": 310, "qvalueactor": 311, "qvaluemodul": 312, "rssmposterior": 313, "rssmprior": 314, "rssmrollout": 315, "reparamgradientstrategi": 316, "tanhdelta": 317, "tanhnorm": 318, "truncatednorm": 319, "valueoper": 320, "worldmodelwrapp": 321, "asyncvllm": 322, "chathistori": 323, "llmwrapperbas": 324, "logprob": 325, "remotetransformerswrapp": 327, "text": [328, 634], "transformerswrapp": 330, "make_async_vllm_engin": 331, "make_vllm_work": 332, "stateless_init_process_group": 333, "stateless_init_process_group_async": 334, "vllmwrapper": 335, "squashdim": 336, "actor": [337, 601, 608, 621, 627], "multistepactorwrapp": 338, "probabilisticactor": 339, "safemodul": [340, 601], "safeprobabilisticmodul": 341, "safeprobabilistictensordictsequenti": 342, "safesequenti": 343, "tanhmodul": 344, "a2closs": 345, "cqlloss": 346, "clipppoloss": 347, "crossqloss": 348, "ddpgloss": 349, "dqnloss": 350, "dtloss": 351, "discretecqlloss": 352, "discreteiqlloss": 353, "discretesacloss": 354, "distributionaldqnloss": 355, "dreameractorloss": 356, "dreamermodelloss": 357, "dreamervalueloss": 358, "gailloss": 359, "iqlloss": 360, "klpenppoloss": 361, "lossmodul": [362, 621, 628], "onlinedtloss": 363, "ppoloss": 364, "redqloss": 365, "reinforceloss": 366, "sacloss": 367, "td3bcloss": 368, "td3loss": 369, "valueestim": 370, "add_random_modul": 371, "cispolossoutput": 372, "dapo": 373, "dapolossoutput": 374, "grpoloss": 375, "grpolossoutput": 376, "llmlossoutput": 377, "mcadvantag": 378, "sftloss": 379, "sftlossoutput": 380, "gae": 381, "td0estim": 382, "td1estim": 383, "tdlambdaestim": 384, "valueestimatorbas": 385, "pixelrendertransform": 386, "tensordictrecord": 387, "videorecord": 388, "logger": [389, 618, 630, 631], "csvlogger": 390, "generate_exp_nam": 391, "get_logg": 392, "mlflowlogg": 393, "tensorboardlogg": 394, "wandblogg": 395, "rayservic": 396, "servicebas": 397, "get_servic": 398, "set_auto_unwrap_transformed_env": 399, "batchsubsampl": 400, "clearcudacach": 401, "countframeslog": 402, "logscalar": 403, "logvalidationreward": 404, "optimizerhook": 405, "replaybuffertrain": 406, "rewardnorm": 407, "selectkei": 408, "targetnetupdaterhook": 409, "trainer": [410, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 615, 616, 622], "trainerhookbas": 411, "utdrhook": 412, "updateweight": 413, "ppotrain": 414, "sactrain": 415, "config": [416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 642], "asyncdatacollectorconfig": 416, "datacollectorconfig": 417, "multisyncdatacollectorconfig": 418, "multiasyncdatacollectorconfig": 419, "syncdatacollectorconfig": 420, "configbas": 421, "lazymemmapstorageconfig": 422, "lazystackstorageconfig": 423, "lazytensorstorageconfig": 424, "liststorageconfig": 425, "prioritizedsamplerconfig": 426, "randomsamplerconfig": 427, "replaybufferconfig": 428, "roundrobinwriterconfig": 429, "samplerwithoutreplacementconfig": 430, "slicesamplerconfig": 431, "slicesamplerwithoutreplacementconfig": 432, "storageensembleconfig": 433, "storageensemblewriterconfig": 434, "tensordictreplaybufferconfig": 435, "tensorstorageconfig": 436, "batchedenvconfig": 437, "envconfig": 438, "transformedenvconfig": 439, "envs_lib": [440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456], "braxenvconfig": 440, "dmcontrolenvconfig": 441, "envlibsconfig": 442, "gymenvconfig": 443, "habitatenvconfig": 444, "isaacgymenvconfig": 445, "jumanjienvconfig": 446, "mogymenvconfig": 447, "meltingpotenvconfig": 448, "multithreadedenvconfig": 449, "openmlenvconfig": 450, "openspielenvconfig": 451, "pettingzooenvconfig": 452, "robohiveenvconfig": 453, "smacv2envconfig": 454, "unitymlagentsenvconfig": 455, "vmasenvconfig": 456, "csvloggerconfig": 457, "loggerconfig": 458, "tensorboardloggerconfig": 459, "wandbloggerconfig": 460, "modul": [461, 462, 463, 464, 465, 466, 467, 600, 601, 611, 621, 624, 625, 627, 631, 642], "convnetconfig": 461, "mlpconfig": 462, "modelconfig": 463, "networkconfig": 464, "tanhnormalmodelconfig": 465, "tensordictmoduleconfig": 466, "valuemodelconfig": 467, "object": [468, 469, 593, 598, 607, 621, 628, 642], "lossconfig": 468, "ppolossconfig": 469, "ppotrainerconfig": 470, "trainerconfig": 471, "actiondiscretizerconfig": 472, "actionmaskconfig": 473, "autoresettransformconfig": 474, "batchsizetransformconfig": 475, "binarizerewardconfig": 476, "burnintransformconfig": 477, "catframesconfig": 478, "cattensorsconfig": 479, "centercropconfig": 480, "cliptransformconfig": 481, "composeconfig": 482, "conditionalpolicyswitchconfig": 483, "conditionalskipconfig": 484, "cropconfig": 485, "dtypecasttransformconfig": 486, "devicecasttransformconfig": 487, "discreteactionprojectionconfig": 488, "doubletofloatconfig": 489, "endoflifetransformconfig": 490, "excludetransformconfig": 491, "finitetensordictcheckconfig": 492, "flattenobservationconfig": 493, "frameskiptransformconfig": 494, "grayscaleconfig": 495, "hashconfig": 496, "inittrackerconfig": 497, "klrewardtransformconfig": 498, "lineariserewardsconfig": 499, "multiactionconfig": 500, "multisteptransformconfig": 501, "noopresetenvconfig": 502, "observationnormconfig": 503, "permutetransformconfig": 504, "pinmemorytransformconfig": 505, "r3mtransformconfig": 506, "randomcroptensordictconfig": 507, "removeemptyspecsconfig": 508, "renametransformconfig": 509, "resizeconfig": 510, "reward2gotransformconfig": 511, "rewardclippingconfig": 512, "rewardscalingconfig": 513, "rewardsumconfig": 514, "selecttransformconfig": 515, "signtransformconfig": 516, "squeezetransformconfig": 517, "stackconfig": 518, "stepcounterconfig": 519, "targetreturnconfig": 520, "tensordictprimerconfig": 521, "timemaxpoolconfig": 522, "timerconfig": 523, "totensorimageconfig": 524, "tokenizerconfig": 525, "trajcounterconfig": 526, "transformconfig": 527, "unarytransformconfig": 528, "unsqueezetransformconfig": 529, "vc1transformconfig": 530, "viprewardtransformconfig": 531, "viptransformconfig": 532, "vecgymenvtransformconfig": 533, "vecnormconfig": 534, "vecnormv2config": 535, "util": [536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 597, 606, 616, 618, 636], "asgdconfig": 536, "adadeltaconfig": 537, "adagradconfig": 538, "adamconfig": 539, "adamwconfig": 540, "adamaxconfig": 541, "lbfgsconfig": 542, "lionconfig": 543, "nadamconfig": 544, "radamconfig": 545, "rmspropconfig": 546, "rpropconfig": 547, "sgdconfig": 548, "sparseadamconfig": 549, "correct_for_frame_skip": 550, "get_stats_random_rollout": 551, "make_collector_offpolici": 552, "make_collector_onpolici": 553, "make_dqn_loss": 554, "make_replay_buff": 555, "make_target_updat": 556, "make_train": 557, "parallel_env_constructor": 558, "sync_async_collector": 559, "sync_sync_collector": 560, "transformed_env_constructor": 561, "distributedtransport": 562, "distributedweightsyncschem": 563, "mptransport": 564, "multiprocessweightsyncschem": 565, "noweightsyncschem": 566, "rpctransport": 567, "rpcweightsyncschem": 568, "rayactortransport": 569, "raymoduletransformreceiv": 570, "raymoduletransformschem": 571, "raymoduletransformsend": 572, "raytransport": 573, "rayweightsyncschem": 574, "sharedmemtransport": 575, "sharedmemweightsyncschem": 576, "transportbackend": 577, "weightreceiv": 578, "weightsend": 579, "weightsyncschem": 580, "vllmcollectivetransport": 581, "vllmdoublebuffersyncschem": 582, "vllmdoublebuffertransport": 583, "vllmdoublebufferweightreceiv": 584, "vllmdoublebufferweightsend": 585, "vllmweightreceiv": 586, "vllmweightsend": 587, "vllmweightsyncschem": 588, "get_model_metadata": 589, "readm": [590, 632], "tuto": [590, 632], "contribut": [592, 642], "content": 592, "llm": [593, 594, 596, 597, 598, 599, 633, 634], "interfac": 593, "deprec": 593, "architectur": 593, "integr": [593, 634, 640], "structur": [595, 597, 634, 640], "topk": 595, "selector": 595, "grpo": 598, "sft": 598, "tensordictmodul": [601, 625, 627, 642], "probabilist": [601, 627], "q": [601, 622, 624, 627], "critic": [602, 608, 636, 637], "estim": [609, 621], "other": [611, 640], "servic": 614, "registri": 614, "overview": [614, 621, 624], "registr": 614, "access": [614, 643], "cross": 614, "worker": 614, "visibl": 614, "namespac": 614, "isol": 614, "cleanup": 614, "python": 614, "executor": 614, "condit": 614, "pattern": 614, "It": 614, "consider": [614, 628], "multipl": 614, "see": 614, "hook": [616, 617, 622], "builder": 616, "_util": 619, "comput": [620, 622, 638, 641], "time": [620, 621, 641], "code": [621, 638], "ddpg": [621, 636], "setup": [621, 624, 633, 634], "The": 621, "__init__": 621, "put": 621, "togeth": [621, 638], "call": 621, "execut": [621, 633, 635, 638], "stat": 621, "build": [621, 622, 631, 633, 640], "evalu": 621, "construct": 621, "target": [621, 622, 628], "result": [621, 623, 633, 636, 637], "conclus": [621, 622, 623, 624, 625, 633, 634, 636, 637, 638, 640], "next": [621, 623, 626, 629, 636, 637, 640], "A": [622, 640], "dqn": [622, 624], "deep": 622, "paramet": [622, 623, 628], "regist": 622, "possibl": 622, "improv": 622, "reinforc": [623, 636, 637], "ppo": [623, 637], "defin": [623, 636, 637], "loop": [623, 624, 625, 631, 636, 637, 638], "recurr": [624, 625], "convolut": 624, "lstm": 624, "select": 624, "further": [624, 628], "read": 624, "export": 625, "introduct": [625, 642], "fast": 625, "recap": 625, "stochast": 625, "aotinductor": 625, "free": 625, "c": 625, "onnx": 625, "rollout": [625, 626, 635, 636, 637, 638, 643], "ted": 626, "s": [627, 628], "special": [627, 642], "output": 628, "first": 631, "tool": 633, "enabl": 633, "3": [633, 634], "interact": 633, "4": [633, 634], "search": 633, "5": [633, 634], "extract": 633, "vllm": 634, "input": 634, "mode": 634, "probabl": 634, "onli": 634, "tensorclass": [634, 640], "6": 634, "handl": 634, "7": 634, "divers": 635, "competit": 636, "map": 636, "pendulum": 638, "write": 638, "_step": 638, "simul": 638, "_reset": 638, "metadata": 638, "_spec": 638, "shape": 638, "seed": [638, 643], "wrap": 638, "test": 638, "our": 638, "pretrain": 639, "vanilla": 640, "tensordict": [640, 642], "pytre": 640, "iter": 640, "over": 640, "fix": 640, "priorit": 640, "save": 640, "raw": 640, "imag": 640, "trajectori": 640, "sequenc": 642, "program": 642, "ensembl": 642, "meta": 642, "vmap": 642, "sync": 642, "multiprocess": 642, "frame_skip": 643, "deepmind": 643, "control": 643, "devic": 643, "close": 643, "attribut": 643, "kwarg": 643}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 56}})
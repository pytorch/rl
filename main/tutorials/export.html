


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Exporting TorchRL modules &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/pytorch.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx-design.min.css" type="text/css" />
  <link rel="stylesheet" href="../https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial" href="multiagent_competitive_ddpg.html" />
    <link rel="prev" title="Using Replay Buffers" href="rb_tutorial.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://shiftlab.github.io/pytorch/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://shiftlab.github.io/pytorch/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/features">Features</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   
  <div>

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="../../versions.html"><span style="font-size:110%">main (0.11.0) &#x25BC</span></a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="getting-started-0.html">Get started with Environments, TED and transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting-started-1.html">Get started with TorchRL’s modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting-started-2.html">Getting started with model optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting-started-3.html">Get started with data collection and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting-started-4.html">Get started with logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting-started-5.html">Get started with your own first training loop</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="coding_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchrl_demo.html">Introduction to TorchRL</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="multiagent_ppo.html">Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchrl_envs.html">TorchRL envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="pretrained_models.html">Using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="dqn_with_rnn.html">Recurrent DQN: Training recurrent policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="rb_tutorial.html">Using Replay Buffers</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Exporting TorchRL modules</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multiagent_competitive_ddpg.html">Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="coding_ddpg.html">TorchRL objectives: Coding a DDPG loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="coding_dqn.html">TorchRL trainer: A DQN example</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">

      <section data-toggle="wy-nav-shift" class="pytorch-content-wrap">
        <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
          <div class="pytorch-breadcrumbs-wrapper">
            















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Exporting TorchRL modules</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/tutorials/export.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
          </div>

          <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
            Shortcuts
          </div>
        </div>

        <div class="pytorch-content-left">
    

    <div class="pytorch-call-to-action-links">
      <div id="tutorial-type">tutorials/export</div>

      <div id="google-colab-link">
        <img class="call-to-action-img" src="../_static/images/pytorch-colab.svg"/>
        <div class="call-to-action-desktop-view">Run in Google Colab</div>
        <div class="call-to-action-mobile-view">Colab</div>
      </div>
      <div id="download-notebook-link">
        <img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
        <div class="call-to-action-desktop-view">Download Notebook</div>
        <div class="call-to-action-mobile-view">Notebook</div>
      </div>
      <div id="github-view-link">
        <img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
        <div class="call-to-action-desktop-view">View on GitHub</div>
        <div class="call-to-action-mobile-view">GitHub</div>
      </div>
    </div>

    
    
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" class="pytorch-article">
              
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-tutorials-export-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="exporting-torchrl-modules">
<span id="sphx-glr-tutorials-export-py"></span><h1>Exporting TorchRL modules<a class="headerlink" href="#exporting-torchrl-modules" title="Link to this heading">¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://github.com/vmoens">Vincent Moens</a></p>
<div class="admonition note" id="export-tuto">
<p class="admonition-title">Note</p>
<p>To run this tutorial in a notebook, add an installation cell
at the beginning containing:</p>
<blockquote>
<div><div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!pip install tensordict
!pip install torchrl
!pip install &quot;gymnasium[atari]&quot;
</pre></div>
</div>
</div></blockquote>
</div>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">¶</a></h2>
<p>Learning a policy has little value if that policy cannot be deployed in real-world settings.
As shown in other tutorials, TorchRL has a strong focus on modularity and composability: thanks to <code class="docutils literal notranslate"><span class="pre">tensordict</span></code>,
the components of the library can be written in the most generic way there is by abstracting their signature to a
mere set of operations on an input <code class="docutils literal notranslate"><span class="pre">TensorDict</span></code>.
This may give the impression that the library is bound to be used only for training, as typical low-level execution
hardwares (edge devices, robots, arduino, Raspberry Pi) do not execute python code, let alone with pytorch, tensordict
or torchrl installed.</p>
<p>Fortunately, PyTorch provides a full ecosystem of solutions to export code and trained models to devices and
hardwares, and TorchRL is fully equipped to interact with it.
It is possible to choose from a varied set of backends, including ONNX or AOTInductor examplified in this tutorial.
This tutorial gives a quick overview of how a trained model can be isolated and shipped as a standalone executable
to be exported on hardware.</p>
<p>Key learnings:</p>
<ul class="simple">
<li><p>Export any TorchRL module after training;</p></li>
<li><p>Using various backends;</p></li>
<li><p>Testing your exported model.</p></li>
</ul>
</section>
<section id="fast-recap-a-simple-torchrl-training-loop">
<h2>Fast recap: a simple TorchRL training loop<a class="headerlink" href="#fast-recap-a-simple-torchrl-training-loop" title="Link to this heading">¶</a></h2>
<p>In this section, we reproduce the training loop from the last Getting Started tutorial, slightly adapted to be used
with Atari games as they are rendered by the gymnasium library.
We will stick to the DQN example, and show how a policy that outputs a distribution over values can be used instead
later.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">tensordict.nn</span> <span class="kn">import</span> <span class="p">(</span>
    <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictModule.html#tensordict.nn.TensorDictModule" title="tensordict.nn.TensorDictModule" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">TensorDictModule</span></a> <span class="k">as</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictModule.html#tensordict.nn.TensorDictModule" title="tensordict.nn.TensorDictModule" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">Mod</span></a><span class="p">,</span>
    <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">TensorDictSequential</span></a><span class="p">,</span>
    <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">TensorDictSequential</span></a> <span class="k">as</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">Seq</span></a><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">Adam</span></a>

<span class="kn">from</span> <span class="nn">torchrl._utils</span> <span class="kn">import</span> <span class="n">timeit</span>
<span class="kn">from</span> <span class="nn">torchrl.collectors</span> <span class="kn">import</span> <a href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset" title="torch.utils.data.IterableDataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">SyncDataCollector</span></a>
<span class="kn">from</span> <span class="nn">torchrl.data</span> <span class="kn">import</span> <span class="n">LazyTensorStorage</span><span class="p">,</span> <span class="n">ReplayBuffer</span>

<span class="kn">from</span> <span class="nn">torchrl.envs</span> <span class="kn">import</span> <span class="p">(</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">Compose</span></a><span class="p">,</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">GrayScale</span></a><span class="p">,</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">GymEnv</span></a><span class="p">,</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">Resize</span></a><span class="p">,</span>
    <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.set_interaction_type.html#tensordict.nn.set_interaction_type" title="tensordict.nn.set_interaction_type" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">set_exploration_type</span></a><span class="p">,</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">StepCounter</span></a><span class="p">,</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">ToTensorImage</span></a><span class="p">,</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">TransformedEnv</span></a><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">torchrl.modules</span> <span class="kn">import</span> <span class="n">ConvNet</span><span class="p">,</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictModuleBase.html#tensordict.nn.TensorDictModuleBase" title="tensordict.nn.TensorDictModuleBase" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">EGreedyModule</span></a><span class="p">,</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictModuleBase.html#tensordict.nn.TensorDictModuleBase" title="tensordict.nn.TensorDictModuleBase" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">QValueModule</span></a>

<span class="kn">from</span> <span class="nn">torchrl.objectives</span> <span class="kn">import</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictModuleBase.html#tensordict.nn.TensorDictModuleBase" title="tensordict.nn.TensorDictModuleBase" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">DQNLoss</span></a><span class="p">,</span> <span class="n">SoftUpdate</span>

<a href="https://docs.pytorch.org/docs/stable/generated/torch.manual_seed.html#torch.manual_seed" title="torch.manual_seed" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span></a><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">env</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">TransformedEnv</span></a><span class="p">(</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">GymEnv</span></a><span class="p">(</span><span class="s2">&quot;ALE/Pong-v5&quot;</span><span class="p">,</span> <span class="n">categorical_action_encoding</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">Compose</span></a><span class="p">(</span>
        <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">ToTensorImage</span></a><span class="p">(),</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">Resize</span></a><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;nearest&quot;</span><span class="p">),</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">GrayScale</span></a><span class="p">(),</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">StepCounter</span></a><span class="p">()</span>
    <span class="p">),</span>
<span class="p">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">value_mlp</span></a> <span class="o">=</span> <span class="n">ConvNet</span><span class="o">.</span><span class="n">default_atari_dqn</span><span class="p">(</span><span class="n">num_actions</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">action_spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
<a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictModule.html#tensordict.nn.TensorDictModule" title="tensordict.nn.TensorDictModule" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">value_net</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictModule.html#tensordict.nn.TensorDictModule" title="tensordict.nn.TensorDictModule" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">Mod</span></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">value_mlp</span></a><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pixels&quot;</span><span class="p">],</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;action_value&quot;</span><span class="p">])</span>
<a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">policy</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">Seq</span></a><span class="p">(</span><a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictModule.html#tensordict.nn.TensorDictModule" title="tensordict.nn.TensorDictModule" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">value_net</span></a><span class="p">,</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictModuleBase.html#tensordict.nn.TensorDictModuleBase" title="tensordict.nn.TensorDictModuleBase" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">QValueModule</span></a><span class="p">(</span><span class="n">spec</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">action_spec</span><span class="p">))</span>
<span class="n">exploration_module</span> <span class="o">=</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictModuleBase.html#tensordict.nn.TensorDictModuleBase" title="tensordict.nn.TensorDictModuleBase" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">EGreedyModule</span></a><span class="p">(</span>
    <span class="n">env</span><span class="o">.</span><span class="n">action_spec</span><span class="p">,</span> <span class="n">annealing_num_steps</span><span class="o">=</span><span class="mi">100_000</span><span class="p">,</span> <span class="n">eps_init</span><span class="o">=</span><span class="mf">0.5</span>
<span class="p">)</span>
<a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">policy_explore</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">Seq</span></a><span class="p">(</span><a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">policy</span></a><span class="p">,</span> <span class="n">exploration_module</span><span class="p">)</span>

<span class="n">init_rand_steps</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">frames_per_batch</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">optim_steps</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">collector</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset" title="torch.utils.data.IterableDataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">SyncDataCollector</span></a><span class="p">(</span>
    <span class="n">env</span><span class="p">,</span>
    <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">policy_explore</span></a><span class="p">,</span>
    <span class="n">frames_per_batch</span><span class="o">=</span><span class="n">frames_per_batch</span><span class="p">,</span>
    <span class="n">total_frames</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">init_random_frames</span><span class="o">=</span><span class="n">init_rand_steps</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">rb</span> <span class="o">=</span> <span class="n">ReplayBuffer</span><span class="p">(</span><span class="n">storage</span><span class="o">=</span><span class="n">LazyTensorStorage</span><span class="p">(</span><span class="mi">100_000</span><span class="p">))</span>

<span class="n">loss</span> <span class="o">=</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictModuleBase.html#tensordict.nn.TensorDictModuleBase" title="tensordict.nn.TensorDictModuleBase" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">DQNLoss</span></a><span class="p">(</span><span class="n">value_network</span><span class="o">=</span><a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">policy</span></a><span class="p">,</span> <span class="n">action_space</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">action_spec</span><span class="p">,</span> <span class="n">delay_value</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optim</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">Adam</span></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters" title="torch.nn.Module.parameters" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">loss</span><span class="o">.</span><span class="n">parameters</span></a><span class="p">())</span>
<span class="n">updater</span> <span class="o">=</span> <span class="n">SoftUpdate</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.99</span><span class="p">)</span>

<span class="n">total_count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">total_episodes</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a> <span class="ow">in</span> <span class="n">collector</span><span class="p">:</span>
    <span class="c1"># Write data in replay buffer</span>
    <span class="n">rb</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">)</span>
    <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">max_length</span></a> <span class="o">=</span> <span class="n">rb</span><span class="p">[:][</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;step_count&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">rb</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">init_rand_steps</span><span class="p">:</span>
        <span class="c1"># Optim loop (we do several optim steps</span>
        <span class="c1"># per batch collected for efficiency)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">optim_steps</span><span class="p">):</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="n">rb</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>
            <span class="n">loss_vals</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
            <span class="n">loss_vals</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step" title="torch.optim.Adam.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">optim</span><span class="o">.</span><span class="n">step</span></a><span class="p">()</span>
            <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.zero_grad" title="torch.optim.Adam.zero_grad" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span></a><span class="p">()</span>
            <span class="c1"># Update exploration factor</span>
            <span class="n">exploration_module</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.numel" title="tensordict.TensorDict.numel" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">data</span><span class="o">.</span><span class="n">numel</span></a><span class="p">())</span>
            <span class="c1"># Update target params</span>
            <span class="n">updater</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">total_count</span> <span class="o">+=</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.numel" title="tensordict.TensorDict.numel" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">data</span><span class="o">.</span><span class="n">numel</span></a><span class="p">()</span>
            <span class="n">total_episodes</span> <span class="o">+=</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">if</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">max_length</span></a> <span class="o">&gt;</span> <span class="mi">200</span><span class="p">:</span>
        <span class="k">break</span>
</pre></div>
</div>
</section>
<section id="exporting-a-tensordictmodule-based-policy">
<h2>Exporting a TensorDictModule-based policy<a class="headerlink" href="#exporting-a-tensordictmodule-based-policy" title="Link to this heading">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">TensorDict</span></code> allowed us to build a policy with a great flexibility: from a regular <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> that
outputs action values from an observation, we added a <a class="reference internal" href="../reference/generated/torchrl.modules.QValueModule.html#torchrl.modules.QValueModule" title="torchrl.modules.QValueModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">QValueModule</span></code></a> module that
read these values and computed an action using some heuristic (e.g., an argmax call).</p>
<p>However, there’s a small technical catch in our case: the environment (the actual Atari game) doesn’t return
grayscale, 84x84 images but raw screen-size color ones. The transforms we appended to the environment make sure that
the images can be read by the model. We can see that, from the training perspective, the boundary between environment
and model is blurry, but at execution time things are much clearer: the model should take care of transforming
the input data (images) to the format that can be processed by our CNN.</p>
<p>Here again, the magic of tensordict will unblock us: it happens that most of local (non-recursive) TorchRL’s
transforms can be used both as environment transforms or preprocessing blocks within a <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>
instance. Let’s see how we can prepend them to our policy:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">policy_transform</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">TensorDictSequential</span></a><span class="p">(</span>
    <span class="n">env</span><span class="o">.</span><span class="n">transform</span><span class="p">[</span>
        <span class="p">:</span><span class="o">-</span><span class="mi">1</span>
    <span class="p">],</span>  <span class="c1"># the last transform is a step counter which we don&#39;t need for preproc</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.requires_grad_" title="torch.nn.Module.requires_grad_" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">policy_explore</span><span class="o">.</span><span class="n">requires_grad_</span></a><span class="p">(</span>
        <span class="kc">False</span>
    <span class="p">),</span>  <span class="c1"># Using the explorative version of the policy for didactic purposes, see below.</span>
<span class="p">)</span>
</pre></div>
</div>
<p>We create a fake input, and pass it to <a class="reference external" href="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/export/api_reference.html#torch.export.export" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">export()</span></code></a> with the policy. This will give a “raw” python
function that will read our input tensor and output an action without any reference to TorchRL or tensordict modules.</p>
<p>A good practice is to call <a class="reference external" href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential.select_out_keys" title="(in tensordict v0.11)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">select_out_keys()</span></code></a> to let the model know that
we only want a certain set of outputs (in case the policy returns more than one tensor).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fake_td</span></a> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">base_env</span><span class="o">.</span><span class="n">fake_tensordict</span><span class="p">()</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pixels</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fake_td</span></a><span class="p">[</span><span class="s2">&quot;pixels&quot;</span><span class="p">]</span>
<span class="k">with</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.set_interaction_type.html#tensordict.nn.set_interaction_type" title="tensordict.nn.set_interaction_type" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">set_exploration_type</span></a><span class="p">(</span><span class="s2">&quot;DETERMINISTIC&quot;</span><span class="p">):</span>
    <a href="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/export/api_reference.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">exported_policy</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/export/api_reference.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span></a><span class="p">(</span>
        <span class="c1"># Select only the &quot;action&quot; output key</span>
        <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential.select_out_keys" title="tensordict.nn.TensorDictSequential.select_out_keys" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-method"><span class="n">policy_transform</span><span class="o">.</span><span class="n">select_out_keys</span></a><span class="p">(</span><span class="s2">&quot;action&quot;</span><span class="p">),</span>
        <span class="n">args</span><span class="o">=</span><span class="p">(),</span>
        <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;pixels&quot;</span><span class="p">:</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pixels</span></a><span class="p">},</span>
        <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>Representing the policy can be quite insightful: we can see that the first operations are a permute, a div, unsqueeze,
resize followed by the convolutional and MLP layers.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Deterministic policy&quot;</span><span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/export/api_reference.html#torch.export.ExportedProgram.graph_module" title="torch.export.ExportedProgram.graph_module" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-property"><span class="n">exported_policy</span><span class="o">.</span><span class="n">graph_module</span><span class="o">.</span><span class="n">print_readable</span></a><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Deterministic policy
class GraphModule(torch.nn.Module):
    def forward(self, p_module_1_module_0_module_0_module_0_0_weight: &quot;f32[32, 1, 8, 8]&quot;, p_module_1_module_0_module_0_module_0_0_bias: &quot;f32[32]&quot;, p_module_1_module_0_module_0_module_0_2_weight: &quot;f32[64, 32, 4, 4]&quot;, p_module_1_module_0_module_0_module_0_2_bias: &quot;f32[64]&quot;, p_module_1_module_0_module_0_module_0_4_weight: &quot;f32[64, 64, 3, 3]&quot;, p_module_1_module_0_module_0_module_0_4_bias: &quot;f32[64]&quot;, p_module_1_module_0_module_0_module_1_0_weight: &quot;f32[512, 3136]&quot;, p_module_1_module_0_module_0_module_1_0_bias: &quot;f32[512]&quot;, p_module_1_module_0_module_0_module_1_2_weight: &quot;f32[6, 512]&quot;, p_module_1_module_0_module_0_module_1_2_bias: &quot;f32[6]&quot;, b_module_1_module_1_eps_init: &quot;f32[]&quot;, b_module_1_module_1_eps_end: &quot;f32[]&quot;, b_module_1_module_1_eps: &quot;f32[]&quot;, pixels: &quot;u8[210, 160, 3]&quot;):
        # File: /pytorch/rl/torchrl/envs/transforms/transforms.py:500 in forward, code: data = self._apply_transform(data)
        permute: &quot;u8[3, 210, 160]&quot; = torch.ops.aten.permute.default(pixels, [-1, -3, -2]);  pixels = None
        div: &quot;f32[3, 210, 160]&quot; = torch.ops.aten.div.Tensor(permute, 255);  permute = None
        _assert_tensor_metadata_default = torch.ops.aten._assert_tensor_metadata.default(div, dtype = torch.float32, device = device(type=&#39;cpu&#39;), layout = torch.strided);  _assert_tensor_metadata_default = None
        to: &quot;f32[3, 210, 160]&quot; = torch.ops.aten.to.dtype(div, torch.float32);  div = None
        unsqueeze: &quot;f32[1, 3, 210, 160]&quot; = torch.ops.aten.unsqueeze.default(to, 0);  to = None
        upsample_nearest2d: &quot;f32[1, 3, 84, 84]&quot; = torch.ops.aten.upsample_nearest2d.vec(unsqueeze, [84, 84], None);  unsqueeze = None
        squeeze: &quot;f32[3, 84, 84]&quot; = torch.ops.aten.squeeze.dim(upsample_nearest2d, 0);  upsample_nearest2d = None
        unbind = torch.ops.aten.unbind.int(squeeze, -3);  squeeze = None
        getitem: &quot;f32[84, 84]&quot; = unbind[0]
        getitem_1: &quot;f32[84, 84]&quot; = unbind[1]
        getitem_2: &quot;f32[84, 84]&quot; = unbind[2];  unbind = None
        mul: &quot;f32[84, 84]&quot; = torch.ops.aten.mul.Tensor(getitem, 0.2989);  getitem = None
        mul_1: &quot;f32[84, 84]&quot; = torch.ops.aten.mul.Tensor(getitem_1, 0.587);  getitem_1 = None
        add: &quot;f32[84, 84]&quot; = torch.ops.aten.add.Tensor(mul, mul_1);  mul = mul_1 = None
        mul_2: &quot;f32[84, 84]&quot; = torch.ops.aten.mul.Tensor(getitem_2, 0.114);  getitem_2 = None
        add_1: &quot;f32[84, 84]&quot; = torch.ops.aten.add.Tensor(add, mul_2);  add = mul_2 = None
        _assert_tensor_metadata_default_1 = torch.ops.aten._assert_tensor_metadata.default(add_1, dtype = torch.float32, device = device(type=&#39;cpu&#39;), layout = torch.strided);  _assert_tensor_metadata_default_1 = None
        to_1: &quot;f32[84, 84]&quot; = torch.ops.aten.to.dtype(add_1, torch.float32);  add_1 = None
        unsqueeze_1: &quot;f32[1, 84, 84]&quot; = torch.ops.aten.unsqueeze.default(to_1, -3);  to_1 = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:553 in forward, code: return self._conv_forward(input, self.weight, self.bias)
        conv2d: &quot;f32[32, 20, 20]&quot; = torch.ops.aten.conv2d.default(unsqueeze_1, p_module_1_module_0_module_0_module_0_0_weight, p_module_1_module_0_module_0_module_0_0_bias, [4, 4]);  unsqueeze_1 = p_module_1_module_0_module_0_module_0_0_weight = p_module_1_module_0_module_0_module_0_0_bias = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:143 in forward, code: return F.relu(input, inplace=self.inplace)
        relu: &quot;f32[32, 20, 20]&quot; = torch.ops.aten.relu.default(conv2d);  conv2d = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:553 in forward, code: return self._conv_forward(input, self.weight, self.bias)
        conv2d_1: &quot;f32[64, 9, 9]&quot; = torch.ops.aten.conv2d.default(relu, p_module_1_module_0_module_0_module_0_2_weight, p_module_1_module_0_module_0_module_0_2_bias, [2, 2]);  relu = p_module_1_module_0_module_0_module_0_2_weight = p_module_1_module_0_module_0_module_0_2_bias = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:143 in forward, code: return F.relu(input, inplace=self.inplace)
        relu_1: &quot;f32[64, 9, 9]&quot; = torch.ops.aten.relu.default(conv2d_1);  conv2d_1 = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:553 in forward, code: return self._conv_forward(input, self.weight, self.bias)
        conv2d_2: &quot;f32[64, 7, 7]&quot; = torch.ops.aten.conv2d.default(relu_1, p_module_1_module_0_module_0_module_0_4_weight, p_module_1_module_0_module_0_module_0_4_bias);  relu_1 = p_module_1_module_0_module_0_module_0_4_weight = p_module_1_module_0_module_0_module_0_4_bias = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:143 in forward, code: return F.relu(input, inplace=self.inplace)
        relu_2: &quot;f32[64, 7, 7]&quot; = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None

        # File: /pytorch/rl/torchrl/modules/models/utils.py:84 in forward, code: value = value.flatten(-self.ndims_in, -1)
        flatten: &quot;f32[3136]&quot; = torch.ops.aten.flatten.using_ints(relu_2, -3);  relu_2 = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)
        linear: &quot;f32[512]&quot; = torch.ops.aten.linear.default(flatten, p_module_1_module_0_module_0_module_1_0_weight, p_module_1_module_0_module_0_module_1_0_bias);  flatten = p_module_1_module_0_module_0_module_1_0_weight = p_module_1_module_0_module_0_module_1_0_bias = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:143 in forward, code: return F.relu(input, inplace=self.inplace)
        relu_3: &quot;f32[512]&quot; = torch.ops.aten.relu.default(linear);  linear = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)
        linear_1: &quot;f32[6]&quot; = torch.ops.aten.linear.default(relu_3, p_module_1_module_0_module_0_module_1_2_weight, p_module_1_module_0_module_0_module_1_2_bias);  relu_3 = p_module_1_module_0_module_0_module_1_2_weight = p_module_1_module_0_module_0_module_1_2_bias = None

        # File: /pytorch/rl/torchrl/modules/tensordict_module/actors.py:615 in forward, code: action = self.action_func_mapping[self.action_space](action_values)
        argmax: &quot;i64[]&quot; = torch.ops.aten.argmax.default(linear_1, -1)
        _assert_tensor_metadata_default_2 = torch.ops.aten._assert_tensor_metadata.default(argmax, dtype = torch.int64, device = device(type=&#39;cpu&#39;), layout = torch.strided);  _assert_tensor_metadata_default_2 = None
        to_2: &quot;i64[]&quot; = torch.ops.aten.to.dtype(argmax, torch.int64);  argmax = None

        # File: /pytorch/rl/torchrl/modules/tensordict_module/actors.py:620 in forward, code: chosen_action_value = action_value_func(action_values, action)
        unsqueeze_2: &quot;i64[1]&quot; = torch.ops.aten.unsqueeze.default(to_2, -1)
        gather: &quot;f32[1]&quot; = torch.ops.aten.gather.default(linear_1, -1, unsqueeze_2);  linear_1 = unsqueeze_2 = gather = None
        return (to_2,)


&#39;class GraphModule(torch.nn.Module):\n    def forward(self, p_module_1_module_0_module_0_module_0_0_weight: &quot;f32[32, 1, 8, 8]&quot;, p_module_1_module_0_module_0_module_0_0_bias: &quot;f32[32]&quot;, p_module_1_module_0_module_0_module_0_2_weight: &quot;f32[64, 32, 4, 4]&quot;, p_module_1_module_0_module_0_module_0_2_bias: &quot;f32[64]&quot;, p_module_1_module_0_module_0_module_0_4_weight: &quot;f32[64, 64, 3, 3]&quot;, p_module_1_module_0_module_0_module_0_4_bias: &quot;f32[64]&quot;, p_module_1_module_0_module_0_module_1_0_weight: &quot;f32[512, 3136]&quot;, p_module_1_module_0_module_0_module_1_0_bias: &quot;f32[512]&quot;, p_module_1_module_0_module_0_module_1_2_weight: &quot;f32[6, 512]&quot;, p_module_1_module_0_module_0_module_1_2_bias: &quot;f32[6]&quot;, b_module_1_module_1_eps_init: &quot;f32[]&quot;, b_module_1_module_1_eps_end: &quot;f32[]&quot;, b_module_1_module_1_eps: &quot;f32[]&quot;, pixels: &quot;u8[210, 160, 3]&quot;):\n        # File: /pytorch/rl/torchrl/envs/transforms/transforms.py:500 in forward, code: data = self._apply_transform(data)\n        permute: &quot;u8[3, 210, 160]&quot; = torch.ops.aten.permute.default(pixels, [-1, -3, -2]);  pixels = None\n        div: &quot;f32[3, 210, 160]&quot; = torch.ops.aten.div.Tensor(permute, 255);  permute = None\n        _assert_tensor_metadata_default = torch.ops.aten._assert_tensor_metadata.default(div, dtype = torch.float32, device = device(type=\&#39;cpu\&#39;), layout = torch.strided);  _assert_tensor_metadata_default = None\n        to: &quot;f32[3, 210, 160]&quot; = torch.ops.aten.to.dtype(div, torch.float32);  div = None\n        unsqueeze: &quot;f32[1, 3, 210, 160]&quot; = torch.ops.aten.unsqueeze.default(to, 0);  to = None\n        upsample_nearest2d: &quot;f32[1, 3, 84, 84]&quot; = torch.ops.aten.upsample_nearest2d.vec(unsqueeze, [84, 84], None);  unsqueeze = None\n        squeeze: &quot;f32[3, 84, 84]&quot; = torch.ops.aten.squeeze.dim(upsample_nearest2d, 0);  upsample_nearest2d = None\n        unbind = torch.ops.aten.unbind.int(squeeze, -3);  squeeze = None\n        getitem: &quot;f32[84, 84]&quot; = unbind[0]\n        getitem_1: &quot;f32[84, 84]&quot; = unbind[1]\n        getitem_2: &quot;f32[84, 84]&quot; = unbind[2];  unbind = None\n        mul: &quot;f32[84, 84]&quot; = torch.ops.aten.mul.Tensor(getitem, 0.2989);  getitem = None\n        mul_1: &quot;f32[84, 84]&quot; = torch.ops.aten.mul.Tensor(getitem_1, 0.587);  getitem_1 = None\n        add: &quot;f32[84, 84]&quot; = torch.ops.aten.add.Tensor(mul, mul_1);  mul = mul_1 = None\n        mul_2: &quot;f32[84, 84]&quot; = torch.ops.aten.mul.Tensor(getitem_2, 0.114);  getitem_2 = None\n        add_1: &quot;f32[84, 84]&quot; = torch.ops.aten.add.Tensor(add, mul_2);  add = mul_2 = None\n        _assert_tensor_metadata_default_1 = torch.ops.aten._assert_tensor_metadata.default(add_1, dtype = torch.float32, device = device(type=\&#39;cpu\&#39;), layout = torch.strided);  _assert_tensor_metadata_default_1 = None\n        to_1: &quot;f32[84, 84]&quot; = torch.ops.aten.to.dtype(add_1, torch.float32);  add_1 = None\n        unsqueeze_1: &quot;f32[1, 84, 84]&quot; = torch.ops.aten.unsqueeze.default(to_1, -3);  to_1 = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:553 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n        conv2d: &quot;f32[32, 20, 20]&quot; = torch.ops.aten.conv2d.default(unsqueeze_1, p_module_1_module_0_module_0_module_0_0_weight, p_module_1_module_0_module_0_module_0_0_bias, [4, 4]);  unsqueeze_1 = p_module_1_module_0_module_0_module_0_0_weight = p_module_1_module_0_module_0_module_0_0_bias = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:143 in forward, code: return F.relu(input, inplace=self.inplace)\n        relu: &quot;f32[32, 20, 20]&quot; = torch.ops.aten.relu.default(conv2d);  conv2d = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:553 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n        conv2d_1: &quot;f32[64, 9, 9]&quot; = torch.ops.aten.conv2d.default(relu, p_module_1_module_0_module_0_module_0_2_weight, p_module_1_module_0_module_0_module_0_2_bias, [2, 2]);  relu = p_module_1_module_0_module_0_module_0_2_weight = p_module_1_module_0_module_0_module_0_2_bias = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:143 in forward, code: return F.relu(input, inplace=self.inplace)\n        relu_1: &quot;f32[64, 9, 9]&quot; = torch.ops.aten.relu.default(conv2d_1);  conv2d_1 = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:553 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n        conv2d_2: &quot;f32[64, 7, 7]&quot; = torch.ops.aten.conv2d.default(relu_1, p_module_1_module_0_module_0_module_0_4_weight, p_module_1_module_0_module_0_module_0_4_bias);  relu_1 = p_module_1_module_0_module_0_module_0_4_weight = p_module_1_module_0_module_0_module_0_4_bias = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:143 in forward, code: return F.relu(input, inplace=self.inplace)\n        relu_2: &quot;f32[64, 7, 7]&quot; = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None\n\n        # File: /pytorch/rl/torchrl/modules/models/utils.py:84 in forward, code: value = value.flatten(-self.ndims_in, -1)\n        flatten: &quot;f32[3136]&quot; = torch.ops.aten.flatten.using_ints(relu_2, -3);  relu_2 = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n        linear: &quot;f32[512]&quot; = torch.ops.aten.linear.default(flatten, p_module_1_module_0_module_0_module_1_0_weight, p_module_1_module_0_module_0_module_1_0_bias);  flatten = p_module_1_module_0_module_0_module_1_0_weight = p_module_1_module_0_module_0_module_1_0_bias = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:143 in forward, code: return F.relu(input, inplace=self.inplace)\n        relu_3: &quot;f32[512]&quot; = torch.ops.aten.relu.default(linear);  linear = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n        linear_1: &quot;f32[6]&quot; = torch.ops.aten.linear.default(relu_3, p_module_1_module_0_module_0_module_1_2_weight, p_module_1_module_0_module_0_module_1_2_bias);  relu_3 = p_module_1_module_0_module_0_module_1_2_weight = p_module_1_module_0_module_0_module_1_2_bias = None\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/actors.py:615 in forward, code: action = self.action_func_mapping[self.action_space](action_values)\n        argmax: &quot;i64[]&quot; = torch.ops.aten.argmax.default(linear_1, -1)\n        _assert_tensor_metadata_default_2 = torch.ops.aten._assert_tensor_metadata.default(argmax, dtype = torch.int64, device = device(type=\&#39;cpu\&#39;), layout = torch.strided);  _assert_tensor_metadata_default_2 = None\n        to_2: &quot;i64[]&quot; = torch.ops.aten.to.dtype(argmax, torch.int64);  argmax = None\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/actors.py:620 in forward, code: chosen_action_value = action_value_func(action_values, action)\n        unsqueeze_2: &quot;i64[1]&quot; = torch.ops.aten.unsqueeze.default(to_2, -1)\n        gather: &quot;f32[1]&quot; = torch.ops.aten.gather.default(linear_1, -1, unsqueeze_2);  linear_1 = unsqueeze_2 = gather = None\n        return (to_2,)\n&#39;
</pre></div>
</div>
<p>As a final check, we can execute the policy with a dummy input. The output (for a single image) should be an integer
from 0 to 6 representing the action to be executed in the game.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/export/api_reference.html#torch.export.ExportedProgram.module" title="torch.export.ExportedProgram.module" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-method"><span class="n">exported_policy</span><span class="o">.</span><span class="n">module</span></a><span class="p">()(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pixels</span></a><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pixels</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Exported module output&quot;</span><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Exported module output tensor(1)
</pre></div>
</div>
<p>Further details on exporting <a class="reference external" href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictModule.html#tensordict.nn.TensorDictModule" title="(in tensordict v0.11)"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorDictModule</span></code></a> instances can be found in the tensordict
<a class="reference external" href="https://pytorch.org/tensordict/stable/tutorials/export.html">documentation</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Exporting modules that take and output nested keys is perfectly fine.
The corresponding kwargs will be the <cite>“_”.join(key)</cite> version of the key, i.e., the <cite>(“group0”, “agent0”, “obs”)</cite>
key will correspond to the <cite>“group0_agent0_obs”</cite> keyword argument. Colliding keys (e.g., <cite>(“group0_agent0”, “obs”)</cite>
and <cite>(“group0”, “agent0_obs”)</cite> may lead to undefined behaviours and should be avoided at all cost.
Obviously, key names should also always produce valid keyword arguments, i.e., they should not contain special
characters such as spaces or commas.</p>
</div>
<p><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> has many other features that we will explore further below. Before this, let us just do a small
digression on exploration and stochastic policies in the context of test-time inference, as well as recurrent
policies.</p>
</section>
<section id="working-with-stochastic-policies">
<h2>Working with stochastic policies<a class="headerlink" href="#working-with-stochastic-policies" title="Link to this heading">¶</a></h2>
<p>As you probably noted, above we used the <a class="reference internal" href="../reference/generated/torchrl.envs.set_exploration_type.html#torchrl.envs.set_exploration_type" title="torchrl.envs.set_exploration_type"><code class="xref py py-class docutils literal notranslate"><span class="pre">set_exploration_type</span></code></a> context manager to control
the behaviour of the policy. If the policy is stochastic (e.g., the policy outputs a distribution over the action
space like it is the case in PPO or other similar on-policy algorithms) or explorative (with an exploration module
appended like E-Greedy, additive gaussian or Ornstein-Uhlenbeck) we may want or not want to use that exploration
strategy in its exported version.
Fortunately, export utils can understand that context manager and as long as the exportation occurs within the right
context manager, the behaviour of the policy should match what is indicated. To demonstrate this, let us try with
another exploration type:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.set_interaction_type.html#tensordict.nn.set_interaction_type" title="tensordict.nn.set_interaction_type" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">set_exploration_type</span></a><span class="p">(</span><span class="s2">&quot;RANDOM&quot;</span><span class="p">):</span>
    <a href="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/export/api_reference.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">exported_stochastic_policy</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/export/api_reference.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span></a><span class="p">(</span>
        <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential.select_out_keys" title="tensordict.nn.TensorDictSequential.select_out_keys" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-method"><span class="n">policy_transform</span><span class="o">.</span><span class="n">select_out_keys</span></a><span class="p">(</span><span class="s2">&quot;action&quot;</span><span class="p">),</span>
        <span class="n">args</span><span class="o">=</span><span class="p">(),</span>
        <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;pixels&quot;</span><span class="p">:</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pixels</span></a><span class="p">},</span>
        <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>Our exported policy should now have a random module at the end of the call stack, unlike the previous version.
Indeed, the last three operations are: generate a random integer between 0 and 6, use a random mask and select
the network output or the random action based on the value in the mask.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Stochastic policy&quot;</span><span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/export/api_reference.html#torch.export.ExportedProgram.graph_module" title="torch.export.ExportedProgram.graph_module" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-property"><span class="n">exported_stochastic_policy</span><span class="o">.</span><span class="n">graph_module</span><span class="o">.</span><span class="n">print_readable</span></a><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Stochastic policy
class GraphModule(torch.nn.Module):
    def forward(self, p_module_1_module_0_module_0_module_0_0_weight: &quot;f32[32, 1, 8, 8]&quot;, p_module_1_module_0_module_0_module_0_0_bias: &quot;f32[32]&quot;, p_module_1_module_0_module_0_module_0_2_weight: &quot;f32[64, 32, 4, 4]&quot;, p_module_1_module_0_module_0_module_0_2_bias: &quot;f32[64]&quot;, p_module_1_module_0_module_0_module_0_4_weight: &quot;f32[64, 64, 3, 3]&quot;, p_module_1_module_0_module_0_module_0_4_bias: &quot;f32[64]&quot;, p_module_1_module_0_module_0_module_1_0_weight: &quot;f32[512, 3136]&quot;, p_module_1_module_0_module_0_module_1_0_bias: &quot;f32[512]&quot;, p_module_1_module_0_module_0_module_1_2_weight: &quot;f32[6, 512]&quot;, p_module_1_module_0_module_0_module_1_2_bias: &quot;f32[6]&quot;, b_module_1_module_1_eps_init: &quot;f32[]&quot;, b_module_1_module_1_eps_end: &quot;f32[]&quot;, b_module_1_module_1_eps: &quot;f32[]&quot;, pixels: &quot;u8[210, 160, 3]&quot;):
        # File: /pytorch/rl/torchrl/envs/transforms/transforms.py:500 in forward, code: data = self._apply_transform(data)
        permute: &quot;u8[3, 210, 160]&quot; = torch.ops.aten.permute.default(pixels, [-1, -3, -2]);  pixels = None
        div: &quot;f32[3, 210, 160]&quot; = torch.ops.aten.div.Tensor(permute, 255);  permute = None
        _assert_tensor_metadata_default = torch.ops.aten._assert_tensor_metadata.default(div, dtype = torch.float32, device = device(type=&#39;cpu&#39;), layout = torch.strided);  _assert_tensor_metadata_default = None
        to: &quot;f32[3, 210, 160]&quot; = torch.ops.aten.to.dtype(div, torch.float32);  div = None
        unsqueeze: &quot;f32[1, 3, 210, 160]&quot; = torch.ops.aten.unsqueeze.default(to, 0);  to = None
        upsample_nearest2d: &quot;f32[1, 3, 84, 84]&quot; = torch.ops.aten.upsample_nearest2d.vec(unsqueeze, [84, 84], None);  unsqueeze = None
        squeeze: &quot;f32[3, 84, 84]&quot; = torch.ops.aten.squeeze.dim(upsample_nearest2d, 0);  upsample_nearest2d = None
        unbind = torch.ops.aten.unbind.int(squeeze, -3);  squeeze = None
        getitem: &quot;f32[84, 84]&quot; = unbind[0]
        getitem_1: &quot;f32[84, 84]&quot; = unbind[1]
        getitem_2: &quot;f32[84, 84]&quot; = unbind[2];  unbind = None
        mul: &quot;f32[84, 84]&quot; = torch.ops.aten.mul.Tensor(getitem, 0.2989);  getitem = None
        mul_1: &quot;f32[84, 84]&quot; = torch.ops.aten.mul.Tensor(getitem_1, 0.587);  getitem_1 = None
        add: &quot;f32[84, 84]&quot; = torch.ops.aten.add.Tensor(mul, mul_1);  mul = mul_1 = None
        mul_2: &quot;f32[84, 84]&quot; = torch.ops.aten.mul.Tensor(getitem_2, 0.114);  getitem_2 = None
        add_1: &quot;f32[84, 84]&quot; = torch.ops.aten.add.Tensor(add, mul_2);  add = mul_2 = None
        _assert_tensor_metadata_default_1 = torch.ops.aten._assert_tensor_metadata.default(add_1, dtype = torch.float32, device = device(type=&#39;cpu&#39;), layout = torch.strided);  _assert_tensor_metadata_default_1 = None
        to_1: &quot;f32[84, 84]&quot; = torch.ops.aten.to.dtype(add_1, torch.float32);  add_1 = None
        unsqueeze_1: &quot;f32[1, 84, 84]&quot; = torch.ops.aten.unsqueeze.default(to_1, -3);  to_1 = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:553 in forward, code: return self._conv_forward(input, self.weight, self.bias)
        conv2d: &quot;f32[32, 20, 20]&quot; = torch.ops.aten.conv2d.default(unsqueeze_1, p_module_1_module_0_module_0_module_0_0_weight, p_module_1_module_0_module_0_module_0_0_bias, [4, 4]);  unsqueeze_1 = p_module_1_module_0_module_0_module_0_0_weight = p_module_1_module_0_module_0_module_0_0_bias = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:143 in forward, code: return F.relu(input, inplace=self.inplace)
        relu: &quot;f32[32, 20, 20]&quot; = torch.ops.aten.relu.default(conv2d);  conv2d = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:553 in forward, code: return self._conv_forward(input, self.weight, self.bias)
        conv2d_1: &quot;f32[64, 9, 9]&quot; = torch.ops.aten.conv2d.default(relu, p_module_1_module_0_module_0_module_0_2_weight, p_module_1_module_0_module_0_module_0_2_bias, [2, 2]);  relu = p_module_1_module_0_module_0_module_0_2_weight = p_module_1_module_0_module_0_module_0_2_bias = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:143 in forward, code: return F.relu(input, inplace=self.inplace)
        relu_1: &quot;f32[64, 9, 9]&quot; = torch.ops.aten.relu.default(conv2d_1);  conv2d_1 = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:553 in forward, code: return self._conv_forward(input, self.weight, self.bias)
        conv2d_2: &quot;f32[64, 7, 7]&quot; = torch.ops.aten.conv2d.default(relu_1, p_module_1_module_0_module_0_module_0_4_weight, p_module_1_module_0_module_0_module_0_4_bias);  relu_1 = p_module_1_module_0_module_0_module_0_4_weight = p_module_1_module_0_module_0_module_0_4_bias = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:143 in forward, code: return F.relu(input, inplace=self.inplace)
        relu_2: &quot;f32[64, 7, 7]&quot; = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None

        # File: /pytorch/rl/torchrl/modules/models/utils.py:84 in forward, code: value = value.flatten(-self.ndims_in, -1)
        flatten: &quot;f32[3136]&quot; = torch.ops.aten.flatten.using_ints(relu_2, -3);  relu_2 = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)
        linear: &quot;f32[512]&quot; = torch.ops.aten.linear.default(flatten, p_module_1_module_0_module_0_module_1_0_weight, p_module_1_module_0_module_0_module_1_0_bias);  flatten = p_module_1_module_0_module_0_module_1_0_weight = p_module_1_module_0_module_0_module_1_0_bias = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:143 in forward, code: return F.relu(input, inplace=self.inplace)
        relu_3: &quot;f32[512]&quot; = torch.ops.aten.relu.default(linear);  linear = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)
        linear_1: &quot;f32[6]&quot; = torch.ops.aten.linear.default(relu_3, p_module_1_module_0_module_0_module_1_2_weight, p_module_1_module_0_module_0_module_1_2_bias);  relu_3 = p_module_1_module_0_module_0_module_1_2_weight = p_module_1_module_0_module_0_module_1_2_bias = None

        # File: /pytorch/rl/torchrl/modules/tensordict_module/actors.py:615 in forward, code: action = self.action_func_mapping[self.action_space](action_values)
        argmax: &quot;i64[]&quot; = torch.ops.aten.argmax.default(linear_1, -1)
        _assert_tensor_metadata_default_2 = torch.ops.aten._assert_tensor_metadata.default(argmax, dtype = torch.int64, device = device(type=&#39;cpu&#39;), layout = torch.strided);  _assert_tensor_metadata_default_2 = None
        to_2: &quot;i64[]&quot; = torch.ops.aten.to.dtype(argmax, torch.int64);  argmax = None

        # File: /pytorch/rl/torchrl/modules/tensordict_module/actors.py:620 in forward, code: chosen_action_value = action_value_func(action_values, action)
        unsqueeze_2: &quot;i64[1]&quot; = torch.ops.aten.unsqueeze.default(to_2, -1)
        gather: &quot;f32[1]&quot; = torch.ops.aten.gather.default(linear_1, -1, unsqueeze_2);  linear_1 = unsqueeze_2 = gather = None

        # File: /pytorch/rl/torchrl/modules/tensordict_module/exploration.py:175 in forward, code: cond = torch.rand(action_tensordict.shape, device=device) &lt; eps
        rand: &quot;f32[]&quot; = torch.ops.aten.rand.default([], device = device(type=&#39;cpu&#39;), pin_memory = False)
        lt: &quot;b8[]&quot; = torch.ops.aten.lt.Tensor(rand, b_module_1_module_1_eps);  rand = b_module_1_module_1_eps = None

        # File: /pytorch/rl/torchrl/modules/tensordict_module/exploration.py:177 in forward, code: cond = expand_as_right(cond, action)
        expand: &quot;b8[]&quot; = torch.ops.aten.expand.default(lt, []);  lt = None

        # File: /pytorch/rl/torchrl/modules/tensordict_module/exploration.py:201 in forward, code: r = spec.rand()
        randint: &quot;i64[]&quot; = torch.ops.aten.randint.low(0, 6, [], device = device(type=&#39;cpu&#39;), pin_memory = False)

        # File: /pytorch/rl/torchrl/modules/tensordict_module/exploration.py:204 in forward, code: action = torch.where(cond, r, action)
        where: &quot;i64[]&quot; = torch.ops.aten.where.self(expand, randint, to_2);  expand = randint = to_2 = None
        return (where,)


&#39;class GraphModule(torch.nn.Module):\n    def forward(self, p_module_1_module_0_module_0_module_0_0_weight: &quot;f32[32, 1, 8, 8]&quot;, p_module_1_module_0_module_0_module_0_0_bias: &quot;f32[32]&quot;, p_module_1_module_0_module_0_module_0_2_weight: &quot;f32[64, 32, 4, 4]&quot;, p_module_1_module_0_module_0_module_0_2_bias: &quot;f32[64]&quot;, p_module_1_module_0_module_0_module_0_4_weight: &quot;f32[64, 64, 3, 3]&quot;, p_module_1_module_0_module_0_module_0_4_bias: &quot;f32[64]&quot;, p_module_1_module_0_module_0_module_1_0_weight: &quot;f32[512, 3136]&quot;, p_module_1_module_0_module_0_module_1_0_bias: &quot;f32[512]&quot;, p_module_1_module_0_module_0_module_1_2_weight: &quot;f32[6, 512]&quot;, p_module_1_module_0_module_0_module_1_2_bias: &quot;f32[6]&quot;, b_module_1_module_1_eps_init: &quot;f32[]&quot;, b_module_1_module_1_eps_end: &quot;f32[]&quot;, b_module_1_module_1_eps: &quot;f32[]&quot;, pixels: &quot;u8[210, 160, 3]&quot;):\n        # File: /pytorch/rl/torchrl/envs/transforms/transforms.py:500 in forward, code: data = self._apply_transform(data)\n        permute: &quot;u8[3, 210, 160]&quot; = torch.ops.aten.permute.default(pixels, [-1, -3, -2]);  pixels = None\n        div: &quot;f32[3, 210, 160]&quot; = torch.ops.aten.div.Tensor(permute, 255);  permute = None\n        _assert_tensor_metadata_default = torch.ops.aten._assert_tensor_metadata.default(div, dtype = torch.float32, device = device(type=\&#39;cpu\&#39;), layout = torch.strided);  _assert_tensor_metadata_default = None\n        to: &quot;f32[3, 210, 160]&quot; = torch.ops.aten.to.dtype(div, torch.float32);  div = None\n        unsqueeze: &quot;f32[1, 3, 210, 160]&quot; = torch.ops.aten.unsqueeze.default(to, 0);  to = None\n        upsample_nearest2d: &quot;f32[1, 3, 84, 84]&quot; = torch.ops.aten.upsample_nearest2d.vec(unsqueeze, [84, 84], None);  unsqueeze = None\n        squeeze: &quot;f32[3, 84, 84]&quot; = torch.ops.aten.squeeze.dim(upsample_nearest2d, 0);  upsample_nearest2d = None\n        unbind = torch.ops.aten.unbind.int(squeeze, -3);  squeeze = None\n        getitem: &quot;f32[84, 84]&quot; = unbind[0]\n        getitem_1: &quot;f32[84, 84]&quot; = unbind[1]\n        getitem_2: &quot;f32[84, 84]&quot; = unbind[2];  unbind = None\n        mul: &quot;f32[84, 84]&quot; = torch.ops.aten.mul.Tensor(getitem, 0.2989);  getitem = None\n        mul_1: &quot;f32[84, 84]&quot; = torch.ops.aten.mul.Tensor(getitem_1, 0.587);  getitem_1 = None\n        add: &quot;f32[84, 84]&quot; = torch.ops.aten.add.Tensor(mul, mul_1);  mul = mul_1 = None\n        mul_2: &quot;f32[84, 84]&quot; = torch.ops.aten.mul.Tensor(getitem_2, 0.114);  getitem_2 = None\n        add_1: &quot;f32[84, 84]&quot; = torch.ops.aten.add.Tensor(add, mul_2);  add = mul_2 = None\n        _assert_tensor_metadata_default_1 = torch.ops.aten._assert_tensor_metadata.default(add_1, dtype = torch.float32, device = device(type=\&#39;cpu\&#39;), layout = torch.strided);  _assert_tensor_metadata_default_1 = None\n        to_1: &quot;f32[84, 84]&quot; = torch.ops.aten.to.dtype(add_1, torch.float32);  add_1 = None\n        unsqueeze_1: &quot;f32[1, 84, 84]&quot; = torch.ops.aten.unsqueeze.default(to_1, -3);  to_1 = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:553 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n        conv2d: &quot;f32[32, 20, 20]&quot; = torch.ops.aten.conv2d.default(unsqueeze_1, p_module_1_module_0_module_0_module_0_0_weight, p_module_1_module_0_module_0_module_0_0_bias, [4, 4]);  unsqueeze_1 = p_module_1_module_0_module_0_module_0_0_weight = p_module_1_module_0_module_0_module_0_0_bias = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:143 in forward, code: return F.relu(input, inplace=self.inplace)\n        relu: &quot;f32[32, 20, 20]&quot; = torch.ops.aten.relu.default(conv2d);  conv2d = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:553 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n        conv2d_1: &quot;f32[64, 9, 9]&quot; = torch.ops.aten.conv2d.default(relu, p_module_1_module_0_module_0_module_0_2_weight, p_module_1_module_0_module_0_module_0_2_bias, [2, 2]);  relu = p_module_1_module_0_module_0_module_0_2_weight = p_module_1_module_0_module_0_module_0_2_bias = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:143 in forward, code: return F.relu(input, inplace=self.inplace)\n        relu_1: &quot;f32[64, 9, 9]&quot; = torch.ops.aten.relu.default(conv2d_1);  conv2d_1 = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:553 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n        conv2d_2: &quot;f32[64, 7, 7]&quot; = torch.ops.aten.conv2d.default(relu_1, p_module_1_module_0_module_0_module_0_4_weight, p_module_1_module_0_module_0_module_0_4_bias);  relu_1 = p_module_1_module_0_module_0_module_0_4_weight = p_module_1_module_0_module_0_module_0_4_bias = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:143 in forward, code: return F.relu(input, inplace=self.inplace)\n        relu_2: &quot;f32[64, 7, 7]&quot; = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None\n\n        # File: /pytorch/rl/torchrl/modules/models/utils.py:84 in forward, code: value = value.flatten(-self.ndims_in, -1)\n        flatten: &quot;f32[3136]&quot; = torch.ops.aten.flatten.using_ints(relu_2, -3);  relu_2 = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n        linear: &quot;f32[512]&quot; = torch.ops.aten.linear.default(flatten, p_module_1_module_0_module_0_module_1_0_weight, p_module_1_module_0_module_0_module_1_0_bias);  flatten = p_module_1_module_0_module_0_module_1_0_weight = p_module_1_module_0_module_0_module_1_0_bias = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:143 in forward, code: return F.relu(input, inplace=self.inplace)\n        relu_3: &quot;f32[512]&quot; = torch.ops.aten.relu.default(linear);  linear = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n        linear_1: &quot;f32[6]&quot; = torch.ops.aten.linear.default(relu_3, p_module_1_module_0_module_0_module_1_2_weight, p_module_1_module_0_module_0_module_1_2_bias);  relu_3 = p_module_1_module_0_module_0_module_1_2_weight = p_module_1_module_0_module_0_module_1_2_bias = None\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/actors.py:615 in forward, code: action = self.action_func_mapping[self.action_space](action_values)\n        argmax: &quot;i64[]&quot; = torch.ops.aten.argmax.default(linear_1, -1)\n        _assert_tensor_metadata_default_2 = torch.ops.aten._assert_tensor_metadata.default(argmax, dtype = torch.int64, device = device(type=\&#39;cpu\&#39;), layout = torch.strided);  _assert_tensor_metadata_default_2 = None\n        to_2: &quot;i64[]&quot; = torch.ops.aten.to.dtype(argmax, torch.int64);  argmax = None\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/actors.py:620 in forward, code: chosen_action_value = action_value_func(action_values, action)\n        unsqueeze_2: &quot;i64[1]&quot; = torch.ops.aten.unsqueeze.default(to_2, -1)\n        gather: &quot;f32[1]&quot; = torch.ops.aten.gather.default(linear_1, -1, unsqueeze_2);  linear_1 = unsqueeze_2 = gather = None\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/exploration.py:175 in forward, code: cond = torch.rand(action_tensordict.shape, device=device) &lt; eps\n        rand: &quot;f32[]&quot; = torch.ops.aten.rand.default([], device = device(type=\&#39;cpu\&#39;), pin_memory = False)\n        lt: &quot;b8[]&quot; = torch.ops.aten.lt.Tensor(rand, b_module_1_module_1_eps);  rand = b_module_1_module_1_eps = None\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/exploration.py:177 in forward, code: cond = expand_as_right(cond, action)\n        expand: &quot;b8[]&quot; = torch.ops.aten.expand.default(lt, []);  lt = None\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/exploration.py:201 in forward, code: r = spec.rand()\n        randint: &quot;i64[]&quot; = torch.ops.aten.randint.low(0, 6, [], device = device(type=\&#39;cpu\&#39;), pin_memory = False)\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/exploration.py:204 in forward, code: action = torch.where(cond, r, action)\n        where: &quot;i64[]&quot; = torch.ops.aten.where.self(expand, randint, to_2);  expand = randint = to_2 = None\n        return (where,)\n&#39;
</pre></div>
</div>
</section>
<section id="working-with-recurrent-policies">
<h2>Working with recurrent policies<a class="headerlink" href="#working-with-recurrent-policies" title="Link to this heading">¶</a></h2>
<p>Another typical use case is a recurrent policy that will output an action as well as a one or more recurrent state.
LSTM and GRU are CuDNN-based modules, which means that they will behave differently than regular
<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> instances (export utils may not trace them well). Fortunately, TorchRL provides a python
implementation of these modules that can be swapped with the CuDNN version when desired.</p>
<p>To show this, let us write a prototypical policy that relies on an RNN:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensordict.nn</span> <span class="kn">import</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictModule.html#tensordict.nn.TensorDictModule" title="tensordict.nn.TensorDictModule" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">TensorDictModule</span></a>
<span class="kn">from</span> <span class="nn">torchrl.envs</span> <span class="kn">import</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">BatchSizeTransform</span></a>
<span class="kn">from</span> <span class="nn">torchrl.modules</span> <span class="kn">import</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictModuleBase.html#tensordict.nn.TensorDictModuleBase" title="tensordict.nn.TensorDictModuleBase" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">LSTMModule</span></a><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">MLP</span></a>

<span class="n">lstm</span> <span class="o">=</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictModuleBase.html#tensordict.nn.TensorDictModuleBase" title="tensordict.nn.TensorDictModuleBase" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">LSTMModule</span></a><span class="p">(</span>
    <span class="n">input_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">,</span> <span class="s2">&quot;hidden0&quot;</span><span class="p">,</span> <span class="s2">&quot;hidden1&quot;</span><span class="p">],</span>
    <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;intermediate&quot;</span><span class="p">,</span> <span class="s2">&quot;hidden0&quot;</span><span class="p">,</span> <span class="s2">&quot;hidden1&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<p>If the LSTM module is not python based but CuDNN (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSTM</span></code></a>), the <a class="reference internal" href="../reference/generated/torchrl.modules.LSTMModule.html#torchrl.modules.LSTMModule.make_python_based" title="torchrl.modules.LSTMModule.make_python_based"><code class="xref py py-meth docutils literal notranslate"><span class="pre">make_python_based()</span></code></a>
method can be used to use the python version.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">lstm</span> <span class="o">=</span> <span class="n">lstm</span><span class="o">.</span><span class="n">make_python_based</span><span class="p">()</span>
</pre></div>
</div>
<p>Let’s now create the policy. We combine two layers that modify the shape of the input (unsqueeze/squeeze operations)
with the LSTM and an MLP.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">recurrent_policy</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">TensorDictSequential</span></a><span class="p">(</span>
    <span class="c1"># Unsqueeze the first dim of all tensors to make LSTMCell happy</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">BatchSizeTransform</span></a><span class="p">(</span><span class="n">reshape_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)),</span>
    <span class="n">lstm</span><span class="p">,</span>
    <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictModule.html#tensordict.nn.TensorDictModule" title="tensordict.nn.TensorDictModule" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">TensorDictModule</span></a><span class="p">(</span>
        <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">MLP</span></a><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">num_cells</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">]),</span>
        <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;intermediate&quot;</span><span class="p">],</span>
        <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">],</span>
    <span class="p">),</span>
    <span class="c1"># Squeeze the first dim of all tensors to get the original shape back</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">BatchSizeTransform</span></a><span class="p">(</span><span class="n">reshape_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)),</span>
<span class="p">)</span>
</pre></div>
</div>
<p>As before, we select the relevant keys:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential.select_out_keys" title="tensordict.nn.TensorDictSequential.select_out_keys" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-method"><span class="n">recurrent_policy</span><span class="o">.</span><span class="n">select_out_keys</span></a><span class="p">(</span><span class="s2">&quot;action&quot;</span><span class="p">,</span> <span class="s2">&quot;hidden0&quot;</span><span class="p">,</span> <span class="s2">&quot;hidden1&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;recurrent policy input keys:&quot;</span><span class="p">,</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">recurrent_policy</span></a><span class="o">.</span><span class="n">in_keys</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;recurrent policy output keys:&quot;</span><span class="p">,</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">recurrent_policy</span></a><span class="o">.</span><span class="n">out_keys</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>recurrent policy input keys: [&#39;observation&#39;, &#39;hidden0&#39;, &#39;hidden1&#39;, &#39;is_init&#39;]
recurrent policy output keys: [&#39;action&#39;, &#39;hidden0&#39;, &#39;hidden1&#39;]
</pre></div>
</div>
<p>We are now ready to export. To do this, we build fake inputs and pass them to <a class="reference external" href="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/export/api_reference.html#torch.export.export" title="(in PyTorch v2.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">export()</span></code></a>:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fake_obs</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fake_hidden0</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fake_hidden1</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>

<span class="c1"># Tensor indicating whether the state is the first of a sequence</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fake_is_init</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros" title="torch.zeros" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">bool</span></a><span class="p">)</span>

<a href="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/export/api_reference.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">exported_recurrent_policy</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/export/api_reference.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span></a><span class="p">(</span>
    <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">recurrent_policy</span></a><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="p">(),</span>
    <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;observation&quot;</span><span class="p">:</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fake_obs</span></a><span class="p">,</span>
        <span class="s2">&quot;hidden0&quot;</span><span class="p">:</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fake_hidden0</span></a><span class="p">,</span>
        <span class="s2">&quot;hidden1&quot;</span><span class="p">:</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fake_hidden1</span></a><span class="p">,</span>
        <span class="s2">&quot;is_init&quot;</span><span class="p">:</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fake_is_init</span></a><span class="p">,</span>
    <span class="p">},</span>
    <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Recurrent policy graph:&quot;</span><span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/export/api_reference.html#torch.export.ExportedProgram.graph_module" title="torch.export.ExportedProgram.graph_module" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-property"><span class="n">exported_recurrent_policy</span><span class="o">.</span><span class="n">graph_module</span><span class="o">.</span><span class="n">print_readable</span></a><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Recurrent policy graph:
class GraphModule(torch.nn.Module):
    def forward(self, p_module_1_lstm_weight_ih_l0: &quot;f32[1024, 32]&quot;, p_module_1_lstm_weight_hh_l0: &quot;f32[1024, 256]&quot;, p_module_1_lstm_bias_ih_l0: &quot;f32[1024]&quot;, p_module_1_lstm_bias_hh_l0: &quot;f32[1024]&quot;, p_module_1_lstm_weight_ih_l1: &quot;f32[1024, 256]&quot;, p_module_1_lstm_weight_hh_l1: &quot;f32[1024, 256]&quot;, p_module_1_lstm_bias_ih_l1: &quot;f32[1024]&quot;, p_module_1_lstm_bias_hh_l1: &quot;f32[1024]&quot;, p_module_2_module_0_weight: &quot;f32[64, 256]&quot;, p_module_2_module_0_bias: &quot;f32[64]&quot;, p_module_2_module_2_weight: &quot;f32[64, 64]&quot;, p_module_2_module_2_bias: &quot;f32[64]&quot;, p_module_2_module_4_weight: &quot;f32[5, 64]&quot;, p_module_2_module_4_bias: &quot;f32[5]&quot;, observation: &quot;f32[32]&quot;, hidden0: &quot;f32[2, 256]&quot;, hidden1: &quot;f32[2, 256]&quot;, is_init: &quot;b8[]&quot;):
        # File: /opt/conda/lib/python3.11/site-packages/tensordict/nn/sequence.py:642 in forward, code: tensordict_exec = self._run_module(
        unsqueeze: &quot;f32[1, 32]&quot; = torch.ops.aten.unsqueeze.default(observation, 0);  observation = None
        unsqueeze_1: &quot;f32[1, 2, 256]&quot; = torch.ops.aten.unsqueeze.default(hidden0, 0);  hidden0 = None
        unsqueeze_2: &quot;f32[1, 2, 256]&quot; = torch.ops.aten.unsqueeze.default(hidden1, 0);  hidden1 = None
        unsqueeze_3: &quot;b8[1]&quot; = torch.ops.aten.unsqueeze.default(is_init, 0);  is_init = None

        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:705 in forward, code: tensordict_shaped = tensordict.reshape(-1).unsqueeze(-1)
        unsqueeze_4: &quot;f32[1, 1, 32]&quot; = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None
        unsqueeze_5: &quot;f32[1, 1, 2, 256]&quot; = torch.ops.aten.unsqueeze.default(unsqueeze_1, 1);  unsqueeze_1 = None
        unsqueeze_6: &quot;f32[1, 1, 2, 256]&quot; = torch.ops.aten.unsqueeze.default(unsqueeze_2, 1);  unsqueeze_2 = None
        unsqueeze_7: &quot;b8[1, 1]&quot; = torch.ops.aten.unsqueeze.default(unsqueeze_3, 1);  unsqueeze_3 = None

        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:707 in forward, code: is_init = tensordict_shaped[&quot;is_init&quot;].squeeze(-1)
        squeeze: &quot;b8[1]&quot; = torch.ops.aten.squeeze.dim(unsqueeze_7, -1)

        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:738 in forward, code: is_init_expand = expand_as_right(is_init, hidden0)
        unsqueeze_8: &quot;b8[1, 1]&quot; = torch.ops.aten.unsqueeze.default(squeeze, -1);  squeeze = None
        unsqueeze_9: &quot;b8[1, 1, 1]&quot; = torch.ops.aten.unsqueeze.default(unsqueeze_8, -1);  unsqueeze_8 = None
        unsqueeze_10: &quot;b8[1, 1, 1, 1]&quot; = torch.ops.aten.unsqueeze.default(unsqueeze_9, -1);  unsqueeze_9 = None
        expand: &quot;b8[1, 1, 2, 256]&quot; = torch.ops.aten.expand.default(unsqueeze_10, [1, 1, 2, 256]);  unsqueeze_10 = None

        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:739 in forward, code: zeros = torch.zeros_like(hidden0)
        zeros_like: &quot;f32[1, 1, 2, 256]&quot; = torch.ops.aten.zeros_like.default(unsqueeze_5, pin_memory = False)

        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:740 in forward, code: hidden0 = torch.where(is_init_expand, zeros, hidden0)
        where: &quot;f32[1, 1, 2, 256]&quot; = torch.ops.aten.where.self(expand, zeros_like, unsqueeze_5);  unsqueeze_5 = None

        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:741 in forward, code: hidden1 = torch.where(is_init_expand, zeros, hidden1)
        where_1: &quot;f32[1, 1, 2, 256]&quot; = torch.ops.aten.where.self(expand, zeros_like, unsqueeze_6);  expand = zeros_like = unsqueeze_6 = None

        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:747 in forward, code: val, hidden0, hidden1 = self._lstm(
        select: &quot;f32[1, 2, 256]&quot; = torch.ops.aten.select.int(where, 1, 0);  where = None
        select_1: &quot;f32[1, 2, 256]&quot; = torch.ops.aten.select.int(where_1, 1, 0);  where_1 = None
        transpose: &quot;f32[2, 1, 256]&quot; = torch.ops.aten.transpose.int(select, -3, -2);  select = None
        transpose_1: &quot;f32[2, 1, 256]&quot; = torch.ops.aten.transpose.int(select_1, -3, -2);  select_1 = None

        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:308 in forward, code: return self._lstm(input, hx)
        unbind = torch.ops.aten.unbind.int(transpose);  transpose = None
        getitem: &quot;f32[1, 256]&quot; = unbind[0]
        getitem_1: &quot;f32[1, 256]&quot; = unbind[1];  unbind = None
        unbind_1 = torch.ops.aten.unbind.int(transpose_1);  transpose_1 = None
        getitem_2: &quot;f32[1, 256]&quot; = unbind_1[0]
        getitem_3: &quot;f32[1, 256]&quot; = unbind_1[1];  unbind_1 = None
        unbind_2 = torch.ops.aten.unbind.int(unsqueeze_4, 1)
        getitem_4: &quot;f32[1, 32]&quot; = unbind_2[0];  unbind_2 = None
        linear: &quot;f32[1, 1024]&quot; = torch.ops.aten.linear.default(getitem_4, p_module_1_lstm_weight_ih_l0, p_module_1_lstm_bias_ih_l0);  getitem_4 = p_module_1_lstm_weight_ih_l0 = p_module_1_lstm_bias_ih_l0 = None
        linear_1: &quot;f32[1, 1024]&quot; = torch.ops.aten.linear.default(getitem, p_module_1_lstm_weight_hh_l0, p_module_1_lstm_bias_hh_l0);  getitem = p_module_1_lstm_weight_hh_l0 = p_module_1_lstm_bias_hh_l0 = None
        add: &quot;f32[1, 1024]&quot; = torch.ops.aten.add.Tensor(linear, linear_1);  linear = linear_1 = None
        chunk = torch.ops.aten.chunk.default(add, 4, 1);  add = None
        getitem_5: &quot;f32[1, 256]&quot; = chunk[0]
        getitem_6: &quot;f32[1, 256]&quot; = chunk[1]
        getitem_7: &quot;f32[1, 256]&quot; = chunk[2]
        getitem_8: &quot;f32[1, 256]&quot; = chunk[3];  chunk = None
        sigmoid: &quot;f32[1, 256]&quot; = torch.ops.aten.sigmoid.default(getitem_5);  getitem_5 = None
        sigmoid_1: &quot;f32[1, 256]&quot; = torch.ops.aten.sigmoid.default(getitem_6);  getitem_6 = None
        tanh: &quot;f32[1, 256]&quot; = torch.ops.aten.tanh.default(getitem_7);  getitem_7 = None
        sigmoid_2: &quot;f32[1, 256]&quot; = torch.ops.aten.sigmoid.default(getitem_8);  getitem_8 = None
        mul: &quot;f32[1, 256]&quot; = torch.ops.aten.mul.Tensor(getitem_2, sigmoid_1);  getitem_2 = sigmoid_1 = None
        mul_1: &quot;f32[1, 256]&quot; = torch.ops.aten.mul.Tensor(sigmoid, tanh);  sigmoid = tanh = None
        add_1: &quot;f32[1, 256]&quot; = torch.ops.aten.add.Tensor(mul, mul_1);  mul = mul_1 = None
        tanh_1: &quot;f32[1, 256]&quot; = torch.ops.aten.tanh.default(add_1)
        mul_2: &quot;f32[1, 256]&quot; = torch.ops.aten.mul.Tensor(sigmoid_2, tanh_1);  sigmoid_2 = tanh_1 = None
        linear_2: &quot;f32[1, 1024]&quot; = torch.ops.aten.linear.default(mul_2, p_module_1_lstm_weight_ih_l1, p_module_1_lstm_bias_ih_l1);  p_module_1_lstm_weight_ih_l1 = p_module_1_lstm_bias_ih_l1 = None
        linear_3: &quot;f32[1, 1024]&quot; = torch.ops.aten.linear.default(getitem_1, p_module_1_lstm_weight_hh_l1, p_module_1_lstm_bias_hh_l1);  getitem_1 = p_module_1_lstm_weight_hh_l1 = p_module_1_lstm_bias_hh_l1 = None
        add_2: &quot;f32[1, 1024]&quot; = torch.ops.aten.add.Tensor(linear_2, linear_3);  linear_2 = linear_3 = None
        chunk_1 = torch.ops.aten.chunk.default(add_2, 4, 1);  add_2 = None
        getitem_9: &quot;f32[1, 256]&quot; = chunk_1[0]
        getitem_10: &quot;f32[1, 256]&quot; = chunk_1[1]
        getitem_11: &quot;f32[1, 256]&quot; = chunk_1[2]
        getitem_12: &quot;f32[1, 256]&quot; = chunk_1[3];  chunk_1 = None
        sigmoid_3: &quot;f32[1, 256]&quot; = torch.ops.aten.sigmoid.default(getitem_9);  getitem_9 = None
        sigmoid_4: &quot;f32[1, 256]&quot; = torch.ops.aten.sigmoid.default(getitem_10);  getitem_10 = None
        tanh_2: &quot;f32[1, 256]&quot; = torch.ops.aten.tanh.default(getitem_11);  getitem_11 = None
        sigmoid_5: &quot;f32[1, 256]&quot; = torch.ops.aten.sigmoid.default(getitem_12);  getitem_12 = None
        mul_3: &quot;f32[1, 256]&quot; = torch.ops.aten.mul.Tensor(getitem_3, sigmoid_4);  getitem_3 = sigmoid_4 = None
        mul_4: &quot;f32[1, 256]&quot; = torch.ops.aten.mul.Tensor(sigmoid_3, tanh_2);  sigmoid_3 = tanh_2 = None
        add_3: &quot;f32[1, 256]&quot; = torch.ops.aten.add.Tensor(mul_3, mul_4);  mul_3 = mul_4 = None
        tanh_3: &quot;f32[1, 256]&quot; = torch.ops.aten.tanh.default(add_3)
        mul_5: &quot;f32[1, 256]&quot; = torch.ops.aten.mul.Tensor(sigmoid_5, tanh_3);  sigmoid_5 = tanh_3 = None
        stack: &quot;f32[1, 1, 256]&quot; = torch.ops.aten.stack.default([mul_5], 1)
        stack_1: &quot;f32[2, 1, 256]&quot; = torch.ops.aten.stack.default([mul_2, mul_5]);  mul_2 = mul_5 = None
        stack_2: &quot;f32[2, 1, 256]&quot; = torch.ops.aten.stack.default([add_1, add_3]);  add_1 = add_3 = None

        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:747 in forward, code: val, hidden0, hidden1 = self._lstm(
        transpose_2: &quot;f32[1, 2, 256]&quot; = torch.ops.aten.transpose.int(stack_1, 0, 1);  stack_1 = None
        transpose_3: &quot;f32[1, 2, 256]&quot; = torch.ops.aten.transpose.int(stack_2, 0, 1);  stack_2 = None
        stack_3: &quot;f32[1, 1, 2, 256]&quot; = torch.ops.aten.stack.default([transpose_2], 1);  transpose_2 = None
        stack_4: &quot;f32[1, 1, 2, 256]&quot; = torch.ops.aten.stack.default([transpose_3], 1);  transpose_3 = None

        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:760 in forward, code: tensordict.update(tensordict_shaped.reshape(shape))
        reshape: &quot;f32[1, 32]&quot; = torch.ops.aten.reshape.default(unsqueeze_4, [1, 32]);  unsqueeze_4 = None
        reshape_1: &quot;f32[1, 2, 256]&quot; = torch.ops.aten.reshape.default(stack_3, [1, 2, 256]);  stack_3 = None
        reshape_2: &quot;f32[1, 2, 256]&quot; = torch.ops.aten.reshape.default(stack_4, [1, 2, 256]);  stack_4 = None
        reshape_3: &quot;b8[1]&quot; = torch.ops.aten.reshape.default(unsqueeze_7, [1]);  unsqueeze_7 = None
        reshape_4: &quot;f32[1, 256]&quot; = torch.ops.aten.reshape.default(stack, [1, 256]);  stack = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)
        linear_4: &quot;f32[1, 64]&quot; = torch.ops.aten.linear.default(reshape_4, p_module_2_module_0_weight, p_module_2_module_0_bias);  p_module_2_module_0_weight = p_module_2_module_0_bias = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:432 in forward, code: return torch.tanh(input)
        tanh_4: &quot;f32[1, 64]&quot; = torch.ops.aten.tanh.default(linear_4);  linear_4 = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)
        linear_5: &quot;f32[1, 64]&quot; = torch.ops.aten.linear.default(tanh_4, p_module_2_module_2_weight, p_module_2_module_2_bias);  tanh_4 = p_module_2_module_2_weight = p_module_2_module_2_bias = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:432 in forward, code: return torch.tanh(input)
        tanh_5: &quot;f32[1, 64]&quot; = torch.ops.aten.tanh.default(linear_5);  linear_5 = None

        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)
        linear_6: &quot;f32[1, 5]&quot; = torch.ops.aten.linear.default(tanh_5, p_module_2_module_4_weight, p_module_2_module_4_bias);  tanh_5 = p_module_2_module_4_weight = p_module_2_module_4_bias = None

        # File: /opt/conda/lib/python3.11/site-packages/tensordict/nn/sequence.py:642 in forward, code: tensordict_exec = self._run_module(
        squeeze_1: &quot;f32[32]&quot; = torch.ops.aten.squeeze.dim(reshape, 0);  reshape = squeeze_1 = None
        squeeze_2: &quot;f32[2, 256]&quot; = torch.ops.aten.squeeze.dim(reshape_1, 0);  reshape_1 = None
        squeeze_3: &quot;f32[2, 256]&quot; = torch.ops.aten.squeeze.dim(reshape_2, 0);  reshape_2 = None
        squeeze_4: &quot;b8[]&quot; = torch.ops.aten.squeeze.dim(reshape_3, 0);  reshape_3 = squeeze_4 = None
        squeeze_5: &quot;f32[256]&quot; = torch.ops.aten.squeeze.dim(reshape_4, 0);  reshape_4 = squeeze_5 = None
        squeeze_6: &quot;f32[5]&quot; = torch.ops.aten.squeeze.dim(linear_6, 0);  linear_6 = None
        return (squeeze_6, squeeze_2, squeeze_3)


&#39;class GraphModule(torch.nn.Module):\n    def forward(self, p_module_1_lstm_weight_ih_l0: &quot;f32[1024, 32]&quot;, p_module_1_lstm_weight_hh_l0: &quot;f32[1024, 256]&quot;, p_module_1_lstm_bias_ih_l0: &quot;f32[1024]&quot;, p_module_1_lstm_bias_hh_l0: &quot;f32[1024]&quot;, p_module_1_lstm_weight_ih_l1: &quot;f32[1024, 256]&quot;, p_module_1_lstm_weight_hh_l1: &quot;f32[1024, 256]&quot;, p_module_1_lstm_bias_ih_l1: &quot;f32[1024]&quot;, p_module_1_lstm_bias_hh_l1: &quot;f32[1024]&quot;, p_module_2_module_0_weight: &quot;f32[64, 256]&quot;, p_module_2_module_0_bias: &quot;f32[64]&quot;, p_module_2_module_2_weight: &quot;f32[64, 64]&quot;, p_module_2_module_2_bias: &quot;f32[64]&quot;, p_module_2_module_4_weight: &quot;f32[5, 64]&quot;, p_module_2_module_4_bias: &quot;f32[5]&quot;, observation: &quot;f32[32]&quot;, hidden0: &quot;f32[2, 256]&quot;, hidden1: &quot;f32[2, 256]&quot;, is_init: &quot;b8[]&quot;):\n        # File: /opt/conda/lib/python3.11/site-packages/tensordict/nn/sequence.py:642 in forward, code: tensordict_exec = self._run_module(\n        unsqueeze: &quot;f32[1, 32]&quot; = torch.ops.aten.unsqueeze.default(observation, 0);  observation = None\n        unsqueeze_1: &quot;f32[1, 2, 256]&quot; = torch.ops.aten.unsqueeze.default(hidden0, 0);  hidden0 = None\n        unsqueeze_2: &quot;f32[1, 2, 256]&quot; = torch.ops.aten.unsqueeze.default(hidden1, 0);  hidden1 = None\n        unsqueeze_3: &quot;b8[1]&quot; = torch.ops.aten.unsqueeze.default(is_init, 0);  is_init = None\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:705 in forward, code: tensordict_shaped = tensordict.reshape(-1).unsqueeze(-1)\n        unsqueeze_4: &quot;f32[1, 1, 32]&quot; = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n        unsqueeze_5: &quot;f32[1, 1, 2, 256]&quot; = torch.ops.aten.unsqueeze.default(unsqueeze_1, 1);  unsqueeze_1 = None\n        unsqueeze_6: &quot;f32[1, 1, 2, 256]&quot; = torch.ops.aten.unsqueeze.default(unsqueeze_2, 1);  unsqueeze_2 = None\n        unsqueeze_7: &quot;b8[1, 1]&quot; = torch.ops.aten.unsqueeze.default(unsqueeze_3, 1);  unsqueeze_3 = None\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:707 in forward, code: is_init = tensordict_shaped[&quot;is_init&quot;].squeeze(-1)\n        squeeze: &quot;b8[1]&quot; = torch.ops.aten.squeeze.dim(unsqueeze_7, -1)\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:738 in forward, code: is_init_expand = expand_as_right(is_init, hidden0)\n        unsqueeze_8: &quot;b8[1, 1]&quot; = torch.ops.aten.unsqueeze.default(squeeze, -1);  squeeze = None\n        unsqueeze_9: &quot;b8[1, 1, 1]&quot; = torch.ops.aten.unsqueeze.default(unsqueeze_8, -1);  unsqueeze_8 = None\n        unsqueeze_10: &quot;b8[1, 1, 1, 1]&quot; = torch.ops.aten.unsqueeze.default(unsqueeze_9, -1);  unsqueeze_9 = None\n        expand: &quot;b8[1, 1, 2, 256]&quot; = torch.ops.aten.expand.default(unsqueeze_10, [1, 1, 2, 256]);  unsqueeze_10 = None\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:739 in forward, code: zeros = torch.zeros_like(hidden0)\n        zeros_like: &quot;f32[1, 1, 2, 256]&quot; = torch.ops.aten.zeros_like.default(unsqueeze_5, pin_memory = False)\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:740 in forward, code: hidden0 = torch.where(is_init_expand, zeros, hidden0)\n        where: &quot;f32[1, 1, 2, 256]&quot; = torch.ops.aten.where.self(expand, zeros_like, unsqueeze_5);  unsqueeze_5 = None\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:741 in forward, code: hidden1 = torch.where(is_init_expand, zeros, hidden1)\n        where_1: &quot;f32[1, 1, 2, 256]&quot; = torch.ops.aten.where.self(expand, zeros_like, unsqueeze_6);  expand = zeros_like = unsqueeze_6 = None\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:747 in forward, code: val, hidden0, hidden1 = self._lstm(\n        select: &quot;f32[1, 2, 256]&quot; = torch.ops.aten.select.int(where, 1, 0);  where = None\n        select_1: &quot;f32[1, 2, 256]&quot; = torch.ops.aten.select.int(where_1, 1, 0);  where_1 = None\n        transpose: &quot;f32[2, 1, 256]&quot; = torch.ops.aten.transpose.int(select, -3, -2);  select = None\n        transpose_1: &quot;f32[2, 1, 256]&quot; = torch.ops.aten.transpose.int(select_1, -3, -2);  select_1 = None\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:308 in forward, code: return self._lstm(input, hx)\n        unbind = torch.ops.aten.unbind.int(transpose);  transpose = None\n        getitem: &quot;f32[1, 256]&quot; = unbind[0]\n        getitem_1: &quot;f32[1, 256]&quot; = unbind[1];  unbind = None\n        unbind_1 = torch.ops.aten.unbind.int(transpose_1);  transpose_1 = None\n        getitem_2: &quot;f32[1, 256]&quot; = unbind_1[0]\n        getitem_3: &quot;f32[1, 256]&quot; = unbind_1[1];  unbind_1 = None\n        unbind_2 = torch.ops.aten.unbind.int(unsqueeze_4, 1)\n        getitem_4: &quot;f32[1, 32]&quot; = unbind_2[0];  unbind_2 = None\n        linear: &quot;f32[1, 1024]&quot; = torch.ops.aten.linear.default(getitem_4, p_module_1_lstm_weight_ih_l0, p_module_1_lstm_bias_ih_l0);  getitem_4 = p_module_1_lstm_weight_ih_l0 = p_module_1_lstm_bias_ih_l0 = None\n        linear_1: &quot;f32[1, 1024]&quot; = torch.ops.aten.linear.default(getitem, p_module_1_lstm_weight_hh_l0, p_module_1_lstm_bias_hh_l0);  getitem = p_module_1_lstm_weight_hh_l0 = p_module_1_lstm_bias_hh_l0 = None\n        add: &quot;f32[1, 1024]&quot; = torch.ops.aten.add.Tensor(linear, linear_1);  linear = linear_1 = None\n        chunk = torch.ops.aten.chunk.default(add, 4, 1);  add = None\n        getitem_5: &quot;f32[1, 256]&quot; = chunk[0]\n        getitem_6: &quot;f32[1, 256]&quot; = chunk[1]\n        getitem_7: &quot;f32[1, 256]&quot; = chunk[2]\n        getitem_8: &quot;f32[1, 256]&quot; = chunk[3];  chunk = None\n        sigmoid: &quot;f32[1, 256]&quot; = torch.ops.aten.sigmoid.default(getitem_5);  getitem_5 = None\n        sigmoid_1: &quot;f32[1, 256]&quot; = torch.ops.aten.sigmoid.default(getitem_6);  getitem_6 = None\n        tanh: &quot;f32[1, 256]&quot; = torch.ops.aten.tanh.default(getitem_7);  getitem_7 = None\n        sigmoid_2: &quot;f32[1, 256]&quot; = torch.ops.aten.sigmoid.default(getitem_8);  getitem_8 = None\n        mul: &quot;f32[1, 256]&quot; = torch.ops.aten.mul.Tensor(getitem_2, sigmoid_1);  getitem_2 = sigmoid_1 = None\n        mul_1: &quot;f32[1, 256]&quot; = torch.ops.aten.mul.Tensor(sigmoid, tanh);  sigmoid = tanh = None\n        add_1: &quot;f32[1, 256]&quot; = torch.ops.aten.add.Tensor(mul, mul_1);  mul = mul_1 = None\n        tanh_1: &quot;f32[1, 256]&quot; = torch.ops.aten.tanh.default(add_1)\n        mul_2: &quot;f32[1, 256]&quot; = torch.ops.aten.mul.Tensor(sigmoid_2, tanh_1);  sigmoid_2 = tanh_1 = None\n        linear_2: &quot;f32[1, 1024]&quot; = torch.ops.aten.linear.default(mul_2, p_module_1_lstm_weight_ih_l1, p_module_1_lstm_bias_ih_l1);  p_module_1_lstm_weight_ih_l1 = p_module_1_lstm_bias_ih_l1 = None\n        linear_3: &quot;f32[1, 1024]&quot; = torch.ops.aten.linear.default(getitem_1, p_module_1_lstm_weight_hh_l1, p_module_1_lstm_bias_hh_l1);  getitem_1 = p_module_1_lstm_weight_hh_l1 = p_module_1_lstm_bias_hh_l1 = None\n        add_2: &quot;f32[1, 1024]&quot; = torch.ops.aten.add.Tensor(linear_2, linear_3);  linear_2 = linear_3 = None\n        chunk_1 = torch.ops.aten.chunk.default(add_2, 4, 1);  add_2 = None\n        getitem_9: &quot;f32[1, 256]&quot; = chunk_1[0]\n        getitem_10: &quot;f32[1, 256]&quot; = chunk_1[1]\n        getitem_11: &quot;f32[1, 256]&quot; = chunk_1[2]\n        getitem_12: &quot;f32[1, 256]&quot; = chunk_1[3];  chunk_1 = None\n        sigmoid_3: &quot;f32[1, 256]&quot; = torch.ops.aten.sigmoid.default(getitem_9);  getitem_9 = None\n        sigmoid_4: &quot;f32[1, 256]&quot; = torch.ops.aten.sigmoid.default(getitem_10);  getitem_10 = None\n        tanh_2: &quot;f32[1, 256]&quot; = torch.ops.aten.tanh.default(getitem_11);  getitem_11 = None\n        sigmoid_5: &quot;f32[1, 256]&quot; = torch.ops.aten.sigmoid.default(getitem_12);  getitem_12 = None\n        mul_3: &quot;f32[1, 256]&quot; = torch.ops.aten.mul.Tensor(getitem_3, sigmoid_4);  getitem_3 = sigmoid_4 = None\n        mul_4: &quot;f32[1, 256]&quot; = torch.ops.aten.mul.Tensor(sigmoid_3, tanh_2);  sigmoid_3 = tanh_2 = None\n        add_3: &quot;f32[1, 256]&quot; = torch.ops.aten.add.Tensor(mul_3, mul_4);  mul_3 = mul_4 = None\n        tanh_3: &quot;f32[1, 256]&quot; = torch.ops.aten.tanh.default(add_3)\n        mul_5: &quot;f32[1, 256]&quot; = torch.ops.aten.mul.Tensor(sigmoid_5, tanh_3);  sigmoid_5 = tanh_3 = None\n        stack: &quot;f32[1, 1, 256]&quot; = torch.ops.aten.stack.default([mul_5], 1)\n        stack_1: &quot;f32[2, 1, 256]&quot; = torch.ops.aten.stack.default([mul_2, mul_5]);  mul_2 = mul_5 = None\n        stack_2: &quot;f32[2, 1, 256]&quot; = torch.ops.aten.stack.default([add_1, add_3]);  add_1 = add_3 = None\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:747 in forward, code: val, hidden0, hidden1 = self._lstm(\n        transpose_2: &quot;f32[1, 2, 256]&quot; = torch.ops.aten.transpose.int(stack_1, 0, 1);  stack_1 = None\n        transpose_3: &quot;f32[1, 2, 256]&quot; = torch.ops.aten.transpose.int(stack_2, 0, 1);  stack_2 = None\n        stack_3: &quot;f32[1, 1, 2, 256]&quot; = torch.ops.aten.stack.default([transpose_2], 1);  transpose_2 = None\n        stack_4: &quot;f32[1, 1, 2, 256]&quot; = torch.ops.aten.stack.default([transpose_3], 1);  transpose_3 = None\n\n        # File: /pytorch/rl/torchrl/modules/tensordict_module/rnn.py:760 in forward, code: tensordict.update(tensordict_shaped.reshape(shape))\n        reshape: &quot;f32[1, 32]&quot; = torch.ops.aten.reshape.default(unsqueeze_4, [1, 32]);  unsqueeze_4 = None\n        reshape_1: &quot;f32[1, 2, 256]&quot; = torch.ops.aten.reshape.default(stack_3, [1, 2, 256]);  stack_3 = None\n        reshape_2: &quot;f32[1, 2, 256]&quot; = torch.ops.aten.reshape.default(stack_4, [1, 2, 256]);  stack_4 = None\n        reshape_3: &quot;b8[1]&quot; = torch.ops.aten.reshape.default(unsqueeze_7, [1]);  unsqueeze_7 = None\n        reshape_4: &quot;f32[1, 256]&quot; = torch.ops.aten.reshape.default(stack, [1, 256]);  stack = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n        linear_4: &quot;f32[1, 64]&quot; = torch.ops.aten.linear.default(reshape_4, p_module_2_module_0_weight, p_module_2_module_0_bias);  p_module_2_module_0_weight = p_module_2_module_0_bias = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:432 in forward, code: return torch.tanh(input)\n        tanh_4: &quot;f32[1, 64]&quot; = torch.ops.aten.tanh.default(linear_4);  linear_4 = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n        linear_5: &quot;f32[1, 64]&quot; = torch.ops.aten.linear.default(tanh_4, p_module_2_module_2_weight, p_module_2_module_2_bias);  tanh_4 = p_module_2_module_2_weight = p_module_2_module_2_bias = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:432 in forward, code: return torch.tanh(input)\n        tanh_5: &quot;f32[1, 64]&quot; = torch.ops.aten.tanh.default(linear_5);  linear_5 = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n        linear_6: &quot;f32[1, 5]&quot; = torch.ops.aten.linear.default(tanh_5, p_module_2_module_4_weight, p_module_2_module_4_bias);  tanh_5 = p_module_2_module_4_weight = p_module_2_module_4_bias = None\n\n        # File: /opt/conda/lib/python3.11/site-packages/tensordict/nn/sequence.py:642 in forward, code: tensordict_exec = self._run_module(\n        squeeze_1: &quot;f32[32]&quot; = torch.ops.aten.squeeze.dim(reshape, 0);  reshape = squeeze_1 = None\n        squeeze_2: &quot;f32[2, 256]&quot; = torch.ops.aten.squeeze.dim(reshape_1, 0);  reshape_1 = None\n        squeeze_3: &quot;f32[2, 256]&quot; = torch.ops.aten.squeeze.dim(reshape_2, 0);  reshape_2 = None\n        squeeze_4: &quot;b8[]&quot; = torch.ops.aten.squeeze.dim(reshape_3, 0);  reshape_3 = squeeze_4 = None\n        squeeze_5: &quot;f32[256]&quot; = torch.ops.aten.squeeze.dim(reshape_4, 0);  reshape_4 = squeeze_5 = None\n        squeeze_6: &quot;f32[5]&quot; = torch.ops.aten.squeeze.dim(linear_6, 0);  linear_6 = None\n        return (squeeze_6, squeeze_2, squeeze_3)\n&#39;
</pre></div>
</div>
</section>
<section id="aotinductor-export-your-policy-to-pytorch-free-c-binaries">
<h2>AOTInductor: Export your policy to pytorch-free C++ binaries<a class="headerlink" href="#aotinductor-export-your-policy-to-pytorch-free-c-binaries" title="Link to this heading">¶</a></h2>
<p>AOTInductor is a PyTorch module that allows you to export your model (policy or other) to pytorch-free C++ binaries.
This is particularly useful when you need to deploy your model on devices or platforms where PyTorch is not available.</p>
<p>Here’s an example of how you can use AOTInductor to export your policy, inspired by the
<a class="reference external" href="https://pytorch.org/docs/main/torch.compiler_aot_inductor.html">AOTI documentation</a>:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tempfile</span> <span class="kn">import</span> <span class="n">TemporaryDirectory</span>

<span class="kn">from</span> <span class="nn">torch._inductor</span> <span class="kn">import</span> <a href="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/torch.compiler_aot_inductor.html#torch._inductor.aoti_compile_and_package" title="torch._inductor.aoti_compile_and_package" class="sphx-glr-backref-module-torch-_inductor sphx-glr-backref-type-py-function"><span class="n">aoti_compile_and_package</span></a><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/torch.compiler_aot_inductor.html#torch._inductor.aoti_load_package" title="torch._inductor.aoti_load_package" class="sphx-glr-backref-module-torch-_inductor sphx-glr-backref-type-py-function"><span class="n">aoti_load_package</span></a>

<span class="k">with</span> <span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdir</span><span class="p">:</span>
    <span class="n">path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;model.pt2&quot;</span><span class="p">)</span>
    <span class="k">with</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">():</span>
        <span class="n">pkg_path</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/torch.compiler_aot_inductor.html#torch._inductor.aoti_compile_and_package" title="torch._inductor.aoti_compile_and_package" class="sphx-glr-backref-module-torch-_inductor sphx-glr-backref-type-py-function"><span class="n">aoti_compile_and_package</span></a><span class="p">(</span>
            <a href="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/export/api_reference.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">exported_policy</span></a><span class="p">,</span>
            <span class="c1"># Specify the generated shared library path</span>
            <span class="n">package_path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pkg_path&quot;</span><span class="p">,</span> <span class="n">pkg_path</span><span class="p">)</span>

    <span class="n">compiled_module</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/torch.compiler_aot_inductor.html#torch._inductor.aoti_load_package" title="torch._inductor.aoti_load_package" class="sphx-glr-backref-module-torch-_inductor sphx-glr-backref-type-py-function"><span class="n">aoti_load_package</span></a><span class="p">(</span><span class="n">pkg_path</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">compiled_module</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pixels</span></a><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pixels</span></a><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>pkg_path /tmp/tmptdeuvvnn/model.pt2
tensor(1)
</pre></div>
</div>
</section>
<section id="exporting-torchrl-models-with-onnx">
<h2>Exporting TorchRL models with ONNX<a class="headerlink" href="#exporting-torchrl-models-with-onnx" title="Link to this heading">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To execute this part of the script, make sure pytorch onnx is installed:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!pip install onnx-pytorch
!pip install onnxruntime
</pre></div>
</div>
</div>
<p>You can also find more information about using ONNX in the PyTorch ecosystem
<a class="reference external" href="https://pytorch.org/tutorials/beginner/onnx/intro_onnx.html">here</a>. The following example is based on this
documentation.</p>
<p>In this section, we are going to showcase how we can export our model in such a way that it can be
executed on a pytorch-free setting.</p>
<p>There are plenty of resources on the web explaining how ONNX can be used to deploy PyTorch models on various
hardwares and devices, including <a class="reference external" href="https://qengineering.eu/install-pytorch-on-raspberry-pi-4.html">Raspberry Pi</a>,
<a class="reference external" href="https://docs.nvidia.com/deeplearning/tensorrt/quick-start-guide/index.html">NVIDIA TensorRT</a>,
<a class="reference external" href="https://apple.github.io/coremltools/docs-guides/source/convert-pytorch.html">iOS</a> and
<a class="reference external" href="https://onnxruntime.ai/docs/tutorials/mobile/">Android</a>.</p>
<p>The Atari game we trained on can be isolated without TorchRL or gymnasium with the
<a class="reference external" href="https://github.com/Farama-Foundation/Arcade-Learning-Environment">ALE library</a> and therefore provides us with
a good example of what we can achieve with ONNX.</p>
<p>Let us see what this API looks like:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ale_py</span> <span class="kn">import</span> <span class="n">ALEInterface</span><span class="p">,</span> <span class="n">roms</span>

<span class="c1"># Create the interface</span>
<span class="n">ale</span> <span class="o">=</span> <span class="n">ALEInterface</span><span class="p">()</span>
<span class="c1"># Load the pong environment</span>
<span class="n">ale</span><span class="o">.</span><span class="n">loadROM</span><span class="p">(</span><span class="n">roms</span><span class="o">.</span><span class="n">get_rom_path</span><span class="p">(</span><span class="s2">&quot;pong&quot;</span><span class="p">))</span>
<span class="n">ale</span><span class="o">.</span><span class="n">reset_game</span><span class="p">()</span>

<span class="c1"># Make a step in the simulator</span>
<span class="n">action</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">reward</span> <span class="o">=</span> <span class="n">ale</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
<span class="n">screen_obs</span> <span class="o">=</span> <span class="n">ale</span><span class="o">.</span><span class="n">getScreenRGB</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Observation from ALE simulator:&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">screen_obs</span><span class="p">),</span> <span class="n">screen_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">labelleft</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">labelbottom</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">screen_obs</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Screen rendering of Pong game.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_export_001.png" srcset="../_images/sphx_glr_export_001.png" alt="Screen rendering of Pong game." class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Observation from ALE simulator: &lt;class &#39;numpy.ndarray&#39;&gt; (210, 160, 3)

Text(0.5, 1.0, &#39;Screen rendering of Pong game.&#39;)
</pre></div>
</div>
<p>Exporting to ONNX is quite similar the Export/AOTI above:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">onnxruntime</span>

<span class="k">with</span> <span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdir</span><span class="p">:</span>
    <span class="n">onnx_file_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;policy.onnx&quot;</span><span class="p">)</span>

    <span class="k">with</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.set_interaction_type.html#tensordict.nn.set_interaction_type" title="tensordict.nn.set_interaction_type" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">set_exploration_type</span></a><span class="p">(</span><span class="s2">&quot;DETERMINISTIC&quot;</span><span class="p">):</span>
        <span class="c1"># We use torch.onnx.export with dynamo=True to capture the computation graph</span>
        <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pixels</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.as_tensor.html#torch.as_tensor" title="torch.as_tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span></a><span class="p">(</span><span class="n">screen_obs</span><span class="p">)</span>
        <a href="https://docs.pytorch.org/docs/stable/onnx_export.html#torch.onnx.export" title="torch.onnx.export" class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span></a><span class="p">(</span>
            <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">policy_transform</span></a><span class="p">,</span>
            <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;pixels&quot;</span><span class="p">:</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pixels</span></a><span class="p">},</span>
            <span class="n">f</span><span class="o">=</span><span class="n">onnx_file_path</span><span class="p">,</span>
            <span class="n">dynamo</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1">#####################################</span>
    <span class="c1"># We can now load the model and run it with ONNX Runtime:</span>

    <span class="n">ort_session</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span>
        <span class="n">onnx_file_path</span><span class="p">,</span> <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;CPUExecutionProvider&quot;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="n">onnxruntime_input</span> <span class="o">=</span> <span class="p">{</span><span class="n">ort_session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">screen_obs</span><span class="p">}</span>
    <span class="n">onnx_result</span> <span class="o">=</span> <span class="n">ort_session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">onnxruntime_input</span><span class="p">)</span>

    <span class="c1">#####################################</span>
    <span class="c1"># Running a rollout with ONNX</span>
    <span class="c1"># ~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
    <span class="c1">#</span>
    <span class="c1"># We now have an ONNX model that runs our policy. Let&#39;s compare it to the original TorchRL instance: because it is</span>
    <span class="c1"># more lightweight, the ONNX version should be faster than the TorchRL one.</span>

    <span class="k">def</span> <span class="nf">onnx_policy</span><span class="p">(</span><span class="n">screen_obs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="n">onnxruntime_input</span> <span class="o">=</span> <span class="p">{</span><span class="n">ort_session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">screen_obs</span><span class="p">}</span>
        <span class="n">onnxruntime_outputs</span> <span class="o">=</span> <span class="n">ort_session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">onnxruntime_input</span><span class="p">)</span>
        <span class="n">action</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">onnxruntime_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">action</span>

    <span class="k">with</span> <span class="n">timeit</span><span class="p">(</span><span class="s2">&quot;ONNX rollout&quot;</span><span class="p">):</span>
        <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">1000</span>
        <span class="n">ale</span><span class="o">.</span><span class="n">reset_game</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
            <span class="n">screen_obs</span> <span class="o">=</span> <span class="n">ale</span><span class="o">.</span><span class="n">getScreenRGB</span><span class="p">()</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">onnx_policy</span><span class="p">(</span><span class="n">screen_obs</span><span class="p">)</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="n">ale</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">timeit</span><span class="p">(</span><span class="s2">&quot;TorchRL version&quot;</span><span class="p">),</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">(),</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.set_interaction_type.html#tensordict.nn.set_interaction_type" title="tensordict.nn.set_interaction_type" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">set_exploration_type</span></a><span class="p">(</span>
        <span class="s2">&quot;DETERMINISTIC&quot;</span>
    <span class="p">):</span>
        <span class="n">env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">num_steps</span><span class="p">,</span> <a href="https://docs.pytorch.org/tensordict/stable/reference/generated/tensordict.nn.TensorDictSequential.html#tensordict.nn.TensorDictSequential" title="tensordict.nn.TensorDictSequential" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">policy_explore</span></a><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">timeit</span><span class="o">.</span><span class="n">print</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[torch.onnx] Obtain model graph for `TensorDictSequential([...]` with `torch.export.export(..., strict=False)`...
[torch.onnx] Obtain model graph for `TensorDictSequential([...]` with `torch.export.export(..., strict=False)`... ✅
[torch.onnx] Run decompositions...
[torch.onnx] Run decompositions... ✅
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... ✅
[torch.onnx] Optimize the ONNX graph...
[torch.onnx] Optimize the ONNX graph... ✅
ONNX rollout took 650.7552 msec (total =  0.6508 sec since last reset).
TorchRL version took 1958.9174 msec (total =  1.9589 sec since last reset).
</pre></div>
</div>
<p>Note that ONNX also offers the possibility of optimizing models directly, but this is beyond the scope of this
tutorial.</p>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">¶</a></h2>
<p>In this tutorial, we learned how to export TorchRL modules using various backends such as PyTorch’s built-in export
functionality, <code class="docutils literal notranslate"><span class="pre">AOTInductor</span></code>, and <code class="docutils literal notranslate"><span class="pre">ONNX</span></code>.
We demonstrated how to export a policy trained on an Atari game and run it on a pytorch-free setting using the <code class="docutils literal notranslate"><span class="pre">ALE</span></code>
library. We also compared the performance of the original TorchRL instance with the exported ONNX model.</p>
<p>Key takeaways:</p>
<ul class="simple">
<li><p>Exporting TorchRL modules allows for deployment on devices without PyTorch installed.</p></li>
<li><p>AOTInductor and ONNX provide alternative backends for exporting models.</p></li>
<li><p>Optimizing ONNX models can improve performance.</p></li>
</ul>
<p>Further reading and learning steps:</p>
<ul class="simple">
<li><p>Check out the official documentation for PyTorch’s <a class="reference external" href="https://pytorch.org/docs/stable/export.html">export functionality</a>,
<a class="reference external" href="https://pytorch.org/tutorials/recipes/torch_export_aoti_python.html">AOTInductor</a>, and
<a class="reference external" href="https://pytorch.org/tutorials/beginner/onnx/intro_onnx.html">ONNX</a> for more
information.</p></li>
<li><p>Experiment with deploying exported models on different devices.</p></li>
<li><p>Explore optimization techniques for ONNX models to improve performance.</p></li>
</ul>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 21.583 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorials-export-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/4e8ac58ef63f1e596d49d1b7366ef9bc/export.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">export.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/bbb4a09f4b0d139b93b8e77c84568b01/export.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">export.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/150528e38f6816824f1e81ed67476a9f/export.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">export.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="multiagent_competitive_ddpg.html" class="btn btn-neutral float-right" title="Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="rb_tutorial.html" class="btn btn-neutral" title="Using Replay Buffers" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Exporting TorchRL modules</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#fast-recap-a-simple-torchrl-training-loop">Fast recap: a simple TorchRL training loop</a></li>
<li><a class="reference internal" href="#exporting-a-tensordictmodule-based-policy">Exporting a TensorDictModule-based policy</a></li>
<li><a class="reference internal" href="#working-with-stochastic-policies">Working with stochastic policies</a></li>
<li><a class="reference internal" href="#working-with-recurrent-policies">Working with recurrent policies</a></li>
<li><a class="reference internal" href="#aotinductor-export-your-policy-to-pytorch-free-c-binaries">AOTInductor: Export your policy to pytorch-free C++ binaries</a></li>
<li><a class="reference internal" href="#exporting-torchrl-models-with-onnx">Exporting TorchRL models with ONNX</a></li>
<li><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>
  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'main',
            LANGUAGE:'en',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="../_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="../_static/design-tabs.js"></script>

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrl = $("#tutorial-type").text();
	      var githubLink = "https://github.com/pytorch/rl/blob/main/tutorials/sphinx-"  + tutorialUrl + ".py",
		  notebookLink = $(".sphx-glr-download-jupyter").find(".download.reference")[0].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/rl/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }

          var overwrite = function(_) {
              if ($(this).length > 0) {
                  $(this)[0].href = "https://github.com/pytorch/rl"
              }
          }
          // PC
          $(".main-menu a:contains('GitHub')").each(overwrite);
          // Mobile
          $(".main-menu a:contains('Github')").each(overwrite);
      });

      
       $(window).ready(function() {
           var original = window.sideMenus.bind;
           var startup = true;
           window.sideMenus.bind = function() {
               original();
               if (startup) {
                   $("#pytorch-right-menu a.reference.internal").each(function(i) {
                       if (this.classList.contains("not-expanded")) {
                           this.nextElementSibling.style.display = "block";
                           this.classList.remove("not-expanded");
                           this.classList.add("expanded");
                       }
                   });
                   startup = false;
               }
           };
       });
    </script>

    


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://shiftlab.github.io/pytorch/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://shiftlab.github.io/pytorch/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://shiftlab.github.io/pytorch/">PyTorch</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/get-started">Get Started</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/features">Features</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/ecosystem">Ecosystem</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/blog/">Blog</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://shiftlab.github.io/pytorch/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://shiftlab.github.io/pytorch/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    mobileMenu.bind();
    mobileTOC.bind();
    pytorchAnchors.bind();

    $(window).on("load", function() {
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
    })

    // Add class to links that have code blocks, since we cannot create links in code blocks
    $("article.pytorch-article a span.pre").each(function(e) {
      $(this).closest("a").addClass("has-code");
    });
  </script>
</body>
</html>
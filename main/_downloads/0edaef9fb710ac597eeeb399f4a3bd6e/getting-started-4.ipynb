{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Get started with logging\n\n**Author**: [Vincent Moens](https://github.com/vmoens)\n\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>To run this tutorial in a notebook, add an installation cell\n  at the beginning containing:\n\n```\n!pip install tensordict\n!pip install torchrl</p></div>\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The final chapter of this series before we orchestrate everything in a\ntraining script is to learn about logging.\n\n## Loggers\n\nLogging is crucial for reporting your results to the outside world and for\nyou to check that your algorithm is learning properly. TorchRL has several\nloggers that interface with custom backends such as\nwandb (:class:`~torchrl.record.loggers.wandb.WandbLogger`),\ntensorboard (:class:`~torchrl.record.loggers.tensorboard.TensorBoardLogger`) or a lightweight and\nportable CSV logger (:class:`~torchrl.record.loggers.csv.CSVLogger`) that you can use\npretty much everywhere.\n\nLoggers are located in the ``torchrl.record`` module and the various classes\ncan be found in the `API reference <ref_loggers>`.\n\nWe tried to keep the loggers APIs as similar as we could, given the\ndifferences in the underlying backends. While execution of the loggers will\nmostly be interchangeable, their instantiation can differ.\n\nUsually, building a logger requires\nat least an experiment name and possibly a logging directory and other\nhyperparameters.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchrl.record import CSVLogger\n\nlogger = CSVLogger(exp_name=\"my_exp\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the logger is instantiated, the only thing left to do is call the\nlogging methods! For example, :meth:`~torchrl.record.CSVLogger.log_scalar`\nis used in several places across the training examples to log values such as\nreward, loss value or time elapsed for executing a piece of code.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "logger.log_scalar(\"my_scalar\", 0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recording videos\n\nFinally, it can come in handy to record videos of a simulator. Some\nenvironments (e.g., Atari games) are already rendered as images whereas\nothers require you to create them as such. Fortunately, in most common cases,\nrendering and recording videos isn't too difficult.\n\nLet's first see how we can create a Gym environment that outputs images\nalongside its observations. :class:`~torchrl.envs.GymEnv` accept two keywords\nfor this purpose:\n- ``from_pixels=True`` will make the env ``step`` function\nwrite a ``\"pixels\"`` entry containing the images corresponding to your\nobservations, and\n\n- ``pixels_only=False`` will indicate that you want the\nobservations to be returned as well.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchrl.envs import GymEnv\n\nenv = GymEnv(\"CartPole-v1\", from_pixels=True, pixels_only=False)\n\nprint(env.rollout(max_steps=3))\n\nfrom torchrl.envs import TransformedEnv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now have built an environment that renders images with its observations.\nTo record videos, we will need to combine that environment with a recorder\nand the logger (the logger providing the backend to save the video).\nThis will happen within a transformed environment, like the one we saw in\nthe `first tutorial <gs_env_ted>`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchrl.record import VideoRecorder\n\nrecorder = VideoRecorder(logger, tag=\"my_video\")\nrecord_env = TransformedEnv(env, recorder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When running this environment, all the ``\"pixels\"`` entries will be saved in\na local buffer (i.e. RAM) and dumped in a video on demand (to prevent excessive\nRAM usage, you are advised to call this method whenever appropriate!):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rollout = record_env.rollout(max_steps=3)\n# Uncomment this line to save the video on disk:\n# recorder.dump()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this specific case, the video format can be chosen when instantiating\nthe CSVLogger.\n\n(If you want to customise how your video is recorded, have a look at `our knowledge base <ref_knowledge_base>`.)\n\nThis is all we wanted to cover in the getting started tutorial.\nYou should now be ready to code your\n`first training loop with TorchRL <gs_first_training>`!\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}



<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchrl.modules.llm.policies.vllm_wrapper &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','UA-117752657-2');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="../../../../../../versions.html"><span style="font-size:110%">main (0.0.0+unknown) &#x25BC</span></a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/getting-started-0.html">Get started with Environments, TED and transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/getting-started-1.html">Get started with TorchRL’s modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/getting-started-2.html">Getting started with model optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/getting-started-3.html">Get started with data collection and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/getting-started-4.html">Get started with logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/getting-started-5.html">Get started with your own first training loop</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/coding_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/torchrl_demo.html">Introduction to TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/multiagent_ppo.html">Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/torchrl_envs.html">TorchRL envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/pretrained_models.html">Using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/dqn_with_rnn.html">Recurrent DQN: Training recurrent policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/rb_tutorial.html">Using Replay Buffers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/export.html">Exporting TorchRL modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/llm_browser.html">TorchRL LLM: Building Tool-Enabled Environments</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/multiagent_competitive_ddpg.html">Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/coding_ddpg.html">TorchRL objectives: Coding a DDPG loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/coding_dqn.html">TorchRL trainer: A DQN example</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../reference/index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../reference/knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../../index.html">Module code</a> &gt;</li>
        
      <li>torchrl.modules.llm.policies.vllm_wrapper</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
    
    
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=UA-117752657-2"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torchrl.modules.llm.policies.vllm_wrapper</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">collections</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">threading</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Literal</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">lazy_stack</span><span class="p">,</span>
    <span class="n">LazyStackedTensorDict</span><span class="p">,</span>
    <span class="n">MetaData</span><span class="p">,</span>
    <span class="n">NonTensorStack</span><span class="p">,</span>
    <span class="n">set_list_to_stack</span><span class="p">,</span>
    <span class="n">TensorDict</span><span class="p">,</span>
    <span class="n">TensorDictBase</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.tensorclass</span><span class="w"> </span><span class="kn">import</span> <span class="n">from_dataclass</span><span class="p">,</span> <span class="n">TensorClass</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_zip_strict</span><span class="p">,</span> <span class="n">NestedKey</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">distributions</span> <span class="k">as</span> <span class="n">D</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn.utils.rnn</span><span class="w"> </span><span class="kn">import</span> <span class="n">pad_sequence</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_classproperty</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.modules.llm.backends.vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">AsyncVLLM</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.modules.llm.policies.common</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_batching</span><span class="p">,</span>
    <span class="n">_extract_responses_from_full_histories</span><span class="p">,</span>
    <span class="n">ChatHistory</span><span class="p">,</span>
    <span class="n">LLMWrapperBase</span><span class="p">,</span>
    <span class="n">LogProbs</span><span class="p">,</span>
    <span class="n">Masks</span><span class="p">,</span>
    <span class="n">Text</span><span class="p">,</span>
    <span class="n">Tokens</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.modules.utils.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_unpad_tensors</span>

<span class="c1"># Type imports</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">transformers</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">vllm</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">vllm.outputs</span><span class="w"> </span><span class="kn">import</span> <span class="n">RequestOutput</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">vllm.sampling_params</span><span class="w"> </span><span class="kn">import</span> <span class="n">SamplingParams</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">vllm</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">transformers</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">SamplingParams</span> <span class="o">=</span> <span class="n">Any</span>  <span class="c1"># type: ignore</span>
    <span class="n">RequestOutput</span> <span class="o">=</span> <span class="n">Any</span>  <span class="c1"># type: ignore</span>

<span class="c1"># Import async vLLM engines</span>


<div class="viewcode-block" id="vLLMWrapper"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.vLLMWrapper.html#torchrl.modules.llm.vLLMWrapper">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">vLLMWrapper</span><span class="p">(</span><span class="n">LLMWrapperBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A wrapper class for vLLM models, providing a consistent interface for text generation and log probability computation.</span>

<span class="sd">    This class is a subclass of :class:`~torchrl.modules.llm.policies.LLMWrapperBase` and provides a unified API for handling different input</span>
<span class="sd">    modalities (history, text, tokens) with consistent output structure using :class:`~tensordict.TensorClass` objects.</span>

<span class="sd">    The wrapper supports both synchronous (vllm.LLM) and asynchronous (:class:`~torchrl.modules.llm.backends.AsyncVLLM`) vLLM engines.</span>

<span class="sd">    .. note::</span>
<span class="sd">        **Recommended: Use AsyncVLLM for better performance**</span>

<span class="sd">        For distributed inference and better resource utilization, we recommend using</span>
<span class="sd">        :class:`~torchrl.modules.llm.backends.AsyncVLLM` instead of the synchronous vllm.LLM:</span>

<span class="sd">        &gt;&gt;&gt; from torchrl.modules.llm.backends import AsyncVLLM</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules.llm import vLLMWrapper</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Recommended approach</span>
<span class="sd">        &gt;&gt;&gt; async_engine = AsyncVLLM.from_pretrained(&quot;Qwen/Qwen2.5-3B&quot;, num_replicas=2)</span>
<span class="sd">        &gt;&gt;&gt; wrapper = vLLMWrapper(async_engine, input_mode=&quot;history&quot;, generate=True)</span>

<span class="sd">        AsyncVLLM provides:</span>
<span class="sd">        - Better GPU utilization through Ray-based distribution</span>
<span class="sd">        - Multiple replicas for higher throughput</span>
<span class="sd">        - Native vLLM batching for optimal performance</span>
<span class="sd">        - Automatic resource management and cleanup</span>

<span class="sd">    Args:</span>
<span class="sd">        model (vllm.LLM | AsyncVLLM | Ray Actor | str): The vLLM model to wrap.</span>
<span class="sd">            - If a string, it will be converted to an AsyncVLLM instance (recommended)</span>
<span class="sd">            - If a vllm.LLM instance, uses synchronous generation via `model.generate()`</span>
<span class="sd">            - If an AsyncVLLM instance, uses async generation via `model.generate()`</span>
<span class="sd">            - If a Ray actor with generate method, uses remote calls via `ray.get(model.generate.remote())`</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        tokenizer (transformers.tokenization_utils.PreTrainedTokenizer | str | None, optional): The tokenizer to use for encoding and decoding text.</span>
<span class="sd">            If `None`, the tokenizer associated with the model will be used. If a string, it will be passed to `transformers.AutoTokenizer.from_pretrained`.</span>
<span class="sd">            Defaults to `None`.</span>
<span class="sd">        input_mode (str, optional): The input modality to use. Must be one of `&quot;history&quot;`, `&quot;text&quot;`, or `&quot;tokens&quot;`. Defaults to `&quot;history&quot;`.</span>
<span class="sd">        input_key (str | None, optional): The key for the input data. If `None`, defaults to</span>
<span class="sd">            - `(&quot;history&quot;, &quot;prompt&quot;)` for `&quot;history&quot;` when `generate=True`, `(&quot;history&quot;, &quot;full&quot;)` for `&quot;history&quot;` when `generate=False`</span>
<span class="sd">            - `(&quot;text&quot;, &quot;prompt&quot;)` for `&quot;text&quot;` when `generate=True`, `(&quot;text&quot;, &quot;full&quot;)` for `&quot;text&quot;` when `generate=False`</span>
<span class="sd">            - `(&quot;tokens&quot;, &quot;prompt&quot;)` for `&quot;tokens&quot;` when `generate=True`, `(&quot;tokens&quot;, &quot;full&quot;)` for `&quot;tokens&quot;` when `generate=False`</span>
<span class="sd">        attention_mask_key (str, optional): The key for attention masks (used in `&quot;tokens&quot;` mode). Defaults to `&quot;attention_mask&quot;`.</span>

<span class="sd">                    .. warning:: This argument is under development and may change in the future.</span>

<span class="sd">        generate (bool, optional): Whether to enable text generation. If `True`, the model will generate text based on the input.</span>
<span class="sd">            If `False`, only log probabilities will be computed. Defaults to `True`.</span>
<span class="sd">        return_log_probs (bool, optional): Whether to return log probabilities. Defaults to `True`.</span>
<span class="sd">        generate_kwargs (dict | None, optional): Additional arguments to pass to the model&#39;s generate method. Defaults to `None`.</span>

<span class="sd">            **Standardized Parameters (cross-backend compatible):**</span>

<span class="sd">            * **max_new_tokens** (int): Maximum number of new tokens to generate (maps to vLLM&#39;s max_tokens)</span>
<span class="sd">            * **num_return_sequences** (int): Number of sequences to return (maps to vLLM&#39;s n)</span>
<span class="sd">            * **temperature** (float): Sampling temperature (0.0 = deterministic, higher = more random)</span>
<span class="sd">            * **top_p** (float): Nucleus sampling parameter (0.0-1.0)</span>
<span class="sd">            * **top_k** (int): Top-k sampling parameter</span>
<span class="sd">            * **repetition_penalty** (float): Penalty for repeating tokens</span>
<span class="sd">            * **do_sample** (bool): Whether to use sampling vs greedy decoding</span>
<span class="sd">            * **num_beams** (int): Number of beams for beam search</span>
<span class="sd">            * **length_penalty** (float): Penalty for sequence length</span>
<span class="sd">            * **early_stopping** (bool): Whether to stop early in beam search</span>
<span class="sd">            * **stop_sequences** (list): Sequences that stop generation (maps to vLLM&#39;s stop)</span>
<span class="sd">            * **skip_special_tokens** (bool): Whether to skip special tokens in output</span>
<span class="sd">            * **logprobs** (bool): Whether to return log probabilities</span>

<span class="sd">                .. warning:: Usage of this parameter is discouraged as it may conflict with the `generate` parameter</span>
<span class="sd">                    of the class.</span>

<span class="sd">            **vLLM-Specific Parameters:**</span>

<span class="sd">            * **presence_penalty** (float): Penalty for token presence</span>
<span class="sd">            * **frequency_penalty** (float): Penalty for token frequency</span>
<span class="sd">            * **ignore_eos** (bool): Whether to ignore EOS token</span>
<span class="sd">            * **prompt_logprobs** (bool): Whether to return prompt log probabilities</span>
<span class="sd">            * **detokenize** (bool): Whether to detokenize output</span>
<span class="sd">            * **include_stop_str_in_output** (bool): Whether to include stop strings in output</span>
<span class="sd">            * **spaces_between_special_tokens** (bool): Whether to add spaces between special tokens</span>
<span class="sd">            * **sampling_type** (str): Type of sampling to use</span>
<span class="sd">            * **temperature_last** (bool): Whether to apply temperature only to last token</span>
<span class="sd">            * **top_p_last** (bool): Whether to apply top_p only to last token</span>
<span class="sd">            * **top_k_last** (bool): Whether to apply top_k only to last token</span>

<span class="sd">            **Legacy Parameter Support:**</span>

<span class="sd">            * **max_tokens** (int): Automatically converted to max_new_tokens</span>
<span class="sd">            * **n** (int): Automatically converted to num_return_sequences</span>

<span class="sd">            **Parameter Conflict Resolution:**</span>

<span class="sd">            When both legacy (vLLM-specific) and standardized parameter names are provided,</span>
<span class="sd">            a :exc:`ValueError` is raised to prevent confusion. For example:</span>

<span class="sd">            * If both ``max_tokens`` and ``max_new_tokens`` are passed, an error is raised</span>
<span class="sd">            * If both ``n`` and ``num_return_sequences`` are passed, an error is raised</span>

<span class="sd">            This ensures clear parameter usage and prevents unexpected behavior.</span>

<span class="sd">        tokenizer_kwargs (dict | None, optional): Additional arguments to pass to the tokenizer. Defaults to `None`.</span>
<span class="sd">        pad_output (bool, optional): Whether to pad the output sequences to a uniform length. Defaults to `False`.</span>
<span class="sd">        pad_model_input (bool, optional): Whether to pad the model input sequences to a uniform length.</span>
<span class="sd">            This is not supported by vLLM.</span>
<span class="sd">        inplace (Literal[True, False, &quot;empty&quot;] | None, optional): Determines how the module should handle in-place operations. Defaults to `True`.</span>
<span class="sd">        device (torch.device | None, optional): The device to use for computation. Defaults to `None`.</span>
<span class="sd">        layout (torch.layout | None, optional): The layout to use for the output tensors when `pad_output=False`. Defaults to `torch.strided`.</span>
<span class="sd">        chat_template_name (Literal[&quot;chatml_format&quot;, &quot;qwen&quot;] | None, optional): The name of the chat template to use when applying the chat template to the history.</span>
<span class="sd">            Defaults to `None`. For `input_mode=&quot;history&quot;` only.</span>
<span class="sd">        chat_template (str | None, optional): The chat template to use when applying the chat template to the history. Defaults to `None`.</span>
<span class="sd">            For `input_mode=&quot;history&quot;` only.</span>
<span class="sd">        num_samples (int | None, optional): The number of samples to generate. Defaults to `None` (one sample, and no batch-dimension for it).</span>
<span class="sd">            Can also be set via the `generate_kwargs[&quot;n&quot;] = value` argument.</span>
<span class="sd">        log_probs_key (NestedKey | None, optional): The key for the log probabilities :class:`~torchrl.modules.llm.policies.LogProbs` object. Defaults to `&quot;log_probs&quot;`.</span>
<span class="sd">        text_key (NestedKey | None, optional): The key for the action :class:`~torchrl.modules.llm.policies.Text` object. Defaults to `&quot;text&quot;`.</span>
<span class="sd">        tokens_key (NestedKey | None, optional): The key for the action :class:`~torchrl.modules.llm.policies.Tokens` object. Defaults to `&quot;tokens&quot;`.</span>
<span class="sd">        masks_key (NestedKey | None, optional): The key for the action :class:`~torchrl.modules.llm.policies.Masks` object. Defaults to `&quot;masks&quot;`.</span>
<span class="sd">        history_key (NestedKey | None, optional): The key for the action :class:`~torchrl.modules.llm.policies.ChatHistory` object. Defaults to `&quot;history&quot;`.</span>
<span class="sd">        batching (bool, optional): Whether to enable batching. Defaults to `False`. See :ref:`ref_batching` below for more details.</span>
<span class="sd">        min_batch_size (int | None, optional): The minimum batch size to use for batching. See :ref:`ref_batching` below for more details.</span>
<span class="sd">        max_batch_size (int | None, optional): The maximum batch size to use for batching. See :ref:`ref_batching` below for more details.</span>
<span class="sd">        batching_timeout (float, optional): The timeout for batching. See :ref:`ref_batching` below for more details.</span>

<span class="sd">    .. _ref_batching:</span>
<span class="sd">        Batching is a feature that allows the module to process multiple inputs in a single call.</span>
<span class="sd">        It is designed to work in a multi-threaded environment.</span>
<span class="sd">        To enable batching, it suffices to set `batching=True` which will set `min_batch_size` to 1 if not provided.</span>
<span class="sd">        If you want to set a different value for `min_batch_size` or `max_batch_size` for a fine-grained control,</span>
<span class="sd">        you can to set `batching=True` and then set `min_batch_size` or `max_batch_size` to a value greater or equal to 1.</span>
<span class="sd">        The way batching works is as follows:</span>
<span class="sd">        - If `min_batch_size` is not provided but `max_batch_size` is, `min_batch_size` is set to 1.</span>
<span class="sd">        - If `max_batch_size` is not provided but `min_batch_size` is, `max_batch_size` is set to the number of inputs in the queue.</span>
<span class="sd">        - When the model is called, a check is performed to see if the number of inputs in the queue is greater or equal to `min_batch_size`.</span>
<span class="sd">          If it is, the batch is processed immediately, while waiting for the previous batch to be processed if the model is busy.</span>
<span class="sd">          Otherwise, the input is added to the queue and the function waits for the batch to be completed.</span>
<span class="sd">          While waiting for the batch to be completed, a timeout is set to `batching_timeout` seconds such that if the batch is not</span>
<span class="sd">          completed after `batching_timeout` seconds, the remaining items to process are processed as is and the function returns after</span>
<span class="sd">          at most `batching_timeout` seconds (plus the time to finish processing the previous and current batch).</span>

<span class="sd">    Input Keys:</span>
<span class="sd">        The input key depends on both `input_mode` and `generate`:</span>

<span class="sd">        - If `input_mode=&quot;history&quot;` and `generate=True`: `input_key` (defaults to `(&quot;history&quot;, &quot;prompt&quot;)`)</span>
<span class="sd">        - If `input_mode=&quot;history&quot;` and `generate=False`: `input_key` (defaults to `(&quot;history&quot;, &quot;full&quot;)`)</span>
<span class="sd">        - If `input_mode=&quot;text&quot;` and `generate=True`: `input_key` (defaults to `(&quot;text&quot;, &quot;prompt&quot;)`)</span>
<span class="sd">        - If `input_mode=&quot;text&quot;` and `generate=False`: `input_key` (defaults to `(&quot;text&quot;, &quot;full&quot;)`)</span>
<span class="sd">        - If `input_mode=&quot;tokens&quot;` and `generate=True`: `input_key` (defaults to `(&quot;tokens&quot;, &quot;prompt&quot;)`)</span>
<span class="sd">        - If `input_mode=&quot;tokens&quot;` and `generate=False`: `input_key` (defaults to `(&quot;tokens&quot;, &quot;full&quot;)`)</span>

<span class="sd">    Output Keys:</span>
<span class="sd">        The output keys are automatically determined based on the input_mode:</span>
<span class="sd">        - **Tokens**: Always returned (`tokens_key`, defaults to `&quot;tokens&quot;`)</span>
<span class="sd">        - **Text**: Returned for `&quot;text&quot;` and `&quot;history&quot;` modes (`text_key`, defaults to `&quot;text&quot;`)</span>
<span class="sd">        - **History**: Returned only for `&quot;history&quot;` mode (`history_key`, defaults to `&quot;history&quot;`)</span>
<span class="sd">        - **Masks**: Always returned (`masks_key`, defaults to `&quot;masks&quot;`)</span>
<span class="sd">        - **Log Probs**: Returned when `return_log_probs=True` (`log_probs_key`, defaults to `&quot;log_probs&quot;`)</span>

<span class="sd">        Example output structure for `input_mode=&quot;history&quot;`:</span>
<span class="sd">        ```</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            text=Text(prompt=..., response=..., full=...),</span>
<span class="sd">            masks=Masks(all_attention_mask=..., all_assistant_mask=...),</span>
<span class="sd">            tokens=Tokens(prompt=..., response=..., full=...),</span>
<span class="sd">            log_probs=LogProbs(prompt=..., response=..., full=...),</span>
<span class="sd">            history=ChatHistory(prompt=..., response=..., full=...)</span>
<span class="sd">        )</span>
<span class="sd">        ```</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; from vllm import LLM</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoTokenizer</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data.llm import History</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules.llm.policies import ChatHistory</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; model = LLM(&quot;gpt2&quot;)</span>
<span class="sd">        &gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(&quot;gpt2&quot;)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # History input (recommended for RL environments)</span>
<span class="sd">        &gt;&gt;&gt; wrapper = vLLMWrapper(</span>
<span class="sd">        ...     model,</span>
<span class="sd">        ...     tokenizer=tokenizer,</span>
<span class="sd">        ...     input_mode=&quot;history&quot;,</span>
<span class="sd">        ...     generate=True,</span>
<span class="sd">        ...     return_log_probs=True,</span>
<span class="sd">        ...     generate_kwargs={</span>
<span class="sd">        ...         &quot;max_new_tokens&quot;: 50,  # Standardized parameter</span>
<span class="sd">        ...         &quot;temperature&quot;: 0.7,</span>
<span class="sd">        ...         &quot;top_p&quot;: 0.9,</span>
<span class="sd">        ...         &quot;do_sample&quot;: True,</span>
<span class="sd">        ...     }</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; history = History.from_chats([[</span>
<span class="sd">        ...     {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello&quot;},</span>
<span class="sd">        ...     {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Hi there!&quot;}</span>
<span class="sd">        ... ]])</span>
<span class="sd">        &gt;&gt;&gt; chat_history = ChatHistory(prompt=history)</span>
<span class="sd">        &gt;&gt;&gt; result = wrapper(TensorDict(history=chat_history, batch_size=(1,)))</span>
<span class="sd">        &gt;&gt;&gt; print(result[&quot;text&quot;].response)  # Generated text</span>
<span class="sd">        &gt;&gt;&gt; print(result[&quot;log_probs&quot;].response)  # Log probabilities</span>
<span class="sd">        &gt;&gt;&gt; print(result[&quot;history&quot;].response)  # History with response</span>

<span class="sd">    Attributes:</span>
<span class="sd">        collector: The collector associated with the module, if it exists.</span>

<span class="sd">    .. seealso::</span>
<span class="sd">        - :class:`~torchrl.modules.llm.policies.LLMWrapperBase` (see :ref:`ref_categorical_sequential`)</span>
<span class="sd">        - :class:`~torchrl.modules.llm.policies.TransformersWrapper` (see :ref:`ref_transformers_wrapper`)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>  <span class="c1"># vllm.LLM | AsyncVLLMEngineService | AsyncLLMEngineExtended | str</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="nb">callable</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
        <span class="n">input_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;history&quot;</span><span class="p">,</span>
        <span class="n">input_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attention_mask_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span>
        <span class="n">generate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">generate_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tokenizer_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pad_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">pad_model_input</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">inplace</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;empty&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">layout</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">layout</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">chat_template_name</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;chatml_format&quot;</span><span class="p">,</span> <span class="s2">&quot;qwen&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">chat_template</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_log_probs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">history_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="s2">&quot;history&quot;</span><span class="p">,</span>
        <span class="n">text_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span>
        <span class="n">tokens_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="s2">&quot;tokens&quot;</span><span class="p">,</span>
        <span class="n">masks_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="s2">&quot;masks&quot;</span><span class="p">,</span>
        <span class="n">log_probs_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="s2">&quot;log_probs&quot;</span><span class="p">,</span>
        <span class="n">batching</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">min_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batching_timeout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10.0</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">batching</span> <span class="ow">and</span> <span class="n">min_batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">min_batch_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="p">(</span><span class="n">min_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">max_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="n">batching</span> <span class="ow">is</span> <span class="kc">False</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;min_batch_size and max_batch_size must be None if batching is False.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Validate that min_batch_size &lt;= max_batch_size when both are specified</span>
        <span class="k">if</span> <span class="n">min_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">max_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">min_batch_size</span> <span class="o">&gt;</span> <span class="n">max_batch_size</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;min_batch_size (</span><span class="si">{</span><span class="n">min_batch_size</span><span class="si">}</span><span class="s2">) must be &lt;= max_batch_size (</span><span class="si">{</span><span class="n">max_batch_size</span><span class="si">}</span><span class="s2">)&quot;</span>
                <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_min_batch_size</span> <span class="o">=</span> <span class="n">min_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_max_batch_size</span> <span class="o">=</span> <span class="n">max_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batching_timeout</span> <span class="o">=</span> <span class="n">batching_timeout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_queue</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_futures</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batching</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batching_lock</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Lock</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batching_lock</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">vllm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;vllm is required for vLLMWrapper&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">transformers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;transformers is required for vLLMWrapper&quot;</span><span class="p">)</span>

        <span class="c1"># Detect and initialize model</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">AsyncVLLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

        <span class="c1"># Validate model type</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">AsyncVLLM</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">=</span> <span class="s2">&quot;async_vllm&quot;</span>
        <span class="k">elif</span> <span class="n">vllm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">vllm</span><span class="o">.</span><span class="n">LLM</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">=</span> <span class="s2">&quot;sync_vllm&quot;</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;generate&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;remote&quot;</span><span class="p">):</span>
            <span class="c1"># Ray actor with generate method</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">=</span> <span class="s2">&quot;ray_actor&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;model must be a string, vllm.LLM, AsyncVLLM, or Ray actor. Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>

            <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">SamplingParams</span>

        <span class="c1"># Validate input_mode</span>
        <span class="k">if</span> <span class="n">input_mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;history&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;tokens&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;input_mode must be one of &#39;history&#39;, &#39;text&#39;, &#39;tokens&#39;. Got &#39;</span><span class="si">{</span><span class="n">input_mode</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_mode</span> <span class="o">=</span> <span class="n">input_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_mask_key</span> <span class="o">=</span> <span class="n">attention_mask_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generate</span> <span class="o">=</span> <span class="n">generate</span>
        <span class="k">if</span> <span class="n">pad_model_input</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;pad_model_input is not supported by vLLMWrapper.&quot;</span><span class="p">)</span>

        <span class="c1"># Auto-determine what to return based on input mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_history</span> <span class="o">=</span> <span class="n">input_mode</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;history&quot;</span><span class="p">,)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_text</span> <span class="o">=</span> <span class="n">input_mode</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;history&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_tokens</span> <span class="o">=</span> <span class="n">input_mode</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;history&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_masks</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="n">return_log_probs</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">generate</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;return_log_probs must be True when generate=False.&quot;</span><span class="p">)</span>
        <span class="n">return_log_probs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="kc">True</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">return_log_probs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">generate</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="n">generate</span><span class="p">)</span>
            <span class="k">else</span> <span class="nb">bool</span><span class="p">(</span><span class="n">return_log_probs</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_log_probs</span> <span class="o">=</span> <span class="n">return_log_probs</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">history_key</span> <span class="o">=</span> <span class="n">history_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_probs_key</span> <span class="o">=</span> <span class="n">log_probs_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">masks_key</span> <span class="o">=</span> <span class="n">masks_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_key</span> <span class="o">=</span> <span class="n">text_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span> <span class="o">=</span> <span class="n">tokens_key</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pad_output</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;pad_output must be a boolean&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span> <span class="o">=</span> <span class="n">pad_output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">pad_output</span> <span class="ow">and</span> <span class="n">layout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">layout</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">strided</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layout</span> <span class="o">=</span> <span class="n">layout</span>
        <span class="n">padding_value</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Set input keys based on mode and generate parameter</span>
        <span class="k">if</span> <span class="n">input_mode</span> <span class="o">==</span> <span class="s2">&quot;history&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">generate</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="p">(</span><span class="s2">&quot;history&quot;</span><span class="p">,</span> <span class="s2">&quot;prompt&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_key</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">input_key</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;history&quot;</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_key</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">input_key</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">input_mode</span> <span class="o">==</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">generate</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;prompt&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_key</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">input_key</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_key</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">input_key</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">input_mode</span> <span class="o">==</span> <span class="s2">&quot;tokens&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">generate</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;prompt&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_key</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">input_key</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_key</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">input_key</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid input_mode: </span><span class="si">{</span><span class="n">input_mode</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Set output keys based on auto-determined return flags</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_text</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_masks</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">masks_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_tokens</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_log_probs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_probs_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_history</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history_key</span><span class="p">)</span>

        <span class="c1"># Tokenizer setup</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tokenizer_kwargs</span><span class="p">:</span>
            <span class="n">tokenizer_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;return_attention_mask&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;return_attention_mask must be True&quot;</span><span class="p">)</span>

        <span class="c1"># If we don&#39;t pad, we use lists</span>
        <span class="n">return_tensors</span> <span class="o">=</span> <span class="s2">&quot;pt&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span> <span class="k">else</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">return_tensors</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;return_tensors&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="p">)</span>
                <span class="o">!=</span> <span class="n">return_tensors</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span>
        <span class="k">if</span> <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;padding&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span>
        <span class="k">if</span> <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;padding_side&quot;</span><span class="p">,</span> <span class="s2">&quot;left&quot;</span><span class="p">)</span> <span class="o">!=</span> <span class="s2">&quot;left&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_kwargs</span> <span class="o">=</span> <span class="n">tokenizer_kwargs</span>

        <span class="c1"># Get tokenizer if needed</span>
        <span class="k">if</span> <span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;get_tokenizer&quot;</span><span class="p">):</span>
                    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_tokenizer</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Try to extract model name and load tokenizer as fallback</span>
                    <span class="n">model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_model_name</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">model_name</span><span class="p">:</span>
                        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;No tokenizer provided. Attempting to load tokenizer from model name: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>

                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
                        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">tokenizer_error</span><span class="p">:</span>
                            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Failed to load tokenizer from </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">tokenizer_error</span><span class="si">}</span><span class="s2">&quot;</span>
                            <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                            <span class="s2">&quot;No tokenizer provided and no tokenizer found in model.&quot;</span>
                        <span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not get tokenizer from model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;pad_token&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">padding_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span><span class="p">)[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span> <span class="o">=</span> <span class="n">padding_value</span>

        <span class="c1"># Generate kwargs setup</span>
        <span class="k">if</span> <span class="n">generate_kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">generate_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">generate_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">generate_kwargs</span><span class="p">)</span>

        <span class="c1"># Standardize common parameters</span>
        <span class="n">generate_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_standardize_generate_kwargs</span><span class="p">(</span><span class="n">generate_kwargs</span><span class="p">)</span>

        <span class="c1"># Extract wrapper-specific parameters</span>
        <span class="n">vllm_specific_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_wrapper_specific_kwargs</span><span class="p">(</span>
            <span class="n">generate_kwargs</span><span class="p">,</span> <span class="s2">&quot;vllm&quot;</span>
        <span class="p">)</span>

        <span class="c1"># Convert common parameters back to vLLM format</span>
        <span class="n">vllm_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">generate_kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">COMMON_GENERATION_PARAMS</span><span class="p">:</span>
                <span class="c1"># Convert common names to vLLM names</span>
                <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span>
                    <span class="n">vllm_kwargs</span><span class="p">[</span><span class="s2">&quot;max_tokens&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">elif</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;num_return_sequences&quot;</span><span class="p">:</span>
                    <span class="n">vllm_kwargs</span><span class="p">[</span><span class="s2">&quot;n&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">elif</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;stop_sequences&quot;</span><span class="p">:</span>
                    <span class="n">vllm_kwargs</span><span class="p">[</span><span class="s2">&quot;stop&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">elif</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;logprobs&quot;</span><span class="p">:</span>
                    <span class="n">vllm_kwargs</span><span class="p">[</span><span class="s2">&quot;logprobs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">elif</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;do_sample&quot;</span><span class="p">:</span>
                    <span class="c1"># do_sample is handled through the sampling parameters</span>
                    <span class="c1"># If do_sample=False, we use greedy decoding (temperature=0)</span>
                    <span class="c1"># If do_sample=True, we use the provided sampling parameters</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">value</span><span class="p">:</span>
                        <span class="n">vllm_kwargs</span><span class="p">[</span><span class="s2">&quot;temperature&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
                    <span class="c1"># If do_sample=True, we keep the existing temperature/top_p/top_k values</span>
                <span class="k">elif</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;num_beams&quot;</span><span class="p">:</span>
                    <span class="c1"># vLLM uses best_of instead of num_beams</span>
                    <span class="n">vllm_kwargs</span><span class="p">[</span><span class="s2">&quot;best_of&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">elif</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;length_penalty&quot;</span><span class="p">,</span> <span class="s2">&quot;early_stopping&quot;</span><span class="p">]:</span>
                    <span class="c1"># These parameters are not supported by vLLM, skip them</span>
                    <span class="k">pass</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Direct mapping for other common parameters</span>
                    <span class="n">vllm_kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

        <span class="c1"># Add vLLM-specific parameters</span>
        <span class="n">vllm_kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">vllm_specific_kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="n">num_samples</span>
        <span class="k">if</span> <span class="n">vllm_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;n&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">num_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">inplace</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;empty&quot;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;inplace must be False (or None) when generating more than one sample.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">inplace</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">inplace</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">vllm_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;n&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
                <span class="ow">and</span> <span class="n">num_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="ow">and</span> <span class="n">vllm_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;n&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">!=</span> <span class="n">num_samples</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;num_samples differs from generate_kwargs[&#39;n&#39;].&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">num_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="n">vllm_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;n&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">vllm_kwargs</span><span class="p">[</span><span class="s2">&quot;n&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span>
        <span class="k">elif</span> <span class="n">inplace</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span> <span class="o">=</span> <span class="n">inplace</span>

        <span class="n">prompt_logprobs</span> <span class="o">=</span> <span class="n">return_log_probs</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">generate</span><span class="p">:</span>
            <span class="c1"># We want only the log-probs, we generate a single token (that we then discard)</span>
            <span class="c1"># and retrieve the prompt log-probs</span>
            <span class="n">vllm_kwargs</span><span class="p">[</span><span class="s2">&quot;max_tokens&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">return_log_probs</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;return_log_probs must be True when generate=False.&quot;</span><span class="p">)</span>

        <span class="n">vllm_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;detokenize&quot;</span><span class="p">,</span> <span class="ow">not</span> <span class="n">pad_output</span><span class="p">)</span>
        <span class="n">vllm_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;prompt_logprobs&quot;</span><span class="p">,</span> <span class="n">prompt_logprobs</span><span class="p">)</span>
        <span class="n">vllm_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;logprobs&quot;</span><span class="p">,</span> <span class="n">return_log_probs</span><span class="p">)</span>
        <span class="n">vllm_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;include_stop_str_in_output&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">vllm_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;skip_special_tokens&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

        <span class="n">sampling_params</span> <span class="o">=</span> <span class="n">SamplingParams</span><span class="p">(</span><span class="o">**</span><span class="n">vllm_kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampling_params</span> <span class="o">=</span> <span class="n">sampling_params</span>

        <span class="c1"># Additional transformers-specific settings</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chat_template_name</span> <span class="o">=</span> <span class="n">chat_template_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chat_template</span> <span class="o">=</span> <span class="n">chat_template</span>

<div class="viewcode-block" id="vLLMWrapper.get_new_version"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.vLLMWrapper.html#torchrl.modules.llm.vLLMWrapper.get_new_version">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_new_version</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a new version of the module with altered parameters.</span>

<span class="sd">        For instance, the generate parameter can be altered to enable text generation or log-probabilities computation.</span>
<span class="sd">        This is especially useful when one wants to avoid re-initializing the module with a new set of parameters, when the</span>
<span class="sd">        same parameters could be used to gather log-probs.</span>

<span class="sd">        Positional arguments are not supported.</span>

<span class="sd">        See the class constructor for more details about the parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Build the constructor arguments by using current values for missing parameters</span>
        <span class="n">constructor_kwargs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Model is always required</span>
        <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

        <span class="c1"># Check for each parameter and use current value if not provided</span>
        <span class="k">if</span> <span class="s2">&quot;tokenizer&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;tokenizer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;tokenizer&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;tokenizer&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;tokenizer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span>

        <span class="k">if</span> <span class="s2">&quot;input_mode&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;input_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;input_mode&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;input_mode&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;input_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_mode</span>

        <span class="k">if</span> <span class="s2">&quot;input_key&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;input_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;input_key&quot;</span><span class="p">]</span>
        <span class="c1"># Since the input_key is dynamically determined, we don&#39;t want to set it here</span>
        <span class="c1"># elif hasattr(self, &quot;input_key&quot;):</span>
        <span class="c1"># constructor_kwargs[&quot;input_key&quot;] = self.input_key</span>

        <span class="k">if</span> <span class="s2">&quot;attention_mask_key&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;attention_mask_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;attention_mask_key&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;attention_mask_key&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;attention_mask_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_mask_key</span>

        <span class="k">if</span> <span class="s2">&quot;generate&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;generate&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;generate&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;generate&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;generate&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate</span>

        <span class="k">if</span> <span class="s2">&quot;return_log_probs&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;return_log_probs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;return_log_probs&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="n">constructor_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;generate&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="c1"># if we are not generating, we want to return log-probs</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;return_log_probs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;return_log_probs&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;return_log_probs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_log_probs</span>

        <span class="k">if</span> <span class="s2">&quot;generate_kwargs&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;generate_kwargs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;generate_kwargs&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;generate_kwargs&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;generate_kwargs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_kwargs</span>

        <span class="k">if</span> <span class="s2">&quot;pad_output&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;pad_output&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;pad_output&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;pad_output&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;pad_output&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span>

        <span class="k">if</span> <span class="s2">&quot;tokenizer_kwargs&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;tokenizer_kwargs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;tokenizer_kwargs&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;tokenizer_kwargs&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;tokenizer_kwargs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_kwargs</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="s2">&quot;pad_output&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span>
                <span class="ow">and</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pad_output&quot;</span><span class="p">)</span>
                <span class="o">!=</span> <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;tokenizer_kwargs&quot;</span><span class="p">][</span><span class="s2">&quot;padding&quot;</span><span class="p">]</span>
            <span class="p">):</span>
                <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;tokenizer_kwargs&quot;</span><span class="p">][</span><span class="s2">&quot;padding&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s2">&quot;pad_output&quot;</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;inplace&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;inplace&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;inplace&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;inplace&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;inplace&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span>

        <span class="k">if</span> <span class="s2">&quot;device&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_device&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>

        <span class="k">if</span> <span class="s2">&quot;layout&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;layout&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;layout&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;layout&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;layout&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layout</span>

        <span class="k">if</span> <span class="s2">&quot;num_samples&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;num_samples&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;num_samples&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;num_samples&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;num_samples&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span>

        <span class="k">if</span> <span class="s2">&quot;chat_template_name&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;chat_template_name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;chat_template_name&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;chat_template_name&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;chat_template_name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template_name</span>

        <span class="k">if</span> <span class="s2">&quot;chat_template&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;chat_template&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;chat_template&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;chat_template&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;chat_template&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template</span>

        <span class="k">if</span> <span class="s2">&quot;history_key&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;history_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;history_key&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;history_key&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;history_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">history_key</span>

        <span class="k">if</span> <span class="s2">&quot;text_key&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;text_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;text_key&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;text_key&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;text_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_key</span>

        <span class="k">if</span> <span class="s2">&quot;tokens_key&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;tokens_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;tokens_key&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;tokens_key&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;tokens_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span>

        <span class="k">if</span> <span class="s2">&quot;masks_key&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;masks_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;masks_key&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;masks_key&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;masks_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">masks_key</span>

        <span class="k">if</span> <span class="s2">&quot;log_probs_key&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;log_probs_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;log_probs_key&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;log_probs_key&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;log_probs_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_probs_key</span>

        <span class="c1"># Create and return new instance</span>
        <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)(</span><span class="o">**</span><span class="n">constructor_kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="vLLMWrapper.set_tokenizer"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.vLLMWrapper.html#torchrl.modules.llm.vLLMWrapper.set_tokenizer">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the tokenizer for the wrapper. Useful for async engines where tokenizer retrieval is deferred.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;pad_token&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">padding_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span><span class="p">)[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">padding_value</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span> <span class="o">=</span> <span class="n">padding_value</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_extract_model_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract model name from different model types for tokenizer fallback.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># For AsyncVLLM, try to get the model name from engine_args</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;engine_args&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">engine_args</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">engine_args</span><span class="o">.</span><span class="n">model</span>

            <span class="c1"># For vllm.LLM, try to get the model name</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;llm_engine&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="n">model</span><span class="o">.</span><span class="n">llm_engine</span><span class="p">,</span> <span class="s2">&quot;model_config&quot;</span>
            <span class="p">):</span>
                <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">llm_engine</span><span class="o">.</span><span class="n">model_config</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

            <span class="c1"># For Ray actors, try to get model name via remote call</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;remote&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;get_model_name&quot;</span><span class="p">):</span>
                <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

                <span class="k">try</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_model_name</span><span class="o">.</span><span class="n">remote</span><span class="p">())</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="k">pass</span>

            <span class="c1"># Try common attributes that might contain model name</span>
            <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;model_name&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="s2">&quot;model_path&quot;</span><span class="p">,</span> <span class="s2">&quot;_model_name&quot;</span><span class="p">]:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                        <span class="k">return</span> <span class="n">value</span>

            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_call_generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Call generate method based on model type.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">==</span> <span class="s2">&quot;ray_actor&quot;</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

            <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Both sync_vllm and async_vllm have direct generate methods</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="vLLMWrapper.forward"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.vLLMWrapper.html#torchrl.modules.llm.vLLMWrapper.forward">[docs]</a>    <span class="nd">@set_list_to_stack</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="nd">@_batching</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tensordict_out</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">logits_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">tensordict_orig</span> <span class="o">=</span> <span class="n">tensordict</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">tensordict_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;tensordict_out must not be provided when tensordict.ndim == 0. If this is needed, &quot;</span>
                    <span class="s2">&quot;please submit an issue on github.&quot;</span>
                <span class="p">)</span>
            <span class="c1"># unsqueeze - squeeze the input</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">lazy_stack</span><span class="p">([</span><span class="n">tensordict</span><span class="p">]),</span> <span class="n">logits_only</span><span class="o">=</span><span class="n">logits_only</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">tensordict_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;tensordict_out must not be provided when tensordict.ndim &gt; 1. If this is needed, &quot;</span>
                    <span class="s2">&quot;please submit an issue on github.&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">logits_only</span><span class="o">=</span><span class="n">logits_only</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                <span class="n">tensordict</span><span class="o">.</span><span class="n">shape</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">):</span>
            <span class="n">tensordict</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">_source_device</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">:</span>
            <span class="n">_source_device</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">device</span>
        <span class="k">if</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
            <span class="n">tensordict</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">SamplingParams</span>

            <span class="n">sampling_params</span> <span class="o">=</span> <span class="n">SamplingParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sampling_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampling_params</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">TensorDict</span><span class="p">(</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">tensordict</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="p">(</span>
                        <span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">,</span>
                        <span class="o">*</span><span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>
                    <span class="p">),</span>
                <span class="p">)</span>
                <span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span>
                <span class="n">device</span><span class="o">=</span><span class="n">tensordict</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_mode</span> <span class="o">==</span> <span class="s2">&quot;history&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_vllm_generate_history</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_vllm_logprobs_history</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_mode</span> <span class="o">==</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_vllm_generate_text</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_vllm_logprobs_text</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_mode</span> <span class="o">==</span> <span class="s2">&quot;tokens&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_vllm_generate_tokens</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_vllm_logprobs_tokens</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">_source_device</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">_source_device</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">tensordict_out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="c1"># The output is the input</span>
                <span class="n">tensordict_out</span> <span class="o">=</span> <span class="n">tensordict_orig</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="c1"># The output is the new structure</span>
                <span class="n">tensordict_out</span> <span class="o">=</span> <span class="n">out</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span> <span class="o">==</span> <span class="s2">&quot;empty&quot;</span><span class="p">:</span>
                <span class="c1"># The output is empty</span>
                <span class="n">tensordict_out</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">tensordict_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">tensordict_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">out</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">tensordict_out</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">result</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">keys_to_update</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">tensordict_out</span> <span class="ow">is</span> <span class="n">out</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">out</span>
            <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">))))</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="n">result</span><span class="p">,</span> <span class="n">keys_to_update</span><span class="o">=</span><span class="n">keys</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">out</span>
        <span class="k">return</span> <span class="n">result</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_from_vllm_generate_history</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensordict_input</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">sampling_params</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">out</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate text from history input.&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data.llm</span><span class="w"> </span><span class="kn">import</span> <span class="n">History</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">tensordict_input</span><span class="p">,</span> <span class="n">TensorDictBase</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;tensordict_input must be TensorDictBase, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">tensordict_input</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">sampling_params</span><span class="p">,</span> <span class="n">SamplingParams</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;sampling_params must be SamplingParams, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">sampling_params</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">out</span><span class="p">,</span> <span class="n">TensorDictBase</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;out must be TensorDictBase, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">out</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="c1"># Validate input</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tensordict_input</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39; key for history input mode, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but found keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">tensordict_input</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">history</span> <span class="o">=</span> <span class="n">tensordict_input</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">History</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected History object for &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39;, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">history</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Apply chat template</span>
        <span class="n">tokenizer_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;chat_template_name&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;chat_template&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template</span><span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;add_generation_prompt&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">text_prompt</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="o">**</span><span class="n">tokenizer_kwargs</span>
        <span class="p">)</span>

        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;return_assistant_tokens_mask&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;tokenize&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;padding&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;return_dict&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">response_struct</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="o">**</span><span class="n">tokenizer_kwargs</span>
        <span class="p">)</span>
        <span class="n">tokens_prompt_padded</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">tokens_prompt_unpadded</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="n">tokens_prompt_padded</span> <span class="o">=</span> <span class="n">response_struct</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;input_ids&quot;</span><span class="p">,</span>
                <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokens_prompt_unpadded</span> <span class="o">=</span> <span class="n">response_struct</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="n">as_list</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_from_tokens</span><span class="p">(</span>
            <span class="n">tokens_prompt_padded</span><span class="o">=</span><span class="n">tokens_prompt_padded</span><span class="p">,</span>
            <span class="n">tokens_prompt_unpadded</span><span class="o">=</span><span class="n">tokens_prompt_unpadded</span><span class="p">,</span>
            <span class="n">sampling_params</span><span class="o">=</span><span class="n">sampling_params</span><span class="p">,</span>
            <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Generate using text path</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="n">result</span><span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="s2">&quot;prompt&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">tokens_prompt_padded</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span>
                <span class="k">else</span> <span class="n">tokens_prompt_padded</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokens_prompt_nested</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nested</span><span class="o">.</span><span class="n">as_nested_tensor</span><span class="p">(</span><span class="n">tokens_prompt_unpadded</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">:</span>
                <span class="n">result</span><span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="s2">&quot;prompt&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="n">tokens_prompt_nested</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
                    <span class="n">r</span><span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="s2">&quot;prompt&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="n">tokens_prompt_nested</span>

        <span class="n">text_result</span> <span class="o">=</span> <span class="n">Text</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
        <span class="n">result</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="n">text_result</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">:</span>
            <span class="n">text_result</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">text_prompt</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">r</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="s2">&quot;prompt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">text_prompt</span>
        <span class="k">with</span> <span class="n">result</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="n">result_flat</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                <span class="n">tokens_full_padded</span> <span class="o">=</span> <span class="n">result_flat</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">),</span>
                    <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
                    <span class="n">padding_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">tokens_full_padded</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;tokens_full_padded is None&quot;</span><span class="p">)</span>
                <span class="n">text_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span>
                    <span class="n">tokens_full_padded</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tokens_full_unpadded</span> <span class="o">=</span> <span class="n">result_flat</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">),</span> <span class="n">as_list</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>
                <span class="c1"># print(&quot;shapes of assistant masks&quot;, [t.shape for t in result_flat.get((&quot;masks&quot;, &quot;all_assistant_mask&quot;), as_list=True)])</span>
                <span class="k">if</span> <span class="n">tokens_full_unpadded</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;tokens_full_unpadded is None&quot;</span><span class="p">)</span>
                <span class="n">text_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span>
                    <span class="n">tokens_full_unpadded</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
            <span class="n">text_prompt</span> <span class="o">=</span> <span class="n">result_flat</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="s2">&quot;prompt&quot;</span><span class="p">]</span>
            <span class="n">text_response</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">txt</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span> <span class="p">:]</span>
                <span class="k">for</span> <span class="n">txt</span><span class="p">,</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="n">text_full</span><span class="p">,</span> <span class="n">text_prompt</span><span class="p">)</span>
            <span class="p">]</span>
            <span class="n">result_flat</span><span class="o">.</span><span class="n">set</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">),</span> <span class="n">text_full</span><span class="p">)</span>
            <span class="n">result_flat</span><span class="o">.</span><span class="n">set</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="s2">&quot;response&quot;</span><span class="p">),</span> <span class="n">text_response</span><span class="p">)</span>

        <span class="c1"># Now parse the full text back to a history object, and use the extra history objects</span>
        <span class="c1"># as response</span>
        <span class="n">history_chat</span> <span class="o">=</span> <span class="n">ChatHistory</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">history_chat</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">history</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">history_chat</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">h</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">history</span>
        <span class="k">with</span> <span class="n">history_chat</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="n">history_chat_flat</span><span class="p">:</span>
            <span class="n">prompt_histories</span> <span class="o">=</span> <span class="n">history_chat_flat</span><span class="o">.</span><span class="n">prompt</span>
            <span class="c1"># Extract response histories from full text</span>
            <span class="n">h_responses</span> <span class="o">=</span> <span class="n">_extract_responses_from_full_histories</span><span class="p">(</span>
                <span class="n">text_full</span><span class="p">,</span> <span class="n">prompt_histories</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span>
            <span class="p">)</span>
            <span class="n">history_chat_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">h_responses</span>
            <span class="n">history_chat_flat</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">history_chat_flat</span><span class="o">.</span><span class="n">prompt</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                <span class="n">h_responses</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
            <span class="p">)</span>
        <span class="n">result</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history_key</span><span class="p">,</span> <span class="n">history_chat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_from_vllm_logprobs_history</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensordict_input</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">sampling_params</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">out</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute log-probs from history input.&quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">tensordict_input</span><span class="p">,</span> <span class="n">TensorDictBase</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;tensordict_input must be TensorDictBase, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">tensordict_input</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">sampling_params</span><span class="p">,</span> <span class="n">SamplingParams</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;sampling_params must be SamplingParams, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">sampling_params</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">out</span><span class="p">,</span> <span class="n">TensorDictBase</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;out must be TensorDictBase, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">out</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data.llm</span><span class="w"> </span><span class="kn">import</span> <span class="n">History</span>

        <span class="c1"># Validate input</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tensordict_input</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39; key for history input mode, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but found keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">tensordict_input</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">history</span> <span class="o">=</span> <span class="n">tensordict_input</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">History</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected History object for &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39;, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">history</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Apply chat template</span>
        <span class="n">tokenizer_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;chat_template_name&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;chat_template&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template</span><span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;add_generation_prompt&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">text_full</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="o">**</span><span class="n">tokenizer_kwargs</span>
        <span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;return_assistant_tokens_mask&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;tokenize&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;padding&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;return_dict&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">response_struct</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="o">**</span><span class="n">tokenizer_kwargs</span>
        <span class="p">)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logprobs_from_tokens</span><span class="p">(</span>
            <span class="n">response_struct</span><span class="o">=</span><span class="n">response_struct</span><span class="p">,</span> <span class="n">sampling_params</span><span class="o">=</span><span class="n">sampling_params</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">out</span>
        <span class="p">)</span>
        <span class="n">text_result</span> <span class="o">=</span> <span class="n">Text</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
        <span class="n">result</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="n">text_result</span><span class="p">)</span>
        <span class="n">result</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">text_full</span>
        <span class="n">result</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history_key</span><span class="p">,</span> <span class="n">ChatHistory</span><span class="p">(</span><span class="n">full</span><span class="o">=</span><span class="n">history</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_from_vllm_generate_text</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">out</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate text from text input.&quot;&quot;&quot;</span>
        <span class="c1"># Type assertions</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">td</span><span class="p">,</span> <span class="n">TensorDictBase</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;td must be TensorDictBase, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">td</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">sampling_params</span><span class="p">,</span> <span class="n">SamplingParams</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;sampling_params must be SamplingParams, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">sampling_params</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">out</span><span class="p">,</span> <span class="n">TensorDictBase</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;out must be TensorDictBase, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">out</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="c1"># Validate input</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">td</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39; key for text input mode, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but found keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">text</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39; key for text input mode&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_from_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_from_vllm_logprobs_text</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">out</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute log-probs from text input.&quot;&quot;&quot;</span>
        <span class="c1"># Type assertions</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">td</span><span class="p">,</span> <span class="n">TensorDictBase</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;td must be TensorDictBase, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">td</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">sampling_params</span><span class="p">,</span> <span class="n">SamplingParams</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;sampling_params must be SamplingParams, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">sampling_params</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">out</span><span class="p">,</span> <span class="n">TensorDictBase</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;out must be TensorDictBase, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">out</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="c1"># Validate input</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">td</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39; key for text input mode, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but found keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">text</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39; key for text input mode&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logprobs_from_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_from_vllm_generate_tokens</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">out</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate text from tokens input.&quot;&quot;&quot;</span>
        <span class="c1"># Type assertions</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">td</span><span class="p">,</span> <span class="n">TensorDictBase</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;td must be TensorDictBase, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">td</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">sampling_params</span><span class="p">,</span> <span class="n">SamplingParams</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;sampling_params must be SamplingParams, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">sampling_params</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">out</span><span class="p">,</span> <span class="n">TensorDictBase</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;out must be TensorDictBase, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">out</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="c1"># Validate input</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">td</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39; key for tokens input mode, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but found keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">tokens_prompt_padded</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">tokens_prompt_unpadded</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="n">tokens_prompt_padded</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokens_prompt_unpadded</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">,</span> <span class="n">as_list</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
            <span class="c1"># make sure we remove the padding tokens</span>
            <span class="n">tokens_prompt_unpadded</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">tokens</span><span class="p">[</span><span class="n">tokens</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="n">tokens_prompt_unpadded</span>
            <span class="p">]</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_from_tokens</span><span class="p">(</span>
            <span class="n">tokens_prompt_unpadded</span><span class="o">=</span><span class="n">tokens_prompt_unpadded</span><span class="p">,</span>
            <span class="n">tokens_prompt_padded</span><span class="o">=</span><span class="n">tokens_prompt_padded</span><span class="p">,</span>
            <span class="n">sampling_params</span><span class="o">=</span><span class="n">sampling_params</span><span class="p">,</span>
            <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_from_vllm_logprobs_tokens</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">out</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute log-probs from tokens input.&quot;&quot;&quot;</span>
        <span class="c1"># Type assertions</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">td</span><span class="p">,</span> <span class="n">TensorDictBase</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;td must be TensorDictBase, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">td</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">sampling_params</span><span class="p">,</span> <span class="n">SamplingParams</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;sampling_params must be SamplingParams, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">sampling_params</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">out</span><span class="p">,</span> <span class="n">TensorDictBase</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;out must be TensorDictBase, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">out</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="c1"># Validate input</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">td</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39; key for tokens input mode, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but found keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">tokens_full_padded</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">tokens_full_unpadded</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="n">tokens_full_padded</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokens_full_unpadded</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">,</span> <span class="n">as_list</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
            <span class="c1"># make sure we remove the padding tokens</span>
            <span class="n">tokens_full_unpadded</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">tokens</span><span class="p">[</span><span class="n">tokens</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">]</span> <span class="k">for</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="n">tokens_full_unpadded</span>
            <span class="p">]</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logprobs_from_tokens</span><span class="p">(</span>
            <span class="n">response_struct</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">tokens_full_unpadded</span><span class="o">=</span><span class="n">tokens_full_unpadded</span><span class="p">,</span>
            <span class="n">tokens_full_padded</span><span class="o">=</span><span class="n">tokens_full_padded</span><span class="p">,</span>
            <span class="n">sampling_params</span><span class="o">=</span><span class="n">sampling_params</span><span class="p">,</span>
            <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_cat_text</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">response_text</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Concatenate text and response text.&quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">text</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;text must be str or list, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">text</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="c1"># Handle None response_text (when tokenizer is not available)</span>
        <span class="k">if</span> <span class="n">response_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;response_text is None, likely due to missing tokenizer. &quot;</span>
                <span class="s2">&quot;Cannot decode vLLM response without a tokenizer. &quot;</span>
                <span class="s2">&quot;Please provide a tokenizer explicitly or ensure the model has one available.&quot;</span>
            <span class="p">)</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">response_text</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;response_text must be str or list, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">response_text</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_cat_text</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">t_</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">t_</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">response_text</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">text</span> <span class="o">+</span> <span class="n">response_text</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_from_text</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="n">NonTensorStack</span><span class="p">,</span>
        <span class="n">sampling_params</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">out</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate text from text input.&quot;&quot;&quot;</span>
        <span class="c1"># Convert text to list format</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="n">text</span><span class="p">]</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">text</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;text must be str or list, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">text</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">sampling_params</span><span class="p">,</span> <span class="n">SamplingParams</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;sampling_params must be SamplingParams, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">sampling_params</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">out</span><span class="p">,</span> <span class="n">TensorDictBase</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;out must be TensorDictBase, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">out</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="n">generate_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;sampling_params&quot;</span><span class="p">:</span> <span class="n">sampling_params</span><span class="p">}</span>
        <span class="n">args</span> <span class="o">=</span> <span class="p">()</span>

        <span class="c1"># Convert text to list format</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="n">text</span><span class="p">]</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="c1"># Call generate based on model type</span>
        <span class="n">request_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_generate</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">generate_kwargs</span><span class="p">)</span>

        <span class="n">request_output_tc</span> <span class="o">=</span> <span class="n">_RequestOutput_tc</span><span class="o">.</span><span class="n">from_request_output</span><span class="p">(</span><span class="n">request_output</span><span class="p">)</span>

        <span class="c1"># Extract response tokens and text</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">request_output_tc</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">request_output_tc</span><span class="o">.</span><span class="n">outputs</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="n">response_tokens_padded</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;token_ids&quot;</span><span class="p">,</span>
                <span class="n">as_padded_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">response_tokens_list</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="s2">&quot;token_ids&quot;</span><span class="p">,</span>
            <span class="n">as_list</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_not_padded</span><span class="p">(</span><span class="n">response_tokens_list</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">response_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span>
                <span class="n">response_tokens_list</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">response_text</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Build output TensorClass objects</span>

        <span class="n">masks_obj</span> <span class="o">=</span> <span class="n">Masks</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
        <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_attention_mask</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_assistant_mask</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">masks_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">masks_key</span><span class="p">,</span> <span class="n">masks_obj</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="n">txt</span> <span class="k">for</span> <span class="n">txt</span> <span class="ow">in</span> <span class="n">text</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">)]</span>
        <span class="n">text_obj</span> <span class="o">=</span> <span class="n">Text</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
        <span class="k">with</span> <span class="n">text_obj</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="n">text_obj_flat</span><span class="p">:</span>
            <span class="n">text_obj_flat</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">text</span>
            <span class="n">text_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">response_text</span>
            <span class="n">text_obj_flat</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cat_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">response_text</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="n">text_obj</span><span class="p">)</span>

        <span class="n">tokens_obj</span> <span class="o">=</span> <span class="n">Tokens</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
        <span class="k">with</span> <span class="n">tokens_obj</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="n">tokens_obj_flat</span><span class="p">:</span>
            <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># We don&#39;t have prompt tokens in this path</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">response_tokens_padded</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_check_padded</span><span class="p">(</span><span class="n">response_tokens_padded</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">response_tokens_list</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_check_not_padded</span><span class="p">(</span><span class="n">response_tokens_list</span><span class="p">)</span>
            <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="p">(</span>
                <span class="kc">None</span>  <span class="c1"># we don&#39;t have prompt tokens in this path so no all_tokens either</span>
            <span class="p">)</span>
        <span class="n">tokens_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="n">tokens_obj</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_log_probs</span><span class="p">:</span>
            <span class="n">log_probs_obj</span> <span class="o">=</span> <span class="n">LogProbs</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
            <span class="k">with</span> <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="n">log_probs_obj_flat</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                    <span class="n">log_probs_padded</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                        <span class="s2">&quot;logprobs&quot;</span><span class="p">,</span>
                        <span class="n">as_padded_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">,</span>
                        <span class="n">padding_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">,</span>
                        <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_check_padded</span><span class="p">(</span><span class="n">log_probs_padded</span><span class="p">)</span>
                    <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">log_probs_padded</span>
                    <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">log_probs_padded</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">log_probs_list</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                        <span class="s2">&quot;logprobs&quot;</span><span class="p">,</span>
                        <span class="n">as_list</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_check_not_padded</span><span class="p">(</span><span class="n">log_probs_list</span><span class="p">)</span>
                    <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">log_probs_list</span>
                    <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">log_probs_list</span>
                <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
            <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_probs_key</span><span class="p">,</span> <span class="n">log_probs_obj</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_logprobs_from_text</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="n">NonTensorStack</span><span class="p">,</span>
        <span class="n">sampling_params</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">out</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute log-probs from text input.&quot;&quot;&quot;</span>
        <span class="c1"># Convert text to list format</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="n">text</span><span class="p">]</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">text</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;text must be str or list, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">text</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">sampling_params</span><span class="p">,</span> <span class="n">SamplingParams</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;sampling_params must be SamplingParams, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">sampling_params</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">out</span><span class="p">,</span> <span class="n">TensorDictBase</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;out must be TensorDictBase, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">out</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="c1"># Tokenize the text</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Tokenizer is required for log-probs computation with text input&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Tokenize the text</span>
        <span class="n">tokenized_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="n">tokens_full_padded</span> <span class="o">=</span> <span class="n">tokenized_output</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>
            <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">tokenized_output</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>
            <span class="n">tokens_full_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_list</span><span class="p">(</span>
                <span class="n">tokens_full_padded</span><span class="p">,</span> <span class="n">attention_mask_full_padded</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokens_full_unpadded</span> <span class="o">=</span> <span class="n">tokenized_output</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>
            <span class="n">tokens_full_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_list</span><span class="p">(</span><span class="n">tokens_full_unpadded</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">attention_mask_full_unpadded</span> <span class="o">=</span> <span class="n">tokenized_output</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>
            <span class="n">attention_mask_full_unpadded</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">am</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">am</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
                <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">am</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">am</span> <span class="ow">in</span> <span class="n">attention_mask_full_unpadded</span>
            <span class="p">]</span>

        <span class="c1"># Convert to list format for vLLM</span>
        <span class="n">generate_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;sampling_params&quot;</span><span class="p">:</span> <span class="n">sampling_params</span><span class="p">,</span>
            <span class="s2">&quot;prompt_token_ids&quot;</span><span class="p">:</span> <span class="n">tokens_full_list</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="c1"># Generate with vLLM to get prompt_logprobs</span>
        <span class="n">request_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_generate</span><span class="p">(</span><span class="o">**</span><span class="n">generate_kwargs</span><span class="p">)</span>

        <span class="n">request_output_tc</span> <span class="o">=</span> <span class="n">_RequestOutput_tc</span><span class="o">.</span><span class="n">from_request_output</span><span class="p">(</span><span class="n">request_output</span><span class="p">)</span>

        <span class="c1"># Extract log-probs from prompt_logprobs</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="c1"># For padded case, use all prompt_logprobs</span>
            <span class="n">log_probs_full_padded</span> <span class="o">=</span> <span class="n">request_output_tc</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;prompt_logprobs&quot;</span><span class="p">,</span>
                <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Mask out padding</span>
            <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">tokens_full_padded</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span>
            <span class="n">log_probs_full_padded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="n">log_probs_full_padded</span><span class="p">,</span> <span class="mf">0.0</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># For unpadded case, extract from each sequence</span>
            <span class="n">log_probs_full_unpadded</span> <span class="o">=</span> <span class="n">request_output_tc</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;prompt_logprobs&quot;</span><span class="p">,</span> <span class="n">as_list</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_not_padded</span><span class="p">(</span><span class="n">log_probs_full_unpadded</span><span class="p">)</span>

        <span class="n">masks_obj</span> <span class="o">=</span> <span class="n">Masks</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
            <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_padded</span><span class="p">(</span><span class="n">attention_mask_full_padded</span><span class="p">)</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask_full_padded</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_not_padded</span><span class="p">(</span><span class="n">attention_mask_full_unpadded</span><span class="p">)</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask_full_unpadded</span>
        <span class="n">masks_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">masks_key</span><span class="p">,</span> <span class="n">masks_obj</span><span class="p">)</span>

        <span class="c1"># Build output TensorClass objects</span>
        <span class="n">text_obj</span> <span class="o">=</span> <span class="n">Text</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
            <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">text_obj</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">text_obj</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">text_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">text</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="n">text_obj</span><span class="p">)</span>

        <span class="n">tokens_obj</span> <span class="o">=</span> <span class="n">Tokens</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
            <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_padded</span><span class="p">(</span><span class="n">tokens_full_padded</span><span class="p">)</span>
            <span class="n">tokens_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">tokens_full_padded</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokens_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">tokens_full_unpadded</span>
        <span class="n">tokens_obj</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">tokens_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="n">tokens_obj</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_log_probs</span><span class="p">:</span>
            <span class="n">log_probs_obj</span> <span class="o">=</span> <span class="n">LogProbs</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
                <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_check_padded</span><span class="p">(</span><span class="n">log_probs_full_padded</span><span class="p">)</span>
                <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">log_probs_full_padded</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_check_not_padded</span><span class="p">(</span><span class="n">log_probs_full_unpadded</span><span class="p">)</span>
                <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">log_probs_full_unpadded</span>
            <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
            <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_probs_key</span><span class="p">,</span> <span class="n">log_probs_obj</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_cat_tensors</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tokens</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">response_tokens</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Concatenate tokens and response tokens.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">response_tokens</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_cat_tensors</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">t_</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">t_</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">response_tokens</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">tokens</span><span class="p">,</span> <span class="n">response_tokens</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_from_tokens</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tokens_prompt_unpadded</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tokens_prompt_padded</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sampling_params</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">out</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate text from tokens input.&quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">tokens_prompt_padded</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;tokens_prompt_padded must be torch.Tensor or None, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">tokens_prompt_padded</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">tokens_prompt_unpadded</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;tokens_prompt_unpadded must be list or None, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">tokens_prompt_unpadded</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">sampling_params</span><span class="p">,</span> <span class="n">SamplingParams</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;sampling_params must be SamplingParams, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">sampling_params</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">out</span><span class="p">,</span> <span class="n">TensorDictBase</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;out must be TensorDictBase, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">out</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="n">generate_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;sampling_params&quot;</span><span class="p">:</span> <span class="n">sampling_params</span><span class="p">}</span>
        <span class="n">args</span> <span class="o">=</span> <span class="p">()</span>
        <span class="n">empirical_attention_mask</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">tokens_prompt_unpadded</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># TODO: To be on the safe side, we may do this even in the unpadded case since we&#39;re not sure</span>
            <span class="c1">#  the user passed an unpadded tensor in the first place.</span>
            <span class="n">empirical_attention_mask</span> <span class="o">=</span> <span class="n">tokens_prompt_padded</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span>
            <span class="n">tokens_prompt_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_list</span><span class="p">(</span>
                <span class="n">tokens_prompt_padded</span><span class="p">,</span> <span class="n">empirical_attention_mask</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokens_prompt_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_list</span><span class="p">(</span><span class="n">tokens_prompt_unpadded</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">generate_kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;prompt_token_ids&quot;</span><span class="p">:</span> <span class="n">tokens_prompt_list</span><span class="p">})</span>

        <span class="c1"># Call generate based on model type</span>
        <span class="n">request_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_generate</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">generate_kwargs</span><span class="p">)</span>

        <span class="n">request_output_tc</span> <span class="o">=</span> <span class="n">_RequestOutput_tc</span><span class="o">.</span><span class="n">from_request_output</span><span class="p">(</span><span class="n">request_output</span><span class="p">)</span>

        <span class="c1"># Extract response tokens and text</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">request_output_tc</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">request_output_tc</span><span class="o">.</span><span class="n">outputs</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="n">tokens_response_padded</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;token_ids&quot;</span><span class="p">,</span>
                <span class="n">as_padded_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_padded</span><span class="p">(</span><span class="n">tokens_response_padded</span><span class="p">)</span>
        <span class="n">tokens_response_unpadded</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="s2">&quot;token_ids&quot;</span><span class="p">,</span>
            <span class="n">as_list</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_not_padded</span><span class="p">(</span><span class="n">tokens_response_unpadded</span><span class="p">)</span>

        <span class="n">tokens_obj</span> <span class="o">=</span> <span class="n">Tokens</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_padded</span><span class="p">(</span><span class="n">tokens_response_padded</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_padded</span><span class="p">(</span><span class="n">tokens_prompt_padded</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_not_padded</span><span class="p">(</span><span class="n">tokens_response_unpadded</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_not_padded</span><span class="p">(</span><span class="n">tokens_prompt_unpadded</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># replicate tokens</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">):</span>
                <span class="n">tokens_obj</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">tokens_prompt_unpadded</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span>
                    <span class="k">else</span> <span class="n">tokens_prompt_padded</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokens_obj</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">tokens_prompt_unpadded</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span> <span class="k">else</span> <span class="n">tokens_prompt_padded</span>
            <span class="p">)</span>
        <span class="k">with</span> <span class="n">tokens_obj</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="n">tokens_obj_flat</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">tokens_response_padded</span>
                <span class="n">tokens_full_padded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cat_tensors</span><span class="p">(</span>
                    <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">prompt</span><span class="p">,</span> <span class="n">tokens_response_padded</span>
                <span class="p">)</span>
                <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">tokens_full_padded</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">tokens_response_unpadded</span>
                <span class="n">tokens_full_unpadded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cat_tensors</span><span class="p">(</span>
                    <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">,</span> <span class="n">as_list</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                    <span class="n">tokens_response_unpadded</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">tokens_full_unpadded</span>
        <span class="n">tokens_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="n">tokens_obj</span><span class="p">)</span>

        <span class="n">masks_obj</span> <span class="o">=</span> <span class="n">Masks</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
        <span class="c1"># self.return_tokens must be True</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="c1"># Get &quot;real&quot; attention masks</span>
            <span class="n">full_attention_mask_padded</span> <span class="o">=</span> <span class="n">tokens_obj</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;full&quot;</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_attention_mask</span> <span class="o">=</span> <span class="n">full_attention_mask_padded</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Get &quot;real&quot; attention masks</span>
            <span class="c1"># We can use select to avoid batch-size problems</span>
            <span class="n">_td</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span>
                <span class="n">out</span><span class="o">.</span><span class="n">select</span><span class="p">((</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">))</span>
                <span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="o">.</span><span class="n">rename_key_</span><span class="p">((</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">),</span> <span class="s2">&quot;all_attention_mask&quot;</span><span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
            <span class="k">del</span> <span class="n">_td</span><span class="p">[</span><span class="s2">&quot;tokens&quot;</span><span class="p">]</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_td</span><span class="p">)</span>
        <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_assistant_mask</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">masks_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">masks_key</span><span class="p">,</span> <span class="n">masks_obj</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_log_probs</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                <span class="n">log_probs_padded</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s2">&quot;logprobs&quot;</span><span class="p">,</span>
                    <span class="n">as_padded_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">,</span>
                    <span class="n">padding_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">,</span>
                    <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">log_probs_list</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s2">&quot;logprobs&quot;</span><span class="p">,</span>
                    <span class="n">as_list</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_check_not_padded</span><span class="p">(</span><span class="n">log_probs_list</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># TODO: this is not correct, we should use the prompt_logprobs</span>
                <span class="c1">#  but they&#39;re not returned by vLLM</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                    <span class="n">prompt_logprobs_padded</span> <span class="o">=</span> <span class="n">request_output_tc</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                        <span class="s2">&quot;prompt_logprobs&quot;</span><span class="p">,</span>
                        <span class="n">as_padded_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">,</span>
                        <span class="n">padding_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">,</span>
                        <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="n">prompt_logprobs_padded</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                        <span class="o">!=</span> <span class="n">tokens_prompt_padded</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="p">):</span>
                        <span class="n">tshape</span> <span class="o">=</span> <span class="n">tokens_prompt_padded</span><span class="o">.</span><span class="n">shape</span>
                        <span class="n">oshape</span> <span class="o">=</span> <span class="n">prompt_logprobs_padded</span><span class="o">.</span><span class="n">shape</span>
                        <span class="c1"># it could be that the input was padded already - padding again then</span>
                        <span class="n">prompt_logprobs_padded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                            <span class="p">[</span>
                                <span class="n">prompt_logprobs_padded</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span>
                                    <span class="n">tshape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">tshape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">oshape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],)</span>
                                <span class="p">),</span>
                                <span class="n">prompt_logprobs_padded</span><span class="p">,</span>
                            <span class="p">],</span>
                            <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                        <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">prompt_logprobs_list</span> <span class="o">=</span> <span class="n">request_output_tc</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                        <span class="s2">&quot;prompt_logprobs&quot;</span><span class="p">,</span>
                        <span class="n">as_list</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_check_not_padded</span><span class="p">(</span><span class="n">prompt_logprobs_list</span><span class="p">)</span>
            <span class="n">log_probs_obj</span> <span class="o">=</span> <span class="n">LogProbs</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_check_padded</span><span class="p">(</span><span class="n">log_probs_padded</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_check_padded</span><span class="p">(</span><span class="n">prompt_logprobs_padded</span><span class="p">)</span>
                    <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt_logprobs_padded</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_check_not_padded</span><span class="p">(</span><span class="n">log_probs_list</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_check_not_padded</span><span class="p">(</span><span class="n">prompt_logprobs_list</span><span class="p">)</span>
                    <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt_logprobs_list</span>
            <span class="k">with</span> <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="n">log_probs_obj_flat</span><span class="p">:</span>
                <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">log_probs_padded</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span> <span class="k">else</span> <span class="n">log_probs_list</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                        <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cat_tensors</span><span class="p">(</span>
                            <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">prompt</span><span class="p">,</span> <span class="n">log_probs_padded</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cat_tensors</span><span class="p">(</span>
                            <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">,</span> <span class="n">as_list</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                            <span class="n">log_probs_list</span><span class="p">,</span>
                        <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
            <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_probs_key</span><span class="p">,</span> <span class="n">log_probs_obj</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_logprobs_from_tokens</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">response_struct</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tokens_full_unpadded</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tokens_full_padded</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sampling_params</span><span class="p">:</span> <span class="n">Any</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute log-probs from tokens input.&quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">response_struct</span><span class="p">,</span> <span class="p">(</span><span class="n">TensorDictBase</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;response_struct must be TensorDictBase or None, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">response_struct</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">tokens_full_unpadded</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;tokens_full_unpadded must be list or None, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">tokens_full_unpadded</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">tokens_full_padded</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;tokens_full_padded must be torch.Tensor or None, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">tokens_full_padded</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">sampling_params</span><span class="p">,</span> <span class="p">(</span><span class="n">SamplingParams</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;sampling_params must be SamplingParams or None, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">sampling_params</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">out</span><span class="p">,</span> <span class="p">(</span><span class="n">TensorDictBase</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;out must be TensorDictBase or None, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">out</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="c1"># Convert to list format for vLLM</span>
        <span class="k">if</span> <span class="n">response_struct</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tokens_full_padded</span> <span class="o">=</span> <span class="n">response_struct</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;input_ids&quot;</span><span class="p">,</span>
                <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">response_struct</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span>
                <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
            <span class="n">attention_mask_full_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                <span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">tokens_full_unpadded</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tokens_full_padded</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
                <span class="n">tokens_full_unpadded</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">,</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">attention_mask_full_unpadded</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">t</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens_full_unpadded</span>
            <span class="p">]</span>
            <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
                <span class="n">attention_mask_full_unpadded</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">tokens_full_padded</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">tokens_full_padded</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Either response_struct or tokens must be provided&quot;</span><span class="p">)</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens_full_padded</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">tokens_full_unpadded</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tokens_full_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_list</span><span class="p">(</span>
                <span class="n">tokens_full_padded</span><span class="p">,</span> <span class="n">attention_mask_full_padded</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokens_full_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_list</span><span class="p">(</span><span class="n">tokens_full_unpadded</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="n">generate_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;sampling_params&quot;</span><span class="p">:</span> <span class="n">sampling_params</span><span class="p">,</span>
            <span class="s2">&quot;prompt_token_ids&quot;</span><span class="p">:</span> <span class="n">tokens_full_list</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="c1"># Generate with vLLM to get prompt_logprobs</span>
        <span class="n">tokens_out_stuct</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_generate</span><span class="p">(</span><span class="o">**</span><span class="n">generate_kwargs</span><span class="p">)</span>

        <span class="n">request_output_tc</span> <span class="o">=</span> <span class="n">_RequestOutput_tc</span><span class="o">.</span><span class="n">from_request_output</span><span class="p">(</span><span class="n">tokens_out_stuct</span><span class="p">)</span>

        <span class="c1"># For unpadded case, extract from each sequence</span>
        <span class="n">log_probs_full_unpadded</span> <span class="o">=</span> <span class="n">request_output_tc</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt_logprobs&quot;</span><span class="p">,</span> <span class="n">as_list</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Extract log-probs from prompt_logprobs</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="c1"># For padded case, use all prompt_logprobs</span>
            <span class="k">if</span> <span class="n">attention_mask_full_padded</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">tokens_full_padded</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span>
            <span class="n">log_probs_full_padded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span>
                <span class="n">tokens_full_padded</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="n">log_probs_full_padded</span><span class="p">[</span><span class="n">attention_mask_full_padded</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="n">log_probs_full_unpadded</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_not_padded</span><span class="p">(</span><span class="n">log_probs_full_unpadded</span><span class="p">)</span>

        <span class="n">assistant_mask_full_padded</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">response_struct</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">assistant_mask_full_padded</span> <span class="o">=</span> <span class="n">response_struct</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;assistant_masks&quot;</span><span class="p">,</span>
                <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">assistant_mask_full_padded</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">assistant_mask_full_padded</span> <span class="o">=</span> <span class="n">assistant_mask_full_padded</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                <span class="n">assistant_mask_full_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                    <span class="n">assistant_mask_full_padded</span><span class="p">,</span>
                    <span class="n">attention_mask_full_padded</span><span class="p">,</span>
                    <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">assistant_mask_full_unpadded</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">assistant_mask_full_unpadded</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">masks_obj</span> <span class="o">=</span> <span class="n">Masks</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
            <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_padded</span><span class="p">(</span><span class="n">attention_mask_full_padded</span><span class="p">)</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask_full_padded</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">assistant_mask_full_padded</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_assistant_mask</span> <span class="o">=</span> <span class="n">assistant_mask_full_padded</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_not_padded</span><span class="p">(</span><span class="n">attention_mask_full_unpadded</span><span class="p">)</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask_full_unpadded</span>
            <span class="k">if</span> <span class="n">assistant_mask_full_unpadded</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_assistant_mask</span> <span class="o">=</span> <span class="n">assistant_mask_full_unpadded</span>
        <span class="n">masks_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">masks_key</span><span class="p">,</span> <span class="n">masks_obj</span><span class="p">)</span>

        <span class="n">tokens_obj</span> <span class="o">=</span> <span class="n">Tokens</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
            <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_padded</span><span class="p">(</span><span class="n">tokens_full_padded</span><span class="p">)</span>
            <span class="n">tokens_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">tokens_full_padded</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokens_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">tokens_full_unpadded</span>
        <span class="n">tokens_obj</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">tokens_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="n">tokens_obj</span><span class="p">)</span>

        <span class="n">log_probs_obj</span> <span class="o">=</span> <span class="n">LogProbs</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
            <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_padded</span><span class="p">(</span><span class="n">log_probs_full_padded</span><span class="p">)</span>
            <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">log_probs_full_padded</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_not_padded</span><span class="p">(</span><span class="n">log_probs_full_unpadded</span><span class="p">)</span>
            <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">log_probs_full_unpadded</span>
        <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_probs_key</span><span class="p">,</span> <span class="n">log_probs_obj</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_to_list</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tokens_padded</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">attention_mask_padded</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts a tensor of integers into a masked list (of lists) of integers.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens_padded</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">parent</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">queue</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">attention_mask_padded</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">attention_mask_padded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">tokens_padded</span><span class="p">)</span>
            <span class="n">queue</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">tokens_padded</span><span class="p">,</span> <span class="n">attention_mask_padded</span><span class="o">.</span><span class="n">bool</span><span class="p">(),</span> <span class="n">parent</span><span class="p">))</span>
            <span class="k">while</span> <span class="n">queue</span><span class="p">:</span>
                <span class="n">token_tensor</span><span class="p">,</span> <span class="n">attention_mask_bool</span><span class="p">,</span> <span class="n">_parent</span> <span class="o">=</span> <span class="n">queue</span><span class="o">.</span><span class="n">popleft</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">token_tensor</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">_parent</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">token_tensor</span><span class="p">[</span><span class="n">attention_mask_bool</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">_parent</span><span class="o">.</span><span class="n">extend</span><span class="p">([[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">token_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])])</span>
                    <span class="n">queue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                        <span class="p">[</span>
                            <span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">local_parent</span><span class="p">)</span>
                            <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">local_parent</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                                <span class="n">token_tensor</span><span class="p">,</span> <span class="n">attention_mask_bool</span><span class="p">,</span> <span class="n">_parent</span>
                            <span class="p">)</span>
                        <span class="p">]</span>
                    <span class="p">)</span>
            <span class="n">tokens_list</span> <span class="o">=</span> <span class="n">parent</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens_padded</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">parent</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">queue</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">()</span>
            <span class="n">queue</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">tokens_padded</span><span class="p">,</span> <span class="n">parent</span><span class="p">))</span>
            <span class="k">while</span> <span class="n">queue</span><span class="p">:</span>
                <span class="n">tokens_list</span><span class="p">,</span> <span class="n">_parent</span> <span class="o">=</span> <span class="n">queue</span><span class="o">.</span><span class="n">popleft</span><span class="p">()</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens_list</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span>
                    <span class="n">tokens_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
                <span class="p">):</span>
                    <span class="n">_parent</span><span class="o">.</span><span class="n">extend</span><span class="p">([[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tokens_list</span><span class="p">])</span>
                    <span class="n">queue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                        <span class="p">[</span>
                            <span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">local_parent</span><span class="p">)</span>
                            <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">local_parent</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tokens_list</span><span class="p">,</span> <span class="n">_parent</span><span class="p">)</span>
                        <span class="p">]</span>
                    <span class="p">)</span>
                    <span class="k">continue</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens_list</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                    <span class="n">tokens_list</span> <span class="o">=</span> <span class="n">tokens_list</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                <span class="n">_parent</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">tokens_list</span><span class="p">)</span>
            <span class="n">tokens_list</span> <span class="o">=</span> <span class="n">parent</span>

        <span class="k">return</span> <span class="n">tokens_list</span>

    <span class="nd">@_classproperty</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">CompletionOutput_tc</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">vllm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;vllm is required for CompletionOutput_tc&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="s2">&quot;_CompletionOutput_tc&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_CompletionOutput_tc</span>
        <span class="n">CompletionOutput_tc</span> <span class="o">=</span> <span class="n">from_dataclass</span><span class="p">(</span><span class="n">vllm</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">CompletionOutput</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_CompletionOutput_tc</span> <span class="o">=</span> <span class="n">CompletionOutput_tc</span>
        <span class="k">return</span> <span class="n">CompletionOutput_tc</span>

<div class="viewcode-block" id="vLLMWrapper.get_dist"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.vLLMWrapper.html#torchrl.modules.llm.vLLMWrapper.get_dist">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_dist</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">tensordict_out</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">logits_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="s2">&quot;logits&quot;</span><span class="p">,</span>
        <span class="n">mask_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">as_padded_tensor</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">as_nested_tensor</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">padding_value</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">padding_side</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;right&quot;</span><span class="p">,</span>
        <span class="n">layout</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">layout</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution from logits/log-probs with optional masking.</span>

<span class="sd">        vLLM does not return logits, so this method is not supported.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;vLLM does not return logits, so get_dist is not supported&quot;</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="vLLMWrapper.get_dist_with_prompt_mask"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.vLLMWrapper.html#torchrl.modules.llm.vLLMWrapper.get_dist_with_prompt_mask">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_dist_with_prompt_mask</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">tokens_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">),</span>
        <span class="n">logits_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="s2">&quot;logits&quot;</span><span class="p">,</span>
        <span class="n">assistant_mask_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;masks&quot;</span><span class="p">,</span> <span class="s2">&quot;all_assistant_mask&quot;</span><span class="p">),</span>
        <span class="n">attention_mask_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;masks&quot;</span><span class="p">,</span> <span class="s2">&quot;all_attention_mask&quot;</span><span class="p">),</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution masked to only include response tokens (exclude prompt).</span>

<span class="sd">        vLLM does not return logits, so this method is not supported.</span>

<span class="sd">        This is a provisional method that will be replaced by the `get_dist` method once we have a better masking strategy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;vLLM does not return logits, so get_dist_with_prompt_mask is not supported&quot;</span>
        <span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_dist_with_assistant_mask</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">assistant_mask_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;masks&quot;</span><span class="p">,</span> <span class="s2">&quot;all_assistant_mask&quot;</span><span class="p">),</span>
        <span class="n">logits_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="s2">&quot;logits&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution masked to only include assistant tokens.</span>

<span class="sd">        vLLM does not return logits, so this method is not supported.</span>

<span class="sd">        This is a provisional method that will be replaced by the `get_dist` method once we have a better masking strategy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;vLLM does not return logits, so get_dist_with_assistant_mask is not supported&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_dist_with_attention_mask</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">attention_mask_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;masks&quot;</span><span class="p">,</span> <span class="s2">&quot;all_attention_mask&quot;</span><span class="p">),</span>
        <span class="n">logits_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="s2">&quot;logits&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution masked using attention mask.</span>

<span class="sd">        vLLM does not return logits, so this method is not supported.</span>

<span class="sd">        This is a provisional method that will be replaced by the `get_dist` method once we have a better masking strategy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;vLLM does not return logits, so get_dist_with_attention_mask is not supported&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_dist_with_custom_mask</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">logits_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="s2">&quot;logits&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution with custom mask.</span>

<span class="sd">        vLLM does not return logits, so this method is not supported.</span>

<span class="sd">        This is a provisional method that will be replaced by the `get_dist` method once we have a better masking strategy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;vLLM does not return logits, so get_dist_with_custom_mask is not supported&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Convenience methods for common LLM training scenarios</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_get_sft_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution suitable for SFT loss (response tokens only).</span>

<span class="sd">        vLLM does not return logits, so this method is not supported.</span>

<span class="sd">        This is a provisional method that will be replaced by the `get_dist` method once we have a better masking strategy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;vLLM does not return logits, so get_sft_dist is not supported&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_rlhf_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution suitable for RLHF loss (assistant tokens only).</span>

<span class="sd">        vLLM does not return logits, so this method is not supported.</span>

<span class="sd">        This is a provisional method that will be replaced by the `get_dist` method once we have a better masking strategy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;vLLM does not return logits, so get_rlhf_dist is not supported&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_generic_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution suitable for generic losses (all tokens).</span>

<span class="sd">        vLLM does not return logits, so this method is not supported.</span>

<span class="sd">        This is a provisional method that will be replaced by the `get_dist` method once we have a better masking strategy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;vLLM does not return logits, so get_generic_dist is not supported&quot;</span>
        <span class="p">)</span></div>


<span class="k">class</span><span class="w"> </span><span class="nc">_RequestOutput_tc</span><span class="p">(</span><span class="n">TensorClass</span><span class="p">[</span><span class="s2">&quot;nocast&quot;</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;TensorClass wrapper for vLLM RequestOutput.&quot;&quot;&quot;</span>

    <span class="n">request_id</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">prompt_token_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="n">prompt_logprobs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">Any</span>
    <span class="n">finished</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">metrics</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">lora_request</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">encoder_prompt</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">encoder_prompt_token_ids</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">num_cached_tokens</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">CompletionOutput_tc</span> <span class="o">=</span> <span class="n">vLLMWrapper</span><span class="o">.</span><span class="n">CompletionOutput_tc</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">postproc</span><span class="p">(</span><span class="n">output</span><span class="p">):</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">get_logprob</span><span class="p">(</span><span class="n">output</span><span class="p">):</span>
                <span class="n">t</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">token_ids</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">token_ids</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">token_ids</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                    <span class="n">token_ids</span> <span class="o">=</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">v</span><span class="p">,</span> <span class="n">tid</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">logprobs</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">):</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">v</span><span class="p">[</span><span class="n">tid</span><span class="p">][</span><span class="s2">&quot;logprob&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">v</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;logprob&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mf">0.0</span>
                    <span class="p">)</span>
                <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">output</span><span class="o">.</span><span class="n">logprobs</span><span class="p">:</span>
                <span class="n">output</span><span class="o">.</span><span class="n">logprobs</span> <span class="o">=</span> <span class="n">get_logprob</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
            <span class="n">output</span><span class="o">.</span><span class="n">token_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">token_ids</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">output</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">postproc</span><span class="p">(</span><span class="n">from_dataclass</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dest_cls</span><span class="o">=</span><span class="n">CompletionOutput_tc</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span>
            <span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Check if we can stack the outputs (they should have the same shape)</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">lazy_stack</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
                    <span class="c1"># If stacking fails (different sizes), keep as list</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_request_output</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">requests</span><span class="p">:</span> <span class="n">RequestOutput</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">RequestOutput</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_RequestOutput_tc</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">_RequestOutput_tc</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create _RequestOutput_tc from vLLM RequestOutput.&quot;&quot;&quot;</span>
        <span class="c1"># Type assertions</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">requests</span><span class="p">,</span> <span class="p">(</span><span class="n">RequestOutput</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;requests must be RequestOutput or list, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">requests</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="c1"># Check if we can stack the outputs</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">lazy_stack</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="bp">cls</span><span class="p">(</span>
                        <span class="n">request_id</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">request_id</span><span class="p">,</span>
                        <span class="n">prompt</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">prompt</span><span class="p">,</span>
                        <span class="n">prompt_token_ids</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">prompt_token_ids</span><span class="p">),</span>
                        <span class="n">prompt_logprobs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                            <span class="p">[</span>
                                <span class="n">v</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">tid</span><span class="p">)]</span><span class="o">.</span><span class="n">logprob</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mf">0.0</span>
                                <span class="k">for</span> <span class="n">v</span><span class="p">,</span> <span class="n">tid</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span>
                                    <span class="n">request</span><span class="o">.</span><span class="n">prompt_logprobs</span><span class="p">,</span> <span class="n">request</span><span class="o">.</span><span class="n">prompt_token_ids</span>
                                <span class="p">)</span>
                            <span class="p">]</span>
                        <span class="p">)</span>
                        <span class="k">if</span> <span class="n">request</span><span class="o">.</span><span class="n">prompt_logprobs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([]),</span>
                        <span class="n">outputs</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">outputs</span><span class="p">,</span>
                        <span class="n">finished</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">finished</span><span class="p">,</span>
                        <span class="n">metrics</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">metrics</span><span class="p">,</span>
                        <span class="n">lora_request</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">lora_request</span><span class="p">,</span>
                        <span class="n">encoder_prompt</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">encoder_prompt</span><span class="p">,</span>
                        <span class="n">encoder_prompt_token_ids</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">encoder_prompt_token_ids</span><span class="p">,</span>
                        <span class="n">num_cached_tokens</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">num_cached_tokens</span><span class="p">),</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">request</span> <span class="ow">in</span> <span class="n">requests</span>
                <span class="p">]</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">out</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
            <span class="c1"># If stacking fails, return a list of individual _RequestOutput_tc objects</span>
            <span class="k">return</span> <span class="p">[</span>
                <span class="bp">cls</span><span class="p">(</span>
                    <span class="n">request_id</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">request_id</span><span class="p">,</span>
                    <span class="n">prompt</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">prompt</span><span class="p">,</span>
                    <span class="n">prompt_token_ids</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">prompt_token_ids</span><span class="p">),</span>
                    <span class="n">prompt_logprobs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                        <span class="p">[</span>
                            <span class="n">v</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">tid</span><span class="p">)]</span><span class="o">.</span><span class="n">logprob</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mf">0.0</span>
                            <span class="k">for</span> <span class="n">v</span><span class="p">,</span> <span class="n">tid</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span>
                                <span class="n">request</span><span class="o">.</span><span class="n">prompt_logprobs</span><span class="p">,</span> <span class="n">request</span><span class="o">.</span><span class="n">prompt_token_ids</span>
                            <span class="p">)</span>
                        <span class="p">]</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="n">request</span><span class="o">.</span><span class="n">prompt_logprobs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([]),</span>
                    <span class="n">outputs</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">outputs</span><span class="p">,</span>
                    <span class="n">finished</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">finished</span><span class="p">,</span>
                    <span class="n">metrics</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">metrics</span><span class="p">,</span>
                    <span class="n">lora_request</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">lora_request</span><span class="p">,</span>
                    <span class="n">encoder_prompt</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">encoder_prompt</span><span class="p">,</span>
                    <span class="n">encoder_prompt_token_ids</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">encoder_prompt_token_ids</span><span class="p">,</span>
                    <span class="n">num_cached_tokens</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">num_cached_tokens</span><span class="p">),</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">request</span> <span class="ow">in</span> <span class="n">requests</span>
            <span class="p">]</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../../" src="../../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../../" id="documentation_options" src="../../../../../_static/documentation_options.js"></script>
         <script src="../../../../../_static/jquery.js"></script>
         <script src="../../../../../_static/underscore.js"></script>
         <script src="../../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../../../_static/doctools.js"></script>
         <script src="../../../../../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrl = $("#tutorial-type").text();
	      var githubLink = "https://github.com/pytorch/rl/blob/main/tutorials/sphinx-"  + tutorialUrl + ".py",
		  notebookLink = $(".sphx-glr-download-jupyter").find(".download.reference")[0].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/rl/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }

          var overwrite = function(_) {
              if ($(this).length > 0) {
                  $(this)[0].href = "https://github.com/pytorch/rl"
              }
          }
          // PC
          $(".main-menu a:contains('GitHub')").each(overwrite);
          // Mobile
          $(".main-menu a:contains('Github')").each(overwrite);
      });

      
       $(window).ready(function() {
           var original = window.sideMenus.bind;
           var startup = true;
           window.sideMenus.bind = function() {
               original();
               if (startup) {
                   $("#pytorch-right-menu a.reference.internal").each(function(i) {
                       if (this.classList.contains("not-expanded")) {
                           this.nextElementSibling.style.display = "block";
                           this.classList.remove("not-expanded");
                           this.classList.add("expanded");
                       }
                   });
                   startup = false;
               }
           };
       });
    </script>

    


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch Documentation</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">Newsletter</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">Cloud Credit Program</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">Technical Advisory Council</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">Staff</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">Contact Us</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>
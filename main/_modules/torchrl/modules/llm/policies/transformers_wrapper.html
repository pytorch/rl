


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchrl.modules.llm.policies.transformers_wrapper &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','UA-117752657-2');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="../../../../../../versions.html"><span style="font-size:110%">main (0.0.0+unknown) &#x25BC</span></a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/getting-started-0.html">Get started with Environments, TED and transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/getting-started-1.html">Get started with TorchRL’s modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/getting-started-2.html">Getting started with model optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/getting-started-3.html">Get started with data collection and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/getting-started-4.html">Get started with logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/getting-started-5.html">Get started with your own first training loop</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/coding_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/torchrl_demo.html">Introduction to TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/multiagent_ppo.html">Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/torchrl_envs.html">TorchRL envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/pretrained_models.html">Using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/dqn_with_rnn.html">Recurrent DQN: Training recurrent policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/rb_tutorial.html">Using Replay Buffers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/export.html">Exporting TorchRL modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/llm_browser.html">TorchRL LLM: Building Tool-Enabled Environments</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/multiagent_competitive_ddpg.html">Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/coding_ddpg.html">TorchRL objectives: Coding a DDPG loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials/coding_dqn.html">TorchRL trainer: A DQN example</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../reference/index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../reference/knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../../index.html">Module code</a> &gt;</li>
        
      <li>torchrl.modules.llm.policies.transformers_wrapper</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
    
    
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=UA-117752657-2"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torchrl.modules.llm.policies.transformers_wrapper</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">contextlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">threading</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">contextlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">nullcontext</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">copy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Literal</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">lazy_stack</span><span class="p">,</span>
    <span class="n">LazyStackedTensorDict</span><span class="p">,</span>
    <span class="n">MetaData</span><span class="p">,</span>
    <span class="n">NonTensorStack</span><span class="p">,</span>
    <span class="n">set_list_to_stack</span><span class="p">,</span>
    <span class="n">TensorDict</span><span class="p">,</span>
    <span class="n">TensorDictBase</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_zip_strict</span><span class="p">,</span> <span class="n">NestedKey</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">distributions</span> <span class="k">as</span> <span class="n">D</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn.utils.rnn</span><span class="w"> </span><span class="kn">import</span> <span class="n">pad_sequence</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span> <span class="k">as</span> <span class="n">torchrl_logger</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.modules.llm.policies.common</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_batching</span><span class="p">,</span>
    <span class="n">_extract_responses_from_full_histories</span><span class="p">,</span>
    <span class="n">ChatHistory</span><span class="p">,</span>
    <span class="n">LLMWrapperBase</span><span class="p">,</span>
    <span class="n">LogProbs</span><span class="p">,</span>
    <span class="n">Masks</span><span class="p">,</span>
    <span class="n">Text</span><span class="p">,</span>
    <span class="n">Tokens</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.modules.utils.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_unpad_tensors</span>


<div class="viewcode-block" id="TransformersWrapper"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.TransformersWrapper.html#torchrl.modules.llm.TransformersWrapper">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">TransformersWrapper</span><span class="p">(</span><span class="n">LLMWrapperBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A wrapper class for Hugging Face Transformers models, providing a consistent interface for text generation and log probability computation.</span>

<span class="sd">    Packing vs Padding:</span>
<span class="sd">        - Packing (`pad_model_input=False`):</span>
<span class="sd">            * More memory efficient for variable-length sequences.</span>
<span class="sd">            * Not all models support packed input (requires custom attention masks and position ids).</span>
<span class="sd">            * May be less compatible with some HuggingFace models or custom architectures.</span>
<span class="sd">        - Padding (`pad_model_input=True`):</span>
<span class="sd">            * Universally supported by all models.</span>
<span class="sd">            * Wastes memory for short sequences in a batch.</span>
<span class="sd">            * Simpler, but less efficient for highly variable-length data.</span>
<span class="sd">        - If unsure, use padding for maximum compatibility. Use packing for large batches of variable-length data and when your model supports it.</span>

<span class="sd">    Additional error handling is provided for empty and overlong sequences.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (transformers.AutoModelForCausalLM | str): The Hugging Face Transformers model to wrap.</span>
<span class="sd">            If a string, it will be passed to `transformers.AutoModelForCausalLM.from_pretrained` (and `AutoTokenizer.from_pretrained`</span>
<span class="sd">            if `tokenizer` is not provided).</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        tokenizer (transformers.tokenization_utils.PreTrainedTokenizer | str | None, optional): The tokenizer to use for</span>
<span class="sd">            encoding and decoding text. If `None`, the tokenizer associated with the model will be used.</span>
<span class="sd">            If a string, it will be passed to `transformers.AutoTokenizer.from_pretrained`. Defaults to `None`.</span>
<span class="sd">        input_mode (str, optional): The input modality to use. Must be one of `&quot;history&quot;`, `&quot;text&quot;`, or `&quot;tokens&quot;`.</span>
<span class="sd">            Defaults to `&quot;history&quot;`.</span>
<span class="sd">        input_key (str | None, optional): The key for the input data. If `None`, defaults to</span>
<span class="sd">            - `(&quot;history&quot;, &quot;prompt&quot;)` for `&quot;history&quot;` when `generate=True`, `(&quot;history&quot;, &quot;full&quot;)` for `&quot;history&quot;` when `generate=False`</span>
<span class="sd">            - `(&quot;text&quot;, &quot;prompt&quot;)` for `&quot;text&quot;` when `generate=True`, `(&quot;text&quot;, &quot;full&quot;)` for `&quot;text&quot;` when `generate=False`</span>
<span class="sd">            - `(&quot;tokens&quot;, &quot;prompt&quot;)` for `&quot;tokens&quot;` when `generate=True`, `(&quot;tokens&quot;, &quot;full&quot;)` for `&quot;tokens&quot;` when `generate=False`</span>
<span class="sd">        attention_mask_key (str, optional): The key for attention masks (used in `&quot;tokens&quot;` mode). Defaults to `&quot;attention_mask&quot;`.</span>

<span class="sd">                    .. warning:: This argument is under development and may change in the future.</span>

<span class="sd">        generate (bool, optional): Whether to enable text generation. If `True`, the model will generate text based on the input.</span>
<span class="sd">            If `False`, only log probabilities will be computed. Defaults to `True`.</span>
<span class="sd">        return_log_probs (bool, optional): Whether to return log probabilities. Defaults to `False`.</span>
<span class="sd">        generate_kwargs (dict | None, optional): Additional arguments to pass to the model&#39;s generate method. Defaults to `None`.</span>

<span class="sd">            **Standardized Parameters (cross-backend compatible):**</span>

<span class="sd">            * **max_new_tokens** (int): Maximum number of new tokens to generate</span>
<span class="sd">            * **num_return_sequences** (int): Number of sequences to return</span>
<span class="sd">            * **temperature** (float): Sampling temperature (0.0 = deterministic, higher = more random)</span>
<span class="sd">            * **top_p** (float): Nucleus sampling parameter (0.0-1.0)</span>
<span class="sd">            * **top_k** (int): Top-k sampling parameter</span>
<span class="sd">            * **repetition_penalty** (float): Penalty for repeating tokens</span>
<span class="sd">            * **do_sample** (bool): Whether to use sampling vs greedy decoding</span>
<span class="sd">            * **num_beams** (int): Number of beams for beam search</span>
<span class="sd">            * **length_penalty** (float): Penalty for sequence length</span>
<span class="sd">            * **early_stopping** (bool): Whether to stop early in beam search</span>
<span class="sd">            * **stop_sequences** (list): Sequences that stop generation (requires custom stopping criteria)</span>
<span class="sd">            * **skip_special_tokens** (bool): Whether to skip special tokens in output</span>
<span class="sd">            * **logprobs** (bool): Whether to return log probabilities (maps to output_scores)</span>

<span class="sd">                .. warning:: Usage of this parameter is discouraged as it may conflict with the `generate` parameter</span>
<span class="sd">                    of the class.</span>

<span class="sd">            **Transformers-Specific Parameters:**</span>

<span class="sd">            * **pad_token_id** (int): Token ID for padding</span>
<span class="sd">            * **eos_token_id** (int): Token ID for end of sequence</span>
<span class="sd">            * **bad_words_ids** (list): List of token IDs to avoid</span>
<span class="sd">            * **force_words_ids** (list): List of token IDs to force</span>
<span class="sd">            * **no_repeat_ngram_size** (int): Size of n-grams to avoid repeating</span>
<span class="sd">            * **encoder_repetition_penalty** (float): Repetition penalty for encoder-decoder models</span>
<span class="sd">            * **num_beam_groups** (int): Number of beam groups for diverse beam search</span>
<span class="sd">            * **diversity_penalty** (float): Penalty for beam diversity</span>
<span class="sd">            * **output_scores** (bool): Whether to output scores</span>
<span class="sd">            * **return_dict_in_generate** (bool): Whether to return dict in generate</span>

<span class="sd">            **Legacy Parameter Support:**</span>

<span class="sd">            * **max_tokens** (int): Automatically converted to max_new_tokens</span>
<span class="sd">            * **n** (int): Automatically converted to num_return_sequences</span>

<span class="sd">            **Parameter Conflict Resolution:**</span>

<span class="sd">            When both legacy (Transformers-specific) and standardized parameter names are provided,</span>
<span class="sd">            a :exc:`ValueError` is raised to prevent confusion. For example:</span>

<span class="sd">            * If both ``max_tokens`` and ``max_new_tokens`` are passed, an error is raised</span>
<span class="sd">            * If both ``n`` and ``num_return_sequences`` are passed, an error is raised</span>

<span class="sd">            This ensures clear parameter usage and prevents unexpected behavior.</span>

<span class="sd">        tokenizer_kwargs (dict | None, optional): Additional arguments to pass to the tokenizer. Defaults to `None`.</span>
<span class="sd">        pad_output (bool, optional): Whether to pad the output sequences to a uniform length. This does not impact the underlying padding</span>
<span class="sd">            during call to the model. To use padding or packing during the model `forward` call, see `pad_model_input`.</span>
<span class="sd">            Defaults to `False`.</span>
<span class="sd">        pad_model_input (bool, optional): Whether to pad the model input sequences to a uniform length.</span>
<span class="sd">            If `False`, packing will be used instead. Packing is generally more memory efficient than padding,</span>
<span class="sd">            but this feature may not work with all models.</span>
<span class="sd">            `pad_model_input` can only be used when `generate=False`.</span>
<span class="sd">            This does not impact the padding of the model output - one may ask for padded output though `pad_output=True` while the model</span>
<span class="sd">            is called with `pad_model_input=False`.</span>
<span class="sd">            Defaults to `True`.</span>
<span class="sd">        inplace (Literal[True, False, &quot;empty&quot;] | None, optional): Determines how the module should handle in-place operations. Defaults to `True`.</span>
<span class="sd">        device (torch.device | None, optional): The device to use for computation. Defaults to `None`.</span>
<span class="sd">        layout (torch.layout | None, optional): The layout to use for the output tensors when `pad_output=False`. Defaults to `torch.strided`.</span>
<span class="sd">        num_samples (int | None, optional): The number of samples to generate. Defaults to `None` (one sample, and no batch-dimension for it).</span>
<span class="sd">            Can also be set via the `generate_kwargs[&quot;num_return_sequences&quot;] = value` argument. Requires the &quot;do_sample&quot; argument to be set to `True` in `generate_kwargs`.</span>
<span class="sd">        chat_template_name (Literal[&quot;chatml_format&quot;, &quot;qwen&quot;] | None, optional): The name of the chat template to use when applying the chat</span>
<span class="sd">            template to the history. Defaults to `None`. For `input_mode=&quot;history&quot;` only.</span>
<span class="sd">        chat_template (str | None, optional): The chat template to use when applying the chat template to the history.</span>
<span class="sd">            Defaults to `None`. For `input_mode=&quot;history&quot;` only.</span>
<span class="sd">        log_probs_key (NestedKey | None, optional): The key for the log probabilities :class:`~torchrl.modules.llm.policies.LogProbs` object. Defaults to `&quot;log_probs&quot;`.</span>
<span class="sd">        text_key (NestedKey | None, optional): The key for the action :class:`~torchrl.modules.llm.policies.Text` object. Defaults to `&quot;text&quot;`.</span>
<span class="sd">        tokens_key (NestedKey | None, optional): The key for the action :class:`~torchrl.modules.llm.policies.Tokens` object. Defaults to `&quot;tokens&quot;`.</span>
<span class="sd">        masks_key (NestedKey | None, optional): The key for the action :class:`~torchrl.modules.llm.policies.Masks` object. Defaults to `&quot;masks&quot;`.</span>
<span class="sd">        history_key (NestedKey | None, optional): The key for the action :class:`~torchrl.modules.llm.policies.ChatHistory` object. Defaults to `&quot;history&quot;`.</span>
<span class="sd">        batching (bool | None, optional): Whether to enable batching. See :ref:`ref_batching` below for more details.</span>
<span class="sd">        min_batch_size (int | None, optional): The minimum batch size to use for batching. See :ref:`ref_batching` below for more details.</span>
<span class="sd">        max_batch_size (int | None, optional): The maximum batch size to use for batching. See :ref:`ref_batching` below for more details.</span>
<span class="sd">        batching_timeout (float, optional): The timeout for batching. See :ref:`ref_batching` below for more details.</span>

<span class="sd">    .. _ref_batching:</span>
<span class="sd">        Batching is a feature that allows the module to process multiple inputs in a single call.</span>
<span class="sd">        It is designed to work in a multi-threaded environment.</span>
<span class="sd">        To enable batching, it suffices to set `batching=True` which will set `min_batch_size` to 1 if not provided.</span>
<span class="sd">        If you want to set a different value for `min_batch_size` or `max_batch_size` for a fine-grained control,</span>
<span class="sd">        you can to set `batching=True` and then set `min_batch_size` or `max_batch_size` to a value greater or equal to 1.</span>
<span class="sd">        The way batching works is as follows:</span>
<span class="sd">        - If `min_batch_size` is not provided but `max_batch_size` is, `min_batch_size` is set to 1.</span>
<span class="sd">        - If `max_batch_size` is not provided but `min_batch_size` is, `max_batch_size` is set to the number of inputs in the queue.</span>
<span class="sd">        - When the model is called, a check is performed to see if the number of inputs in the queue is greater or equal to `min_batch_size`.</span>
<span class="sd">          If it is, the batch is processed immediately, while waiting for the previous batch to be processed if the model is busy.</span>
<span class="sd">          Otherwise, the input is added to the queue and the function waits for the batch to be completed.</span>
<span class="sd">          While waiting for the batch to be completed, a timeout is set to `batching_timeout` seconds such that if the batch is not</span>
<span class="sd">          completed after `batching_timeout` seconds, the remaining items to process are processed as is and the function returns after</span>
<span class="sd">          at most `batching_timeout` seconds (plus the time to finish processing the previous and current batch).</span>

<span class="sd">    Input Keys:</span>
<span class="sd">        The input key depends on both `input_mode` and `generate`:</span>

<span class="sd">        - If `input_mode=&quot;history&quot;` and `generate=True`: `input_key` (defaults to `(&quot;history&quot;, &quot;prompt&quot;)`)</span>
<span class="sd">        - If `input_mode=&quot;history&quot;` and `generate=False`: `input_key` (defaults to `(&quot;history&quot;, &quot;full&quot;)`)</span>
<span class="sd">        - If `input_mode=&quot;text&quot;` and `generate=True`: `input_key` (defaults to `(&quot;text&quot;, &quot;prompt&quot;)`)</span>
<span class="sd">        - If `input_mode=&quot;text&quot;` and `generate=False`: `input_key` (defaults to `(&quot;text&quot;, &quot;full&quot;)`)</span>
<span class="sd">        - If `input_mode=&quot;tokens&quot;` and `generate=True`: `input_key` (defaults to `(&quot;tokens&quot;, &quot;prompt&quot;)`)</span>
<span class="sd">        - If `input_mode=&quot;tokens&quot;` and `generate=False`: `input_key` (defaults to `(&quot;tokens&quot;, &quot;full&quot;)`)</span>

<span class="sd">    Output Keys:</span>
<span class="sd">        The output keys are automatically determined based on the input_mode:</span>
<span class="sd">        - **Tokens**: Always returned (`tokens_key`, defaults to `&quot;tokens&quot;`)</span>
<span class="sd">        - **Text**: Returned for `&quot;text&quot;` and `&quot;history&quot;` modes (`text_key`, defaults to `&quot;text&quot;`)</span>
<span class="sd">        - **History**: Returned only for `&quot;history&quot;` mode (`history_key`, defaults to `&quot;history&quot;`)</span>
<span class="sd">        - **Masks**: Always returned (`masks_key`, defaults to `&quot;masks&quot;`)</span>
<span class="sd">        - **Log Probs**: Returned when `return_log_probs=True` (`log_probs_key`, defaults to `&quot;log_probs&quot;`)</span>

<span class="sd">        Example output structure for `input_mode=&quot;history&quot;`:</span>
<span class="sd">        ```</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            text=Text(prompt=..., response=..., full=...),</span>
<span class="sd">            masks=Masks(all_attention_mask=..., all_assistant_mask=...),</span>
<span class="sd">            tokens=Tokens(prompt=..., response=..., full=...),</span>
<span class="sd">            log_probs=LogProbs(prompt=..., response=..., full=...),</span>
<span class="sd">            history=ChatHistory(prompt=..., response=..., full=...)</span>
<span class="sd">        )</span>
<span class="sd">        ```</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoModelForCausalLM, AutoTokenizer</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data.llm import History</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules.llm.policies import ChatHistory</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; model = AutoModelForCausalLM.from_pretrained(&quot;gpt2&quot;)</span>
<span class="sd">        &gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(&quot;gpt2&quot;)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # History input (recommended for RL environments)</span>
<span class="sd">        &gt;&gt;&gt; wrapper = TransformersWrapper(</span>
<span class="sd">        ...     model,</span>
<span class="sd">        ...     tokenizer=tokenizer,</span>
<span class="sd">        ...     input_mode=&quot;history&quot;,</span>
<span class="sd">        ...     generate=True,</span>
<span class="sd">        ...     return_log_probs=True,</span>
<span class="sd">        ...     generate_kwargs={</span>
<span class="sd">        ...         &quot;max_new_tokens&quot;: 50,  # Standardized parameter</span>
<span class="sd">        ...         &quot;temperature&quot;: 0.7,</span>
<span class="sd">        ...         &quot;top_p&quot;: 0.9,</span>
<span class="sd">        ...         &quot;do_sample&quot;: True,</span>
<span class="sd">        ...     }</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; history = History.from_chats([[</span>
<span class="sd">        ...     {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello&quot;},</span>
<span class="sd">        ...     {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Hi there!&quot;}</span>
<span class="sd">        ... ]])</span>
<span class="sd">        &gt;&gt;&gt; chat_history = ChatHistory(prompt=history)</span>
<span class="sd">        &gt;&gt;&gt; result = wrapper(TensorDict(history=chat_history, batch_size=(1,)))</span>
<span class="sd">        &gt;&gt;&gt; print(result[&quot;text&quot;].response)  # Generated text</span>
<span class="sd">        &gt;&gt;&gt; print(result[&quot;log_probs&quot;].response)  # Log probabilities</span>
<span class="sd">        &gt;&gt;&gt; print(result[&quot;history&quot;].response)  # History with response</span>

<span class="sd">    Attributes:</span>
<span class="sd">        collector: The collector associated with the module, if it exists.</span>

<span class="sd">    .. seealso::</span>
<span class="sd">        - :class:`~torchrl.modules.llm.policies.LLMWrapperBase` (see :ref:`ref_categorical_sequential`)</span>
<span class="sd">        - :class:`~torchrl.modules.llm.policies.vLLMWrapper` (see :ref:`ref_vllm_wrapper`)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">input_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;history&quot;</span><span class="p">,</span>
        <span class="n">input_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attention_mask_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span>
        <span class="n">generate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">generate_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tokenizer_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pad_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">pad_model_input</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">inplace</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;empty&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">layout</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">layout</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">chat_template_name</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;chatml_format&quot;</span><span class="p">,</span> <span class="s2">&quot;qwen&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">chat_template</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_log_probs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">history_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="s2">&quot;history&quot;</span><span class="p">,</span>
        <span class="n">text_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span>
        <span class="n">tokens_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="s2">&quot;tokens&quot;</span><span class="p">,</span>
        <span class="n">masks_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="s2">&quot;masks&quot;</span><span class="p">,</span>
        <span class="n">log_probs_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="s2">&quot;log_probs&quot;</span><span class="p">,</span>
        <span class="n">batching</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">min_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batching_timeout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10.0</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">batching</span> <span class="ow">and</span> <span class="n">min_batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">min_batch_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="p">(</span><span class="n">min_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">max_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="n">batching</span> <span class="ow">is</span> <span class="kc">False</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;min_batch_size and max_batch_size must be None if batching is False.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Validate that min_batch_size &lt;= max_batch_size when both are specified</span>
        <span class="k">if</span> <span class="n">min_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">max_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">min_batch_size</span> <span class="o">&gt;</span> <span class="n">max_batch_size</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;min_batch_size (</span><span class="si">{</span><span class="n">min_batch_size</span><span class="si">}</span><span class="s2">) must be &lt;= max_batch_size (</span><span class="si">{</span><span class="n">max_batch_size</span><span class="si">}</span><span class="s2">)&quot;</span>
                <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_min_batch_size</span> <span class="o">=</span> <span class="n">min_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_max_batch_size</span> <span class="o">=</span> <span class="n">max_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batching_timeout</span> <span class="o">=</span> <span class="n">batching_timeout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_queue</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_futures</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batching</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batching_lock</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Lock</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batching_lock</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>

                <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>

            <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>

            <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>

        <span class="c1"># Validate input_mode</span>
        <span class="k">if</span> <span class="n">input_mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;history&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;tokens&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;input_mode must be one of &#39;history&#39;, &#39;text&#39;, &#39;tokens&#39;. Got &#39;</span><span class="si">{</span><span class="n">input_mode</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_mode</span> <span class="o">=</span> <span class="n">input_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_mask_key</span> <span class="o">=</span> <span class="n">attention_mask_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generate</span> <span class="o">=</span> <span class="n">generate</span>
        <span class="k">if</span> <span class="n">pad_model_input</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">generate</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;pad_model_input is not supported when generate=True.&quot;</span><span class="p">)</span>
        <span class="n">pad_model_input</span> <span class="o">=</span> <span class="n">pad_model_input</span> <span class="k">if</span> <span class="n">pad_model_input</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_model_input</span> <span class="o">=</span> <span class="n">pad_model_input</span>

        <span class="c1"># Auto-determine what to return based on input mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_history</span> <span class="o">=</span> <span class="n">input_mode</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;history&quot;</span><span class="p">,)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_text</span> <span class="o">=</span> <span class="n">input_mode</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;history&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_tokens</span> <span class="o">=</span> <span class="n">input_mode</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;history&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_masks</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="n">return_log_probs</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">generate</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;return_log_probs must be True when generate=False.&quot;</span><span class="p">)</span>
        <span class="n">return_log_probs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="kc">True</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">return_log_probs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">generate</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="n">generate</span><span class="p">)</span>
            <span class="k">else</span> <span class="nb">bool</span><span class="p">(</span><span class="n">return_log_probs</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_log_probs</span> <span class="o">=</span> <span class="n">return_log_probs</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">history_key</span> <span class="o">=</span> <span class="n">history_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_key</span> <span class="o">=</span> <span class="n">text_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span> <span class="o">=</span> <span class="n">tokens_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">masks_key</span> <span class="o">=</span> <span class="n">masks_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_probs_key</span> <span class="o">=</span> <span class="n">log_probs_key</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pad_output</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;pad_output must be a boolean&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span> <span class="o">=</span> <span class="n">pad_output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">pad_output</span> <span class="ow">and</span> <span class="n">layout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">layout</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">strided</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layout</span> <span class="o">=</span> <span class="n">layout</span>
        <span class="n">padding_value</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Auto-determine input_key if not provided</span>

        <span class="c1"># Set input keys based on mode and generate parameter</span>
        <span class="k">if</span> <span class="n">input_mode</span> <span class="o">==</span> <span class="s2">&quot;history&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">generate</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="p">(</span><span class="s2">&quot;history&quot;</span><span class="p">,</span> <span class="s2">&quot;prompt&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_key</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">input_key</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;history&quot;</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_key</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">input_key</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">input_mode</span> <span class="o">==</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">generate</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;prompt&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_key</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">input_key</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_key</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">input_key</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">input_mode</span> <span class="o">==</span> <span class="s2">&quot;tokens&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">generate</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;prompt&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_key</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">input_key</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_key</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">input_key</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Set output keys based on auto-determined return flags</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_text</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_masks</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">masks_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_tokens</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_log_probs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_probs_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_history</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history_key</span><span class="p">)</span>

        <span class="c1"># Tokenizer setup</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tokenizer_kwargs</span><span class="p">:</span>
            <span class="n">tokenizer_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokenizer_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">tokenizer_kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;return_attention_mask&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;return_attention_mask must be True&quot;</span><span class="p">)</span>

        <span class="c1"># We always pad, so we always return tensors</span>
        <span class="n">return_tensors</span> <span class="o">=</span> <span class="s2">&quot;pt&quot;</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;padding&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">return_tensors</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;return_tensors&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="p">)</span>
                <span class="o">!=</span> <span class="n">return_tensors</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span>

        <span class="c1"># We always pad atm</span>
        <span class="k">if</span> <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;padding_side&quot;</span><span class="p">,</span> <span class="s2">&quot;left&quot;</span><span class="p">)</span> <span class="o">!=</span> <span class="s2">&quot;left&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_kwargs</span> <span class="o">=</span> <span class="n">tokenizer_kwargs</span>

        <span class="c1"># Get tokenizer if needed</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">pad_output</span> <span class="ow">or</span> <span class="p">(</span><span class="n">input_mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;history&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">generate</span><span class="p">)</span>
        <span class="p">)</span> <span class="ow">and</span> <span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_tokenizer</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;pad_token&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">padding_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span><span class="p">)[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span> <span class="o">=</span> <span class="n">padding_value</span>

        <span class="c1"># Generate kwargs setup</span>
        <span class="k">if</span> <span class="n">generate_kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">generate_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">generate_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">generate_kwargs</span><span class="p">)</span>

        <span class="c1"># Standardize common parameters</span>
        <span class="n">generate_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_standardize_generate_kwargs</span><span class="p">(</span><span class="n">generate_kwargs</span><span class="p">)</span>

        <span class="c1"># Extract wrapper-specific parameters</span>
        <span class="n">transformers_specific_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_wrapper_specific_kwargs</span><span class="p">(</span>
            <span class="n">generate_kwargs</span><span class="p">,</span> <span class="s2">&quot;transformers&quot;</span>
        <span class="p">)</span>

        <span class="c1"># Convert common parameters to Transformers format</span>
        <span class="n">transformers_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">generate_kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">COMMON_GENERATION_PARAMS</span><span class="p">:</span>
                <span class="c1"># Convert common names to Transformers names</span>
                <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;stop_sequences&quot;</span><span class="p">:</span>
                    <span class="c1"># Transformers uses stopping_criteria for stop sequences</span>
                    <span class="c1"># This requires custom stopping criteria implementation</span>
                    <span class="c1"># For now, we&#39;ll warn and skip this parameter</span>
                    <span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>

                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                        <span class="s2">&quot;stop_sequences parameter is not yet fully supported in TransformersWrapper. &quot;</span>
                        <span class="s2">&quot;Use eos_token_id or implement custom stopping criteria for full support.&quot;</span><span class="p">,</span>
                        <span class="ne">UserWarning</span><span class="p">,</span>
                        <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">continue</span>
                <span class="k">elif</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;logprobs&quot;</span><span class="p">:</span>
                    <span class="n">transformers_kwargs</span><span class="p">[</span><span class="s2">&quot;output_scores&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Direct mapping for other common parameters</span>
                    <span class="n">transformers_kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

        <span class="c1"># Add Transformers-specific parameters</span>
        <span class="n">transformers_kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">transformers_specific_kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="n">num_samples</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">transformers_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;num_return_sequences&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
            <span class="ow">or</span> <span class="n">num_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="n">inplace</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;empty&quot;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;inplace must be False (or None) when generating more than one sample.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">inplace</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">inplace</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">transformers_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;num_return_sequences&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
                <span class="ow">and</span> <span class="n">num_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="ow">and</span> <span class="n">transformers_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;num_return_sequences&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">!=</span> <span class="n">num_samples</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;num_samples differs from generate_kwargs[&#39;n&#39;].&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">num_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="n">transformers_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;num_return_sequences&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">transformers_kwargs</span><span class="p">[</span><span class="s2">&quot;num_return_sequences&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span>
        <span class="k">elif</span> <span class="n">inplace</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span> <span class="o">=</span> <span class="n">inplace</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">generate</span><span class="p">:</span>
            <span class="c1"># We want only the log-probs, we generate a single token (that we then discard)</span>
            <span class="c1"># and retrieve the prompt log-probs</span>
            <span class="n">transformers_kwargs</span><span class="p">[</span><span class="s2">&quot;max_new_tokens&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="n">transformers_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;tokenizer&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>
        <span class="n">transformers_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;output_logits&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_log_probs</span><span class="p">)</span>
        <span class="n">transformers_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;return_dict_in_generate&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">generate_kwargs</span> <span class="o">=</span> <span class="n">transformers_kwargs</span>

        <span class="c1"># Additional transformers-specific settings</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chat_template_name</span> <span class="o">=</span> <span class="n">chat_template_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chat_template</span> <span class="o">=</span> <span class="n">chat_template</span>

        <span class="c1"># Flag to track when we&#39;re in a get_dist call</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span> <span class="o">=</span> <span class="kc">False</span>

<div class="viewcode-block" id="TransformersWrapper.get_new_version"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.TransformersWrapper.html#torchrl.modules.llm.TransformersWrapper.get_new_version">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_new_version</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a new version of the module with altered parameters.</span>

<span class="sd">        For instance, the generate parameter can be altered to enable text generation or log-probabilities computation.</span>
<span class="sd">        This is especially useful when one wants to avoid re-initializing the module with a new set of parameters, when the</span>
<span class="sd">        same parameters could be used to gather log-probs.</span>

<span class="sd">        Positional arguments are not supported.</span>

<span class="sd">        See the class constructor for more details about the parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Build the constructor arguments by using current values for missing parameters</span>
        <span class="n">constructor_kwargs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Model is always required</span>
        <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

        <span class="c1"># Check for each parameter and use current value if not provided</span>
        <span class="k">if</span> <span class="s2">&quot;tokenizer&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;tokenizer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;tokenizer&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;tokenizer&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;tokenizer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span>

        <span class="k">if</span> <span class="s2">&quot;input_mode&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;input_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;input_mode&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;input_mode&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;input_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_mode</span>

        <span class="k">if</span> <span class="s2">&quot;input_key&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;input_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;input_key&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;input_key&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;input_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span>

        <span class="k">if</span> <span class="s2">&quot;attention_mask_key&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;attention_mask_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;attention_mask_key&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;attention_mask_key&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;attention_mask_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_mask_key</span>

        <span class="k">if</span> <span class="s2">&quot;generate&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;generate&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;generate&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;generate&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;generate&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate</span>

        <span class="k">if</span> <span class="s2">&quot;generate_kwargs&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;generate_kwargs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;generate_kwargs&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;generate_kwargs&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;generate_kwargs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_kwargs</span>

        <span class="k">if</span> <span class="s2">&quot;pad_output&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;pad_output&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;pad_output&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;pad_output&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;pad_output&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span>

        <span class="k">if</span> <span class="s2">&quot;tokenizer_kwargs&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;tokenizer_kwargs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;tokenizer_kwargs&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;tokenizer_kwargs&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;tokenizer_kwargs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_kwargs</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="s2">&quot;pad_output&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span>
                <span class="ow">and</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pad_output&quot;</span><span class="p">)</span>
                <span class="o">!=</span> <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;tokenizer_kwargs&quot;</span><span class="p">][</span><span class="s2">&quot;padding&quot;</span><span class="p">]</span>
            <span class="p">):</span>
                <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;tokenizer_kwargs&quot;</span><span class="p">][</span><span class="s2">&quot;padding&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s2">&quot;pad_output&quot;</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;inplace&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;inplace&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;inplace&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;inplace&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;inplace&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span>

        <span class="k">if</span> <span class="s2">&quot;device&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_device&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>

        <span class="k">if</span> <span class="s2">&quot;layout&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;layout&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;layout&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;layout&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;layout&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layout</span>

        <span class="k">if</span> <span class="s2">&quot;num_samples&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;num_samples&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;num_samples&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;num_samples&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;num_samples&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span>

        <span class="k">if</span> <span class="s2">&quot;chat_template_name&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;chat_template_name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;chat_template_name&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;chat_template_name&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;chat_template_name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template_name</span>

        <span class="k">if</span> <span class="s2">&quot;chat_template&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;chat_template&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;chat_template&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;chat_template&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;chat_template&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template</span>

        <span class="k">if</span> <span class="s2">&quot;text_key&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;text_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;text_key&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;text_key&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;text_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_key</span>

        <span class="k">if</span> <span class="s2">&quot;tokens_key&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;tokens_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;tokens_key&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;tokens_key&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;tokens_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span>

        <span class="k">if</span> <span class="s2">&quot;masks_key&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;masks_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;masks_key&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;masks_key&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;masks_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">masks_key</span>

        <span class="k">if</span> <span class="s2">&quot;log_probs_key&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;log_probs_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;log_probs_key&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;log_probs_key&quot;</span><span class="p">):</span>
            <span class="n">constructor_kwargs</span><span class="p">[</span><span class="s2">&quot;log_probs_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_probs_key</span>

        <span class="c1"># Create and return new instance</span>
        <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)(</span><span class="o">**</span><span class="n">constructor_kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="TransformersWrapper.forward"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.TransformersWrapper.html#torchrl.modules.llm.TransformersWrapper.forward">[docs]</a>    <span class="nd">@set_list_to_stack</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="nd">@_batching</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tensordict_out</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">logits_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">tensordict_orig</span> <span class="o">=</span> <span class="n">tensordict</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">tensordict_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;tensordict_out must not be provided when tensordict.ndim == 0. If this is needed, &quot;</span>
                    <span class="s2">&quot;please submit an issue on github.&quot;</span>
                <span class="p">)</span>
            <span class="c1"># unsqueeze - squeeze the input</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">lazy_stack</span><span class="p">([</span><span class="n">tensordict</span><span class="p">]),</span> <span class="n">logits_only</span><span class="o">=</span><span class="n">logits_only</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">tensordict_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;tensordict_out must not be provided when tensordict.ndim &gt; 1. If this is needed, &quot;</span>
                    <span class="s2">&quot;please submit an issue on github.&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">logits_only</span><span class="o">=</span><span class="n">logits_only</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                <span class="n">tensordict</span><span class="o">.</span><span class="n">shape</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">):</span>
            <span class="n">tensordict</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">_source_device</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">:</span>
            <span class="n">_source_device</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">device</span>
        <span class="k">if</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
            <span class="n">tensordict</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">GenerationConfig</span>

            <span class="n">cfg</span> <span class="o">=</span> <span class="n">GenerationConfig</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cfg</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">TensorDict</span><span class="p">(</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">tensordict</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="p">(</span>
                        <span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">,</span>
                        <span class="o">*</span><span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>
                    <span class="p">),</span>
                <span class="p">)</span>
                <span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span>
                <span class="n">device</span><span class="o">=</span><span class="n">tensordict</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_mode</span> <span class="o">==</span> <span class="s2">&quot;history&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_transformers_generate_history</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_transformers_logprobs_history</span><span class="p">(</span>
                    <span class="n">tensordict</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">logits_only</span><span class="o">=</span><span class="n">logits_only</span>
                <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_mode</span> <span class="o">==</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_transformers_generate_text</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_transformers_logprobs_text</span><span class="p">(</span>
                    <span class="n">tensordict</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">logits_only</span><span class="o">=</span><span class="n">logits_only</span>
                <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_mode</span> <span class="o">==</span> <span class="s2">&quot;tokens&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_transformers_generate_tokens</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_transformers_logprobs_tokens</span><span class="p">(</span>
                    <span class="n">tensordict</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">logits_only</span><span class="o">=</span><span class="n">logits_only</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">_source_device</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">_source_device</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">tensordict_out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="c1"># The output is the input</span>
                <span class="n">tensordict_out</span> <span class="o">=</span> <span class="n">tensordict_orig</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="c1"># The output is the new structure</span>
                <span class="n">tensordict_out</span> <span class="o">=</span> <span class="n">out</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span> <span class="o">==</span> <span class="s2">&quot;empty&quot;</span><span class="p">:</span>
                <span class="c1"># The output is empty</span>
                <span class="n">tensordict_out</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">tensordict_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">tensordict_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">out</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">tensordict_out</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">result</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">keys_to_update</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">tensordict_out</span> <span class="ow">is</span> <span class="n">out</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">out</span>
            <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">))))</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="n">result</span><span class="p">,</span> <span class="n">keys_to_update</span><span class="o">=</span><span class="n">keys</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">out</span>
        <span class="k">return</span> <span class="n">result</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_from_transformers_generate_history</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">td</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate text from history input.&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data.llm</span><span class="w"> </span><span class="kn">import</span> <span class="n">History</span>

        <span class="c1"># Validate input</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">td</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39; key for history input mode, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but found keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">history</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">History</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected History object for &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39;, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">history</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Apply chat template</span>
        <span class="n">tokenizer_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;chat_template_name&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;chat_template&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template</span><span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;add_generation_prompt&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">text_prompt</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="o">**</span><span class="n">tokenizer_kwargs</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text_prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected list of text for history input, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">text_prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;return_assistant_tokens_mask&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;tokenize&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;padding&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;return_dict&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">response_struct</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="o">**</span><span class="n">tokenizer_kwargs</span>
        <span class="p">)</span>
        <span class="n">tokens_prompt_padded</span> <span class="o">=</span> <span class="n">response_struct</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="s2">&quot;input_ids&quot;</span><span class="p">,</span>
            <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">padding_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">,</span>
            <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">attention_mask_prompt_padded</span> <span class="o">=</span> <span class="n">response_struct</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span>
            <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">padding_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">attention_mask_prompt_padded</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">attention_mask_prompt_padded</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">tokens_prompt_padded</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>
            <span class="p">)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_from_tokens</span><span class="p">(</span>
            <span class="n">tokens_prompt_padded</span><span class="p">,</span> <span class="n">attention_mask_prompt_padded</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">out</span>
        <span class="p">)</span>

        <span class="c1"># Generate using text path</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="n">result</span><span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="s2">&quot;prompt&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">tokens_prompt_padded</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span>
                <span class="k">else</span> <span class="n">tokens_prompt_padded</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokens_prompt_unpadded</span> <span class="o">=</span> <span class="n">response_struct</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;input_ids&quot;</span><span class="p">,</span>
                <span class="n">as_nested_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">:</span>
                <span class="n">result</span><span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="s2">&quot;prompt&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="n">tokens_prompt_unpadded</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
                    <span class="n">r</span><span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="s2">&quot;prompt&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="n">tokens_prompt_unpadded</span>

        <span class="n">text_result</span> <span class="o">=</span> <span class="n">Text</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
        <span class="n">result</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="n">text_result</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">:</span>
            <span class="n">text_result</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">text_prompt</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">r</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="s2">&quot;prompt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">text_prompt</span>
        <span class="k">with</span> <span class="n">result</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="n">result_flat</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                <span class="n">tokens_full_padded</span> <span class="o">=</span> <span class="n">result_flat</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">),</span>
                    <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
                    <span class="n">padding_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">tokens_full_padded</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;tokens_full_padded is None&quot;</span><span class="p">)</span>
                <span class="n">text_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span>
                    <span class="n">tokens_full_padded</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tokens_full_unpadded</span> <span class="o">=</span> <span class="n">result_flat</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">),</span> <span class="n">as_list</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">tokens_full_unpadded</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;tokens_full_unpadded is None&quot;</span><span class="p">)</span>
                <span class="n">text_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span>
                    <span class="n">tokens_full_unpadded</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
            <span class="n">text_prompt</span> <span class="o">=</span> <span class="n">result_flat</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="s2">&quot;prompt&quot;</span><span class="p">]</span>
            <span class="n">text_response</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">txt</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span> <span class="p">:]</span>
                <span class="k">for</span> <span class="n">txt</span><span class="p">,</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="n">text_full</span><span class="p">,</span> <span class="n">text_prompt</span><span class="p">)</span>
            <span class="p">]</span>
            <span class="n">result_flat</span><span class="o">.</span><span class="n">set</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">),</span> <span class="n">text_full</span><span class="p">)</span>
            <span class="n">result_flat</span><span class="o">.</span><span class="n">set</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="s2">&quot;response&quot;</span><span class="p">),</span> <span class="n">text_response</span><span class="p">)</span>
        <span class="c1"># Now parse the full text back to a history object, and use the extra history objects</span>
        <span class="c1"># as response</span>
        <span class="n">history_chat</span> <span class="o">=</span> <span class="n">ChatHistory</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">history_chat</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">history</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">history_chat</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">h</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">history</span>
        <span class="k">with</span> <span class="n">history_chat</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="n">history_chat_flat</span><span class="p">:</span>
            <span class="n">prompt_histories</span> <span class="o">=</span> <span class="n">history_chat_flat</span><span class="o">.</span><span class="n">prompt</span>
            <span class="c1"># Extract response histories from full text</span>
            <span class="n">h_responses</span> <span class="o">=</span> <span class="n">_extract_responses_from_full_histories</span><span class="p">(</span>
                <span class="n">text_full</span><span class="p">,</span> <span class="n">prompt_histories</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span>
            <span class="p">)</span>
            <span class="n">history_chat_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">h_responses</span>
        <span class="n">result</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history_key</span><span class="p">,</span> <span class="n">history_chat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_from_transformers_logprobs_history</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">td</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">logits_only</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute log-probs from history input.&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data.llm</span><span class="w"> </span><span class="kn">import</span> <span class="n">History</span>

        <span class="c1"># Validate input</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">td</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39; key for history input mode, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but found keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">history</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">History</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected History object for &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39;, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">history</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Apply chat template</span>
        <span class="n">tokenizer_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;chat_template_name&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;chat_template&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_template</span><span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;add_generation_prompt&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">text_full</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="o">**</span><span class="n">tokenizer_kwargs</span>
        <span class="p">)</span>

        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;return_assistant_tokens_mask&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;tokenize&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;padding&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;return_dict&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">nullcontext</span><span class="p">():</span>
            <span class="n">response_tokens</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
                <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="o">**</span><span class="n">tokenizer_kwargs</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">response_tokens</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected TensorDictBase for history input, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">response_tokens</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logprobs_from_history_tokens</span><span class="p">(</span>
            <span class="n">response_tokens</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">logits_only</span><span class="o">=</span><span class="n">logits_only</span>
        <span class="p">)</span>
        <span class="n">text_result</span> <span class="o">=</span> <span class="n">Text</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
        <span class="n">result</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="n">text_result</span><span class="p">)</span>
        <span class="n">result</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">text_full</span>
        <span class="n">result</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history_key</span><span class="p">,</span> <span class="n">ChatHistory</span><span class="p">(</span><span class="n">full</span><span class="o">=</span><span class="n">history</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_cat_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">response_text</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Concatenate text and response text.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_cat_text</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">t_</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">t_</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">response_text</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">text</span> <span class="o">+</span> <span class="n">response_text</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_from_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate text from text input.&quot;&quot;&quot;</span>
        <span class="n">pad_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>

        <span class="c1"># Convert text to list format</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="n">text</span><span class="p">]</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="n">tokenizer_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_kwargs</span><span class="p">)</span>
        <span class="n">tokenizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;padding&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>
        <span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">nullcontext</span><span class="p">():</span>
            <span class="n">tokens_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="o">**</span><span class="n">tokenizer_kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tokens_in</span> <span class="o">=</span> <span class="n">tokens_in</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
        <span class="c1"># We are going to map this tokens_in to a tensordict to facilitate the padding in case we need it</span>
        <span class="n">tokens_in</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">tokens_in</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">dict</span><span class="p">(</span><span class="n">tokens_in</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                    <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nested</span><span class="o">.</span><span class="n">nested_tensor</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nested</span><span class="o">.</span><span class="n">nested_tensor</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">v</span><span class="p">])</span>
            <span class="n">tokens_in</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
        <span class="n">tokens_in</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">tokens_in</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
            <span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">tokens_in</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">tokens_prompt_padded</span> <span class="o">=</span> <span class="n">tokens_in</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="s2">&quot;input_ids&quot;</span><span class="p">,</span>
            <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="n">padding_value</span><span class="o">=</span><span class="n">pad_val</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">attention_mask_prompt_padded</span> <span class="o">=</span> <span class="n">tokens_in</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span>
            <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="n">padding_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">cfg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">generate_kwargs</span><span class="p">)</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;generation_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cfg</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_kwargs</span>

        <span class="n">tokens_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="n">tokens_prompt_padded</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask_prompt_padded</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">tokens_full_padded</span> <span class="o">=</span> <span class="n">tokens_out</span><span class="p">[</span><span class="s2">&quot;sequences&quot;</span><span class="p">]</span>
        <span class="n">tokens_response_padded</span> <span class="o">=</span> <span class="n">tokens_full_padded</span><span class="p">[</span>
            <span class="o">...</span><span class="p">,</span> <span class="n">tokens_prompt_padded</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">:</span>
        <span class="p">]</span>

        <span class="n">attention_mask_response_padded</span> <span class="o">=</span> <span class="n">tokens_response_padded</span> <span class="o">!=</span> <span class="n">pad_val</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">:</span>
            <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">attention_mask_prompt_padded</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span>
                    <span class="p">),</span>
                    <span class="n">attention_mask_response_padded</span><span class="p">,</span>
                <span class="p">],</span>
                <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">attention_mask_prompt_padded</span><span class="p">,</span> <span class="n">attention_mask_response_padded</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
            <span class="p">)</span>
        <span class="n">tokens_response_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
            <span class="n">tokens_response_padded</span><span class="p">,</span> <span class="n">attention_mask_response_padded</span><span class="p">,</span> <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_log_probs</span><span class="p">:</span>
            <span class="c1"># These are only for the new tokens, not for the prompt - to get that, we&#39;d need to run the forward pass again</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">tokens_out</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]),</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">log_probs</span><span class="p">,</span> <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_probs_generate</span><span class="p">(</span>
                <span class="n">tokens_response_padded</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">pad_val</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>

        <span class="n">response_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span>
            <span class="n">tokens_response_unpadded</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="c1"># Build output TensorClass objects</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="n">txt</span> <span class="k">for</span> <span class="n">txt</span> <span class="ow">in</span> <span class="n">text</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">)]</span>
        <span class="n">text_obj</span> <span class="o">=</span> <span class="n">Text</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
        <span class="k">with</span> <span class="n">text_obj</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="n">text_obj_flat</span><span class="p">:</span>
            <span class="n">text_obj_flat</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">text</span>
            <span class="n">text_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">response_text</span>
            <span class="n">text_obj_flat</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cat_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">response_text</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="n">text_obj</span><span class="p">)</span>

        <span class="n">tokens_obj</span> <span class="o">=</span> <span class="n">Tokens</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="n">tokens_prompt_padded</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                <span class="n">tokens_prompt_padded</span><span class="p">,</span> <span class="n">attention_mask_prompt_padded</span><span class="p">,</span> <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">tokens_obj</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">):</span>
                <span class="n">tokens_obj</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokens_obj</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span>
        <span class="k">with</span> <span class="n">tokens_obj</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="n">tokens_obj_flat</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">tokens_response_unpadded</span>
                <span class="n">tokens_full_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                    <span class="n">tokens_full_padded</span><span class="p">,</span> <span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
                <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">tokens_full_unpadded</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">tokens_response_padded</span>
                <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">tokens_full_padded</span>
        <span class="n">tokens_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="n">tokens_obj</span><span class="p">)</span>

        <span class="n">masks_obj</span> <span class="o">=</span> <span class="n">Masks</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">out</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">attention_mask_full_padded</span><span class="o">.</span><span class="n">unflatten</span><span class="p">(</span>
                <span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask_full_padded</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">out</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">tokens_obj</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="n">tokens_obj_flat</span><span class="p">,</span> <span class="n">masks_obj</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                    <span class="o">-</span><span class="mi">1</span>
                <span class="p">)</span> <span class="k">as</span> <span class="n">masks_obj_flat</span><span class="p">:</span>
                    <span class="n">attention_mask_full_unpadded</span> <span class="o">=</span> <span class="n">attention_mask_full_padded</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span>
                        <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>
                    <span class="p">)</span>
                    <span class="n">attention_mask_full_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                        <span class="n">attention_mask_full_unpadded</span><span class="o">.</span><span class="n">bool</span><span class="p">(),</span>
                        <span class="n">attention_mask_full_padded</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                        <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">masks_obj_flat</span><span class="o">.</span><span class="n">all_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask_full_unpadded</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">attention_mask_full_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                    <span class="n">attention_mask_full_padded</span><span class="o">.</span><span class="n">bool</span><span class="p">(),</span>
                    <span class="n">attention_mask_full_padded</span><span class="p">,</span>
                    <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask_full_unpadded</span>
        <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_assistant_mask</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">masks_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">masks_key</span><span class="p">,</span> <span class="n">masks_obj</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_log_probs</span><span class="p">:</span>
            <span class="n">log_probs_obj</span> <span class="o">=</span> <span class="n">LogProbs</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
            <span class="k">with</span> <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="n">log_probs_obj_flat</span><span class="p">:</span>
                <span class="c1"># Unfortunate but we only have the log-probs for the new tokens, not for the prompt - to get that, we&#39;d need to run the forward pass again</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                    <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">log_probs</span>
                    <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">log_probs_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                        <span class="n">log_probs</span><span class="p">,</span> <span class="n">attention_mask_response_padded</span><span class="p">,</span> <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span>
                    <span class="p">)</span>
                    <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">log_probs_unpadded</span>
                    <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
            <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_probs_key</span><span class="p">,</span> <span class="n">log_probs_obj</span><span class="p">)</span>

        <span class="c1"># Add logits to output if we&#39;re in a get_dist call</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">,</span> <span class="n">logits</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logits_full_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                    <span class="n">logits</span><span class="p">,</span> <span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
                <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">,</span> <span class="n">logits_full_unpadded</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_cat_tensors</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tokens</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">response_tokens</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">cast</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Concatenate tokens and response tokens.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">response_tokens</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_cat_tensors</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">t_</span><span class="p">,</span> <span class="n">cast</span><span class="o">=</span><span class="n">cast</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">t_</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">response_tokens</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">tokens</span><span class="p">,</span> <span class="n">response_tokens</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">cast</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cast</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_logprobs_from_history_tokens</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">response_tokens</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">logits_only</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute log-probs from history tokens.&quot;&quot;&quot;</span>
        <span class="n">pad_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>

        <span class="k">if</span> <span class="n">cfg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">generate_kwargs</span><span class="p">)</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;generation_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cfg</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_kwargs</span>

        <span class="c1"># non-packed forward pass</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_model_input</span><span class="p">:</span>
            <span class="c1"># unfortunately HF wants us to use padded tensors</span>
            <span class="n">tokens_full_padded</span> <span class="o">=</span> <span class="n">response_tokens</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;input_ids&quot;</span><span class="p">,</span>
                <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="n">pad_val</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens_full_padded</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected Tensor for tokens_full_padded, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">tokens_full_padded</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">response_tokens</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span>
                <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected Tensor for attention_mask_full_padded, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">attention_mask_full_padded</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="p">(</span>
                <span class="n">log_probs_full_padded</span><span class="p">,</span>
                <span class="n">logits_full_padded</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_forward_with_padded_sequences</span><span class="p">(</span>
                <span class="n">tokens_full_padded</span><span class="p">,</span>
                <span class="n">attention_mask_full_padded</span><span class="p">,</span>
                <span class="n">pad_val</span><span class="o">=</span><span class="n">pad_val</span><span class="p">,</span>
                <span class="n">logits_only</span><span class="o">=</span><span class="n">logits_only</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># unfortunately HF wants us to use padded tensors</span>
            <span class="n">tokens_full_unpadded</span> <span class="o">=</span> <span class="n">response_tokens</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;input_ids&quot;</span><span class="p">,</span>
                <span class="n">as_nested_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">layout</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">jagged</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">attention_mask_full_unpadded</span> <span class="o">=</span> <span class="n">response_tokens</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span>
                <span class="n">as_nested_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">layout</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">jagged</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="p">(</span>
                <span class="n">log_probs_full_unpadded</span><span class="p">,</span>
                <span class="n">logits_full_unpadded</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_forward_with_packed_sequences</span><span class="p">(</span>
                <span class="c1"># TODO: no padding if we don&#39;t need to</span>
                <span class="n">tokens_full_unpadded</span><span class="p">,</span>
                <span class="n">attention_mask_full_unpadded</span><span class="p">,</span>
                <span class="n">pad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">logits_only</span><span class="o">=</span><span class="n">logits_only</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">tokens_full_padded</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
                <span class="n">tokens_full_unpadded</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="n">pad_val</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
                <span class="n">attention_mask_full_unpadded</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">log_probs_full_unpadded</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">log_probs_full_padded</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
                    <span class="n">log_probs_full_unpadded</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                    <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">padding_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                    <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">log_probs_full_padded</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">logits_full_padded</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
                <span class="n">logits_full_unpadded</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="c1"># Build output TensorClass objects</span>
        <span class="n">text_obj</span> <span class="o">=</span> <span class="n">Text</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
            <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">text_obj</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">text_obj</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">text_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="n">text_obj</span><span class="p">)</span>

        <span class="n">all_assistant_mask_padded</span> <span class="o">=</span> <span class="n">response_tokens</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="s2">&quot;assistant_masks&quot;</span><span class="p">,</span>
            <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="n">padding_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">all_assistant_mask_padded</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">all_assistant_mask_padded</span> <span class="o">=</span> <span class="n">all_assistant_mask_padded</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
        <span class="n">masks_obj</span> <span class="o">=</span> <span class="n">Masks</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
            <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask_full_padded</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">all_assistant_mask_padded</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_assistant_mask</span> <span class="o">=</span> <span class="n">all_assistant_mask_padded</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_attention_mask</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                <span class="n">attention_mask_full_padded</span><span class="o">.</span><span class="n">bool</span><span class="p">(),</span>
                <span class="n">attention_mask_full_padded</span><span class="p">,</span>
                <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">all_assistant_mask_padded</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_assistant_mask</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                    <span class="n">all_assistant_mask_padded</span><span class="p">,</span>
                    <span class="n">attention_mask_full_padded</span><span class="p">,</span>
                    <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="n">masks_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">masks_key</span><span class="p">,</span> <span class="n">masks_obj</span><span class="p">)</span>

        <span class="n">tokens_obj</span> <span class="o">=</span> <span class="n">Tokens</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
            <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="n">tokens_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">tokens_full_padded</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_ids_full_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                <span class="n">tokens_full_padded</span><span class="p">,</span> <span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="n">tokens_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">input_ids_full_unpadded</span>
        <span class="n">tokens_obj</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">tokens_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="n">tokens_obj</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">logits_only</span><span class="p">:</span>
            <span class="n">log_probs_obj</span> <span class="o">=</span> <span class="n">LogProbs</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
                <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">log_probs_full_padded</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">log_probs_full_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                    <span class="n">log_probs_full_padded</span><span class="p">,</span> <span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
                <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">log_probs_full_unpadded</span>
            <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
            <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_probs_key</span><span class="p">,</span> <span class="n">log_probs_obj</span><span class="p">)</span>

        <span class="c1"># Add logits to output if we&#39;re in a get_dist call</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">,</span> <span class="n">logits_full_padded</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logits_full_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                    <span class="n">logits_full_padded</span><span class="p">,</span> <span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
                <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">,</span> <span class="n">logits_full_unpadded</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_from_transformers_generate_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">td</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate text from text input.&quot;&quot;&quot;</span>
        <span class="c1"># Validate input</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">td</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39; key for text input mode, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but found keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">text</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39; key for text input mode&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">NonTensorStack</span><span class="p">):</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected list of text for text input, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">text</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_from_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_from_transformers_logprobs_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">td</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">logits_only</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute log-probs from text input.&quot;&quot;&quot;</span>
        <span class="c1"># Validate input</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">td</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39; key for text input mode, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but found keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">text</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">NonTensorStack</span><span class="p">):</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39; key for text input mode&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected list of text for text input, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">text</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># Tokenize the text</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Tokenizer is required for log-probs computation with text input&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Convert text to list format</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="n">text</span><span class="p">]</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="c1"># Tokenize the text</span>
        <span class="n">tokenizer_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_kwargs</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>
        <span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">nullcontext</span><span class="p">():</span>
            <span class="n">tokens_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="o">**</span><span class="n">tokenizer_kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">cfg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">generate_kwargs</span><span class="p">)</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;generation_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cfg</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_kwargs</span>

        <span class="c1"># We are going to map this tokens_in to a tensordict to facilitate the padding in case we need it</span>
        <span class="n">tokens_in</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens_in</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]))</span>
            <span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">tokens_in</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="n">pad_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_model_input</span><span class="p">:</span>
            <span class="n">tokens_full_padded</span> <span class="o">=</span> <span class="n">tokens_in</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;input_ids&quot;</span><span class="p">,</span>
                <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="n">pad_val</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">tokens_in</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span>
                <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="p">(</span>
                <span class="n">log_probs_full_padded</span><span class="p">,</span>
                <span class="n">logits_full_padded</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_forward_with_padded_sequences</span><span class="p">(</span>
                <span class="n">tokens_full_padded</span><span class="p">,</span>
                <span class="n">attention_mask_full_padded</span><span class="p">,</span>
                <span class="n">pad_val</span><span class="o">=</span><span class="n">pad_val</span><span class="p">,</span>
                <span class="n">logits_only</span><span class="o">=</span><span class="n">logits_only</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># packed forward pass</span>
            <span class="n">tokens_full_unpadded</span> <span class="o">=</span> <span class="n">tokens_in</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;input_ids&quot;</span><span class="p">,</span>
                <span class="n">as_nested_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">layout</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">jagged</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">attention_mask_full_unpadded</span> <span class="o">=</span> <span class="n">tokens_in</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span>
                <span class="n">as_nested_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">layout</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">jagged</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="p">(</span>
                <span class="n">log_probs_full_unpadded</span><span class="p">,</span>
                <span class="n">logits_full_unpadded</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_forward_with_packed_sequences</span><span class="p">(</span>
                <span class="n">tokens_full_unpadded</span><span class="p">,</span> <span class="n">attention_mask_full_unpadded</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>
            <span class="n">tokens_full_padded</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
                <span class="n">tokens_full_unpadded</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="n">pad_val</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
                <span class="n">attention_mask_full_unpadded</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">log_probs_full_padded</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
                <span class="n">log_probs_full_unpadded</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logits_full_padded</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
                <span class="n">logits_full_unpadded</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Build output TensorClass objects</span>
        <span class="n">text_obj</span> <span class="o">=</span> <span class="n">Text</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
            <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">text_obj</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">text_obj</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">text_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">text</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="n">text_obj</span><span class="p">)</span>

        <span class="n">tokens_obj</span> <span class="o">=</span> <span class="n">Tokens</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
            <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="n">tokens_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">tokens_full_padded</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_ids_full_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                <span class="n">tokens_full_padded</span><span class="p">,</span> <span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="n">tokens_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">input_ids_full_unpadded</span>
        <span class="n">tokens_obj</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">tokens_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="n">tokens_obj</span><span class="p">)</span>

        <span class="n">masks_obj</span> <span class="o">=</span> <span class="n">Masks</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
            <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask_full_padded</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_assistant_mask</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;masks&quot;</span><span class="p">,</span> <span class="s2">&quot;all_assistant_mask&quot;</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">attention_mask_full_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                <span class="n">attention_mask_full_padded</span><span class="o">.</span><span class="n">bool</span><span class="p">(),</span>
                <span class="n">attention_mask_full_padded</span><span class="p">,</span>
                <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask_full_unpadded</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_assistant_mask</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="p">(</span><span class="s2">&quot;masks&quot;</span><span class="p">,</span> <span class="s2">&quot;all_assistant_mask&quot;</span><span class="p">),</span> <span class="n">as_list</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
        <span class="n">masks_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">masks_key</span><span class="p">,</span> <span class="n">masks_obj</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">logits_only</span><span class="p">:</span>
            <span class="n">log_probs_obj</span> <span class="o">=</span> <span class="n">LogProbs</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
                <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">log_probs_full_padded</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">log_probs_full_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                    <span class="n">log_probs_full_padded</span><span class="p">,</span> <span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
                <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">log_probs_full_unpadded</span>
            <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
            <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_probs_key</span><span class="p">,</span> <span class="n">log_probs_obj</span><span class="p">)</span>

        <span class="c1"># Add logits to output if we&#39;re in a get_dist call</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">,</span> <span class="n">logits_full_padded</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logits_full_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                    <span class="n">logits_full_padded</span><span class="p">,</span> <span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
                <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">,</span> <span class="n">logits_full_unpadded</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_from_transformers_generate_tokens</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="p">:</span> <span class="n">TensorDictBase</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate text from tokens input.&quot;&quot;&quot;</span>
        <span class="c1"># Validate input</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">td</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39; key for tokens input mode, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but found keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">pad_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>

        <span class="n">input_ids_prompt_padded</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">,</span>
            <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="n">padding_value</span><span class="o">=</span><span class="n">pad_val</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">attention_mask_prompt_padded</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="p">(</span><span class="s2">&quot;masks&quot;</span><span class="p">,</span> <span class="s2">&quot;all_attention_mask&quot;</span><span class="p">),</span>
            <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="n">padding_value</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">attention_mask_prompt_padded</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">attention_mask_prompt_padded</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">attention_mask_key</span><span class="p">,</span>
                <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">attention_mask_prompt_padded</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">attention_mask_prompt_padded</span> <span class="o">=</span> <span class="n">input_ids_prompt_padded</span> <span class="o">!=</span> <span class="n">pad_val</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_from_tokens</span><span class="p">(</span>
            <span class="n">input_ids_prompt_padded</span><span class="p">,</span> <span class="n">attention_mask_prompt_padded</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">out</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_from_tokens</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tokens_prompt_padded</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attention_mask_prompt_padded</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">cfg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">generate_kwargs</span><span class="p">)</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;generation_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cfg</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_kwargs</span>

        <span class="n">tokens_out_struct</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="n">tokens_prompt_padded</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask_prompt_padded</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">tokens_full_padded</span> <span class="o">=</span> <span class="n">tokens_out_struct</span><span class="p">[</span><span class="s2">&quot;sequences&quot;</span><span class="p">]</span>
        <span class="n">tokens_response_padded</span> <span class="o">=</span> <span class="n">tokens_full_padded</span><span class="p">[:,</span> <span class="n">tokens_prompt_padded</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">:]</span>
        <span class="n">pad_val</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;pad_token_id&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">pad_val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pad_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_value</span>
        <span class="n">attention_mask_reponse_padded</span> <span class="o">=</span> <span class="n">tokens_response_padded</span> <span class="o">!=</span> <span class="n">pad_val</span>
        <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">tokens_full_padded</span> <span class="o">!=</span> <span class="n">pad_val</span>
        <span class="n">tokens_response_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
            <span class="n">tokens_response_padded</span><span class="p">,</span> <span class="n">attention_mask_reponse_padded</span><span class="p">,</span> <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_log_probs</span><span class="p">:</span>
            <span class="c1"># These are only for the new tokens, not for the prompt - to get that, we&#39;d need to run the forward pass again</span>
            <span class="n">logits_response_padded</span> <span class="o">=</span> <span class="n">tokens_out_struct</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span>
            <span class="n">logits_response_padded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">logits_response_padded</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">(</span>
                <span class="n">log_probs_response_padded</span><span class="p">,</span>
                <span class="n">logits_response_padded</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_probs_generate</span><span class="p">(</span>
                <span class="n">tokens_response_padded</span><span class="p">,</span>
                <span class="n">logits_response_padded</span><span class="p">,</span>
                <span class="n">pad_val</span><span class="o">=</span><span class="n">pad_val</span><span class="p">,</span>
                <span class="n">pad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">response_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span>
            <span class="n">tokens_response_unpadded</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="c1"># Build output TensorClass objects</span>
        <span class="n">text_obj</span> <span class="o">=</span> <span class="n">Text</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
        <span class="n">text_obj</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># We don&#39;t have text in tokens mode</span>
        <span class="k">with</span> <span class="n">text_obj</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="n">text_obj_flat</span><span class="p">:</span>
            <span class="n">text_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">response_text</span>
        <span class="n">text_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># we don&#39;t have text in tokens mode so no all_text either</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="n">text_obj</span><span class="p">)</span>

        <span class="n">tokens_obj</span> <span class="o">=</span> <span class="n">Tokens</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="n">input_ids_prompt_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                <span class="n">tokens_prompt_padded</span><span class="p">,</span>
                <span class="n">attention_mask_prompt_padded</span><span class="p">,</span>
                <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># replicate tokens</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">):</span>
                <span class="n">tokens_obj</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">input_ids_prompt_unpadded</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span>
                    <span class="k">else</span> <span class="n">tokens_prompt_padded</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokens_obj</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">input_ids_prompt_unpadded</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span>
                <span class="k">else</span> <span class="n">tokens_prompt_padded</span>
            <span class="p">)</span>
        <span class="k">with</span> <span class="n">tokens_obj</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="n">tokens_obj_flat</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">tokens_response_padded</span>
                <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">tokens_full_padded</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">tokens_response_unpadded</span>
                <span class="n">tokens_full_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                    <span class="n">tokens_full_padded</span><span class="p">,</span> <span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
                <span class="n">tokens_obj_flat</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">tokens_full_unpadded</span>
        <span class="n">tokens_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="n">tokens_obj</span><span class="p">)</span>

        <span class="n">masks_obj</span> <span class="o">=</span> <span class="n">Masks</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">out</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">attention_mask_full_padded</span><span class="o">.</span><span class="n">unflatten</span><span class="p">(</span>
                <span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="c1"># Get &quot;real&quot; attention masks</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask_full_padded</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Get &quot;real&quot; attention masks</span>
            <span class="c1"># We can use select to avoid batch-size problems</span>
            <span class="n">_td</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span>
                <span class="n">out</span><span class="o">.</span><span class="n">select</span><span class="p">((</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">))</span>
                <span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="o">.</span><span class="n">rename_key_</span><span class="p">((</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;full&quot;</span><span class="p">),</span> <span class="s2">&quot;all_attention_mask&quot;</span><span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
            <span class="k">del</span> <span class="n">_td</span><span class="p">[</span><span class="s2">&quot;tokens&quot;</span><span class="p">]</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_td</span><span class="p">)</span>
        <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_assistant_mask</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">masks_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">masks_key</span><span class="p">,</span> <span class="n">masks_obj</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_log_probs</span><span class="p">:</span>
            <span class="n">log_probs_obj</span> <span class="o">=</span> <span class="n">LogProbs</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">empty</span><span class="p">())</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                    <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">log_probs_response_padded</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">log_probs_response_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                        <span class="n">log_probs_response_padded</span><span class="p">,</span>
                        <span class="n">attention_mask_reponse_padded</span><span class="p">,</span>
                        <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">log_probs_response_unpadded</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="n">log_probs_obj_flat</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                        <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">log_probs_response_padded</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">log_probs_response_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                            <span class="n">log_probs_response_padded</span><span class="p">,</span>
                            <span class="n">attention_mask_reponse_padded</span><span class="p">,</span>
                            <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="p">)</span>
                        <span class="n">log_probs_obj_flat</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">log_probs_response_unpadded</span>
            <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
            <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_probs_key</span><span class="p">,</span> <span class="n">log_probs_obj</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_from_transformers_logprobs_tokens</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">logits_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute log-probs from tokens input.&quot;&quot;&quot;</span>
        <span class="c1"># Validate input</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">td</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39; key for tokens input mode, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but found keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">,</span><span class="w"> </span><span class="nb">tuple</span><span class="p">)))</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">pad_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>

        <span class="k">if</span> <span class="n">cfg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">generate_kwargs</span><span class="p">)</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;generation_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cfg</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_kwargs</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_model_input</span><span class="p">:</span>
            <span class="n">tokens_full_padded</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">,</span>
                <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="n">pad_val</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Attention mask: try first the regular entry, then the key provided in the constructor, finally fallback on eager attention mask</span>
            <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="p">(</span><span class="s2">&quot;masks&quot;</span><span class="p">,</span> <span class="s2">&quot;all_attention_mask&quot;</span><span class="p">),</span>
                <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">attention_mask_full_padded</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">attention_mask_key</span><span class="p">,</span>
                    <span class="n">as_padded_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
                    <span class="n">padding_value</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">attention_mask_full_padded</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">tokens_full_padded</span> <span class="o">!=</span> <span class="n">pad_val</span>

            <span class="p">(</span>
                <span class="n">log_probs_full_padded</span><span class="p">,</span>
                <span class="n">logits_full_padded</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_forward_with_padded_sequences</span><span class="p">(</span>
                <span class="n">tokens_full_padded</span><span class="p">,</span>
                <span class="n">attention_mask_full_padded</span><span class="p">,</span>
                <span class="n">pad_val</span><span class="o">=</span><span class="n">pad_val</span><span class="p">,</span>
                <span class="n">logits_only</span><span class="o">=</span><span class="n">logits_only</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># packed forward pass</span>
            <span class="c1"># unfortunately HF wants us to use padded tensors</span>
            <span class="n">tokens_full_unpadded</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">,</span>
                <span class="n">as_nested_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">layout</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">jagged</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">tokens_full_unpadded</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="si">}</span><span class="s2">&#39; key for tokens input mode, but found keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="c1"># Attention mask: try first the regular entry, then the key provided in the constructor, finally fallback on eager attention mask</span>
            <span class="n">attention_mask_full_unpadded</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="p">(</span><span class="s2">&quot;masks&quot;</span><span class="p">,</span> <span class="s2">&quot;all_attention_mask&quot;</span><span class="p">),</span>
                <span class="n">as_nested_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">layout</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">jagged</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">attention_mask_full_unpadded</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">attention_mask_full_unpadded</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">attention_mask_key</span><span class="p">,</span>
                    <span class="n">as_nested_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">layout</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">jagged</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">attention_mask_full_unpadded</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># does this even work?</span>
                    <span class="n">attention_mask_full_unpadded</span> <span class="o">=</span> <span class="n">tokens_full_unpadded</span> <span class="o">!=</span> <span class="n">pad_val</span>

            <span class="p">(</span>
                <span class="n">log_probs_full_unpadded</span><span class="p">,</span>
                <span class="n">logits_full_unpadded</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_forward_with_packed_sequences</span><span class="p">(</span>
                <span class="c1"># TODO: no padding if we don&#39;t need to</span>
                <span class="n">tokens_full_unpadded</span><span class="p">,</span>
                <span class="n">attention_mask_full_unpadded</span><span class="p">,</span>
                <span class="n">pad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">logits_only</span><span class="o">=</span><span class="n">logits_only</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">tokens_full_padded</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
                <span class="n">tokens_full_unpadded</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="n">pad_val</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">attention_mask_full_padded</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
                <span class="n">attention_mask_full_unpadded</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">log_probs_full_unpadded</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">log_probs_full_padded</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
                    <span class="n">log_probs_full_unpadded</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                    <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">padding_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                    <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">log_probs_full_padded</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">logits_full_padded</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
                <span class="n">logits_full_unpadded</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Build output TensorClass objects</span>
        <span class="n">text_obj</span> <span class="o">=</span> <span class="n">Text</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
            <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">text_obj</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">text_obj</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">text_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">,</span> <span class="n">text_obj</span><span class="p">)</span>

        <span class="n">tokens_obj</span> <span class="o">=</span> <span class="n">Tokens</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
            <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="n">input_ids_full_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                <span class="n">tokens_full_padded</span><span class="p">,</span> <span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="n">tokens_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">input_ids_full_unpadded</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokens_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">tokens_full_padded</span>
        <span class="n">tokens_obj</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">tokens_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_key</span><span class="p">,</span> <span class="n">tokens_obj</span><span class="p">)</span>

        <span class="n">masks_obj</span> <span class="o">=</span> <span class="n">Masks</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
            <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask_full_padded</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_assistant_mask</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;masks&quot;</span><span class="p">,</span> <span class="s2">&quot;all_assistant_mask&quot;</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_attention_mask</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                <span class="n">attention_mask_full_padded</span><span class="o">.</span><span class="n">bool</span><span class="p">(),</span>
                <span class="n">attention_mask_full_padded</span><span class="p">,</span>
                <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">masks_obj</span><span class="o">.</span><span class="n">all_assistant_mask</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="p">(</span><span class="s2">&quot;masks&quot;</span><span class="p">,</span> <span class="s2">&quot;all_assistant_mask&quot;</span><span class="p">),</span> <span class="n">as_list</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

        <span class="n">masks_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">masks_key</span><span class="p">,</span> <span class="n">masks_obj</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">logits_only</span><span class="p">:</span>
            <span class="n">log_probs_obj</span> <span class="o">=</span> <span class="n">LogProbs</span><span class="o">.</span><span class="n">_from_tensordict</span><span class="p">(</span>
                <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to_lazystack</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">log_probs_full_padded</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">log_probs_full_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                    <span class="n">log_probs_full_padded</span><span class="p">,</span> <span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
                <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">full</span> <span class="o">=</span> <span class="n">log_probs_full_unpadded</span>
            <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">log_probs_obj</span><span class="o">.</span><span class="n">padded</span> <span class="o">=</span> <span class="n">MetaData</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">)</span>
            <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_probs_key</span><span class="p">,</span> <span class="n">log_probs_obj</span><span class="p">)</span>

        <span class="c1"># Add logits to output if we&#39;re in a get_dist call</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_output</span><span class="p">:</span>
                <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">,</span> <span class="n">logits_full_padded</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logits_full_unpadded</span> <span class="o">=</span> <span class="n">_unpad_tensors</span><span class="p">(</span>
                    <span class="n">logits_full_padded</span><span class="p">,</span> <span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="n">as_nested</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
                <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">,</span> <span class="n">logits_full_unpadded</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_log_probs_generate</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">pad_val</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span> <span class="n">pad</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">pad</span><span class="p">:</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
                <span class="n">tokens</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="n">pad_val</span><span class="p">,</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
                <span class="n">logits</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># logits = logits.log_softmax(dim=-1)</span>
        <span class="c1"># log_probs = logits.gather(-1, tokens.unsqueeze(-1)).squeeze(-1)</span>
        <span class="n">td</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">tokens</span><span class="o">=</span><span class="n">tokens</span><span class="p">)</span><span class="o">.</span><span class="n">auto_batch_size_</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">td</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">as</span> <span class="n">tdflat</span><span class="p">:</span>
            <span class="n">tdflat</span><span class="p">[</span><span class="s2">&quot;log_probs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span>
                <span class="n">tdflat</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">],</span> <span class="n">tdflat</span><span class="p">[</span><span class="s2">&quot;tokens&quot;</span><span class="p">],</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="n">pad_val</span>
            <span class="p">)</span>
        <span class="n">td</span><span class="p">[</span><span class="s2">&quot;log_probs&quot;</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">log_probs</span> <span class="o">=</span> <span class="n">td</span><span class="p">[</span><span class="s2">&quot;log_probs&quot;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">log_probs</span><span class="p">,</span> <span class="n">logits</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_log_probs_from_model_output</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_output</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">pad_val</span><span class="p">,</span> <span class="n">logits_only</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute log-probs from model output without modifying original tensors.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_output: Output from the model containing logits</span>
<span class="sd">            input_ids: Original input token ids</span>
<span class="sd">            attention_mask: Original attention mask</span>
<span class="sd">            pad_val: Padding token value to ignore in loss computation</span>
<span class="sd">            logits_only: Whether to return only the logits.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: (log_probs, shifted_logits) where log_probs are the computed log probabilities</span>
<span class="sd">                   and shifted_logits are the logits shifted to align with tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">model_output</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span>

        <span class="c1"># Create shifted versions for log-prob computation without modifying originals</span>
        <span class="n">shifted_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="c1"># shifted_logits = shifted_logits - shifted_logits.logsumexp(dim=-1, keepdim=True)</span>
        <span class="n">shifted_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">shifted_logits</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">]),</span> <span class="n">shifted_logits</span><span class="p">],</span> <span class="mi">1</span>
        <span class="p">)</span>

        <span class="n">shifted_input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
        <span class="n">shifted_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">shifted_input_ids</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">]),</span> <span class="n">shifted_input_ids</span><span class="p">],</span> <span class="mi">1</span>
        <span class="p">)</span>

        <span class="c1"># Check that the shape is correct</span>
        <span class="k">if</span> <span class="n">shifted_logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">!=</span> <span class="n">shifted_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The logits shape </span><span class="si">{</span><span class="n">shifted_logits</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> does not match the input ids shape </span><span class="si">{</span><span class="n">shifted_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">logits_only</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="n">shifted_logits</span>

        <span class="c1"># Compute log-probs</span>
        <span class="n">td</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span>
            <span class="n">logits</span><span class="o">=</span><span class="n">shifted_logits</span><span class="p">,</span> <span class="n">tokens</span><span class="o">=</span><span class="n">shifted_input_ids</span>
        <span class="p">)</span><span class="o">.</span><span class="n">auto_batch_size_</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">td</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">as</span> <span class="n">tdflat</span><span class="p">:</span>
            <span class="n">tdflat</span><span class="p">[</span><span class="s2">&quot;log_probs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span>
                <span class="n">tdflat</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">],</span>
                <span class="n">tdflat</span><span class="p">[</span><span class="s2">&quot;tokens&quot;</span><span class="p">],</span>
                <span class="n">reduce</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">ignore_index</span><span class="o">=</span><span class="n">pad_val</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="c1"># For consistency with vllm, we set the log-probs of the first token to 0</span>
        <span class="c1">#  However, the first element may not be the first - we want the first of the attention mask,</span>
        <span class="c1">#  i.e, the first element that is true on the left</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
        <span class="n">attention_mask_first_left</span> <span class="o">=</span> <span class="o">~</span><span class="n">attention_mask</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">attention_mask</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
        <span class="n">attention_mask_first_left</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">attention_mask_first_left</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">1</span><span class="p">]),</span>
                <span class="n">attention_mask_first_left</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">attention_mask_first_left</span><span class="p">[</span><span class="o">~</span><span class="p">(</span><span class="n">attention_mask_first_left</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">assert</span> <span class="n">attention_mask_first_left</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
        <span class="n">attention_mask_first_left</span> <span class="o">=</span> <span class="n">attention_mask_first_left</span> <span class="o">|</span> <span class="o">~</span><span class="n">attention_mask</span>
        <span class="n">td</span><span class="p">[</span><span class="s2">&quot;log_probs&quot;</span><span class="p">][</span><span class="n">attention_mask_first_left</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">return</span> <span class="n">td</span><span class="p">[</span><span class="s2">&quot;log_probs&quot;</span><span class="p">],</span> <span class="n">shifted_logits</span>

<div class="viewcode-block" id="TransformersWrapper.get_dist"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.TransformersWrapper.html#torchrl.modules.llm.TransformersWrapper.get_dist">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_dist</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">tensordict_out</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">logits_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="s2">&quot;logits&quot;</span><span class="p">,</span>
        <span class="n">mask_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">as_padded_tensor</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">as_nested_tensor</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">padding_value</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">padding_side</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;right&quot;</span><span class="p">,</span>
        <span class="n">layout</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">layout</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution from logits/log-probs with optional masking.</span>

<span class="sd">        This method enables logits computation for distribution creation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_dist</span><span class="p">(</span>
                <span class="n">tensordict</span><span class="p">,</span>
                <span class="n">tensordict_out</span><span class="p">,</span>
                <span class="n">logits_key</span><span class="p">,</span>
                <span class="n">mask_key</span><span class="p">,</span>
                <span class="n">as_padded_tensor</span><span class="p">,</span>
                <span class="n">as_nested_tensor</span><span class="p">,</span>
                <span class="n">padding_value</span><span class="p">,</span>
                <span class="n">padding_side</span><span class="p">,</span>
                <span class="n">layout</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_dist_with_prompt_mask</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">tokens_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;prompt&quot;</span><span class="p">),</span>
        <span class="n">logits_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="s2">&quot;logits&quot;</span><span class="p">,</span>
        <span class="n">assistant_mask_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;masks&quot;</span><span class="p">,</span> <span class="s2">&quot;all_assistant_mask&quot;</span><span class="p">),</span>
        <span class="n">attention_mask_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;masks&quot;</span><span class="p">,</span> <span class="s2">&quot;all_attention_mask&quot;</span><span class="p">),</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution masked to only include response tokens (exclude prompt).</span>

<span class="sd">        This method enables logits computation for distribution creation.</span>

<span class="sd">        This is a provisional method that will be replaced by the `get_dist` method once we have a better masking strategy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_get_dist_with_prompt_mask</span><span class="p">(</span>
                <span class="n">tensordict</span><span class="p">,</span>
                <span class="n">tokens_key</span><span class="p">,</span>
                <span class="n">logits_key</span><span class="p">,</span>
                <span class="n">assistant_mask_key</span><span class="p">,</span>
                <span class="n">attention_mask_key</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_dist_with_assistant_mask</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">assistant_mask_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;masks&quot;</span><span class="p">,</span> <span class="s2">&quot;all_assistant_mask&quot;</span><span class="p">),</span>
        <span class="n">logits_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="s2">&quot;logits&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution masked to only include assistant tokens.</span>

<span class="sd">        This method enables logits computation for distribution creation.</span>

<span class="sd">        This is a provisional method that will be replaced by the `get_dist` method once we have a better masking strategy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_get_dist_with_assistant_mask</span><span class="p">(</span>
                <span class="n">tensordict</span><span class="p">,</span> <span class="n">assistant_mask_key</span><span class="p">,</span> <span class="n">logits_key</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_dist_with_attention_mask</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">attention_mask_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;masks&quot;</span><span class="p">,</span> <span class="s2">&quot;all_attention_mask&quot;</span><span class="p">),</span>
        <span class="n">logits_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="s2">&quot;logits&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution masked using attention mask.</span>

<span class="sd">        This method enables logits computation for distribution creation.</span>

<span class="sd">        This is a provisional method that will be replaced by the `get_dist` method once we have a better masking strategy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_get_dist_with_attention_mask</span><span class="p">(</span>
                <span class="n">tensordict</span><span class="p">,</span> <span class="n">attention_mask_key</span><span class="p">,</span> <span class="n">logits_key</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_dist_with_custom_mask</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">logits_key</span><span class="p">:</span> <span class="n">NestedKey</span> <span class="o">=</span> <span class="s2">&quot;logits&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution with custom mask.</span>

<span class="sd">        This method enables logits computation for distribution creation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_get_dist_with_custom_mask</span><span class="p">(</span>
                <span class="n">tensordict</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">logits_key</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">)</span>

    <span class="c1"># Convenience methods for common LLM training scenarios</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_get_sft_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution suitable for SFT loss (response tokens only).</span>

<span class="sd">        This method enables logits computation for distribution creation.</span>

<span class="sd">        This is a provisional method that will be replaced by the `get_dist` method once we have a better masking strategy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_get_sft_dist</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_rlhf_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution suitable for RLHF loss (assistant tokens only).</span>

<span class="sd">        This method enables logits computation for distribution creation.</span>

<span class="sd">        This is a provisional method that will be replaced by the `get_dist` method once we have a better masking strategy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_get_rlhf_dist</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_generic_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution suitable for generic losses (all tokens).</span>

<span class="sd">        This method enables logits computation for distribution creation.</span>

<span class="sd">        This is a provisional method that will be replaced by the `get_dist` method once we have a better masking strategy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_get_generic_dist</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_dist_call</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_pack_sequences</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nested</span><span class="o">.</span><span class="n">NestedTensor</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nested</span><span class="o">.</span><span class="n">NestedTensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Pack sequences into a single tensor.&quot;&quot;&quot;</span>
        <span class="n">packed_input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">lengths</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">lengths</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">offsets</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">offsets</span><span class="p">()</span>
            <span class="n">lengths</span> <span class="o">=</span> <span class="n">offsets</span><span class="o">.</span><span class="n">diff</span><span class="p">()</span>
            <span class="n">offsets</span> <span class="o">=</span> <span class="n">offsets</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">offsets</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># Create block-diagonal attention mask to prevent cross-sequence attention</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_block_diagonal_attention_mask</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span>
        <span class="c1"># Create position IDs that restart for each sequence</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_packed_position_ids</span><span class="p">(</span>
            <span class="n">lengths</span><span class="p">,</span> <span class="n">total_length</span><span class="o">=</span><span class="n">packed_input_ids</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="n">packing_metadata</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;sequence_lengths&quot;</span><span class="p">:</span> <span class="n">lengths</span><span class="p">,</span>
            <span class="s2">&quot;cumulative_lengths&quot;</span><span class="p">:</span> <span class="n">offsets</span><span class="p">,</span>
            <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">attention_mask</span><span class="p">,</span>
            <span class="s2">&quot;position_ids&quot;</span><span class="p">:</span> <span class="n">position_ids</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="n">packed_input_ids</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
            <span class="n">attention_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
            <span class="n">packing_metadata</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_model_forward_with_padded_sequences</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tokens_full_padded</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attention_mask_full_padded</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">pad_val</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">logits_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass with padded sequences.&quot;&quot;&quot;</span>
        <span class="c1"># Error handling for empty sequences</span>
        <span class="k">if</span> <span class="n">tokens_full_padded</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Input contains empty sequences. Packing/padding requires at least one token per sequence.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># Error handling for overlong sequences</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;config&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">max_len</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;max_position_embeddings&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">max_len</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">tokens_full_padded</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">max_len</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Input sequence length (</span><span class="si">{</span><span class="n">tokens_full_padded</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">) exceeds model&#39;s max_position_embeddings (</span><span class="si">{</span><span class="n">max_len</span><span class="si">}</span><span class="s2">). Consider truncating or splitting your input.&quot;</span>
            <span class="p">)</span>
        <span class="n">tokens_out_struct</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
            <span class="n">tokens_full_padded</span><span class="p">,</span> <span class="n">attention_mask_full_padded</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>
        <span class="p">(</span>
            <span class="n">log_probs_full_padded</span><span class="p">,</span>
            <span class="n">logits_full_padded</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_log_probs_from_model_output</span><span class="p">(</span>
            <span class="n">tokens_out_struct</span><span class="p">,</span>
            <span class="n">tokens_full_padded</span><span class="p">,</span>
            <span class="n">attention_mask_full_padded</span><span class="p">,</span>
            <span class="n">pad_val</span><span class="p">,</span>
            <span class="n">logits_only</span><span class="o">=</span><span class="n">logits_only</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">log_probs_full_padded</span><span class="p">,</span> <span class="n">logits_full_padded</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_model_forward_with_packed_sequences</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">flat_input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">block_diag_attention_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">pad</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">logits_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Pack sequences into a single tensor and forward them through the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            flat_input_ids (NestedTensor): NestedTensor of shape (batch_size, -1)</span>
<span class="sd">            block_diag_attention_mask (NestedTensor): NestedTensor of shape (batch_size, -1)</span>

<span class="sd">        Returns:</span>
<span class="sd">            pad (bool): Whether to pad the output tensors.</span>
<span class="sd">            logits_only (bool): Whether to return only logits.</span>
<span class="sd">            kwargs (dict): Additional keyword arguments to pass to the model.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Error handling for empty sequences</span>
        <span class="k">if</span> <span class="n">flat_input_ids</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Input contains empty sequences. Packing requires at least one token per sequence.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># Error handling for overlong sequences</span>
        <span class="c1"># Note: Skipping this check for nested tensors due to symbolic representation issues</span>
        <span class="c1"># The model will handle sequence length limits internally</span>
        <span class="n">max_len</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;max_position_embeddings&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">max_len</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">flat_input_ids</span><span class="p">,</span> <span class="s2">&quot;size&quot;</span><span class="p">):</span>
            <span class="c1"># Only check for regular tensors, not nested tensors</span>
            <span class="n">actual_size</span> <span class="o">=</span> <span class="n">flat_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">actual_size</span> <span class="o">&gt;</span> <span class="n">max_len</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Input sequence length (</span><span class="si">{</span><span class="n">actual_size</span><span class="si">}</span><span class="s2">) exceeds model&#39;s max_position_embeddings (</span><span class="si">{</span><span class="n">max_len</span><span class="si">}</span><span class="s2">). Consider truncating or splitting your input.&quot;</span>
                <span class="p">)</span>
        <span class="p">(</span>
            <span class="n">flat_input_ids</span><span class="p">,</span>
            <span class="n">block_diag_attention_mask</span><span class="p">,</span>
            <span class="n">packing_metadata</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pack_sequences</span><span class="p">(</span><span class="n">flat_input_ids</span><span class="p">,</span> <span class="n">block_diag_attention_mask</span><span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="n">flat_input_ids</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">block_diag_attention_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
            <span class="n">position_ids</span><span class="o">=</span><span class="n">packing_metadata</span><span class="p">[</span><span class="s2">&quot;position_ids&quot;</span><span class="p">],</span>
            <span class="n">use_cache</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># Disable KV cache for packing</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">log_probs</span><span class="p">,</span> <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unpack_outputs</span><span class="p">(</span>
            <span class="n">outputs</span><span class="p">,</span> <span class="n">packing_metadata</span><span class="p">,</span> <span class="n">flat_input_ids</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="n">pad</span><span class="p">,</span> <span class="n">logits_only</span><span class="o">=</span><span class="n">logits_only</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">log_probs</span><span class="p">,</span> <span class="n">logits</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_unpack_outputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">,</span>
        <span class="n">packing_metadata</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">flat_input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">pad</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">logits_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Unpack outputs using nested tensors - zero syncs.&quot;&quot;&quot;</span>
        <span class="c1"># use cross_entropy to compute log_probs</span>
        <span class="n">log_probs</span><span class="p">,</span> <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_log_probs_from_model_output</span><span class="p">(</span>
            <span class="n">outputs</span><span class="p">,</span>
            <span class="n">flat_input_ids</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">flat_input_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">),</span>
            <span class="o">-</span><span class="mi">100</span><span class="p">,</span>
            <span class="n">logits_only</span><span class="o">=</span><span class="n">logits_only</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># check shapes: [1, L] for log_probs, [1, L, vocab_size] for logits</span>
        <span class="n">sequence_lengths</span> <span class="o">=</span> <span class="n">packing_metadata</span><span class="p">[</span><span class="s2">&quot;sequence_lengths&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">logits_only</span><span class="p">:</span>
            <span class="n">log_probs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">log_probs</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Log probs shape </span><span class="si">{</span><span class="n">log_probs</span><span class="o">.</span><span class="n">shape</span><span class="si">=}</span><span class="s2"> does not match logits shape </span><span class="si">{</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span><span class="si">=}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">log_probs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Log probs shape </span><span class="si">{</span><span class="n">log_probs</span><span class="o">.</span><span class="n">shape</span><span class="si">=}</span><span class="s2"> is not 2D&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">logits</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Logits shape </span><span class="si">{</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="si">=}</span><span class="s2"> is not 3D&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">log_probs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">sequence_lengths</span><span class="o">.</span><span class="n">sum</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Log probs shape </span><span class="si">{</span><span class="n">log_probs</span><span class="o">.</span><span class="n">shape</span><span class="si">=}</span><span class="s2"> does not match sequence lengths </span><span class="si">{</span><span class="n">sequence_lengths</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">=}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="n">log_probs</span> <span class="o">=</span> <span class="n">log_probs</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">nested_logprobs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nested</span><span class="o">.</span><span class="n">nested_tensor_from_jagged</span><span class="p">(</span>
                <span class="n">log_probs</span><span class="p">,</span>
                <span class="n">lengths</span><span class="o">=</span><span class="n">sequence_lengths</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">nested_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nested</span><span class="o">.</span><span class="n">nested_tensor_from_jagged</span><span class="p">(</span>
            <span class="n">logits</span><span class="p">,</span>  <span class="c1"># Remove batch dim: (total_length, vocab_size)</span>
            <span class="n">lengths</span><span class="o">=</span><span class="n">sequence_lengths</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">logits_only</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">pad</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="n">nested_logits</span><span class="o">.</span><span class="n">to_padded_tensor</span><span class="p">(</span><span class="n">padding</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="n">nested_logits</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">pad</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">nested_logprobs</span><span class="o">.</span><span class="n">to_padded_tensor</span><span class="p">(</span>
                    <span class="n">padding</span><span class="o">=</span><span class="mf">0.0</span>
                <span class="p">),</span> <span class="n">nested_logits</span><span class="o">.</span><span class="n">to_padded_tensor</span><span class="p">(</span><span class="n">padding</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">nested_logprobs</span><span class="p">,</span> <span class="n">nested_logits</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_block_diagonal_attention_mask</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">sequence_lengths</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Efficient creation of a block-diagonal attention mask.</span>

<span class="sd">        Zero cuda syncs, no integer involved except len(tensor) - compilable.</span>

<span class="sd">        Args:</span>
<span class="sd">            sequence_lengths: Tensor of shape (batch_size,) containing the lengths of the sequences</span>

<span class="sd">        Returns:</span>
<span class="sd">            attention_mask: Tensor of shape (batch_size, total_length, total_length)</span>
<span class="sd">                where each sequence can only attend to itself.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">seq_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sequence_lengths</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">sequence_lengths</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">position_to_seq_id</span> <span class="o">=</span> <span class="n">seq_ids</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">sequence_lengths</span><span class="p">)</span>

        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">position_to_seq_id</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span>
            <span class="mi">1</span>
        <span class="p">)</span> <span class="o">==</span> <span class="n">position_to_seq_id</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">attention_mask</span>

<div class="viewcode-block" id="TransformersWrapper.repeat_interleave_causal"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.TransformersWrapper.html#torchrl.modules.llm.TransformersWrapper.repeat_interleave_causal">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">repeat_interleave_causal</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_lengths</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Same as _create_block_diagonal_attention_mask, but with causal masking.&quot;&quot;&quot;</span>
        <span class="n">total_length</span> <span class="o">=</span> <span class="n">sequence_lengths</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

        <span class="n">seq_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sequence_lengths</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">sequence_lengths</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">position_to_seq_id</span> <span class="o">=</span> <span class="n">seq_ids</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">sequence_lengths</span><span class="p">)</span>

        <span class="n">positions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">total_length</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">sequence_lengths</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">same_sequence</span> <span class="o">=</span> <span class="n">position_to_seq_id</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">position_to_seq_id</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span>
            <span class="mi">0</span>
        <span class="p">)</span>
        <span class="n">causal</span> <span class="o">=</span> <span class="n">positions</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">positions</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">same_sequence</span> <span class="o">&amp;</span> <span class="n">causal</span>
        <span class="k">return</span> <span class="n">attention_mask</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_packed_position_ids</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">sequence_lengths</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">total_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create position IDs that restart from 0 for each sequence.</span>

<span class="sd">        For sequences of length [3, 2], creates: [0, 1, 2, 0, 1]</span>

<span class="sd">        No cuda syncs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">total_length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">total_length</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sequence_lengths</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="c1"># Create global position IDs: [0, 1, 2, 3, 4]</span>
        <span class="n">global_positions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">total_length</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">sequence_lengths</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Create sequence start offsets repeated for each position: [0, 0, 0, 3, 3]</span>
        <span class="n">offsets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">sequence_lengths</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
                <span class="n">sequence_lengths</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="mi">0</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="n">sequence_starts</span> <span class="o">=</span> <span class="n">offsets</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">sequence_lengths</span><span class="p">)</span>

        <span class="c1"># Subtract to get local positions: [0, 1, 2, 0, 1]</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">global_positions</span> <span class="o">-</span> <span class="n">sequence_starts</span>

        <span class="k">return</span> <span class="n">position_ids</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (1, total_length)</span></div>


<div class="viewcode-block" id="RemoteTransformersWrapper"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.RemoteTransformersWrapper.html#torchrl.modules.llm.RemoteTransformersWrapper">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">RemoteTransformersWrapper</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A remote Ray actor wrapper for TransformersWrapper that provides a simplified interface.</span>

<span class="sd">    This class wraps a TransformersWrapper instance as a Ray actor, allowing remote execution</span>
<span class="sd">    while providing a clean interface that doesn&#39;t require explicit `remote()` and `get()` calls.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (str): The Hugging Face Transformers model to wrap.</span>
<span class="sd">            Must be a string (model name or path) that will be passed to `transformers.AutoModelForCausalLM.from_pretrained`.</span>
<span class="sd">            Transformers models are not serializable, so only model names/paths are supported.</span>
<span class="sd">        max_concurrency (int, optional): Maximum number of concurrent calls to the remote actor. Defaults to 16.</span>
<span class="sd">        validate_model (bool, optional): Whether to validate the model. Defaults to True.</span>
<span class="sd">        num_gpus (int, optional): Number of GPUs to use. Defaults to 0.</span>
<span class="sd">        num_cpus (int, optional): Number of CPUs to use. Defaults to 0.</span>
<span class="sd">        **kwargs: All other arguments are passed directly to TransformersWrapper.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules.llm.policies import RemoteTransformersWrapper</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Initialize Ray if not already done</span>
<span class="sd">        &gt;&gt;&gt; if not ray.is_initialized():</span>
<span class="sd">        ...     ray.init()</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Create remote wrapper</span>
<span class="sd">        &gt;&gt;&gt; remote_wrapper = RemoteTransformersWrapper(</span>
<span class="sd">        ...     model=&quot;gpt2&quot;,</span>
<span class="sd">        ...     input_mode=&quot;history&quot;,</span>
<span class="sd">        ...     generate=True,</span>
<span class="sd">        ...     generate_kwargs={&quot;max_new_tokens&quot;: 50}</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use like a regular wrapper (no remote/get calls needed)</span>
<span class="sd">        &gt;&gt;&gt; result = remote_wrapper(tensordict_input)</span>
<span class="sd">        &gt;&gt;&gt; print(result[&quot;text&quot;].response)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">max_concurrency</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
        <span class="n">validate_model</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">actor_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_gpus</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">num_cpus</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="c1"># Validate model parameter - only strings are allowed for Transformers</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">validate_model</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;For RemoteTransformersWrapper, the model parameter must be a string &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;(model name or path). Got type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="s2">&quot;Transformers models are not serializable, so only model names/paths are supported. &quot;</span>
                <span class="s2">&quot;You can bypass this check by setting validate_model=False.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">ray</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
            <span class="n">ray</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">actor_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Check if an actor with this name already exists</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">existing_actor</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get_actor</span><span class="p">(</span><span class="n">actor_name</span><span class="p">)</span>
                <span class="c1"># If we can get the actor, assume it&#39;s alive and use it</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span> <span class="o">=</span> <span class="n">existing_actor</span>
                <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using existing actor </span><span class="si">{</span><span class="n">actor_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">return</span>
            <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                <span class="c1"># Actor doesn&#39;t exist, create a new one</span>
                <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Creating new actor </span><span class="si">{</span><span class="n">actor_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Create the remote actor with the unique name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">ray</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">TransformersWrapper</span><span class="p">)</span>
            <span class="o">.</span><span class="n">options</span><span class="p">(</span>
                <span class="n">max_concurrency</span><span class="o">=</span><span class="n">max_concurrency</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">actor_name</span><span class="p">,</span>
                <span class="n">num_gpus</span><span class="o">=</span><span class="n">num_gpus</span><span class="p">,</span>
                <span class="n">num_cpus</span><span class="o">=</span><span class="n">num_cpus</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass that automatically handles remote execution.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">forward</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>

<div class="viewcode-block" id="RemoteTransformersWrapper.get_new_version"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.RemoteTransformersWrapper.html#torchrl.modules.llm.RemoteTransformersWrapper.get_new_version">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_new_version</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get a new version of the wrapper with altered parameters.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">get_new_version</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">))</span></div>

<div class="viewcode-block" id="RemoteTransformersWrapper.get_dist"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.RemoteTransformersWrapper.html#torchrl.modules.llm.RemoteTransformersWrapper.get_dist">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution from logits/log-probs with optional masking.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">get_dist</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span></div>

<div class="viewcode-block" id="RemoteTransformersWrapper.get_dist_with_prompt_mask"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.RemoteTransformersWrapper.html#torchrl.modules.llm.RemoteTransformersWrapper.get_dist_with_prompt_mask">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_dist_with_prompt_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution masked to only include response tokens (exclude prompt).&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">get_dist_with_prompt_mask</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_dist_with_assistant_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution masked to only include assistant tokens.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">_get_dist_with_assistant_mask</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span>
                <span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_dist_with_attention_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution masked using attention mask.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">_get_dist_with_attention_mask</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span>
                <span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_dist_with_custom_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution with custom mask.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">_get_dist_with_custom_mask</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_sft_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution suitable for SFT loss (response tokens only).&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">_get_sft_dist</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_rlhf_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution suitable for RLHF loss (assistant tokens only).&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">_get_rlhf_dist</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_generic_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get distribution suitable for generic losses (all tokens).&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">_get_generic_dist</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="p">)</span>

<div class="viewcode-block" id="RemoteTransformersWrapper.log_prob"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.RemoteTransformersWrapper.html#torchrl.modules.llm.RemoteTransformersWrapper.log_prob">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute log probabilities.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">log_prob</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span></div>

<div class="viewcode-block" id="RemoteTransformersWrapper.cleanup_batching"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.RemoteTransformersWrapper.html#torchrl.modules.llm.RemoteTransformersWrapper.cleanup_batching">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">cleanup_batching</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clean up batching resources.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">cleanup_batching</span><span class="o">.</span><span class="n">remote</span><span class="p">())</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Cleanup when the wrapper is destroyed.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_remote_wrapper&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ray</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
                <span class="c1"># Clean up batching resources</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">cleanup_batching</span><span class="o">.</span><span class="n">remote</span><span class="p">())</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="k">pass</span>  <span class="c1"># Ignore cleanup errors during destruction</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">pass</span>  <span class="c1"># Ignore any errors during cleanup</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Context manager entry.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exc_type</span><span class="p">,</span> <span class="n">exc_val</span><span class="p">,</span> <span class="n">exc_tb</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Context manager exit with cleanup.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cleanup_batching</span><span class="p">()</span>

<div class="viewcode-block" id="RemoteTransformersWrapper.get_batching_state"><a class="viewcode-back" href="../../../../../reference/generated/torchrl.modules.llm.RemoteTransformersWrapper.html#torchrl.modules.llm.RemoteTransformersWrapper.get_batching_state">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_batching_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the current batching state.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">get_batching_state</span><span class="o">.</span><span class="n">remote</span><span class="p">())</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Whether text generation is enabled.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">generate</span><span class="o">.</span><span class="n">remote</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">pad_output</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Whether output sequences are padded.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">pad_output</span><span class="o">.</span><span class="n">remote</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">text_key</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The key for text output.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">text_key</span><span class="o">.</span><span class="n">remote</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">tokens_key</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The key for tokens output.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">tokens_key</span><span class="o">.</span><span class="n">remote</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">masks_key</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The key for masks output.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">masks_key</span><span class="o">.</span><span class="n">remote</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">log_probs_key</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The key for log probabilities output.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">log_probs_key</span><span class="o">.</span><span class="n">remote</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The input keys.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">in_keys</span><span class="o">.</span><span class="n">remote</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The output keys.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">out_keys</span><span class="o">.</span><span class="n">remote</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">inplace</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Whether in-place operations are used.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">inplace</span><span class="o">.</span><span class="n">remote</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The device used for computation.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">remote</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">layout</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The layout used for output tensors.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">layout</span><span class="o">.</span><span class="n">remote</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">num_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The number of samples to generate.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">num_samples</span><span class="o">.</span><span class="n">remote</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">batching</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Whether batching is enabled.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">batching</span><span class="o">.</span><span class="n">remote</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">collector</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The collector associated with the module.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">collector</span><span class="o">.</span><span class="n">remote</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">log_prob_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The keys for log probabilities.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">log_prob_keys</span><span class="o">.</span><span class="n">remote</span><span class="p">)</span>

    <span class="nd">@log_prob_keys</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">log_prob_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the keys for log probabilities.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">log_prob_keys</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">dist_params_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The keys for distribution parameters.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">dist_params_keys</span><span class="o">.</span><span class="n">remote</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">dist_sample_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The keys for distribution samples.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>

        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_remote_wrapper</span><span class="o">.</span><span class="n">dist_sample_keys</span><span class="o">.</span><span class="n">remote</span><span class="p">)</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../../" src="../../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../../" id="documentation_options" src="../../../../../_static/documentation_options.js"></script>
         <script src="../../../../../_static/jquery.js"></script>
         <script src="../../../../../_static/underscore.js"></script>
         <script src="../../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../../../_static/doctools.js"></script>
         <script src="../../../../../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrl = $("#tutorial-type").text();
	      var githubLink = "https://github.com/pytorch/rl/blob/main/tutorials/sphinx-"  + tutorialUrl + ".py",
		  notebookLink = $(".sphx-glr-download-jupyter").find(".download.reference")[0].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/rl/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }

          var overwrite = function(_) {
              if ($(this).length > 0) {
                  $(this)[0].href = "https://github.com/pytorch/rl"
              }
          }
          // PC
          $(".main-menu a:contains('GitHub')").each(overwrite);
          // Mobile
          $(".main-menu a:contains('Github')").each(overwrite);
      });

      
       $(window).ready(function() {
           var original = window.sideMenus.bind;
           var startup = true;
           window.sideMenus.bind = function() {
               original();
               if (startup) {
                   $("#pytorch-right-menu a.reference.internal").each(function(i) {
                       if (this.classList.contains("not-expanded")) {
                           this.nextElementSibling.style.display = "block";
                           this.classList.remove("not-expanded");
                           this.classList.add("expanded");
                       }
                   });
                   startup = false;
               }
           };
       });
    </script>

    


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch Documentation</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">Newsletter</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">Cloud Credit Program</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">Technical Advisory Council</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">Staff</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">Contact Us</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>



<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchrl.modules.tensordict_module.actors &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','UA-117752657-2');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="../../../../../versions.html"><span style="font-size:110%">main (0.7.0+edfa25d) &#x25BC</span></a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-0.html">Get started with Environments, TED and transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-1.html">Get started with TorchRLâ€™s modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-2.html">Getting started with model optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-3.html">Get started with data collection and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-4.html">Get started with logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-5.html">Get started with your own first training loop</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/coding_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/torchrl_demo.html">Introduction to TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/multiagent_ppo.html">Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/torchrl_envs.html">TorchRL envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/pretrained_models.html">Using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/dqn_with_rnn.html">Recurrent DQN: Training recurrent policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/rb_tutorial.html">Using Replay Buffers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/export.html">Exporting TorchRL modules</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/multiagent_competitive_ddpg.html">Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/coding_ddpg.html">TorchRL objectives: Coding a DDPG loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/coding_dqn.html">TorchRL trainer: A DQN example</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../reference/index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../reference/knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
      <li>torchrl.modules.tensordict_module.actors</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
    
    
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=UA-117752657-2"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torchrl.modules.tensordict_module.actors</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">unravel_key</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.nn</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">CompositeDistribution</span><span class="p">,</span>
    <span class="n">dispatch</span><span class="p">,</span>
    <span class="n">TensorDictModule</span><span class="p">,</span>
    <span class="n">TensorDictModuleBase</span><span class="p">,</span>
    <span class="n">TensorDictModuleWrapper</span><span class="p">,</span>
    <span class="n">TensorDictSequential</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">expand_as_right</span><span class="p">,</span> <span class="n">NestedKey</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Categorical</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl._utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_replace_last</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data.tensor_specs</span><span class="w"> </span><span class="kn">import</span> <span class="n">Composite</span><span class="p">,</span> <span class="n">TensorSpec</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_process_action_space_spec</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.modules.tensordict_module.common</span><span class="w"> </span><span class="kn">import</span> <span class="n">DistributionalDQNnet</span><span class="p">,</span> <span class="n">SafeModule</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.modules.tensordict_module.probabilistic</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">SafeProbabilisticModule</span><span class="p">,</span>
    <span class="n">SafeProbabilisticTensorDictSequential</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.modules.tensordict_module.sequence</span><span class="w"> </span><span class="kn">import</span> <span class="n">SafeSequential</span>


<div class="viewcode-block" id="Actor"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.Actor.html#torchrl.modules.Actor">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">Actor</span><span class="p">(</span><span class="n">SafeModule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;General class for deterministic actors in RL.</span>

<span class="sd">    The Actor class comes with default values for the out_keys (``[&quot;action&quot;]``)</span>
<span class="sd">    and if the spec is provided but not as a</span>
<span class="sd">    :class:`~torchrl.data.Composite` object, it will be</span>
<span class="sd">    automatically translated into ``spec = Composite(action=spec)``.</span>

<span class="sd">    Args:</span>
<span class="sd">        module (nn.Module): a :class:`~torch.nn.Module` used to map the input to</span>
<span class="sd">            the output parameter space.</span>
<span class="sd">        in_keys (iterable of str, optional): keys to be read from input</span>
<span class="sd">            tensordict and passed to the module. If it</span>
<span class="sd">            contains more than one element, the values will be passed in the</span>
<span class="sd">            order given by the in_keys iterable.</span>
<span class="sd">            Defaults to ``[&quot;observation&quot;]``.</span>
<span class="sd">        out_keys (iterable of str): keys to be written to the input tensordict.</span>
<span class="sd">            The length of out_keys must match the</span>
<span class="sd">            number of tensors returned by the embedded module. Using ``&quot;_&quot;`` as a</span>
<span class="sd">            key avoid writing tensor to output.</span>
<span class="sd">            Defaults to ``[&quot;action&quot;]``.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        spec (TensorSpec, optional): Keyword-only argument.</span>
<span class="sd">            Specs of the output tensor. If the module</span>
<span class="sd">            outputs multiple output tensors,</span>
<span class="sd">            spec characterize the space of the first output tensor.</span>
<span class="sd">        safe (bool): Keyword-only argument.</span>
<span class="sd">            If ``True``, the value of the output is checked against the</span>
<span class="sd">            input spec. Out-of-domain sampling can</span>
<span class="sd">            occur because of exploration policies or numerical under/overflow</span>
<span class="sd">            issues. If this value is out of bounds, it is projected back onto the</span>
<span class="sd">            desired space using the :meth:`~torchrl.data.TensorSpec.project`</span>
<span class="sd">            method. Default is ``False``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import Unbounded</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import Actor</span>
<span class="sd">        &gt;&gt;&gt; torch.manual_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;observation&quot;: torch.randn(3, 4)}, [3,])</span>
<span class="sd">        &gt;&gt;&gt; action_spec = Unbounded(4)</span>
<span class="sd">        &gt;&gt;&gt; module = torch.nn.Linear(4, 4)</span>
<span class="sd">        &gt;&gt;&gt; td_module = Actor(</span>
<span class="sd">        ...    module=module,</span>
<span class="sd">        ...    spec=action_spec,</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; td_module(td)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; print(td.get(&quot;action&quot;))</span>
<span class="sd">        tensor([[-1.3635, -0.0340,  0.1476, -1.3911],</span>
<span class="sd">                [-0.1664,  0.5455,  0.2247, -0.4583],</span>
<span class="sd">                [-0.2916,  0.2160,  0.5337, -0.5193]], grad_fn=&lt;AddmmBackward0&gt;)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorSpec</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="s2">&quot;action&quot;</span> <span class="ow">in</span> <span class="n">out_keys</span>
            <span class="ow">and</span> <span class="n">spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="n">spec</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">module</span><span class="p">,</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">spec</span><span class="o">=</span><span class="n">spec</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="ProbabilisticActor"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor.html#torchrl.modules.ProbabilisticActor">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ProbabilisticActor</span><span class="p">(</span><span class="n">SafeProbabilisticTensorDictSequential</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;General class for probabilistic actors in RL.</span>

<span class="sd">    The Actor class comes with default values for the out_keys ([&quot;action&quot;])</span>
<span class="sd">    and if the spec is provided but not as a Composite object, it will be</span>
<span class="sd">    automatically translated into :obj:`spec = Composite(action=spec)`</span>

<span class="sd">    Args:</span>
<span class="sd">        module (nn.Module): a :class:`torch.nn.Module` used to map the input to</span>
<span class="sd">            the output parameter space.</span>
<span class="sd">        in_keys (str or iterable of str or dict): key(s) that will be read from the</span>
<span class="sd">            input TensorDict and used to build the distribution. Importantly, if it&#39;s an</span>
<span class="sd">            iterable of string or a string, those keys must match the keywords used by</span>
<span class="sd">            the distribution class of interest, e.g. :obj:`&quot;loc&quot;` and :obj:`&quot;scale&quot;` for</span>
<span class="sd">            the Normal distribution and similar. If in_keys is a dictionary,, the keys</span>
<span class="sd">            are the keys of the distribution and the values are the keys in the</span>
<span class="sd">            tensordict that will get match to the corresponding distribution keys.</span>
<span class="sd">        out_keys (str or iterable of str): keys where the sampled values will be</span>
<span class="sd">            written. Importantly, if these keys are found in the input TensorDict, the</span>
<span class="sd">            sampling step will be skipped.</span>
<span class="sd">        spec (TensorSpec, optional): keyword-only argument containing the specs</span>
<span class="sd">            of the output tensor. If the module outputs multiple output tensors,</span>
<span class="sd">            spec characterize the space of the first output tensor.</span>
<span class="sd">        safe (bool): keyword-only argument. if ``True``, the value of the output is checked against the</span>
<span class="sd">            input spec. Out-of-domain sampling can</span>
<span class="sd">            occur because of exploration policies or numerical under/overflow</span>
<span class="sd">            issues. If this value is out of bounds, it is projected back onto the</span>
<span class="sd">            desired space using the :obj:`TensorSpec.project`</span>
<span class="sd">            method. Default is ``False``.</span>
<span class="sd">        default_interaction_type (tensordict.nn.InteractionType, optional): keyword-only argument.</span>
<span class="sd">            Default method to be used to retrieve</span>
<span class="sd">            the output value. Should be one of: ``InteractionType.MODE``, ``InteractionType.DETERMINISTIC``,</span>
<span class="sd">            ``InteractionType.MEDIAN``, ``InteractionType.MEAN`` or</span>
<span class="sd">            ``InteractionType.RANDOM`` (in which case the value is sampled</span>
<span class="sd">            randomly from the distribution).</span>
<span class="sd">            TorchRL&#39;s ``ExplorationType`` class is a proxy to ``InteractionType``.</span>
<span class="sd">            Defaults to ``InteractionType.DETERMINISTIC``.</span>

<span class="sd">            .. note:: When a sample is drawn, the :class:`ProbabilisticActor` instance will</span>
<span class="sd">              first look for the interaction mode dictated by the</span>
<span class="sd">              :func:`~tensordict.nn.probabilistic.interaction_type`</span>
<span class="sd">              global function. If this returns `None` (its default value), then the</span>
<span class="sd">              `default_interaction_type` of the `ProbabilisticTDModule`</span>
<span class="sd">              instance will be used. Note that</span>
<span class="sd">              :class:`~torchrl.collectors.collectors.DataCollectorBase`</span>
<span class="sd">              instances will use `set_interaction_type` to</span>
<span class="sd">              :class:`tensordict.nn.InteractionType.RANDOM` by default.</span>

<span class="sd">        distribution_class (Type, optional): keyword-only argument.</span>
<span class="sd">            A :class:`torch.distributions.Distribution` class to</span>
<span class="sd">            be used for sampling.</span>
<span class="sd">            Default is :class:`tensordict.nn.distributions.Delta`.</span>

<span class="sd">            .. note:: if ``distribution_class`` is of type :class:`~tensordict.nn.distributions.CompositeDistribution`,</span>
<span class="sd">                the keys will be inferred from the ``distribution_map`` / ``name_map`` keyword arguments of that</span>
<span class="sd">                distribution. If this distribution is used with another constructor (e.g.,  partial or lambda function)</span>
<span class="sd">                then the out_keys will need to be provided explicitly.</span>
<span class="sd">                Note also that actions will __not__ be prefixed with an ``&quot;action&quot;`` key, see the example below</span>
<span class="sd">                on how this can be  achieved with a ``ProbabilisticActor``.</span>

<span class="sd">        distribution_kwargs (dict, optional): keyword-only argument.</span>
<span class="sd">            Keyword-argument pairs to be passed to the distribution.</span>
<span class="sd">        return_log_prob (bool, optional): keyword-only argument.</span>
<span class="sd">            If ``True``, the log-probability of the</span>
<span class="sd">            distribution sample will be written in the tensordict with the key</span>
<span class="sd">            `&#39;sample_log_prob&#39;`. Default is ``False``.</span>
<span class="sd">        cache_dist (bool, optional): keyword-only argument.</span>
<span class="sd">            EXPERIMENTAL: if ``True``, the parameters of the</span>
<span class="sd">            distribution (i.e. the output of the module) will be written to the</span>
<span class="sd">            tensordict along with the sample. Those parameters can be used to re-compute</span>
<span class="sd">            the original distribution later on (e.g. to compute the divergence between</span>
<span class="sd">            the distribution used to sample the action and the updated distribution in</span>
<span class="sd">            PPO). Default is ``False``.</span>
<span class="sd">        n_empirical_estimate (int, optional): keyword-only argument.</span>
<span class="sd">            Number of samples to compute the empirical</span>
<span class="sd">            mean when it is not available. Defaults to 1000.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import Bounded</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import ProbabilisticActor, NormalParamExtractor, TanhNormal</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;observation&quot;: torch.randn(3, 4)}, [3,])</span>
<span class="sd">        &gt;&gt;&gt; action_spec = Bounded(shape=torch.Size([4]),</span>
<span class="sd">        ...    low=-1, high=1)</span>
<span class="sd">        &gt;&gt;&gt; module = nn.Sequential(torch.nn.Linear(4, 8), NormalParamExtractor())</span>
<span class="sd">        &gt;&gt;&gt; tensordict_module = TensorDictModule(module, in_keys=[&quot;observation&quot;], out_keys=[&quot;loc&quot;, &quot;scale&quot;])</span>
<span class="sd">        &gt;&gt;&gt; td_module = ProbabilisticActor(</span>
<span class="sd">        ...    module=tensordict_module,</span>
<span class="sd">        ...    spec=action_spec,</span>
<span class="sd">        ...    in_keys=[&quot;loc&quot;, &quot;scale&quot;],</span>
<span class="sd">        ...    distribution_class=TanhNormal,</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; td = td_module(td)</span>
<span class="sd">        &gt;&gt;&gt; td</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    Probabilistic actors also support compound actions through the</span>
<span class="sd">    :class:`tensordict.nn.CompositeDistribution` class. This distribution takes</span>
<span class="sd">    a tensordict as input (typically `&quot;params&quot;`) and reads it as a whole: the</span>
<span class="sd">    content of this tensordict is the input to the distributions contained in the</span>
<span class="sd">    compound one.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import CompositeDistribution, TensorDictModule</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import ProbabilisticActor</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn, distributions as d</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; class Module(nn.Module):</span>
<span class="sd">        ...     def forward(self, x):</span>
<span class="sd">        ...         return x[..., :3], x[..., 3:6], x[..., 6:]</span>
<span class="sd">        &gt;&gt;&gt; module = TensorDictModule(Module(),</span>
<span class="sd">        ...                           in_keys=[&quot;x&quot;],</span>
<span class="sd">        ...                           out_keys=[(&quot;params&quot;, &quot;normal&quot;, &quot;loc&quot;),</span>
<span class="sd">        ...                              (&quot;params&quot;, &quot;normal&quot;, &quot;scale&quot;),</span>
<span class="sd">        ...                              (&quot;params&quot;, &quot;categ&quot;, &quot;logits&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; actor = ProbabilisticActor(module,</span>
<span class="sd">        ...                            in_keys=[&quot;params&quot;],</span>
<span class="sd">        ...                            distribution_class=CompositeDistribution,</span>
<span class="sd">        ...                            distribution_kwargs={&quot;distribution_map&quot;: {</span>
<span class="sd">        ...                                 &quot;normal&quot;: d.Normal, &quot;categ&quot;: d.Categorical}}</span>
<span class="sd">        ...                           )</span>
<span class="sd">        &gt;&gt;&gt; data = TensorDict({&quot;x&quot;: torch.rand(10)}, [])</span>
<span class="sd">        &gt;&gt;&gt; actor(data)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                categ: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                normal: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                params: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        categ: TensorDict(</span>
<span class="sd">                            fields={</span>
<span class="sd">                                logits: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">                            batch_size=torch.Size([]),</span>
<span class="sd">                            device=None,</span>
<span class="sd">                            is_shared=False),</span>
<span class="sd">                        normal: TensorDict(</span>
<span class="sd">                            fields={</span>
<span class="sd">                                loc: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                                scale: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">                            batch_size=torch.Size([]),</span>
<span class="sd">                            device=None,</span>
<span class="sd">                            is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([]),</span>
<span class="sd">                    device=None,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                x: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    Using a probabilistic actor with a composite distribution can be achieved using the following</span>
<span class="sd">    example code:</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import CompositeDistribution</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">        &gt;&gt;&gt; from torch import distributions as d</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import ProbabilisticActor</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; class Module(nn.Module):</span>
<span class="sd">        ...     def forward(self, x):</span>
<span class="sd">        ...         return x[..., :3], x[..., 3:6], x[..., 6:]</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; module = TensorDictModule(Module(),</span>
<span class="sd">        ...                           in_keys=[&quot;x&quot;],</span>
<span class="sd">        ...                           out_keys=[</span>
<span class="sd">        ...                               (&quot;params&quot;, &quot;normal&quot;, &quot;loc&quot;), (&quot;params&quot;, &quot;normal&quot;, &quot;scale&quot;), (&quot;params&quot;, &quot;categ&quot;, &quot;logits&quot;)</span>
<span class="sd">        ...                           ])</span>
<span class="sd">        &gt;&gt;&gt; actor = ProbabilisticActor(module,</span>
<span class="sd">        ...                            in_keys=[&quot;params&quot;],</span>
<span class="sd">        ...                            distribution_class=CompositeDistribution,</span>
<span class="sd">        ...                            distribution_kwargs={&quot;distribution_map&quot;: {&quot;normal&quot;: d.Normal, &quot;categ&quot;: d.Categorical},</span>
<span class="sd">        ...                                                 &quot;name_map&quot;: {&quot;normal&quot;: (&quot;action&quot;, &quot;normal&quot;),</span>
<span class="sd">        ...                                                              &quot;categ&quot;: (&quot;action&quot;, &quot;categ&quot;)}}</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; print(actor.out_keys)</span>
<span class="sd">        [(&#39;params&#39;, &#39;normal&#39;, &#39;loc&#39;), (&#39;params&#39;, &#39;normal&#39;, &#39;scale&#39;), (&#39;params&#39;, &#39;categ&#39;, &#39;logits&#39;), (&#39;action&#39;, &#39;normal&#39;), (&#39;action&#39;, &#39;categ&#39;)]</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; data = TensorDict({&quot;x&quot;: torch.rand(10)}, [])</span>
<span class="sd">        &gt;&gt;&gt; module(data)</span>
<span class="sd">        &gt;&gt;&gt; print(actor(data))</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        categ: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                        normal: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([]),</span>
<span class="sd">                    device=None,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                params: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        categ: TensorDict(</span>
<span class="sd">                            fields={</span>
<span class="sd">                                logits: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">                            batch_size=torch.Size([]),</span>
<span class="sd">                            device=None,</span>
<span class="sd">                            is_shared=False),</span>
<span class="sd">                        normal: TensorDict(</span>
<span class="sd">                            fields={</span>
<span class="sd">                                loc: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                                scale: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">                            batch_size=torch.Size([]),</span>
<span class="sd">                            device=None,</span>
<span class="sd">                            is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([]),</span>
<span class="sd">                    device=None,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                x: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]],</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorSpec</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">distribution_class</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;distribution_class&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">distribution_class</span> <span class="ow">is</span> <span class="n">CompositeDistribution</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">&quot;distribution_map&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;distribution_kwargs&quot;</span><span class="p">,</span> <span class="p">{}):</span>
                    <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                        <span class="s2">&quot;&#39;distribution_map&#39; must be provided within &quot;</span>
                        <span class="s2">&quot;distribution_kwargs whenever the distribution is of type CompositeDistribution.&quot;</span>
                    <span class="p">)</span>
                <span class="n">distribution_map</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;distribution_kwargs&quot;</span><span class="p">][</span><span class="s2">&quot;distribution_map&quot;</span><span class="p">]</span>
                <span class="n">name_map</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;distribution_kwargs&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;name_map&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">name_map</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">out_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">name_map</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">out_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">distribution_map</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">out_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_keys</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">({</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="n">spec</span><span class="p">})</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">module</span><span class="p">,</span>
            <span class="n">SafeProbabilisticModule</span><span class="p">(</span>
                <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span> <span class="n">spec</span><span class="o">=</span><span class="n">spec</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">),</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="ValueOperator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ValueOperator.html#torchrl.modules.ValueOperator">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ValueOperator</span><span class="p">(</span><span class="n">TensorDictModule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;General class for value functions in RL.</span>

<span class="sd">    The ValueOperator class comes with default values for the in_keys and</span>
<span class="sd">    out_keys arguments ([&quot;observation&quot;] and [&quot;state_value&quot;] or</span>
<span class="sd">    [&quot;state_action_value&quot;], respectively and depending on whether the &quot;action&quot;</span>
<span class="sd">    key is part of the in_keys list).</span>

<span class="sd">    Args:</span>
<span class="sd">        module (nn.Module): a :class:`torch.nn.Module` used to map the input to</span>
<span class="sd">            the output parameter space.</span>
<span class="sd">        in_keys (iterable of str, optional): keys to be read from input</span>
<span class="sd">            tensordict and passed to the module. If it</span>
<span class="sd">            contains more than one element, the values will be passed in the</span>
<span class="sd">            order given by the in_keys iterable.</span>
<span class="sd">            Defaults to ``[&quot;observation&quot;]``.</span>
<span class="sd">        out_keys (iterable of str): keys to be written to the input tensordict.</span>
<span class="sd">            The length of out_keys must match the</span>
<span class="sd">            number of tensors returned by the embedded module. Using &quot;_&quot; as a</span>
<span class="sd">            key avoid writing tensor to output.</span>
<span class="sd">            Defaults to ``[&quot;state_value&quot;]`` or</span>
<span class="sd">            ``[&quot;state_action_value&quot;]`` if ``&quot;action&quot;`` is part of the ``in_keys``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import Unbounded</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import ValueOperator</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;observation&quot;: torch.randn(3, 4), &quot;action&quot;: torch.randn(3, 2)}, [3,])</span>
<span class="sd">        &gt;&gt;&gt; class CustomModule(nn.Module):</span>
<span class="sd">        ...     def __init__(self):</span>
<span class="sd">        ...         super().__init__()</span>
<span class="sd">        ...         self.linear = torch.nn.Linear(6, 1)</span>
<span class="sd">        ...     def forward(self, obs, action):</span>
<span class="sd">        ...         return self.linear(torch.cat([obs, action], -1))</span>
<span class="sd">        &gt;&gt;&gt; module = CustomModule()</span>
<span class="sd">        &gt;&gt;&gt; td_module = ValueOperator(</span>
<span class="sd">        ...    in_keys=[&quot;observation&quot;, &quot;action&quot;], module=module</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; td = td_module(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 2]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                state_action_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>


<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">[</span><span class="s2">&quot;state_value&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;action&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">in_keys</span> <span class="k">else</span> <span class="p">[</span><span class="s2">&quot;state_action_value&quot;</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">module</span><span class="o">=</span><span class="n">module</span><span class="p">,</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="QValueModule"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.QValueModule.html#torchrl.modules.QValueModule">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">QValueModule</span><span class="p">(</span><span class="n">TensorDictModuleBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Q-Value TensorDictModule for Q-value policies.</span>

<span class="sd">    This module processes a tensor containing action value into is argmax</span>
<span class="sd">    component (i.e. the resulting greedy action), following a given</span>
<span class="sd">    action space (one-hot, binary or categorical).</span>
<span class="sd">    It works with both tensordict and regular tensors.</span>

<span class="sd">    Args:</span>
<span class="sd">        action_space (str, optional): Action space. Must be one of</span>
<span class="sd">            ``&quot;one-hot&quot;``, ``&quot;mult-one-hot&quot;``, ``&quot;binary&quot;`` or ``&quot;categorical&quot;``.</span>
<span class="sd">            This argument is exclusive with ``spec``, since ``spec``</span>
<span class="sd">            conditions the action_space.</span>
<span class="sd">        action_value_key (str or tuple of str, optional): The input key</span>
<span class="sd">            representing the action value. Defaults to ``&quot;action_value&quot;``.</span>
<span class="sd">        action_mask_key (str or tuple of str, optional): The input key</span>
<span class="sd">            representing the action mask. Defaults to ``&quot;None&quot;`` (equivalent to no masking).</span>
<span class="sd">        out_keys (list of str or tuple of str, optional): The output keys</span>
<span class="sd">            representing the actions, action values and chosen action value.</span>
<span class="sd">            Defaults to ``[&quot;action&quot;, &quot;action_value&quot;, &quot;chosen_action_value&quot;]``.</span>
<span class="sd">        var_nums (int, optional): if ``action_space = &quot;mult-one-hot&quot;``,</span>
<span class="sd">            this value represents the cardinality of each</span>
<span class="sd">            action component.</span>
<span class="sd">        spec (TensorSpec, optional): if provided, the specs of the action (and/or</span>
<span class="sd">            other outputs). This is exclusive with ``action_space``, as the spec</span>
<span class="sd">            conditions the action space.</span>
<span class="sd">        safe (bool): if ``True``, the value of the output is checked against the</span>
<span class="sd">            input spec. Out-of-domain sampling can</span>
<span class="sd">            occur because of exploration policies or numerical under/overflow issues.</span>
<span class="sd">            If this value is out of bounds, it is projected back onto the</span>
<span class="sd">            desired space using the :obj:`TensorSpec.project`</span>
<span class="sd">            method. Default is ``False``.</span>

<span class="sd">    Returns:</span>
<span class="sd">        if the input is a single tensor, a triplet containing the chosen action,</span>
<span class="sd">        the values and the value of the chose action is returned. If a tensordict</span>
<span class="sd">        is provided, it is updated with these entries at the keys indicated by the</span>
<span class="sd">        ``out_keys`` field.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; action_space = &quot;categorical&quot;</span>
<span class="sd">        &gt;&gt;&gt; action_value_key = &quot;my_action_value&quot;</span>
<span class="sd">        &gt;&gt;&gt; actor = QValueModule(action_space, action_value_key=action_value_key)</span>
<span class="sd">        &gt;&gt;&gt; # This module works with both tensordict and regular tensors:</span>
<span class="sd">        &gt;&gt;&gt; value = torch.zeros(4)</span>
<span class="sd">        &gt;&gt;&gt; value[-1] = 1</span>
<span class="sd">        &gt;&gt;&gt; actor(my_action_value=value)</span>
<span class="sd">        (tensor(3), tensor([0., 0., 0., 1.]), tensor([1.]))</span>
<span class="sd">        &gt;&gt;&gt; actor(value)</span>
<span class="sd">        (tensor(3), tensor([0., 0., 0., 1.]), tensor([1.]))</span>
<span class="sd">        &gt;&gt;&gt; actor(TensorDict({action_value_key: value}, []))</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                action_value: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                chosen_action_value: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                my_action_value: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">action_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_value_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_mask_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">var_nums</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorSpec</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">safe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="n">TensorSpec</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Using specs in action_space is deprecated&quot;</span><span class="p">)</span>
        <span class="n">action_space</span><span class="p">,</span> <span class="n">spec</span> <span class="o">=</span> <span class="n">_process_action_space_spec</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="n">spec</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">action_space</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var_nums</span> <span class="o">=</span> <span class="n">var_nums</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_func_mapping</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;one_hot&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_one_hot</span><span class="p">,</span>
            <span class="s2">&quot;mult_one_hot&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mult_one_hot</span><span class="p">,</span>
            <span class="s2">&quot;binary&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_binary</span><span class="p">,</span>
            <span class="s2">&quot;categorical&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_categorical</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_value_func_mapping</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;categorical&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_action_value</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">action_space</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_func_mapping</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;action_space must be one of </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_func_mapping</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">, got </span><span class="si">{</span><span class="n">action_space</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">action_value_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">action_value_key</span> <span class="o">=</span> <span class="s2">&quot;action_value&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span> <span class="o">=</span> <span class="n">action_mask_key</span>
        <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">action_value_key</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">in_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="n">in_keys</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">,</span> <span class="n">action_value_key</span><span class="p">,</span> <span class="s2">&quot;chosen_action_value&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">action_value_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">out_keys</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected the action-value key to be &#39;</span><span class="si">{</span><span class="n">action_value_key</span><span class="si">}</span><span class="s2">&#39; but got </span><span class="si">{</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">=</span> <span class="n">out_keys</span>
        <span class="n">action_key</span> <span class="o">=</span> <span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">({</span><span class="n">action_key</span><span class="p">:</span> <span class="n">spec</span><span class="p">})</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_spec</span><span class="p">(</span><span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">,</span> <span class="n">spec</span><span class="o">=</span><span class="n">spec</span><span class="p">)</span>

    <span class="n">register_spec</span> <span class="o">=</span> <span class="n">SafeModule</span><span class="o">.</span><span class="n">register_spec</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">spec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composite</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span>

    <span class="nd">@spec</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spec</span><span class="p">:</span> <span class="n">Composite</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Trying to set an object of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">spec</span><span class="p">)</span><span class="si">}</span><span class="s2"> as a tensorspec but expected a Composite instance.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span> <span class="o">=</span> <span class="n">spec</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">action_value_key</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<div class="viewcode-block" id="QValueModule.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.QValueModule.html#torchrl.modules.QValueModule.forward">[docs]</a>    <span class="nd">@dispatch</span><span class="p">(</span><span class="n">auto_batch_size</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">action_values</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">action_values</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Action value key </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span><span class="si">}</span><span class="s2"> not found in </span><span class="si">{</span><span class="n">tensordict</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">action_mask</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">action_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Action mask key </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span><span class="si">}</span><span class="s2"> not found in </span><span class="si">{</span><span class="n">tensordict</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="n">action_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="n">action_mask</span><span class="p">,</span> <span class="n">action_values</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">action_values</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">min</span>
            <span class="p">)</span>

        <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_func_mapping</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">](</span><span class="n">action_values</span><span class="p">)</span>

        <span class="n">action_value_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_value_func_mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_action_value</span>
        <span class="p">)</span>
        <span class="n">chosen_action_value</span> <span class="o">=</span> <span class="n">action_value_func</span><span class="p">(</span><span class="n">action_values</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
        <span class="n">tensordict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">,</span> <span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">action_values</span><span class="p">,</span> <span class="n">chosen_action_value</span><span class="p">)))</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span></div>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_one_hot</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="p">(</span><span class="n">value</span> <span class="o">==</span> <span class="n">value</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_categorical</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_mult_one_hot</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">support</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_nums</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;var_nums must be provided to the constructor for multi one-hot action spaces.&quot;</span>
            <span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_nums</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_one_hot</span><span class="p">(</span>
                    <span class="n">_value</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">_value</span> <span class="ow">in</span> <span class="n">values</span>
            <span class="p">],</span>
            <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_binary</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">support</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_default_action_value</span><span class="p">(</span>
        <span class="n">values</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">action</span> <span class="o">*</span> <span class="n">values</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_categorical_action_value</span><span class="p">(</span>
        <span class="n">values</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">values</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span></div>
        <span class="c1"># if values.ndim == 1:</span>
        <span class="c1">#     return values[action].unsqueeze(-1)</span>
        <span class="c1"># batch_size = values.size(0)</span>
        <span class="c1"># return values[range(batch_size), action].unsqueeze(-1)</span>


<div class="viewcode-block" id="DistributionalQValueModule"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.DistributionalQValueModule.html#torchrl.modules.DistributionalQValueModule">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">DistributionalQValueModule</span><span class="p">(</span><span class="n">QValueModule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Distributional Q-Value hook for Q-value policies.</span>

<span class="sd">    This module processes a tensor containing action value logits into is argmax</span>
<span class="sd">    component (i.e. the resulting greedy action), following a given</span>
<span class="sd">    action space (one-hot, binary or categorical).</span>
<span class="sd">    It works with both tensordict and regular tensors.</span>

<span class="sd">    The input action value is expected to be the result of a log-softmax</span>
<span class="sd">    operation.</span>

<span class="sd">    For more details regarding Distributional DQN, refer to &quot;A Distributional Perspective on Reinforcement Learning&quot;,</span>
<span class="sd">    https://arxiv.org/pdf/1707.06887.pdf</span>

<span class="sd">    Args:</span>
<span class="sd">        action_space (str, optional): Action space. Must be one of</span>
<span class="sd">            ``&quot;one-hot&quot;``, ``&quot;mult-one-hot&quot;``, ``&quot;binary&quot;`` or ``&quot;categorical&quot;``.</span>
<span class="sd">            This argument is exclusive with ``spec``, since ``spec``</span>
<span class="sd">            conditions the action_space.</span>
<span class="sd">        support (torch.Tensor): support of the action values.</span>
<span class="sd">        action_value_key (str or tuple of str, optional): The input key</span>
<span class="sd">            representing the action value. Defaults to ``&quot;action_value&quot;``.</span>
<span class="sd">        action_mask_key (str or tuple of str, optional): The input key</span>
<span class="sd">            representing the action mask. Defaults to ``&quot;None&quot;`` (equivalent to no masking).</span>
<span class="sd">        out_keys (list of str or tuple of str, optional): The output keys</span>
<span class="sd">            representing the actions and action values.</span>
<span class="sd">            Defaults to ``[&quot;action&quot;, &quot;action_value&quot;]``.</span>
<span class="sd">        var_nums (int, optional): if ``action_space = &quot;mult-one-hot&quot;``,</span>
<span class="sd">            this value represents the cardinality of each</span>
<span class="sd">            action component.</span>
<span class="sd">        spec (TensorSpec, optional): if provided, the specs of the action (and/or</span>
<span class="sd">            other outputs). This is exclusive with ``action_space``, as the spec</span>
<span class="sd">            conditions the action space.</span>
<span class="sd">        safe (bool): if ``True``, the value of the output is checked against the</span>
<span class="sd">            input spec. Out-of-domain sampling can</span>
<span class="sd">            occur because of exploration policies or numerical under/overflow issues.</span>
<span class="sd">            If this value is out of bounds, it is projected back onto the</span>
<span class="sd">            desired space using the :obj:`TensorSpec.project`</span>
<span class="sd">            method. Default is ``False``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; torch.manual_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; action_space = &quot;categorical&quot;</span>
<span class="sd">        &gt;&gt;&gt; action_value_key = &quot;my_action_value&quot;</span>
<span class="sd">        &gt;&gt;&gt; support = torch.tensor([-1, 0.0, 1.0]) # the action value is between -1 and 1</span>
<span class="sd">        &gt;&gt;&gt; actor = DistributionalQValueModule(action_space, support=support, action_value_key=action_value_key)</span>
<span class="sd">        &gt;&gt;&gt; # This module works with both tensordict and regular tensors:</span>
<span class="sd">        &gt;&gt;&gt; value = torch.full((3, 4), -100)</span>
<span class="sd">        &gt;&gt;&gt; # the first bin (-1) of the first action is high: there&#39;s a high chance that it has a low value</span>
<span class="sd">        &gt;&gt;&gt; value[0, 0] = 0</span>
<span class="sd">        &gt;&gt;&gt; # the second bin (0) of the second action is high: there&#39;s a high chance that it has an intermediate value</span>
<span class="sd">        &gt;&gt;&gt; value[1, 1] = 0</span>
<span class="sd">        &gt;&gt;&gt; # the third bin (0) of the thid action is high: there&#39;s a high chance that it has an high value</span>
<span class="sd">        &gt;&gt;&gt; value[2, 2] = 0</span>
<span class="sd">        &gt;&gt;&gt; actor(my_action_value=value)</span>
<span class="sd">        (tensor(2), tensor([[   0, -100, -100, -100],</span>
<span class="sd">                [-100,    0, -100, -100],</span>
<span class="sd">                [-100, -100,    0, -100]]))</span>
<span class="sd">        &gt;&gt;&gt; actor(value)</span>
<span class="sd">        (tensor(2), tensor([[   0, -100, -100, -100],</span>
<span class="sd">                [-100,    0, -100, -100],</span>
<span class="sd">                [-100, -100,    0, -100]]))</span>
<span class="sd">        &gt;&gt;&gt; actor(TensorDict({action_value_key: value}, []))</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                my_action_value: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.int64, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">action_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">support</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">action_value_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_mask_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">var_nums</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">spec</span><span class="p">:</span> <span class="n">TensorSpec</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">safe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">action_value_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">action_value_key</span> <span class="o">=</span> <span class="s2">&quot;action_value&quot;</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">,</span> <span class="n">action_value_key</span><span class="p">]</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">action_space</span><span class="o">=</span><span class="n">action_space</span><span class="p">,</span>
            <span class="n">action_value_key</span><span class="o">=</span><span class="n">action_value_key</span><span class="p">,</span>
            <span class="n">action_mask_key</span><span class="o">=</span><span class="n">action_mask_key</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">var_nums</span><span class="o">=</span><span class="n">var_nums</span><span class="p">,</span>
            <span class="n">spec</span><span class="o">=</span><span class="n">spec</span><span class="p">,</span>
            <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;support&quot;</span><span class="p">,</span> <span class="n">support</span><span class="p">)</span>

<div class="viewcode-block" id="DistributionalQValueModule.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.DistributionalQValueModule.html#torchrl.modules.DistributionalQValueModule.forward">[docs]</a>    <span class="nd">@dispatch</span><span class="p">(</span><span class="n">auto_batch_size</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">action_values</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">action_values</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Action value key </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span><span class="si">}</span><span class="s2"> not found in </span><span class="si">{</span><span class="n">tensordict</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">action_mask</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">action_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Action mask key </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">action_mask_key</span><span class="si">}</span><span class="s2"> not found in </span><span class="si">{</span><span class="n">tensordict</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="n">action_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="n">action_mask</span><span class="p">,</span> <span class="n">action_values</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">action_values</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">min</span>
            <span class="p">)</span>

        <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_func_mapping</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">](</span><span class="n">action_values</span><span class="p">)</span>

        <span class="n">tensordict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="nb">dict</span><span class="p">(</span>
                <span class="nb">zip</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">,</span>
                    <span class="p">(</span>
                        <span class="n">action</span><span class="p">,</span>
                        <span class="n">action_values</span><span class="p">,</span>
                    <span class="p">),</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_support_expected</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">log_softmax_values</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">support</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">support</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">support</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">support</span>
        <span class="n">support</span> <span class="o">=</span> <span class="n">support</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">log_softmax_values</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">log_softmax_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">!=</span> <span class="n">support</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Support length and number of atoms in module output should match, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;got self.support.shape=</span><span class="si">{</span><span class="n">support</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> and module(...).shape=</span><span class="si">{</span><span class="n">log_softmax_values</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">log_softmax_values</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;input to QValueHook must be log-softmax values (which are expected to be non-positive numbers). &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;got a maximum value of </span><span class="si">{</span><span class="n">log_softmax_values</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">4.4f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">log_softmax_values</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span> <span class="o">*</span> <span class="n">support</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_one_hot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">support</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">support</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">support</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">support</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;got value of type </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">support</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;got support of type </span><span class="si">{</span><span class="n">support</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_support_expected</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="p">(</span><span class="n">value</span> <span class="o">==</span> <span class="n">value</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_mult_one_hot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">support</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">support</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">support</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">support</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_nums</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_one_hot</span><span class="p">(</span><span class="n">_value</span><span class="p">,</span> <span class="n">_support</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">_value</span><span class="p">,</span> <span class="n">_support</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">support</span><span class="p">)</span>
            <span class="p">],</span>
            <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_categorical</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_support_expected</span><span class="p">(</span>
            <span class="n">value</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_binary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;&#39;binary&#39; is currently not supported for DistributionalQValueModule.&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="QValueHook"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.QValueHook.html#torchrl.modules.QValueHook">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">QValueHook</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Q-Value hook for Q-value policies.</span>

<span class="sd">    Given the output of a regular nn.Module, representing the values of the</span>
<span class="sd">    different discrete actions available,</span>
<span class="sd">    a QValueHook will transform these values into their argmax component (i.e.</span>
<span class="sd">    the resulting greedy action).</span>

<span class="sd">    Args:</span>
<span class="sd">        action_space (str): Action space. Must be one of</span>
<span class="sd">            ``&quot;one-hot&quot;``, ``&quot;mult-one-hot&quot;``, ``&quot;binary&quot;`` or ``&quot;categorical&quot;``.</span>
<span class="sd">        var_nums (int, optional): if ``action_space = &quot;mult-one-hot&quot;``,</span>
<span class="sd">            this value represents the cardinality of each</span>
<span class="sd">            action component.</span>
<span class="sd">        action_value_key (str or tuple of str, optional): to be used when hooked on</span>
<span class="sd">            a TensorDictModule. The input key representing the action value. Defaults</span>
<span class="sd">            to ``&quot;action_value&quot;``.</span>
<span class="sd">        action_mask_key (str or tuple of str, optional): The input key</span>
<span class="sd">            representing the action mask. Defaults to ``&quot;None&quot;`` (equivalent to no masking).</span>
<span class="sd">        out_keys (list of str or tuple of str, optional): to be used when hooked on</span>
<span class="sd">            a TensorDictModule. The output keys representing the actions, action values</span>
<span class="sd">            and chosen action value. Defaults to ``[&quot;action&quot;, &quot;action_value&quot;, &quot;chosen_action_value&quot;]``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import OneHot</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules.tensordict_module.actors import QValueHook, Actor</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&#39;observation&#39;: torch.randn(5, 4)}, [5])</span>
<span class="sd">        &gt;&gt;&gt; module = nn.Linear(4, 4)</span>
<span class="sd">        &gt;&gt;&gt; hook = QValueHook(&quot;one_hot&quot;)</span>
<span class="sd">        &gt;&gt;&gt; module.register_forward_hook(hook)</span>
<span class="sd">        &gt;&gt;&gt; action_spec = OneHot(4)</span>
<span class="sd">        &gt;&gt;&gt; qvalue_actor = Actor(module=module, spec=action_spec, out_keys=[&quot;action&quot;, &quot;action_value&quot;])</span>
<span class="sd">        &gt;&gt;&gt; td = qvalue_actor(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                action_value: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([5]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">action_space</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">var_nums</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_value_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_mask_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="n">TensorSpec</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Using specs in action_space is deprecated. &quot;</span>
                <span class="s2">&quot;Please use the &#39;spec&#39; argument if you want to provide an action spec&quot;</span>
            <span class="p">)</span>
        <span class="n">action_space</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_process_action_space_spec</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">qvalue_model</span> <span class="o">=</span> <span class="n">QValueModule</span><span class="p">(</span>
            <span class="n">action_space</span><span class="o">=</span><span class="n">action_space</span><span class="p">,</span>
            <span class="n">var_nums</span><span class="o">=</span><span class="n">var_nums</span><span class="p">,</span>
            <span class="n">action_value_key</span><span class="o">=</span><span class="n">action_value_key</span><span class="p">,</span>
            <span class="n">action_mask_key</span><span class="o">=</span><span class="n">action_mask_key</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">action_value_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qvalue_model</span><span class="o">.</span><span class="n">in_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_value_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">action_value_key</span> <span class="o">=</span> <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">action_value_key</span><span class="p">)</span>
        <span class="c1"># uses &quot;dispatch&quot; to get and return tensors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span> <span class="o">=</span> <span class="n">action_value_key</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">observation</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">values</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span><span class="p">:</span> <span class="n">values</span><span class="p">}</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">qvalue_model</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="DistributionalQValueHook"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.DistributionalQValueHook.html#torchrl.modules.DistributionalQValueHook">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">DistributionalQValueHook</span><span class="p">(</span><span class="n">QValueHook</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Distributional Q-Value hook for Q-value policies.</span>

<span class="sd">    Given the output of a mapping operator, representing the log-probability of the</span>
<span class="sd">    different action value bin available,</span>
<span class="sd">    a DistributionalQValueHook will transform these values into their argmax</span>
<span class="sd">    component using the provided support.</span>

<span class="sd">    For more details regarding Distributional DQN, refer to &quot;A Distributional Perspective on Reinforcement Learning&quot;,</span>
<span class="sd">    https://arxiv.org/pdf/1707.06887.pdf</span>

<span class="sd">    Args:</span>
<span class="sd">        action_space (str): Action space. Must be one of</span>
<span class="sd">            ``&quot;one-hot&quot;``, ``&quot;mult-one-hot&quot;``, ``&quot;binary&quot;`` or ``&quot;categorical&quot;``.</span>
<span class="sd">        action_value_key (str or tuple of str, optional): to be used when hooked on</span>
<span class="sd">            a TensorDictModule. The input key representing the action value. Defaults</span>
<span class="sd">            to ``&quot;action_value&quot;``.</span>
<span class="sd">        action_mask_key (str or tuple of str, optional): The input key</span>
<span class="sd">            representing the action mask. Defaults to ``&quot;None&quot;`` (equivalent to no masking).</span>
<span class="sd">        support (torch.Tensor): support of the action values.</span>
<span class="sd">        var_nums (int, optional): if ``action_space = &quot;mult-one-hot&quot;``, this</span>
<span class="sd">            value represents the cardinality of each</span>
<span class="sd">            action component.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import OneHot</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules.tensordict_module.actors import DistributionalQValueHook, Actor</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&#39;observation&#39;: torch.randn(5, 4)}, [5])</span>
<span class="sd">        &gt;&gt;&gt; nbins = 3</span>
<span class="sd">        &gt;&gt;&gt; class CustomDistributionalQval(nn.Module):</span>
<span class="sd">        ...     def __init__(self):</span>
<span class="sd">        ...         super().__init__()</span>
<span class="sd">        ...         self.linear = nn.Linear(4, nbins*4)</span>
<span class="sd">        ...</span>
<span class="sd">        ...     def forward(self, x):</span>
<span class="sd">        ...         return self.linear(x).view(-1, nbins, 4).log_softmax(-2)</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; module = CustomDistributionalQval()</span>
<span class="sd">        &gt;&gt;&gt; params = TensorDict.from_module(module)</span>
<span class="sd">        &gt;&gt;&gt; action_spec = OneHot(4)</span>
<span class="sd">        &gt;&gt;&gt; hook = DistributionalQValueHook(&quot;one_hot&quot;, support = torch.arange(nbins))</span>
<span class="sd">        &gt;&gt;&gt; module.register_forward_hook(hook)</span>
<span class="sd">        &gt;&gt;&gt; qvalue_actor = Actor(module=module, spec=action_spec, out_keys=[&quot;action&quot;, &quot;action_value&quot;])</span>
<span class="sd">        &gt;&gt;&gt; with params.to_module(module):</span>
<span class="sd">        ...     qvalue_actor(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(torch.Size([5, 4]), dtype=torch.int64),</span>
<span class="sd">                action_value: Tensor(torch.Size([5, 3, 4]), dtype=torch.float32),</span>
<span class="sd">                observation: Tensor(torch.Size([5, 4]), dtype=torch.float32)},</span>
<span class="sd">            batch_size=torch.Size([5]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">action_space</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">support</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">var_nums</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_value_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_mask_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="n">TensorSpec</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Using specs in action_space is deprecated&quot;</span><span class="p">)</span>
        <span class="n">action_space</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_process_action_space_spec</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qvalue_model</span> <span class="o">=</span> <span class="n">DistributionalQValueModule</span><span class="p">(</span>
            <span class="n">action_space</span><span class="o">=</span><span class="n">action_space</span><span class="p">,</span>
            <span class="n">var_nums</span><span class="o">=</span><span class="n">var_nums</span><span class="p">,</span>
            <span class="n">support</span><span class="o">=</span><span class="n">support</span><span class="p">,</span>
            <span class="n">action_value_key</span><span class="o">=</span><span class="n">action_value_key</span><span class="p">,</span>
            <span class="n">action_mask_key</span><span class="o">=</span><span class="n">action_mask_key</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">action_value_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qvalue_model</span><span class="o">.</span><span class="n">in_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_value_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">action_value_key</span> <span class="o">=</span> <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">action_value_key</span><span class="p">)</span>
        <span class="c1"># uses &quot;dispatch&quot; to get and return tensors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span> <span class="o">=</span> <span class="n">action_value_key</span></div>


<div class="viewcode-block" id="QValueActor"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.QValueActor">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">QValueActor</span><span class="p">(</span><span class="n">SafeSequential</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A Q-Value actor class.</span>

<span class="sd">    This class appends a :class:`~.QValueModule` after the input module</span>
<span class="sd">    such that the action values are used to select an action.</span>

<span class="sd">    Args:</span>
<span class="sd">        module (nn.Module): a :class:`torch.nn.Module` used to map the input to</span>
<span class="sd">            the output parameter space. If the class provided is not compatible</span>
<span class="sd">            with :class:`tensordict.nn.TensorDictModuleBase`, it will be</span>
<span class="sd">            wrapped in a :class:`tensordict.nn.TensorDictModule` with</span>
<span class="sd">            ``in_keys`` indicated by the following keyword argument.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        in_keys (iterable of str, optional): If the class provided is not</span>
<span class="sd">            compatible with :class:`tensordict.nn.TensorDictModuleBase`, this</span>
<span class="sd">            list of keys indicates what observations need to be passed to the</span>
<span class="sd">            wrapped module to get the action values.</span>
<span class="sd">            Defaults to ``[&quot;observation&quot;]``.</span>
<span class="sd">        spec (TensorSpec, optional): Keyword-only argument.</span>
<span class="sd">            Specs of the output tensor. If the module</span>
<span class="sd">            outputs multiple output tensors,</span>
<span class="sd">            spec characterize the space of the first output tensor.</span>
<span class="sd">        safe (bool): Keyword-only argument.</span>
<span class="sd">            If ``True``, the value of the output is checked against the</span>
<span class="sd">            input spec. Out-of-domain sampling can</span>
<span class="sd">            occur because of exploration policies or numerical under/overflow</span>
<span class="sd">            issues. If this value is out of bounds, it is projected back onto the</span>
<span class="sd">            desired space using the :obj:`TensorSpec.project`</span>
<span class="sd">            method. Default is ``False``.</span>
<span class="sd">        action_space (str, optional): Action space. Must be one of</span>
<span class="sd">            ``&quot;one-hot&quot;``, ``&quot;mult-one-hot&quot;``, ``&quot;binary&quot;`` or ``&quot;categorical&quot;``.</span>
<span class="sd">            This argument is exclusive with ``spec``, since ``spec``</span>
<span class="sd">            conditions the action_space.</span>
<span class="sd">        action_value_key (str or tuple of str, optional): if the input module</span>
<span class="sd">            is a :class:`tensordict.nn.TensorDictModuleBase` instance, it must</span>
<span class="sd">            match one of its output keys. Otherwise, this string represents</span>
<span class="sd">            the name of the action-value entry in the output tensordict.</span>
<span class="sd">        action_mask_key (str or tuple of str, optional): The input key</span>
<span class="sd">            representing the action mask. Defaults to ``&quot;None&quot;`` (equivalent to no masking).</span>

<span class="sd">    .. note::</span>
<span class="sd">        ``out_keys`` cannot be passed. If the module is a :class:`tensordict.nn.TensorDictModule`</span>
<span class="sd">        instance, the out_keys will be updated accordingly. For regular</span>
<span class="sd">        :class:`torch.nn.Module` instance, the triplet ``[&quot;action&quot;, action_value_key, &quot;chosen_action_value&quot;]``</span>
<span class="sd">        will be used.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import OneHot</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules.tensordict_module.actors import QValueActor</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&#39;observation&#39;: torch.randn(5, 4)}, [5])</span>
<span class="sd">        &gt;&gt;&gt; # with a regular nn.Module</span>
<span class="sd">        &gt;&gt;&gt; module = nn.Linear(4, 4)</span>
<span class="sd">        &gt;&gt;&gt; action_spec = OneHot(4)</span>
<span class="sd">        &gt;&gt;&gt; qvalue_actor = QValueActor(module=module, spec=action_spec)</span>
<span class="sd">        &gt;&gt;&gt; td = qvalue_actor(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                action_value: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                chosen_action_value: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([5]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; # with a TensorDictModule</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&#39;obs&#39;: torch.randn(5, 4)}, [5])</span>
<span class="sd">        &gt;&gt;&gt; module = TensorDictModule(lambda x: x, in_keys=[&quot;obs&quot;], out_keys=[&quot;action_value&quot;])</span>
<span class="sd">        &gt;&gt;&gt; action_spec = OneHot(4)</span>
<span class="sd">        &gt;&gt;&gt; qvalue_actor = QValueActor(module=module, spec=action_spec)</span>
<span class="sd">        &gt;&gt;&gt; td = qvalue_actor(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                action_value: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                chosen_action_value: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                obs: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([5]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">spec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">safe</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">action_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_value_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">action_mask_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="n">TensorSpec</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Using specs in action_space is deprecated. &quot;</span>
                <span class="s2">&quot;Please use the &#39;spec&#39; argument if you want to provide an action spec&quot;</span>
            <span class="p">)</span>
        <span class="n">action_space</span><span class="p">,</span> <span class="n">spec</span> <span class="o">=</span> <span class="n">_process_action_space_spec</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="n">spec</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">action_space</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span> <span class="o">=</span> <span class="n">action_value_key</span>
        <span class="k">if</span> <span class="n">action_value_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">action_value_key</span> <span class="o">=</span> <span class="s2">&quot;action_value&quot;</span>
        <span class="n">out_keys</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;action&quot;</span><span class="p">,</span>
            <span class="n">action_value_key</span><span class="p">,</span>
            <span class="s2">&quot;chosen_action_value&quot;</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">TensorDictModuleBase</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">action_value_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">out_keys</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The key &#39;</span><span class="si">{</span><span class="n">action_value_key</span><span class="si">}</span><span class="s2">&#39; is not part of the module out-keys.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">]</span>
            <span class="n">module</span> <span class="o">=</span> <span class="n">TensorDictModule</span><span class="p">(</span>
                <span class="n">module</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="n">action_value_key</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="k">if</span> <span class="s2">&quot;action&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">spec</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">spec</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="n">spec</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">spec</span><span class="p">[</span><span class="n">action_value_key</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">spec</span><span class="p">[</span><span class="s2">&quot;chosen_action_value&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">qvalue</span> <span class="o">=</span> <span class="n">QValueModule</span><span class="p">(</span>
            <span class="n">action_value_key</span><span class="o">=</span><span class="n">action_value_key</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">spec</span><span class="o">=</span><span class="n">spec</span><span class="p">,</span>
            <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">,</span>
            <span class="n">action_space</span><span class="o">=</span><span class="n">action_space</span><span class="p">,</span>
            <span class="n">action_mask_key</span><span class="o">=</span><span class="n">action_mask_key</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">qvalue</span><span class="p">)</span></div>


<div class="viewcode-block" id="DistributionalQValueActor"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.DistributionalQValueActor.html#torchrl.modules.DistributionalQValueActor">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">DistributionalQValueActor</span><span class="p">(</span><span class="n">QValueActor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A Distributional DQN actor class.</span>

<span class="sd">    This class appends a :class:`~.QValueModule` after the input module</span>
<span class="sd">    such that the action values are used to select an action.</span>

<span class="sd">    Args:</span>
<span class="sd">        module (nn.Module): a :class:`torch.nn.Module` used to map the input to</span>
<span class="sd">            the output parameter space.</span>
<span class="sd">            If the module isn&#39;t of type :class:`torchrl.modules.DistributionalDQNnet`,</span>
<span class="sd">            :class:`~.DistributionalQValueActor` will ensure that a log-softmax</span>
<span class="sd">            operation is applied to the action value tensor along dimension ``-2``.</span>
<span class="sd">            This can be deactivated by turning off the ``make_log_softmax``</span>
<span class="sd">            keyword argument.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        in_keys (iterable of str, optional): keys to be read from input</span>
<span class="sd">            tensordict and passed to the module. If it</span>
<span class="sd">            contains more than one element, the values will be passed in the</span>
<span class="sd">            order given by the in_keys iterable.</span>
<span class="sd">            Defaults to ``[&quot;observation&quot;]``.</span>
<span class="sd">        spec (TensorSpec, optional): Keyword-only argument.</span>
<span class="sd">            Specs of the output tensor. If the module</span>
<span class="sd">            outputs multiple output tensors,</span>
<span class="sd">            spec characterize the space of the first output tensor.</span>
<span class="sd">        safe (bool): Keyword-only argument.</span>
<span class="sd">            If ``True``, the value of the output is checked against the</span>
<span class="sd">            input spec. Out-of-domain sampling can</span>
<span class="sd">            occur because of exploration policies or numerical under/overflow</span>
<span class="sd">            issues. If this value is out of bounds, it is projected back onto the</span>
<span class="sd">            desired space using the :obj:`TensorSpec.project`</span>
<span class="sd">            method. Default is ``False``.</span>
<span class="sd">        var_nums (int, optional): if ``action_space = &quot;mult-one-hot&quot;``,</span>
<span class="sd">            this value represents the cardinality of each</span>
<span class="sd">            action component.</span>
<span class="sd">        support (torch.Tensor): support of the action values.</span>
<span class="sd">        action_space (str, optional): Action space. Must be one of</span>
<span class="sd">            ``&quot;one-hot&quot;``, ``&quot;mult-one-hot&quot;``, ``&quot;binary&quot;`` or ``&quot;categorical&quot;``.</span>
<span class="sd">            This argument is exclusive with ``spec``, since ``spec``</span>
<span class="sd">            conditions the action_space.</span>
<span class="sd">        make_log_softmax (bool, optional): if ``True`` and if the module is not</span>
<span class="sd">            of type :class:`torchrl.modules.DistributionalDQNnet`, a log-softmax</span>
<span class="sd">            operation will be applied along dimension -2 of the action value tensor.</span>
<span class="sd">        action_value_key (str or tuple of str, optional): if the input module</span>
<span class="sd">            is a :class:`tensordict.nn.TensorDictModuleBase` instance, it must</span>
<span class="sd">            match one of its output keys. Otherwise, this string represents</span>
<span class="sd">            the name of the action-value entry in the output tensordict.</span>
<span class="sd">        action_mask_key (str or tuple of str, optional): The input key</span>
<span class="sd">            representing the action mask. Defaults to ``&quot;None&quot;`` (equivalent to no masking).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import TensorDictModule, TensorDictSequential</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import OneHot</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import DistributionalQValueActor, MLP</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&#39;observation&#39;: torch.randn(5, 4)}, [5])</span>
<span class="sd">        &gt;&gt;&gt; nbins = 3</span>
<span class="sd">        &gt;&gt;&gt; module = MLP(out_features=(nbins, 4), depth=2)</span>
<span class="sd">        &gt;&gt;&gt; # let us make sure that the output is a log-softmax</span>
<span class="sd">        &gt;&gt;&gt; module = TensorDictSequential(</span>
<span class="sd">        ...     TensorDictModule(module, [&quot;observation&quot;], [&quot;action_value&quot;]),</span>
<span class="sd">        ...     TensorDictModule(lambda x: x.log_softmax(-2), [&quot;action_value&quot;], [&quot;action_value&quot;]),</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; action_spec = OneHot(4)</span>
<span class="sd">        &gt;&gt;&gt; qvalue_actor = DistributionalQValueActor(</span>
<span class="sd">        ...     module=module,</span>
<span class="sd">        ...     spec=action_spec,</span>
<span class="sd">        ...     support=torch.arange(nbins))</span>
<span class="sd">        &gt;&gt;&gt; td = qvalue_actor(td)</span>
<span class="sd">        &gt;&gt;&gt; print(td)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                action_value: Tensor(shape=torch.Size([5, 3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([5]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module</span><span class="p">,</span>
        <span class="n">support</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">spec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">safe</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">var_nums</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_value_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;action_value&quot;</span><span class="p">,</span>
        <span class="n">action_mask_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">make_log_softmax</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="n">TensorSpec</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Using specs in action_space is deprecated&quot;</span><span class="p">)</span>
        <span class="n">action_space</span><span class="p">,</span> <span class="n">spec</span> <span class="o">=</span> <span class="n">_process_action_space_spec</span><span class="p">(</span><span class="n">action_space</span><span class="p">,</span> <span class="n">spec</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">action_space</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_value_key</span> <span class="o">=</span> <span class="n">action_value_key</span>
        <span class="n">out_keys</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;action&quot;</span><span class="p">,</span>
            <span class="n">action_value_key</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">TensorDictModuleBase</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">action_value_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">out_keys</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The key &#39;</span><span class="si">{</span><span class="n">action_value_key</span><span class="si">}</span><span class="s2">&#39; is not part of the module out-keys.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">in_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">]</span>
            <span class="n">module</span> <span class="o">=</span> <span class="n">TensorDictModule</span><span class="p">(</span>
                <span class="n">module</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="n">action_value_key</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="k">if</span> <span class="s2">&quot;action&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">spec</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">spec</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="n">spec</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">spec</span><span class="p">[</span><span class="n">action_value_key</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">qvalue</span> <span class="o">=</span> <span class="n">DistributionalQValueModule</span><span class="p">(</span>
            <span class="n">action_value_key</span><span class="o">=</span><span class="n">action_value_key</span><span class="p">,</span>
            <span class="n">out_keys</span><span class="o">=</span><span class="n">out_keys</span><span class="p">,</span>
            <span class="n">spec</span><span class="o">=</span><span class="n">spec</span><span class="p">,</span>
            <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">,</span>
            <span class="n">action_space</span><span class="o">=</span><span class="n">action_space</span><span class="p">,</span>
            <span class="n">action_mask_key</span><span class="o">=</span><span class="n">action_mask_key</span><span class="p">,</span>
            <span class="n">support</span><span class="o">=</span><span class="n">support</span><span class="p">,</span>
            <span class="n">var_nums</span><span class="o">=</span><span class="n">var_nums</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">make_log_softmax</span> <span class="o">=</span> <span class="n">make_log_softmax</span>
        <span class="k">if</span> <span class="n">make_log_softmax</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">DistributionalDQNnet</span><span class="p">):</span>
            <span class="n">log_softmax_module</span> <span class="o">=</span> <span class="n">DistributionalDQNnet</span><span class="p">(</span>
                <span class="n">in_keys</span><span class="o">=</span><span class="n">qvalue</span><span class="o">.</span><span class="n">in_keys</span><span class="p">,</span> <span class="n">out_keys</span><span class="o">=</span><span class="n">qvalue</span><span class="o">.</span><span class="n">in_keys</span>
            <span class="p">)</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">QValueActor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">log_softmax_module</span><span class="p">,</span> <span class="n">qvalue</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">QValueActor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">qvalue</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;support&quot;</span><span class="p">,</span> <span class="n">support</span><span class="p">)</span></div>


<div class="viewcode-block" id="ActorValueOperator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorValueOperator.html#torchrl.modules.ActorValueOperator">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ActorValueOperator</span><span class="p">(</span><span class="n">SafeSequential</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Actor-value operator.</span>

<span class="sd">    This class wraps together an actor and a value model that share a common</span>
<span class="sd">    observation embedding network:</span>

<span class="sd">    .. aafig::</span>
<span class="sd">        :aspect: 60</span>
<span class="sd">        :scale: 120</span>
<span class="sd">        :proportional:</span>
<span class="sd">        :textual:</span>

<span class="sd">               +---------------+</span>
<span class="sd">               |Observation (s)|</span>
<span class="sd">               +---------------+</span>
<span class="sd">                        |</span>
<span class="sd">                       &quot;common&quot;</span>
<span class="sd">                        |</span>
<span class="sd">                        v</span>
<span class="sd">                 +------------+</span>
<span class="sd">                 |Hidden state|</span>
<span class="sd">                 +------------+</span>
<span class="sd">                   |         |</span>
<span class="sd">                  actor     critic</span>
<span class="sd">                   |         |</span>
<span class="sd">                   v         v</span>
<span class="sd">        +-------------+ +------------+</span>
<span class="sd">        |Action (a(s))| |Value (V(s))|</span>
<span class="sd">        +-------------+ +------------+</span>

<span class="sd">    .. note::</span>
<span class="sd">      For a similar class that returns an action and a Quality value :math:`Q(s, a)`,</span>
<span class="sd">      see :class:`~.ActorCriticOperator`. For a version without common embedding,</span>
<span class="sd">      refer to :class:`~.ActorCriticWrapper`.</span>

<span class="sd">    To facilitate the workflow, this  class comes with a get_policy_operator() and get_value_operator() methods, which</span>
<span class="sd">    will both return a standalone TDModule with the dedicated functionality.</span>

<span class="sd">    Args:</span>
<span class="sd">        common_operator (TensorDictModule): a common operator that reads</span>
<span class="sd">            observations and produces a hidden variable</span>
<span class="sd">        policy_operator (TensorDictModule): a policy operator that reads the</span>
<span class="sd">            hidden variable and returns an action</span>
<span class="sd">        value_operator (TensorDictModule): a value operator, that reads the</span>
<span class="sd">            hidden variable and returns a value</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import ProbabilisticActor, SafeModule</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import ValueOperator, TanhNormal, ActorValueOperator, NormalParamExtractor</span>
<span class="sd">        &gt;&gt;&gt; module_hidden = torch.nn.Linear(4, 4)</span>
<span class="sd">        &gt;&gt;&gt; td_module_hidden = SafeModule(</span>
<span class="sd">        ...    module=module_hidden,</span>
<span class="sd">        ...    in_keys=[&quot;observation&quot;],</span>
<span class="sd">        ...    out_keys=[&quot;hidden&quot;],</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; module_action = TensorDictModule(</span>
<span class="sd">        ...     nn.Sequential(torch.nn.Linear(4, 8), NormalParamExtractor()),</span>
<span class="sd">        ...     in_keys=[&quot;hidden&quot;],</span>
<span class="sd">        ...     out_keys=[&quot;loc&quot;, &quot;scale&quot;],</span>
<span class="sd">        ...     )</span>
<span class="sd">        &gt;&gt;&gt; td_module_action = ProbabilisticActor(</span>
<span class="sd">        ...    module=module_action,</span>
<span class="sd">        ...    in_keys=[&quot;loc&quot;, &quot;scale&quot;],</span>
<span class="sd">        ...    out_keys=[&quot;action&quot;],</span>
<span class="sd">        ...    distribution_class=TanhNormal,</span>
<span class="sd">        ...    return_log_prob=True,</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; module_value = torch.nn.Linear(4, 1)</span>
<span class="sd">        &gt;&gt;&gt; td_module_value = ValueOperator(</span>
<span class="sd">        ...    module=module_value,</span>
<span class="sd">        ...    in_keys=[&quot;hidden&quot;],</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; td_module = ActorValueOperator(td_module_hidden, td_module_action, td_module_value)</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;observation&quot;: torch.randn(3, 4)}, [3,])</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                state_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module.get_policy_operator()(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)  # no value</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module.get_value_operator()(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)  # no action</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                state_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">common_operator</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
        <span class="n">policy_operator</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
        <span class="n">value_operator</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">common_operator</span><span class="p">,</span>
            <span class="n">policy_operator</span><span class="p">,</span>
            <span class="n">value_operator</span><span class="p">,</span>
        <span class="p">)</span>

<div class="viewcode-block" id="ActorValueOperator.get_policy_operator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorValueOperator.html#torchrl.modules.ActorValueOperator.get_policy_operator">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_policy_operator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SafeSequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a standalone policy operator that maps an observation to an action.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">SafeProbabilisticTensorDictSequential</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">SafeProbabilisticTensorDictSequential</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">module</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">SafeSequential</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span></div>

<div class="viewcode-block" id="ActorValueOperator.get_value_operator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorValueOperator.html#torchrl.modules.ActorValueOperator.get_value_operator">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_value_operator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SafeSequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a standalone value network operator that maps an observation to a value estimate.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">SafeSequential</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span></div>

<div class="viewcode-block" id="ActorValueOperator.get_policy_head"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorValueOperator.html#torchrl.modules.ActorValueOperator.get_policy_head">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_policy_head</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SafeSequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the policy head.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span></div>

<div class="viewcode-block" id="ActorValueOperator.get_value_head"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorValueOperator.html#torchrl.modules.ActorValueOperator.get_value_head">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_value_head</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SafeSequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the value head.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span></div></div>


<div class="viewcode-block" id="ActorCriticOperator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator.html#torchrl.modules.ActorCriticOperator">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ActorCriticOperator</span><span class="p">(</span><span class="n">ActorValueOperator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Actor-critic operator.</span>

<span class="sd">    This class wraps together an actor and a value model that share a common</span>
<span class="sd">    observation embedding network:</span>

<span class="sd">    .. aafig::</span>
<span class="sd">        :aspect: 60</span>
<span class="sd">        :scale: 120</span>
<span class="sd">        :proportional:</span>
<span class="sd">        :textual:</span>

<span class="sd">                 +---------------+</span>
<span class="sd">                 |Observation (s)|</span>
<span class="sd">                 +---------------+</span>
<span class="sd">                         |</span>
<span class="sd">                         v</span>
<span class="sd">                        &quot;common&quot;</span>
<span class="sd">                         |</span>
<span class="sd">                         v</span>
<span class="sd">                  +------------+</span>
<span class="sd">                  |Hidden state|</span>
<span class="sd">                  +------------+</span>
<span class="sd">                    |        |</span>
<span class="sd">                    v        v</span>
<span class="sd">                   actor --&gt; critic</span>
<span class="sd">                    |        |</span>
<span class="sd">                    v        v</span>
<span class="sd">            +-------------+ +----------------+</span>
<span class="sd">            |Action (a(s))| |Quality (Q(s,a))|</span>
<span class="sd">            +-------------+ +----------------+</span>

<span class="sd">    .. note::</span>
<span class="sd">      For a similar class that returns an action and a state-value :math:`V(s)`</span>
<span class="sd">      see :class:`~.ActorValueOperator`.</span>


<span class="sd">    To facilitate the workflow, this  class comes with a get_policy_operator() method, which</span>
<span class="sd">    will both return a standalone TDModule with the dedicated functionality. The get_critic_operator will return the</span>
<span class="sd">    parent object, as the value is computed based on the policy output.</span>

<span class="sd">    Args:</span>
<span class="sd">        common_operator (TensorDictModule): a common operator that reads</span>
<span class="sd">            observations and produces a hidden variable</span>
<span class="sd">        policy_operator (TensorDictModule): a policy operator that reads the</span>
<span class="sd">            hidden variable and returns an action</span>
<span class="sd">        value_operator (TensorDictModule): a value operator, that reads the</span>
<span class="sd">            hidden variable and returns a value</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import ProbabilisticActor</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import  ValueOperator, TanhNormal, ActorCriticOperator, NormalParamExtractor, MLP</span>
<span class="sd">        &gt;&gt;&gt; module_hidden = torch.nn.Linear(4, 4)</span>
<span class="sd">        &gt;&gt;&gt; td_module_hidden = SafeModule(</span>
<span class="sd">        ...    module=module_hidden,</span>
<span class="sd">        ...    in_keys=[&quot;observation&quot;],</span>
<span class="sd">        ...    out_keys=[&quot;hidden&quot;],</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; module_action = nn.Sequential(torch.nn.Linear(4, 8), NormalParamExtractor())</span>
<span class="sd">        &gt;&gt;&gt; module_action = TensorDictModule(module_action, in_keys=[&quot;hidden&quot;], out_keys=[&quot;loc&quot;, &quot;scale&quot;])</span>
<span class="sd">        &gt;&gt;&gt; td_module_action = ProbabilisticActor(</span>
<span class="sd">        ...    module=module_action,</span>
<span class="sd">        ...    in_keys=[&quot;loc&quot;, &quot;scale&quot;],</span>
<span class="sd">        ...    out_keys=[&quot;action&quot;],</span>
<span class="sd">        ...    distribution_class=TanhNormal,</span>
<span class="sd">        ...    return_log_prob=True,</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; module_value = MLP(in_features=8, out_features=1, num_cells=[])</span>
<span class="sd">        &gt;&gt;&gt; td_module_value = ValueOperator(</span>
<span class="sd">        ...    module=module_value,</span>
<span class="sd">        ...    in_keys=[&quot;hidden&quot;, &quot;action&quot;],</span>
<span class="sd">        ...    out_keys=[&quot;state_action_value&quot;],</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; td_module = ActorCriticOperator(td_module_hidden, td_module_action, td_module_value)</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;observation&quot;: torch.randn(3, 4)}, [3,])</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                state_action_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module.get_policy_operator()(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)  # no value</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module.get_critic_operator()(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)  # no action</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                state_action_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">common_operator</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
        <span class="n">policy_operator</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
        <span class="n">value_operator</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">common_operator</span><span class="p">,</span>
            <span class="n">policy_operator</span><span class="p">,</span>
            <span class="n">value_operator</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">out_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;state_value&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Value out_key is state_value, which may lead to errors in downstream usages&quot;</span>
                <span class="s2">&quot;of that module. Consider setting `&#39;state_action_value&#39;` instead.&quot;</span>
                <span class="s2">&quot;Make also sure that `&#39;action&#39;` is amongst the input keys of the value network.&quot;</span>
                <span class="s2">&quot;If you are confident that action should not be used to compute the value, please&quot;</span>
                <span class="s2">&quot;user `ActorValueOperator` instead.&quot;</span>
            <span class="p">)</span>

<div class="viewcode-block" id="ActorCriticOperator.get_critic_operator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator.html#torchrl.modules.ActorCriticOperator.get_critic_operator">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_critic_operator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictModuleWrapper</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a standalone critic network operator that maps a state-action pair to a critic estimate.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="ActorCriticOperator.get_value_operator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator.html#torchrl.modules.ActorCriticOperator.get_value_operator">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_value_operator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictModuleWrapper</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;value_operator is the term used for operators that associate a value with a &quot;</span>
            <span class="s2">&quot;state/observation. This class computes the value of a state-action pair: to get the &quot;</span>
            <span class="s2">&quot;network computing this value, please call td_sequence.get_critic_operator()&quot;</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="ActorCriticOperator.get_policy_head"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator.html#torchrl.modules.ActorCriticOperator.get_policy_head">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_policy_head</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SafeSequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the policy head.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span></div>

<div class="viewcode-block" id="ActorCriticOperator.get_value_head"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator.html#torchrl.modules.ActorCriticOperator.get_value_head">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_value_head</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SafeSequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the value head.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span></div></div>


<div class="viewcode-block" id="ActorCriticWrapper"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorCriticWrapper.html#torchrl.modules.ActorCriticWrapper">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ActorCriticWrapper</span><span class="p">(</span><span class="n">SafeSequential</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Actor-value operator without common module.</span>

<span class="sd">    This class wraps together an actor and a value model that do not share a common observation embedding network:</span>

<span class="sd">    .. aafig::</span>
<span class="sd">        :aspect: 60</span>
<span class="sd">        :scale: 120</span>
<span class="sd">        :proportional:</span>
<span class="sd">        :textual:</span>

<span class="sd">                 +---------------+</span>
<span class="sd">                 |Observation (s)|</span>
<span class="sd">                 +---------------+</span>
<span class="sd">                    |    |    |</span>
<span class="sd">                    v    |    v</span>
<span class="sd">                   actor |    critic</span>
<span class="sd">                    |    |    |</span>
<span class="sd">                    v    |    v</span>
<span class="sd">        +-------------+  |  +------------+</span>
<span class="sd">        |Action (a(s))|  |  |Value (V(s))|</span>
<span class="sd">        +-------------+  |  +------------+</span>


<span class="sd">    To facilitate the workflow, this  class comes with a get_policy_operator() and get_value_operator() methods, which</span>
<span class="sd">    will both return a standalone TDModule with the dedicated functionality.</span>

<span class="sd">    Args:</span>
<span class="sd">        policy_operator (TensorDictModule): a policy operator that reads the hidden variable and returns an action</span>
<span class="sd">        value_operator (TensorDictModule): a value operator, that reads the hidden variable and returns a value</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import (</span>
<span class="sd">        ...      ActorCriticWrapper,</span>
<span class="sd">        ...      ProbabilisticActor,</span>
<span class="sd">        ...      NormalParamExtractor,</span>
<span class="sd">        ...      TanhNormal,</span>
<span class="sd">        ...      ValueOperator,</span>
<span class="sd">        ...  )</span>
<span class="sd">        &gt;&gt;&gt; action_module = TensorDictModule(</span>
<span class="sd">        ...        nn.Sequential(torch.nn.Linear(4, 8), NormalParamExtractor()),</span>
<span class="sd">        ...        in_keys=[&quot;observation&quot;],</span>
<span class="sd">        ...        out_keys=[&quot;loc&quot;, &quot;scale&quot;],</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; td_module_action = ProbabilisticActor(</span>
<span class="sd">        ...    module=action_module,</span>
<span class="sd">        ...    in_keys=[&quot;loc&quot;, &quot;scale&quot;],</span>
<span class="sd">        ...    distribution_class=TanhNormal,</span>
<span class="sd">        ...    return_log_prob=True,</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; module_value = torch.nn.Linear(4, 1)</span>
<span class="sd">        &gt;&gt;&gt; td_module_value = ValueOperator(</span>
<span class="sd">        ...    module=module_value,</span>
<span class="sd">        ...    in_keys=[&quot;observation&quot;],</span>
<span class="sd">        ...    )</span>
<span class="sd">        &gt;&gt;&gt; td_module = ActorCriticWrapper(td_module_action, td_module_value)</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;observation&quot;: torch.randn(3, 4)}, [3,])</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                state_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module.get_policy_operator()(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)  # no value</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; td_clone = td_module.get_value_operator()(td.clone())</span>
<span class="sd">        &gt;&gt;&gt; print(td_clone)  # no action</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                state_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([3]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">policy_operator</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
        <span class="n">value_operator</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">policy_operator</span><span class="p">,</span>
            <span class="n">value_operator</span><span class="p">,</span>
        <span class="p">)</span>

<div class="viewcode-block" id="ActorCriticWrapper.get_policy_operator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorCriticWrapper.html#torchrl.modules.ActorCriticWrapper.get_policy_operator">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_policy_operator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SafeSequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a standalone policy operator that maps an observation to an action.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="ActorCriticWrapper.get_value_operator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.ActorCriticWrapper.html#torchrl.modules.ActorCriticWrapper.get_value_operator">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_value_operator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SafeSequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a standalone value network operator that maps an observation to a value estimate.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span></div>

    <span class="n">get_policy_head</span> <span class="o">=</span> <span class="n">get_policy_operator</span>
    <span class="n">get_value_head</span> <span class="o">=</span> <span class="n">get_value_operator</span></div>


<div class="viewcode-block" id="DecisionTransformerInferenceWrapper"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper.html#torchrl.modules.DecisionTransformerInferenceWrapper">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">DecisionTransformerInferenceWrapper</span><span class="p">(</span><span class="n">TensorDictModuleWrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Inference Action Wrapper for the Decision Transformer.</span>

<span class="sd">    A wrapper specifically designed for the Decision Transformer, which will mask the</span>
<span class="sd">    input tensordict sequences to the inferece context.</span>
<span class="sd">    The output will be a TensorDict with the same keys as the input, but with only the last</span>
<span class="sd">    action of the predicted action sequence and the last return to go.</span>

<span class="sd">    This module creates returns a modified copy of the tensordict, ie. it does</span>
<span class="sd">    **not** modify the tensordict in-place.</span>

<span class="sd">    .. note:: If the action, observation or reward-to-go key is not standard,</span>
<span class="sd">        the method :meth:`set_tensor_keys` should be used, e.g.</span>

<span class="sd">            &gt;&gt;&gt; dt_inference_wrapper.set_tensor_keys(action=&quot;foo&quot;, observation=&quot;bar&quot;, return_to_go=&quot;baz&quot;)</span>

<span class="sd">    The in_keys are the observation, action and return-to-go keys. The out-keys</span>
<span class="sd">    match the in-keys, with the addition of any other out-key from the policy</span>
<span class="sd">    (eg., parameters of the distribution or hidden values).</span>

<span class="sd">    Args:</span>
<span class="sd">        policy (TensorDictModule): The policy module that takes in</span>
<span class="sd">            observations and produces an action value</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        inference_context (int): The number of previous actions that will not be masked in the context.</span>
<span class="sd">            For example for an observation input of shape [batch_size, context, obs_dim] with context=20 and inference_context=5, the first 15 entries</span>
<span class="sd">            of the context will be masked. Defaults to 5.</span>
<span class="sd">        spec (Optional[TensorSpec]): The spec of the input TensorDict. If None, it will be inferred from the policy module.</span>
<span class="sd">        device (torch.device, optional): if provided, the device where the buffers / specs will be placed.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules import (</span>
<span class="sd">        ...      ProbabilisticActor,</span>
<span class="sd">        ...      TanhDelta,</span>
<span class="sd">        ...      DTActor,</span>
<span class="sd">        ...      DecisionTransformerInferenceWrapper,</span>
<span class="sd">        ...  )</span>
<span class="sd">        &gt;&gt;&gt; dtactor = DTActor(state_dim=4, action_dim=2,</span>
<span class="sd">        ...             transformer_config=DTActor.default_config()</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; actor_module = TensorDictModule(</span>
<span class="sd">        ...         dtactor,</span>
<span class="sd">        ...         in_keys=[&quot;observation&quot;, &quot;action&quot;, &quot;return_to_go&quot;],</span>
<span class="sd">        ...         out_keys=[&quot;param&quot;])</span>
<span class="sd">        &gt;&gt;&gt; dist_class = TanhDelta</span>
<span class="sd">        &gt;&gt;&gt; dist_kwargs = {</span>
<span class="sd">        ...     &quot;low&quot;: -1.0,</span>
<span class="sd">        ...     &quot;high&quot;: 1.0,</span>
<span class="sd">        ... }</span>
<span class="sd">        &gt;&gt;&gt; actor = ProbabilisticActor(</span>
<span class="sd">        ...     in_keys=[&quot;param&quot;],</span>
<span class="sd">        ...     out_keys=[&quot;action&quot;],</span>
<span class="sd">        ...     module=actor_module,</span>
<span class="sd">        ...     distribution_class=dist_class,</span>
<span class="sd">        ...     distribution_kwargs=dist_kwargs)</span>
<span class="sd">        &gt;&gt;&gt; inference_actor = DecisionTransformerInferenceWrapper(actor)</span>
<span class="sd">        &gt;&gt;&gt; sequence_length = 20</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&quot;observation&quot;: torch.randn(1, sequence_length, 4),</span>
<span class="sd">        ...                 &quot;action&quot;: torch.randn(1, sequence_length, 2),</span>
<span class="sd">        ...                 &quot;return_to_go&quot;: torch.randn(1, sequence_length, 1)}, [1,])</span>
<span class="sd">        &gt;&gt;&gt; result = inference_actor(td)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([1, 2]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([1, 20, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                param: Tensor(shape=torch.Size([1, 20, 2]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                return_to_go: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([1]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">policy</span><span class="p">:</span> <span class="n">TensorDictModule</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">inference_context</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorSpec</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span> <span class="o">=</span> <span class="s2">&quot;observation&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_key</span> <span class="o">=</span> <span class="s2">&quot;action&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_action_key</span> <span class="o">=</span> <span class="s2">&quot;action&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span> <span class="o">=</span> <span class="s2">&quot;return_to_go&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inference_context</span> <span class="o">=</span> <span class="n">inference_context</span>
        <span class="k">if</span> <span class="n">spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">({</span><span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="p">:</span> <span class="n">spec</span><span class="p">},</span> <span class="n">shape</span><span class="o">=</span><span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span> <span class="o">=</span> <span class="n">spec</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">td_module</span><span class="p">,</span> <span class="s2">&quot;_spec&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">td_module</span><span class="o">.</span><span class="n">_spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">td_module</span><span class="p">,</span> <span class="s2">&quot;spec&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">td_module</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">({</span><span class="n">key</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">policy</span><span class="o">.</span><span class="n">out_keys</span><span class="p">})</span>
        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_spec</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checked</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span>
            <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">td_module</span><span class="o">.</span><span class="n">out_keys</span><span class="p">)</span><span class="o">.</span><span class="n">union</span><span class="p">(</span>
                <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span><span class="p">}</span>
            <span class="p">),</span>
            <span class="n">key</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="p">)</span>

<div class="viewcode-block" id="DecisionTransformerInferenceWrapper.set_tensor_keys"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper.html#torchrl.modules.DecisionTransformerInferenceWrapper.set_tensor_keys">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_tensor_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sets the input keys of the module.</span>

<span class="sd">        Keyword Args:</span>
<span class="sd">            observation (NestedKey, optional): The observation key.</span>
<span class="sd">            action (NestedKey, optional): The action key (input to the network).</span>
<span class="sd">            return_to_go (NestedKey, optional): The return_to_go key.</span>
<span class="sd">            out_action (NestedKey, optional): The action key (output of the network).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">observation_key</span> <span class="o">=</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;observation&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span><span class="p">))</span>
        <span class="n">action_key</span> <span class="o">=</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;action&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="p">))</span>
        <span class="n">out_action_key</span> <span class="o">=</span> <span class="n">unravel_key</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;out_action&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_action_key</span><span class="p">))</span>
        <span class="n">return_to_go_key</span> <span class="o">=</span> <span class="n">unravel_key</span><span class="p">(</span>
            <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;return_to_go&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Got unknown input(s) </span><span class="si">{</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">. Accepted keys are &#39;action&#39;, &#39;return_to_go&#39; and &#39;observation&#39;.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span> <span class="o">=</span> <span class="n">observation_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_key</span> <span class="o">=</span> <span class="n">action_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span> <span class="o">=</span> <span class="n">return_to_go_key</span>
        <span class="k">if</span> <span class="n">out_action_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">td_module</span><span class="o">.</span><span class="n">out_keys</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The value of out_action_key (</span><span class="si">{</span><span class="n">out_action_key</span><span class="si">}</span><span class="s2">) must be &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;within the actor output keys (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">td_module</span><span class="o">.</span><span class="n">out_keys</span><span class="si">}</span><span class="s2">).&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_action_key</span> <span class="o">=</span> <span class="n">out_action_key</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frames</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_check_tensor_dims</span><span class="p">(</span><span class="n">reward</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">reward</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">action</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Mismatched tensor dimensions. This is not supported yet, file an issue on torchrl&quot;</span>
            <span class="p">)</span>

<div class="viewcode-block" id="DecisionTransformerInferenceWrapper.mask_context"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper.html#torchrl.modules.DecisionTransformerInferenceWrapper.mask_context">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">mask_context</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Mask the context of the input sequences.&quot;&quot;&quot;</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">return_to_go</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_tensor_dims</span><span class="p">(</span><span class="n">return_to_go</span><span class="p">,</span> <span class="n">observation</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>

        <span class="n">observation</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_context</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">action</span><span class="p">[</span>
            <span class="o">...</span><span class="p">,</span> <span class="p">:</span> <span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_context</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="p">:</span>
        <span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># as we add zeros to the end of the action</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">action</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:],</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="o">*</span><span class="n">action</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">action</span><span class="o">.</span><span class="n">device</span>
                <span class="p">),</span>
            <span class="p">],</span>
            <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">return_to_go</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_context</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span><span class="p">,</span> <span class="n">observation</span><span class="p">)</span>
        <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_key</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
        <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span><span class="p">,</span> <span class="n">return_to_go</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">check_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># an exception will be raised if the action key mismatch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_tensor_keys</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checked</span> <span class="o">=</span> <span class="kc">True</span>

<div class="viewcode-block" id="DecisionTransformerInferenceWrapper.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper.html#torchrl.modules.DecisionTransformerInferenceWrapper.forward">[docs]</a>    <span class="nd">@dispatch</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">checked</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">check_keys</span><span class="p">()</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass of the inference wrapper.&quot;&quot;&quot;</span>
        <span class="n">tensordict</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span><span class="p">)</span>
        <span class="c1"># Mask the context of the input sequences</span>
        <span class="n">tensordict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_context</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
        <span class="c1"># forward pass</span>
        <span class="n">tensordict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">td_module</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
        <span class="c1"># get last action prediction</span>
        <span class="n">out_action</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_action_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="n">out_action</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># then time dimension is in the TD&#39;s dimensions, and we must get rid of it</span>
            <span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">out_action</span> <span class="o">=</span> <span class="n">out_action</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_action_key</span><span class="p">,</span> <span class="n">out_action</span><span class="p">)</span>

        <span class="n">out_rtg</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span><span class="p">)</span>
        <span class="n">out_rtg</span> <span class="o">=</span> <span class="n">out_rtg</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">return_to_go_key</span><span class="p">,</span> <span class="n">out_rtg</span><span class="p">)</span>

        <span class="c1"># set unmasked observation</span>
        <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_key</span><span class="p">,</span> <span class="n">obs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span></div></div>


<div class="viewcode-block" id="TanhModule"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.TanhModule.html#torchrl.modules.TanhModule">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">TanhModule</span><span class="p">(</span><span class="n">TensorDictModuleBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A Tanh module for deterministic policies with bounded action space.</span>

<span class="sd">    This transform is to be used as a TensorDictModule layer to map a network</span>
<span class="sd">    output to a bounded space.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_keys (list of str or tuples of str): the input keys of the module.</span>
<span class="sd">        out_keys (list of str or tuples of str, optional): the output keys of the module.</span>
<span class="sd">            If none is provided, the same keys as in_keys are assumed.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        spec (TensorSpec, optional): if provided, the spec of the output.</span>
<span class="sd">            If a Composite is provided, its key(s) must match the key(s)</span>
<span class="sd">            in out_keys. Otherwise, the key(s) of out_keys are assumed and the</span>
<span class="sd">            same spec is used for all outputs.</span>
<span class="sd">        low (:obj:`float`, np.ndarray or torch.Tensor): the lower bound of the space.</span>
<span class="sd">            If none is provided and no spec is provided, -1 is assumed. If a</span>
<span class="sd">            spec is provided, the minimum value of the spec will be retrieved.</span>
<span class="sd">        high (:obj:`float`, np.ndarray or torch.Tensor): the higher bound of the space.</span>
<span class="sd">            If none is provided and no spec is provided, 1 is assumed. If a</span>
<span class="sd">            spec is provided, the maximum value of the spec will be retrieved.</span>
<span class="sd">        clamp (bool, optional): if ``True``, the outputs will be clamped to be</span>
<span class="sd">            within the boundaries but at a minimum resolution from them.</span>
<span class="sd">            Defaults to ``False``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; # simplest use case: -1 - 1 boundaries</span>
<span class="sd">        &gt;&gt;&gt; torch.manual_seed(0)</span>
<span class="sd">        &gt;&gt;&gt; in_keys = [&quot;action&quot;]</span>
<span class="sd">        &gt;&gt;&gt; mod = TanhModule(</span>
<span class="sd">        ...     in_keys=in_keys,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; data = TensorDict({&quot;action&quot;: torch.randn(5) * 10}, [])</span>
<span class="sd">        &gt;&gt;&gt; data = mod(data)</span>
<span class="sd">        &gt;&gt;&gt; data[&#39;action&#39;]</span>
<span class="sd">        tensor([ 1.0000, -0.9944, -1.0000,  1.0000, -1.0000])</span>
<span class="sd">        &gt;&gt;&gt; # low and high can be customized</span>
<span class="sd">        &gt;&gt;&gt; low = -2</span>
<span class="sd">        &gt;&gt;&gt; high = 1</span>
<span class="sd">        &gt;&gt;&gt; mod = TanhModule(</span>
<span class="sd">        ...     in_keys=in_keys,</span>
<span class="sd">        ...     low=low,</span>
<span class="sd">        ...     high=high,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; data = TensorDict({&quot;action&quot;: torch.randn(5) * 10}, [])</span>
<span class="sd">        &gt;&gt;&gt; data = mod(data)</span>
<span class="sd">        &gt;&gt;&gt; data[&#39;action&#39;]</span>
<span class="sd">        tensor([-2.0000,  0.9991,  1.0000, -2.0000, -1.9991])</span>
<span class="sd">        &gt;&gt;&gt; # A spec can be provided</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import Bounded</span>
<span class="sd">        &gt;&gt;&gt; spec = Bounded(low, high, shape=())</span>
<span class="sd">        &gt;&gt;&gt; mod = TanhModule(</span>
<span class="sd">        ...     in_keys=in_keys,</span>
<span class="sd">        ...     low=low,</span>
<span class="sd">        ...     high=high,</span>
<span class="sd">        ...     spec=spec,</span>
<span class="sd">        ...     clamp=False,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; # One can also work with multiple keys</span>
<span class="sd">        &gt;&gt;&gt; in_keys = [&#39;a&#39;, &#39;b&#39;]</span>
<span class="sd">        &gt;&gt;&gt; spec = Composite(</span>
<span class="sd">        ...     a=Bounded(-3, 0, shape=()),</span>
<span class="sd">        ...     b=Bounded(0, 3, shape=()))</span>
<span class="sd">        &gt;&gt;&gt; mod = TanhModule(</span>
<span class="sd">        ...     in_keys=in_keys,</span>
<span class="sd">        ...     spec=spec,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; data = TensorDict(</span>
<span class="sd">        ...     {&#39;a&#39;: torch.randn(10), &#39;b&#39;: torch.randn(10)}, batch_size=[])</span>
<span class="sd">        &gt;&gt;&gt; data = mod(data)</span>
<span class="sd">        &gt;&gt;&gt; data[&#39;a&#39;]</span>
<span class="sd">        tensor([-2.3020, -1.2299, -2.5418, -0.2989, -2.6849, -1.3169, -2.2690, -0.9649,</span>
<span class="sd">                -2.5686, -2.8602])</span>
<span class="sd">        &gt;&gt;&gt; data[&#39;b&#39;]</span>
<span class="sd">        tensor([2.0315, 2.8455, 2.6027, 2.4746, 1.7843, 2.7782, 0.2111, 0.5115, 1.4687,</span>
<span class="sd">                0.5760])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">,</span>
        <span class="n">out_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">spec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">low</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">high</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">clamp</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TanhModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">=</span> <span class="n">in_keys</span>
        <span class="k">if</span> <span class="n">out_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_keys</span> <span class="o">=</span> <span class="n">in_keys</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_keys</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;in_keys and out_keys should have the same length, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;got in_keys=</span><span class="si">{</span><span class="n">in_keys</span><span class="si">}</span><span class="s2"> and out_keys=</span><span class="si">{</span><span class="n">out_keys</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span> <span class="o">=</span> <span class="n">out_keys</span>
        <span class="c1"># action_spec can be a composite spec or not</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">Composite</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">out_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                    <span class="n">spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># if one spec is present, we assume it is the same for all keys</span>
            <span class="n">spec</span> <span class="o">=</span> <span class="n">Composite</span><span class="p">(</span>
                <span class="p">{</span><span class="n">out_key</span><span class="p">:</span> <span class="n">spec</span> <span class="k">for</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="n">out_keys</span><span class="p">},</span>
            <span class="p">)</span>

        <span class="n">leaf_specs</span> <span class="o">=</span> <span class="p">[</span><span class="n">spec</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="k">for</span> <span class="n">out_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="o">=</span> <span class="n">spec</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">non_trivial</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">out_key</span><span class="p">,</span> <span class="n">leaf_spec</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">out_keys</span><span class="p">,</span> <span class="n">leaf_specs</span><span class="p">):</span>
            <span class="n">_low</span><span class="p">,</span> <span class="n">_high</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_low_high</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">leaf_spec</span><span class="p">)</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">out_key</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_key</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">_low&quot;</span><span class="p">,</span> <span class="n">_low</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">_high&quot;</span><span class="p">,</span> <span class="n">_high</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">non_trivial</span><span class="p">[</span><span class="n">out_key</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">_high</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="ow">or</span> <span class="p">(</span><span class="n">_low</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">_high</span> <span class="o">&lt;</span> <span class="n">_low</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Got high &lt; low in </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clamp</span> <span class="o">=</span> <span class="n">clamp</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_make_low_high</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">leaf_spec</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">low</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">leaf_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">low</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(())</span>
        <span class="k">elif</span> <span class="n">low</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">low</span> <span class="o">=</span> <span class="n">leaf_spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">low</span>
        <span class="k">elif</span> <span class="n">leaf_spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">low</span> <span class="o">!=</span> <span class="n">leaf_spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The minimum value (</span><span class="si">{</span><span class="n">low</span><span class="si">}</span><span class="s2">) provided to </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2"> does not match the action spec one (</span><span class="si">{</span><span class="n">leaf_spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">low</span><span class="si">}</span><span class="s2">).&quot;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">low</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">low</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">high</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">leaf_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">high</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(())</span>
        <span class="k">elif</span> <span class="n">high</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">high</span> <span class="o">=</span> <span class="n">leaf_spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">high</span>
        <span class="k">elif</span> <span class="n">leaf_spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">high</span> <span class="o">!=</span> <span class="n">leaf_spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The maximum value (</span><span class="si">{</span><span class="n">high</span><span class="si">}</span><span class="s2">) provided to </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2"> does not match the action spec one (</span><span class="si">{</span><span class="n">leaf_spec</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">high</span><span class="si">}</span><span class="s2">).&quot;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">high</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">high</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">high</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span>

<div class="viewcode-block" id="TanhModule.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.TanhModule.html#torchrl.modules.TanhModule.forward">[docs]</a>    <span class="nd">@dispatch</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">):</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_keys</span><span class="p">]</span>
        <span class="c1"># map</span>
        <span class="k">for</span> <span class="n">out_key</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_keys</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">out_key</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_key</span><span class="p">)</span>
            <span class="n">low_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">_low&quot;</span>
            <span class="n">high_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">_high&quot;</span>
            <span class="n">low</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">low_key</span><span class="p">)</span>
            <span class="n">high</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">high_key</span><span class="p">)</span>
            <span class="n">feature</span> <span class="o">=</span> <span class="n">feature</span><span class="o">.</span><span class="n">tanh</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clamp</span><span class="p">:</span>
                <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">feature</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">resolution</span>
                <span class="n">feature</span> <span class="o">=</span> <span class="n">feature</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">+</span> <span class="n">eps</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">eps</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">non_trivial</span><span class="p">:</span>
                <span class="n">feature</span> <span class="o">=</span> <span class="n">low</span> <span class="o">+</span> <span class="p">(</span><span class="n">high</span> <span class="o">-</span> <span class="n">low</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">feature</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">out_key</span><span class="p">,</span> <span class="n">feature</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span></div></div>


<div class="viewcode-block" id="LMHeadActorValueOperator"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.LMHeadActorValueOperator.html#torchrl.modules.LMHeadActorValueOperator">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">LMHeadActorValueOperator</span><span class="p">(</span><span class="n">ActorValueOperator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Builds an Actor-Value operator from an huggingface-like *LMHeadModel.</span>

<span class="sd">    This method:</span>

<span class="sd">    - takes as input an huggingface-like *LMHeadModel</span>
<span class="sd">    - extracts the final linear layer uses it as a base layer of the actor_head and</span>
<span class="sd">      adds the sampling layer</span>
<span class="sd">    - uses the common transformer as common model</span>
<span class="sd">    - adds a linear critic</span>

<span class="sd">    Args:</span>
<span class="sd">        base_model (nn.Module): a torch model composed by a `.transformer` model and `.lm_head` linear layer</span>

<span class="sd">      .. note:: For more details regarding the class construction, please refer to :class:`~.ActorValueOperator`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_model</span><span class="p">):</span>
        <span class="n">actor_head</span> <span class="o">=</span> <span class="n">base_model</span><span class="o">.</span><span class="n">lm_head</span>
        <span class="n">value_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">actor_head</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">common</span> <span class="o">=</span> <span class="n">TensorDictSequential</span><span class="p">(</span>
            <span class="n">TensorDictModule</span><span class="p">(</span>
                <span class="n">base_model</span><span class="o">.</span><span class="n">transformer</span><span class="p">,</span>
                <span class="n">in_keys</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">},</span>
                <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
            <span class="p">),</span>
            <span class="n">TensorDictModule</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]),</span>
        <span class="p">)</span>
        <span class="n">actor_head</span> <span class="o">=</span> <span class="n">TensorDictModule</span><span class="p">(</span><span class="n">actor_head</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">])</span>
        <span class="n">actor_head</span> <span class="o">=</span> <span class="n">SafeProbabilisticTensorDictSequential</span><span class="p">(</span>
            <span class="n">actor_head</span><span class="p">,</span>
            <span class="n">SafeProbabilisticModule</span><span class="p">(</span>
                <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">],</span>
                <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">],</span>
                <span class="n">distribution_class</span><span class="o">=</span><span class="n">Categorical</span><span class="p">,</span>
                <span class="n">return_log_prob</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="n">value_head</span> <span class="o">=</span> <span class="n">TensorDictModule</span><span class="p">(</span>
            <span class="n">value_head</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="n">out_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;state_value&quot;</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">common</span><span class="p">,</span> <span class="n">actor_head</span><span class="p">,</span> <span class="n">value_head</span><span class="p">)</span></div>


<div class="viewcode-block" id="MultiStepActorWrapper"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.MultiStepActorWrapper.html#torchrl.modules.MultiStepActorWrapper">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">MultiStepActorWrapper</span><span class="p">(</span><span class="n">TensorDictModuleBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A wrapper around a multi-action actor.</span>

<span class="sd">    This class enables macros to be executed in an environment.</span>
<span class="sd">    The actor action(s) entry must have an additional time dimension to</span>
<span class="sd">    be consumed. It must be placed adjacent to the last dimension of the</span>
<span class="sd">    input tensordict (i.e. at ``tensordict.ndim``).</span>

<span class="sd">    The action entry keys are retrieved automatically from the actor if</span>
<span class="sd">    not provided using a simple heuristic (any nested key ending with the</span>
<span class="sd">    ``&quot;action&quot;`` string).</span>

<span class="sd">    An ``&quot;is_init&quot;`` entry must also be present in the input tensordict</span>
<span class="sd">    to track which and when the current collection should be interrupted</span>
<span class="sd">    because a &quot;done&quot; state has been encountered. Unlike ``action_keys``,</span>
<span class="sd">    this key must be unique.</span>

<span class="sd">    Args:</span>
<span class="sd">        actor (TensorDictModuleBase): An actor.</span>
<span class="sd">        n_steps (int): the number of actions the actor outputs at once</span>
<span class="sd">            (lookahead window).</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        action_keys (list of NestedKeys, optional): the action keys from</span>
<span class="sd">            the environment. Can be retrieved from ``env.action_keys``.</span>
<span class="sd">            Defaults to all ``out_keys`` of the ``actor`` which end</span>
<span class="sd">            with the ``&quot;action&quot;`` string.</span>
<span class="sd">        init_key (NestedKey, optional): the key of the entry indicating</span>
<span class="sd">            when the environment has gone through a reset.</span>
<span class="sd">            Defaults to ``&quot;is_init&quot;`` which is the ``out_key`` from the</span>
<span class="sd">            :class:`~torchrl.envs.transforms.InitTracker` transform.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch.nn</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules.tensordict_module.actors import MultiStepActorWrapper, Actor</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import CatFrames, GymEnv, TransformedEnv, SerialEnv, InitTracker, Compose</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import TensorDictSequential as Seq, TensorDictModule as Mod</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; time_steps = 6</span>
<span class="sd">        &gt;&gt;&gt; n_obs = 4</span>
<span class="sd">        &gt;&gt;&gt; n_action = 2</span>
<span class="sd">        &gt;&gt;&gt; batch = 5</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Transforms a CatFrames in a stack of frames</span>
<span class="sd">        &gt;&gt;&gt; def reshape_cat(data: torch.Tensor):</span>
<span class="sd">        ...     return data.unflatten(-1, (time_steps, n_obs))</span>
<span class="sd">        &gt;&gt;&gt; # an actor that reads `time_steps` frames and outputs one action per frame</span>
<span class="sd">        &gt;&gt;&gt; # (actions are conditioned on the observation of `time_steps` in the past)</span>
<span class="sd">        &gt;&gt;&gt; actor_base = Seq(</span>
<span class="sd">        ...     Mod(reshape_cat, in_keys=[&quot;obs_cat&quot;], out_keys=[&quot;obs_cat_reshape&quot;]),</span>
<span class="sd">        ...     Mod(torch.nn.Linear(n_obs, n_action), in_keys=[&quot;obs_cat_reshape&quot;], out_keys=[&quot;action&quot;])</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; # Wrap the actor to dispatch the actions</span>
<span class="sd">        &gt;&gt;&gt; actor = MultiStepActorWrapper(actor_base, n_steps=time_steps)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; env = TransformedEnv(</span>
<span class="sd">        ...     SerialEnv(batch, lambda: GymEnv(&quot;CartPole-v1&quot;)),</span>
<span class="sd">        ...     Compose(</span>
<span class="sd">        ...         InitTracker(),</span>
<span class="sd">        ...         CatFrames(N=time_steps, in_keys=[&quot;observation&quot;], out_keys=[&quot;obs_cat&quot;], dim=-1)</span>
<span class="sd">        ...     )</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; print(env.rollout(100, policy=actor, break_when_any_done=False))</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([5, 100, 2]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                action_orig: Tensor(shape=torch.Size([5, 100, 6, 2]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                counter: Tensor(shape=torch.Size([5, 100, 1]), device=cpu, dtype=torch.int32, is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([5, 100, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                is_init: Tensor(shape=torch.Size([5, 100, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([5, 100, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        is_init: Tensor(shape=torch.Size([5, 100, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        obs_cat: Tensor(shape=torch.Size([5, 100, 24]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([5, 100, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([5, 100, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        terminated: Tensor(shape=torch.Size([5, 100, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        truncated: Tensor(shape=torch.Size([5, 100, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([5, 100]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                obs_cat: Tensor(shape=torch.Size([5, 100, 24]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([5, 100, 4]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                terminated: Tensor(shape=torch.Size([5, 100, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                truncated: Tensor(shape=torch.Size([5, 100, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([5, 100]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    .. seealso:: :class:`torchrl.envs.MultiStepEnvWrapper` is the EnvBase alter-ego of this wrapper:</span>
<span class="sd">        It wraps an environment and unbinds the action, executing it one element at a time.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">actor</span><span class="p">:</span> <span class="n">TensorDictModuleBase</span><span class="p">,</span>
        <span class="n">n_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">action_keys</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">init_key</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_keys</span> <span class="o">=</span> <span class="n">action_keys</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_key</span> <span class="o">=</span> <span class="n">init_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">=</span> <span class="n">n_steps</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actor</span> <span class="o">=</span> <span class="n">actor</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">in_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">in_keys</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">init_key</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">out_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">out_keys</span>
            <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_actor_keys_map</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
            <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">counter_key</span><span class="p">]</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_and_move</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">action_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_keys</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">action_key</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="n">action_key_orig</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span><span class="n">action_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">action_key</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_orig&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">action_key_orig</span> <span class="o">=</span> <span class="n">action_key</span> <span class="o">+</span> <span class="s2">&quot;_orig&quot;</span>
            <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">action_key_orig</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>

    <span class="n">_NO_INIT_ERR</span> <span class="o">=</span> <span class="ne">RuntimeError</span><span class="p">(</span>
        <span class="s2">&quot;Cannot initialize the wrapper with partial is_init signal.&quot;</span>
    <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">):</span>
        <span class="n">is_init</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_key</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_init</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;No init key was passed to the batched action wrapper.&quot;</span><span class="p">)</span>
        <span class="n">counter</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">counter_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">counter</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">counter</span> <span class="o">=</span> <span class="n">is_init</span><span class="o">.</span><span class="n">int</span><span class="p">()</span>
        <span class="n">is_init</span> <span class="o">=</span> <span class="n">is_init</span> <span class="o">|</span> <span class="p">(</span><span class="n">counter</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_init</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="n">counter</span> <span class="o">=</span> <span class="n">counter</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">is_init</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">tensordict_filtered</span> <span class="o">=</span> <span class="n">tensordict</span><span class="p">[</span><span class="n">is_init</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">shape</span><span class="p">)]</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="p">(</span><span class="n">tensordict_filtered</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">action_key</span><span class="p">,</span> <span class="n">action_key_orig</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_actor_keys_map</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">action_computed</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">action_key</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
                <span class="n">action_orig</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">action_key_orig</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">action_orig</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_init</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                        <span class="k">raise</span> <span class="bp">self</span><span class="o">.</span><span class="n">_NO_INIT_ERR</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">is_init_expand</span> <span class="o">=</span> <span class="n">expand_as_right</span><span class="p">(</span><span class="n">is_init</span><span class="p">,</span> <span class="n">action_orig</span><span class="p">)</span>
                    <span class="n">action_computed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">masked_scatter</span><span class="p">(</span>
                        <span class="n">action_orig</span><span class="p">,</span> <span class="n">is_init_expand</span><span class="p">,</span> <span class="n">action_computed</span>
                    <span class="p">)</span>
                <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">action_key_orig</span><span class="p">,</span> <span class="n">action_computed</span><span class="p">)</span>
        <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;counter&quot;</span><span class="p">,</span> <span class="n">counter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<div class="viewcode-block" id="MultiStepActorWrapper.forward"><a class="viewcode-back" href="../../../../reference/generated/torchrl.modules.tensordict_module.MultiStepActorWrapper.html#torchrl.modules.MultiStepActorWrapper.forward">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">action_key</span><span class="p">,</span> <span class="n">action_key_orig</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_actor_keys_map</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># get orig</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_key_orig</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">parent_td</span> <span class="o">=</span> <span class="n">tensordict</span>
                <span class="n">action_entry</span> <span class="o">=</span> <span class="n">parent_td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">action_key_orig</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">parent_td</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">action_key_orig</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">action_entry</span> <span class="o">=</span> <span class="n">parent_td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">action_key_orig</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">action_entry</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="bp">self</span><span class="o">.</span><span class="n">_NO_INIT_ERR</span>
            <span class="k">if</span> <span class="n">action_entry</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">parent_td</span><span class="o">.</span><span class="n">ndim</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The action&#39;s time dimension (dim=</span><span class="si">{</span><span class="n">parent_td</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">) doesn&#39;t match the n_steps argument (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="si">}</span><span class="s2">). &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;The action shape was </span><span class="si">{</span><span class="n">action_entry</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="n">base_idx</span> <span class="o">=</span> <span class="p">(</span>
                <span class="nb">slice</span><span class="p">(</span>
                    <span class="kc">None</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span> <span class="o">*</span> <span class="n">parent_td</span><span class="o">.</span><span class="n">ndim</span>
            <span class="n">cur_action</span> <span class="o">=</span> <span class="n">action_entry</span><span class="p">[</span><span class="n">base_idx</span> <span class="o">+</span> <span class="p">(</span><span class="mi">0</span><span class="p">,)]</span>
            <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">action_key</span><span class="p">,</span> <span class="n">cur_action</span><span class="p">)</span>
            <span class="n">tensordict</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                <span class="n">action_key_orig</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">action_entry</span><span class="p">,</span> <span class="n">shifts</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">parent_td</span><span class="o">.</span><span class="n">ndim</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">action_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">action_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_action_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">action_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">ends_with_action</span><span class="p">(</span><span class="n">key</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;action&quot;</span>
                <span class="k">return</span> <span class="n">key</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;action&quot;</span>

            <span class="n">action_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">out_keys</span> <span class="k">if</span> <span class="n">ends_with_action</span><span class="p">(</span><span class="n">key</span><span class="p">)]</span>

            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_action_keys&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">action_keys</span>
        <span class="k">return</span> <span class="n">action_keys</span>

    <span class="nd">@action_keys</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">action_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_actor_keys_map_values&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_action_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">unravel_key</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_actor_keys_map</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">NestedKey</span><span class="p">,</span> <span class="n">NestedKey</span><span class="p">]:</span>
        <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_actor_keys_map_values&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">_replace_last</span><span class="p">(</span><span class="n">action_key</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action_key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                    <span class="n">action_key_orig</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span><span class="n">action_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">action_key</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_orig&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">action_key_orig</span> <span class="o">=</span> <span class="n">action_key</span> <span class="o">+</span> <span class="s2">&quot;_orig&quot;</span>
                <span class="k">return</span> <span class="n">action_key_orig</span>

            <span class="n">val</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">_replace_last</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_keys</span><span class="p">}</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_actor_keys_map_values&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span>
        <span class="k">return</span> <span class="n">val</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">init_key</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NestedKey</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The indicator of the initial step for a given element of the batch.&quot;&quot;&quot;</span>
        <span class="n">init_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_init_key&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">init_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">init_key</span> <span class="o">=</span> <span class="s2">&quot;is_init&quot;</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_key</span>
        <span class="k">return</span> <span class="n">init_key</span>

    <span class="nd">@init_key</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">init_key</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only a single init_key can be passed.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_key</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">counter_key</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_replace_last</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_key</span><span class="p">,</span> <span class="s2">&quot;counter&quot;</span><span class="p">)</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="../../../../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrl = $("#tutorial-type").text();
	      var githubLink = "https://github.com/pytorch/rl/blob/main/tutorials/sphinx-tutorials/"  + tutorialUrl + ".py",
		  notebookLink = $(".sphx-glr-download-jupyter").find(".download.reference")[0].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/rl/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }

          var overwrite = function(_) {
              if ($(this).length > 0) {
                  $(this)[0].href = "https://github.com/pytorch/rl"
              }
          }
          // PC
          $(".main-menu a:contains('GitHub')").each(overwrite);
          // Mobile
          $(".main-menu a:contains('Github')").each(overwrite);
      });

      
       $(window).ready(function() {
           var original = window.sideMenus.bind;
           var startup = true;
           window.sideMenus.bind = function() {
               original();
               if (startup) {
                   $("#pytorch-right-menu a.reference.internal").each(function(i) {
                       if (this.classList.contains("not-expanded")) {
                           this.nextElementSibling.style.display = "block";
                           this.classList.remove("not-expanded");
                           this.classList.add("expanded");
                       }
                   });
                   startup = false;
               }
           };
       });
    </script>

    


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch Documentation</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">Newsletter</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">Cloud Credit Program</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">Technical Advisory Council</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">Staff</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">Contact Us</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>
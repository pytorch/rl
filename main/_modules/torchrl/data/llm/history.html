


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchrl.data.llm.history &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','UA-117752657-2');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="../../../../../versions.html"><span style="font-size:110%">main (0.0.0+unknown) &#x25BC</span></a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-0.html">Get started with Environments, TED and transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-1.html">Get started with TorchRL’s modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-2.html">Getting started with model optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-3.html">Get started with data collection and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-4.html">Get started with logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-5.html">Get started with your own first training loop</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/coding_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/torchrl_demo.html">Introduction to TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/multiagent_ppo.html">Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/torchrl_envs.html">TorchRL envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/pretrained_models.html">Using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/dqn_with_rnn.html">Recurrent DQN: Training recurrent policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/rb_tutorial.html">Using Replay Buffers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/export.html">Exporting TorchRL modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/llm_browser.html">TorchRL LLM: Building Tool-Enabled Environments</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/multiagent_competitive_ddpg.html">Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/coding_ddpg.html">TorchRL objectives: Coding a DDPG loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/coding_dqn.html">TorchRL trainer: A DQN example</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../reference/index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../reference/knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
      <li>torchrl.data.llm.history</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
    
    
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=UA-117752657-2"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torchrl.data.llm.history</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">dataclasses</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">TYPE_CHECKING</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">lazy_stack</span><span class="p">,</span>
    <span class="n">LazyStackedTensorDict</span><span class="p">,</span>
    <span class="n">list_to_stack</span><span class="p">,</span>
    <span class="n">TensorClass</span><span class="p">,</span>
    <span class="n">TensorDict</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_maybe_correct_neg_dim</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl._utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span> <span class="k">as</span> <span class="n">torchrl_logger</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">transformers</span>


<span class="c1"># Global storage for custom templates and their metadata</span>
<span class="n">_CHAT_TEMPLATES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;chatml_format&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;{</span><span class="si">% f</span><span class="s2">or message in messages %}</span>
<span class="s2">    {</span><span class="si">%- i</span><span class="s2">f message[&#39;role&#39;] == &#39;assistant&#39; %}</span>
<span class="s2">    {</span><span class="si">% g</span><span class="s2">eneration %}{{&#39;&lt;|im_start|&gt;&#39; + message[&#39;role&#39;] + &#39;</span><span class="se">\n</span><span class="s2">&#39; + message[&#39;content&#39;] + &#39;&lt;|im_end|&gt;&#39; + &#39;</span><span class="se">\n</span><span class="s2">&#39;}}{</span><span class="si">% e</span><span class="s2">ndgeneration %}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">lse %}</span>
<span class="s2">    {{&#39;&lt;|im_start|&gt;&#39; + message[&#39;role&#39;] + &#39;</span><span class="se">\n</span><span class="s2">&#39; + message[&#39;content&#39;] + &#39;&lt;|im_end|&gt;&#39; + &#39;</span><span class="se">\n</span><span class="s2">&#39;}}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">{</span><span class="si">% e</span><span class="s2">ndfor %}</span>
<span class="s2">{</span><span class="si">%- i</span><span class="s2">f add_generation_prompt %}</span>
<span class="s2">    {</span><span class="si">% g</span><span class="s2">eneration %}{{- &#39;&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&#39; }}{</span><span class="si">% e</span><span class="s2">ndgeneration %}</span>
<span class="s2">{</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="s2">&quot;qwen&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">{</span><span class="si">%- i</span><span class="s2">f tools %}</span>
<span class="s2">    {{- &#39;&lt;|im_start|&gt;system</span><span class="se">\\</span><span class="s2">n&#39; }}</span>
<span class="s2">    {</span><span class="si">%- i</span><span class="s2">f messages[0][&#39;role&#39;] == &#39;system&#39; %}</span>
<span class="s2">        {{- messages[0][&#39;content&#39;] }}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">lse %}</span>
<span class="s2">        {{- &#39;You are a helpful assistant.&#39; }}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">    {{- &quot;</span><span class="se">\\</span><span class="s2">n</span><span class="se">\\</span><span class="s2">n# Tools</span><span class="se">\\</span><span class="s2">n</span><span class="se">\\</span><span class="s2">nYou may call one or more functions to assist with the user query.</span><span class="se">\\</span><span class="s2">n</span><span class="se">\\</span><span class="s2">nYou are provided with function signatures within &lt;tools&gt;&lt;/tools&gt; XML tags:</span><span class="se">\\</span><span class="s2">n&lt;tools&gt;&quot; }}</span>
<span class="s2">    {</span><span class="si">%- f</span><span class="s2">or tool in tools %}</span>
<span class="s2">        {{- &quot;</span><span class="se">\\</span><span class="s2">n&quot; }}</span>
<span class="s2">        {{- tool | tojson }}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">ndfor %}</span>
<span class="s2">    {{- &quot;</span><span class="se">\\</span><span class="s2">n&lt;/tools&gt;</span><span class="se">\\</span><span class="s2">n</span><span class="se">\\</span><span class="s2">nFor each function call, return a json object with function name and arguments within &lt;tool_call&gt;&lt;/tool_call&gt; XML tags:</span><span class="se">\\</span><span class="s2">n&lt;tool_call&gt;</span><span class="se">\\</span><span class="s2">n{</span><span class="se">\\\&quot;</span><span class="s2">name</span><span class="se">\\\&quot;</span><span class="s2">: &lt;function-name&gt;, </span><span class="se">\\\&quot;</span><span class="s2">arguments</span><span class="se">\\\&quot;</span><span class="s2">: &lt;args-json-object&gt;}</span><span class="se">\\</span><span class="s2">n&lt;/tool_call&gt;&lt;|im_end|&gt;</span><span class="se">\\</span><span class="s2">n&quot; }}</span>
<span class="s2">{</span><span class="si">%- e</span><span class="s2">lse %}</span>
<span class="s2">    {</span><span class="si">%- i</span><span class="s2">f messages[0][&#39;role&#39;] == &#39;system&#39; %}</span>
<span class="s2">        {{- &#39;&lt;|im_start|&gt;system</span><span class="se">\\</span><span class="s2">n&#39; + messages[0][&#39;content&#39;] + &#39;&lt;|im_end|&gt;</span><span class="se">\\</span><span class="s2">n&#39; }}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">lse %}</span>
<span class="s2">        {{- &#39;&lt;|im_start|&gt;system</span><span class="se">\\</span><span class="s2">nYou are a helpful assistant.&lt;|im_end|&gt;</span><span class="se">\\</span><span class="s2">n&#39; }}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">{</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">{</span><span class="si">%- f</span><span class="s2">or message in messages %}</span>
<span class="s2">    {</span><span class="si">%- i</span><span class="s2">f (message.role == &quot;user&quot;) or (message.role == &quot;system&quot; and not loop.first) %}</span>
<span class="s2">        {{- &#39;&lt;|im_start|&gt;&#39; + message.role + &#39;</span><span class="se">\\</span><span class="s2">n&#39; + message.content + &#39;&lt;|im_end|&gt;&#39; + &#39;</span><span class="se">\\</span><span class="s2">n&#39; }}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">lif (message.role == &quot;assistant&quot; and not message.tool_calls) %}</span>
<span class="s2">    {</span><span class="si">% g</span><span class="s2">eneration %}    {{- &#39;&lt;|im_start|&gt;&#39; + message.role + &#39;</span><span class="se">\\</span><span class="s2">n&#39; + message.content + &#39;&lt;|im_end|&gt;&#39; + &#39;</span><span class="se">\\</span><span class="s2">n&#39; }}    {</span><span class="si">% e</span><span class="s2">ndgeneration %}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">lif message.role == &quot;assistant&quot; %}</span>
<span class="s2">        {</span><span class="si">% g</span><span class="s2">eneration %}{{- &#39;&lt;|im_start|&gt;&#39; + message.role }}</span>
<span class="s2">        {</span><span class="si">%- i</span><span class="s2">f message.content %}</span>
<span class="s2">            {{- &#39;</span><span class="se">\\</span><span class="s2">n&#39; + message.content }}</span>
<span class="s2">        {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">        {</span><span class="si">%- f</span><span class="s2">or tool_call in message.tool_calls %}</span>
<span class="s2">            {</span><span class="si">%- i</span><span class="s2">f tool_call.function is defined %}</span>
<span class="s2">                {</span><span class="si">%- s</span><span class="s2">et tool_call = tool_call.function %}</span>
<span class="s2">            {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">            {{- &#39;</span><span class="se">\\</span><span class="s2">n&lt;tool_call&gt;</span><span class="se">\\</span><span class="s2">n{</span><span class="se">\\\&quot;</span><span class="s2">name</span><span class="se">\\\&quot;</span><span class="s2">: </span><span class="se">\\\&quot;</span><span class="s2">&#39; }}</span>
<span class="s2">            {{- tool_call.name }}</span>
<span class="s2">            {{- &#39;</span><span class="se">\\\&quot;</span><span class="s2">, </span><span class="se">\\\&quot;</span><span class="s2">arguments</span><span class="se">\\\&quot;</span><span class="s2">: &#39; }}</span>
<span class="s2">            {{- tool_call.arguments | tojson }}</span>
<span class="s2">            {{- &#39;}</span><span class="se">\\</span><span class="s2">n&lt;/tool_call&gt;&#39; }}</span>
<span class="s2">        {</span><span class="si">%- e</span><span class="s2">ndfor %}</span>
<span class="s2">        {{- &#39;&lt;|im_end|&gt;</span><span class="se">\\</span><span class="s2">n&#39; }}{</span><span class="si">% e</span><span class="s2">ndgeneration %}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">lif message.role == &quot;tool&quot; %}</span>
<span class="s2">        {</span><span class="si">%- i</span><span class="s2">f (loop.index0 == 0) or (messages[loop.index0 - 1].role != &quot;tool&quot;) %}</span>
<span class="s2">            {{- &#39;&lt;|im_start|&gt;tool&#39; }}</span>
<span class="s2">        {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">        {{- &#39;</span><span class="se">\\</span><span class="s2">n&lt;tool_response&gt;</span><span class="se">\\</span><span class="s2">n&#39; }}</span>
<span class="s2">        {</span><span class="si">%- i</span><span class="s2">f message.tool_responses %}</span>
<span class="s2">            {{- message.tool_responses }}</span>
<span class="s2">        {</span><span class="si">%- e</span><span class="s2">lse %}</span>
<span class="s2">            {{- message.content }}</span>
<span class="s2">        {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">        {{- &#39;</span><span class="se">\\</span><span class="s2">n&lt;/tool_response&gt;&#39; }}</span>
<span class="s2">        {</span><span class="si">%- i</span><span class="s2">f loop.last or (messages[loop.index0 + 1].role != &quot;tool&quot;) %}</span>
<span class="s2">            {{- &#39;&lt;|im_end|&gt;</span><span class="se">\\</span><span class="s2">n&#39; }}</span>
<span class="s2">        {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">{</span><span class="si">%- e</span><span class="s2">ndfor %}</span>
<span class="s2">{</span><span class="si">%- i</span><span class="s2">f add_generation_prompt %}</span>
<span class="s2">    {</span><span class="si">% g</span><span class="s2">eneration %}{{- &#39;&lt;|im_start|&gt;assistant</span><span class="se">\\</span><span class="s2">n&#39; }}{</span><span class="si">% e</span><span class="s2">ndgeneration %}</span>
<span class="s2">{</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="s2">&quot;dialogpt&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;{</span><span class="si">% f</span><span class="s2">or message in messages %}{</span><span class="si">% i</span><span class="s2">f message[&#39;role&#39;] == &#39;assistant&#39; %}{</span><span class="si">% g</span><span class="s2">eneration %}{{ message[&#39;content&#39;] }}{</span><span class="si">% e</span><span class="s2">ndgeneration %}{{ eos_token }}{</span><span class="si">% e</span><span class="s2">lif message[&#39;role&#39;] == &#39;user&#39; %}{{ message[&#39;content&#39;] }}{{ eos_token }}{</span><span class="si">% e</span><span class="s2">ndif %}{</span><span class="si">% e</span><span class="s2">ndfor %}{</span><span class="si">% i</span><span class="s2">f add_generation_prompt %}{</span><span class="si">% g</span><span class="s2">eneration %}{{ &#39; &#39; }}{</span><span class="si">% e</span><span class="s2">ndgeneration %}{</span><span class="si">% e</span><span class="s2">ndif %}&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="s2">&quot;falcon&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;{</span><span class="si">% f</span><span class="s2">or message in messages %}{</span><span class="si">% i</span><span class="s2">f message[&#39;role&#39;] == &#39;assistant&#39; %}{</span><span class="si">% g</span><span class="s2">eneration %}{{ &#39;Assistant: &#39; + message[&#39;content&#39;] }}{</span><span class="si">% e</span><span class="s2">ndgeneration %}</span><span class="se">\n\n</span><span class="s2">{</span><span class="si">% e</span><span class="s2">lif message[&#39;role&#39;] == &#39;user&#39; %}{{ &#39;User: &#39; + message[&#39;content&#39;] }}</span><span class="se">\n\n</span><span class="s2">{</span><span class="si">% e</span><span class="s2">lif message[&#39;role&#39;] == &#39;system&#39; %}{{ message[&#39;content&#39;] }}</span><span class="se">\n\n</span><span class="s2">{</span><span class="si">% e</span><span class="s2">ndif %}{</span><span class="si">% e</span><span class="s2">ndfor %}{</span><span class="si">% i</span><span class="s2">f add_generation_prompt %}{</span><span class="si">% g</span><span class="s2">eneration %}{{ &#39;Assistant: &#39; }}{</span><span class="si">% e</span><span class="s2">ndgeneration %}{</span><span class="si">% e</span><span class="s2">ndif %}&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="s2">&quot;deepseek&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;{</span><span class="si">% i</span><span class="s2">f not add_generation_prompt is defined %}{</span><span class="si">% s</span><span class="s2">et add_generation_prompt = false %}{</span><span class="si">% e</span><span class="s2">ndif %}{{ bos_token }}{</span><span class="si">% f</span><span class="s2">or message in messages %}{</span><span class="si">% i</span><span class="s2">f message[&#39;role&#39;] == &#39;user&#39; %}{{ &#39;User: &#39; + message[&#39;content&#39;] + &#39;</span><span class="se">\n\n</span><span class="s2">&#39; }}{</span><span class="si">% e</span><span class="s2">lif message[&#39;role&#39;] == &#39;assistant&#39; %}{</span><span class="si">% g</span><span class="s2">eneration %}{{ &#39;Assistant: &#39; + message[&#39;content&#39;] + eos_token }}{</span><span class="si">% e</span><span class="s2">ndgeneration %}{</span><span class="si">% e</span><span class="s2">lif message[&#39;role&#39;] == &#39;system&#39; %}{{ message[&#39;content&#39;] + &#39;</span><span class="se">\n\n</span><span class="s2">&#39; }}{</span><span class="si">% e</span><span class="s2">ndif %}{</span><span class="si">% e</span><span class="s2">ndfor %}{</span><span class="si">% i</span><span class="s2">f add_generation_prompt %}{</span><span class="si">% g</span><span class="s2">eneration %}{{ &#39;Assistant:&#39; }}{</span><span class="si">% e</span><span class="s2">ndgeneration %}{</span><span class="si">% e</span><span class="s2">ndif %}&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="s2">&quot;llama&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;{{- bos_token }}</span>
<span class="s2">{</span><span class="si">%- i</span><span class="s2">f messages[0][&#39;role&#39;] == &#39;system&#39; %}</span>
<span class="s2">    {</span><span class="si">%- s</span><span class="s2">et system_message = messages[0][&#39;content&#39;]|trim %}</span>
<span class="s2">    {</span><span class="si">%- s</span><span class="s2">et messages = messages[1:] %}</span>
<span class="s2">{</span><span class="si">%- e</span><span class="s2">lse %}</span>
<span class="s2">    {</span><span class="si">%- s</span><span class="s2">et system_message = &quot;&quot; %}</span>
<span class="s2">{</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">{</span><span class="si">%- i</span><span class="s2">f system_message %}</span>
<span class="s2">    {{- &quot;&lt;|header_start|&gt;system&lt;|header_end|&gt;</span><span class="se">\n\n</span><span class="s2">&quot; }}</span>
<span class="s2">    {{- system_message }}</span>
<span class="s2">    {{- &quot;&lt;|eot|&gt;&quot; }}</span>
<span class="s2">{</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">{</span><span class="si">%- f</span><span class="s2">or message in messages %}</span>
<span class="s2">    {</span><span class="si">%- i</span><span class="s2">f message[&#39;role&#39;] == &#39;assistant&#39; %}</span>
<span class="s2">    {</span><span class="si">% g</span><span class="s2">eneration %}{{- &#39;&lt;|header_start|&gt;&#39; + message[&#39;role&#39;] + &#39;&lt;|header_end|&gt;</span><span class="se">\n\n</span><span class="s2">&#39; }}</span>
<span class="s2">        {</span><span class="si">%- i</span><span class="s2">f message[&#39;content&#39;] is string %}</span>
<span class="s2">            {{- message[&#39;content&#39;] }}</span>
<span class="s2">        {</span><span class="si">%- e</span><span class="s2">lse %}</span>
<span class="s2">            {</span><span class="si">%- f</span><span class="s2">or content in message[&#39;content&#39;] %}</span>
<span class="s2">                {</span><span class="si">%- i</span><span class="s2">f content[&#39;type&#39;] == &#39;text&#39; %}</span>
<span class="s2">                    {{- content[&#39;text&#39;] | trim }}</span>
<span class="s2">                {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">            {</span><span class="si">%- e</span><span class="s2">ndfor %}</span>
<span class="s2">        {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">    {{- &quot;&lt;|eot|&gt;&quot; }}{</span><span class="si">% e</span><span class="s2">ndgeneration %}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">lse %}</span>
<span class="s2">    {{- &#39;&lt;|header_start|&gt;&#39; + message[&#39;role&#39;] + &#39;&lt;|header_end|&gt;</span><span class="se">\n\n</span><span class="s2">&#39; }}</span>
<span class="s2">        {</span><span class="si">%- i</span><span class="s2">f message[&#39;content&#39;] is string %}</span>
<span class="s2">            {{- message[&#39;content&#39;] }}</span>
<span class="s2">        {</span><span class="si">%- e</span><span class="s2">lse %}</span>
<span class="s2">            {</span><span class="si">%- f</span><span class="s2">or content in message[&#39;content&#39;] %}</span>
<span class="s2">                {</span><span class="si">%- i</span><span class="s2">f content[&#39;type&#39;] == &#39;text&#39; %}</span>
<span class="s2">                    {{- content[&#39;text&#39;] | trim }}</span>
<span class="s2">                {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">            {</span><span class="si">%- e</span><span class="s2">ndfor %}</span>
<span class="s2">        {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">    {{- &quot;&lt;|eot|&gt;&quot; }}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">{</span><span class="si">%- e</span><span class="s2">ndfor %}</span>
<span class="s2">{</span><span class="si">%- i</span><span class="s2">f add_generation_prompt %}</span>
<span class="s2">    {</span><span class="si">% g</span><span class="s2">eneration %}{{- &#39;&lt;|header_start|&gt;assistant&lt;|header_end|&gt;</span><span class="se">\n\n</span><span class="s2">&#39; }}{</span><span class="si">% e</span><span class="s2">ndgeneration %}</span>
<span class="s2">{</span><span class="si">%- e</span><span class="s2">ndif %}&quot;&quot;&quot;</span><span class="p">,</span>
<span class="p">}</span>

<span class="c1"># Global storage for custom template metadata</span>
<span class="n">_CUSTOM_INVERSE_PARSERS</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">_CUSTOM_MODEL_FAMILY_KEYWORDS</span> <span class="o">=</span> <span class="p">{}</span>


<div class="viewcode-block" id="add_chat_template"><a class="viewcode-back" href="../../../../reference/llms.html#torchrl.data.llm.add_chat_template">[docs]</a><span class="k">def</span><span class="w"> </span><span class="nf">add_chat_template</span><span class="p">(</span>
    <span class="n">template_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">template</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">inverse_parser</span><span class="p">:</span> <span class="nb">callable</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_family_keywords</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Add a custom chat template to the global template dictionary.</span>

<span class="sd">    This function allows you to add custom chat templates for new model families</span>
<span class="sd">    that support assistant token masking via the `{% generation %}` keyword.</span>

<span class="sd">    Args:</span>
<span class="sd">        template_name (str): The name of the template (e.g., &quot;llama&quot;, &quot;mistral&quot;).</span>
<span class="sd">            This name will be used in the `chat_template_name` parameter of</span>
<span class="sd">            `History.apply_chat_template()` and `History.from_text()`.</span>
<span class="sd">        template (str): The Jinja2 template string. Must include `{% generation %}`</span>
<span class="sd">            blocks around assistant message content to enable token masking.</span>
<span class="sd">        inverse_parser (callable, optional): A function that parses formatted text back</span>
<span class="sd">            into a History object. Should have signature `(text: str) -&gt; History`.</span>
<span class="sd">            If None, a basic parser will be used.</span>
<span class="sd">        model_family_keywords (list[str], optional): Keywords to detect this model family</span>
<span class="sd">            in the auto-detection logic. For example, [&quot;llama&quot;, &quot;meta-llama&quot;] for Llama models.</span>
<span class="sd">            If provided, the template will be automatically selected for models containing</span>
<span class="sd">            these keywords in their name.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data.llm.chat import add_chat_template, History</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoTokenizer</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Add a custom template for Llama models</span>
<span class="sd">        &gt;&gt;&gt; llama_template = &#39;&#39;&#39;</span>
<span class="sd">        ... {% for message in messages %}</span>
<span class="sd">        ... {%- if message[&#39;role&#39;] == &#39;user&#39; %}</span>
<span class="sd">        ... {{ &#39;&lt;s&gt;[INST] &#39; + message[&#39;content&#39;] + &#39; [/INST]&#39; }}</span>
<span class="sd">        ... {%- elif message[&#39;role&#39;] == &#39;assistant&#39; %}</span>
<span class="sd">        ... {% generation %}{{ message[&#39;content&#39;] + &#39;&lt;/s&gt;&#39; }}{% endgeneration %}</span>
<span class="sd">        ... {%- endif %}</span>
<span class="sd">        ... {% endfor %}</span>
<span class="sd">        ... {%- if add_generation_prompt %}</span>
<span class="sd">        ... {% generation %}{{ &#39; &#39; }}{% endgeneration %}</span>
<span class="sd">        ... {%- endif %}</span>
<span class="sd">        ... &#39;&#39;&#39;</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; def parse_llama_text(text: str) -&gt; History:</span>
<span class="sd">        ...     # Custom parser for Llama format</span>
<span class="sd">        ...     import re</span>
<span class="sd">        ...     pattern = r&#39;&lt;s&gt;\[INST\]\s*(.*?)\s*\[/INST\]\s*(.*?)&lt;/s&gt;&#39;</span>
<span class="sd">        ...     matches = re.findall(pattern, text, re.DOTALL)</span>
<span class="sd">        ...     messages = []</span>
<span class="sd">        ...     for user_content, assistant_content in matches:</span>
<span class="sd">        ...         messages.append(History(role=&quot;user&quot;, content=user_content.strip()))</span>
<span class="sd">        ...         messages.append(History(role=&quot;assistant&quot;, content=assistant_content.strip()))</span>
<span class="sd">        ...     return lazy_stack(messages)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Add the template with auto-detection</span>
<span class="sd">        &gt;&gt;&gt; add_chat_template(</span>
<span class="sd">        ...     template_name=&quot;llama&quot;,</span>
<span class="sd">        ...     template=llama_template,</span>
<span class="sd">        ...     inverse_parser=parse_llama_text,</span>
<span class="sd">        ...     model_family_keywords=[&quot;llama&quot;, &quot;meta-llama&quot;]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Now you can use it with auto-detection</span>
<span class="sd">        &gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(&quot;meta-llama/Llama-2-7b-chat-hf&quot;)</span>
<span class="sd">        &gt;&gt;&gt; history = History.from_chats([[</span>
<span class="sd">        ...     {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello&quot;},</span>
<span class="sd">        ...     {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Hi there!&quot;}</span>
<span class="sd">        ... ]])</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Auto-detection will use the llama template</span>
<span class="sd">        &gt;&gt;&gt; result = history.apply_chat_template(</span>
<span class="sd">        ...     tokenizer=tokenizer,</span>
<span class="sd">        ...     add_generation_prompt=False,</span>
<span class="sd">        ...     return_dict=True,</span>
<span class="sd">        ...     return_assistant_tokens_mask=True,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Or use it explicitly</span>
<span class="sd">        &gt;&gt;&gt; result = history.apply_chat_template(</span>
<span class="sd">        ...     tokenizer=tokenizer,</span>
<span class="sd">        ...     chat_template_name=&quot;llama&quot;,</span>
<span class="sd">        ...     add_generation_prompt=False,</span>
<span class="sd">        ...     return_dict=True,</span>
<span class="sd">        ...     return_assistant_tokens_mask=True,</span>
<span class="sd">        ... )</span>

<span class="sd">    .. note:</span>
<span class="sd">        - The template must include `{% generation %}` blocks around assistant message</span>
<span class="sd">          content to enable assistant token masking.</span>
<span class="sd">        - The inverse parser should handle the specific format of your template.</span>
<span class="sd">        - Model family keywords are case-insensitive and matched against the tokenizer&#39;s</span>
<span class="sd">          `name_or_path` attribute.</span>
<span class="sd">        - Templates are stored globally and persist for the duration of the Python session.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">global</span> <span class="n">_CHAT_TEMPLATES</span><span class="p">,</span> <span class="n">_CUSTOM_INVERSE_PARSERS</span><span class="p">,</span> <span class="n">_CUSTOM_MODEL_FAMILY_KEYWORDS</span>  <span class="c1"># noqa: F824</span>

    <span class="c1"># Validate template contains generation blocks</span>
    <span class="k">if</span> <span class="s2">&quot;{</span><span class="si">% g</span><span class="s2">eneration %}&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">template</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Template &#39;</span><span class="si">{</span><span class="n">template_name</span><span class="si">}</span><span class="s2">&#39; must include &#39;</span><span class="se">{{</span><span class="s2">% generation %</span><span class="se">}}</span><span class="s2">&#39; blocks &quot;</span>
            <span class="s2">&quot;around assistant message content to enable token masking.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Add template to dictionary</span>
    <span class="n">_CHAT_TEMPLATES</span><span class="p">[</span><span class="n">template_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">template</span>

    <span class="c1"># Store inverse parser if provided</span>
    <span class="k">if</span> <span class="n">inverse_parser</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_CUSTOM_INVERSE_PARSERS</span><span class="p">[</span><span class="n">template_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">inverse_parser</span>

    <span class="c1"># Store model family keywords if provided</span>
    <span class="k">if</span> <span class="n">model_family_keywords</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_CUSTOM_MODEL_FAMILY_KEYWORDS</span><span class="p">[</span><span class="n">template_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_family_keywords</span>

    <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Added custom chat template &#39;</span><span class="si">{</span><span class="n">template_name</span><span class="si">}</span><span class="s2">&#39; with assistant token masking support&quot;</span>
    <span class="p">)</span></div>


<span class="c1"># We need the &#39;shadow&#39; flag to avoid having tensordict complaining about &#39;type&#39;/&#39;size&#39; etc. fields</span>
<div class="viewcode-block" id="ContentBase"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.llm.ContentBase.html#torchrl.data.llm.ContentBase">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ContentBase</span><span class="p">(</span><span class="n">TensorClass</span><span class="p">[</span><span class="s2">&quot;nocast&quot;</span><span class="p">,</span> <span class="s2">&quot;shadow&quot;</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for all message content types.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        type (str): The type of the content.</span>
<span class="sd">        text (str, optional): The text content.</span>
<span class="sd">        url (str, optional): The URL content.</span>
<span class="sd">        data (str, optional): The data content.</span>
<span class="sd">        mime_type (str, optional): The MIME type of the content.</span>
<span class="sd">        name (str, optional): The name of the content.</span>
<span class="sd">        size (int, optional): The size of the content.</span>
<span class="sd">        function_name (str, optional): The name of the function.</span>
<span class="sd">        function_args (dict, optional): The arguments of the function.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import lazy_stack</span>
<span class="sd">        &gt;&gt;&gt; content1 = ContentBase(type=&quot;text&quot;, text=&quot;Hello, world!&quot;)</span>
<span class="sd">        &gt;&gt;&gt; print(content1)</span>
<span class="sd">        ContentBase(</span>
<span class="sd">            text=NonTensorData(data=Hello, world!, batch_size=torch.Size([]), device=None),</span>
<span class="sd">            type=NonTensorData(data=text, batch_size=torch.Size([]), device=None),</span>
<span class="sd">            url=None,</span>
<span class="sd">            data=None,</span>
<span class="sd">            mime_type=None,</span>
<span class="sd">            name=None,</span>
<span class="sd">            size=None,</span>
<span class="sd">            function_name=None,</span>
<span class="sd">            function_args=None,</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; content2 = ContentBase(type=&quot;image&quot;, url=&quot;https://example.com/image.jpg&quot;)</span>
<span class="sd">        &gt;&gt;&gt; print(content2)</span>
<span class="sd">        ContentBase(</span>
<span class="sd">            type=NonTensorData(data=image, batch_size=torch.Size([]), device=None),</span>
<span class="sd">            url=NonTensorData(data=https://example.com/image.jpg, batch_size=torch.Size([]), device=None),</span>
<span class="sd">            text=None,</span>
<span class="sd">            data=None,</span>
<span class="sd">            mime_type=None,</span>
<span class="sd">            name=None,</span>
<span class="sd">            size=None,</span>
<span class="sd">            function_name=None,</span>
<span class="sd">            function_args=None,</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; content = lazy_stack([content1, content2])</span>
<span class="sd">        &gt;&gt;&gt; print(content)</span>
<span class="sd">        ContentBase(</span>
<span class="sd">            type=NonTensorStack(</span>
<span class="sd">                [&#39;text&#39;, &#39;image&#39;],</span>
<span class="sd">                batch_size=torch.Size([2]),</span>
<span class="sd">                device=None),</span>
<span class="sd">            url=None,</span>
<span class="sd">            data=None,</span>
<span class="sd">            mime_type=None,</span>
<span class="sd">            name=None,</span>
<span class="sd">            size=None,</span>
<span class="sd">            function_name=None,</span>
<span class="sd">            function_args=None,</span>
<span class="sd">            text=None,</span>
<span class="sd">            batch_size=torch.Size([2]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; # A content is typically used in a History object. Usually, its batch dimension is</span>
<span class="sd">        &gt;&gt;&gt; #  one dimension greater than the History object.</span>
<span class="sd">        &gt;&gt;&gt; history = History(role=&quot;user&quot;, content=content)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">type</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span>
        <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="s2">&quot;video&quot;</span><span class="p">,</span> <span class="s2">&quot;file&quot;</span><span class="p">,</span> <span class="s2">&quot;function_call&quot;</span>
    <span class="p">]</span>  <span class="c1"># Required: &quot;text&quot;, &quot;image&quot;, &quot;audio&quot;, &quot;video&quot;, &quot;file&quot;, &quot;function_call&quot;</span>

    <span class="c1"># Text content</span>
    <span class="n">text</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Media/file content (either URL or data)</span>
    <span class="n">url</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># HTTP URL to content</span>
    <span class="n">data</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Base64 encoded content</span>

    <span class="c1"># Metadata</span>
    <span class="n">mime_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># &quot;image/jpeg&quot;, &quot;audio/mp3&quot;, &quot;application/pdf&quot;</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Original filename or description</span>
    <span class="n">size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># File size in bytes</span>

    <span class="c1"># Function calling (for AI agents)</span>
    <span class="n">function_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">function_args</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="History"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.llm.History.html#torchrl.data.llm.History">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">History</span><span class="p">(</span><span class="n">TensorClass</span><span class="p">[</span><span class="s2">&quot;nocast&quot;</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A class representing a structured history of messages in a conversation, designed for efficient manipulation and integration with language models.</span>

<span class="sd">    The `History` class provides a centralized API for managing conversational data, offering several advantages over</span>
<span class="sd">    traditional list-based approaches:</span>

<span class="sd">    - Centralized API for conversion to and from string formats, facilitating seamless integration with language models.</span>
<span class="sd">    - Efficient methods to append, extend, and reshape history elements, enabling dynamic construction of conversation</span>
<span class="sd">      trajectories, especially useful in reinforcement learning environments.</span>
<span class="sd">    - Interoperability with the `transformers` API, allowing for easy tokenization and preparation of input data.</span>
<span class="sd">    - **Assistant token masking support** across multiple model families for reinforcement learning applications.</span>

<span class="sd">    **Recent Changes:**</span>
<span class="sd">    - **ChatHistory Integration**: History objects are now used within :class:`~torchrl.modules.llm.policies.ChatHistory`</span>
<span class="sd">      containers for structured conversation management in LLM environments.</span>
<span class="sd">    - **Modular Wrapper Support**: Both vLLMWrapper and TransformersWrapper now use History objects when `input_mode=&quot;history&quot;`</span>
<span class="sd">      is specified, providing consistent conversation state management.</span>
<span class="sd">    - **Environment Integration**: ChatEnv and related environments use History objects for state management and conversation tracking.</span>

<span class="sd">    .. note:: The `&quot;&lt;none&gt;&quot;` role is used to indicate that the element is a placeholder,</span>
<span class="sd">        for example when the tool call was not executed but a stack requires a certain number of elements</span>
<span class="sd">        per batch to have congruent shapes. The :meth:`~torchrl.data.llm.chat.History.apply_chat_template`</span>
<span class="sd">        method will remove the `&lt;none&gt;` role from the history.</span>

<span class="sd">    **Assistant Token Masking Support:**</span>

<span class="sd">    The class supports assistant token masking across multiple model families, allowing you to identify which tokens</span>
<span class="sd">    in a conversation were generated by the assistant. This is crucial for reinforcement learning applications.</span>

<span class="sd">    **Supported Model Families:**</span>

<span class="sd">    - **Qwen family** (e.g., `Qwen/Qwen2.5-0.5B`): Custom template with full tool calling support</span>
<span class="sd">    - **DialoGPT family** (e.g., `microsoft/DialoGPT-medium`): Custom template for conversation format</span>
<span class="sd">    - **Falcon family** (e.g., `tiiuae/falcon-7b-instruct`): Custom template for instruction format</span>
<span class="sd">    - **DeepSeek family** (e.g., `deepseek-ai/deepseek-coder-6.7b-base`): Custom template with native format</span>
<span class="sd">    - **Other models** (OPT, GPT, MPT, BLOOM, Pythia, Phi, etc.): Default `chatml_format` template</span>

<span class="sd">    **Example with Assistant Token Masking:**</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        &gt;&gt;&gt; from torchrl.data.llm.chat import History</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules.llm.policies import ChatHistory</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoTokenizer</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Create a conversation history</span>
<span class="sd">        &gt;&gt;&gt; history = History.from_chats([[</span>
<span class="sd">        ...     {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello&quot;},</span>
<span class="sd">        ...     {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Hi there!&quot;},</span>
<span class="sd">        ...     {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;How are you?&quot;},</span>
<span class="sd">        ...     {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;I&#39;m doing well, thanks!&quot;}</span>
<span class="sd">        ... ]])</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Create ChatHistory container for LLM wrapper</span>
<span class="sd">        &gt;&gt;&gt; chat_history = ChatHistory(prompt=history)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Load any supported tokenizer</span>
<span class="sd">        &gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(&quot;Qwen/Qwen2.5-0.5B&quot;)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Apply chat template with assistant token masking</span>
<span class="sd">        &gt;&gt;&gt; result = history.apply_chat_template(</span>
<span class="sd">        ...     tokenizer=tokenizer,</span>
<span class="sd">        ...     add_generation_prompt=False,</span>
<span class="sd">        ...     return_dict=True,</span>
<span class="sd">        ...     return_assistant_tokens_mask=True,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # The result contains an assistant_masks tensor</span>
<span class="sd">        &gt;&gt;&gt; assistant_masks = result[&quot;assistant_masks&quot;]</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Assistant tokens: {assistant_masks.sum().item()}&quot;)</span>

<span class="sd">    **Integration with LLM Wrappers:**</span>

<span class="sd">    History objects work seamlessly with the new modular wrapper design:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        &gt;&gt;&gt; from torchrl.modules.llm import TransformersWrapper</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.modules.llm.policies import ChatHistory</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Create wrapper with history input mode</span>
<span class="sd">        &gt;&gt;&gt; wrapper = TransformersWrapper(</span>
<span class="sd">        ...     model, tokenizer=tokenizer,</span>
<span class="sd">        ...     input_mode=&quot;history&quot;,</span>
<span class="sd">        ...     generate=True,</span>
<span class="sd">        ...     return_log_probs=True</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use History with ChatHistory container</span>
<span class="sd">        &gt;&gt;&gt; history = History.from_chats([[</span>
<span class="sd">        ...     {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello&quot;},</span>
<span class="sd">        ...     {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Hi there!&quot;}</span>
<span class="sd">        ... ]])</span>
<span class="sd">        &gt;&gt;&gt; chat_history = ChatHistory(prompt=history)</span>
<span class="sd">        &gt;&gt;&gt; result = wrapper(TensorDict(history=chat_history, batch_size=(1,)))</span>
<span class="sd">        &gt;&gt;&gt; print(result[&quot;history&quot;].response)  # New response from LLM</span>

<span class="sd">    Attributes:</span>
<span class="sd">        role (str): The role of the message sender.</span>
<span class="sd">        content (str): The content of the message.</span>
<span class="sd">        is_complete (bool): Whether the message was properly terminated with an end token. Defaults to `True`.</span>
<span class="sd">        tool_calls (list[dict] | None): Optional list of tool calls in the message.</span>
<span class="sd">        tool_responses (list[str] | None): Optional list of tool responses.</span>

<span class="sd">    Methods:</span>
<span class="sd">        apply_chat_template: converts the `History` object to str / tokens.</span>
<span class="sd">        append: append one element to the list of items along a given dimension.</span>
<span class="sd">        extend: extend the list of items along a given dimension.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; # With tensordict &lt; 0.10, we need to tell the lib that lists constitute batches</span>
<span class="sd">        &gt;&gt;&gt; import tensordict</span>
<span class="sd">        &gt;&gt;&gt; tensordict.set_list_to_stack(True).set()</span>
<span class="sd">        &gt;&gt;&gt; import transformers</span>
<span class="sd">        &gt;&gt;&gt; history0 = History(</span>
<span class="sd">        ...     role=&#39;system&#39;,</span>
<span class="sd">        ...     content=&#39;&#39;&#39;CONTENT</span>
<span class="sd">        ... This is the setup&#39;&#39;&#39;,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; history1 = History(</span>
<span class="sd">        ...     role=&#39;user&#39;,</span>
<span class="sd">        ...     content=&#39;&#39;&#39;CONTENT</span>
<span class="sd">        ... This is the first user prompt&#39;&#39;&#39;,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; history2 = History(</span>
<span class="sd">        ...     role=&#39;assistant&#39;,</span>
<span class="sd">        ...     content=&#39;&#39;&#39;CONTENT</span>
<span class="sd">        ... This is the second prompt, the first for the assistant.&#39;&#39;&#39;,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; history = torch.stack([history0, history1, history2])</span>
<span class="sd">        &gt;&gt;&gt; assert history.role == [&#39;system&#39;, &#39;user&#39;, &#39;assistant&#39;]</span>
<span class="sd">        &gt;&gt;&gt; tokenizer = transformers.AutoTokenizer.from_pretrained(&quot;GPT2&quot;)</span>
<span class="sd">        &gt;&gt;&gt; # Apply a template to pass the history to an LLM. Note that the output has</span>
<span class="sd">        &gt;&gt;&gt; #  an additional prompt to elict an answer from the LLM thanks to the &#39;add_generation_prompt&#39; argument.</span>
<span class="sd">        &gt;&gt;&gt; parsed_string = history.apply_chat_template(tokenizer=tokenizer, add_generation_prompt=True)</span>
<span class="sd">        &gt;&gt;&gt; parsed_string</span>
<span class="sd">            &lt;|im_start|&gt;system</span>
<span class="sd">        CONTENT</span>
<span class="sd">        This is the setup&lt;|im_end|&gt;</span>

<span class="sd">            &lt;|im_start|&gt;user</span>
<span class="sd">        CONTENT</span>
<span class="sd">        This is the first user prompt&lt;|im_end|&gt;</span>

<span class="sd">            &lt;|im_start|&gt;assistant</span>
<span class="sd">        CONTENT</span>
<span class="sd">        This is the second prompt, the first for the assistant.&lt;|im_end|&gt;</span>

<span class="sd">        &lt;|im_start|&gt;assistant</span>

<span class="sd">    .. seealso::</span>
<span class="sd">        :class:`~torchrl.modules.llm.policies.ChatHistory`: Container for managing conversation data in LLM environments.</span>
<span class="sd">        :class:`~torchrl.modules.llm.policies.Text`: Container for text data.</span>
<span class="sd">        :class:`~torchrl.modules.llm.policies.Tokens`: Container for token data.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">role</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span>
    <span class="n">content</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">ContentBase</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">ContentBase</span><span class="p">]</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span>
        <span class="nb">list</span><span class="p">[</span><span class="n">ContentBase</span><span class="p">]</span>
    <span class="p">]</span>
    <span class="n">is_complete</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">tool_calls</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">tool_responses</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">list_to_stack</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Please set the list_to_stack to True using tensordict.set_list_to_stack(True).set() at the beginning of your script, &quot;</span>
                <span class="s2">&quot;or the LIST_TO_STACK=1 environment variable.&quot;</span>
            <span class="p">)</span>

<div class="viewcode-block" id="History.apply_chat_template"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.llm.History.html#torchrl.data.llm.History.apply_chat_template">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">apply_chat_template</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoTokenizer</span> <span class="o">|</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoProcessor</span><span class="p">,</span>  <span class="c1"># noqa</span>
        <span class="n">add_generation_prompt</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">chat_template</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">chat_template_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">continue_final_message</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">tokenize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">padding</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">truncation</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_assistant_tokens_mask</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="n">TensorDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Applies a chat template to the history.</span>

<span class="sd">        Keyword Args:</span>
<span class="sd">            tokenizer (transformers.PreTrainedTokenizer | transformers.AutoProcessor): The tokenizer to use.</span>
<span class="sd">            add_generation_prompt (bool, optional): Whether to add a generation prompt (e.g. `&quot;&lt;|im_start|&gt;assistant&quot;`). Defaults to `True`.</span>
<span class="sd">            chat_template (str, optional): The chat template to use. Defaults to the tokenizer&#39;s default template.</span>
<span class="sd">            chat_template_name (str, optional): The name of the chat template to use.</span>
<span class="sd">                Prevalent over `tokenizer.chat_template`. If `None`, the method will automatically detect the model family and use the appropriate template.</span>
<span class="sd">                Defaults to `None`.</span>
<span class="sd">            continue_final_message (bool, optional): Whether to continue the final message. Defaults to `False`.</span>
<span class="sd">            tokenize (bool, optional): Whether to tokenize the output. Defaults to `False`.</span>
<span class="sd">            padding (bool | str, optional): The padding strategy to use. Defaults to `False`.</span>
<span class="sd">            truncation (bool | str, optional): The truncation strategy to use. Defaults to `False`.</span>
<span class="sd">            return_tensors (str | None, optional): The type of tensors to return. Defaults to &quot;pt&quot;.</span>
<span class="sd">            return_dict (bool, optional): Whether to return a dictionary. Defaults to `False`.</span>
<span class="sd">            return_assistant_tokens_mask (bool, optional): Whether to return a mask of the assistant generated tokens.</span>
<span class="sd">                If `True`, the mask will be written to the `assistant_masks` key.</span>
<span class="sd">                For tokens generated by the assistant, the mask will contain `1`.</span>
<span class="sd">                For user and system tokens, the mask will contain `0`.</span>
<span class="sd">                This functionality is only available for chat templates that support it via the `{% generation %}` keyword.</span>
<span class="sd">                Defaults to `False`.</span>

<span class="sd">                .. note:: Assistant token masking is supported across multiple model families:</span>
<span class="sd">                    - **Qwen family**: Uses custom template with full tool calling support</span>
<span class="sd">                    - **DialoGPT family**: Uses custom template for conversation format</span>
<span class="sd">                    - **Falcon family**: Uses custom template for instruction format</span>
<span class="sd">                    - **DeepSeek family**: Uses custom template with native format</span>
<span class="sd">                    - **Other models**: Use the default `chatml_format` template</span>

<span class="sd">                    The method automatically detects the model family and selects the appropriate template.</span>

<span class="sd">            **kwargs: Additional keyword arguments to pass to the tokenizer `apply_chat_template` method.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The formatted history.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">chat_template</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">chat_template_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">chat_template</span> <span class="o">=</span> <span class="n">_CHAT_TEMPLATES</span><span class="p">[</span><span class="n">chat_template_name</span><span class="p">]</span>
                <span class="n">chat_template_name</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">elif</span> <span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;You must specify a tokenizer to use when chat_template is not specified.&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Auto-detect model family and use appropriate template</span>
                <span class="n">model_name</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;name_or_path&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

                <span class="c1"># First check for custom model family keywords</span>
                <span class="n">custom_template_found</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">for</span> <span class="n">template_name</span><span class="p">,</span> <span class="n">keywords</span> <span class="ow">in</span> <span class="n">_CUSTOM_MODEL_FAMILY_KEYWORDS</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">keyword</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="n">model_name</span> <span class="k">for</span> <span class="n">keyword</span> <span class="ow">in</span> <span class="n">keywords</span><span class="p">):</span>
                        <span class="n">chat_template</span> <span class="o">=</span> <span class="n">_CHAT_TEMPLATES</span><span class="p">[</span><span class="n">template_name</span><span class="p">]</span>
                        <span class="n">chat_template_name</span> <span class="o">=</span> <span class="kc">None</span>
                        <span class="n">custom_template_found</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="k">break</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="n">custom_template_found</span><span class="p">:</span>
                    <span class="c1"># Fall back to built-in model family detection</span>
                    <span class="k">if</span> <span class="s2">&quot;qwen&quot;</span> <span class="ow">in</span> <span class="n">model_name</span><span class="p">:</span>
                        <span class="c1"># We prefer our implementation of the Qwen template,</span>
                        <span class="c1">#  since it accounts for the assistant&#39;s masking.</span>
                        <span class="n">chat_template</span> <span class="o">=</span> <span class="n">_CHAT_TEMPLATES</span><span class="p">[</span><span class="s2">&quot;qwen&quot;</span><span class="p">]</span>
                        <span class="n">chat_template_name</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="k">elif</span> <span class="s2">&quot;dialogpt&quot;</span> <span class="ow">in</span> <span class="n">model_name</span> <span class="ow">or</span> <span class="s2">&quot;microsoft/dialo&quot;</span> <span class="ow">in</span> <span class="n">model_name</span><span class="p">:</span>
                        <span class="c1"># DialoGPT family - use our custom template</span>
                        <span class="n">chat_template</span> <span class="o">=</span> <span class="n">_CHAT_TEMPLATES</span><span class="p">[</span><span class="s2">&quot;dialogpt&quot;</span><span class="p">]</span>
                        <span class="n">chat_template_name</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="k">elif</span> <span class="s2">&quot;falcon&quot;</span> <span class="ow">in</span> <span class="n">model_name</span> <span class="ow">or</span> <span class="s2">&quot;tiiuae/falcon&quot;</span> <span class="ow">in</span> <span class="n">model_name</span><span class="p">:</span>
                        <span class="c1"># Falcon family - use our custom template</span>
                        <span class="n">chat_template</span> <span class="o">=</span> <span class="n">_CHAT_TEMPLATES</span><span class="p">[</span><span class="s2">&quot;falcon&quot;</span><span class="p">]</span>
                        <span class="n">chat_template_name</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="k">elif</span> <span class="s2">&quot;deepseek&quot;</span> <span class="ow">in</span> <span class="n">model_name</span><span class="p">:</span>
                        <span class="c1"># DeepSeek family - use our custom template with generation keyword</span>
                        <span class="n">chat_template</span> <span class="o">=</span> <span class="n">_CHAT_TEMPLATES</span><span class="p">[</span><span class="s2">&quot;deepseek&quot;</span><span class="p">]</span>
                        <span class="n">chat_template_name</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="k">elif</span> <span class="s2">&quot;llama&quot;</span> <span class="ow">in</span> <span class="n">model_name</span><span class="p">:</span>
                        <span class="c1"># Llama family - use our custom template</span>
                        <span class="n">chat_template</span> <span class="o">=</span> <span class="n">_CHAT_TEMPLATES</span><span class="p">[</span><span class="s2">&quot;llama&quot;</span><span class="p">]</span>
                        <span class="n">chat_template_name</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># For other models, check if their default template supports generation</span>
                        <span class="k">if</span> <span class="p">(</span>
                            <span class="nb">hasattr</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;chat_template&quot;</span><span class="p">)</span>
                            <span class="ow">and</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">chat_template</span>
                            <span class="ow">and</span> <span class="s2">&quot;{</span><span class="si">% g</span><span class="s2">eneration %}&quot;</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">chat_template</span>
                        <span class="p">):</span>
                            <span class="c1"># Use the model&#39;s own template if it supports generation</span>
                            <span class="n">chat_template</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">chat_template</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="c1"># Use our default chatml_format template</span>
                            <span class="n">chat_template</span> <span class="o">=</span> <span class="n">_CHAT_TEMPLATES</span><span class="p">[</span><span class="s2">&quot;chatml_format&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">chat_template</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">chat_template</span> <span class="o">=</span> <span class="n">_CHAT_TEMPLATES</span><span class="p">[</span><span class="s2">&quot;chatml_format&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">tokenize</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">return_assistant_tokens_mask</span> <span class="ow">or</span> <span class="n">return_tensors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">tokenize</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tokenize</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">tokenize</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">return_tensors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">return_tensors</span> <span class="o">=</span> <span class="s2">&quot;pt&quot;</span>
            <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">return_assistant_tokens_mask</span><span class="p">:</span>
                <span class="n">return_dict</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">return_dict</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="p">[</span>
                <span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
                    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
                    <span class="n">add_generation_prompt</span><span class="o">=</span><span class="n">add_generation_prompt</span><span class="p">,</span>
                    <span class="n">chat_template</span><span class="o">=</span><span class="n">chat_template</span><span class="p">,</span>
                    <span class="n">chat_template_name</span><span class="o">=</span><span class="n">chat_template_name</span><span class="p">,</span>
                    <span class="n">tokenize</span><span class="o">=</span><span class="n">tokenize</span><span class="p">,</span>
                    <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                    <span class="n">truncation</span><span class="o">=</span><span class="n">truncation</span><span class="p">,</span>
                    <span class="n">return_tensors</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">,</span>
                    <span class="n">continue_final_message</span><span class="o">=</span><span class="n">continue_final_message</span><span class="p">,</span>
                    <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
                    <span class="n">return_assistant_tokens_mask</span><span class="o">=</span><span class="n">return_assistant_tokens_mask</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="p">]</span>
            <span class="k">if</span> <span class="n">return_dict</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">result</span>
        <span class="n">self_flat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># tolist_first=True is needed to avoid having a list of dict of dicts, but a list of dicts of lists of dicts</span>
        <span class="n">self_flat</span> <span class="o">=</span> <span class="n">self_flat</span><span class="o">.</span><span class="n">tolist</span><span class="p">(</span><span class="n">tolist_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Remove the &quot;&lt;none&gt;&quot; role</span>
        <span class="n">self_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">self_flat</span> <span class="k">if</span> <span class="n">item</span><span class="p">[</span><span class="s2">&quot;role&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;&lt;none&gt;&quot;</span><span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
            <span class="n">conversation</span><span class="o">=</span><span class="n">self_flat</span><span class="p">,</span>
            <span class="n">add_generation_prompt</span><span class="o">=</span><span class="n">add_generation_prompt</span><span class="p">,</span>
            <span class="n">chat_template</span><span class="o">=</span><span class="n">chat_template</span><span class="p">,</span>
            <span class="n">tokenize</span><span class="o">=</span><span class="n">tokenize</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="n">truncation</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">,</span>
            <span class="n">continue_final_message</span><span class="o">=</span><span class="n">continue_final_message</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
            <span class="n">return_assistant_tokens_mask</span><span class="o">=</span><span class="n">return_assistant_tokens_mask</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="nb">str</span><span class="p">)):</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">auto_batch_size</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_dims</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># If self has a batch_dims of 1, we have just the time dimension, so we need to remove the batch dim from the result</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Expected a batch size of 1, got </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span></div>

<div class="viewcode-block" id="History.from_text"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.llm.History.html#torchrl.data.llm.History.from_text">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_text</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">chat_template_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="c1"># currently without effect</span>
        <span class="n">chat_template</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoTokenizer</span>  <span class="c1"># noqa: F821</span>
        <span class="o">|</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoProcessor</span>  <span class="c1"># noqa: F821</span>
        <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">History</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Inverts a chat template into a History object.</span>

<span class="sd">        Args:</span>
<span class="sd">            text (str | list[str]): The chat template to invert.</span>
<span class="sd">            chat_template_name (str, optional): The name of the chat template to use.</span>
<span class="sd">            tokenizer (transformers.AutoTokenizer | transformers.AutoProcessor, optional): The tokenizer to use.</span>

<span class="sd">        Returns:</span>
<span class="sd">            History: The inverted History object.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.data.llm.history import History</span>
<span class="sd">            &gt;&gt;&gt; from transformers import AutoTokenizer</span>
<span class="sd">            &gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(&quot;Qwen/Qwen2.5-7B-Instruct&quot;)</span>
<span class="sd">            &gt;&gt;&gt; text = &quot;&lt;|im_start|&gt;system\nYou are a helpful assistant.\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\nWrite a python script that gives the capital of France or Germany.\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n&lt;think&gt;The capital of France is Paris, the capital of Germany is Berlin.&lt;/think&gt;\n&lt;answer&gt;&lt;python&gt;\n&quot;</span>
<span class="sd">            &gt;&gt;&gt; history = History.from_text(text, tokenizer=tokenizer)</span>
<span class="sd">            &gt;&gt;&gt; print(history)</span>
<span class="sd">            History(</span>
<span class="sd">                content=NonTensorStack(</span>
<span class="sd">                    [&#39;You are a helpful assistant.&#39;, &#39;Write a python s...,</span>
<span class="sd">                    batch_size=torch.Size([3]),</span>
<span class="sd">                    device=None),</span>
<span class="sd">                is_complete=NonTensorStack(</span>
<span class="sd">                    [True, True, False],</span>
<span class="sd">                    batch_size=torch.Size([3]),</span>
<span class="sd">                    device=None),</span>
<span class="sd">                role=NonTensorStack(</span>
<span class="sd">                    [&#39;system&#39;, &#39;user&#39;, &#39;assistant&#39;],</span>
<span class="sd">                    batch_size=torch.Size([3]),</span>
<span class="sd">                    device=None),</span>
<span class="sd">                tool_calls=None,</span>
<span class="sd">                tool_responses=None,</span>
<span class="sd">                batch_size=torch.Size([3]),</span>
<span class="sd">                device=None,</span>
<span class="sd">                is_shared=False)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">chat_template_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">chat_template</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># TODO: find best match given template</span>
                <span class="k">pass</span>

            <span class="n">model_name</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;name_or_path&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="c1"># First check for custom model family keywords</span>
            <span class="n">custom_template_found</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">for</span> <span class="n">template_name</span><span class="p">,</span> <span class="n">keywords</span> <span class="ow">in</span> <span class="n">_CUSTOM_MODEL_FAMILY_KEYWORDS</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">keyword</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="n">model_name</span> <span class="k">for</span> <span class="n">keyword</span> <span class="ow">in</span> <span class="n">keywords</span><span class="p">):</span>
                    <span class="n">chat_template_name</span> <span class="o">=</span> <span class="n">template_name</span>
                    <span class="n">custom_template_found</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">break</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">custom_template_found</span><span class="p">:</span>
                <span class="c1"># Fall back to built-in model family detection</span>
                <span class="k">if</span> <span class="s2">&quot;qwen&quot;</span> <span class="ow">in</span> <span class="n">model_name</span><span class="p">:</span>
                    <span class="c1"># We can automatically detect the template name from the tokenizer</span>
                    <span class="c1">#  and use the precoded parser.</span>
                    <span class="n">chat_template_name</span> <span class="o">=</span> <span class="s2">&quot;qwen&quot;</span>
                <span class="k">elif</span> <span class="s2">&quot;dialogpt&quot;</span> <span class="ow">in</span> <span class="n">model_name</span> <span class="ow">or</span> <span class="s2">&quot;microsoft/dialo&quot;</span> <span class="ow">in</span> <span class="n">model_name</span><span class="p">:</span>
                    <span class="n">chat_template_name</span> <span class="o">=</span> <span class="s2">&quot;dialogpt&quot;</span>
                <span class="k">elif</span> <span class="s2">&quot;falcon&quot;</span> <span class="ow">in</span> <span class="n">model_name</span> <span class="ow">or</span> <span class="s2">&quot;tiiuae/falcon&quot;</span> <span class="ow">in</span> <span class="n">model_name</span><span class="p">:</span>
                    <span class="n">chat_template_name</span> <span class="o">=</span> <span class="s2">&quot;falcon&quot;</span>
                <span class="k">elif</span> <span class="s2">&quot;deepseek&quot;</span> <span class="ow">in</span> <span class="n">model_name</span><span class="p">:</span>
                    <span class="n">chat_template_name</span> <span class="o">=</span> <span class="s2">&quot;deepseek&quot;</span>
                <span class="k">elif</span> <span class="s2">&quot;llama&quot;</span> <span class="ow">in</span> <span class="n">model_name</span><span class="p">:</span>
                    <span class="n">chat_template_name</span> <span class="o">=</span> <span class="s2">&quot;llama&quot;</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">chat_template_name</span> <span class="o">=</span> <span class="s2">&quot;chatml_format&quot;</span>

        <span class="c1"># Get the appropriate inverse parser function</span>
        <span class="k">if</span> <span class="n">chat_template_name</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;chatml_format&quot;</span><span class="p">,):</span>
            <span class="n">func</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_inv_chatml</span>
        <span class="k">elif</span> <span class="n">chat_template_name</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;qwen&quot;</span><span class="p">,):</span>
            <span class="n">func</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_inv_qwen</span>
        <span class="k">elif</span> <span class="n">chat_template_name</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;dialogpt&quot;</span><span class="p">,):</span>
            <span class="n">func</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_inv_dialogpt</span>
        <span class="k">elif</span> <span class="n">chat_template_name</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;falcon&quot;</span><span class="p">,):</span>
            <span class="n">func</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_inv_falcon</span>
        <span class="k">elif</span> <span class="n">chat_template_name</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;deepseek&quot;</span><span class="p">,):</span>
            <span class="n">func</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_inv_deepseek</span>
        <span class="k">elif</span> <span class="n">chat_template_name</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;llama&quot;</span><span class="p">,):</span>
            <span class="n">func</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_inv_llama</span>
        <span class="k">elif</span> <span class="n">chat_template_name</span> <span class="ow">in</span> <span class="n">_CUSTOM_INVERSE_PARSERS</span><span class="p">:</span>
            <span class="c1"># Use custom inverse parser</span>
            <span class="n">func</span> <span class="o">=</span> <span class="n">_CUSTOM_INVERSE_PARSERS</span><span class="p">[</span><span class="n">chat_template_name</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;chat_template_name &#39;</span><span class="si">{</span><span class="n">chat_template_name</span><span class="si">}</span><span class="s2">&#39; is not supported. &quot;</span>
                <span class="s2">&quot;Supported templates: &#39;chatml_format&#39;, &#39;qwen&#39;, &#39;dialogpt&#39;, &#39;falcon&#39;, &#39;deepseek&#39;. &quot;</span>
                <span class="s2">&quot;Use add_chat_template() to add custom templates.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">list_of_histories</span> <span class="o">=</span> <span class="p">[</span><span class="n">func</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">text</span><span class="p">]</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">(</span><span class="n">list_of_histories</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Failed to stack histories: </span><span class="si">{</span><span class="n">list_of_histories</span><span class="si">=}</span><span class="s2">&quot;</span>
                <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
        <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="n">text</span><span class="p">)</span></div>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_chatml</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">History</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Inverts a chatml string into a History object.</span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): The chatml string to invert.</span>

<span class="sd">        Returns:</span>
<span class="sd">            History: The inverted History object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

        <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inverting chatml:</span><span class="se">\n</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># Find all complete blocks (ending with im_end or endoftext)</span>
        <span class="n">complete_pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;&lt;\|im_start\|&gt;(.*?)\n(.*?)&lt;\|(im_end|endoftext)\|&gt;&quot;</span>
        <span class="n">complete_matches</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">complete_pattern</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>

        <span class="c1"># Find any incomplete block at the end</span>
        <span class="n">incomplete_pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;&lt;\|im_start\|&gt;(.*?)\n(.*?)$&quot;</span>
        <span class="n">incomplete_matches</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">complete_matches</span><span class="p">:</span>
            <span class="c1"># Look for incomplete block after the last complete one</span>
            <span class="n">last_complete</span> <span class="o">=</span> <span class="n">complete_matches</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">last_complete_text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&lt;|im_start|&gt;</span><span class="si">{</span><span class="n">last_complete</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="n">last_complete</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&lt;|</span><span class="si">{</span><span class="n">last_complete</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">|&gt;&quot;</span>
            <span class="n">remaining_text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span>
                <span class="n">text</span><span class="o">.</span><span class="n">rindex</span><span class="p">(</span><span class="n">last_complete_text</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">last_complete_text</span><span class="p">)</span> <span class="p">:</span>
            <span class="p">]</span>
            <span class="k">if</span> <span class="n">remaining_text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                <span class="n">incomplete_match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span>
                    <span class="n">incomplete_pattern</span><span class="p">,</span> <span class="n">remaining_text</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">incomplete_match</span><span class="p">:</span>
                    <span class="n">incomplete_matches</span> <span class="o">=</span> <span class="p">[</span>
                        <span class="p">(</span><span class="n">incomplete_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">incomplete_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="kc">None</span><span class="p">)</span>
                    <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># No complete blocks, check entire text for incomplete block</span>
            <span class="n">incomplete_match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">incomplete_pattern</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">incomplete_match</span><span class="p">:</span>
                <span class="n">incomplete_matches</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="p">(</span><span class="n">incomplete_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">incomplete_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="kc">None</span><span class="p">)</span>
                <span class="p">]</span>

        <span class="c1"># Combine complete and incomplete matches</span>
        <span class="n">matches</span> <span class="o">=</span> <span class="n">complete_matches</span> <span class="o">+</span> <span class="n">incomplete_matches</span>

        <span class="c1"># Define tool patterns - same as Qwen for consistency</span>
        <span class="n">tool_call_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;&lt;tool_call&gt;\n(.*?)\n&lt;/tool_call&gt;&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>
        <span class="n">tool_response_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
            <span class="sa">r</span><span class="s2">&quot;&lt;tool_response&gt;\n(.*?)\n&lt;/tool_response&gt;&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span>
        <span class="p">)</span>

        <span class="n">parsed_messages</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">:</span>
            <span class="n">role</span> <span class="o">=</span> <span class="n">match</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">content</span> <span class="o">=</span> <span class="n">match</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">is_complete</span> <span class="o">=</span> <span class="n">match</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>  <span class="c1"># None indicates incomplete</span>

            <span class="c1"># Initialize message dict</span>
            <span class="n">message_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">role</span><span class="p">,</span>
                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">content</span><span class="p">,</span>
                <span class="s2">&quot;is_complete&quot;</span><span class="p">:</span> <span class="n">is_complete</span><span class="p">,</span>
                <span class="s2">&quot;tool_calls&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;tool_responses&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="c1"># Find tool calls within the message</span>
            <span class="n">tool_calls</span> <span class="o">=</span> <span class="n">tool_call_pattern</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">tool_calls</span><span class="p">:</span>
                <span class="n">tool_calls_list</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">tool_call</span> <span class="ow">in</span> <span class="n">tool_calls</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">tool_call_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">tool_call</span><span class="p">)</span>
                        <span class="n">tool_calls_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tool_call_dict</span><span class="p">)</span>
                    <span class="k">except</span> <span class="n">json</span><span class="o">.</span><span class="n">JSONDecodeError</span><span class="p">:</span>
                        <span class="k">continue</span>
                <span class="k">if</span> <span class="n">tool_calls_list</span><span class="p">:</span>
                    <span class="n">message_dict</span><span class="p">[</span><span class="s2">&quot;tool_calls&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tool_calls_list</span>

            <span class="c1"># Check for tool responses</span>
            <span class="n">tool_responses</span> <span class="o">=</span> <span class="n">tool_response_pattern</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">tool_responses</span><span class="p">:</span>
                <span class="n">message_dict</span><span class="p">[</span><span class="s2">&quot;tool_responses&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tool_responses</span>

            <span class="n">parsed_messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">message_dict</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">parsed_messages</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Couldn&#39;t get a single item out of text </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">. A common cause &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;if that special tokens should not be ommitted, did you set include_stop_str_in_output/skip_special_tokens=False?&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">(</span><span class="n">parsed_messages</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_qwen</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">template</span><span class="p">):</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

        <span class="c1"># Define regex patterns for different parts of the template</span>
        <span class="n">message_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
            <span class="sa">r</span><span class="s2">&quot;&lt;\|im_start\|&gt;(.*?)(?:&lt;\|(im_end|endoftext)\|&gt;|$)&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span>
        <span class="p">)</span>
        <span class="n">tool_call_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;&lt;tool_call&gt;\n(.*?)\n&lt;/tool_call&gt;&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>
        <span class="n">tool_response_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
            <span class="sa">r</span><span class="s2">&quot;&lt;tool_response&gt;\n(.*?)\n&lt;/tool_response&gt;&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span>
        <span class="p">)</span>

        <span class="c1"># Find all messages and track if they end with a proper token</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">is_complete_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">message_pattern</span><span class="o">.</span><span class="n">finditer</span><span class="p">(</span><span class="n">template</span><span class="p">):</span>
            <span class="n">full_match</span> <span class="o">=</span> <span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="c1"># Check if the message ends with a proper token</span>
            <span class="n">is_complete_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">full_match</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;&lt;|im_end|&gt;&quot;</span><span class="p">)</span>
                <span class="ow">or</span> <span class="n">full_match</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="n">parsed_messages</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">message</span><span class="p">,</span> <span class="n">is_complete</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">is_complete_list</span><span class="p">):</span>
            <span class="c1"># Split the message into role and content</span>
            <span class="n">parts</span> <span class="o">=</span> <span class="n">message</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">role</span><span class="p">,</span> <span class="n">content</span> <span class="o">=</span> <span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">parts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

            <span class="c1"># Initialize message dict</span>
            <span class="n">message_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">role</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span>
                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span>
                <span class="s2">&quot;is_complete&quot;</span><span class="p">:</span> <span class="n">is_complete</span><span class="p">,</span>
                <span class="s2">&quot;tool_calls&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;tool_responses&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="c1"># Find tool calls within the message</span>
            <span class="n">tool_calls</span> <span class="o">=</span> <span class="n">tool_call_pattern</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">tool_calls</span><span class="p">:</span>
                <span class="n">tool_calls_list</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">tool_call</span> <span class="ow">in</span> <span class="n">tool_calls</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">tool_call_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">tool_call</span><span class="p">)</span>
                        <span class="n">tool_calls_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tool_call_dict</span><span class="p">)</span>
                    <span class="k">except</span> <span class="n">json</span><span class="o">.</span><span class="n">JSONDecodeError</span><span class="p">:</span>
                        <span class="k">continue</span>
                <span class="k">if</span> <span class="n">tool_calls_list</span><span class="p">:</span>
                    <span class="n">message_dict</span><span class="p">[</span><span class="s2">&quot;tool_calls&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tool_calls_list</span>

            <span class="c1"># Check for tool responses</span>
            <span class="n">tool_responses</span> <span class="o">=</span> <span class="n">tool_response_pattern</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">tool_responses</span><span class="p">:</span>
                <span class="n">message_dict</span><span class="p">[</span><span class="s2">&quot;tool_responses&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tool_responses</span>

            <span class="n">parsed_messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">message_dict</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">parsed_messages</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Couldn&#39;t get a single item out of text </span><span class="si">{</span><span class="n">template</span><span class="si">}</span><span class="s2">. A common cause &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;if that special tokens should not be ommitted, did you set include_stop_str_in_output/skip_special_tokens=False?&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">(</span><span class="n">parsed_messages</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_dialogpt</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">History</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Inverts a DialogPT string into a History object.</span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): The DialogPT string to invert.</span>

<span class="sd">        Returns:</span>
<span class="sd">            History: The inverted History object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inverting DialogPT:</span><span class="se">\n</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># DialogPT format is simple: alternating user/assistant messages</span>
        <span class="c1"># Split by lines and parse</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">parsed_messages</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
            <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">line</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="c1"># Determine role based on content</span>
            <span class="k">if</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;Assistant:&quot;</span><span class="p">):</span>
                <span class="n">role</span> <span class="o">=</span> <span class="s2">&quot;assistant&quot;</span>
                <span class="n">content</span> <span class="o">=</span> <span class="n">line</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Assistant:&quot;</span><span class="p">)</span> <span class="p">:]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">elif</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;User:&quot;</span><span class="p">):</span>
                <span class="n">role</span> <span class="o">=</span> <span class="s2">&quot;user&quot;</span>
                <span class="n">content</span> <span class="o">=</span> <span class="n">line</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;User:&quot;</span><span class="p">)</span> <span class="p">:]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Default to user if no prefix</span>
                <span class="n">role</span> <span class="o">=</span> <span class="s2">&quot;user&quot;</span>
                <span class="n">content</span> <span class="o">=</span> <span class="n">line</span>

            <span class="n">message_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">role</span><span class="p">,</span>
                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">content</span><span class="p">,</span>
                <span class="s2">&quot;is_complete&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>  <span class="c1"># DialogPT doesn&#39;t have explicit end tokens</span>
                <span class="s2">&quot;tool_calls&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;tool_responses&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="n">parsed_messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">message_dict</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">parsed_messages</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Couldn&#39;t get a single item out of text </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">(</span><span class="n">parsed_messages</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_falcon</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">History</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Inverts a Falcon string into a History object.</span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): The Falcon string to invert.</span>

<span class="sd">        Returns:</span>
<span class="sd">            History: The inverted History object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inverting Falcon:</span><span class="se">\n</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Falcon format: &quot;User: ... Assistant: ...&quot;</span>
        <span class="c1"># Split by &quot;User:&quot; and &quot;Assistant:&quot; prefixes</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">re</span>

        <span class="c1"># Pattern to match User: and Assistant: messages</span>
        <span class="n">pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;(User:|Assistant:)\s*(.*?)(?=(User:|Assistant:)|$)&quot;</span>
        <span class="n">matches</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>

        <span class="n">parsed_messages</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">match</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">prefix</span><span class="p">,</span> <span class="n">content</span> <span class="o">=</span> <span class="n">match</span>
            <span class="n">content</span> <span class="o">=</span> <span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">content</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="n">prefix</span> <span class="o">==</span> <span class="s2">&quot;User:&quot;</span><span class="p">:</span>
                <span class="n">role</span> <span class="o">=</span> <span class="s2">&quot;user&quot;</span>
            <span class="k">elif</span> <span class="n">prefix</span> <span class="o">==</span> <span class="s2">&quot;Assistant:&quot;</span><span class="p">:</span>
                <span class="n">role</span> <span class="o">=</span> <span class="s2">&quot;assistant&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">message_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">role</span><span class="p">,</span>
                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">content</span><span class="p">,</span>
                <span class="s2">&quot;is_complete&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>  <span class="c1"># Falcon doesn&#39;t have explicit end tokens</span>
                <span class="s2">&quot;tool_calls&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;tool_responses&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="n">parsed_messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">message_dict</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">parsed_messages</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Couldn&#39;t get a single item out of text </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">(</span><span class="n">parsed_messages</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_deepseek</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">History</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Inverts a DeepSeek string into a History object.</span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): The DeepSeek string to invert.</span>

<span class="sd">        Returns:</span>
<span class="sd">            History: The inverted History object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inverting DeepSeek:</span><span class="se">\n</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">re</span>

        <span class="c1"># Remove leading/trailing special tokens (e.g.</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;^&lt;[^&gt;]+&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>  <span class="c1"># Remove leading &lt;...&gt;</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;&lt;[^&gt;]+&gt;$&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>  <span class="c1"># Remove trailing &lt;...&gt;</span>
        <span class="c1"># Remove any REDACTED_SPECIAL_TOKEN if present</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;REDACTED_SPECIAL_TOKEN&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
        <span class="c1"># Pattern to match User: and Assistant: messages</span>
        <span class="n">pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;(User:|Assistant:)\s*(.*?)(?=(User:|Assistant:)|$)&quot;</span>
        <span class="n">matches</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>
        <span class="n">parsed_messages</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">match</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">prefix</span><span class="p">,</span> <span class="n">content</span> <span class="o">=</span> <span class="n">match</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">match</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">content</span> <span class="o">=</span> <span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">content</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="n">prefix</span> <span class="o">==</span> <span class="s2">&quot;User:&quot;</span><span class="p">:</span>
                <span class="n">role</span> <span class="o">=</span> <span class="s2">&quot;user&quot;</span>
            <span class="k">elif</span> <span class="n">prefix</span> <span class="o">==</span> <span class="s2">&quot;Assistant:&quot;</span><span class="p">:</span>
                <span class="n">role</span> <span class="o">=</span> <span class="s2">&quot;assistant&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">message_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">role</span><span class="p">,</span>
                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">content</span><span class="p">,</span>
                <span class="s2">&quot;is_complete&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>  <span class="c1"># DeepSeek doesn&#39;t have explicit end tokens</span>
                <span class="s2">&quot;tool_calls&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;tool_responses&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="n">parsed_messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">message_dict</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">parsed_messages</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Couldn&#39;t get a single item out of text </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">(</span><span class="n">parsed_messages</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_llama</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">History</span><span class="p">:</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">re</span>

        <span class="n">messages</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Remove BOS token if present</span>
        <span class="k">if</span> <span class="n">text</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;&lt;|begin_of_text|&gt;&quot;</span><span class="p">):</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;&lt;|begin_of_text|&gt;&quot;</span><span class="p">)</span> <span class="p">:]</span>

        <span class="c1"># Pattern to match complete message blocks: &lt;|header_start|&gt;role&lt;|header_end|&gt;\n\ncontent&lt;|eot|&gt;</span>
        <span class="n">complete_pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;&lt;\|header_start\|&gt;(\w+)&lt;\|header_end\|&gt;\n\n(.*?)&lt;\|eot\|&gt;&quot;</span>
        <span class="n">complete_matches</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">complete_pattern</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>

        <span class="c1"># Pattern to match incomplete message blocks: &lt;|header_start|&gt;role&lt;|header_end|&gt;\n\ncontent (without &lt;|eot|&gt;)</span>
        <span class="n">incomplete_pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;&lt;\|header_start\|&gt;(\w+)&lt;\|header_end\|&gt;\n\n(.*?)$&quot;</span>

        <span class="c1"># Find any incomplete message at the end</span>
        <span class="n">incomplete_matches</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">complete_matches</span><span class="p">:</span>
            <span class="c1"># Look for incomplete message after the last complete one</span>
            <span class="n">last_complete_end</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">rfind</span><span class="p">(</span><span class="s2">&quot;&lt;|eot|&gt;&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">last_complete_end</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="n">remaining_text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="n">last_complete_end</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;&lt;|eot|&gt;&quot;</span><span class="p">)</span> <span class="p">:]</span>
                <span class="k">if</span> <span class="n">remaining_text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                    <span class="n">incomplete_match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span>
                        <span class="n">incomplete_pattern</span><span class="p">,</span> <span class="n">remaining_text</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="n">incomplete_match</span><span class="p">:</span>
                        <span class="n">incomplete_matches</span> <span class="o">=</span> <span class="p">[</span>
                            <span class="p">(</span>
                                <span class="n">incomplete_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
                                <span class="n">incomplete_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
                                <span class="kc">False</span><span class="p">,</span>
                            <span class="p">)</span>
                        <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># No complete messages, check entire text for incomplete message</span>
            <span class="n">incomplete_match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">incomplete_pattern</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">incomplete_match</span><span class="p">:</span>
                <span class="n">incomplete_matches</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="p">(</span><span class="n">incomplete_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">incomplete_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="kc">False</span><span class="p">)</span>
                <span class="p">]</span>

        <span class="c1"># Process complete messages</span>
        <span class="k">for</span> <span class="n">role</span><span class="p">,</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">complete_matches</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="bp">cls</span><span class="p">(</span><span class="n">role</span><span class="o">=</span><span class="n">role</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span> <span class="n">is_complete</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="p">)</span>

        <span class="c1"># Process incomplete messages</span>
        <span class="k">for</span> <span class="n">role</span><span class="p">,</span> <span class="n">content</span><span class="p">,</span> <span class="n">is_complete</span> <span class="ow">in</span> <span class="n">incomplete_matches</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="bp">cls</span><span class="p">(</span><span class="n">role</span><span class="o">=</span><span class="n">role</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span> <span class="n">is_complete</span><span class="o">=</span><span class="n">is_complete</span><span class="p">)</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">messages</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Couldn&#39;t parse Llama format from text: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">tensordict</span><span class="w"> </span><span class="kn">import</span> <span class="n">lazy_stack</span>

        <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>

<div class="viewcode-block" id="History.append"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.llm.History.html#torchrl.data.llm.History.append">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">append</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">history</span><span class="p">:</span> <span class="n">History</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">History</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Appends a new history to the current one.</span>

<span class="sd">        Args:</span>
<span class="sd">            history (History): The new history to append.</span>
<span class="sd">            inplace (bool, optional): Whether to perform the operation in-place. Defaults to `True`.</span>
<span class="sd">            dim (int, optional): The dimension to append along. Defaults to -1.</span>

<span class="sd">        Returns:</span>
<span class="sd">            History: The appended History object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: we should remove the &lt;none&gt; role from the history before appending / extending</span>
        <span class="c1">#  It works when keeping them, but it may lead to a lot of useless padding in between valid messages</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot append an element to a batchless History. Call unsqueeze(dim=0) first on self.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">!=</span> <span class="n">history</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The new history to append must have one less dimension than self. Got self.ndim=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2"> and history.ndim=</span><span class="si">{</span><span class="n">history</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="n">_maybe_correct_neg_dim</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">)</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">stack_dim</span> <span class="o">==</span> <span class="n">dim</span>
            <span class="p">):</span>
                <span class="n">td</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">_tensordict</span>
                <span class="k">if</span> <span class="n">td</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
                <span class="k">return</span> <span class="bp">self</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">td</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">_tensordict</span>
                <span class="k">if</span> <span class="n">td</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">td</span> <span class="o">=</span> <span class="n">lazy_stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="n">td</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_tensordict&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">td</span>
                <span class="k">return</span> <span class="bp">self</span>
        <span class="k">if</span> <span class="n">history</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">history</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">history</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="n">history</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">extend</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">history</span><span class="p">:</span> <span class="n">History</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">History</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot add an element to a batchless History. Call unsqueeze(dim=0) first on self.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">!=</span> <span class="n">history</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The new history to extend must have as many dimensions as self. Got self.ndim=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2"> and history.ndim=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="n">_maybe_correct_neg_dim</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="c1"># if self.ndim &gt; 1 and dim &gt;= self.ndim - 1:</span>
        <span class="c1">#     # then we need to append each element independently</span>
        <span class="c1">#     result = []</span>
        <span class="c1">#     for hist, new_hist in zip(self.unbind(0), history.unbind(0)):</span>
        <span class="c1">#         hist_c = hist.extend(new_hist, inplace=inplace, dim=dim - 1)</span>
        <span class="c1">#         result.append(hist_c)</span>
        <span class="c1">#     if inplace:</span>
        <span class="c1">#         return self</span>
        <span class="c1">#     return lazy_stack(result)</span>
        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">)</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">stack_dim</span> <span class="o">==</span> <span class="n">dim</span>
            <span class="p">):</span>
                <span class="n">td</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">_tensordict</span>
                <span class="k">if</span> <span class="n">td</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
                <span class="k">return</span> <span class="bp">self</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">td</span> <span class="o">=</span> <span class="n">lazy_stack</span><span class="p">(</span>
                    <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span>
                    <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">dim</span><span class="p">)),</span>
                    <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">td</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_tensordict&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">td</span>
                <span class="k">return</span> <span class="bp">self</span>
        <span class="k">if</span> <span class="n">history</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">history</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">history</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">dim</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>

<div class="viewcode-block" id="History.default_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.llm.History.html#torchrl.data.llm.History.default_spec">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">default_spec</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A default spec to use in transforms / envs that return History objects.</span>

<span class="sd">        Args:</span>
<span class="sd">            shape (torch.Size, optional): The shape of the returned History spec. Defaults to `(-1)` (variable length</span>
<span class="sd">                along the time dimension).</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; import tensordict</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.data import History</span>
<span class="sd">            &gt;&gt;&gt; tensordict.set_list_to_stack(True).set()</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; history = History(role=[&quot;system&quot;, &quot;user&quot;], content=[&quot;a message&quot;, &quot;another message&quot;], batch_size=(2,))</span>
<span class="sd">            &gt;&gt;&gt; spec = history.default_spec()</span>
<span class="sd">            &gt;&gt;&gt; print(spec)</span>
<span class="sd">            Composite(</span>
<span class="sd">                role: NonTensor(</span>
<span class="sd">                    shape=torch.Size([-1]),</span>
<span class="sd">                    space=None,</span>
<span class="sd">                    device=None,</span>
<span class="sd">                    dtype=None,</span>
<span class="sd">                    domain=None,</span>
<span class="sd">                    example_data=foo),</span>
<span class="sd">                content: NonTensor(</span>
<span class="sd">                    shape=torch.Size([-1]),</span>
<span class="sd">                    space=None,</span>
<span class="sd">                    device=None,</span>
<span class="sd">                    dtype=None,</span>
<span class="sd">                    domain=None,</span>
<span class="sd">                    example_data=foo),</span>
<span class="sd">                device=None,</span>
<span class="sd">                shape=torch.Size([-1]))</span>
<span class="sd">            &gt;&gt;&gt; print(spec.zero())</span>
<span class="sd">            History(</span>
<span class="sd">                content=NonTensorData(data=foo, batch_size=torch.Size([1]), device=None),</span>
<span class="sd">                role=NonTensorData(data=foo, batch_size=torch.Size([1]), device=None),</span>
<span class="sd">                batch_size=torch.Size([1]),</span>
<span class="sd">                device=None,</span>
<span class="sd">                is_shared=False)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Composite</span><span class="p">,</span> <span class="n">NonTensor</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">get_default_value</span><span class="p">(</span><span class="n">field</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">field</span><span class="o">.</span><span class="n">default</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">MISSING</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">field</span><span class="o">.</span><span class="n">default</span>
            <span class="k">elif</span> <span class="n">field</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;str&quot;</span><span class="p">):</span>
                <span class="k">return</span> <span class="s2">&quot;foo&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">None</span>

        <span class="n">defaults</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">k</span><span class="p">:</span> <span class="n">NonTensor</span><span class="p">(</span>
                <span class="n">example_data</span><span class="o">=</span><span class="n">get_default_value</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">__dataclass_fields__</span><span class="p">[</span><span class="n">k</span><span class="p">]),</span>
                <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">__dataclass_fields__</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">Composite</span><span class="p">(</span><span class="n">defaults</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">data_cls</span><span class="o">=</span><span class="bp">cls</span><span class="p">)</span></div>

<div class="viewcode-block" id="History.from_chats"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.llm.History.html#torchrl.data.llm.History.from_chats">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_chats</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">chats</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">History</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a History object from a list of chats.</span>

<span class="sd">        Args:</span>
<span class="sd">            chats (list[list[dict]]): A list of chats, where each chat is a list of dictionaries.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">chats</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">([</span><span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">chat</span><span class="p">)</span> <span class="k">for</span> <span class="n">chat</span> <span class="ow">in</span> <span class="n">chats</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">([</span><span class="bp">cls</span><span class="o">.</span><span class="n">from_chats</span><span class="p">(</span><span class="n">chat</span><span class="p">)</span> <span class="k">for</span> <span class="n">chat</span> <span class="ow">in</span> <span class="n">chats</span><span class="p">])</span></div></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="../../../../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrl = $("#tutorial-type").text();
	      var githubLink = "https://github.com/pytorch/rl/blob/main/tutorials/sphinx-"  + tutorialUrl + ".py",
		  notebookLink = $(".sphx-glr-download-jupyter").find(".download.reference")[0].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/rl/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }

          var overwrite = function(_) {
              if ($(this).length > 0) {
                  $(this)[0].href = "https://github.com/pytorch/rl"
              }
          }
          // PC
          $(".main-menu a:contains('GitHub')").each(overwrite);
          // Mobile
          $(".main-menu a:contains('Github')").each(overwrite);
      });

      
       $(window).ready(function() {
           var original = window.sideMenus.bind;
           var startup = true;
           window.sideMenus.bind = function() {
               original();
               if (startup) {
                   $("#pytorch-right-menu a.reference.internal").each(function(i) {
                       if (this.classList.contains("not-expanded")) {
                           this.nextElementSibling.style.display = "block";
                           this.classList.remove("not-expanded");
                           this.classList.add("expanded");
                       }
                   });
                   startup = false;
               }
           };
       });
    </script>

    


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch Documentation</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">Newsletter</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">Cloud Credit Program</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">Technical Advisory Council</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">Staff</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">Contact Us</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>
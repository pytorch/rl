


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchrl.data.llm.chat &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','UA-117752657-2');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="../../../../../versions.html"><span style="font-size:110%">main (0.9.0+77dbc6c) &#x25BC</span></a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-0.html">Get started with Environments, TED and transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-1.html">Get started with TorchRLâ€™s modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-2.html">Getting started with model optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-3.html">Get started with data collection and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-4.html">Get started with logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/getting-started-5.html">Get started with your own first training loop</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/coding_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/torchrl_demo.html">Introduction to TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/multiagent_ppo.html">Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/torchrl_envs.html">TorchRL envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/pretrained_models.html">Using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/dqn_with_rnn.html">Recurrent DQN: Training recurrent policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/rb_tutorial.html">Using Replay Buffers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/export.html">Exporting TorchRL modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/llm_browser.html">TorchRL LLM: Building Tool-Enabled Environments</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/multiagent_competitive_ddpg.html">Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/coding_ddpg.html">TorchRL objectives: Coding a DDPG loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/coding_dqn.html">TorchRL trainer: A DQN example</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../reference/index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../reference/knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
      <li>torchrl.data.llm.chat</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
    
    
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=UA-117752657-2"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torchrl.data.llm.chat</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">dataclasses</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Literal</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">lazy_stack</span><span class="p">,</span>
    <span class="n">LazyStackedTensorDict</span><span class="p">,</span>
    <span class="n">list_to_stack</span><span class="p">,</span>
    <span class="n">TensorClass</span><span class="p">,</span>
    <span class="n">TensorDict</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_maybe_correct_neg_dim</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl._utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span> <span class="k">as</span> <span class="n">torchrl_logger</span>


<span class="n">_CHAT_TEMPLATES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;chatml_format&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;{</span><span class="si">% f</span><span class="s2">or message in messages %}</span>
<span class="s2">    {</span><span class="si">%- i</span><span class="s2">f message[&#39;role&#39;] == &#39;assistant&#39; %}</span>
<span class="s2">    {</span><span class="si">% g</span><span class="s2">eneration %}{{&#39;&lt;|im_start|&gt;&#39; + message[&#39;role&#39;] + &#39;</span><span class="se">\n</span><span class="s2">&#39; + message[&#39;content&#39;] + &#39;&lt;|im_end|&gt;&#39; + &#39;</span><span class="se">\n</span><span class="s2">&#39;}}{</span><span class="si">% e</span><span class="s2">ndgeneration %}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">lse %}</span>
<span class="s2">    {{&#39;&lt;|im_start|&gt;&#39; + message[&#39;role&#39;] + &#39;</span><span class="se">\n</span><span class="s2">&#39; + message[&#39;content&#39;] + &#39;&lt;|im_end|&gt;&#39; + &#39;</span><span class="se">\n</span><span class="s2">&#39;}}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">{</span><span class="si">% e</span><span class="s2">ndfor %}</span>
<span class="s2">{</span><span class="si">%- i</span><span class="s2">f add_generation_prompt %}</span>
<span class="s2">    {</span><span class="si">% g</span><span class="s2">eneration %}{{- &#39;&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&#39; }}{</span><span class="si">% e</span><span class="s2">ndgeneration %}</span>
<span class="s2">{</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="s2">&quot;qwen&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">{</span><span class="si">%- i</span><span class="s2">f tools %}</span>
<span class="s2">    {{- &#39;&lt;|im_start|&gt;system</span><span class="se">\\</span><span class="s2">n&#39; }}</span>
<span class="s2">    {</span><span class="si">%- i</span><span class="s2">f messages[0][&#39;role&#39;] == &#39;system&#39; %}</span>
<span class="s2">        {{- messages[0][&#39;content&#39;] }}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">lse %}</span>
<span class="s2">        {{- &#39;You are Qwen, created by Alibaba Cloud. You are a helpful assistant.&#39; }}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">    {{- &quot;</span><span class="se">\\</span><span class="s2">n</span><span class="se">\\</span><span class="s2">n# Tools</span><span class="se">\\</span><span class="s2">n</span><span class="se">\\</span><span class="s2">nYou may call one or more functions to assist with the user query.</span><span class="se">\\</span><span class="s2">n</span><span class="se">\\</span><span class="s2">nYou are provided with function signatures within &lt;tools&gt;&lt;/tools&gt; XML tags:</span><span class="se">\\</span><span class="s2">n&lt;tools&gt;&quot; }}</span>
<span class="s2">    {</span><span class="si">%- f</span><span class="s2">or tool in tools %}</span>
<span class="s2">        {{- &quot;</span><span class="se">\\</span><span class="s2">n&quot; }}</span>
<span class="s2">        {{- tool | tojson }}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">ndfor %}</span>
<span class="s2">    {{- &quot;</span><span class="se">\\</span><span class="s2">n&lt;/tools&gt;</span><span class="se">\\</span><span class="s2">n</span><span class="se">\\</span><span class="s2">nFor each function call, return a json object with function name and arguments within &lt;tool_call&gt;&lt;/tool_call&gt; XML tags:</span><span class="se">\\</span><span class="s2">n&lt;tool_call&gt;</span><span class="se">\\</span><span class="s2">n{</span><span class="se">\\\&quot;</span><span class="s2">name</span><span class="se">\\\&quot;</span><span class="s2">: &lt;function-name&gt;, </span><span class="se">\\\&quot;</span><span class="s2">arguments</span><span class="se">\\\&quot;</span><span class="s2">: &lt;args-json-object&gt;}</span><span class="se">\\</span><span class="s2">n&lt;/tool_call&gt;&lt;|im_end|&gt;</span><span class="se">\\</span><span class="s2">n&quot; }}</span>
<span class="s2">{</span><span class="si">%- e</span><span class="s2">lse %}</span>
<span class="s2">    {</span><span class="si">%- i</span><span class="s2">f messages[0][&#39;role&#39;] == &#39;system&#39; %}</span>
<span class="s2">        {{- &#39;&lt;|im_start|&gt;system</span><span class="se">\\</span><span class="s2">n&#39; + messages[0][&#39;content&#39;] + &#39;&lt;|im_end|&gt;</span><span class="se">\\</span><span class="s2">n&#39; }}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">lse %}</span>
<span class="s2">        {{- &#39;&lt;|im_start|&gt;system</span><span class="se">\\</span><span class="s2">nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.&lt;|im_end|&gt;</span><span class="se">\\</span><span class="s2">n&#39; }}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">{</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">{</span><span class="si">%- f</span><span class="s2">or message in messages %}</span>
<span class="s2">    {</span><span class="si">%- i</span><span class="s2">f (message.role == &quot;user&quot;) or (message.role == &quot;system&quot; and not loop.first) %}</span>
<span class="s2">        {{- &#39;&lt;|im_start|&gt;&#39; + message.role + &#39;</span><span class="se">\\</span><span class="s2">n&#39; + message.content + &#39;&lt;|im_end|&gt;&#39; + &#39;</span><span class="se">\\</span><span class="s2">n&#39; }}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">lif (message.role == &quot;assistant&quot; and not message.tool_calls) %}</span>
<span class="s2">    {</span><span class="si">% g</span><span class="s2">eneration %}    {{- &#39;&lt;|im_start|&gt;&#39; + message.role + &#39;</span><span class="se">\\</span><span class="s2">n&#39; + message.content + &#39;&lt;|im_end|&gt;&#39; + &#39;</span><span class="se">\\</span><span class="s2">n&#39; }}    {</span><span class="si">% e</span><span class="s2">ndgeneration %}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">lif message.role == &quot;assistant&quot; %}</span>
<span class="s2">        {</span><span class="si">% g</span><span class="s2">eneration %}{{- &#39;&lt;|im_start|&gt;&#39; + message.role }}</span>
<span class="s2">        {</span><span class="si">%- i</span><span class="s2">f message.content %}</span>
<span class="s2">            {{- &#39;</span><span class="se">\\</span><span class="s2">n&#39; + message.content }}</span>
<span class="s2">        {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">        {</span><span class="si">%- f</span><span class="s2">or tool_call in message.tool_calls %}</span>
<span class="s2">            {</span><span class="si">%- i</span><span class="s2">f tool_call.function is defined %}</span>
<span class="s2">                {</span><span class="si">%- s</span><span class="s2">et tool_call = tool_call.function %}</span>
<span class="s2">            {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">            {{- &#39;</span><span class="se">\\</span><span class="s2">n&lt;tool_call&gt;</span><span class="se">\\</span><span class="s2">n{</span><span class="se">\\\&quot;</span><span class="s2">name</span><span class="se">\\\&quot;</span><span class="s2">: </span><span class="se">\\\&quot;</span><span class="s2">&#39; }}</span>
<span class="s2">            {{- tool_call.name }}</span>
<span class="s2">            {{- &#39;</span><span class="se">\\\&quot;</span><span class="s2">, </span><span class="se">\\\&quot;</span><span class="s2">arguments</span><span class="se">\\\&quot;</span><span class="s2">: &#39; }}</span>
<span class="s2">            {{- tool_call.arguments | tojson }}</span>
<span class="s2">            {{- &#39;}</span><span class="se">\\</span><span class="s2">n&lt;/tool_call&gt;&#39; }}</span>
<span class="s2">        {</span><span class="si">%- e</span><span class="s2">ndfor %}</span>
<span class="s2">        {{- &#39;&lt;|im_end|&gt;</span><span class="se">\\</span><span class="s2">n&#39; }}{</span><span class="si">% e</span><span class="s2">ndgeneration %}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">lif message.role == &quot;tool&quot; %}</span>
<span class="s2">        {</span><span class="si">%- i</span><span class="s2">f (loop.index0 == 0) or (messages[loop.index0 - 1].role != &quot;tool&quot;) %}</span>
<span class="s2">            {{- &#39;&lt;|im_start|&gt;user&#39; }}</span>
<span class="s2">        {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">        {{- &#39;</span><span class="se">\\</span><span class="s2">n&lt;tool_response&gt;</span><span class="se">\\</span><span class="s2">n&#39; }}</span>
<span class="s2">        {{- message.content }}</span>
<span class="s2">        {{- &#39;</span><span class="se">\\</span><span class="s2">n&lt;/tool_response&gt;&#39; }}</span>
<span class="s2">        {</span><span class="si">%- i</span><span class="s2">f loop.last or (messages[loop.index0 + 1].role != &quot;tool&quot;) %}</span>
<span class="s2">            {{- &#39;&lt;|im_end|&gt;</span><span class="se">\\</span><span class="s2">n&#39; }}</span>
<span class="s2">        {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">    {</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">{</span><span class="si">%- e</span><span class="s2">ndfor %}</span>
<span class="s2">{</span><span class="si">%- i</span><span class="s2">f add_generation_prompt %}</span>
<span class="s2">    {</span><span class="si">% g</span><span class="s2">eneration %}{{- &#39;&lt;|im_start|&gt;assistant</span><span class="se">\\</span><span class="s2">n&#39; }}{</span><span class="si">% e</span><span class="s2">ndgeneration %}</span>
<span class="s2">{</span><span class="si">%- e</span><span class="s2">ndif %}</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">,</span>
<span class="p">}</span>


<span class="c1"># We need the &#39;shadow&#39; flag to avoid having tensordict complaining about &#39;type&#39;/&#39;size&#39; etc. fields</span>
<div class="viewcode-block" id="ContentBase"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.llm.ContentBase.html#torchrl.data.llm.ContentBase">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">ContentBase</span><span class="p">(</span><span class="n">TensorClass</span><span class="p">[</span><span class="s2">&quot;nocast&quot;</span><span class="p">,</span> <span class="s2">&quot;shadow&quot;</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for all message content types.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        type (str): The type of the content.</span>
<span class="sd">        text (str, optional): The text content.</span>
<span class="sd">        url (str, optional): The URL content.</span>
<span class="sd">        data (str, optional): The data content.</span>
<span class="sd">        mime_type (str, optional): The MIME type of the content.</span>
<span class="sd">        name (str, optional): The name of the content.</span>
<span class="sd">        size (int, optional): The size of the content.</span>
<span class="sd">        function_name (str, optional): The name of the function.</span>
<span class="sd">        function_args (dict, optional): The arguments of the function.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from tensordict import lazy_stack</span>
<span class="sd">        &gt;&gt;&gt; content1 = ContentBase(type=&quot;text&quot;, text=&quot;Hello, world!&quot;)</span>
<span class="sd">        &gt;&gt;&gt; print(content1)</span>
<span class="sd">        ContentBase(</span>
<span class="sd">            text=NonTensorData(data=Hello, world!, batch_size=torch.Size([]), device=None),</span>
<span class="sd">            type=NonTensorData(data=text, batch_size=torch.Size([]), device=None),</span>
<span class="sd">            url=None,</span>
<span class="sd">            data=None,</span>
<span class="sd">            mime_type=None,</span>
<span class="sd">            name=None,</span>
<span class="sd">            size=None,</span>
<span class="sd">            function_name=None,</span>
<span class="sd">            function_args=None,</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; content2 = ContentBase(type=&quot;image&quot;, url=&quot;https://example.com/image.jpg&quot;)</span>
<span class="sd">        &gt;&gt;&gt; print(content2)</span>
<span class="sd">        ContentBase(</span>
<span class="sd">            type=NonTensorData(data=image, batch_size=torch.Size([]), device=None),</span>
<span class="sd">            url=NonTensorData(data=https://example.com/image.jpg, batch_size=torch.Size([]), device=None),</span>
<span class="sd">            text=None,</span>
<span class="sd">            data=None,</span>
<span class="sd">            mime_type=None,</span>
<span class="sd">            name=None,</span>
<span class="sd">            size=None,</span>
<span class="sd">            function_name=None,</span>
<span class="sd">            function_args=None,</span>
<span class="sd">            batch_size=torch.Size([]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; content = lazy_stack([content1, content2])</span>
<span class="sd">        &gt;&gt;&gt; print(content)</span>
<span class="sd">        ContentBase(</span>
<span class="sd">            type=NonTensorStack(</span>
<span class="sd">                [&#39;text&#39;, &#39;image&#39;],</span>
<span class="sd">                batch_size=torch.Size([2]),</span>
<span class="sd">                device=None),</span>
<span class="sd">            url=None,</span>
<span class="sd">            data=None,</span>
<span class="sd">            mime_type=None,</span>
<span class="sd">            name=None,</span>
<span class="sd">            size=None,</span>
<span class="sd">            function_name=None,</span>
<span class="sd">            function_args=None,</span>
<span class="sd">            text=None,</span>
<span class="sd">            batch_size=torch.Size([2]),</span>
<span class="sd">            device=None,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; # A content is typically used in a History object. Usually, its batch dimension is</span>
<span class="sd">        &gt;&gt;&gt; #  one dimension greater than the History object.</span>
<span class="sd">        &gt;&gt;&gt; history = History(role=&quot;user&quot;, content=content)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">type</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span>
        <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="s2">&quot;video&quot;</span><span class="p">,</span> <span class="s2">&quot;file&quot;</span><span class="p">,</span> <span class="s2">&quot;function_call&quot;</span>
    <span class="p">]</span>  <span class="c1"># Required: &quot;text&quot;, &quot;image&quot;, &quot;audio&quot;, &quot;video&quot;, &quot;file&quot;, &quot;function_call&quot;</span>

    <span class="c1"># Text content</span>
    <span class="n">text</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Media/file content (either URL or data)</span>
    <span class="n">url</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># HTTP URL to content</span>
    <span class="n">data</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Base64 encoded content</span>

    <span class="c1"># Metadata</span>
    <span class="n">mime_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># &quot;image/jpeg&quot;, &quot;audio/mp3&quot;, &quot;application/pdf&quot;</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Original filename or description</span>
    <span class="n">size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># File size in bytes</span>

    <span class="c1"># Function calling (for AI agents)</span>
    <span class="n">function_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">function_args</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="History"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.llm.History.html#torchrl.data.llm.History">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">History</span><span class="p">(</span><span class="n">TensorClass</span><span class="p">[</span><span class="s2">&quot;nocast&quot;</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A class representing a structured history of messages in a conversation, designed for efficient manipulation and integration with language models.</span>

<span class="sd">    The `History` class provides a centralized API for managing conversational data, offering several advantages over</span>
<span class="sd">    traditional list-based approaches:</span>

<span class="sd">    - Centralized API for conversion to and from string formats, facilitating seamless integration with language models.</span>
<span class="sd">    - Efficient methods to append, extend, and reshape history elements, enabling dynamic construction of conversation</span>
<span class="sd">      trajectories, especially useful in reinforcement learning environments.</span>
<span class="sd">    - Interoperability with the `transformers` API, allowing for easy tokenization and preparation of input data.</span>

<span class="sd">    .. note:: The `&quot;&lt;none&gt;&quot;` role is used to indicate that the element is a placeholder,</span>
<span class="sd">        for example when the tool call was not executed but a stack requires a certain number of elements</span>
<span class="sd">        per batch to have congruent shapes. The :meth:`~torchrl.data.llm.chat.History.apply_chat_template`</span>
<span class="sd">        method will remove the `&lt;none&gt;` role from the history.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        role (str): The role of the message sender.</span>
<span class="sd">        content (str): The content of the message.</span>
<span class="sd">        is_complete (bool): Whether the message was properly terminated with an end token. Defaults to `True`.</span>
<span class="sd">        tool_calls (list[dict] | None): Optional list of tool calls in the message.</span>
<span class="sd">        tool_responses (list[str] | None): Optional list of tool responses.</span>

<span class="sd">    Methods:</span>
<span class="sd">        apply_chat_template: converts the `History` object to str / tokens.</span>
<span class="sd">        append: append one element to the list of items along a given dimension.</span>
<span class="sd">        extend: extend the list of items along a given dimension.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; # With tensordict &lt; 0.10, we need to tell the lib that lists constitute batches</span>
<span class="sd">        &gt;&gt;&gt; import tensordict</span>
<span class="sd">        &gt;&gt;&gt; tensordict.set_list_to_stack(True).set()</span>
<span class="sd">        &gt;&gt;&gt; import transformers</span>
<span class="sd">        &gt;&gt;&gt; history0 = History(</span>
<span class="sd">        ...     role=&#39;system&#39;,</span>
<span class="sd">        ...     content=&#39;&#39;&#39;CONTENT</span>
<span class="sd">        ... This is the setup&#39;&#39;&#39;,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; history1 = History(</span>
<span class="sd">        ...     role=&#39;user&#39;,</span>
<span class="sd">        ...     content=&#39;&#39;&#39;CONTENT</span>
<span class="sd">        ... This is the first user prompt&#39;&#39;&#39;,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; history2 = History(</span>
<span class="sd">        ...     role=&#39;assistant&#39;,</span>
<span class="sd">        ...     content=&#39;&#39;&#39;CONTENT</span>
<span class="sd">        ... This is the second prompt, the first for the assistant.&#39;&#39;&#39;,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; history = torch.stack([history0, history1, history2])</span>
<span class="sd">        &gt;&gt;&gt; assert history.role == [&#39;system&#39;, &#39;user&#39;, &#39;assistant&#39;]</span>
<span class="sd">        &gt;&gt;&gt; tokenizer = transformers.AutoTokenizer.from_pretrained(&quot;GPT2&quot;)</span>
<span class="sd">        &gt;&gt;&gt; # Apply a template to pass the history to an LLM. Note that the output has</span>
<span class="sd">        &gt;&gt;&gt; #  an additional prompt to elict an answer from the LLM thanks to the &#39;add_generation_prompt&#39; argument.</span>
<span class="sd">        &gt;&gt;&gt; parsed_string = history.apply_chat_template(tokenizer=tokenizer, add_generation_prompt=True)</span>
<span class="sd">        &gt;&gt;&gt; parsed_string</span>
<span class="sd">            &lt;|im_start|&gt;system</span>
<span class="sd">        CONTENT</span>
<span class="sd">        This is the setup&lt;|im_end|&gt;</span>

<span class="sd">            &lt;|im_start|&gt;user</span>
<span class="sd">        CONTENT</span>
<span class="sd">        This is the first user prompt&lt;|im_end|&gt;</span>

<span class="sd">            &lt;|im_start|&gt;assistant</span>
<span class="sd">        CONTENT</span>
<span class="sd">        This is the second prompt, the first for the assistant.&lt;|im_end|&gt;</span>

<span class="sd">        &lt;|im_start|&gt;assistant</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">role</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">content</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">ContentBase</span>
    <span class="n">is_complete</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">tool_calls</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">tool_responses</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">list_to_stack</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Please set the list_to_stack to True using tensordict.set_list_to_stack(True).set() at the beginning of your script, &quot;</span>
                <span class="s2">&quot;or the LIST_TO_STACK=1 environment variable.&quot;</span>
            <span class="p">)</span>

<div class="viewcode-block" id="History.apply_chat_template"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.llm.History.html#torchrl.data.llm.History.apply_chat_template">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">apply_chat_template</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoTokenizer</span> <span class="o">|</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoProcessor</span><span class="p">,</span>  <span class="c1"># noqa</span>
        <span class="n">add_generation_prompt</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">chat_template</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">chat_template_name</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;chatml_format&quot;</span><span class="p">,</span> <span class="s2">&quot;qwen&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">continue_final_message</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">tokenize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">padding</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">truncation</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_assistant_tokens_mask</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Applies a chat template to the history.</span>

<span class="sd">        Keyword Args:</span>
<span class="sd">            tokenizer (transformers.PreTrainedTokenizer | transformers.AutoProcessor): The tokenizer to use.</span>
<span class="sd">            add_generation_prompt (bool, optional): Whether to add a generation prompt (e.g. `&quot;&lt;|im_start|&gt;assistant&quot;`). Defaults to `True`.</span>
<span class="sd">            chat_template (str, optional): The chat template to use. Defaults to the tokenizer&#39;s default template.</span>
<span class="sd">            chat_template_name (Literal[&quot;chatml_format&quot;, &quot;qwen&quot;], optional): The name of the chat template to use.</span>
<span class="sd">                Prevalent over `tokenizer.chat_template`. Defaults to `None`.</span>
<span class="sd">            continue_final_message (bool, optional): Whether to continue the final message. Defaults to `False`.</span>
<span class="sd">            tokenize (bool, optional): Whether to tokenize the output. Defaults to `False`.</span>
<span class="sd">            padding (bool | str, optional): The padding strategy to use. Defaults to `False`.</span>
<span class="sd">            truncation (bool | str, optional): The truncation strategy to use. Defaults to `False`.</span>
<span class="sd">            return_tensors (str | None, optional): The type of tensors to return. Defaults to &quot;pt&quot;.</span>
<span class="sd">            return_dict (bool, optional): Whether to return a dictionary. Defaults to `False`.</span>
<span class="sd">            return_assistant_tokens_mask (bool, optional): Whether to return a mask of the assistant generated tokens.</span>
<span class="sd">                If `True`, the mask will be written to the `assistant_masks` key.</span>
<span class="sd">                For tokens generated by the assistant, the mask will contain `1`.</span>
<span class="sd">                For user and system tokens, the mask will contain `0`.</span>
<span class="sd">                This functionality is only available for chat templates that support it via the `{% generation %}` keyword.</span>
<span class="sd">                Defaults to `False`.</span>

<span class="sd">                .. note:: By default, the `&quot;qwen&quot;` chat template does not support this functionality. A modified version of the template</span>
<span class="sd">                    can be used by setting `chat_template_name=&quot;qwen&quot;`, which will override the default template from the tokenizer.</span>
<span class="sd">                    For other tokenizers, similar edits can be made to the template and passed to the method via the `chat_template` argument.</span>

<span class="sd">            **kwargs: Additional keyword arguments to pass to the tokenizer `apply_chat_template` method.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The formatted history.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">chat_template</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">chat_template_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">chat_template</span> <span class="o">=</span> <span class="n">_CHAT_TEMPLATES</span><span class="p">[</span><span class="n">chat_template_name</span><span class="p">]</span>
                <span class="n">chat_template_name</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">elif</span> <span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;You must specify a tokenizer to use when chat_template is not specified.&quot;</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="s2">&quot;qwen&quot;</span> <span class="ow">in</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;name_or_path&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                <span class="c1"># We prefer our implementation of the Qwen template,</span>
                <span class="c1">#  since it accounts for the assistant&#39;s masking.</span>
                <span class="n">chat_template</span> <span class="o">=</span> <span class="n">_CHAT_TEMPLATES</span><span class="p">[</span><span class="s2">&quot;qwen&quot;</span><span class="p">]</span>
                <span class="n">chat_template_name</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">chat_template</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">chat_template</span>
        <span class="k">if</span> <span class="n">chat_template</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">chat_template</span> <span class="o">=</span> <span class="n">_CHAT_TEMPLATES</span><span class="p">[</span><span class="s2">&quot;chatml_format&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">tokenize</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">return_assistant_tokens_mask</span> <span class="ow">or</span> <span class="n">return_tensors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">tokenize</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tokenize</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">tokenize</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">return_tensors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">return_tensors</span> <span class="o">=</span> <span class="s2">&quot;pt&quot;</span>
            <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">return_assistant_tokens_mask</span><span class="p">:</span>
                <span class="n">return_dict</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">return_dict</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="p">[</span>
                <span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
                    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
                    <span class="n">add_generation_prompt</span><span class="o">=</span><span class="n">add_generation_prompt</span><span class="p">,</span>
                    <span class="n">chat_template</span><span class="o">=</span><span class="n">chat_template</span><span class="p">,</span>
                    <span class="n">chat_template_name</span><span class="o">=</span><span class="n">chat_template_name</span><span class="p">,</span>
                    <span class="n">tokenize</span><span class="o">=</span><span class="n">tokenize</span><span class="p">,</span>
                    <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                    <span class="n">truncation</span><span class="o">=</span><span class="n">truncation</span><span class="p">,</span>
                    <span class="n">return_tensors</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">,</span>
                    <span class="n">continue_final_message</span><span class="o">=</span><span class="n">continue_final_message</span><span class="p">,</span>
                    <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
                    <span class="n">return_assistant_tokens_mask</span><span class="o">=</span><span class="n">return_assistant_tokens_mask</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="p">]</span>
            <span class="k">if</span> <span class="n">return_dict</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">result</span>
        <span class="n">self_flat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># tolist_first=True is needed to avoid having a list of dict of dicts, but a list of dicts of lists of dicts</span>
        <span class="n">self_flat</span> <span class="o">=</span> <span class="n">self_flat</span><span class="o">.</span><span class="n">tolist</span><span class="p">(</span><span class="n">tolist_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Remove the &quot;&lt;none&gt;&quot; role</span>
        <span class="n">self_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">self_flat</span> <span class="k">if</span> <span class="n">item</span><span class="p">[</span><span class="s2">&quot;role&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;&lt;none&gt;&quot;</span><span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
            <span class="n">conversation</span><span class="o">=</span><span class="n">self_flat</span><span class="p">,</span>
            <span class="n">add_generation_prompt</span><span class="o">=</span><span class="n">add_generation_prompt</span><span class="p">,</span>
            <span class="n">chat_template</span><span class="o">=</span><span class="n">chat_template</span><span class="p">,</span>
            <span class="n">tokenize</span><span class="o">=</span><span class="n">tokenize</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="n">truncation</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">,</span>
            <span class="n">continue_final_message</span><span class="o">=</span><span class="n">continue_final_message</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
            <span class="n">return_assistant_tokens_mask</span><span class="o">=</span><span class="n">return_assistant_tokens_mask</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="nb">str</span><span class="p">)):</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">auto_batch_size</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_dims</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># If self has a batch_dims of 1, we have just the time dimension, so we need to remove the batch dim from the result</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Expected a batch size of 1, got </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span></div>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_text</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">chat_template_name</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;chatml_format&quot;</span><span class="p">,</span> <span class="s2">&quot;qwen&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">chat_template</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoTokenizer</span>  <span class="c1"># noqa: F821</span>
        <span class="o">|</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoProcessor</span>  <span class="c1"># noqa: F821</span>
        <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">History</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">chat_template_name</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">chat_template</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;qwen&quot;</span> <span class="ow">in</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;name_or_path&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                <span class="c1"># We can automatically detect the template name from the tokenizer</span>
                <span class="c1">#  and use the precoded parser.</span>
                <span class="n">chat_template_name</span> <span class="o">=</span> <span class="s2">&quot;qwen&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">chat_template_name</span> <span class="o">=</span> <span class="s2">&quot;chatml_format&quot;</span>
        <span class="k">elif</span> <span class="n">chat_template_name</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;chatml_format&quot;</span><span class="p">,):</span>
            <span class="n">func</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_inv_chatml</span>
        <span class="k">elif</span> <span class="n">chat_template_name</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;qwen&quot;</span><span class="p">,):</span>
            <span class="n">func</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_inv_qwen</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;chat_template_name must be one of (&#39;chatml_format&#39;, &#39;qwen&#39;)&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">list_of_histories</span> <span class="o">=</span> <span class="p">[</span><span class="n">func</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">text</span><span class="p">]</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">(</span><span class="n">list_of_histories</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Failed to stack histories: </span><span class="si">{</span><span class="n">list_of_histories</span><span class="si">=}</span><span class="s2">&quot;</span>
                <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
        <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_chatml</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">History</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Inverts a chatml string into a History object.</span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): The chatml string to invert.</span>

<span class="sd">        Returns:</span>
<span class="sd">            History: The inverted History object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

        <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inverting chatml:</span><span class="se">\n</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># Find all complete blocks (ending with im_end or endoftext)</span>
        <span class="n">complete_pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;&lt;\|im_start\|&gt;(.*?)\n(.*?)&lt;\|(im_end|endoftext)\|&gt;&quot;</span>
        <span class="n">complete_matches</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">complete_pattern</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>

        <span class="c1"># Find any incomplete block at the end</span>
        <span class="n">incomplete_pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;&lt;\|im_start\|&gt;(.*?)\n(.*?)$&quot;</span>
        <span class="n">incomplete_matches</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">complete_matches</span><span class="p">:</span>
            <span class="c1"># Look for incomplete block after the last complete one</span>
            <span class="n">last_complete</span> <span class="o">=</span> <span class="n">complete_matches</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">last_complete_text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&lt;|im_start|&gt;</span><span class="si">{</span><span class="n">last_complete</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="n">last_complete</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&lt;|</span><span class="si">{</span><span class="n">last_complete</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">|&gt;&quot;</span>
            <span class="n">remaining_text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span>
                <span class="n">text</span><span class="o">.</span><span class="n">rindex</span><span class="p">(</span><span class="n">last_complete_text</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">last_complete_text</span><span class="p">)</span> <span class="p">:</span>
            <span class="p">]</span>
            <span class="k">if</span> <span class="n">remaining_text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                <span class="n">incomplete_match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span>
                    <span class="n">incomplete_pattern</span><span class="p">,</span> <span class="n">remaining_text</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">incomplete_match</span><span class="p">:</span>
                    <span class="n">incomplete_matches</span> <span class="o">=</span> <span class="p">[</span>
                        <span class="p">(</span><span class="n">incomplete_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">incomplete_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="kc">None</span><span class="p">)</span>
                    <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># No complete blocks, check entire text for incomplete block</span>
            <span class="n">incomplete_match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">incomplete_pattern</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">incomplete_match</span><span class="p">:</span>
                <span class="n">incomplete_matches</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="p">(</span><span class="n">incomplete_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">incomplete_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="kc">None</span><span class="p">)</span>
                <span class="p">]</span>

        <span class="c1"># Combine complete and incomplete matches</span>
        <span class="n">matches</span> <span class="o">=</span> <span class="n">complete_matches</span> <span class="o">+</span> <span class="n">incomplete_matches</span>

        <span class="c1"># Define tool patterns - same as Qwen for consistency</span>
        <span class="n">tool_call_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;&lt;tool_call&gt;\n(.*?)\n&lt;/tool_call&gt;&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>
        <span class="n">tool_response_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
            <span class="sa">r</span><span class="s2">&quot;&lt;tool_response&gt;\n(.*?)\n&lt;/tool_response&gt;&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span>
        <span class="p">)</span>

        <span class="n">parsed_messages</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">:</span>
            <span class="n">role</span> <span class="o">=</span> <span class="n">match</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">content</span> <span class="o">=</span> <span class="n">match</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">is_complete</span> <span class="o">=</span> <span class="n">match</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>  <span class="c1"># None indicates incomplete</span>

            <span class="c1"># Initialize message dict</span>
            <span class="n">message_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">role</span><span class="p">,</span>
                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">content</span><span class="p">,</span>
                <span class="s2">&quot;is_complete&quot;</span><span class="p">:</span> <span class="n">is_complete</span><span class="p">,</span>
                <span class="s2">&quot;tool_calls&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;tool_responses&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="c1"># Find tool calls within the message</span>
            <span class="n">tool_calls</span> <span class="o">=</span> <span class="n">tool_call_pattern</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">tool_calls</span><span class="p">:</span>
                <span class="n">tool_calls_list</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">tool_call</span> <span class="ow">in</span> <span class="n">tool_calls</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">tool_call_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">tool_call</span><span class="p">)</span>
                        <span class="n">tool_calls_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tool_call_dict</span><span class="p">)</span>
                    <span class="k">except</span> <span class="n">json</span><span class="o">.</span><span class="n">JSONDecodeError</span><span class="p">:</span>
                        <span class="k">continue</span>
                <span class="k">if</span> <span class="n">tool_calls_list</span><span class="p">:</span>
                    <span class="n">message_dict</span><span class="p">[</span><span class="s2">&quot;tool_calls&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tool_calls_list</span>

            <span class="c1"># Check for tool responses</span>
            <span class="n">tool_responses</span> <span class="o">=</span> <span class="n">tool_response_pattern</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">tool_responses</span><span class="p">:</span>
                <span class="n">message_dict</span><span class="p">[</span><span class="s2">&quot;tool_responses&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tool_responses</span>

            <span class="n">parsed_messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">message_dict</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">parsed_messages</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Couldn&#39;t get a single item out of text </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">. A common cause &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;if that special tokens should not be ommitted, did you set include_stop_str_in_output/skip_special_tokens=False?&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">(</span><span class="n">parsed_messages</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_inv_qwen</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">template</span><span class="p">):</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

        <span class="c1"># Define regex patterns for different parts of the template</span>
        <span class="n">message_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
            <span class="sa">r</span><span class="s2">&quot;&lt;\|im_start\|&gt;(.*?)(?:&lt;\|(im_end|endoftext)\|&gt;|$)&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span>
        <span class="p">)</span>
        <span class="n">tool_call_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;&lt;tool_call&gt;\n(.*?)\n&lt;/tool_call&gt;&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>
        <span class="n">tool_response_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
            <span class="sa">r</span><span class="s2">&quot;&lt;tool_response&gt;\n(.*?)\n&lt;/tool_response&gt;&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span>
        <span class="p">)</span>

        <span class="c1"># Find all messages and track if they end with a proper token</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">is_complete_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">message_pattern</span><span class="o">.</span><span class="n">finditer</span><span class="p">(</span><span class="n">template</span><span class="p">):</span>
            <span class="n">full_match</span> <span class="o">=</span> <span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="c1"># Check if the message ends with a proper token</span>
            <span class="n">is_complete_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">full_match</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;&lt;|im_end|&gt;&quot;</span><span class="p">)</span>
                <span class="ow">or</span> <span class="n">full_match</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="n">parsed_messages</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">message</span><span class="p">,</span> <span class="n">is_complete</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">is_complete_list</span><span class="p">):</span>
            <span class="c1"># Split the message into role and content</span>
            <span class="n">parts</span> <span class="o">=</span> <span class="n">message</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">role</span><span class="p">,</span> <span class="n">content</span> <span class="o">=</span> <span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">parts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

            <span class="c1"># Initialize message dict</span>
            <span class="n">message_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">role</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span>
                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span>
                <span class="s2">&quot;is_complete&quot;</span><span class="p">:</span> <span class="n">is_complete</span><span class="p">,</span>
                <span class="s2">&quot;tool_calls&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;tool_responses&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="c1"># Find tool calls within the message</span>
            <span class="n">tool_calls</span> <span class="o">=</span> <span class="n">tool_call_pattern</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">tool_calls</span><span class="p">:</span>
                <span class="n">tool_calls_list</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">tool_call</span> <span class="ow">in</span> <span class="n">tool_calls</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">tool_call_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">tool_call</span><span class="p">)</span>
                        <span class="n">tool_calls_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tool_call_dict</span><span class="p">)</span>
                    <span class="k">except</span> <span class="n">json</span><span class="o">.</span><span class="n">JSONDecodeError</span><span class="p">:</span>
                        <span class="k">continue</span>
                <span class="k">if</span> <span class="n">tool_calls_list</span><span class="p">:</span>
                    <span class="n">message_dict</span><span class="p">[</span><span class="s2">&quot;tool_calls&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tool_calls_list</span>

            <span class="c1"># Check for tool responses</span>
            <span class="n">tool_responses</span> <span class="o">=</span> <span class="n">tool_response_pattern</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">tool_responses</span><span class="p">:</span>
                <span class="n">message_dict</span><span class="p">[</span><span class="s2">&quot;tool_responses&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tool_responses</span>

            <span class="n">parsed_messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">message_dict</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">parsed_messages</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Couldn&#39;t get a single item out of text </span><span class="si">{</span><span class="n">template</span><span class="si">}</span><span class="s2">. A common cause &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;if that special tokens should not be ommitted, did you set include_stop_str_in_output/skip_special_tokens=False?&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">(</span><span class="n">parsed_messages</span><span class="p">)</span>

<div class="viewcode-block" id="History.append"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.llm.History.html#torchrl.data.llm.History.append">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">append</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">history</span><span class="p">:</span> <span class="n">History</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">History</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Appends a new history to the current one.</span>

<span class="sd">        Args:</span>
<span class="sd">            history (History): The new history to append.</span>
<span class="sd">            inplace (bool, optional): Whether to perform the operation in-place. Defaults to `True`.</span>
<span class="sd">            dim (int, optional): The dimension to append along. Defaults to -1.</span>

<span class="sd">        Returns:</span>
<span class="sd">            History: The appended History object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot append an element to a batchless History. Call unsqueeze(dim=0) first on self.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">!=</span> <span class="n">history</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The new history to append must have one less dimension than self. Got self.ndim=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2"> and history.ndim=</span><span class="si">{</span><span class="n">history</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="n">_maybe_correct_neg_dim</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="c1"># if self.ndim &gt; 1 and dim &gt;= self.ndim - 1:</span>
        <span class="c1">#     # then we need to append each element independently</span>
        <span class="c1">#     result = []</span>
        <span class="c1">#     for hist, new_hist in zip(self.unbind(0), history.unbind(0)):</span>
        <span class="c1">#         hist_c = hist.append(new_hist, inplace=inplace, dim=dim - 1)</span>
        <span class="c1">#         result.append(hist_c)</span>
        <span class="c1">#     if inplace:</span>
        <span class="c1">#         return self</span>
        <span class="c1">#     return lazy_stack(result)</span>
        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">)</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">stack_dim</span> <span class="o">==</span> <span class="n">dim</span>
            <span class="p">):</span>
                <span class="n">td</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">_tensordict</span>
                <span class="k">if</span> <span class="n">td</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
                <span class="k">return</span> <span class="bp">self</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">td</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">_tensordict</span>
                <span class="k">if</span> <span class="n">td</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">td</span> <span class="o">=</span> <span class="n">lazy_stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="n">td</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_tensordict&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">td</span>
                <span class="k">return</span> <span class="bp">self</span>
        <span class="k">if</span> <span class="n">history</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">history</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">history</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="n">history</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">extend</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">history</span><span class="p">:</span> <span class="n">History</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">History</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot add an element to a batchless History. Call unsqueeze(dim=0) first on self.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">!=</span> <span class="n">history</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The new history to extend must have as many dimensions as self. Got self.ndim=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2"> and history.ndim=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="n">_maybe_correct_neg_dim</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="c1"># if self.ndim &gt; 1 and dim &gt;= self.ndim - 1:</span>
        <span class="c1">#     # then we need to append each element independently</span>
        <span class="c1">#     result = []</span>
        <span class="c1">#     for hist, new_hist in zip(self.unbind(0), history.unbind(0)):</span>
        <span class="c1">#         hist_c = hist.extend(new_hist, inplace=inplace, dim=dim - 1)</span>
        <span class="c1">#         result.append(hist_c)</span>
        <span class="c1">#     if inplace:</span>
        <span class="c1">#         return self</span>
        <span class="c1">#     return lazy_stack(result)</span>
        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">)</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">stack_dim</span> <span class="o">==</span> <span class="n">dim</span>
            <span class="p">):</span>
                <span class="n">td</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">_tensordict</span>
                <span class="k">if</span> <span class="n">td</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
                <span class="k">return</span> <span class="bp">self</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">td</span> <span class="o">=</span> <span class="n">lazy_stack</span><span class="p">(</span>
                    <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span>
                    <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">dim</span><span class="p">)),</span>
                    <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">td</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_tensordict&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">td</span>
                <span class="k">return</span> <span class="bp">self</span>
        <span class="k">if</span> <span class="n">history</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">history</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">history</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">dim</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>

<div class="viewcode-block" id="History.default_spec"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.llm.History.html#torchrl.data.llm.History.default_spec">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">default_spec</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A default spec to use in transforms / envs that return History objects.</span>

<span class="sd">        Args:</span>
<span class="sd">            shape (torch.Size, optional): The shape of the returned History spec. Defaults to `(-1)` (variable length</span>
<span class="sd">                along the time dimension).</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; import tensordict</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.data import History</span>
<span class="sd">            &gt;&gt;&gt; tensordict.set_list_to_stack(True).set()</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; history = History(role=[&quot;system&quot;, &quot;user&quot;], content=[&quot;a message&quot;, &quot;another message&quot;], batch_size=(2,))</span>
<span class="sd">            &gt;&gt;&gt; spec = history.default_spec()</span>
<span class="sd">            &gt;&gt;&gt; print(spec)</span>
<span class="sd">            Composite(</span>
<span class="sd">                role: NonTensor(</span>
<span class="sd">                    shape=torch.Size([-1]),</span>
<span class="sd">                    space=None,</span>
<span class="sd">                    device=None,</span>
<span class="sd">                    dtype=None,</span>
<span class="sd">                    domain=None,</span>
<span class="sd">                    example_data=foo),</span>
<span class="sd">                content: NonTensor(</span>
<span class="sd">                    shape=torch.Size([-1]),</span>
<span class="sd">                    space=None,</span>
<span class="sd">                    device=None,</span>
<span class="sd">                    dtype=None,</span>
<span class="sd">                    domain=None,</span>
<span class="sd">                    example_data=foo),</span>
<span class="sd">                device=None,</span>
<span class="sd">                shape=torch.Size([-1]))</span>
<span class="sd">            &gt;&gt;&gt; print(spec.zero())</span>
<span class="sd">            History(</span>
<span class="sd">                content=NonTensorData(data=foo, batch_size=torch.Size([1]), device=None),</span>
<span class="sd">                role=NonTensorData(data=foo, batch_size=torch.Size([1]), device=None),</span>
<span class="sd">                batch_size=torch.Size([1]),</span>
<span class="sd">                device=None,</span>
<span class="sd">                is_shared=False)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Composite</span><span class="p">,</span> <span class="n">NonTensor</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">get_default_value</span><span class="p">(</span><span class="n">field</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">field</span><span class="o">.</span><span class="n">default</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">MISSING</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">field</span><span class="o">.</span><span class="n">default</span>
            <span class="k">elif</span> <span class="n">field</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;str&quot;</span><span class="p">):</span>
                <span class="k">return</span> <span class="s2">&quot;foo&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">None</span>

        <span class="n">defaults</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">k</span><span class="p">:</span> <span class="n">NonTensor</span><span class="p">(</span>
                <span class="n">example_data</span><span class="o">=</span><span class="n">get_default_value</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">__dataclass_fields__</span><span class="p">[</span><span class="n">k</span><span class="p">]),</span>
                <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">__dataclass_fields__</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">Composite</span><span class="p">(</span><span class="n">defaults</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">data_cls</span><span class="o">=</span><span class="bp">cls</span><span class="p">)</span></div>

<div class="viewcode-block" id="History.from_chats"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.llm.History.html#torchrl.data.llm.History.from_chats">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_chats</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">chats</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">History</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a History object from a list of chats.</span>

<span class="sd">        Args:</span>
<span class="sd">            chats (list[list[dict]]): A list of chats, where each chat is a list of dictionaries.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">chats</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">([</span><span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">chat</span><span class="p">)</span> <span class="k">for</span> <span class="n">chat</span> <span class="ow">in</span> <span class="n">chats</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">lazy_stack</span><span class="p">([</span><span class="bp">cls</span><span class="o">.</span><span class="n">from_chats</span><span class="p">(</span><span class="n">chat</span><span class="p">)</span> <span class="k">for</span> <span class="n">chat</span> <span class="ow">in</span> <span class="n">chats</span><span class="p">])</span></div></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="../../../../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrl = $("#tutorial-type").text();
	      var githubLink = "https://github.com/pytorch/rl/blob/main/tutorials/sphinx-"  + tutorialUrl + ".py",
		  notebookLink = $(".sphx-glr-download-jupyter").find(".download.reference")[0].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/rl/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }

          var overwrite = function(_) {
              if ($(this).length > 0) {
                  $(this)[0].href = "https://github.com/pytorch/rl"
              }
          }
          // PC
          $(".main-menu a:contains('GitHub')").each(overwrite);
          // Mobile
          $(".main-menu a:contains('Github')").each(overwrite);
      });

      
       $(window).ready(function() {
           var original = window.sideMenus.bind;
           var startup = true;
           window.sideMenus.bind = function() {
               original();
               if (startup) {
                   $("#pytorch-right-menu a.reference.internal").each(function(i) {
                       if (this.classList.contains("not-expanded")) {
                           this.nextElementSibling.style.display = "block";
                           this.classList.remove("not-expanded");
                           this.classList.add("expanded");
                       }
                   });
                   startup = false;
               }
           };
       });
    </script>

    


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch Documentation</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">Newsletter</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">Cloud Credit Program</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">Technical Advisory Council</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">Staff</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">Contact Us</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>
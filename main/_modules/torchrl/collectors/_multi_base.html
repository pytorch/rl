


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchrl.collectors._multi_base &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','UA-117752657-2');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="../../../../versions.html"><span style="font-size:110%">main (0.10.0+g3ab4b30) &#x25BC</span></a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-0.html">Get started with Environments, TED and transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-1.html">Get started with TorchRLâ€™s modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-2.html">Getting started with model optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-3.html">Get started with data collection and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-4.html">Get started with logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-5.html">Get started with your own first training loop</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/coding_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/torchrl_demo.html">Introduction to TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/multiagent_ppo.html">Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/torchrl_envs.html">TorchRL envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/pretrained_models.html">Using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/dqn_with_rnn.html">Recurrent DQN: Training recurrent policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/rb_tutorial.html">Using Replay Buffers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/export.html">Exporting TorchRL modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/llm_browser.html">TorchRL LLM: Building Tool-Enabled Environments</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/multiagent_competitive_ddpg.html">Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/coding_ddpg.html">TorchRL objectives: Coding a DDPG loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/coding_dqn.html">TorchRL trainer: A DQN example</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
      <li>torchrl.collectors._multi_base</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
    
    
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=UA-117752657-2"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torchrl.collectors._multi_base</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">_pickle</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">abc</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">contextlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">,</span> <span class="n">Sequence</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorDict</span><span class="p">,</span> <span class="n">TensorDictBase</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">CudaGraphModule</span><span class="p">,</span> <span class="n">TensorDictModule</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_zip_strict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">multiprocessing</span> <span class="k">as</span> <span class="n">mp</span><span class="p">,</span> <span class="n">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span> <span class="k">as</span> <span class="n">torchrl_logger</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl._utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_check_for_faulty_process</span><span class="p">,</span>
    <span class="n">_get_mp_ctx</span><span class="p">,</span>
    <span class="n">_make_process_no_warn_cls</span><span class="p">,</span>
    <span class="n">_mp_sharing_strategy_for_spawn</span><span class="p">,</span>
    <span class="n">_set_mp_start_method_if_unset</span><span class="p">,</span>
    <span class="n">RL_WARNINGS</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.collectors._base</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseCollector</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.collectors._constants</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_InterruptorManager</span><span class="p">,</span>
    <span class="n">_is_osx</span><span class="p">,</span>
    <span class="n">DEFAULT_EXPLORATION_TYPE</span><span class="p">,</span>
    <span class="n">ExplorationType</span><span class="p">,</span>
    <span class="n">INSTANTIATE_TIMEOUT</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.collectors._runner</span><span class="w"> </span><span class="kn">import</span> <span class="n">_main_async_collector</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.collectors._single</span><span class="w"> </span><span class="kn">import</span> <span class="n">Collector</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.collectors.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_make_meta_policy_cm</span><span class="p">,</span> <span class="n">_TrajectoryPool</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.collectors.weight_update</span><span class="w"> </span><span class="kn">import</span> <span class="n">WeightUpdaterBase</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">ReplayBuffer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">CloudpickleWrapper</span><span class="p">,</span> <span class="n">DEVICE_TYPING</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs</span><span class="w"> </span><span class="kn">import</span> <span class="n">EnvBase</span><span class="p">,</span> <span class="n">EnvCreator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.llm.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="n">PolicyVersion</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.weight_update</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">MultiProcessWeightSyncScheme</span><span class="p">,</span>
    <span class="n">SharedMemWeightSyncScheme</span><span class="p">,</span>
    <span class="n">WeightSyncScheme</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.weight_update.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_resolve_model</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_MultiCollectorMeta</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABCMeta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Metaclass for MultiCollector that dispatches based on sync parameter.</span>

<span class="sd">    When MultiCollector is instantiated with sync=True or sync=False, the metaclass</span>
<span class="sd">    intercepts the call and returns the appropriate subclass instance:</span>
<span class="sd">    - sync=True: returns MultiSyncCollector (alias: MultiSyncCollector)</span>
<span class="sd">    - sync=False: returns MultiAsyncCollector (alias: MultiAsyncCollector)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">sync</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># Only dispatch if we&#39;re instantiating MultiCollector directly (not a subclass)</span>
        <span class="c1"># and sync is explicitly provided</span>
        <span class="k">if</span> <span class="bp">cls</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;MultiCollector&quot;</span> <span class="ow">and</span> <span class="n">sync</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">sync</span><span class="p">:</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.collectors._multi_sync</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultiSyncCollector</span>

                <span class="k">return</span> <span class="n">MultiSyncCollector</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.collectors._multi_async</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultiAsyncCollector</span>

                <span class="k">return</span> <span class="n">MultiAsyncCollector</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<div class="viewcode-block" id="MultiCollector"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">MultiCollector</span><span class="p">(</span><span class="n">BaseCollector</span><span class="p">,</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">_MultiCollectorMeta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Runs a given number of DataCollectors on separate processes.</span>

<span class="sd">    Args:</span>
<span class="sd">        create_env_fn (List[Callabled]): list of Callables, each returning an</span>
<span class="sd">            instance of :class:`~torchrl.envs.EnvBase`.</span>
<span class="sd">        policy (Callable): Policy to be executed in the environment.</span>
<span class="sd">            Must accept :class:`tensordict.tensordict.TensorDictBase` object as input.</span>
<span class="sd">            If ``None`` is provided (default), the policy used will be a</span>
<span class="sd">            :class:`~torchrl.collectors.RandomPolicy` instance with the environment</span>
<span class="sd">            ``action_spec``.</span>
<span class="sd">            Accepted policies are usually subclasses of :class:`~tensordict.nn.TensorDictModuleBase`.</span>
<span class="sd">            This is the recommended usage of the collector.</span>
<span class="sd">            Other callables are accepted too:</span>
<span class="sd">            If the policy is not a ``TensorDictModuleBase`` (e.g., a regular :class:`~torch.nn.Module`</span>
<span class="sd">            instances) it will be wrapped in a `nn.Module` first.</span>
<span class="sd">            Then, the collector will try to assess if these</span>
<span class="sd">            modules require wrapping in a :class:`~tensordict.nn.TensorDictModule` or not.</span>

<span class="sd">            - If the policy forward signature matches any of ``forward(self, tensordict)``,</span>
<span class="sd">              ``forward(self, td)`` or ``forward(self, &lt;anything&gt;: TensorDictBase)`` (or</span>
<span class="sd">              any typing with a single argument typed as a subclass of ``TensorDictBase``)</span>
<span class="sd">              then the policy won&#39;t be wrapped in a :class:`~tensordict.nn.TensorDictModule`.</span>

<span class="sd">            - In all other cases an attempt to wrap it will be undergone as such:</span>
<span class="sd">              ``TensorDictModule(policy, in_keys=env_obs_key, out_keys=env.action_keys)``.</span>

<span class="sd">            .. note:: If the policy needs to be passed as a policy factory (e.g., in case it mustn&#39;t be serialized /</span>
<span class="sd">                pickled directly), the ``policy_factory`` should be used instead.</span>

<span class="sd">            .. note:: When using ``weight_sync_schemes``, both ``policy`` and ``policy_factory`` can be provided together.</span>
<span class="sd">                In this case, the ``policy`` is used ONLY for weight extraction (via ``TensorDict.from_module()``) to</span>
<span class="sd">                set up weight synchronization, but it is NOT sent to workers and its weights are NOT depopulated.</span>
<span class="sd">                The ``policy_factory`` is what actually gets passed to workers to create their local policy instances.</span>
<span class="sd">                This is useful when the policy is hard to serialize but you have a copy on the main node for</span>
<span class="sd">                weight synchronization purposes.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        sync (bool, optional): if ``True``, the collector will run in sync mode (:class:`~torchrl.collectors.MultiSyncCollector`). If</span>
<span class="sd">            `False`, the collector will run in async mode (:class:`~torchrl.collectors.MultiAsyncCollector`).</span>
<span class="sd">        policy_factory (Callable[[], Callable], list of Callable[[], Callable], optional): a callable</span>
<span class="sd">            (or list of callables) that returns a policy instance.</span>

<span class="sd">            When not using ``weight_sync_schemes``, this is mutually exclusive with the ``policy`` argument.</span>

<span class="sd">            When using ``weight_sync_schemes``, both ``policy`` and ``policy_factory`` can be provided:</span>
<span class="sd">            the ``policy`` is used for weight extraction only, while ``policy_factory`` creates policies on workers.</span>

<span class="sd">            .. note:: `policy_factory` comes in handy whenever the policy cannot be serialized.</span>

<span class="sd">            .. warning:: `policy_factory` is currently not compatible with multiprocessed data</span>
<span class="sd">                collectors.</span>

<span class="sd">        num_workers (int, optional): number of workers to use. If `create_env_fn` is a list, this will be ignored.</span>
<span class="sd">            Defaults to `None` (workers determined by the `create_env_fn` length).</span>
<span class="sd">        frames_per_batch (int, Sequence[int]): A keyword-only argument representing the</span>
<span class="sd">            total number of elements in a batch. If a sequence is provided, represents the number of elements in a</span>
<span class="sd">            batch per worker. Total number of elements in a batch is then the sum over the sequence.</span>
<span class="sd">        total_frames (int, optional): A keyword-only argument representing the</span>
<span class="sd">            total number of frames returned by the collector</span>
<span class="sd">            during its lifespan. If the ``total_frames`` is not divisible by</span>
<span class="sd">            ``frames_per_batch``, an exception is raised.</span>
<span class="sd">             Endless collectors can be created by passing ``total_frames=-1``.</span>
<span class="sd">             Defaults to ``-1`` (never ending collector).</span>
<span class="sd">        device (int, str or torch.device, optional): The generic device of the</span>
<span class="sd">            collector. The ``device`` args fills any non-specified device: if</span>
<span class="sd">            ``device`` is not ``None`` and any of ``storing_device``, ``policy_device`` or</span>
<span class="sd">            ``env_device`` is not specified, its value will be set to ``device``.</span>
<span class="sd">            Defaults to ``None`` (No default device).</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        storing_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the output :class:`~tensordict.TensorDict` will be stored.</span>
<span class="sd">            If ``device`` is passed and ``storing_device`` is ``None``, it will</span>
<span class="sd">            default to the value indicated by ``device``.</span>
<span class="sd">            For long trajectories, it may be necessary to store the data on a different</span>
<span class="sd">            device than the one where the policy and env are executed.</span>
<span class="sd">            Defaults to ``None`` (the output tensordict isn&#39;t on a specific device,</span>
<span class="sd">            leaf tensors sit on the device where they were created).</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        env_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the environment should be cast (or executed if that functionality is</span>
<span class="sd">            supported). If not specified and the env has a non-``None`` device,</span>
<span class="sd">            ``env_device`` will default to that value. If ``device`` is passed</span>
<span class="sd">            and ``env_device=None``, it will default to ``device``. If the value</span>
<span class="sd">            as such specified of ``env_device`` differs from ``policy_device``</span>
<span class="sd">            and one of them is not ``None``, the data will be cast to ``env_device``</span>
<span class="sd">            before being passed to the env (i.e., passing different devices to</span>
<span class="sd">            policy and env is supported). Defaults to ``None``.</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        policy_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the policy should be cast.</span>
<span class="sd">            If ``device`` is passed and ``policy_device=None``, it will default</span>
<span class="sd">            to ``device``. If the value as such specified of ``policy_device``</span>
<span class="sd">            differs from ``env_device`` and one of them is not ``None``,</span>
<span class="sd">            the data will be cast to ``policy_device`` before being passed to</span>
<span class="sd">            the policy (i.e., passing different devices to policy and env is</span>
<span class="sd">            supported). Defaults to ``None``.</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        create_env_kwargs (dict, optional): A dictionary with the</span>
<span class="sd">            keyword arguments used to create an environment. If a list is</span>
<span class="sd">            provided, each of its elements will be assigned to a sub-collector.</span>
<span class="sd">        collector_class (Python class or constructor): a collector class to be remotely instantiated. Can be</span>
<span class="sd">            :class:`~torchrl.collectors.Collector`,</span>
<span class="sd">            :class:`~torchrl.collectors.MultiSyncCollector`,</span>
<span class="sd">            :class:`~torchrl.collectors.MultiAsyncCollector`</span>
<span class="sd">            or a derived class of these.</span>
<span class="sd">            Defaults to :class:`~torchrl.collectors.Collector`.</span>
<span class="sd">        max_frames_per_traj (int, optional): Maximum steps per trajectory.</span>
<span class="sd">            Note that a trajectory can span across multiple batches (unless</span>
<span class="sd">            ``reset_at_each_iter`` is set to ``True``, see below).</span>
<span class="sd">            Once a trajectory reaches ``n_steps``, the environment is reset.</span>
<span class="sd">            If the environment wraps multiple environments together, the number</span>
<span class="sd">            of steps is tracked for each environment independently. Negative</span>
<span class="sd">            values are allowed, in which case this argument is ignored.</span>
<span class="sd">            Defaults to ``None`` (i.e. no maximum number of steps).</span>
<span class="sd">        init_random_frames (int, optional): Number of frames for which the</span>
<span class="sd">            policy is ignored before it is called. This feature is mainly</span>
<span class="sd">            intended to be used in offline/model-based settings, where a</span>
<span class="sd">            batch of random trajectories can be used to initialize training.</span>
<span class="sd">            If provided, it will be rounded up to the closest multiple of frames_per_batch.</span>
<span class="sd">            Defaults to ``None`` (i.e. no random frames).</span>
<span class="sd">        reset_at_each_iter (bool, optional): Whether environments should be reset</span>
<span class="sd">            at the beginning of a batch collection.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        postproc (Callable, optional): A post-processing transform, such as</span>
<span class="sd">            a :class:`~torchrl.envs.Transform` or a :class:`~torchrl.data.postprocs.MultiStep`</span>
<span class="sd">            instance.</span>
<span class="sd">            Defaults to ``None``.</span>
<span class="sd">        split_trajs (bool, optional): Boolean indicating whether the resulting</span>
<span class="sd">            TensorDict should be split according to the trajectories.</span>
<span class="sd">            See :func:`~torchrl.collectors.utils.split_trajectories` for more</span>
<span class="sd">            information.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        exploration_type (ExplorationType, optional): interaction mode to be used when</span>
<span class="sd">            collecting data. Must be one of ``torchrl.envs.utils.ExplorationType.DETERMINISTIC``,</span>
<span class="sd">            ``torchrl.envs.utils.ExplorationType.RANDOM``, ``torchrl.envs.utils.ExplorationType.MODE``</span>
<span class="sd">            or ``torchrl.envs.utils.ExplorationType.MEAN``.</span>
<span class="sd">        reset_when_done (bool, optional): if ``True`` (default), an environment</span>
<span class="sd">            that return a ``True`` value in its ``&quot;done&quot;`` or ``&quot;truncated&quot;``</span>
<span class="sd">            entry will be reset at the corresponding indices.</span>
<span class="sd">        update_at_each_batch (boolm optional): if ``True``, :meth:`update_policy_weights_()`</span>
<span class="sd">            will be called before (sync) or after (async) each data collection.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        preemptive_threshold (:obj:`float`, optional): a value between 0.0 and 1.0 that specifies the ratio of workers</span>
<span class="sd">            that will be allowed to finished collecting their rollout before the rest are forced to end early.</span>
<span class="sd">        num_threads (int, optional): number of threads for this process.</span>
<span class="sd">            Defaults to the number of workers.</span>
<span class="sd">        num_sub_threads (int, optional): number of threads of the subprocesses.</span>
<span class="sd">            Should be equal to one plus the number of processes launched within</span>
<span class="sd">            each subprocess (or one if a single process is launched).</span>
<span class="sd">            Defaults to 1 for safety: if none is indicated, launching multiple</span>
<span class="sd">            workers may charge the cpu load too much and harm performance.</span>
<span class="sd">        cat_results (str, int or None): (:class:`~torchrl.collectors.MultiSyncCollector` exclusively).</span>
<span class="sd">            If ``&quot;stack&quot;``, the data collected from the workers will be stacked along the</span>
<span class="sd">            first dimension. This is the preferred behavior as it is the most compatible</span>
<span class="sd">            with the rest of the library.</span>
<span class="sd">            If ``0``, results will be concatenated along the first dimension</span>
<span class="sd">            of the outputs, which can be the batched dimension if the environments are</span>
<span class="sd">            batched or the time dimension if not.</span>
<span class="sd">            A ``cat_results`` value of ``-1`` will always concatenate results along the</span>
<span class="sd">            time dimension. This should be preferred over the default. Intermediate values</span>
<span class="sd">            are also accepted.</span>
<span class="sd">            Defaults to ``&quot;stack&quot;``.</span>

<span class="sd">            .. note:: From v0.5, this argument will default to ``&quot;stack&quot;`` for a better</span>
<span class="sd">                interoperability with the rest of the library.</span>

<span class="sd">        set_truncated (bool, optional): if ``True``, the truncated signals (and corresponding</span>
<span class="sd">            ``&quot;done&quot;`` but not ``&quot;terminated&quot;``) will be set to ``True`` when the last frame of</span>
<span class="sd">            a rollout is reached. If no ``&quot;truncated&quot;`` key is found, an exception is raised.</span>
<span class="sd">            Truncated keys can be set through ``env.add_truncated_keys``.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        use_buffers (bool, optional): if ``True``, a buffer will be used to stack the data.</span>
<span class="sd">            This isn&#39;t compatible with environments with dynamic specs. Defaults to ``True``</span>
<span class="sd">            for envs without dynamic specs, ``False`` for others.</span>
<span class="sd">        replay_buffer (ReplayBuffer, optional): if provided, the collector will not yield tensordicts</span>
<span class="sd">            but populate the buffer instead. Defaults to ``None``.</span>
<span class="sd">        extend_buffer (bool, optional): if `True`, the replay buffer is extended with entire rollouts and not</span>
<span class="sd">            with single steps. Defaults to `True` for multiprocessed data collectors.</span>
<span class="sd">        local_init_rb (bool, optional): if ``False``, the collector will use fake data to initialize</span>
<span class="sd">            the replay buffer in the main process (legacy behavior). If ``True``, the storage-level</span>
<span class="sd">            coordination will handle initialization with real data from worker processes.</span>
<span class="sd">            Defaults to ``None``, which maintains backward compatibility but shows a deprecation warning.</span>
<span class="sd">            This parameter is deprecated and will be removed in v0.12.</span>
<span class="sd">        trust_policy (bool, optional): if ``True``, a non-TensorDictModule policy will be trusted to be</span>
<span class="sd">            assumed to be compatible with the collector. This defaults to ``True`` for CudaGraphModules</span>
<span class="sd">            and ``False`` otherwise.</span>
<span class="sd">        compile_policy (bool or Dict[str, Any], optional): if ``True``, the policy will be compiled</span>
<span class="sd">            using :func:`~torch.compile` default behaviour. If a dictionary of kwargs is passed, it</span>
<span class="sd">            will be used to compile the policy.</span>
<span class="sd">        cudagraph_policy (bool or Dict[str, Any], optional): if ``True``, the policy will be wrapped</span>
<span class="sd">            in :class:`~tensordict.nn.CudaGraphModule` with default kwargs.</span>
<span class="sd">            If a dictionary of kwargs is passed, it will be used to wrap the policy.</span>
<span class="sd">        no_cuda_sync (bool): if ``True``, explicit CUDA synchronizations calls will be bypassed.</span>
<span class="sd">            For environments running directly on CUDA (`IsaacLab &lt;https://github.com/isaac-sim/IsaacLab/&gt;`_</span>
<span class="sd">            or `ManiSkills &lt;https://github.com/haosulab/ManiSkill/&gt;`_) cuda synchronization may cause unexpected</span>
<span class="sd">            crashes.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        weight_updater (WeightUpdaterBase or constructor, optional): An instance of :class:`~torchrl.collectors.WeightUpdaterBase`</span>
<span class="sd">            or its subclass, responsible for updating the policy weights on remote inference workers.</span>
<span class="sd">            If not provided, a :class:`~torchrl.collectors.MultiProcessedWeightUpdater` will be used by default,</span>
<span class="sd">            which handles weight synchronization across multiple processes.</span>
<span class="sd">            Consider using a constructor if the updater needs to be serialized.</span>
<span class="sd">        weight_sync_schemes (dict[str, WeightSyncScheme], optional): Dictionary of weight sync schemes for</span>
<span class="sd">            SENDING weights to worker sub-collectors. Keys are model identifiers (e.g., &quot;policy&quot;)</span>
<span class="sd">            and values are WeightSyncScheme instances configured to send weights to child processes.</span>
<span class="sd">            If not provided, a :class:`~torchrl.collectors.MultiProcessWeightSyncScheme` will be used by default.</span>
<span class="sd">            This is for propagating weights DOWN the hierarchy (parent -&gt; children).</span>
<span class="sd">        weight_recv_schemes (dict[str, WeightSyncScheme], optional): Dictionary of weight sync schemes for</span>
<span class="sd">            RECEIVING weights from parent collectors. Keys are model identifiers (e.g., &quot;policy&quot;)</span>
<span class="sd">            and values are WeightSyncScheme instances configured to receive weights.</span>
<span class="sd">            This enables cascading in hierarchies like: RPCDataCollector -&gt; MultiSyncCollector -&gt; Collector.</span>
<span class="sd">            Received weights are automatically propagated to sub-collectors if matching model_ids exist.</span>
<span class="sd">            Defaults to ``None``.</span>
<span class="sd">        track_policy_version (bool or PolicyVersion, optional): if ``True``, the collector will track the version of the policy.</span>
<span class="sd">            This will be mediated by the :class:`~torchrl.envs.llm.transforms.policy_version.PolicyVersion` transform, which will be added to the environment.</span>
<span class="sd">            Alternatively, a :class:`~torchrl.envs.llm.transforms.policy_version.PolicyVersion` instance can be passed, which will be used to track</span>
<span class="sd">            the policy version.</span>
<span class="sd">            Defaults to `False`.</span>
<span class="sd">        worker_idx (int, optional): the index of the worker.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.collectors import MultiCollector</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs import GymEnv</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; def make_env():</span>
<span class="sd">        ...     return GymEnv(&quot;CartPole-v1&quot;)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Synchronous collection (for on-policy algorithms like PPO)</span>
<span class="sd">        &gt;&gt;&gt; sync_collector = MultiCollector(</span>
<span class="sd">        ...     create_env_fn=[make_env] * 4,  # 4 parallel workers</span>
<span class="sd">        ...     policy=my_policy,</span>
<span class="sd">        ...     frames_per_batch=1000,</span>
<span class="sd">        ...     total_frames=100000,</span>
<span class="sd">        ...     sync=True,  # All workers complete before batch is delivered</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Asynchronous collection (for off-policy algorithms like SAC)</span>
<span class="sd">        &gt;&gt;&gt; async_collector = MultiCollector(</span>
<span class="sd">        ...     create_env_fn=[make_env] * 4,</span>
<span class="sd">        ...     policy=my_policy,</span>
<span class="sd">        ...     frames_per_batch=1000,</span>
<span class="sd">        ...     total_frames=100000,</span>
<span class="sd">        ...     sync=False,  # First-come-first-serve delivery</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Iterate over collected data</span>
<span class="sd">        &gt;&gt;&gt; for data in sync_collector:</span>
<span class="sd">        ...     # data is a TensorDict with collected transitions</span>
<span class="sd">        ...     pass</span>
<span class="sd">        &gt;&gt;&gt; sync_collector.shutdown()</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">create_env_fn</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="n">EnvBase</span><span class="p">]],</span>
        <span class="n">policy</span><span class="p">:</span> <span class="kc">None</span>
        <span class="o">|</span> <span class="p">(</span><span class="n">TensorDictModule</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">])</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">policy_factory</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Callable</span><span class="p">]</span>
        <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="n">Callable</span><span class="p">]]</span>
        <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">frames_per_batch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">total_frames</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">storing_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">env_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">policy_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">create_env_kwargs</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">collector_class</span><span class="p">:</span> <span class="nb">type</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">BaseCollector</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_frames_per_traj</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">init_random_frames</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">reset_at_each_iter</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">postproc</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">split_trajs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">exploration_type</span><span class="p">:</span> <span class="n">ExplorationType</span> <span class="o">=</span> <span class="n">DEFAULT_EXPLORATION_TYPE</span><span class="p">,</span>
        <span class="n">reset_when_done</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">update_at_each_batch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">preemptive_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_threads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_sub_threads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">cat_results</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">set_truncated</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">use_buffers</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">replay_buffer</span><span class="p">:</span> <span class="n">ReplayBuffer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">extend_buffer</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">replay_buffer_chunk</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_init_rb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">trust_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">compile_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cudagraph_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">no_cuda_sync</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">weight_updater</span><span class="p">:</span> <span class="n">WeightUpdaterBase</span>
        <span class="o">|</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">WeightUpdaterBase</span><span class="p">]</span>
        <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">weight_sync_schemes</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">WeightSyncScheme</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">weight_recv_schemes</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">WeightSyncScheme</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">track_policy_version</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">worker_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">worker_idx</span> <span class="o">=</span> <span class="n">worker_idx</span>

        <span class="c1"># Set up workers and environment functions</span>
        <span class="n">create_env_fn</span><span class="p">,</span> <span class="n">total_frames_per_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_setup_workers_and_env_fns</span><span class="p">(</span>
            <span class="n">create_env_fn</span><span class="p">,</span> <span class="n">num_workers</span><span class="p">,</span> <span class="n">frames_per_batch</span>
        <span class="p">)</span>

        <span class="c1"># Set up basic configuration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_truncated</span> <span class="o">=</span> <span class="n">set_truncated</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_sub_threads</span> <span class="o">=</span> <span class="n">num_sub_threads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_threads</span> <span class="o">=</span> <span class="n">num_threads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span> <span class="o">=</span> <span class="n">create_env_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_read_compile_kwargs</span><span class="p">(</span><span class="n">compile_policy</span><span class="p">,</span> <span class="n">cudagraph_policy</span><span class="p">)</span>

        <span class="c1"># Set up environment kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">create_env_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_setup_env_kwargs</span><span class="p">(</span><span class="n">create_env_kwargs</span><span class="p">)</span>

        <span class="c1"># Set up devices</span>
        <span class="n">storing_devices</span><span class="p">,</span> <span class="n">policy_devices</span><span class="p">,</span> <span class="n">env_devices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_devices</span><span class="p">(</span>
            <span class="n">storing_device</span><span class="o">=</span><span class="n">storing_device</span><span class="p">,</span>
            <span class="n">env_device</span><span class="o">=</span><span class="n">env_device</span><span class="p">,</span>
            <span class="n">policy_device</span><span class="o">=</span><span class="n">policy_device</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span> <span class="o">=</span> <span class="n">storing_devices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="o">=</span> <span class="n">policy_devices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span> <span class="o">=</span> <span class="n">env_devices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">collector_class</span> <span class="o">=</span> <span class="n">collector_class</span>
        <span class="k">del</span> <span class="n">storing_device</span><span class="p">,</span> <span class="n">env_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span> <span class="o">=</span> <span class="n">no_cuda_sync</span>

        <span class="c1"># Set up replay buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span> <span class="o">=</span> <span class="n">use_buffers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">replay_buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_multi_replay_buffer</span><span class="p">(</span>
            <span class="n">local_init_rb</span><span class="p">,</span> <span class="n">replay_buffer</span><span class="p">,</span> <span class="n">replay_buffer_chunk</span><span class="p">,</span> <span class="n">extend_buffer</span>
        <span class="p">)</span>

        <span class="c1"># Set up policy and weights</span>
        <span class="k">if</span> <span class="n">trust_policy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">trust_policy</span> <span class="o">=</span> <span class="n">policy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">CudaGraphModule</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trust_policy</span> <span class="o">=</span> <span class="n">trust_policy</span>

        <span class="n">policy_factory</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_setup_policy_factory</span><span class="p">(</span><span class="n">policy_factory</span><span class="p">)</span>

        <span class="c1"># Set up weight synchronization</span>
        <span class="k">if</span> <span class="n">weight_sync_schemes</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">weight_updater</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">weight_sync_schemes</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">elif</span> <span class="n">weight_sync_schemes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">weight_updater</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot specify both weight_sync_schemes and weight_updater.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">weight_sync_schemes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="n">weight_sync_schemes</span>
            <span class="ow">and</span> <span class="n">weight_updater</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">any</span><span class="p">(</span><span class="n">policy_factory</span><span class="p">))</span>
        <span class="p">):</span>
            <span class="c1"># Set up a default local shared-memory sync scheme for the policy.</span>
            <span class="c1"># This is used to propagate weights from the orchestrator policy</span>
            <span class="c1"># (possibly combined with a policy_factory) down to worker policies.</span>
            <span class="n">weight_sync_schemes</span><span class="p">[</span><span class="s2">&quot;policy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">SharedMemWeightSyncScheme</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_multi_weight_sync</span><span class="p">(</span><span class="n">weight_updater</span><span class="p">,</span> <span class="n">weight_sync_schemes</span><span class="p">)</span>

        <span class="c1"># Store policy and policy_factory - temporary set to make them visible to the receiver</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">policy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_factory</span> <span class="o">=</span> <span class="n">policy_factory</span>

        <span class="c1"># Set up weight receivers if provided</span>
        <span class="k">if</span> <span class="n">weight_recv_schemes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_scheme_receiver</span><span class="p">(</span><span class="n">weight_recv_schemes</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_multi_policy_and_weights</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_factory</span><span class="p">,</span> <span class="n">weight_updater</span><span class="p">,</span> <span class="n">weight_sync_schemes</span>
        <span class="p">)</span>

        <span class="c1"># Set up policy version tracking</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_multi_policy_version_tracking</span><span class="p">(</span><span class="n">track_policy_version</span><span class="p">)</span>

        <span class="c1"># # Set up fallback policy for weight extraction</span>
        <span class="c1"># self._setup_fallback_policy(policy, policy_factory, weight_sync_schemes)</span>

        <span class="c1"># Set up total frames and other parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_multi_total_frames</span><span class="p">(</span>
            <span class="n">total_frames</span><span class="p">,</span> <span class="n">total_frames_per_batch</span><span class="p">,</span> <span class="n">frames_per_batch</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_at_each_iter</span> <span class="o">=</span> <span class="n">reset_at_each_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span> <span class="o">=</span> <span class="n">postproc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_frames_per_traj</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">max_frames_per_traj</span><span class="p">)</span> <span class="k">if</span> <span class="n">max_frames_per_traj</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="p">)</span>

        <span class="c1"># Set up split trajectories</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">requested_frames_per_batch</span> <span class="o">=</span> <span class="n">total_frames_per_batch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_when_done</span> <span class="o">=</span> <span class="n">reset_when_done</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_split_trajs</span><span class="p">(</span><span class="n">split_trajs</span><span class="p">,</span> <span class="n">reset_when_done</span><span class="p">)</span>

        <span class="c1"># Set up other parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">init_random_frames</span><span class="p">)</span> <span class="k">if</span> <span class="n">init_random_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_at_each_batch</span> <span class="o">=</span> <span class="n">update_at_each_batch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exploration_type</span> <span class="o">=</span> <span class="n">exploration_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_worker</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>

        <span class="c1"># Set up preemptive threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_preemptive_threshold</span><span class="p">(</span><span class="n">preemptive_threshold</span><span class="p">)</span>

        <span class="c1"># Run worker processes</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_run_processes</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">(</span><span class="n">raise_on_error</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">e</span>

        <span class="c1"># Set up frame tracking and other options</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_exclude_private_keys</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

        <span class="c1"># Validate cat_results</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_cat_results</span><span class="p">(</span><span class="n">cat_results</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_workers_and_env_fns</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">create_env_fn</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">frames_per_batch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Callable</span><span class="p">],</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set up workers and environment functions.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">create_env_fn</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">create_env_fn</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">=</span> <span class="n">num_workers</span>
            <span class="n">create_env_fn</span> <span class="o">=</span> <span class="p">[</span><span class="n">create_env_fn</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">frames_per_batch</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">)</span>
            <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">frames_per_batch</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;If `frames_per_batch` is provided as a sequence, it should contain exactly one value per worker.&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">frames_per_batch</span><span class="p">)</span><span class="si">}</span><span class="s2"> values for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="si">}</span><span class="s2"> workers.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_frames_per_batch</span> <span class="o">=</span> <span class="n">frames_per_batch</span>
        <span class="n">total_frames_per_batch</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">sum</span><span class="p">(</span><span class="n">frames_per_batch</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">frames_per_batch</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">frames_per_batch</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">create_env_fn</span><span class="p">,</span> <span class="n">total_frames_per_batch</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_env_kwargs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">create_env_kwargs</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">|</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set up environment kwargs for each worker.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">create_env_kwargs</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
            <span class="n">create_env_kwargs</span> <span class="o">=</span> <span class="p">[</span><span class="n">create_env_kwargs</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">elif</span> <span class="n">create_env_kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">create_env_kwargs</span> <span class="o">=</span> <span class="p">[{}]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">create_env_kwargs</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="n">create_env_kwargs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">create_env_kwargs</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">create_env_kwargs</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;len(create_env_kwargs) must be equal to num_workers, got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">create_env_kwargs</span><span class="p">)</span><span class="si">=}</span><span class="s2"> and </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="si">=}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">create_env_kwargs</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_multi_replay_buffer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">local_init_rb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">replay_buffer</span><span class="p">:</span> <span class="n">ReplayBuffer</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">replay_buffer_chunk</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">extend_buffer</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set up replay buffer for multi-process collector.&quot;&quot;&quot;</span>
        <span class="c1"># Handle local_init_rb deprecation</span>
        <span class="k">if</span> <span class="n">local_init_rb</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">local_init_rb</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">local_init_rb</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;local_init_rb=False is deprecated and will be removed in v0.12. &quot;</span>
                    <span class="s2">&quot;The new storage-level initialization provides better performance.&quot;</span><span class="p">,</span>
                    <span class="ne">FutureWarning</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">local_init_rb</span> <span class="o">=</span> <span class="n">local_init_rb</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_check_replay_buffer_init</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">replay_buffer_chunk</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">extend_buffer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">replay_buffer_chunk</span> <span class="o">=</span> <span class="n">extend_buffer</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;The replay_buffer_chunk is deprecated and replaced by extend_buffer. This argument will disappear in v0.10.&quot;</span><span class="p">,</span>
                    <span class="ne">DeprecationWarning</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">extend_buffer</span> <span class="o">!=</span> <span class="n">replay_buffer_chunk</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;conflicting values for replay_buffer_chunk and extend_buffer.&quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">extend_buffer</span> <span class="o">=</span> <span class="n">extend_buffer</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">replay_buffer</span><span class="p">,</span> <span class="s2">&quot;shared&quot;</span><span class="p">)</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="n">replay_buffer</span><span class="o">.</span><span class="n">shared</span>
        <span class="p">):</span>
            <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Replay buffer is not shared. Sharing it.&quot;</span><span class="p">)</span>
            <span class="n">replay_buffer</span><span class="o">.</span><span class="n">share</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_policy_factory</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">policy_factory</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set up policy factory for each worker.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy_factory</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="n">policy_factory</span> <span class="o">=</span> <span class="p">[</span><span class="n">policy_factory</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">return</span> <span class="n">policy_factory</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_multi_policy_and_weights</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">policy</span><span class="p">:</span> <span class="n">TensorDictModule</span> <span class="o">|</span> <span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">policy_factory</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span><span class="p">],</span>
        <span class="n">weight_updater</span><span class="p">:</span> <span class="n">WeightUpdaterBase</span> <span class="o">|</span> <span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">weight_sync_schemes</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">WeightSyncScheme</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set up policy for multi-process collector.</span>

<span class="sd">        With weight sync schemes: validates and stores policy without weight extraction.</span>
<span class="sd">        With weight updater: extracts weights and creates stateful policies.</span>

<span class="sd">        When both policy and policy_factory are provided (with weight_sync_schemes):</span>
<span class="sd">        - The policy is used ONLY for weight extraction via get_model()</span>
<span class="sd">        - The policy is NOT depopulated of its weights</span>
<span class="sd">        - The policy is NOT sent to workers</span>
<span class="sd">        - The policy_factory is used to create policies on workers</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">policy_factory</span><span class="p">)</span> <span class="ow">and</span> <span class="n">policy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">weight_sync_schemes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s2">&quot;policy_factory and policy are mutually exclusive when not using weight_sync_schemes. &quot;</span>
                    <span class="s2">&quot;When using weight_sync_schemes, policy can be provided alongside policy_factory &quot;</span>
                    <span class="s2">&quot;for weight extraction purposes only (the policy will not be sent to workers).&quot;</span>
                <span class="p">)</span>
            <span class="c1"># Store policy as fallback for weight extraction only</span>
            <span class="c1"># The policy keeps its weights and is NOT sent to workers</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fallback_policy</span> <span class="o">=</span> <span class="n">policy</span>

        <span class="k">if</span> <span class="n">weight_sync_schemes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">weight_sync_policy</span> <span class="o">=</span> <span class="n">weight_sync_schemes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;policy&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">weight_sync_policy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span>
            <span class="c1"># # If we only have a policy_factory (no policy instance), the scheme must</span>
            <span class="c1"># # be pre-initialized on the sender, since there is no policy on the</span>
            <span class="c1"># # collector to extract weights from.</span>
            <span class="c1"># if any(p is not None for p in policy_factory) and policy is None:</span>
            <span class="c1">#     if not weight_sync_policy.initialized_on_sender:</span>
            <span class="c1">#         raise RuntimeError(</span>
            <span class="c1">#             &quot;the weight sync scheme must be initialized on sender ahead of time &quot;</span>
            <span class="c1">#             &quot;when passing a policy_factory without a policy instance on the collector. &quot;</span>
            <span class="c1">#             f&quot;Got {policy_factory=}&quot;</span>
            <span class="c1">#         )</span>
            <span class="c1"># # When a policy instance is provided alongside a policy_factory, the scheme</span>
            <span class="c1"># # can rely on the collector context (and its policy) to extract weights.</span>
            <span class="c1"># # Weight sync scheme initialization then happens in _run_processes where</span>
            <span class="c1"># # pipes and workers are available.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Using legacy weight updater - extract weights and create stateful policies</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_setup_multi_policy_and_weights_legacy</span><span class="p">(</span>
                <span class="n">policy</span><span class="p">,</span> <span class="n">policy_factory</span><span class="p">,</span> <span class="n">weight_updater</span><span class="p">,</span> <span class="n">weight_sync_schemes</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_multi_policy_and_weights_legacy</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">policy</span><span class="p">:</span> <span class="n">TensorDictModule</span> <span class="o">|</span> <span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">policy_factory</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span><span class="p">],</span>
        <span class="n">weight_updater</span><span class="p">:</span> <span class="n">WeightUpdaterBase</span> <span class="o">|</span> <span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">weight_sync_schemes</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">WeightSyncScheme</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set up policy and extract weights for each device.</span>

<span class="sd">        Creates stateful policies with weights extracted and placed in shared memory.</span>
<span class="sd">        Used with weight updater for in-place weight replacement.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_policy_weights_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fallback_policy</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Policy to use for weight extraction fallback</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">policy_factory</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_maker</span><span class="p">,</span> <span class="n">env_maker_kwargs</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_kwargs</span>
            <span class="p">):</span>
                <span class="n">policy_new_device</span><span class="p">,</span> <span class="n">get_weights_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_policy_and_device</span><span class="p">(</span>
                    <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">,</span>
                    <span class="n">policy_device</span><span class="o">=</span><span class="n">policy_device</span><span class="p">,</span>
                    <span class="n">env_maker</span><span class="o">=</span><span class="n">env_maker</span><span class="p">,</span>
                    <span class="n">env_maker_kwargs</span><span class="o">=</span><span class="n">env_maker_kwargs</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">policy_new_device</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">policy</span><span class="p">):</span>
                    <span class="n">policy</span> <span class="o">=</span> <span class="n">policy_new_device</span>
                <span class="n">weights</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">TensorDict</span><span class="o">.</span><span class="n">from_module</span><span class="p">(</span><span class="n">policy_new_device</span><span class="p">)</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy_new_device</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
                    <span class="k">else</span> <span class="n">TensorDict</span><span class="p">()</span>
                <span class="p">)</span>
                <span class="c1"># For multi-process collectors, ensure weights are in shared memory</span>
                <span class="k">if</span> <span class="n">policy_device</span> <span class="ow">and</span> <span class="n">policy_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
                    <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_policy_weights_dict</span><span class="p">[</span><span class="n">policy_device</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span>
                <span class="c1"># Store the first policy instance for fallback weight extraction</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fallback_policy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_fallback_policy</span> <span class="o">=</span> <span class="n">policy_new_device</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_get_weights_fn</span> <span class="o">=</span> <span class="n">get_weights_fn</span>
            <span class="k">if</span> <span class="n">weight_updater</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># For multiprocessed collectors, use MultiProcessWeightSyncScheme by default</span>
                <span class="k">if</span> <span class="n">weight_sync_schemes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">weight_sync_schemes</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;policy&quot;</span><span class="p">:</span> <span class="n">MultiProcessWeightSyncScheme</span><span class="p">()}</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span> <span class="o">=</span> <span class="n">weight_sync_schemes</span>
        <span class="k">elif</span> <span class="n">weight_updater</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;weight_updater is None, but policy_factory is provided. This means that the server will &quot;</span>
                <span class="s2">&quot;not know how to send the weights to the workers. If the workers can handle their weight synchronization &quot;</span>
                <span class="s2">&quot;on their own (via some specialized worker type / constructor) this may well work, but make sure &quot;</span>
                <span class="s2">&quot;your weight synchronization strategy is properly set. To suppress this warning, you can use &quot;</span>
                <span class="s2">&quot;RemoteModuleWeightUpdater() which enforces explicit weight passing when calling update_policy_weights_(weights). &quot;</span>
                <span class="s2">&quot;This will work whenever your inference and training policies are nn.Module instances with similar structures.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_multi_weight_sync</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">weight_updater</span><span class="p">:</span> <span class="n">WeightUpdaterBase</span> <span class="o">|</span> <span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">weight_sync_schemes</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">WeightSyncScheme</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set up weight synchronization for multi-process collector.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">weight_sync_schemes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Use weight sync schemes for weight distribution</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span> <span class="o">=</span> <span class="n">weight_sync_schemes</span>
            <span class="c1"># Senders will be created in _run_processes</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_updater</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Use weight updater for weight distribution</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_updater</span> <span class="o">=</span> <span class="n">weight_updater</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_multi_policy_version_tracking</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">track_policy_version</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="n">PolicyVersion</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set up policy version tracking for multi-process collector.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span> <span class="o">=</span> <span class="n">track_policy_version</span>
        <span class="k">if</span> <span class="n">PolicyVersion</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">track_policy_version</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">and</span> <span class="n">track_policy_version</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span> <span class="o">=</span> <span class="n">PolicyVersion</span><span class="p">()</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">track_policy_version</span><span class="p">,</span> <span class="s2">&quot;increment_version&quot;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span> <span class="o">=</span> <span class="n">track_policy_version</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">track_policy_version</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                    <span class="s2">&quot;PolicyVersion is not available. Please install the LLM dependencies or set track_policy_version=False.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># TODO: Remove this</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_fallback_policy</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">policy</span><span class="p">:</span> <span class="n">TensorDictModule</span> <span class="o">|</span> <span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">policy_factory</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span><span class="p">],</span>
        <span class="n">weight_sync_schemes</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">WeightSyncScheme</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set up fallback policy for weight extraction when using policy_factory.&quot;&quot;&quot;</span>
        <span class="c1"># _fallback_policy is already set in _setup_multi_policy_and_weights if a policy was provided</span>
        <span class="c1"># If policy_factory was used, create a policy instance to use as fallback</span>
        <span class="k">if</span> <span class="n">policy</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span><span class="n">policy_factory</span><span class="p">)</span> <span class="ow">and</span> <span class="n">weight_sync_schemes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_fallback_policy&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fallback_policy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">first_factory</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">policy_factory</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy_factory</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
                    <span class="k">else</span> <span class="n">policy_factory</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">first_factory</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># Create a policy instance for weight extraction</span>
                    <span class="c1"># This will be a reference to a policy with the same structure</span>
                    <span class="c1"># For shared memory, modifications to any policy will be visible here</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_fallback_policy</span> <span class="o">=</span> <span class="n">first_factory</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_multi_total_frames</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">total_frames</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">total_frames_per_batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">frames_per_batch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validate and set total frames for multi-process collector.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">total_frames</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">total_frames</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">total_frames</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">remainder</span> <span class="o">=</span> <span class="n">total_frames</span> <span class="o">%</span> <span class="n">total_frames_per_batch</span>
            <span class="k">if</span> <span class="n">remainder</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">RL_WARNINGS</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;total_frames (</span><span class="si">{</span><span class="n">total_frames</span><span class="si">}</span><span class="s2">) is not exactly divisible by frames_per_batch (</span><span class="si">{</span><span class="n">total_frames_per_batch</span><span class="si">}</span><span class="s2">). &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;This means </span><span class="si">{</span><span class="n">total_frames_per_batch</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">remainder</span><span class="si">}</span><span class="s2"> additional frames will be collected. &quot;</span>
                    <span class="s2">&quot;To silence this message, set the environment variable RL_WARNINGS to False.&quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">total_frames</span><span class="p">)</span> <span class="k">if</span> <span class="n">total_frames</span> <span class="o">!=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">total_frames</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_split_trajs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">split_trajs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="n">reset_when_done</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set up split trajectories option.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">split_trajs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">split_trajs</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="n">reset_when_done</span> <span class="ow">and</span> <span class="n">split_trajs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot split trajectories when reset_when_done is False.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">split_trajs</span> <span class="o">=</span> <span class="n">split_trajs</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_preemptive_threshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">preemptive_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set up preemptive threshold for early stopping.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">preemptive_threshold</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">_is_osx</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot use preemption on OSX due to Queue.qsize() not being implemented on this platform.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">preemptive_threshold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">preemptive_threshold</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="n">manager</span> <span class="o">=</span> <span class="n">_InterruptorManager</span><span class="p">()</span>
            <span class="n">manager</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">_Interruptor</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">preemptive_threshold</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_should_use_random_frames</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Determine if random frames should be used instead of the policy.</span>

<span class="sd">        When a replay buffer is provided, uses `replay_buffer.write_count` as the</span>
<span class="sd">        global step counter to support `.start()` mode where `_frames` isn&#39;t updated</span>
<span class="sd">        until after collection. Otherwise, uses the internal `_frames` counter.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: True if random frames should be used, False otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="c1"># Use replay_buffer.write_count when available for accurate counting in .start() mode</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">write_count</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_validate_cat_results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cat_results</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validate cat_results parameter.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">cat_results</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cat_results</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">))</span>
            <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">cat_results</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">cat_results</span> <span class="o">!=</span> <span class="s2">&quot;stack&quot;</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;cat_results must be a string (&#39;stack&#39;) &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;or an integer representing the cat dimension. Got </span><span class="si">{</span><span class="n">cat_results</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># Lazy import to avoid circular dependency</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.collectors._multi_sync</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultiSyncCollector</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">MultiSyncCollector</span><span class="p">)</span> <span class="ow">and</span> <span class="n">cat_results</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span>
            <span class="s2">&quot;stack&quot;</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;cat_results can only be used with ``MultiSyncCollector``.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cat_results</span> <span class="o">=</span> <span class="n">cat_results</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_check_replay_buffer_init</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="n">is_init</span> <span class="o">=</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">,</span> <span class="s2">&quot;_storage&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">getattr</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">_storage</span><span class="p">,</span> <span class="s2">&quot;initialized&quot;</span><span class="p">,</span> <span class="kc">True</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_init</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_init_rb</span><span class="p">:</span>
                <span class="c1"># New behavior: storage handles all coordination itself</span>
                <span class="c1"># Nothing to do here - the storage will coordinate during first write</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">share</span><span class="p">()</span>
                <span class="k">return</span>

            <span class="c1"># Legacy behavior: fake tensordict initialization</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">EnvCreator</span><span class="p">):</span>
                <span class="n">fake_td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">meta_data</span><span class="o">.</span><span class="n">tensordict</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">EnvBase</span><span class="p">):</span>
                <span class="n">fake_td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">fake_tensordict</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">fake_td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span>
                    <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_kwargs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="p">)</span><span class="o">.</span><span class="n">fake_tensordict</span><span class="p">()</span>
            <span class="n">fake_td</span><span class="p">[</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="n">fake_td</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span>
            <span class="p">)</span>
            <span class="c1"># Use extend to avoid time-related transforms to fail</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">fake_td</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_total_workers_from_env</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">env_creators</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_creators</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="bp">cls</span><span class="o">.</span><span class="n">_total_workers_from_env</span><span class="p">(</span><span class="n">env_creator</span><span class="p">)</span> <span class="k">for</span> <span class="n">env_creator</span> <span class="ow">in</span> <span class="n">env_creators</span>
            <span class="p">)</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs</span><span class="w"> </span><span class="kn">import</span> <span class="n">ParallelEnv</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_creators</span><span class="p">,</span> <span class="n">ParallelEnv</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">env_creators</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">return</span> <span class="mi">1</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_devices</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">storing_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">policy_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">env_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># convert all devices to lists</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">storing_device</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">storing_device</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">storing_device</span><span class="p">,</span>
            <span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy_device</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">policy_device</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">policy_device</span><span class="p">,</span>
            <span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_device</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">env_device</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">env_device</span><span class="p">,</span>
            <span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">device</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">device</span><span class="p">,</span>
            <span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">storing_device</span><span class="p">)</span>
            <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">policy_device</span><span class="p">)</span>
            <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">env_device</span><span class="p">)</span>
            <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;THe length of the devices does not match the number of workers: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="n">storing_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_device</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span>
                <span class="n">Collector</span><span class="o">.</span><span class="n">_get_devices</span><span class="p">(</span>
                    <span class="n">storing_device</span><span class="o">=</span><span class="n">storing_device</span><span class="p">,</span>
                    <span class="n">policy_device</span><span class="o">=</span><span class="n">policy_device</span><span class="p">,</span>
                    <span class="n">env_device</span><span class="o">=</span><span class="n">env_device</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="p">(</span><span class="n">storing_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_device</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                    <span class="n">storing_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_device</span><span class="p">,</span> <span class="n">device</span>
                <span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">storing_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_device</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">frames_per_batch_worker</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">worker_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_queue_len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_recv_and_check</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pipe</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">timeout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">check_interval</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">worker_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Receive from a pipe while periodically checking worker health.</span>

<span class="sd">        This method prevents the main process from hanging indefinitely if a worker</span>
<span class="sd">        dies while we&#39;re waiting for a response. It polls the pipe with a timeout</span>
<span class="sd">        and checks if all worker processes are still alive between polls.</span>

<span class="sd">        The overhead is minimal: if data is already available, `poll()` returns</span>
<span class="sd">        immediately and no health check is performed. Health checks only run</span>
<span class="sd">        when actually waiting for a slow response.</span>

<span class="sd">        Args:</span>
<span class="sd">            pipe: The pipe to receive from.</span>
<span class="sd">            timeout: Maximum total time to wait for a message (seconds).</span>
<span class="sd">                If None (default), wait indefinitely but still check worker health</span>
<span class="sd">                periodically.</span>
<span class="sd">            check_interval: How often to check worker health (seconds). Default 1.0.</span>
<span class="sd">            worker_idx: Optional worker index for error messages.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The received message.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: If a worker process dies while waiting.</span>
<span class="sd">            TimeoutError: If no message is received within the timeout (only if</span>
<span class="sd">                timeout is not None).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Fast path: check if data is already available (no overhead)</span>
        <span class="k">if</span> <span class="n">pipe</span><span class="o">.</span><span class="n">poll</span><span class="p">(</span><span class="mi">0</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">pipe</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>

        <span class="c1"># Slow path: wait with periodic health checks</span>
        <span class="n">elapsed</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">while</span> <span class="n">timeout</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">elapsed</span> <span class="o">&lt;</span> <span class="n">timeout</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">pipe</span><span class="o">.</span><span class="n">poll</span><span class="p">(</span><span class="n">check_interval</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">pipe</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
            <span class="n">elapsed</span> <span class="o">+=</span> <span class="n">check_interval</span>
            <span class="c1"># Check if any worker has died</span>
            <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>
            <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;MultiCollector._recv_and_check: Still waiting after </span><span class="si">{</span><span class="n">elapsed</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">s&quot;</span>
                <span class="o">+</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot; for worker </span><span class="si">{</span><span class="n">worker_idx</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="n">worker_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># Final check before timeout</span>
        <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>
        <span class="n">worker_info</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot; from worker </span><span class="si">{</span><span class="n">worker_idx</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="n">worker_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">TimeoutError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Timed out after </span><span class="si">{</span><span class="n">timeout</span><span class="si">}</span><span class="s2">s waiting for message</span><span class="si">{</span><span class="n">worker_info</span><span class="si">}</span><span class="s2">. &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;All workers are still alive - this may indicate a deadlock or very slow operation.&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_run_processes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_threads</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">total_workers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_workers_from_env</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_threads</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
                <span class="mi">1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_num_threads</span><span class="p">()</span> <span class="o">-</span> <span class="n">total_workers</span>
            <span class="p">)</span>  <span class="c1"># 1 more thread for this proc</span>

        <span class="c1"># Set up for worker processes</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_threads</span><span class="p">)</span>
        <span class="n">ctx</span> <span class="o">=</span> <span class="n">_get_mp_ctx</span><span class="p">()</span>
        <span class="c1"># Best-effort global init (only if unset) to keep other mp users consistent.</span>
        <span class="n">_set_mp_start_method_if_unset</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">get_start_method</span><span class="p">())</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s2">&quot;linux&quot;</span>
            <span class="ow">and</span> <span class="n">sys</span><span class="o">.</span><span class="n">version_info</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
            <span class="ow">and</span> <span class="n">ctx</span><span class="o">.</span><span class="n">get_start_method</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;spawn&quot;</span>
        <span class="p">):</span>
            <span class="n">strategy</span> <span class="o">=</span> <span class="n">_mp_sharing_strategy_for_spawn</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">strategy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">mp</span><span class="o">.</span><span class="n">set_sharing_strategy</span><span class="p">(</span><span class="n">strategy</span><span class="p">)</span>
        <span class="n">queue_out</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">Queue</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_queue_len</span><span class="p">)</span>  <span class="c1"># sends data from proc to main</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">procs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_traj_pool</span> <span class="o">=</span> <span class="n">_TrajectoryPool</span><span class="p">(</span><span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">lock</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Create all pipes upfront (needed for weight sync scheme initialization)</span>
        <span class="c1"># Store as list of (parent, child) tuples for use in worker creation</span>
        <span class="n">pipe_pairs</span> <span class="o">=</span> <span class="p">[</span><span class="n">ctx</span><span class="o">.</span><span class="n">Pipe</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">)]</span>
        <span class="c1"># Extract parent pipes for external use (e.g., polling, receiving messages)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span> <span class="o">=</span> <span class="p">[</span><span class="n">pipe_parent</span> <span class="k">for</span> <span class="n">pipe_parent</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">pipe_pairs</span><span class="p">]</span>

        <span class="n">_ProcessNoWarnCtx</span> <span class="o">=</span> <span class="n">_make_process_no_warn_cls</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
        <span class="c1"># Initialize all weight sync schemes now that pipes are available</span>
        <span class="c1"># Both SharedMemWeightSyncScheme (uses queues) and MultiProcessWeightSyncScheme (uses pipes)</span>
        <span class="c1"># can be initialized here since all required resources exist</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">model_id</span><span class="p">,</span> <span class="n">scheme</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">scheme</span><span class="o">.</span><span class="n">initialized_on_sender</span><span class="p">:</span>
                    <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Init weight sync scheme </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">scheme</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> for </span><span class="si">{</span><span class="n">model_id</span><span class="si">=}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>
                    <span class="n">scheme</span><span class="o">.</span><span class="n">init_on_sender</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">)</span>

        <span class="c1"># Create a policy on the right device</span>
        <span class="n">policy_factory</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_factory</span>
        <span class="n">has_policy_factory</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="n">policy_factory</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">has_policy_factory</span><span class="p">:</span>
            <span class="n">policy_factory</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">CloudpickleWrapper</span><span class="p">(</span><span class="n">_policy_factory</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">_policy_factory</span> <span class="ow">in</span> <span class="n">policy_factory</span>
            <span class="p">]</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">env_fun</span><span class="p">,</span> <span class="n">env_fun_kwargs</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
            <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_kwargs</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">pipe_parent</span><span class="p">,</span> <span class="n">pipe_child</span> <span class="o">=</span> <span class="n">pipe_pairs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>  <span class="c1"># use pre-created pipes</span>
            <span class="k">if</span> <span class="n">env_fun</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">!=</span> <span class="s2">&quot;EnvCreator&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">env_fun</span><span class="p">,</span> <span class="n">EnvBase</span>
            <span class="p">):</span>  <span class="c1"># to avoid circular imports</span>
                <span class="n">env_fun</span> <span class="o">=</span> <span class="n">CloudpickleWrapper</span><span class="p">(</span><span class="n">env_fun</span><span class="p">)</span>

            <span class="n">policy_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">storing_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">env_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="c1"># Prepare policy for worker based on weight synchronization method.</span>
            <span class="c1"># IMPORTANT: when a policy_factory is provided, the policy instance</span>
            <span class="c1"># is used ONLY on the main process (for weight extraction etc.) and</span>
            <span class="c1"># is NOT sent to workers.</span>
            <span class="n">policy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span><span class="p">:</span>
                <span class="c1"># With weight sync schemes, send stateless policies.</span>
                <span class="c1"># Schemes handle weight distribution on worker side.</span>
                <span class="k">if</span> <span class="n">has_policy_factory</span><span class="p">:</span>
                    <span class="c1"># Factory will create policy in worker; don&#39;t send policy.</span>
                    <span class="n">policy_to_send</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">cm</span> <span class="o">=</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">nullcontext</span><span class="p">()</span>
                <span class="k">elif</span> <span class="n">policy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># Send a stateless policy down to workers: schemes apply weights.</span>
                    <span class="n">policy_to_send</span> <span class="o">=</span> <span class="n">policy</span>
                    <span class="n">cm</span> <span class="o">=</span> <span class="n">_make_meta_policy_cm</span><span class="p">(</span>
                        <span class="n">policy</span><span class="p">,</span> <span class="n">mp_start_method</span><span class="o">=</span><span class="n">ctx</span><span class="o">.</span><span class="n">get_start_method</span><span class="p">()</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">policy_to_send</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">cm</span> <span class="o">=</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">nullcontext</span><span class="p">()</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_policy_weights_dict&quot;</span><span class="p">):</span>
                <span class="c1"># LEGACY:</span>
                <span class="c1"># With weight updater, use in-place weight replacement.</span>
                <span class="c1"># Take the weights and locally dispatch them to the policy before sending.</span>
                <span class="c1"># This ensures a given set of shared weights for a device are shared</span>
                <span class="c1"># for all policies that rely on that device.</span>
                <span class="n">policy_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_policy_weights_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">policy_device</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">has_policy_factory</span><span class="p">:</span>
                    <span class="c1"># Even in legacy mode, when a policy_factory is present, do not</span>
                    <span class="c1"># send the stateful policy down to workers.</span>
                    <span class="n">policy_to_send</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">cm</span> <span class="o">=</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">nullcontext</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">policy_to_send</span> <span class="o">=</span> <span class="n">policy</span>
                    <span class="k">if</span> <span class="n">policy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">policy_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">cm</span> <span class="o">=</span> <span class="n">policy_weights</span><span class="o">.</span><span class="n">to_module</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">cm</span> <span class="o">=</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">nullcontext</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Parameter-less policy.</span>
                <span class="n">cm</span> <span class="o">=</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">nullcontext</span><span class="p">()</span>
                <span class="c1"># When a policy_factory exists, never send the policy instance.</span>
                <span class="n">policy_to_send</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">has_policy_factory</span> <span class="k">else</span> <span class="n">policy</span>

            <span class="k">with</span> <span class="n">cm</span><span class="p">:</span>
                <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;policy_factory&quot;</span><span class="p">:</span> <span class="n">policy_factory</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="s2">&quot;pipe_child&quot;</span><span class="p">:</span> <span class="n">pipe_child</span><span class="p">,</span>
                    <span class="s2">&quot;queue_out&quot;</span><span class="p">:</span> <span class="n">queue_out</span><span class="p">,</span>
                    <span class="s2">&quot;create_env_fn&quot;</span><span class="p">:</span> <span class="n">env_fun</span><span class="p">,</span>
                    <span class="s2">&quot;create_env_kwargs&quot;</span><span class="p">:</span> <span class="n">env_fun_kwargs</span><span class="p">,</span>
                    <span class="s2">&quot;policy&quot;</span><span class="p">:</span> <span class="n">policy_to_send</span><span class="p">,</span>
                    <span class="s2">&quot;max_frames_per_traj&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_frames_per_traj</span><span class="p">,</span>
                    <span class="s2">&quot;frames_per_batch&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_batch_worker</span><span class="p">(</span><span class="n">worker_idx</span><span class="o">=</span><span class="n">i</span><span class="p">),</span>
                    <span class="s2">&quot;reset_at_each_iter&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_at_each_iter</span><span class="p">,</span>
                    <span class="s2">&quot;policy_device&quot;</span><span class="p">:</span> <span class="n">policy_device</span><span class="p">,</span>
                    <span class="s2">&quot;storing_device&quot;</span><span class="p">:</span> <span class="n">storing_device</span><span class="p">,</span>
                    <span class="s2">&quot;env_device&quot;</span><span class="p">:</span> <span class="n">env_device</span><span class="p">,</span>
                    <span class="s2">&quot;exploration_type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">exploration_type</span><span class="p">,</span>
                    <span class="s2">&quot;reset_when_done&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_when_done</span><span class="p">,</span>
                    <span class="s2">&quot;idx&quot;</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span>
                    <span class="s2">&quot;interruptor&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span><span class="p">,</span>
                    <span class="s2">&quot;set_truncated&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">set_truncated</span><span class="p">,</span>
                    <span class="s2">&quot;use_buffers&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span><span class="p">,</span>
                    <span class="s2">&quot;replay_buffer&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">,</span>
                    <span class="s2">&quot;extend_buffer&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">extend_buffer</span><span class="p">,</span>
                    <span class="s2">&quot;traj_pool&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_traj_pool</span><span class="p">,</span>
                    <span class="s2">&quot;trust_policy&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">trust_policy</span><span class="p">,</span>
                    <span class="s2">&quot;compile_policy&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy_kwargs</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy</span>
                    <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
                    <span class="s2">&quot;cudagraph_policy&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cudagraphed_policy_kwargs</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cudagraphed_policy</span>
                    <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
                    <span class="s2">&quot;no_cuda_sync&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span><span class="p">,</span>
                    <span class="s2">&quot;collector_class&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">collector_class</span><span class="p">,</span>
                    <span class="s2">&quot;postproc&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="s2">&quot;weight_sync_schemes&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span><span class="p">,</span>
                    <span class="s2">&quot;worker_idx&quot;</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span>  <span class="c1"># Worker index for queue-based weight distribution</span>
                    <span class="s2">&quot;init_random_frames&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span><span class="p">,</span>
                    <span class="s2">&quot;profile_config&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_profile_config</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="n">proc</span> <span class="o">=</span> <span class="n">_ProcessNoWarnCtx</span><span class="p">(</span>
                    <span class="n">target</span><span class="o">=</span><span class="n">_main_async_collector</span><span class="p">,</span>
                    <span class="n">num_threads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_sub_threads</span><span class="p">,</span>
                    <span class="n">_start_method</span><span class="o">=</span><span class="n">ctx</span><span class="o">.</span><span class="n">get_start_method</span><span class="p">(),</span>
                    <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="c1"># proc.daemon can&#39;t be set as daemonic processes may be launched by the process itself</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">proc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
                <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                    <span class="k">if</span> <span class="s2">&quot;cannot pickle&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">err</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                            <span class="s2">&quot;A non-serializable object was passed to the collector workers.&quot;</span>
                        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">err</span>
                <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                    <span class="k">if</span> <span class="s2">&quot;Cowardly refusing to serialize non-leaf tensor&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">err</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                            <span class="s2">&quot;At least one of the tensors in the policy, replay buffer, environment constructor or postprocessor requires gradients. &quot;</span>
                            <span class="s2">&quot;This is not supported in multiprocessed data collectors.</span><span class="se">\n</span><span class="s2">- For ReplayBuffer transforms, use a `transform_factory` instead with `delayed_init=True`.</span><span class="se">\n</span><span class="s2">&quot;</span>
                            <span class="s2">&quot;- Make sure your environment constructor does not reference tensors already instantiated on the main process.</span><span class="se">\n</span><span class="s2">&quot;</span>
                            <span class="s2">&quot;- Since no gradient can be propagated through the Collector pipes, the backward graph is never needed. Consider using detached tensors instead.&quot;</span>
                        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">err</span>
                    <span class="k">elif</span> <span class="s2">&quot;_share_fd_: only available on CPU&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span>
                        <span class="n">err</span>
                    <span class="p">)</span> <span class="ow">or</span> <span class="s2">&quot;_share_filename_: only available on CPU&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">err</span><span class="p">):</span>
                        <span class="c1"># This is a common failure mode on older PyTorch versions when using the</span>
                        <span class="c1"># &quot;spawn&quot; multiprocessing start method: the process object contains a</span>
                        <span class="c1"># CUDA/MPS tensor (or a module/buffer on a non-CPU device), which must be</span>
                        <span class="c1"># pickled when spawning workers.</span>
                        <span class="c1">#</span>
                        <span class="c1"># See: https://github.com/pytorch/pytorch/issues/87688#issuecomment-1968901877</span>
                        <span class="n">start_method</span> <span class="o">=</span> <span class="kc">None</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">start_method</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">get_start_method</span><span class="p">(</span><span class="n">allow_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                            <span class="c1"># Best effort: some environments may disallow querying here.</span>
                            <span class="n">start_method</span> <span class="o">=</span> <span class="kc">None</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                            <span class="s2">&quot;Failed to start a collector worker process because a non-CPU tensor &quot;</span>
                            <span class="s2">&quot;was captured in the worker process arguments and had to be serialized &quot;</span>
                            <span class="s2">&quot;(pickled) at process start.</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;Detected multiprocessing start method: </span><span class="si">{</span><span class="n">start_method</span><span class="si">!r}</span><span class="s2">.</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                            <span class="s2">&quot;Workarounds:</span><span class="se">\n</span><span class="s2">&quot;</span>
                            <span class="s2">&quot;- Keep any tensors/modules referenced by your collector constructor &quot;</span>
                            <span class="s2">&quot;(policy, replay buffer, postprocs, env factory captures, etc.) on CPU &quot;</span>
                            <span class="s2">&quot;when using a spawning start method (common on macOS/Windows).</span><span class="se">\n</span><span class="s2">&quot;</span>
                            <span class="s2">&quot;- Or set the multiprocessing start method to &#39;fork&#39; *before* creating &quot;</span>
                            <span class="s2">&quot;the collector (Unix only). Example:</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                            <span class="s2">&quot;    import torch.multiprocessing as mp</span><span class="se">\n</span><span class="s2">&quot;</span>
                            <span class="s2">&quot;    if __name__ == &#39;__main__&#39;:</span><span class="se">\n</span><span class="s2">&quot;</span>
                            <span class="s2">&quot;        mp.set_start_method(&#39;fork&#39;, force=True)</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                            <span class="s2">&quot;Upstream context: https://github.com/pytorch/pytorch/issues/87688#issuecomment-1968901877&quot;</span>
                        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">err</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="n">err</span>
                <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                    <span class="k">if</span> <span class="s2">&quot;bad value(s) in fds_to_keep&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">err</span><span class="p">):</span>
                        <span class="c1"># This error occurs on old Python versions (e.g., 3.9) with old PyTorch (e.g., 2.3)</span>
                        <span class="c1"># when using the spawn multiprocessing start method. The spawn implementation tries to</span>
                        <span class="c1"># preserve file descriptors across exec, but some descriptors may be invalid/closed.</span>
                        <span class="c1"># This is a compatibility issue with old Python multiprocessing implementations.</span>
                        <span class="n">python_version</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="o">.</span><span class="n">major</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="o">.</span><span class="n">minor</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Failed to start collector worker process due to file descriptor issues &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;with spawn multiprocessing on Python </span><span class="si">{</span><span class="n">python_version</span><span class="si">}</span><span class="s2">.</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;This is a known compatibility issue with old Python/PyTorch stacks. &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;Consider upgrading to Python &gt;= 3.10 and PyTorch &gt;= 2.5, or use the &#39;fork&#39; &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;multiprocessing start method on Unix systems.</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;Workarounds:</span><span class="se">\n</span><span class="s2">&quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;- Upgrade Python to &gt;= 3.10 and PyTorch to &gt;= 2.5</span><span class="se">\n</span><span class="s2">&quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;- On Unix systems, force fork start method:</span><span class="se">\n</span><span class="s2">&quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;  import torch.multiprocessing as mp</span><span class="se">\n</span><span class="s2">&quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;  if __name__ == &#39;__main__&#39;:</span><span class="se">\n</span><span class="s2">&quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;      mp.set_start_method(&#39;fork&#39;, force=True)</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;Upstream Python issue: https://github.com/python/cpython/issues/87706&quot;</span>
                        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">err</span>
                <span class="k">except</span> <span class="n">_pickle</span><span class="o">.</span><span class="n">PicklingError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                    <span class="k">if</span> <span class="s2">&quot;&lt;lambda&gt;&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">err</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
<span class="w">                            </span><span class="sd">&quot;&quot;&quot;Can&#39;t open a process with doubly cloud-pickled lambda function.</span>
<span class="sd">This error is likely due to an attempt to use a ParallelEnv in a</span>
<span class="sd">multiprocessed data collector. To do this, consider wrapping your</span>
<span class="sd">lambda function in an `torchrl.envs.EnvCreator` wrapper as follows:</span>
<span class="sd">`env = ParallelEnv(N, EnvCreator(my_lambda_function))`.</span>
<span class="sd">This will not only ensure that your lambda function is cloud-pickled once, but</span>
<span class="sd">also that the state dict is synchronised across processes if needed.&quot;&quot;&quot;</span>
                        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">err</span>
                <span class="n">pipe_child</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">proc</span><span class="p">)</span>

        <span class="c1"># Synchronize initial weights with workers AFTER starting processes but BEFORE waiting for &quot;instantiated&quot;</span>
        <span class="c1"># This must happen after proc.start() but before workers send &quot;instantiated&quot; to avoid deadlock:</span>
        <span class="c1"># Workers will call receiver.collect() during init and may block waiting for data</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span><span class="p">:</span>
            <span class="c1"># start with policy</span>
            <span class="n">policy_scheme</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;policy&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">policy_scheme</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">policy_scheme</span><span class="o">.</span><span class="n">connect</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">scheme</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;policy&quot;</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="n">scheme</span><span class="o">.</span><span class="n">connect</span><span class="p">()</span>

        <span class="c1"># Wait for workers to be ready</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">pipe_parent</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">):</span>
            <span class="n">pipe_parent</span><span class="o">.</span><span class="n">poll</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">INSTANTIATE_TIMEOUT</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="n">pipe_parent</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">EOFError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Worker </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> failed to initialize and closed the connection before sending status. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;This typically indicates that the worker process crashed during initialization. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Check the worker process logs for the actual error.&quot;</span>
                <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
            <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;instantiated&quot;</span><span class="p">:</span>
                <span class="c1"># Check if it&#39;s an error dict from worker</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="n">msg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;error&quot;</span><span class="p">):</span>
                    <span class="c1"># Reconstruct the exception from the worker</span>
                    <span class="n">exc_type_name</span> <span class="o">=</span> <span class="n">msg</span><span class="p">[</span><span class="s2">&quot;exception_type&quot;</span><span class="p">]</span>
                    <span class="n">exc_msg</span> <span class="o">=</span> <span class="n">msg</span><span class="p">[</span><span class="s2">&quot;exception_msg&quot;</span><span class="p">]</span>
                    <span class="n">traceback_str</span> <span class="o">=</span> <span class="n">msg</span><span class="p">[</span><span class="s2">&quot;traceback&quot;</span><span class="p">]</span>

                    <span class="c1"># Try to get the actual exception class</span>
                    <span class="n">exc_class</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">exc_module</span> <span class="o">=</span> <span class="n">msg</span><span class="p">[</span><span class="s2">&quot;exception_module&quot;</span><span class="p">]</span>

                    <span class="k">if</span> <span class="n">exc_module</span> <span class="o">==</span> <span class="s2">&quot;builtins&quot;</span><span class="p">:</span>
                        <span class="c1"># Get from builtins</span>
                        <span class="kn">import</span><span class="w"> </span><span class="nn">builtins</span>

                        <span class="n">exc_class</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builtins</span><span class="p">,</span> <span class="n">exc_type_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># Try to import from the module</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="kn">import</span><span class="w"> </span><span class="nn">importlib</span>

                            <span class="n">mod</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">import_module</span><span class="p">(</span><span class="n">exc_module</span><span class="p">)</span>
                            <span class="n">exc_class</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">exc_type_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                            <span class="k">pass</span>

                    <span class="c1"># Re-raise with original exception type if possible</span>
                    <span class="k">if</span> <span class="n">exc_class</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="n">exc_class</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">exc_msg</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">Worker traceback:</span><span class="se">\n</span><span class="si">{</span><span class="n">traceback_str</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># Fall back to RuntimeError if we can&#39;t get the original type</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Worker </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> raised </span><span class="si">{</span><span class="n">exc_type_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">exc_msg</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">Worker traceback:</span><span class="se">\n</span><span class="si">{</span><span class="n">traceback_str</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Legacy string error message</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span> <span class="o">=</span> <span class="n">queue_out</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="n">_running_free</span> <span class="o">=</span> <span class="kc">False</span>

<div class="viewcode-block" id="MultiCollector.start"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector.start">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">start</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Starts the collector(s) for asynchronous data collection.</span>

<span class="sd">        The collected data is stored in the provided replay buffer. This method initiates the background collection of</span>
<span class="sd">        data across multiple processes, allowing for decoupling of data collection and training.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: If no replay buffer is defined during the collector&#39;s initialization.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.modules import RandomPolicy            &gt;&gt;&gt;             &gt;&gt;&gt; import time</span>
<span class="sd">            &gt;&gt;&gt; from functools import partial</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; import tqdm</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.collectors import MultiAsyncCollector</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.data import LazyTensorStorage, ReplayBuffer</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs import GymEnv, set_gym_backend</span>
<span class="sd">            &gt;&gt;&gt; import ale_py</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Set the gym backend to gymnasium</span>
<span class="sd">            &gt;&gt;&gt; set_gym_backend(&quot;gymnasium&quot;).set()</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; if __name__ == &quot;__main__&quot;:</span>
<span class="sd">            ...     # Create a random policy for the Pong environment</span>
<span class="sd">            ...     env_fn = partial(GymEnv, &quot;ALE/Pong-v5&quot;)</span>
<span class="sd">            ...     policy = RandomPolicy(env_fn().action_spec)</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Initialize a shared replay buffer</span>
<span class="sd">            ...     rb = ReplayBuffer(storage=LazyTensorStorage(10000), shared=True)</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Create a multi-async data collector with 16 environments</span>
<span class="sd">            ...     num_envs = 16</span>
<span class="sd">            ...     collector = MultiAsyncCollector(</span>
<span class="sd">            ...         [env_fn] * num_envs,</span>
<span class="sd">            ...         policy=policy,</span>
<span class="sd">            ...         replay_buffer=rb,</span>
<span class="sd">            ...         frames_per_batch=num_envs * 16,</span>
<span class="sd">            ...         total_frames=-1,</span>
<span class="sd">            ...     )</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Progress bar to track the number of collected frames</span>
<span class="sd">            ...     pbar = tqdm.tqdm(total=100_000)</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Start the collector asynchronously</span>
<span class="sd">            ...     collector.start()</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Track the write count of the replay buffer</span>
<span class="sd">            ...     prec_wc = 0</span>
<span class="sd">            ...     while True:</span>
<span class="sd">            ...         wc = rb.write_count</span>
<span class="sd">            ...         c = wc - prec_wc</span>
<span class="sd">            ...         prec_wc = wc</span>
<span class="sd">            ...</span>
<span class="sd">            ...         # Update the progress bar</span>
<span class="sd">            ...         pbar.update(c)</span>
<span class="sd">            ...         pbar.set_description(f&quot;Write Count: {rb.write_count}&quot;)</span>
<span class="sd">            ...</span>
<span class="sd">            ...         # Check the write count every 0.5 seconds</span>
<span class="sd">            ...         time.sleep(0.5)</span>
<span class="sd">            ...</span>
<span class="sd">            ...         # Stop when the desired number of frames is reached</span>
<span class="sd">            ...         if rb.write_count . 100_000:</span>
<span class="sd">            ...             break</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Shut down the collector</span>
<span class="sd">            ...     collector.async_shutdown()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Replay buffer must be defined for execution.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_running_free</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;MultiCollector.start(): Sending run_free to </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">)</span><span class="si">}</span><span class="s2"> workers...&quot;</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">pipe</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">):</span>
            <span class="n">pipe</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;run_free&quot;</span><span class="p">))</span>
            <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MultiCollector.start(): Sent run_free to worker </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="MultiCollector.pause"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector.pause">[docs]</a>    <span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">pause</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Context manager that pauses the collector if it is running free.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_running_free</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">pipe</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">:</span>
                <span class="n">pipe</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;pause&quot;</span><span class="p">))</span>
            <span class="c1"># Make sure all workers are paused</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">)):</span>
                <span class="c1"># Use timeout with health check to avoid hanging if a worker dies</span>
                <span class="n">timeout</span> <span class="o">=</span> <span class="mf">30.0</span>
                <span class="n">check_interval</span> <span class="o">=</span> <span class="mf">1.0</span>
                <span class="n">elapsed</span> <span class="o">=</span> <span class="mf">0.0</span>
                <span class="k">while</span> <span class="n">elapsed</span> <span class="o">&lt;</span> <span class="n">timeout</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">idx</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">check_interval</span><span class="p">)</span>
                        <span class="k">break</span>
                    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                        <span class="n">elapsed</span> <span class="o">+=</span> <span class="n">check_interval</span>
                        <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>
                    <span class="k">raise</span> <span class="ne">TimeoutError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Timed out waiting for worker </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> to pause after </span><span class="si">{</span><span class="n">timeout</span><span class="si">}</span><span class="s2">s&quot;</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;paused&quot;</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected paused, but got </span><span class="si">{</span><span class="n">msg</span><span class="si">=}</span><span class="s2">.&quot;</span><span class="p">)</span>
                <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> is paused.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_running_free</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">yield</span> <span class="kc">None</span>
            <span class="k">for</span> <span class="n">pipe</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">:</span>
                <span class="n">pipe</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;restart&quot;</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_running_free</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Collector cannot be paused.&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="MultiCollector.enable_profile"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector.enable_profile">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">enable_profile</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Enable profiling for collector worker rollouts.</span>

<span class="sd">        For multi-process collectors, this sends the profile configuration</span>
<span class="sd">        to the specified workers. Must be called before iteration starts.</span>

<span class="sd">        See :meth:`BaseCollector.enable_profile` for full documentation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># First, call parent to validate and set _profile_config</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">enable_profile</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Send profile config to workers that should be profiled</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_profile_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_profile_config</span><span class="o">.</span><span class="n">workers</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_profile_config</span><span class="p">,</span> <span class="s2">&quot;enable_profile&quot;</span><span class="p">))</span>

            <span class="c1"># Wait for confirmation from workers</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_profile_config</span><span class="o">.</span><span class="n">workers</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">poll</span><span class="p">(</span><span class="n">INSTANTIATE_TIMEOUT</span><span class="p">):</span>
                        <span class="n">_</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
                        <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;profile_enabled&quot;</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">: Expected &#39;profile_enabled&#39; message, got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span>
                            <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">TimeoutError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">: Timed out waiting for profile confirmation.&quot;</span>
                        <span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="c1"># an AttributeError will typically be raised if the collector is deleted when the program ends.</span>
            <span class="c1"># In the future, insignificant changes to the close method may change the error type.</span>
            <span class="c1"># We excplicitely assume that any error raised during closure in</span>
            <span class="c1"># __del__ will not affect the program.</span>
            <span class="k">pass</span>

<div class="viewcode-block" id="MultiCollector.shutdown"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector.shutdown">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">shutdown</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">timeout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">close_env</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">raise_on_error</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Shuts down all processes. This operation is irreversible.</span>

<span class="sd">        Args:</span>
<span class="sd">            timeout (float, optional): The timeout for closing pipes between workers.</span>
<span class="sd">            close_env (bool, optional): Whether to close the environment. Defaults to `True`.</span>
<span class="sd">            raise_on_error (bool, optional): Whether to raise an error if the shutdown fails. Defaults to `True`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">close_env</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Cannot shutdown </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> collector without environment being closed.&quot;</span>
            <span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shutdown_main</span><span class="p">(</span><span class="n">timeout</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">raise_on_error</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">e</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">pass</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_shutdown_main</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timeout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">timeout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">timeout</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
                <span class="k">return</span>
            <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>
            <span class="n">all_closed</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
            <span class="n">rep</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">all_closed</span><span class="p">[</span><span class="n">idx</span><span class="p">]:</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">is_alive</span><span class="p">():</span>
                    <span class="k">continue</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;close&quot;</span><span class="p">))</span>

            <span class="k">while</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">all_closed</span><span class="p">)</span> <span class="ow">and</span> <span class="n">rep</span> <span class="o">&lt;</span> <span class="mi">1000</span><span class="p">:</span>
                <span class="n">rep</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">all_closed</span><span class="p">[</span><span class="n">idx</span><span class="p">]:</span>
                        <span class="k">continue</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">is_alive</span><span class="p">():</span>
                        <span class="n">all_closed</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="k">continue</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">poll</span><span class="p">(</span><span class="n">timeout</span> <span class="o">/</span> <span class="mi">1000</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                            <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
                            <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;closed&quot;</span><span class="p">:</span>
                                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2"> but expected &#39;close&#39;&quot;</span><span class="p">)</span>
                            <span class="n">all_closed</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">continue</span>
                    <span class="k">except</span> <span class="ne">BrokenPipeError</span><span class="p">:</span>
                        <span class="n">all_closed</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="k">continue</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">pipe</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">:</span>
                <span class="n">pipe</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">proc</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">:</span>
                <span class="n">proc</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">torchrl</span>

            <span class="n">num_threads</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
                <span class="n">torchrl</span><span class="o">.</span><span class="n">_THREAD_POOL_INIT</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">get_num_threads</span><span class="p">()</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_workers_from_env</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span><span class="p">(</span><span class="n">num_threads</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">proc</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">proc</span><span class="o">.</span><span class="n">is_alive</span><span class="p">():</span>
                    <span class="n">proc</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>

<div class="viewcode-block" id="MultiCollector.async_shutdown"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector.async_shutdown">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">async_shutdown</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timeout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">)</span></div>

<div class="viewcode-block" id="MultiCollector.set_seed"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector.set_seed">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sets the seeds of the environments stored in the DataCollector.</span>

<span class="sd">        Args:</span>
<span class="sd">            seed: integer representing the seed to be used for the environment.</span>
<span class="sd">            static_seed (bool, optional): if ``True``, the seed is not incremented.</span>
<span class="sd">                Defaults to False</span>

<span class="sd">        Returns:</span>
<span class="sd">            Output seed. This is useful when more than one environment is</span>
<span class="sd">            contained in the DataCollector, as the seed will be incremented for</span>
<span class="sd">            each of these. The resulting seed is the seed of the last</span>
<span class="sd">            environment.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs import ParallelEnv</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">            &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">            &gt;&gt;&gt; from torch import nn</span>
<span class="sd">            &gt;&gt;&gt; env_fn = lambda: GymEnv(&quot;Pendulum-v1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; env_fn_parallel = lambda: ParallelEnv(6, env_fn)</span>
<span class="sd">            &gt;&gt;&gt; policy = TensorDictModule(nn.Linear(3, 1), in_keys=[&quot;observation&quot;], out_keys=[&quot;action&quot;])</span>
<span class="sd">            &gt;&gt;&gt; collector = Collector(env_fn_parallel, policy, frames_per_batch=100, total_frames=300)</span>
<span class="sd">            &gt;&gt;&gt; out_seed = collector.set_seed(1)  # out_seed = 6</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">(((</span><span class="n">seed</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">),</span> <span class="s2">&quot;seed&quot;</span><span class="p">))</span>
            <span class="n">new_seed</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recv_and_check</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">worker_idx</span><span class="o">=</span><span class="n">idx</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;seeded&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected msg=&#39;seeded&#39;, got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">seed</span> <span class="o">=</span> <span class="n">new_seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">seed</span></div>

<div class="viewcode-block" id="MultiCollector.reset"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector.reset">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reset_idx</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Resets the environments to a new initial state.</span>

<span class="sd">        Args:</span>
<span class="sd">            reset_idx: Optional. Sequence indicating which environments have</span>
<span class="sd">                to be reset. If None, all environments are reset.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">reset_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">reset_idx</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">reset_idx</span><span class="p">[</span><span class="n">idx</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;reset&quot;</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">reset_idx</span><span class="p">[</span><span class="n">idx</span><span class="p">]:</span>
                <span class="n">j</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recv_and_check</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">worker_idx</span><span class="o">=</span><span class="n">idx</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;reset&quot;</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected msg=&#39;reset&#39;, got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="MultiCollector.state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector.state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the state_dict of the data collector.</span>

<span class="sd">        Each field represents a worker containing its own state_dict.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;state_dict&quot;</span><span class="p">))</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="n">_state_dict</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recv_and_check</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">worker_idx</span><span class="o">=</span><span class="n">idx</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;state_dict&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected msg=&#39;state_dict&#39;, got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">state_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;worker</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_state_dict</span>
        <span class="n">state_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;frames&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span><span class="p">,</span> <span class="s2">&quot;iter&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span><span class="p">})</span>

        <span class="k">return</span> <span class="n">state_dict</span></div>

<div class="viewcode-block" id="MultiCollector.load_state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector.load_state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Loads the state_dict on the workers.</span>

<span class="sd">        Args:</span>
<span class="sd">            state_dict (OrderedDict): state_dict of the form</span>
<span class="sd">                ``{&quot;worker0&quot;: state_dict0, &quot;worker1&quot;: state_dict1}``.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">state_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;worker</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">],</span> <span class="s2">&quot;load_state_dict&quot;</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recv_and_check</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">worker_idx</span><span class="o">=</span><span class="n">idx</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;loaded&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected msg=&#39;loaded&#39;, got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;iter&quot;</span><span class="p">]</span></div>

<div class="viewcode-block" id="MultiCollector.increment_version"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector.increment_version">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">increment_version</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Increment the policy version.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span><span class="p">,</span> <span class="s2">&quot;increment_version&quot;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Policy version tracker is not a PolicyVersion instance. Please pass a PolicyVersion instance to the collector.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span><span class="o">.</span><span class="n">increment_version</span><span class="p">()</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">policy_version</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The current policy version.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span><span class="p">,</span> <span class="s2">&quot;version&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span><span class="o">.</span><span class="n">version</span>

<div class="viewcode-block" id="MultiCollector.get_policy_version"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector.get_policy_version">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_policy_version</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the current policy version.</span>

<span class="sd">        This method exists to support remote calls in Ray actors, since properties</span>
<span class="sd">        cannot be accessed directly through Ray&#39;s RPC mechanism.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The current version number (int) or UUID (str), or None if version tracking is disabled.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_version</span></div>

<div class="viewcode-block" id="MultiCollector.getattr_policy"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector.getattr_policy">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">getattr_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get an attribute from the policy of the first worker.</span>

<span class="sd">        Args:</span>
<span class="sd">            attr (str): The attribute name to retrieve from the policy.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The attribute value from the policy of the first worker.</span>

<span class="sd">        Raises:</span>
<span class="sd">            AttributeError: If the attribute doesn&#39;t exist on the policy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>

        <span class="c1"># Send command to first worker (index 0)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">attr</span><span class="p">,</span> <span class="s2">&quot;getattr_policy&quot;</span><span class="p">))</span>
        <span class="n">result</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recv_and_check</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">worker_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;getattr_policy&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected msg=&#39;getattr_policy&#39;, got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># If the worker returned an AttributeError, re-raise it</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">result</span>

        <span class="k">return</span> <span class="n">result</span></div>

<div class="viewcode-block" id="MultiCollector.getattr_env"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector.getattr_env">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">getattr_env</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get an attribute from the environment of the first worker.</span>

<span class="sd">        Args:</span>
<span class="sd">            attr (str): The attribute name to retrieve from the environment.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The attribute value from the environment of the first worker.</span>

<span class="sd">        Raises:</span>
<span class="sd">            AttributeError: If the attribute doesn&#39;t exist on the environment.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>

        <span class="c1"># Send command to first worker (index 0)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">attr</span><span class="p">,</span> <span class="s2">&quot;getattr_env&quot;</span><span class="p">))</span>
        <span class="n">result</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recv_and_check</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">worker_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;getattr_env&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected msg=&#39;getattr_env&#39;, got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># If the worker returned an AttributeError, re-raise it</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">result</span>

        <span class="k">return</span> <span class="n">result</span></div>

<div class="viewcode-block" id="MultiCollector.getattr_rb"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector.getattr_rb">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">getattr_rb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get an attribute from the replay buffer.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span></div>

<div class="viewcode-block" id="MultiCollector.get_model"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector.get_model">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get model instance by ID (for weight sync schemes).</span>

<span class="sd">        Args:</span>
<span class="sd">            model_id: Model identifier (e.g., &quot;policy&quot;, &quot;value_net&quot;)</span>

<span class="sd">        Returns:</span>
<span class="sd">            The model instance</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If model_id is not recognized</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">model_id</span> <span class="o">==</span> <span class="s2">&quot;policy&quot;</span><span class="p">:</span>
            <span class="c1"># Return the fallback policy instance</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">fallback_policy</span> <span class="o">:=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_fallback_policy&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">fallback_policy</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;policy&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No policy found for model_id &#39;</span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Try to resolve via attribute access</span>
            <span class="k">return</span> <span class="n">_resolve_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">)</span></div>

<div class="viewcode-block" id="MultiCollector.get_cached_weights"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector.get_cached_weights">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_cached_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get cached shared memory weights if available (for weight sync schemes).</span>

<span class="sd">        Args:</span>
<span class="sd">            model_id: Model identifier</span>

<span class="sd">        Returns:</span>
<span class="sd">            Cached TensorDict weights or None if not available</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">model_id</span> <span class="o">==</span> <span class="s2">&quot;policy&quot;</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_policy_weights_dict&quot;</span><span class="p">):</span>
            <span class="c1"># Get the policy device (first device if list)</span>
            <span class="n">policy_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy_device</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="n">policy_device</span> <span class="o">=</span> <span class="n">policy_device</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">policy_device</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>

            <span class="c1"># Return cached weights for this device</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_policy_weights_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">policy_device</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_weight_update_impl</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">policy_or_weights</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">|</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">worker_ids</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">weights_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update weights on workers.</span>

<span class="sd">        Weight sync schemes now use background threads on the receiver side.</span>
<span class="sd">        The scheme&#39;s send() method:</span>
<span class="sd">        1. Puts weights in the queue (or updates shared memory)</span>
<span class="sd">        2. Sends a &quot;receive&quot; instruction to the worker&#39;s background thread</span>
<span class="sd">        3. Waits for acknowledgment (if sync=True)</span>

<span class="sd">        No pipe signaling is needed - the scheme handles everything internally.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Call parent implementation which calls scheme.send()</span>
        <span class="c1"># The scheme handles instruction delivery and acknowledgments</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_weight_update_impl</span><span class="p">(</span>
            <span class="n">policy_or_weights</span><span class="o">=</span><span class="n">policy_or_weights</span><span class="p">,</span>
            <span class="n">worker_ids</span><span class="o">=</span><span class="n">worker_ids</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
            <span class="n">weights_dict</span><span class="o">=</span><span class="n">weights_dict</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiCollector.receive_weights"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiCollector.html#torchrl.collectors.MultiCollector.receive_weights">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">receive_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">policy_or_weights</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">receive_weights</span><span class="p">(</span><span class="n">policy_or_weights</span><span class="p">)</span></div>

    <span class="c1"># for RPC</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_receive_weights_scheme</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_receive_weights_scheme</span><span class="p">()</span></div>


<span class="c1"># Backward-compatible alias (deprecated, use MultiCollector instead)</span>
<span class="n">MultiCollector</span> <span class="o">=</span> <span class="n">MultiCollector</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
         <script src="../../../_static/jquery.js"></script>
         <script src="../../../_static/underscore.js"></script>
         <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../_static/doctools.js"></script>
         <script src="../../../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrl = $("#tutorial-type").text();
	      var githubLink = "https://github.com/pytorch/rl/blob/main/tutorials/sphinx-"  + tutorialUrl + ".py",
		  notebookLink = $(".sphx-glr-download-jupyter").find(".download.reference")[0].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/rl/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }

          var overwrite = function(_) {
              if ($(this).length > 0) {
                  $(this)[0].href = "https://github.com/pytorch/rl"
              }
          }
          // PC
          $(".main-menu a:contains('GitHub')").each(overwrite);
          // Mobile
          $(".main-menu a:contains('Github')").each(overwrite);
      });

      
       $(window).ready(function() {
           var original = window.sideMenus.bind;
           var startup = true;
           window.sideMenus.bind = function() {
               original();
               if (startup) {
                   $("#pytorch-right-menu a.reference.internal").each(function(i) {
                       if (this.classList.contains("not-expanded")) {
                           this.nextElementSibling.style.display = "block";
                           this.classList.remove("not-expanded");
                           this.classList.add("expanded");
                       }
                   });
                   startup = false;
               }
           };
       });
    </script>

    


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch Documentation</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">Newsletter</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">Cloud Credit Program</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">Technical Advisory Council</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">Staff</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">Contact Us</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>
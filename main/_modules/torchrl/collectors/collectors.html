


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchrl.collectors.collectors &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','UA-117752657-2');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="../../../../versions.html"><span style="font-size:110%">main (0.7.0+3acf491) &#x25BC</span></a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-0.html">Get started with Environments, TED and transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-1.html">Get started with TorchRLâ€™s modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-2.html">Getting started with model optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-3.html">Get started with data collection and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-4.html">Get started with logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-5.html">Get started with your own first training loop</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/coding_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/torchrl_demo.html">Introduction to TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/multiagent_ppo.html">Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/torchrl_envs.html">TorchRL envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/pretrained_models.html">Using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/dqn_with_rnn.html">Recurrent DQN: Training recurrent policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/rb_tutorial.html">Using Replay Buffers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/export.html">Exporting TorchRL modules</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/multiagent_competitive_ddpg.html">Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/coding_ddpg.html">TorchRL objectives: Coding a DDPG loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/coding_dqn.html">TorchRL trainer: A DQN example</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
      <li>torchrl.collectors.collectors</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
    
    
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=UA-117752657-2"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torchrl.collectors.collectors</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">_pickle</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">abc</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">collections</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">contextlib</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">functools</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">queue</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">typing</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">defaultdict</span><span class="p">,</span> <span class="n">OrderedDict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">multiprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">connection</span><span class="p">,</span> <span class="n">queues</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">multiprocessing.managers</span><span class="w"> </span><span class="kn">import</span> <span class="n">SyncManager</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">queue</span><span class="w"> </span><span class="kn">import</span> <span class="n">Empty</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">textwrap</span><span class="w"> </span><span class="kn">import</span> <span class="n">indent</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Iterator</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">LazyStackedTensorDict</span><span class="p">,</span>
    <span class="n">TensorDict</span><span class="p">,</span>
    <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="n">TensorDictParams</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">NO_DEFAULT</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">CudaGraphModule</span><span class="p">,</span> <span class="n">TensorDictModule</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">Buffer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">multiprocessing</span> <span class="k">as</span> <span class="n">mp</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Parameter</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">IterableDataset</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl._utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_check_for_faulty_process</span><span class="p">,</span>
    <span class="n">_ends_with</span><span class="p">,</span>
    <span class="n">_make_ordinal_device</span><span class="p">,</span>
    <span class="n">_ProcessNoWarn</span><span class="p">,</span>
    <span class="n">_replace_last</span><span class="p">,</span>
    <span class="n">accept_remote_rref_udf_invocation</span><span class="p">,</span>
    <span class="n">compile_with_warmup</span><span class="p">,</span>
    <span class="n">logger</span> <span class="k">as</span> <span class="n">torchrl_logger</span><span class="p">,</span>
    <span class="n">prod</span><span class="p">,</span>
    <span class="n">RL_WARNINGS</span><span class="p">,</span>
    <span class="n">VERBOSE</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.collectors.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">split_trajectories</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">ReplayBuffer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data.tensor_specs</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorSpec</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">CloudpickleWrapper</span><span class="p">,</span> <span class="n">DEVICE_TYPING</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.common</span><span class="w"> </span><span class="kn">import</span> <span class="n">_do_nothing</span><span class="p">,</span> <span class="n">EnvBase</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.env_creator</span><span class="w"> </span><span class="kn">import</span> <span class="n">EnvCreator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="n">StepCounter</span><span class="p">,</span> <span class="n">TransformedEnv</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_aggregate_end_of_traj</span><span class="p">,</span>
    <span class="n">_make_compatible_policy</span><span class="p">,</span>
    <span class="n">ExplorationType</span><span class="p">,</span>
    <span class="n">RandomPolicy</span><span class="p">,</span>
    <span class="n">set_exploration_type</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">torch.compiler</span><span class="w"> </span><span class="kn">import</span> <span class="n">cudagraph_mark_step_begin</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">cudagraph_mark_step_begin</span><span class="p">():</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Placeholder for missing cudagraph_mark_step_begin method.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;cudagraph_mark_step_begin not implemented.&quot;</span><span class="p">)</span>


<span class="n">_TIMEOUT</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">INSTANTIATE_TIMEOUT</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">_MIN_TIMEOUT</span> <span class="o">=</span> <span class="mf">1e-3</span>  <span class="c1"># should be several orders of magnitude inferior wrt time spent collecting a trajectory</span>
<span class="c1"># MAX_IDLE_COUNT is the maximum number of times a Dataloader worker can timeout with his queue.</span>
<span class="n">_MAX_IDLE_COUNT</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;MAX_IDLE_COUNT&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">iinfo</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">))</span>

<span class="n">DEFAULT_EXPLORATION_TYPE</span><span class="p">:</span> <span class="n">ExplorationType</span> <span class="o">=</span> <span class="n">ExplorationType</span><span class="o">.</span><span class="n">RANDOM</span>

<span class="n">_is_osx</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">platform</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;darwin&quot;</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_Interruptor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A class for managing the collection state of a process.</span>

<span class="sd">    This class provides methods to start and stop collection, and to check</span>
<span class="sd">    whether collection has been stopped. The collection state is protected</span>
<span class="sd">    by a lock to ensure thread-safety.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># interrupter vs interruptor: google trends seems to indicate that &quot;or&quot; is more</span>
    <span class="c1"># widely used than &quot;er&quot; even if my IDE complains about that...</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_collect</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Lock</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">start_collection</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_collect</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">stop_collection</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_collect</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">collection_stopped</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_collect</span> <span class="ow">is</span> <span class="kc">False</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_InterruptorManager</span><span class="p">(</span><span class="n">SyncManager</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A custom SyncManager for managing the collection state of a process.</span>

<span class="sd">    This class extends the SyncManager class and allows to share an Interruptor object</span>
<span class="sd">    between processes.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">pass</span>


<span class="n">_InterruptorManager</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;_Interruptor&quot;</span><span class="p">,</span> <span class="n">_Interruptor</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">recursive_map_to_cpu</span><span class="p">(</span><span class="n">dictionary</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Maps the tensors to CPU through a nested dictionary.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">OrderedDict</span><span class="p">(</span>
        <span class="o">**</span><span class="p">{</span>
            <span class="n">k</span><span class="p">:</span> <span class="n">recursive_map_to_cpu</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">OrderedDict</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">item</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">item</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>
    <span class="p">)</span>


<div class="viewcode-block" id="DataCollectorBase"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.DataCollectorBase.html#torchrl.collectors.DataCollectorBase">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">DataCollectorBase</span><span class="p">(</span><span class="n">IterableDataset</span><span class="p">,</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">abc</span><span class="o">.</span><span class="n">ABCMeta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for data collectors.&quot;&quot;&quot;</span>

    <span class="n">_iterator</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">total_frames</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">requested_frames_per_batch</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">frames_per_batch</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">trust_policy</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">compiled_policy</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">cudagraphed_policy</span><span class="p">:</span> <span class="nb">bool</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_policy_and_device</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">policy</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">observation_spec</span><span class="p">:</span> <span class="n">TensorSpec</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">policy_device</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="n">NO_DEFAULT</span><span class="p">,</span>
        <span class="n">env_maker</span><span class="p">:</span> <span class="n">Any</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">env_maker_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorDictModule</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="nb">dict</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Util method to get a policy and its device given the collector __init__ inputs.</span>

<span class="sd">        We want to copy the policy and then move the data there, not call policy.to(device).</span>

<span class="sd">        Args:</span>
<span class="sd">            policy (TensorDictModule, optional): a policy to be used</span>
<span class="sd">            observation_spec (TensorSpec, optional): spec of the observations</span>
<span class="sd">            policy_device (torch.device, optional): the device where the policy should be placed.</span>
<span class="sd">                Defaults to self.policy_device</span>
<span class="sd">            env_maker (a callable or a batched env, optional): the env_maker function for this device/policy pair.</span>
<span class="sd">            env_maker_kwargs (a dict, optional): the env_maker function kwargs.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">policy_device</span> <span class="ow">is</span> <span class="n">NO_DEFAULT</span><span class="p">:</span>
            <span class="n">policy_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trust_policy</span><span class="p">:</span>
            <span class="n">env</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;env&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">policy</span> <span class="o">=</span> <span class="n">_make_compatible_policy</span><span class="p">(</span>
                <span class="n">policy</span><span class="p">,</span>
                <span class="n">observation_spec</span><span class="p">,</span>
                <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">,</span>
                <span class="n">env_maker</span><span class="o">=</span><span class="n">env_maker</span><span class="p">,</span>
                <span class="n">env_maker_kwargs</span><span class="o">=</span><span class="n">env_maker_kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">policy_device</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">policy</span><span class="p">,</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="n">param_and_buf</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="o">.</span><span class="n">from_module</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">as_module</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Because we want to reach the warning</span>
            <span class="n">param_and_buf</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">()</span>

        <span class="n">i</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">param_and_buf</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">policy_device</span><span class="p">:</span>
                <span class="c1"># Then we need casting</span>
                <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trust_policy</span><span class="p">:</span>
                <span class="c1"># We trust that the policy policy device is adequate</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;A policy device was provided but no parameter/buffer could be found in &quot;</span>
                    <span class="s2">&quot;the policy. Casting to policy_device is therefore impossible. &quot;</span>
                    <span class="s2">&quot;The collector will trust that the devices match. To suppress this &quot;</span>
                    <span class="s2">&quot;warning, set `trust_policy=True` when building the collector.&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">policy</span><span class="p">,</span> <span class="kc">None</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">map_weight</span><span class="p">(</span>
            <span class="n">weight</span><span class="p">,</span>
            <span class="n">policy_device</span><span class="o">=</span><span class="n">policy_device</span><span class="p">,</span>
        <span class="p">):</span>

            <span class="n">is_param</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">)</span>
            <span class="n">is_buffer</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">Buffer</span><span class="p">)</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">data</span>
            <span class="k">if</span> <span class="n">weight</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">policy_device</span><span class="p">:</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">policy_device</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">weight</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">,):</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">is_param</span><span class="p">:</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">is_buffer</span><span class="p">:</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="n">Buffer</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">weight</span>

        <span class="c1"># Create a stateless policy, then populate this copy with params on device</span>
        <span class="n">get_original_weights</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">TensorDict</span><span class="o">.</span><span class="n">from_module</span><span class="p">,</span> <span class="n">policy</span><span class="p">)</span>
        <span class="c1"># We need to use &quot;.data&quot; otherwise buffers may disappear from the `get_original_weights` function</span>
        <span class="k">with</span> <span class="n">param_and_buf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;meta&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to_module</span><span class="p">(</span><span class="n">policy</span><span class="p">):</span>
            <span class="n">policy</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>

        <span class="n">param_and_buf</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
            <span class="n">map_weight</span><span class="p">,</span>
            <span class="n">filter_empty</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to_module</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">policy</span><span class="p">,</span> <span class="n">get_original_weights</span>

<div class="viewcode-block" id="DataCollectorBase.update_policy_weights_"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.DataCollectorBase.html#torchrl.collectors.DataCollectorBase.update_policy_weights_">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">update_policy_weights_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">policy_weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updates the policy weights if the policy of the data collector and the trained policy live on different devices.</span>

<span class="sd">        Args:</span>
<span class="sd">            policy_weights (TensorDictBase, optional): if provided, a TensorDict containing</span>
<span class="sd">                the weights of the policy to be used for the udpdate.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">policy_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_weights</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">update_</span><span class="p">(</span><span class="n">policy_weights</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_weights_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_weights</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">update_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_weights_fn</span><span class="p">())</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">]:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">yield from</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">next</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iterator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_iterator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_iterator</span><span class="p">)</span>
            <span class="c1"># if any, we don&#39;t want the device ref to be passed in distributed settings</span>
            <span class="n">out</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">out</span>
        <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">shutdown</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">iterator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_read_compile_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">compile_policy</span><span class="p">,</span> <span class="n">cudagraph_policy</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy</span> <span class="o">=</span> <span class="n">compile_policy</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cudagraphed_policy</span> <span class="o">=</span> <span class="n">cudagraph_policy</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy_kwargs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">{}</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">compile_policy</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Mapping</span><span class="p">)</span> <span class="k">else</span> <span class="n">compile_policy</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cudagraphed_policy_kwargs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">{}</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cudagraph_policy</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Mapping</span><span class="p">)</span> <span class="k">else</span> <span class="n">cudagraph_policy</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">string</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">()&quot;</span>
        <span class="k">return</span> <span class="n">string</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__class_getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span> <span class="o">//</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">requested_frames_per_batch</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Non-terminating collectors do not have a length&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="SyncDataCollector"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector">[docs]</a><span class="nd">@accept_remote_rref_udf_invocation</span>
<span class="k">class</span><span class="w"> </span><span class="nc">SyncDataCollector</span><span class="p">(</span><span class="n">DataCollectorBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generic data collector for RL problems. Requires an environment constructor and a policy.</span>

<span class="sd">    Args:</span>
<span class="sd">        create_env_fn (Callable): a callable that returns an instance of</span>
<span class="sd">            :class:`~torchrl.envs.EnvBase` class.</span>
<span class="sd">        policy (Callable): Policy to be executed in the environment.</span>
<span class="sd">            Must accept :class:`tensordict.tensordict.TensorDictBase` object as input.</span>
<span class="sd">            If ``None`` is provided, the policy used will be a</span>
<span class="sd">            :class:`~torchrl.collectors.RandomPolicy` instance with the environment</span>
<span class="sd">            ``action_spec``.</span>
<span class="sd">            Accepted policies are usually subclasses of :class:`~tensordict.nn.TensorDictModuleBase`.</span>
<span class="sd">            This is the recommended usage of the collector.</span>
<span class="sd">            Other callables are accepted too:</span>
<span class="sd">            If the policy is not a ``TensorDictModuleBase`` (e.g., a regular :class:`~torch.nn.Module`</span>
<span class="sd">            instances) it will be wrapped in a `nn.Module` first.</span>
<span class="sd">            Then, the collector will try to assess if these</span>
<span class="sd">            modules require wrapping in a :class:`~tensordict.nn.TensorDictModule` or not.</span>

<span class="sd">            - If the policy forward signature matches any of ``forward(self, tensordict)``,</span>
<span class="sd">              ``forward(self, td)`` or ``forward(self, &lt;anything&gt;: TensorDictBase)`` (or</span>
<span class="sd">              any typing with a single argument typed as a subclass of ``TensorDictBase``)</span>
<span class="sd">              then the policy won&#39;t be wrapped in a :class:`~tensordict.nn.TensorDictModule`.</span>

<span class="sd">            - In all other cases an attempt to wrap it will be undergone as such: ``TensorDictModule(policy, in_keys=env_obs_key, out_keys=env.action_keys)``.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        frames_per_batch (int): A keyword-only argument representing the total</span>
<span class="sd">            number of elements in a batch.</span>
<span class="sd">        total_frames (int): A keyword-only argument representing the total</span>
<span class="sd">            number of frames returned by the collector</span>
<span class="sd">            during its lifespan. If the ``total_frames`` is not divisible by</span>
<span class="sd">            ``frames_per_batch``, an exception is raised.</span>
<span class="sd">             Endless collectors can be created by passing ``total_frames=-1``.</span>
<span class="sd">             Defaults to ``-1`` (endless collector).</span>
<span class="sd">        device (int, str or torch.device, optional): The generic device of the</span>
<span class="sd">            collector. The ``device`` args fills any non-specified device: if</span>
<span class="sd">            ``device`` is not ``None`` and any of ``storing_device``, ``policy_device`` or</span>
<span class="sd">            ``env_device`` is not specified, its value will be set to ``device``.</span>
<span class="sd">            Defaults to ``None`` (No default device).</span>
<span class="sd">        storing_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the output :class:`~tensordict.TensorDict` will be stored.</span>
<span class="sd">            If ``device`` is passed and ``storing_device`` is ``None``, it will</span>
<span class="sd">            default to the value indicated by ``device``.</span>
<span class="sd">            For long trajectories, it may be necessary to store the data on a different</span>
<span class="sd">            device than the one where the policy and env are executed.</span>
<span class="sd">            Defaults to ``None`` (the output tensordict isn&#39;t on a specific device,</span>
<span class="sd">            leaf tensors sit on the device where they were created).</span>
<span class="sd">        env_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the environment should be cast (or executed if that functionality is</span>
<span class="sd">            supported). If not specified and the env has a non-``None`` device,</span>
<span class="sd">            ``env_device`` will default to that value. If ``device`` is passed</span>
<span class="sd">            and ``env_device=None``, it will default to ``device``. If the value</span>
<span class="sd">            as such specified of ``env_device`` differs from ``policy_device``</span>
<span class="sd">            and one of them is not ``None``, the data will be cast to ``env_device``</span>
<span class="sd">            before being passed to the env (i.e., passing different devices to</span>
<span class="sd">            policy and env is supported). Defaults to ``None``.</span>
<span class="sd">        policy_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the policy should be cast.</span>
<span class="sd">            If ``device`` is passed and ``policy_device=None``, it will default</span>
<span class="sd">            to ``device``. If the value as such specified of ``policy_device``</span>
<span class="sd">            differs from ``env_device`` and one of them is not ``None``,</span>
<span class="sd">            the data will be cast to ``policy_device`` before being passed to</span>
<span class="sd">            the policy (i.e., passing different devices to policy and env is</span>
<span class="sd">            supported). Defaults to ``None``.</span>
<span class="sd">        create_env_kwargs (dict, optional): Dictionary of kwargs for</span>
<span class="sd">            ``create_env_fn``.</span>
<span class="sd">        max_frames_per_traj (int, optional): Maximum steps per trajectory.</span>
<span class="sd">            Note that a trajectory can span across multiple batches (unless</span>
<span class="sd">            ``reset_at_each_iter`` is set to ``True``, see below).</span>
<span class="sd">            Once a trajectory reaches ``n_steps``, the environment is reset.</span>
<span class="sd">            If the environment wraps multiple environments together, the number</span>
<span class="sd">            of steps is tracked for each environment independently. Negative</span>
<span class="sd">            values are allowed, in which case this argument is ignored.</span>
<span class="sd">            Defaults to ``None`` (i.e., no maximum number of steps).</span>
<span class="sd">        init_random_frames (int, optional): Number of frames for which the</span>
<span class="sd">            policy is ignored before it is called. This feature is mainly</span>
<span class="sd">            intended to be used in offline/model-based settings, where a</span>
<span class="sd">            batch of random trajectories can be used to initialize training.</span>
<span class="sd">            If provided, it will be rounded up to the closest multiple of frames_per_batch.</span>
<span class="sd">            Defaults to ``None`` (i.e. no random frames).</span>
<span class="sd">        reset_at_each_iter (bool, optional): Whether environments should be reset</span>
<span class="sd">            at the beginning of a batch collection.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        postproc (Callable, optional): A post-processing transform, such as</span>
<span class="sd">            a :class:`~torchrl.envs.Transform` or a :class:`~torchrl.data.postprocs.MultiStep`</span>
<span class="sd">            instance.</span>
<span class="sd">            Defaults to ``None``.</span>
<span class="sd">        split_trajs (bool, optional): Boolean indicating whether the resulting</span>
<span class="sd">            TensorDict should be split according to the trajectories.</span>
<span class="sd">            See :func:`~torchrl.collectors.utils.split_trajectories` for more</span>
<span class="sd">            information.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        exploration_type (ExplorationType, optional): interaction mode to be used when</span>
<span class="sd">            collecting data. Must be one of ``torchrl.envs.utils.ExplorationType.DETERMINISTIC``,</span>
<span class="sd">            ``torchrl.envs.utils.ExplorationType.RANDOM``, ``torchrl.envs.utils.ExplorationType.MODE``</span>
<span class="sd">            or ``torchrl.envs.utils.ExplorationType.MEAN``.</span>
<span class="sd">        return_same_td (bool, optional): if ``True``, the same TensorDict</span>
<span class="sd">            will be returned at each iteration, with its values</span>
<span class="sd">            updated. This feature should be used cautiously: if the same</span>
<span class="sd">            tensordict is added to a replay buffer for instance,</span>
<span class="sd">            the whole content of the buffer will be identical.</span>
<span class="sd">            Default is ``False``.</span>
<span class="sd">        interruptor (_Interruptor, optional):</span>
<span class="sd">            An _Interruptor object that can be used from outside the class to control rollout collection.</span>
<span class="sd">            The _Interruptor class has methods Â´start_collectionÂ´ and Â´stop_collectionÂ´, which allow to implement</span>
<span class="sd">            strategies such as preeptively stopping rollout collection.</span>
<span class="sd">            Default is ``False``.</span>
<span class="sd">        set_truncated (bool, optional): if ``True``, the truncated signals (and corresponding</span>
<span class="sd">            ``&quot;done&quot;`` but not ``&quot;terminated&quot;``) will be set to ``True`` when the last frame of</span>
<span class="sd">            a rollout is reached. If no ``&quot;truncated&quot;`` key is found, an exception is raised.</span>
<span class="sd">            Truncated keys can be set through ``env.add_truncated_keys``.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        use_buffers (bool, optional): if ``True``, a buffer will be used to stack the data.</span>
<span class="sd">            This isn&#39;t compatible with environments with dynamic specs. Defaults to ``True``</span>
<span class="sd">            for envs without dynamic specs, ``False`` for others.</span>
<span class="sd">        replay_buffer (ReplayBuffer, optional): if provided, the collector will not yield tensordict</span>
<span class="sd">            but populate the buffer instead. Defaults to ``None``.</span>
<span class="sd">        trust_policy (bool, optional): if ``True``, a non-TensorDictModule policy will be trusted to be</span>
<span class="sd">            assumed to be compatible with the collector. This defaults to ``True`` for CudaGraphModules</span>
<span class="sd">            and ``False`` otherwise.</span>
<span class="sd">        compile_policy (bool or Dict[str, Any], optional): if ``True``, the policy will be compiled</span>
<span class="sd">            using :func:`~torch.compile` default behaviour. If a dictionary of kwargs is passed, it</span>
<span class="sd">            will be used to compile the policy.</span>
<span class="sd">        cudagraph_policy (bool or Dict[str, Any], optional): if ``True``, the policy will be wrapped</span>
<span class="sd">            in :class:`~tensordict.nn.CudaGraphModule` with default kwargs.</span>
<span class="sd">            If a dictionary of kwargs is passed, it will be used to wrap the policy.</span>
<span class="sd">        no_cuda_sync (bool): if ``True``, explicit CUDA synchronizations calls will be bypassed.</span>
<span class="sd">            For environments running directly on CUDA (`IsaacLab &lt;https://github.com/isaac-sim/IsaacLab/&gt;`_</span>
<span class="sd">            or `ManiSkills &lt;https://github.com/haosulab/ManiSkill/&gt;`_) cuda synchronization may cause unexpected</span>
<span class="sd">            crashes.</span>
<span class="sd">            Defaults to ``False``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span class="sd">        &gt;&gt;&gt; env_maker = lambda: GymEnv(&quot;Pendulum-v1&quot;, device=&quot;cpu&quot;)</span>
<span class="sd">        &gt;&gt;&gt; policy = TensorDictModule(nn.Linear(3, 1), in_keys=[&quot;observation&quot;], out_keys=[&quot;action&quot;])</span>
<span class="sd">        &gt;&gt;&gt; collector = SyncDataCollector(</span>
<span class="sd">        ...     create_env_fn=env_maker,</span>
<span class="sd">        ...     policy=policy,</span>
<span class="sd">        ...     total_frames=2000,</span>
<span class="sd">        ...     max_frames_per_traj=50,</span>
<span class="sd">        ...     frames_per_batch=200,</span>
<span class="sd">        ...     init_random_frames=-1,</span>
<span class="sd">        ...     reset_at_each_iter=False,</span>
<span class="sd">        ...     device=&quot;cpu&quot;,</span>
<span class="sd">        ...     storing_device=&quot;cpu&quot;,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; for i, data in enumerate(collector):</span>
<span class="sd">        ...     if i == 2:</span>
<span class="sd">        ...         print(data)</span>
<span class="sd">        ...         break</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                collector: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        traj_ids: Tensor(shape=torch.Size([200]), device=cpu, dtype=torch.int64, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([200]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        step_count: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                        truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([200]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                step_count: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([200]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; del collector</span>

<span class="sd">    The collector delivers batches of data that are marked with a ``&quot;time&quot;``</span>
<span class="sd">    dimension.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; assert data.names[-1] == &quot;time&quot;</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">create_env_fn</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
            <span class="n">EnvBase</span><span class="p">,</span> <span class="s2">&quot;EnvCreator&quot;</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="n">EnvBase</span><span class="p">]]</span>  <span class="c1"># noqa: F821</span>
        <span class="p">],</span>  <span class="c1"># noqa: F821</span>
        <span class="n">policy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Union</span><span class="p">[</span>
                <span class="n">TensorDictModule</span><span class="p">,</span>
                <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">frames_per_batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">total_frames</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">storing_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">policy_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">env_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">create_env_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_frames_per_traj</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">init_random_frames</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">reset_at_each_iter</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">postproc</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">split_trajs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">exploration_type</span><span class="p">:</span> <span class="n">ExplorationType</span> <span class="o">=</span> <span class="n">DEFAULT_EXPLORATION_TYPE</span><span class="p">,</span>
        <span class="n">return_same_td</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">reset_when_done</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">interruptor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">set_truncated</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">use_buffers</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">replay_buffer</span><span class="p">:</span> <span class="n">ReplayBuffer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">trust_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">compile_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cudagraph_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">no_cuda_sync</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.batched_envs</span><span class="w"> </span><span class="kn">import</span> <span class="n">BatchedEnvBase</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="n">create_env_kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">create_env_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">create_env_fn</span><span class="p">,</span> <span class="n">EnvBase</span><span class="p">):</span>
            <span class="n">env</span> <span class="o">=</span> <span class="n">create_env_fn</span><span class="p">(</span><span class="o">**</span><span class="n">create_env_kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">env</span> <span class="o">=</span> <span class="n">create_env_fn</span>
            <span class="k">if</span> <span class="n">create_env_kwargs</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">BatchedEnvBase</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="s2">&quot;kwargs were passed to SyncDataCollector but they can&#39;t be set &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;on environment of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">create_env_fn</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>
                <span class="n">env</span><span class="o">.</span><span class="n">update_kwargs</span><span class="p">(</span><span class="n">create_env_kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">policy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">policy</span> <span class="o">=</span> <span class="n">RandomPolicy</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">full_action_spec</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">trust_policy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">trust_policy</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="p">(</span><span class="n">RandomPolicy</span><span class="p">,</span> <span class="n">CudaGraphModule</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trust_policy</span> <span class="o">=</span> <span class="n">trust_policy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_read_compile_kwargs</span><span class="p">(</span><span class="n">compile_policy</span><span class="p">,</span> <span class="n">cudagraph_policy</span><span class="p">)</span>

        <span class="c1">##########################</span>
        <span class="c1"># Trajectory pool</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_traj_pool_val</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;traj_pool&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Keys </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2"> are unknown to </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="c1">##########################</span>
        <span class="c1"># Setting devices:</span>
        <span class="c1"># The rule is the following:</span>
        <span class="c1"># - If no device is passed, all devices are assumed to work OOB.</span>
        <span class="c1">#   The tensordict used for output is not on any device (ie, actions and observations</span>
        <span class="c1">#   can be on a different device).</span>
        <span class="c1"># - If the ``device`` is passed, it is used for all devices (storing, env and policy)</span>
        <span class="c1">#   unless overridden by another kwarg.</span>
        <span class="c1"># - The rest of the kwargs control the respective device.</span>
        <span class="n">storing_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_devices</span><span class="p">(</span>
            <span class="n">storing_device</span><span class="o">=</span><span class="n">storing_device</span><span class="p">,</span>
            <span class="n">policy_device</span><span class="o">=</span><span class="n">policy_device</span><span class="p">,</span>
            <span class="n">env_device</span><span class="o">=</span><span class="n">env_device</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span> <span class="o">=</span> <span class="n">storing_device</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
            <span class="c1"># Cuda handles sync</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_storage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span>
            <span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;mps&quot;</span><span class="p">):</span>
                <span class="c1"># Will break for older PT versions which don&#39;t have torch.mps</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_storage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">synchronize</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_storage</span> <span class="o">=</span> <span class="n">_do_nothing</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Non supported device&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sync_storage</span> <span class="o">=</span> <span class="n">_do_nothing</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span> <span class="o">=</span> <span class="n">env_device</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
            <span class="c1"># Cuda handles sync</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_env</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span>
            <span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;mps&quot;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_env</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">synchronize</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_env</span> <span class="o">=</span> <span class="n">_do_nothing</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Non supported device&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sync_env</span> <span class="o">=</span> <span class="n">_do_nothing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="o">=</span> <span class="n">policy_device</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
            <span class="c1"># Cuda handles sync</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_policy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span>
            <span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;mps&quot;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_policy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">synchronize</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_policy</span> <span class="o">=</span> <span class="n">_do_nothing</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Non supported device&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sync_policy</span> <span class="o">=</span> <span class="n">_do_nothing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span> <span class="o">=</span> <span class="n">no_cuda_sync</span>
        <span class="c1"># Check if we need to cast things from device to device</span>
        <span class="c1"># If the policy has a None device and the env too, no need to cast (we don&#39;t know</span>
        <span class="c1"># and assume the user knows what she&#39;s doing).</span>
        <span class="c1"># If the devices match we&#39;re happy too.</span>
        <span class="c1"># Only if the values differ we need to cast</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cast_to_policy_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">:</span> <span class="n">EnvBase</span> <span class="o">=</span> <span class="n">env</span>
        <span class="k">del</span> <span class="n">env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">replay_buffer</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">postproc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;postproc must be None when a replay buffer is passed.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">use_buffers</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;replay_buffer is exclusive with use_buffers.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">use_buffers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">use_buffers</span> <span class="o">=</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">_has_dynamic_specs</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span> <span class="o">=</span> <span class="n">use_buffers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">replay_buffer</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">reset_when_done</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;reset_when_done is deprectated.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_when_done</span> <span class="o">=</span> <span class="n">reset_when_done</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">batch_size</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_weights_fn</span><span class="p">,)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_policy_and_device</span><span class="p">(</span>
            <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">,</span>
            <span class="n">observation_spec</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">observation_spec</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_weights</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="o">.</span><span class="n">from_module</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">,</span> <span class="n">as_module</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_weights</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">compile_with_warmup</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy_kwargs</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cudagraphed_policy</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">CudaGraphModule</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">cudagraphed_policy_kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">:</span> <span class="n">EnvBase</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_device</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># we did not receive an env device, we use the device of the env</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">device</span>

        <span class="c1"># If the storing device is not the same as the policy device, we have</span>
        <span class="c1"># no guarantee that the &quot;next&quot; entry from the policy will be on the</span>
        <span class="c1"># same device as the collector metadata.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cast_to_env_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cast_to_policy_device</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_frames_per_traj</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">max_frames_per_traj</span><span class="p">)</span> <span class="k">if</span> <span class="n">max_frames_per_traj</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_frames_per_traj</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_frames_per_traj</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># let&#39;s check that there is no StepCounter yet</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">output_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="n">key</span><span class="p">,)</span>
                <span class="k">if</span> <span class="s2">&quot;step_count&quot;</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;A &#39;step_count&#39; key is already present in the environment &quot;</span>
                        <span class="s2">&quot;and the &#39;max_frames_per_traj&#39; argument may conflict with &quot;</span>
                        <span class="s2">&quot;a &#39;StepCounter&#39; that has already been set. &quot;</span>
                        <span class="s2">&quot;Possible solutions: Set max_frames_per_traj to 0 or &quot;</span>
                        <span class="s2">&quot;remove the StepCounter limit from the environment transforms.&quot;</span>
                    <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">,</span> <span class="n">StepCounter</span><span class="p">(</span><span class="n">max_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_frames_per_traj</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">total_frames</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">total_frames</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">total_frames</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">remainder</span> <span class="o">=</span> <span class="n">total_frames</span> <span class="o">%</span> <span class="n">frames_per_batch</span>
            <span class="k">if</span> <span class="n">remainder</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">RL_WARNINGS</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;total_frames (</span><span class="si">{</span><span class="n">total_frames</span><span class="si">}</span><span class="s2">) is not exactly divisible by frames_per_batch (</span><span class="si">{</span><span class="n">frames_per_batch</span><span class="si">}</span><span class="s2">). &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;This means </span><span class="si">{</span><span class="n">frames_per_batch</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">remainder</span><span class="si">}</span><span class="s2"> additional frames will be collected.&quot;</span>
                    <span class="s2">&quot;To silence this message, set the environment variable RL_WARNINGS to False.&quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">total_frames</span><span class="p">)</span> <span class="k">if</span> <span class="n">total_frames</span> <span class="o">!=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">total_frames</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_at_each_iter</span> <span class="o">=</span> <span class="n">reset_at_each_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">init_random_frames</span><span class="p">)</span> <span class="k">if</span> <span class="n">init_random_frames</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">init_random_frames</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="ow">and</span> <span class="n">init_random_frames</span> <span class="o">%</span> <span class="n">frames_per_batch</span> <span class="o">!=</span> <span class="mi">0</span>
            <span class="ow">and</span> <span class="n">RL_WARNINGS</span>
        <span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;init_random_frames (</span><span class="si">{</span><span class="n">init_random_frames</span><span class="si">}</span><span class="s2">) is not exactly a multiple of frames_per_batch (</span><span class="si">{</span><span class="n">frames_per_batch</span><span class="si">}</span><span class="s2">), &quot;</span>
                <span class="sa">f</span><span class="s2">&quot; this results in more init_random_frames than requested&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; (</span><span class="si">{</span><span class="o">-</span><span class="p">(</span><span class="o">-</span><span class="n">init_random_frames</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">frames_per_batch</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">frames_per_batch</span><span class="si">}</span><span class="s2">).&quot;</span>
                <span class="s2">&quot;To silence this message, set the environment variable RL_WARNINGS to False.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">postproc</span> <span class="o">=</span> <span class="n">postproc</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">postproc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">postproc</span><span class="p">,</span> <span class="s2">&quot;to&quot;</span><span class="p">)</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">postproc</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">frames_per_batch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_env</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">RL_WARNINGS</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;frames_per_batch (</span><span class="si">{</span><span class="n">frames_per_batch</span><span class="si">}</span><span class="s2">) is not exactly divisible by the number of batched environments (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_env</span><span class="si">}</span><span class="s2">), &quot;</span>
                <span class="sa">f</span><span class="s2">&quot; this results in more frames_per_batch per iteration that requested&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; (</span><span class="si">{</span><span class="o">-</span><span class="p">(</span><span class="o">-</span><span class="n">frames_per_batch</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">n_env</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">n_env</span><span class="si">}</span><span class="s2">). &quot;</span>
                <span class="s2">&quot;To silence this message, set the environment variable RL_WARNINGS to False.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_batch</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="o">-</span><span class="n">frames_per_batch</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">requested_frames_per_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_batch</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exploration_type</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">exploration_type</span> <span class="k">if</span> <span class="n">exploration_type</span> <span class="k">else</span> <span class="n">DEFAULT_EXPLORATION_TYPE</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_same_td</span> <span class="o">=</span> <span class="n">return_same_td</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_truncated</span> <span class="o">=</span> <span class="n">set_truncated</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_make_shuttle</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_make_final_rollout</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_truncated_keys</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">split_trajs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">split_trajs</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">split_trajs</span> <span class="o">=</span> <span class="n">split_trajs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_exclude_private_keys</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span> <span class="o">=</span> <span class="n">interruptor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_traj_pool</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">pool</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_traj_pool_val&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">pool</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_traj_pool_val</span> <span class="o">=</span> <span class="n">_TrajectoryPool</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">pool</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_make_shuttle</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Shuttle is a deviceless tensordict that just carried data from env to policy and policy to env</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle_has_no_device</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle_has_no_device</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="n">traj_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_traj_pool</span><span class="o">.</span><span class="n">get_traj_and_increment</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_env</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span>
        <span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
            <span class="p">(</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">),</span>
            <span class="n">traj_ids</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_make_final_rollout</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">fake_tensordict</span><span class="p">()</span>

        <span class="c1"># If storing device is not None, we use this to cast the storage.</span>
        <span class="c1"># If it is None and the env and policy are on the same device,</span>
        <span class="c1"># the storing device is already the same as those, so we don&#39;t need</span>
        <span class="c1"># to consider this use case.</span>
        <span class="c1"># In all other cases, we can&#39;t really put a device on the storage,</span>
        <span class="c1"># since at least one data source has a device that is not clear.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># erase all devices</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>

        <span class="c1"># If the policy has a valid spec, we use it</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_policy_output_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">,</span> <span class="s2">&quot;spec&quot;</span><span class="p">)</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span>
                <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="c1"># if policy spec is non-empty, all the values are not None and the keys</span>
                <span class="c1"># match the out_keys we assume the user has given all relevant information</span>
                <span class="c1"># the policy could have more keys than the env:</span>
                <span class="n">policy_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">spec</span>
                <span class="k">if</span> <span class="n">policy_spec</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
                    <span class="n">policy_spec</span> <span class="o">=</span> <span class="n">policy_spec</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="n">policy_spec</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_policy_output_keys</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
                        <span class="k">continue</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">spec</span><span class="o">.</span><span class="n">zero</span><span class="p">())</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># otherwise, we perform a small number of steps with the policy to</span>
            <span class="c1"># determine the relevant keys with which to pre-populate _final_rollout.</span>
            <span class="c1"># This is the safest thing to do if the spec has None fields or if there is</span>
            <span class="c1"># no spec at all.</span>
            <span class="c1"># See #505 for additional context.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">policy_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">:</span>
                    <span class="n">policy_input</span> <span class="o">=</span> <span class="n">policy_input</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">)</span>
                <span class="c1"># we cast to policy device, we&#39;ll deal with the device later</span>
                <span class="n">policy_input_copy</span> <span class="o">=</span> <span class="n">policy_input</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">policy_input_clone</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">policy_input</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="p">)</span>  <span class="c1"># to test if values have changed in-place</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy</span><span class="p">:</span>
                    <span class="n">cudagraph_mark_step_begin</span><span class="p">()</span>
                <span class="n">policy_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">(</span><span class="n">policy_input</span><span class="p">)</span>

                <span class="c1"># check that we don&#39;t have exclusive keys, because they don&#39;t appear in keys</span>
                <span class="k">def</span><span class="w"> </span><span class="nf">check_exclusive</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">)</span>
                        <span class="ow">and</span> <span class="n">val</span><span class="o">.</span><span class="n">_has_exclusive_keys</span>
                    <span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                            <span class="s2">&quot;LazyStackedTensorDict with exclusive keys are not permitted in collectors. &quot;</span>
                            <span class="s2">&quot;Consider using a placeholder for missing keys.&quot;</span>
                        <span class="p">)</span>

                <span class="n">policy_output</span><span class="o">.</span><span class="n">_fast_apply</span><span class="p">(</span>
                    <span class="n">check_exclusive</span><span class="p">,</span> <span class="n">call_on_nested</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">filter_empty</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>

                <span class="c1"># Use apply, because it works well with lazy stacks</span>
                <span class="c1"># Edge-case of this approach: the policy may change the values in-place and only by a tiny bit</span>
                <span class="c1"># or occasionally. In these cases, the keys will be missed (we can&#39;t detect if the policy has</span>
                <span class="c1"># changed them here).</span>
                <span class="c1"># This will cause a failure to update entries when policy and env device mismatch and</span>
                <span class="c1"># casting is necessary.</span>
                <span class="k">def</span><span class="w"> </span><span class="nf">filter_policy</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value_output</span><span class="p">,</span> <span class="n">value_input</span><span class="p">,</span> <span class="n">value_input_clone</span><span class="p">):</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">value_input</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
                        <span class="p">(</span><span class="n">value_output</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">value_input</span><span class="p">)</span>
                        <span class="ow">and</span> <span class="p">(</span>
                            <span class="n">value_output</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">value_input_clone</span><span class="o">.</span><span class="n">device</span>
                            <span class="ow">or</span> <span class="o">~</span><span class="n">torch</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">value_output</span><span class="p">,</span> <span class="n">value_input_clone</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
                        <span class="p">)</span>
                    <span class="p">):</span>
                        <span class="k">return</span> <span class="n">value_output</span>

                <span class="n">filtered_policy_output</span> <span class="o">=</span> <span class="n">policy_output</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
                    <span class="n">filter_policy</span><span class="p">,</span>
                    <span class="n">policy_input_copy</span><span class="p">,</span>
                    <span class="n">policy_input_clone</span><span class="p">,</span>
                    <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">filter_empty</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">named</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_policy_output_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_policy_output_keys</span><span class="o">.</span><span class="n">union</span><span class="p">(</span>
                        <span class="nb">set</span><span class="p">(</span><span class="n">filtered_policy_output</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                    <span class="n">policy_output</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_policy_output_keys</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="k">del</span> <span class="n">filtered_policy_output</span><span class="p">,</span> <span class="n">policy_output</span><span class="p">,</span> <span class="n">policy_input</span>

        <span class="n">_env_output_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">spec</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;full_observation_spec&quot;</span><span class="p">,</span> <span class="s2">&quot;full_done_spec&quot;</span><span class="p">,</span> <span class="s2">&quot;full_reward_spec&quot;</span><span class="p">]:</span>
            <span class="n">_env_output_keys</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="n">spec</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_env_output_keys</span> <span class="o">=</span> <span class="n">_env_output_keys</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_batch</span><span class="p">)</span>
            <span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="c1"># in addition to outputs of the policy, we add traj_ids to</span>
        <span class="c1"># _final_rollout which will be collected during rollout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
            <span class="p">(</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">refine_names</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="s2">&quot;time&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_set_truncated_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_truncated_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">set_truncated</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">_ends_with</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;truncated&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">done_keys</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;set_truncated was set to True but no truncated key could be found &quot;</span>
                    <span class="s2">&quot;in the environment. Make sure the truncated keys are properly set using &quot;</span>
                    <span class="s2">&quot;`env.add_truncated_keys()` before passing the env to the collector.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_truncated_keys</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">done_keys</span> <span class="k">if</span> <span class="n">_ends_with</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;truncated&quot;</span><span class="p">)</span>
            <span class="p">]</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_get_devices</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">storing_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">policy_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">env_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">_make_ordinal_device</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="n">device</span> <span class="k">else</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">storing_device</span> <span class="o">=</span> <span class="n">_make_ordinal_device</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">storing_device</span><span class="p">)</span> <span class="k">if</span> <span class="n">storing_device</span> <span class="k">else</span> <span class="n">device</span>
        <span class="p">)</span>
        <span class="n">policy_device</span> <span class="o">=</span> <span class="n">_make_ordinal_device</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">policy_device</span><span class="p">)</span> <span class="k">if</span> <span class="n">policy_device</span> <span class="k">else</span> <span class="n">device</span>
        <span class="p">)</span>
        <span class="n">env_device</span> <span class="o">=</span> <span class="n">_make_ordinal_device</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">env_device</span><span class="p">)</span> <span class="k">if</span> <span class="n">env_device</span> <span class="k">else</span> <span class="n">device</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">storing_device</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="n">env_device</span> <span class="o">==</span> <span class="n">policy_device</span><span class="p">):</span>
            <span class="n">storing_device</span> <span class="o">=</span> <span class="n">env_device</span>
        <span class="k">return</span> <span class="n">storing_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_device</span>

    <span class="c1"># for RPC</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">next</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="SyncDataCollector.update_policy_weights_"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.update_policy_weights_">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">update_policy_weights_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">policy_weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">update_policy_weights_</span><span class="p">(</span><span class="n">policy_weights</span><span class="p">)</span></div>

<div class="viewcode-block" id="SyncDataCollector.set_seed"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.set_seed">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sets the seeds of the environments stored in the DataCollector.</span>

<span class="sd">        Args:</span>
<span class="sd">            seed (int): integer representing the seed to be used for the environment.</span>
<span class="sd">            static_seed(bool, optional): if ``True``, the seed is not incremented.</span>
<span class="sd">                Defaults to False</span>

<span class="sd">        Returns:</span>
<span class="sd">            Output seed. This is useful when more than one environment is contained in the DataCollector, as the</span>
<span class="sd">            seed will be incremented for each of these. The resulting seed is the seed of the last environment.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs import ParallelEnv</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">            &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">            &gt;&gt;&gt; from torch import nn</span>
<span class="sd">            &gt;&gt;&gt; env_fn = lambda: GymEnv(&quot;Pendulum-v1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; env_fn_parallel = ParallelEnv(6, env_fn)</span>
<span class="sd">            &gt;&gt;&gt; policy = TensorDictModule(nn.Linear(3, 1), in_keys=[&quot;observation&quot;], out_keys=[&quot;action&quot;])</span>
<span class="sd">            &gt;&gt;&gt; collector = SyncDataCollector(env_fn_parallel, policy, total_frames=300, frames_per_batch=100)</span>
<span class="sd">            &gt;&gt;&gt; out_seed = collector.set_seed(1)  # out_seed = 6</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">static_seed</span><span class="o">=</span><span class="n">static_seed</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_increment_frames</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">numel</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">+=</span> <span class="n">numel</span>
        <span class="n">completed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span>
        <span class="k">if</span> <span class="n">completed</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">completed</span>

<div class="viewcode-block" id="SyncDataCollector.iterator"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.iterator">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">iterator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Iterates through the DataCollector.</span>

<span class="sd">        Yields: TensorDictBase objects containing (chunks of) trajectories</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span>
        <span class="p">):</span>
            <span class="n">stream</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Stream</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="p">,</span> <span class="n">priority</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">event</span> <span class="o">=</span> <span class="n">stream</span><span class="o">.</span><span class="n">record_event</span><span class="p">()</span>
            <span class="n">streams</span> <span class="o">=</span> <span class="p">[</span><span class="n">stream</span><span class="p">]</span>
            <span class="n">events</span> <span class="o">=</span> <span class="p">[</span><span class="n">event</span><span class="p">]</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">streams</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">events</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="c1"># this way of checking cuda is robust to lazy stacks with mismatching shapes</span>
            <span class="n">cuda_devices</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">cuda_check</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">is_cuda</span><span class="p">:</span>
                    <span class="n">cuda_devices</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span><span class="p">:</span>
                <span class="c1"># This may be a bit dangerous as `torch.device(&quot;cuda&quot;)` may not have a precise</span>
                <span class="c1"># device associated, whereas `tensor.device` always has</span>
                <span class="k">for</span> <span class="n">spec</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">specs</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">spec</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
                        <span class="k">if</span> <span class="s2">&quot;:&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
                            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                                <span class="s2">&quot;A cuda spec did not have a device associated. Make sure to &quot;</span>
                                <span class="s2">&quot;pass `&#39;cuda:device_num&#39;` to each spec device.&quot;</span>
                            <span class="p">)</span>
                        <span class="n">cuda_devices</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">cuda_check</span><span class="p">,</span> <span class="n">filter_empty</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">device</span> <span class="ow">in</span> <span class="n">cuda_devices</span><span class="p">:</span>
                <span class="n">streams</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Stream</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">priority</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">events</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">streams</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">record_event</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">streams</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">events</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">ExitStack</span><span class="p">()</span> <span class="k">as</span> <span class="n">stack</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">stream</span> <span class="ow">in</span> <span class="n">streams</span><span class="p">:</span>
                <span class="n">stack</span><span class="o">.</span><span class="n">enter_context</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="n">stream</span><span class="p">))</span>

            <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">tensordict_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rollout</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">tensordict_out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># if a replay buffer is passed, there is no tensordict_out</span>
                    <span class="c1">#  frames are updated within the rollout function</span>
                    <span class="k">yield</span>
                    <span class="k">continue</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_increment_frames</span><span class="p">(</span><span class="n">tensordict_out</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_trajs</span><span class="p">:</span>
                    <span class="n">tensordict_out</span> <span class="o">=</span> <span class="n">split_trajectories</span><span class="p">(</span>
                        <span class="n">tensordict_out</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;collector&quot;</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">postproc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">tensordict_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postproc</span><span class="p">(</span><span class="n">tensordict_out</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exclude_private_keys</span><span class="p">:</span>

                    <span class="k">def</span><span class="w"> </span><span class="nf">is_private</span><span class="p">(</span><span class="n">key</span><span class="p">):</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">):</span>
                            <span class="k">return</span> <span class="kc">True</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span>
                            <span class="n">_key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_key</span> <span class="ow">in</span> <span class="n">key</span>
                        <span class="p">):</span>
                            <span class="k">return</span> <span class="kc">True</span>
                        <span class="k">return</span> <span class="kc">False</span>

                    <span class="n">excluded_keys</span> <span class="o">=</span> <span class="p">[</span>
                        <span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">tensordict_out</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span> <span class="k">if</span> <span class="n">is_private</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                    <span class="p">]</span>
                    <span class="n">tensordict_out</span> <span class="o">=</span> <span class="n">tensordict_out</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span>
                        <span class="o">*</span><span class="n">excluded_keys</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_same_td</span><span class="p">:</span>
                    <span class="c1"># This is used with multiprocessed collectors to use the buffers</span>
                    <span class="c1"># stored in the tensordict.</span>
                    <span class="k">if</span> <span class="n">events</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">event</span> <span class="ow">in</span> <span class="n">events</span><span class="p">:</span>
                            <span class="n">event</span><span class="o">.</span><span class="n">record</span><span class="p">()</span>
                            <span class="n">event</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
                    <span class="k">yield</span> <span class="n">tensordict_out</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># we must clone the values, as the tensordict is updated in-place.</span>
                    <span class="c1"># otherwise the following code may break:</span>
                    <span class="c1"># &gt;&gt;&gt; for i, data in enumerate(collector):</span>
                    <span class="c1"># &gt;&gt;&gt;      if i == 0:</span>
                    <span class="c1"># &gt;&gt;&gt;          data0 = data</span>
                    <span class="c1"># &gt;&gt;&gt;      elif i == 1:</span>
                    <span class="c1"># &gt;&gt;&gt;          data1 = data</span>
                    <span class="c1"># &gt;&gt;&gt;      else:</span>
                    <span class="c1"># &gt;&gt;&gt;          break</span>
                    <span class="c1"># &gt;&gt;&gt; assert data0[&quot;done&quot;] is not data1[&quot;done&quot;]</span>
                    <span class="k">yield</span> <span class="n">tensordict_out</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_update_traj_ids</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># we can&#39;t use the reset keys because they&#39;re gone</span>
        <span class="n">traj_sop</span> <span class="o">=</span> <span class="n">_aggregate_end_of_traj</span><span class="p">(</span>
            <span class="n">env_output</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;next&quot;</span><span class="p">),</span> <span class="n">done_keys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">done_keys</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">traj_sop</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span>

            <span class="n">traj_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">traj_ids</span> <span class="o">=</span> <span class="n">traj_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">traj_sop</span> <span class="o">=</span> <span class="n">traj_sop</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">traj_sop</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">traj_ids</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                <span class="n">traj_sop</span> <span class="o">=</span> <span class="n">traj_sop</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">traj_ids</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="n">pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_traj_pool</span>
            <span class="n">new_traj</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">get_traj_and_increment</span><span class="p">(</span>
                <span class="n">traj_sop</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">device</span><span class="o">=</span><span class="n">traj_sop</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="n">traj_ids</span> <span class="o">=</span> <span class="n">traj_ids</span><span class="o">.</span><span class="n">masked_scatter</span><span class="p">(</span><span class="n">traj_sop</span><span class="p">,</span> <span class="n">new_traj</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">set</span><span class="p">((</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">),</span> <span class="n">traj_ids</span><span class="p">)</span>

<div class="viewcode-block" id="SyncDataCollector.rollout"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.rollout">[docs]</a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">rollout</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes a rollout in the environment using the provided policy.</span>

<span class="sd">        Returns:</span>
<span class="sd">            TensorDictBase containing the computed rollout.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_at_each_iter</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">())</span>

        <span class="c1"># self._shuttle.fill_((&quot;collector&quot;, &quot;step_count&quot;), 0)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">fill_</span><span class="p">((</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="n">tensordicts</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">set_exploration_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">exploration_type</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">frames_per_batch</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span>
                <span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">rand_action</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="p">)</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span>
                    <span class="p">):</span>
                        <span class="c1"># TODO: This may break with exclusive / ragged lazy stacks</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
                            <span class="k">lambda</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="n">val</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span>
                            <span class="p">)</span>
                            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_policy_output_keys</span>
                            <span class="k">else</span> <span class="n">val</span><span class="p">,</span>
                            <span class="n">out</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="p">,</span>
                            <span class="n">named</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">nested_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cast_to_policy_device</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="c1"># This is unsafe if the shuttle is in pin_memory -- otherwise cuda will be happy with non_blocking</span>
                            <span class="n">non_blocking</span> <span class="o">=</span> <span class="p">(</span>
                                <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span>
                                <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span>
                            <span class="p">)</span>
                            <span class="n">policy_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">,</span>
                                <span class="n">non_blocking</span><span class="o">=</span><span class="n">non_blocking</span><span class="p">,</span>
                            <span class="p">)</span>
                            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_policy</span><span class="p">()</span>
                        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="c1"># we know the tensordict has a device otherwise we would not be here</span>
                            <span class="c1"># we can pass this, clear_device_ must have been called earlier</span>
                            <span class="c1"># policy_input = self._shuttle.clear_device_()</span>
                            <span class="n">policy_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">policy_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span>
                    <span class="c1"># we still do the assignment for security</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy</span><span class="p">:</span>
                        <span class="n">cudagraph_mark_step_begin</span><span class="p">()</span>
                    <span class="n">policy_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">(</span><span class="n">policy_input</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy</span><span class="p">:</span>
                        <span class="n">policy_output</span> <span class="o">=</span> <span class="n">policy_output</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">policy_output</span><span class="p">:</span>
                        <span class="c1"># ad-hoc update shuttle</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                            <span class="n">policy_output</span><span class="p">,</span> <span class="n">keys_to_update</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_policy_output_keys</span>
                        <span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cast_to_env_device</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">non_blocking</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span>
                        <span class="p">)</span>
                        <span class="n">env_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="n">non_blocking</span>
                        <span class="p">)</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_sync_env</span><span class="p">()</span>
                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="c1"># we know the tensordict has a device otherwise we would not be here</span>
                        <span class="c1"># we can pass this, clear_device_ must have been called earlier</span>
                        <span class="c1"># env_input = self._shuttle.clear_device_()</span>
                        <span class="n">env_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">env_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span>
                <span class="n">env_output</span><span class="p">,</span> <span class="n">env_next_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step_and_maybe_reset</span><span class="p">(</span><span class="n">env_input</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">env_output</span><span class="p">:</span>
                    <span class="c1"># ad-hoc update shuttle</span>
                    <span class="n">next_data</span> <span class="o">=</span> <span class="n">env_output</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;next&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle_has_no_device</span><span class="p">:</span>
                        <span class="c1"># Make sure</span>
                        <span class="n">next_data</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="n">next_data</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_increment_frames</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">numel</span><span class="p">()):</span>
                        <span class="k">return</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">non_blocking</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span>
                        <span class="p">)</span>
                        <span class="n">tensordicts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="n">non_blocking</span>
                            <span class="p">)</span>
                        <span class="p">)</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_sync_storage</span><span class="p">()</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">tensordicts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="p">)</span>

                <span class="c1"># carry over collector data without messing up devices</span>
                <span class="n">collector_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;collector&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span> <span class="o">=</span> <span class="n">env_next_output</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle_has_no_device</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="n">collector_data</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_update_traj_ids</span><span class="p">(</span><span class="n">env_output</span><span class="p">)</span>

                <span class="k">if</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span><span class="o">.</span><span class="n">collection_stopped</span><span class="p">()</span>
                <span class="p">):</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">return</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span><span class="p">:</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                                <span class="n">tensordicts</span><span class="p">,</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                                <span class="n">out</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
                            <span class="p">)</span>
                        <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
                            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">unlock_</span><span class="p">():</span>
                                <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                                    <span class="n">tensordicts</span><span class="p">,</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                                    <span class="n">out</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
                                <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">result</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="o">.</span><span class="n">maybe_dense_stack</span><span class="p">(</span><span class="n">tensordicts</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span><span class="p">:</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                            <span class="n">tensordicts</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                            <span class="n">out</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="p">,</span>
                        <span class="p">)</span>

                    <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
                        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">unlock_</span><span class="p">():</span>
                            <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                                <span class="n">tensordicts</span><span class="p">,</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                                <span class="n">out</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="p">,</span>
                            <span class="p">)</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">return</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="o">.</span><span class="n">maybe_dense_stack</span><span class="p">(</span><span class="n">tensordicts</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">result</span><span class="o">.</span><span class="n">refine_names</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="s2">&quot;time&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_set_truncated</span><span class="p">(</span><span class="n">result</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_maybe_set_truncated</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">final_rollout</span><span class="p">):</span>
        <span class="n">last_step</span> <span class="o">=</span> <span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">),)</span> <span class="o">*</span> <span class="p">(</span><span class="n">final_rollout</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span>
        <span class="k">for</span> <span class="n">truncated_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_truncated_keys</span><span class="p">:</span>
            <span class="n">truncated</span> <span class="o">=</span> <span class="n">final_rollout</span><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="n">truncated_key</span><span class="p">]</span>
            <span class="n">truncated</span><span class="p">[</span><span class="n">last_step</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">final_rollout</span><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="n">truncated_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">truncated</span>
            <span class="n">done</span> <span class="o">=</span> <span class="n">final_rollout</span><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="n">_replace_last</span><span class="p">(</span><span class="n">truncated_key</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">)]</span>
            <span class="n">final_rollout</span><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="n">_replace_last</span><span class="p">(</span><span class="n">truncated_key</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">done</span> <span class="o">|</span> <span class="n">truncated</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">final_rollout</span>

<div class="viewcode-block" id="SyncDataCollector.reset"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.reset">[docs]</a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Resets the environments to a new initial state.&quot;&quot;&quot;</span>
        <span class="c1"># metadata</span>
        <span class="n">collector_metadata</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;collector&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># check that the env supports partial reset</span>
            <span class="k">if</span> <span class="n">prod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;resetting unique env with index is not permitted.&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">reset_key</span><span class="p">,</span> <span class="n">done_keys</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">done_keys_groups</span>
            <span class="p">):</span>
                <span class="n">_reset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">full_done_spec</span><span class="p">[</span><span class="n">done_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">_reset</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">reset_key</span><span class="p">,</span> <span class="n">_reset</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_reset</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">collector_metadata</span><span class="p">[</span><span class="s2">&quot;traj_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">collector_metadata</span><span class="p">[</span><span class="s2">&quot;traj_ids&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">collector_metadata</span><span class="p">[</span><span class="s2">&quot;traj_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="p">[</span><span class="s2">&quot;collector&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">collector_metadata</span></div>

<div class="viewcode-block" id="SyncDataCollector.shutdown"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.shutdown">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">shutdown</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Shuts down all workers and/or closes the local environment.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span><span class="p">:</span>
                <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">is_closed</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span>
        <span class="k">return</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="c1"># an AttributeError will typically be raised if the collector is deleted when the program ends.</span>
            <span class="c1"># In the future, insignificant changes to the close method may change the error type.</span>
            <span class="c1"># We excplicitely assume that any error raised during closure in</span>
            <span class="c1"># __del__ will not affect the program.</span>
            <span class="k">pass</span>

<div class="viewcode-block" id="SyncDataCollector.state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the local state_dict of the data collector (environment and policy).</span>

<span class="sd">        Returns:</span>
<span class="sd">            an ordered dictionary with fields :obj:`&quot;policy_state_dict&quot;` and</span>
<span class="sd">            `&quot;env_state_dict&quot;`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.batched_envs</span><span class="w"> </span><span class="kn">import</span> <span class="n">BatchedEnvBase</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">,</span> <span class="n">TransformedEnv</span><span class="p">):</span>
            <span class="n">env_state_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">,</span> <span class="n">BatchedEnvBase</span><span class="p">):</span>
            <span class="n">env_state_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">env_state_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">,</span> <span class="s2">&quot;state_dict&quot;</span><span class="p">):</span>
            <span class="n">policy_state_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span>
                <span class="n">policy_state_dict</span><span class="o">=</span><span class="n">policy_state_dict</span><span class="p">,</span>
                <span class="n">env_state_dict</span><span class="o">=</span><span class="n">env_state_dict</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">env_state_dict</span><span class="o">=</span><span class="n">env_state_dict</span><span class="p">)</span>

        <span class="n">state_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;frames&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span><span class="p">,</span> <span class="s2">&quot;iter&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span><span class="p">})</span>

        <span class="k">return</span> <span class="n">state_dict</span></div>

<div class="viewcode-block" id="SyncDataCollector.load_state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.load_state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Loads a state_dict on the environment and policy.</span>

<span class="sd">        Args:</span>
<span class="sd">            state_dict (OrderedDict): ordered dictionary containing the fields</span>
<span class="sd">                `&quot;policy_state_dict&quot;` and :obj:`&quot;env_state_dict&quot;`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">strict</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;strict&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">strict</span> <span class="ow">or</span> <span class="s2">&quot;env_state_dict&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;env_state_dict&quot;</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">strict</span> <span class="ow">or</span> <span class="s2">&quot;policy_state_dict&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;policy_state_dict&quot;</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;iter&quot;</span><span class="p">]</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">env_str</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;env=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
        <span class="n">policy_str</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;policy=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
        <span class="n">td_out_str</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;td_out=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
        <span class="n">string</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">env_str</span><span class="si">}</span><span class="s2">,&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">policy_str</span><span class="si">}</span><span class="s2">,&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">td_out_str</span><span class="si">}</span><span class="s2">,&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">exploration=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">exploration_type</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">string</span></div>


<span class="k">class</span><span class="w"> </span><span class="nc">_MultiDataCollector</span><span class="p">(</span><span class="n">DataCollectorBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Runs a given number of DataCollectors on separate processes.</span>

<span class="sd">    Args:</span>
<span class="sd">        create_env_fn (List[Callabled]): list of Callables, each returning an</span>
<span class="sd">            instance of :class:`~torchrl.envs.EnvBase`.</span>
<span class="sd">        policy (Callable): Policy to be executed in the environment.</span>
<span class="sd">            Must accept :class:`tensordict.tensordict.TensorDictBase` object as input.</span>
<span class="sd">            If ``None`` is provided (default), the policy used will be a</span>
<span class="sd">            :class:`~torchrl.collectors.RandomPolicy` instance with the environment</span>
<span class="sd">            ``action_spec``.</span>
<span class="sd">            Accepted policies are usually subclasses of :class:`~tensordict.nn.TensorDictModuleBase`.</span>
<span class="sd">            This is the recommended usage of the collector.</span>
<span class="sd">            Other callables are accepted too:</span>
<span class="sd">            If the policy is not a ``TensorDictModuleBase`` (e.g., a regular :class:`~torch.nn.Module`</span>
<span class="sd">            instances) it will be wrapped in a `nn.Module` first.</span>
<span class="sd">            Then, the collector will try to assess if these</span>
<span class="sd">            modules require wrapping in a :class:`~tensordict.nn.TensorDictModule` or not.</span>

<span class="sd">            - If the policy forward signature matches any of ``forward(self, tensordict)``,</span>
<span class="sd">              ``forward(self, td)`` or ``forward(self, &lt;anything&gt;: TensorDictBase)`` (or</span>
<span class="sd">              any typing with a single argument typed as a subclass of ``TensorDictBase``)</span>
<span class="sd">              then the policy won&#39;t be wrapped in a :class:`~tensordict.nn.TensorDictModule`.</span>

<span class="sd">            - In all other cases an attempt to wrap it will be undergone as such:</span>
<span class="sd">              ``TensorDictModule(policy, in_keys=env_obs_key, out_keys=env.action_keys)``.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        frames_per_batch (int): A keyword-only argument representing the</span>
<span class="sd">            total number of elements in a batch.</span>
<span class="sd">        total_frames (int, optional): A keyword-only argument representing the</span>
<span class="sd">            total number of frames returned by the collector</span>
<span class="sd">            during its lifespan. If the ``total_frames`` is not divisible by</span>
<span class="sd">            ``frames_per_batch``, an exception is raised.</span>
<span class="sd">             Endless collectors can be created by passing ``total_frames=-1``.</span>
<span class="sd">             Defaults to ``-1`` (never ending collector).</span>
<span class="sd">        device (int, str or torch.device, optional): The generic device of the</span>
<span class="sd">            collector. The ``device`` args fills any non-specified device: if</span>
<span class="sd">            ``device`` is not ``None`` and any of ``storing_device``, ``policy_device`` or</span>
<span class="sd">            ``env_device`` is not specified, its value will be set to ``device``.</span>
<span class="sd">            Defaults to ``None`` (No default device).</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        storing_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the output :class:`~tensordict.TensorDict` will be stored.</span>
<span class="sd">            If ``device`` is passed and ``storing_device`` is ``None``, it will</span>
<span class="sd">            default to the value indicated by ``device``.</span>
<span class="sd">            For long trajectories, it may be necessary to store the data on a different</span>
<span class="sd">            device than the one where the policy and env are executed.</span>
<span class="sd">            Defaults to ``None`` (the output tensordict isn&#39;t on a specific device,</span>
<span class="sd">            leaf tensors sit on the device where they were created).</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        env_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the environment should be cast (or executed if that functionality is</span>
<span class="sd">            supported). If not specified and the env has a non-``None`` device,</span>
<span class="sd">            ``env_device`` will default to that value. If ``device`` is passed</span>
<span class="sd">            and ``env_device=None``, it will default to ``device``. If the value</span>
<span class="sd">            as such specified of ``env_device`` differs from ``policy_device``</span>
<span class="sd">            and one of them is not ``None``, the data will be cast to ``env_device``</span>
<span class="sd">            before being passed to the env (i.e., passing different devices to</span>
<span class="sd">            policy and env is supported). Defaults to ``None``.</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        policy_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the policy should be cast.</span>
<span class="sd">            If ``device`` is passed and ``policy_device=None``, it will default</span>
<span class="sd">            to ``device``. If the value as such specified of ``policy_device``</span>
<span class="sd">            differs from ``env_device`` and one of them is not ``None``,</span>
<span class="sd">            the data will be cast to ``policy_device`` before being passed to</span>
<span class="sd">            the policy (i.e., passing different devices to policy and env is</span>
<span class="sd">            supported). Defaults to ``None``.</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        create_env_kwargs (dict, optional): A dictionary with the</span>
<span class="sd">            keyword arguments used to create an environment. If a list is</span>
<span class="sd">            provided, each of its elements will be assigned to a sub-collector.</span>
<span class="sd">        max_frames_per_traj (int, optional): Maximum steps per trajectory.</span>
<span class="sd">            Note that a trajectory can span across multiple batches (unless</span>
<span class="sd">            ``reset_at_each_iter`` is set to ``True``, see below).</span>
<span class="sd">            Once a trajectory reaches ``n_steps``, the environment is reset.</span>
<span class="sd">            If the environment wraps multiple environments together, the number</span>
<span class="sd">            of steps is tracked for each environment independently. Negative</span>
<span class="sd">            values are allowed, in which case this argument is ignored.</span>
<span class="sd">            Defaults to ``None`` (i.e. no maximum number of steps).</span>
<span class="sd">        init_random_frames (int, optional): Number of frames for which the</span>
<span class="sd">            policy is ignored before it is called. This feature is mainly</span>
<span class="sd">            intended to be used in offline/model-based settings, where a</span>
<span class="sd">            batch of random trajectories can be used to initialize training.</span>
<span class="sd">            If provided, it will be rounded up to the closest multiple of frames_per_batch.</span>
<span class="sd">            Defaults to ``None`` (i.e. no random frames).</span>
<span class="sd">        reset_at_each_iter (bool, optional): Whether environments should be reset</span>
<span class="sd">            at the beginning of a batch collection.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        postproc (Callable, optional): A post-processing transform, such as</span>
<span class="sd">            a :class:`~torchrl.envs.Transform` or a :class:`~torchrl.data.postprocs.MultiStep`</span>
<span class="sd">            instance.</span>
<span class="sd">            Defaults to ``None``.</span>
<span class="sd">        split_trajs (bool, optional): Boolean indicating whether the resulting</span>
<span class="sd">            TensorDict should be split according to the trajectories.</span>
<span class="sd">            See :func:`~torchrl.collectors.utils.split_trajectories` for more</span>
<span class="sd">            information.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        exploration_type (ExplorationType, optional): interaction mode to be used when</span>
<span class="sd">            collecting data. Must be one of ``torchrl.envs.utils.ExplorationType.DETERMINISTIC``,</span>
<span class="sd">            ``torchrl.envs.utils.ExplorationType.RANDOM``, ``torchrl.envs.utils.ExplorationType.MODE``</span>
<span class="sd">            or ``torchrl.envs.utils.ExplorationType.MEAN``.</span>
<span class="sd">        reset_when_done (bool, optional): if ``True`` (default), an environment</span>
<span class="sd">            that return a ``True`` value in its ``&quot;done&quot;`` or ``&quot;truncated&quot;``</span>
<span class="sd">            entry will be reset at the corresponding indices.</span>
<span class="sd">        update_at_each_batch (boolm optional): if ``True``, :meth:`update_policy_weight_()`</span>
<span class="sd">            will be called before (sync) or after (async) each data collection.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        preemptive_threshold (:obj:`float`, optional): a value between 0.0 and 1.0 that specifies the ratio of workers</span>
<span class="sd">            that will be allowed to finished collecting their rollout before the rest are forced to end early.</span>
<span class="sd">        num_threads (int, optional): number of threads for this process.</span>
<span class="sd">            Defaults to the number of workers.</span>
<span class="sd">        num_sub_threads (int, optional): number of threads of the subprocesses.</span>
<span class="sd">            Should be equal to one plus the number of processes launched within</span>
<span class="sd">            each subprocess (or one if a single process is launched).</span>
<span class="sd">            Defaults to 1 for safety: if none is indicated, launching multiple</span>
<span class="sd">            workers may charge the cpu load too much and harm performance.</span>
<span class="sd">        cat_results (str, int or None): (:class:`~torchrl.collectors.MultiSyncDataCollector` exclusively).</span>
<span class="sd">            If ``&quot;stack&quot;``, the data collected from the workers will be stacked along the</span>
<span class="sd">            first dimension. This is the preferred behavior as it is the most compatible</span>
<span class="sd">            with the rest of the library.</span>
<span class="sd">            If ``0``, results will be concatenated along the first dimension</span>
<span class="sd">            of the outputs, which can be the batched dimension if the environments are</span>
<span class="sd">            batched or the time dimension if not.</span>
<span class="sd">            A ``cat_results`` value of ``-1`` will always concatenate results along the</span>
<span class="sd">            time dimension. This should be preferred over the default. Intermediate values</span>
<span class="sd">            are also accepted.</span>
<span class="sd">            Defaults to ``&quot;stack&quot;``.</span>

<span class="sd">            .. note:: From v0.5, this argument will default to ``&quot;stack&quot;`` for a better</span>
<span class="sd">                interoperability with the rest of the library.</span>

<span class="sd">        set_truncated (bool, optional): if ``True``, the truncated signals (and corresponding</span>
<span class="sd">            ``&quot;done&quot;`` but not ``&quot;terminated&quot;``) will be set to ``True`` when the last frame of</span>
<span class="sd">            a rollout is reached. If no ``&quot;truncated&quot;`` key is found, an exception is raised.</span>
<span class="sd">            Truncated keys can be set through ``env.add_truncated_keys``.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        use_buffers (bool, optional): if ``True``, a buffer will be used to stack the data.</span>
<span class="sd">            This isn&#39;t compatible with environments with dynamic specs. Defaults to ``True``</span>
<span class="sd">            for envs without dynamic specs, ``False`` for others.</span>
<span class="sd">        replay_buffer (ReplayBuffer, optional): if provided, the collector will not yield tensordict</span>
<span class="sd">            but populate the buffer instead. Defaults to ``None``.</span>
<span class="sd">        trust_policy (bool, optional): if ``True``, a non-TensorDictModule policy will be trusted to be</span>
<span class="sd">            assumed to be compatible with the collector. This defaults to ``True`` for CudaGraphModules</span>
<span class="sd">            and ``False`` otherwise.</span>
<span class="sd">        compile_policy (bool or Dict[str, Any], optional): if ``True``, the policy will be compiled</span>
<span class="sd">            using :func:`~torch.compile` default behaviour. If a dictionary of kwargs is passed, it</span>
<span class="sd">            will be used to compile the policy.</span>
<span class="sd">        cudagraph_policy (bool or Dict[str, Any], optional): if ``True``, the policy will be wrapped</span>
<span class="sd">            in :class:`~tensordict.nn.CudaGraphModule` with default kwargs.</span>
<span class="sd">            If a dictionary of kwargs is passed, it will be used to wrap the policy.</span>
<span class="sd">        no_cuda_sync (bool): if ``True``, explicit CUDA synchronizations calls will be bypassed.</span>
<span class="sd">            For environments running directly on CUDA (`IsaacLab &lt;https://github.com/isaac-sim/IsaacLab/&gt;`_</span>
<span class="sd">            or `ManiSkills &lt;https://github.com/haosulab/ManiSkill/&gt;`_) cuda synchronization may cause unexpected</span>
<span class="sd">            crashes.</span>
<span class="sd">            Defaults to ``False``.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">create_env_fn</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="n">EnvBase</span><span class="p">]],</span>
        <span class="n">policy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Union</span><span class="p">[</span>
                <span class="n">TensorDictModule</span><span class="p">,</span>
                <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">frames_per_batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">total_frames</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">storing_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">env_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">policy_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">create_env_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_frames_per_traj</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">init_random_frames</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">reset_at_each_iter</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">postproc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">split_trajs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">exploration_type</span><span class="p">:</span> <span class="n">ExplorationType</span> <span class="o">=</span> <span class="n">DEFAULT_EXPLORATION_TYPE</span><span class="p">,</span>
        <span class="n">reset_when_done</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">update_at_each_batch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">preemptive_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_threads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_sub_threads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">cat_results</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">set_truncated</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">use_buffers</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">replay_buffer</span><span class="p">:</span> <span class="n">ReplayBuffer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">replay_buffer_chunk</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">trust_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">compile_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cudagraph_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">no_cuda_sync</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">create_env_fn</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_truncated</span> <span class="o">=</span> <span class="n">set_truncated</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_sub_threads</span> <span class="o">=</span> <span class="n">num_sub_threads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_threads</span> <span class="o">=</span> <span class="n">num_threads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span> <span class="o">=</span> <span class="n">create_env_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_read_compile_kwargs</span><span class="p">(</span><span class="n">compile_policy</span><span class="p">,</span> <span class="n">cudagraph_policy</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">create_env_kwargs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">create_env_kwargs</span>
            <span class="k">if</span> <span class="n">create_env_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="p">[{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">)]</span>
        <span class="p">)</span>
        <span class="c1"># Preparing devices:</span>
        <span class="c1"># We want the user to be able to choose, for each worker, on which</span>
        <span class="c1"># device will the policy live and which device will be used to store</span>
        <span class="c1"># data. Those devices may or may not match.</span>
        <span class="c1"># One caveat is that, if there is only one device for the policy, and</span>
        <span class="c1"># if there are multiple workers, sending the same device and policy</span>
        <span class="c1"># to be copied to each worker will result in multiple copies of the</span>
        <span class="c1"># same policy on the same device.</span>
        <span class="c1"># To go around this, we do the copies of the policy in the server</span>
        <span class="c1"># (this object) to each possible device, and send to all the</span>
        <span class="c1"># processes their copy of the policy.</span>

        <span class="n">storing_devices</span><span class="p">,</span> <span class="n">policy_devices</span><span class="p">,</span> <span class="n">env_devices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_devices</span><span class="p">(</span>
            <span class="n">storing_device</span><span class="o">=</span><span class="n">storing_device</span><span class="p">,</span>
            <span class="n">env_device</span><span class="o">=</span><span class="n">env_device</span><span class="p">,</span>
            <span class="n">policy_device</span><span class="o">=</span><span class="n">policy_device</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># to avoid confusion</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span> <span class="o">=</span> <span class="n">storing_devices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="o">=</span> <span class="n">policy_devices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span> <span class="o">=</span> <span class="n">env_devices</span>

        <span class="k">del</span> <span class="n">storing_device</span><span class="p">,</span> <span class="n">env_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span> <span class="o">=</span> <span class="n">no_cuda_sync</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span> <span class="o">=</span> <span class="n">use_buffers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">replay_buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_replay_buffer_init</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer_chunk</span> <span class="o">=</span> <span class="n">replay_buffer_chunk</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">replay_buffer</span><span class="p">,</span> <span class="s2">&quot;shared&quot;</span><span class="p">)</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="n">replay_buffer</span><span class="o">.</span><span class="n">shared</span>
        <span class="p">):</span>
            <span class="n">replay_buffer</span><span class="o">.</span><span class="n">share</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_policy_weights_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_weights_fn_dict</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="n">trust_policy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">trust_policy</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">CudaGraphModule</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trust_policy</span> <span class="o">=</span> <span class="n">trust_policy</span>

        <span class="k">for</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_maker</span><span class="p">,</span> <span class="n">env_maker_kwargs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_kwargs</span>
        <span class="p">):</span>
            <span class="p">(</span><span class="n">policy_copy</span><span class="p">,</span> <span class="n">get_weights_fn</span><span class="p">,)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_policy_and_device</span><span class="p">(</span>
                <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">,</span>
                <span class="n">policy_device</span><span class="o">=</span><span class="n">policy_device</span><span class="p">,</span>
                <span class="n">env_maker</span><span class="o">=</span><span class="n">env_maker</span><span class="p">,</span>
                <span class="n">env_maker_kwargs</span><span class="o">=</span><span class="n">env_maker_kwargs</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">policy_copy</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">policy</span><span class="p">):</span>
                <span class="n">policy</span> <span class="o">=</span> <span class="n">policy_copy</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">TensorDict</span><span class="o">.</span><span class="n">from_module</span><span class="p">(</span><span class="n">policy_copy</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy_copy</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
                <span class="k">else</span> <span class="n">TensorDict</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_policy_weights_dict</span><span class="p">[</span><span class="n">policy_device</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_get_weights_fn_dict</span><span class="p">[</span><span class="n">policy_device</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_weights_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">policy</span>

        <span class="n">remainder</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">total_frames</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">total_frames</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">total_frames</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">remainder</span> <span class="o">=</span> <span class="n">total_frames</span> <span class="o">%</span> <span class="n">frames_per_batch</span>
            <span class="k">if</span> <span class="n">remainder</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">RL_WARNINGS</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;total_frames (</span><span class="si">{</span><span class="n">total_frames</span><span class="si">}</span><span class="s2">) is not exactly divisible by frames_per_batch (</span><span class="si">{</span><span class="n">frames_per_batch</span><span class="si">}</span><span class="s2">). &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;This means </span><span class="si">{</span><span class="n">frames_per_batch</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">remainder</span><span class="si">}</span><span class="s2"> additional frames will be collected. &quot;</span>
                    <span class="s2">&quot;To silence this message, set the environment variable RL_WARNINGS to False.&quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">total_frames</span><span class="p">)</span> <span class="k">if</span> <span class="n">total_frames</span> <span class="o">!=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">total_frames</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_at_each_iter</span> <span class="o">=</span> <span class="n">reset_at_each_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span> <span class="o">=</span> <span class="n">postproc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_frames_per_traj</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">max_frames_per_traj</span><span class="p">)</span> <span class="k">if</span> <span class="n">max_frames_per_traj</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">requested_frames_per_batch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">frames_per_batch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_when_done</span> <span class="o">=</span> <span class="n">reset_when_done</span>
        <span class="k">if</span> <span class="n">split_trajs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">split_trajs</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_when_done</span> <span class="ow">and</span> <span class="n">split_trajs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot split trajectories when reset_when_done is False.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">split_trajs</span> <span class="o">=</span> <span class="n">split_trajs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">init_random_frames</span><span class="p">)</span> <span class="k">if</span> <span class="n">init_random_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_at_each_batch</span> <span class="o">=</span> <span class="n">update_at_each_batch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exploration_type</span> <span class="o">=</span> <span class="n">exploration_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_worker</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">if</span> <span class="n">preemptive_threshold</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">_is_osx</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot use preemption on OSX due to Queue.qsize() not being implemented on this platform.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">preemptive_threshold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">preemptive_threshold</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="n">manager</span> <span class="o">=</span> <span class="n">_InterruptorManager</span><span class="p">()</span>
            <span class="n">manager</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">_Interruptor</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">preemptive_threshold</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_run_processes</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_exclude_private_keys</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">cat_results</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cat_results</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">))</span>
            <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">cat_results</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">cat_results</span> <span class="o">!=</span> <span class="s2">&quot;stack&quot;</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;cat_results must be a string (&#39;stack&#39;) &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;or an integer representing the cat dimension. Got </span><span class="si">{</span><span class="n">cat_results</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">MultiSyncDataCollector</span><span class="p">)</span> <span class="ow">and</span> <span class="n">cat_results</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span>
            <span class="s2">&quot;stack&quot;</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;cat_results can only be used with ``MultiSyncDataCollector``.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cat_results</span> <span class="o">=</span> <span class="n">cat_results</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_check_replay_buffer_init</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="n">is_init</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">_storage</span><span class="p">,</span> <span class="s2">&quot;initialized&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_init</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">EnvCreator</span><span class="p">):</span>
                <span class="n">fake_td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">meta_data</span><span class="o">.</span><span class="n">tensordict</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">EnvBase</span><span class="p">):</span>
                <span class="n">fake_td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">fake_tensordict</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">fake_td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span>
                    <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_kwargs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="p">)</span><span class="o">.</span><span class="n">fake_tensordict</span><span class="p">()</span>
            <span class="n">fake_td</span><span class="p">[</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="n">fake_td</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">fake_td</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_total_workers_from_env</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">env_creators</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_creators</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="bp">cls</span><span class="o">.</span><span class="n">_total_workers_from_env</span><span class="p">(</span><span class="n">env_creator</span><span class="p">)</span> <span class="k">for</span> <span class="n">env_creator</span> <span class="ow">in</span> <span class="n">env_creators</span>
            <span class="p">)</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs</span><span class="w"> </span><span class="kn">import</span> <span class="n">ParallelEnv</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_creators</span><span class="p">,</span> <span class="n">ParallelEnv</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">env_creators</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">return</span> <span class="mi">1</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_devices</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">storing_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">policy_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">env_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># convert all devices to lists</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">storing_device</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">storing_device</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">storing_device</span><span class="p">,</span>
            <span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy_device</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">policy_device</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">policy_device</span><span class="p">,</span>
            <span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_device</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">env_device</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">env_device</span><span class="p">,</span>
            <span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">device</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">device</span><span class="p">,</span>
            <span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">storing_device</span><span class="p">)</span>
            <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">policy_device</span><span class="p">)</span>
            <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">env_device</span><span class="p">)</span>
            <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;THe length of the devices does not match the number of workers: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="n">storing_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_device</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span>
                <span class="n">SyncDataCollector</span><span class="o">.</span><span class="n">_get_devices</span><span class="p">(</span>
                    <span class="n">storing_device</span><span class="o">=</span><span class="n">storing_device</span><span class="p">,</span>
                    <span class="n">policy_device</span><span class="o">=</span><span class="n">policy_device</span><span class="p">,</span>
                    <span class="n">env_device</span><span class="o">=</span><span class="n">env_device</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="p">(</span><span class="n">storing_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_device</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                    <span class="n">storing_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_device</span><span class="p">,</span> <span class="n">device</span>
                <span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">storing_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_device</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">frames_per_batch_worker</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">update_policy_weights_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">policy_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy_weights</span><span class="p">,</span> <span class="n">TensorDictParams</span><span class="p">):</span>
            <span class="n">policy_weights</span> <span class="o">=</span> <span class="n">policy_weights</span><span class="o">.</span><span class="n">data</span>
        <span class="k">for</span> <span class="n">_device</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_policy_weights_dict</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">policy_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_policy_weights_dict</span><span class="p">[</span><span class="n">_device</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">update_</span><span class="p">(</span><span class="n">policy_weights</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_weights_fn_dict</span><span class="p">[</span><span class="n">_device</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">original_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_weights_fn_dict</span><span class="p">[</span><span class="n">_device</span><span class="p">]()</span>
                <span class="k">if</span> <span class="n">original_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># if the weights match in identity, we can spare a call to update_</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">original_weights</span><span class="p">,</span> <span class="n">TensorDictParams</span><span class="p">):</span>
                    <span class="n">original_weights</span> <span class="o">=</span> <span class="n">original_weights</span><span class="o">.</span><span class="n">data</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_policy_weights_dict</span><span class="p">[</span><span class="n">_device</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">update_</span><span class="p">(</span><span class="n">original_weights</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_queue_len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_run_processes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_threads</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">total_workers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_workers_from_env</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_threads</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
                <span class="mi">1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_num_threads</span><span class="p">()</span> <span class="o">-</span> <span class="n">total_workers</span>
            <span class="p">)</span>  <span class="c1"># 1 more thread for this proc</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_threads</span><span class="p">)</span>
        <span class="n">queue_out</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Queue</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_queue_len</span><span class="p">)</span>  <span class="c1"># sends data from proc to main</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">procs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_traj_pool</span> <span class="o">=</span> <span class="n">_TrajectoryPool</span><span class="p">(</span><span class="n">lock</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">env_fun</span><span class="p">,</span> <span class="n">env_fun_kwargs</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
            <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_kwargs</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">pipe_parent</span><span class="p">,</span> <span class="n">pipe_child</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Pipe</span><span class="p">()</span>  <span class="c1"># send messages to procs</span>
            <span class="k">if</span> <span class="n">env_fun</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">!=</span> <span class="s2">&quot;EnvCreator&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">env_fun</span><span class="p">,</span> <span class="n">EnvBase</span>
            <span class="p">):</span>  <span class="c1"># to avoid circular imports</span>
                <span class="n">env_fun</span> <span class="o">=</span> <span class="n">CloudpickleWrapper</span><span class="p">(</span><span class="n">env_fun</span><span class="p">)</span>

            <span class="c1"># Create a policy on the right device</span>
            <span class="n">policy_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">storing_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">env_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">policy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span>
            <span class="n">policy_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_policy_weights_dict</span><span class="p">[</span><span class="n">policy_device</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">policy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">policy_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">cm</span> <span class="o">=</span> <span class="n">policy_weights</span><span class="o">.</span><span class="n">to_module</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">cm</span> <span class="o">=</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">nullcontext</span><span class="p">()</span>
            <span class="k">with</span> <span class="n">cm</span><span class="p">:</span>
                <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;pipe_parent&quot;</span><span class="p">:</span> <span class="n">pipe_parent</span><span class="p">,</span>
                    <span class="s2">&quot;pipe_child&quot;</span><span class="p">:</span> <span class="n">pipe_child</span><span class="p">,</span>
                    <span class="s2">&quot;queue_out&quot;</span><span class="p">:</span> <span class="n">queue_out</span><span class="p">,</span>
                    <span class="s2">&quot;create_env_fn&quot;</span><span class="p">:</span> <span class="n">env_fun</span><span class="p">,</span>
                    <span class="s2">&quot;create_env_kwargs&quot;</span><span class="p">:</span> <span class="n">env_fun_kwargs</span><span class="p">,</span>
                    <span class="s2">&quot;policy&quot;</span><span class="p">:</span> <span class="n">policy</span><span class="p">,</span>
                    <span class="s2">&quot;max_frames_per_traj&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_frames_per_traj</span><span class="p">,</span>
                    <span class="s2">&quot;frames_per_batch&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_batch_worker</span><span class="p">,</span>
                    <span class="s2">&quot;reset_at_each_iter&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_at_each_iter</span><span class="p">,</span>
                    <span class="s2">&quot;policy_device&quot;</span><span class="p">:</span> <span class="n">policy_device</span><span class="p">,</span>
                    <span class="s2">&quot;storing_device&quot;</span><span class="p">:</span> <span class="n">storing_device</span><span class="p">,</span>
                    <span class="s2">&quot;env_device&quot;</span><span class="p">:</span> <span class="n">env_device</span><span class="p">,</span>
                    <span class="s2">&quot;exploration_type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">exploration_type</span><span class="p">,</span>
                    <span class="s2">&quot;reset_when_done&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_when_done</span><span class="p">,</span>
                    <span class="s2">&quot;idx&quot;</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span>
                    <span class="s2">&quot;interruptor&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span><span class="p">,</span>
                    <span class="s2">&quot;set_truncated&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">set_truncated</span><span class="p">,</span>
                    <span class="s2">&quot;use_buffers&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span><span class="p">,</span>
                    <span class="s2">&quot;replay_buffer&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">,</span>
                    <span class="s2">&quot;replay_buffer_chunk&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer_chunk</span><span class="p">,</span>
                    <span class="s2">&quot;traj_pool&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_traj_pool</span><span class="p">,</span>
                    <span class="s2">&quot;trust_policy&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">trust_policy</span><span class="p">,</span>
                    <span class="s2">&quot;compile_policy&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy_kwargs</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy</span>
                    <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
                    <span class="s2">&quot;cudagraph_policy&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cudagraphed_policy_kwargs</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cudagraphed_policy</span>
                    <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
                    <span class="s2">&quot;no_cuda_sync&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="n">proc</span> <span class="o">=</span> <span class="n">_ProcessNoWarn</span><span class="p">(</span>
                    <span class="n">target</span><span class="o">=</span><span class="n">_main_async_collector</span><span class="p">,</span>
                    <span class="n">num_threads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_sub_threads</span><span class="p">,</span>
                    <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="c1"># proc.daemon can&#39;t be set as daemonic processes may be launched by the process itself</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">proc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
                <span class="k">except</span> <span class="n">_pickle</span><span class="o">.</span><span class="n">PicklingError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                    <span class="k">if</span> <span class="s2">&quot;&lt;lambda&gt;&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">err</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
<span class="w">                            </span><span class="sd">&quot;&quot;&quot;Can&#39;t open a process with doubly cloud-pickled lambda function.</span>
<span class="sd">This error is likely due to an attempt to use a ParallelEnv in a</span>
<span class="sd">multiprocessed data collector. To do this, consider wrapping your</span>
<span class="sd">lambda function in an `torchrl.envs.EnvCreator` wrapper as follows:</span>
<span class="sd">`env = ParallelEnv(N, EnvCreator(my_lambda_function))`.</span>
<span class="sd">This will not only ensure that your lambda function is cloud-pickled once, but</span>
<span class="sd">also that the state dict is synchronised across processes if needed.&quot;&quot;&quot;</span>
                        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">err</span>
                <span class="n">pipe_child</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">proc</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pipe_parent</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">pipe_parent</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">:</span>
            <span class="n">pipe_parent</span><span class="o">.</span><span class="n">poll</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">INSTANTIATE_TIMEOUT</span><span class="p">)</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="n">pipe_parent</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;instantiated&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span> <span class="o">=</span> <span class="n">queue_out</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="c1"># an AttributeError will typically be raised if the collector is deleted when the program ends.</span>
            <span class="c1"># In the future, insignificant changes to the close method may change the error type.</span>
            <span class="c1"># We excplicitely assume that any error raised during closure in</span>
            <span class="c1"># __del__ will not affect the program.</span>
            <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">shutdown</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Shuts down all processes. This operation is irreversible.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shutdown_main</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_shutdown_main</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
                <span class="k">return</span>
            <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">is_alive</span><span class="p">():</span>
                    <span class="k">continue</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;close&quot;</span><span class="p">))</span>

                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">poll</span><span class="p">(</span><span class="mf">10.0</span><span class="p">):</span>
                        <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
                        <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;closed&quot;</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2"> but expected &#39;close&#39;&quot;</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">continue</span>
                <span class="k">except</span> <span class="ne">BrokenPipeError</span><span class="p">:</span>
                    <span class="k">continue</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">pipe</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">:</span>
                <span class="n">pipe</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">proc</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">:</span>
                <span class="n">proc</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">torchrl</span>

            <span class="n">num_threads</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
                <span class="n">torchrl</span><span class="o">.</span><span class="n">_THREAD_POOL_INIT</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">get_num_threads</span><span class="p">()</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_workers_from_env</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span><span class="p">(</span><span class="n">num_threads</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">proc</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">proc</span><span class="o">.</span><span class="n">is_alive</span><span class="p">():</span>
                    <span class="n">proc</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sets the seeds of the environments stored in the DataCollector.</span>

<span class="sd">        Args:</span>
<span class="sd">            seed: integer representing the seed to be used for the environment.</span>
<span class="sd">            static_seed (bool, optional): if ``True``, the seed is not incremented.</span>
<span class="sd">                Defaults to False</span>

<span class="sd">        Returns:</span>
<span class="sd">            Output seed. This is useful when more than one environment is</span>
<span class="sd">            contained in the DataCollector, as the seed will be incremented for</span>
<span class="sd">            each of these. The resulting seed is the seed of the last</span>
<span class="sd">            environment.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs import ParallelEnv</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">            &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">            &gt;&gt;&gt; from torch import nn</span>
<span class="sd">            &gt;&gt;&gt; env_fn = lambda: GymEnv(&quot;Pendulum-v1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; env_fn_parallel = lambda: ParallelEnv(6, env_fn)</span>
<span class="sd">            &gt;&gt;&gt; policy = TensorDictModule(nn.Linear(3, 1), in_keys=[&quot;observation&quot;], out_keys=[&quot;action&quot;])</span>
<span class="sd">            &gt;&gt;&gt; collector = SyncDataCollector(env_fn_parallel, policy, frames_per_batch=100, total_frames=300)</span>
<span class="sd">            &gt;&gt;&gt; out_seed = collector.set_seed(1)  # out_seed = 6</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">(((</span><span class="n">seed</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">),</span> <span class="s2">&quot;seed&quot;</span><span class="p">))</span>
            <span class="n">new_seed</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;seeded&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected msg=&#39;seeded&#39;, got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">seed</span> <span class="o">=</span> <span class="n">new_seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">seed</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reset_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Resets the environments to a new initial state.</span>

<span class="sd">        Args:</span>
<span class="sd">            reset_idx: Optional. Sequence indicating which environments have</span>
<span class="sd">                to be reset. If None, all environments are reset.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">reset_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">reset_idx</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">reset_idx</span><span class="p">[</span><span class="n">idx</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;reset&quot;</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">reset_idx</span><span class="p">[</span><span class="n">idx</span><span class="p">]:</span>
                <span class="n">j</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;reset&quot;</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected msg=&#39;reset&#39;, got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the state_dict of the data collector.</span>

<span class="sd">        Each field represents a worker containing its own state_dict.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;state_dict&quot;</span><span class="p">))</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="n">_state_dict</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;state_dict&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected msg=&#39;state_dict&#39;, got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">state_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;worker</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_state_dict</span>
        <span class="n">state_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;frames&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span><span class="p">,</span> <span class="s2">&quot;iter&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span><span class="p">})</span>

        <span class="k">return</span> <span class="n">state_dict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Loads the state_dict on the workers.</span>

<span class="sd">        Args:</span>
<span class="sd">            state_dict (OrderedDict): state_dict of the form</span>
<span class="sd">                ``{&quot;worker0&quot;: state_dict0, &quot;worker1&quot;: state_dict1}``.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">state_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;worker</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">],</span> <span class="s2">&quot;load_state_dict&quot;</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;loaded&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected msg=&#39;loaded&#39;, got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;iter&quot;</span><span class="p">]</span>


<div class="viewcode-block" id="MultiSyncDataCollector"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiSyncDataCollector.html#torchrl.collectors.MultiSyncDataCollector">[docs]</a><span class="nd">@accept_remote_rref_udf_invocation</span>
<span class="k">class</span><span class="w"> </span><span class="nc">MultiSyncDataCollector</span><span class="p">(</span><span class="n">_MultiDataCollector</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Runs a given number of DataCollectors on separate processes synchronously.</span>

<span class="sd">    .. aafig::</span>

<span class="sd">            +----------------------------------------------------------------------+</span>
<span class="sd">            |            &quot;MultiSyncDataCollector&quot;                 |                |</span>
<span class="sd">            |~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~|                |</span>
<span class="sd">            |   &quot;Collector 1&quot; |  &quot;Collector 2&quot;  |  &quot;Collector 3&quot;  |     Main       |</span>
<span class="sd">            |~~~~~~~~~~~~~~~~~|~~~~~~~~~~~~~~~~~|~~~~~~~~~~~~~~~~~|~~~~~~~~~~~~~~~~|</span>
<span class="sd">            | &quot;env1&quot; | &quot;env2&quot; | &quot;env3&quot; | &quot;env4&quot; | &quot;env5&quot; | &quot;env6&quot; |                |</span>
<span class="sd">            |~~~~~~~~|~~~~~~~~|~~~~~~~~|~~~~~~~~|~~~~~~~~|~~~~~~~~|~~~~~~~~~~~~~~~~|</span>
<span class="sd">            |&quot;reset&quot; |&quot;reset&quot; |&quot;reset&quot; |&quot;reset&quot; |&quot;reset&quot; |&quot;reset&quot; |                |</span>
<span class="sd">            |        |        |        |        |        |        |                |</span>
<span class="sd">            |       &quot;actor&quot;   |        |        |       &quot;actor&quot;   |                |</span>
<span class="sd">            |                 |        |        |                 |                |</span>
<span class="sd">            | &quot;step&quot; | &quot;step&quot; |       &quot;actor&quot;   |                 |                |</span>
<span class="sd">            |        |        |                 |                 |                |</span>
<span class="sd">            |        |        |                 | &quot;step&quot; | &quot;step&quot; |                |</span>
<span class="sd">            |        |        |                 |        |        |                |</span>
<span class="sd">            |       &quot;actor&quot;   | &quot;step&quot; | &quot;step&quot; |       &quot;actor&quot;   |                |</span>
<span class="sd">            |                 |        |        |                 |                |</span>
<span class="sd">            |                 |       &quot;actor&quot;   |                 |                |</span>
<span class="sd">            |                 |                 |                 |                |</span>
<span class="sd">            |                       &quot;yield batch of traj 1&quot;-------&gt;&quot;collect, train&quot;|</span>
<span class="sd">            |                                                     |                |</span>
<span class="sd">            | &quot;step&quot; | &quot;step&quot; | &quot;step&quot; | &quot;step&quot; | &quot;step&quot; | &quot;step&quot; |                |</span>
<span class="sd">            |        |        |        |        |        |        |                |</span>
<span class="sd">            |       &quot;actor&quot;   |       &quot;actor&quot;   |        |        |                |</span>
<span class="sd">            |                 | &quot;step&quot; | &quot;step&quot; |       &quot;actor&quot;   |                |</span>
<span class="sd">            |                 |        |        |                 |                |</span>
<span class="sd">            | &quot;step&quot; | &quot;step&quot; |       &quot;actor&quot;   | &quot;step&quot; | &quot;step&quot; |                |</span>
<span class="sd">            |        |        |                 |        |        |                |</span>
<span class="sd">            |       &quot;actor&quot;   |                 |       &quot;actor&quot;   |                |</span>
<span class="sd">            |                       &quot;yield batch of traj 2&quot;-------&gt;&quot;collect, train&quot;|</span>
<span class="sd">            |                                                     |                |</span>
<span class="sd">            +----------------------------------------------------------------------+</span>

<span class="sd">    Envs can be identical or different.</span>

<span class="sd">    The collection starts when the next item of the collector is queried,</span>
<span class="sd">    and no environment step is computed in between the reception of a batch of</span>
<span class="sd">    trajectory and the start of the next collection.</span>
<span class="sd">    This class can be safely used with online RL sota-implementations.</span>

<span class="sd">    .. note::</span>
<span class="sd">        Python requires multiprocessed code to be instantiated within a main guard:</span>

<span class="sd">            &gt;&gt;&gt; from torchrl.collectors import MultiSyncDataCollector</span>
<span class="sd">            &gt;&gt;&gt; if __name__ == &quot;__main__&quot;:</span>
<span class="sd">            ...     # Create your collector here</span>
<span class="sd">            ...     collector = MultiSyncDataCollector(...)</span>

<span class="sd">        See https://docs.python.org/3/library/multiprocessing.html for more info.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.collectors import MultiSyncDataCollector</span>
<span class="sd">        &gt;&gt;&gt; if __name__ == &quot;__main__&quot;:</span>
<span class="sd">        ...     env_maker = lambda: GymEnv(&quot;Pendulum-v1&quot;, device=&quot;cpu&quot;)</span>
<span class="sd">        ...     policy = TensorDictModule(nn.Linear(3, 1), in_keys=[&quot;observation&quot;], out_keys=[&quot;action&quot;])</span>
<span class="sd">        ...     collector = MultiSyncDataCollector(</span>
<span class="sd">        ...         create_env_fn=[env_maker, env_maker],</span>
<span class="sd">        ...         policy=policy,</span>
<span class="sd">        ...         total_frames=2000,</span>
<span class="sd">        ...         max_frames_per_traj=50,</span>
<span class="sd">        ...         frames_per_batch=200,</span>
<span class="sd">        ...         init_random_frames=-1,</span>
<span class="sd">        ...         reset_at_each_iter=False,</span>
<span class="sd">        ...         device=&quot;cpu&quot;,</span>
<span class="sd">        ...         storing_device=&quot;cpu&quot;,</span>
<span class="sd">        ...         cat_results=&quot;stack&quot;,</span>
<span class="sd">        ...     )</span>
<span class="sd">        ...     for i, data in enumerate(collector):</span>
<span class="sd">        ...         if i == 2:</span>
<span class="sd">        ...             print(data)</span>
<span class="sd">        ...             break</span>
<span class="sd">        &gt;&gt;&gt; collector&gt;shutdown()</span>
<span class="sd">        &gt;&gt;&gt; del collector</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                collector: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        traj_ids: Tensor(shape=torch.Size([200]), device=cpu, dtype=torch.int64, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([200]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        step_count: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                        truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([200]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                step_count: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([200]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="vm">__doc__</span> <span class="o">+=</span> <span class="n">_MultiDataCollector</span><span class="o">.</span><span class="vm">__doc__</span>

    <span class="c1"># for RPC</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">next</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiSyncDataCollector.shutdown"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiSyncDataCollector.html#torchrl.collectors.MultiSyncDataCollector.shutdown">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">shutdown</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;out_buffer&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;buffers&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiSyncDataCollector.set_seed"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiSyncDataCollector.html#torchrl.collectors.MultiSyncDataCollector.set_seed">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">)</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiSyncDataCollector.state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiSyncDataCollector.html#torchrl.collectors.MultiSyncDataCollector.state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiSyncDataCollector.load_state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiSyncDataCollector.html#torchrl.collectors.MultiSyncDataCollector.load_state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiSyncDataCollector.update_policy_weights_"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiSyncDataCollector.html#torchrl.collectors.MultiSyncDataCollector.update_policy_weights_">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">update_policy_weights_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">policy_weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">update_policy_weights_</span><span class="p">(</span><span class="n">policy_weights</span><span class="p">)</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">frames_per_batch_worker</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">requested_frames_per_batch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">RL_WARNINGS</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;frames_per_batch </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">requested_frames_per_batch</span><span class="si">}</span><span class="s2"> is not exactly divisible by the number of collector workers </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="si">}</span><span class="s2">,&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; this results in more frames_per_batch per iteration that requested.&quot;</span>
                <span class="s2">&quot;To silence this message, set the environment variable RL_WARNINGS to False.&quot;</span>
            <span class="p">)</span>
        <span class="n">frames_per_batch_worker</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span>
            <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">requested_frames_per_batch</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">frames_per_batch_worker</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_queue_len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">iterator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">]:</span>
        <span class="n">cat_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cat_results</span>
        <span class="k">if</span> <span class="n">cat_results</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cat_results</span> <span class="o">=</span> <span class="s2">&quot;stack&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">dones</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">)]</span>
        <span class="n">workers_frames</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">)]</span>
        <span class="n">same_device</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">preempt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">preemptive_threshold</span> <span class="o">&lt;</span> <span class="mf">1.0</span>

        <span class="k">while</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">dones</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span><span class="p">:</span>
            <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_at_each_batch</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update_policy_weights_</span><span class="p">()</span>

            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span>
                <span class="p">):</span>
                    <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;continue_random&quot;</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;continue&quot;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="n">msg</span><span class="p">))</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="k">if</span> <span class="n">preempt</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span><span class="o">.</span><span class="n">start_collection</span><span class="p">()</span>
                <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span><span class="o">.</span><span class="n">qsize</span><span class="p">()</span> <span class="o">&lt;</span> <span class="nb">int</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">preemptive_threshold</span>
                <span class="p">):</span>
                    <span class="k">continue</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span><span class="o">.</span><span class="n">stop_collection</span><span class="p">()</span>
                <span class="c1"># Now wait for stragglers to return</span>
                <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span><span class="o">.</span><span class="n">qsize</span><span class="p">()</span> <span class="o">&lt;</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                    <span class="k">continue</span>

            <span class="n">recv</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">()</span>
            <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">recv</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">_TIMEOUT</span> <span class="o">*</span> <span class="n">_MAX_IDLE_COUNT</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">new_data</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">_TIMEOUT</span><span class="p">)</span>
                        <span class="n">recv</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">new_data</span><span class="p">,</span> <span class="n">j</span><span class="p">))</span>
                    <span class="k">except</span> <span class="p">(</span><span class="ne">TimeoutError</span><span class="p">,</span> <span class="n">Empty</span><span class="p">):</span>
                        <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">_TIMEOUT</span> <span class="o">*</span> <span class="n">_MAX_IDLE_COUNT</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
                <span class="k">finally</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Failed to gather all collector output within </span><span class="si">{</span><span class="n">_TIMEOUT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">_MAX_IDLE_COUNT</span><span class="si">}</span><span class="s2"> seconds. &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Increase the MAX_IDLE_COUNT environment variable to bypass this error.&quot;</span>
                    <span class="p">)</span>

            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                <span class="n">new_data</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">recv</span><span class="o">.</span><span class="n">popleft</span><span class="p">()</span>
                <span class="n">use_buffers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">new_data</span>
                    <span class="n">workers_frames</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">workers_frames</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_batch_worker</span>
                    <span class="p">)</span>
                    <span class="k">continue</span>
                <span class="k">elif</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">use_buffers</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">data</span><span class="p">,</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">new_data</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span>
                        <span class="k">if</span> <span class="n">use_buffers</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">use_buffers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="n">idx</span> <span class="o">=</span> <span class="n">new_data</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">new_data</span>

                <span class="k">if</span> <span class="n">preempt</span><span class="p">:</span>
                    <span class="c1"># mask buffers if cat, and create a mask if stack</span>
                    <span class="k">if</span> <span class="n">cat_results</span> <span class="o">!=</span> <span class="s2">&quot;stack&quot;</span><span class="p">:</span>
                        <span class="n">buffers</span> <span class="o">=</span> <span class="p">{}</span>
                        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">buffer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                            <span class="n">valid</span> <span class="o">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">))</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
                            <span class="k">if</span> <span class="n">valid</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                                <span class="n">valid</span> <span class="o">=</span> <span class="n">valid</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">valid</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                                <span class="n">valid</span> <span class="o">=</span> <span class="n">valid</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                            <span class="n">buffers</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">valid</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">buffer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                            <span class="k">with</span> <span class="n">buffer</span><span class="o">.</span><span class="n">unlock_</span><span class="p">():</span>
                                <span class="n">buffer</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                                    <span class="p">(</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;mask&quot;</span><span class="p">),</span>
                                    <span class="n">buffer</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">))</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                <span class="p">)</span>
                        <span class="n">buffers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">buffers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span>

                <span class="n">workers_frames</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">workers_frames</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">buffers</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">workers_frames</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span><span class="p">:</span>
                    <span class="n">dones</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">yield</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_batch_worker</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
                <span class="k">continue</span>

            <span class="c1"># we have to correct the traj_ids to make sure that they don&#39;t overlap</span>
            <span class="c1"># We can count the number of frames collected for free in this loop</span>
            <span class="n">n_collected</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                <span class="n">buffer</span> <span class="o">=</span> <span class="n">buffers</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                <span class="n">traj_ids</span> <span class="o">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">))</span>
                <span class="k">if</span> <span class="n">preempt</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">cat_results</span> <span class="o">==</span> <span class="s2">&quot;stack&quot;</span><span class="p">:</span>
                        <span class="n">mask_frames</span> <span class="o">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">))</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
                        <span class="n">n_collected</span> <span class="o">+=</span> <span class="n">mask_frames</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">n_collected</span> <span class="o">+=</span> <span class="n">traj_ids</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">n_collected</span> <span class="o">+=</span> <span class="n">traj_ids</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">same_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">prev_device</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">same_device</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">prev_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">prev_device</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">device</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">same_device</span> <span class="o">=</span> <span class="n">same_device</span> <span class="ow">and</span> <span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">prev_device</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">cat_results</span> <span class="o">==</span> <span class="s2">&quot;stack&quot;</span><span class="p">:</span>
                <span class="n">stack</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">stack</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span> <span class="k">else</span> <span class="n">TensorDict</span><span class="o">.</span><span class="n">maybe_dense_stack</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">same_device</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span> <span class="o">=</span> <span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">buffers</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="mi">0</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span> <span class="o">=</span> <span class="n">stack</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">buffers</span><span class="o">.</span><span class="n">values</span><span class="p">()],</span> <span class="mi">0</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="s2">&quot;use_buffer not specified and not yet inferred from data, assuming `True`.&quot;</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="s2">&quot;Cannot concatenate results with use_buffers=False&quot;</span>
                    <span class="p">)</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">same_device</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">buffers</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="n">cat_results</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                            <span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">buffers</span><span class="o">.</span><span class="n">values</span><span class="p">()],</span> <span class="n">cat_results</span>
                        <span class="p">)</span>
                <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="n">preempt</span>
                        <span class="ow">and</span> <span class="n">cat_results</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
                        <span class="ow">and</span> <span class="s2">&quot;Sizes of tensors must match&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
                    <span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                            <span class="s2">&quot;The value provided to cat_results isn&#39;t compatible with the collectors outputs. &quot;</span>
                            <span class="s2">&quot;Consider using `cat_results=-1`.&quot;</span>
                        <span class="p">)</span>
                    <span class="k">raise</span>

            <span class="c1"># TODO: why do we need to do cat inplace and clone?</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_trajs</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">split_trajectories</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;collector&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span>
            <span class="k">if</span> <span class="n">cat_results</span> <span class="ow">in</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;stack&quot;</span><span class="p">):</span>
                <span class="n">out</span><span class="o">.</span><span class="n">refine_names</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">])</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">+=</span> <span class="n">n_collected</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exclude_private_keys</span><span class="p">:</span>
                <span class="n">excluded_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">out</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)]</span>
                <span class="k">if</span> <span class="n">excluded_keys</span><span class="p">:</span>
                    <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="n">excluded_keys</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">out</span>
            <span class="k">del</span> <span class="n">out</span>

        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span> <span class="o">=</span> <span class="kc">None</span></div>
        <span class="c1"># We shall not call shutdown just yet as user may want to retrieve state_dict</span>
        <span class="c1"># self._shutdown_main()</span>


<div class="viewcode-block" id="MultiaSyncDataCollector"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiaSyncDataCollector.html#torchrl.collectors.MultiaSyncDataCollector">[docs]</a><span class="nd">@accept_remote_rref_udf_invocation</span>
<span class="k">class</span><span class="w"> </span><span class="nc">MultiaSyncDataCollector</span><span class="p">(</span><span class="n">_MultiDataCollector</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Runs a given number of DataCollectors on separate processes asynchronously.</span>

<span class="sd">    .. aafig::</span>


<span class="sd">            +----------------------------------------------------------------------+</span>
<span class="sd">            |           &quot;MultiConcurrentCollector&quot;                |                |</span>
<span class="sd">            |~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~|                |</span>
<span class="sd">            |  &quot;Collector 1&quot;  |  &quot;Collector 2&quot;  |  &quot;Collector 3&quot;  |     &quot;Main&quot;     |</span>
<span class="sd">            |~~~~~~~~~~~~~~~~~|~~~~~~~~~~~~~~~~~|~~~~~~~~~~~~~~~~~|~~~~~~~~~~~~~~~~|</span>
<span class="sd">            | &quot;env1&quot; | &quot;env2&quot; | &quot;env3&quot; | &quot;env4&quot; | &quot;env5&quot; | &quot;env6&quot; |                |</span>
<span class="sd">            |~~~~~~~~|~~~~~~~~|~~~~~~~~|~~~~~~~~|~~~~~~~~|~~~~~~~~|~~~~~~~~~~~~~~~~|</span>
<span class="sd">            |&quot;reset&quot; |&quot;reset&quot; |&quot;reset&quot; |&quot;reset&quot; |&quot;reset&quot; |&quot;reset&quot; |                |</span>
<span class="sd">            |        |        |        |        |        |        |                |</span>
<span class="sd">            |       &quot;actor&quot;   |        |        |       &quot;actor&quot;   |                |</span>
<span class="sd">            |                 |        |        |                 |                |</span>
<span class="sd">            | &quot;step&quot; | &quot;step&quot; |       &quot;actor&quot;   |                 |                |</span>
<span class="sd">            |        |        |                 |                 |                |</span>
<span class="sd">            |        |        |                 | &quot;step&quot; | &quot;step&quot; |                |</span>
<span class="sd">            |        |        |                 |        |        |                |</span>
<span class="sd">            |       &quot;actor    | &quot;step&quot; | &quot;step&quot; |       &quot;actor&quot;   |                |</span>
<span class="sd">            |                 |        |        |                 |                |</span>
<span class="sd">            | &quot;yield batch 1&quot; |       &quot;actor&quot;   |                 |&quot;collect, train&quot;|</span>
<span class="sd">            |                 |                 |                 |                |</span>
<span class="sd">            | &quot;step&quot; | &quot;step&quot; |                 | &quot;yield batch 2&quot; |&quot;collect, train&quot;|</span>
<span class="sd">            |        |        |                 |                 |                |</span>
<span class="sd">            |        |        | &quot;yield batch 3&quot; |                 |&quot;collect, train&quot;|</span>
<span class="sd">            |        |        |                 |                 |                |</span>
<span class="sd">            +----------------------------------------------------------------------+</span>

<span class="sd">    Environment types can be identical or different.</span>

<span class="sd">    The collection keeps on occuring on all processes even between the time</span>
<span class="sd">    the batch of rollouts is collected and the next call to the iterator.</span>
<span class="sd">    This class can be safely used with offline RL sota-implementations.</span>

<span class="sd">    .. note:: Python requires multiprocessed code to be instantiated within a main guard:</span>

<span class="sd">            &gt;&gt;&gt; from torchrl.collectors import MultiaSyncDataCollector</span>
<span class="sd">            &gt;&gt;&gt; if __name__ == &quot;__main__&quot;:</span>
<span class="sd">            ...     # Create your collector here</span>

<span class="sd">        See https://docs.python.org/3/library/multiprocessing.html for more info.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.collectors import MultiaSyncDataCollector</span>
<span class="sd">        &gt;&gt;&gt; if __name__ == &quot;__main__&quot;:</span>
<span class="sd">        ...     env_maker = lambda: GymEnv(&quot;Pendulum-v1&quot;, device=&quot;cpu&quot;)</span>
<span class="sd">        ...     policy = TensorDictModule(nn.Linear(3, 1), in_keys=[&quot;observation&quot;], out_keys=[&quot;action&quot;])</span>
<span class="sd">        ...     collector = MultiaSyncDataCollector(</span>
<span class="sd">        ...         create_env_fn=[env_maker, env_maker],</span>
<span class="sd">        ...         policy=policy,</span>
<span class="sd">        ...         total_frames=2000,</span>
<span class="sd">        ...         max_frames_per_traj=50,</span>
<span class="sd">        ...         frames_per_batch=200,</span>
<span class="sd">        ...         init_random_frames=-1,</span>
<span class="sd">        ...         reset_at_each_iter=False,</span>
<span class="sd">        ...         device=&quot;cpu&quot;,</span>
<span class="sd">        ...         storing_device=&quot;cpu&quot;,</span>
<span class="sd">        ...         cat_results=&quot;stack&quot;,</span>
<span class="sd">        ...     )</span>
<span class="sd">        ...     for i, data in enumerate(collector):</span>
<span class="sd">        ...         if i == 2:</span>
<span class="sd">        ...             print(data)</span>
<span class="sd">        ...             break</span>
<span class="sd">        ... collector.shutdown()</span>
<span class="sd">        ... del collector</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                collector: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        traj_ids: Tensor(shape=torch.Size([200]), device=cpu, dtype=torch.int64, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([200]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        step_count: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                        truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([200]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                step_count: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([200]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="vm">__doc__</span> <span class="o">+=</span> <span class="n">_MultiDataCollector</span><span class="o">.</span><span class="vm">__doc__</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_tensordicts</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">running</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">postproc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">_device</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">_device</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span><span class="p">[</span><span class="n">_device</span><span class="p">]</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">postproc</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">_device</span><span class="p">)</span>

    <span class="c1"># for RPC</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">next</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiaSyncDataCollector.shutdown"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiaSyncDataCollector.html#torchrl.collectors.MultiaSyncDataCollector.shutdown">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">shutdown</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;out_tensordicts&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensordicts</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiaSyncDataCollector.set_seed"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiaSyncDataCollector.html#torchrl.collectors.MultiaSyncDataCollector.set_seed">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">)</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiaSyncDataCollector.state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiaSyncDataCollector.html#torchrl.collectors.MultiaSyncDataCollector.state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiaSyncDataCollector.load_state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiaSyncDataCollector.html#torchrl.collectors.MultiaSyncDataCollector.load_state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiaSyncDataCollector.update_policy_weights_"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiaSyncDataCollector.html#torchrl.collectors.MultiaSyncDataCollector.update_policy_weights_">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">update_policy_weights_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">policy_weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">update_policy_weights_</span><span class="p">(</span><span class="n">policy_weights</span><span class="p">)</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">frames_per_batch_worker</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">requested_frames_per_batch</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_from_queue</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">]:</span>
        <span class="n">new_data</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">)</span>
        <span class="n">use_buffers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">new_data</span>
        <span class="k">elif</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">use_buffers</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">data</span><span class="p">,</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">new_data</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">out_tensordicts</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span>
                <span class="k">if</span> <span class="n">use_buffers</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">use_buffers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">use_buffers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">use_buffers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">new_data</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">new_data</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensordicts</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">and</span> <span class="p">(</span><span class="n">j</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">use_buffers</span><span class="p">):</span>
            <span class="c1"># we clone the data to make sure that we&#39;ll be working with a fixed copy</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">idx</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">out</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_queue_len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">iterator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">]:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_at_each_batch</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_policy_weights_</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;continue_random&quot;</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;continue&quot;</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">running</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">workers_frames</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">)]</span>
        <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">idx</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_from_queue</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">_TIMEOUT</span><span class="p">)</span>
                    <span class="k">break</span>
                <span class="k">except</span> <span class="p">(</span><span class="ne">TimeoutError</span><span class="p">,</span> <span class="n">Empty</span><span class="p">):</span>
                    <span class="n">counter</span> <span class="o">+=</span> <span class="n">_TIMEOUT</span>
                    <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">counter</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">_TIMEOUT</span> <span class="o">*</span> <span class="n">_MAX_IDLE_COUNT</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Failed to gather all collector output within </span><span class="si">{</span><span class="n">_TIMEOUT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">_MAX_IDLE_COUNT</span><span class="si">}</span><span class="s2"> seconds. &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Increase the MAX_IDLE_COUNT environment variable to bypass this error.&quot;</span>
                    <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">worker_frames</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_trajs</span><span class="p">:</span>
                    <span class="n">out</span> <span class="o">=</span> <span class="n">split_trajectories</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;collector&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">worker_frames</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_batch_worker</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">+=</span> <span class="n">worker_frames</span>
            <span class="n">workers_frames</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">workers_frames</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">worker_frames</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span><span class="p">[</span><span class="n">out</span><span class="o">.</span><span class="n">device</span><span class="p">](</span><span class="n">out</span><span class="p">)</span>

            <span class="c1"># the function blocks here until the next item is asked, hence we send the message to the</span>
            <span class="c1"># worker to keep on working in the meantime before the yield statement</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span>
            <span class="p">):</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;continue_random&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;continue&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="n">msg</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exclude_private_keys</span><span class="p">:</span>
                <span class="n">excluded_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">out</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)]</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="n">excluded_keys</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">out</span>

        <span class="c1"># We don&#39;t want to shutdown yet, the user may want to call state_dict before</span>
        <span class="c1"># self._shutdown_main()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">running</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_shutdown_main</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;out_tensordicts&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensordicts</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_shutdown_main</span><span class="p">()</span>

<div class="viewcode-block" id="MultiaSyncDataCollector.reset"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiaSyncDataCollector.html#torchrl.collectors.MultiaSyncDataCollector.reset">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reset_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">reset_idx</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span><span class="o">.</span><span class="n">full</span><span class="p">():</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">_TIMEOUT</span><span class="p">)</span>  <span class="c1"># wait until queue is empty</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span><span class="o">.</span><span class="n">full</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;self.queue_out is full&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">running</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span>
                <span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="s2">&quot;continue_random&quot;</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="s2">&quot;continue&quot;</span><span class="p">))</span></div></div>


<div class="viewcode-block" id="aSyncDataCollector"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.aSyncDataCollector.html#torchrl.collectors.aSyncDataCollector">[docs]</a><span class="nd">@accept_remote_rref_udf_invocation</span>
<span class="k">class</span><span class="w"> </span><span class="nc">aSyncDataCollector</span><span class="p">(</span><span class="n">MultiaSyncDataCollector</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Runs a single DataCollector on a separate process.</span>

<span class="sd">    This is mostly useful for offline RL paradigms where the policy being</span>
<span class="sd">    trained can differ from the policy used to collect data. In online</span>
<span class="sd">    settings, a regular DataCollector should be preferred. This class is</span>
<span class="sd">    merely a wrapper around a MultiaSyncDataCollector where a single process</span>
<span class="sd">    is being created.</span>

<span class="sd">    Args:</span>
<span class="sd">        create_env_fn (Callabled): Callable returning an instance of EnvBase</span>
<span class="sd">        policy (Callable): Policy to be executed in the environment.</span>
<span class="sd">            Must accept :class:`tensordict.tensordict.TensorDictBase` object as input.</span>
<span class="sd">            If ``None`` is provided, the policy used will be a</span>
<span class="sd">            :class:`~torchrl.collectors.RandomPolicy` instance with the environment</span>
<span class="sd">            ``action_spec``.</span>
<span class="sd">            Accepted policies are usually subclasses of :class:`~tensordict.nn.TensorDictModuleBase`.</span>
<span class="sd">            This is the recommended usage of the collector.</span>
<span class="sd">            Other callables are accepted too:</span>
<span class="sd">            If the policy is not a ``TensorDictModuleBase`` (e.g., a regular :class:`~torch.nn.Module`</span>
<span class="sd">            instances) it will be wrapped in a `nn.Module` first.</span>
<span class="sd">            Then, the collector will try to assess if these</span>
<span class="sd">            modules require wrapping in a :class:`~tensordict.nn.TensorDictModule` or not.</span>

<span class="sd">            - If the policy forward signature matches any of ``forward(self, tensordict)``,</span>
<span class="sd">              ``forward(self, td)`` or ``forward(self, &lt;anything&gt;: TensorDictBase)`` (or</span>
<span class="sd">              any typing with a single argument typed as a subclass of ``TensorDictBase``)</span>
<span class="sd">              then the policy won&#39;t be wrapped in a :class:`~tensordict.nn.TensorDictModule`.</span>

<span class="sd">            - In all other cases an attempt to wrap it will be undergone as such: ``TensorDictModule(policy, in_keys=env_obs_key, out_keys=env.action_keys)``.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        frames_per_batch (int): A keyword-only argument representing the</span>
<span class="sd">            total number of elements in a batch.</span>
<span class="sd">        total_frames (int, optional): A keyword-only argument representing the</span>
<span class="sd">            total number of frames returned by the collector</span>
<span class="sd">            during its lifespan. If the ``total_frames`` is not divisible by</span>
<span class="sd">            ``frames_per_batch``, an exception is raised.</span>
<span class="sd">             Endless collectors can be created by passing ``total_frames=-1``.</span>
<span class="sd">             Defaults to ``-1`` (never ending collector).</span>
<span class="sd">        device (int, str or torch.device, optional): The generic device of the</span>
<span class="sd">            collector. The ``device`` args fills any non-specified device: if</span>
<span class="sd">            ``device`` is not ``None`` and any of ``storing_device``, ``policy_device`` or</span>
<span class="sd">            ``env_device`` is not specified, its value will be set to ``device``.</span>
<span class="sd">            Defaults to ``None`` (No default device).</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        storing_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the output :class:`~tensordict.TensorDict` will be stored.</span>
<span class="sd">            If ``device`` is passed and ``storing_device`` is ``None``, it will</span>
<span class="sd">            default to the value indicated by ``device``.</span>
<span class="sd">            For long trajectories, it may be necessary to store the data on a different</span>
<span class="sd">            device than the one where the policy and env are executed.</span>
<span class="sd">            Defaults to ``None`` (the output tensordict isn&#39;t on a specific device,</span>
<span class="sd">            leaf tensors sit on the device where they were created).</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        env_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the environment should be cast (or executed if that functionality is</span>
<span class="sd">            supported). If not specified and the env has a non-``None`` device,</span>
<span class="sd">            ``env_device`` will default to that value. If ``device`` is passed</span>
<span class="sd">            and ``env_device=None``, it will default to ``device``. If the value</span>
<span class="sd">            as such specified of ``env_device`` differs from ``policy_device``</span>
<span class="sd">            and one of them is not ``None``, the data will be cast to ``env_device``</span>
<span class="sd">            before being passed to the env (i.e., passing different devices to</span>
<span class="sd">            policy and env is supported). Defaults to ``None``.</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        policy_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the policy should be cast.</span>
<span class="sd">            If ``device`` is passed and ``policy_device=None``, it will default</span>
<span class="sd">            to ``device``. If the value as such specified of ``policy_device``</span>
<span class="sd">            differs from ``env_device`` and one of them is not ``None``,</span>
<span class="sd">            the data will be cast to ``policy_device`` before being passed to</span>
<span class="sd">            the policy (i.e., passing different devices to policy and env is</span>
<span class="sd">            supported). Defaults to ``None``.</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        create_env_kwargs (dict, optional): A dictionary with the</span>
<span class="sd">            keyword arguments used to create an environment. If a list is</span>
<span class="sd">            provided, each of its elements will be assigned to a sub-collector.</span>
<span class="sd">        max_frames_per_traj (int, optional): Maximum steps per trajectory.</span>
<span class="sd">            Note that a trajectory can span across multiple batches (unless</span>
<span class="sd">            ``reset_at_each_iter`` is set to ``True``, see below).</span>
<span class="sd">            Once a trajectory reaches ``n_steps``, the environment is reset.</span>
<span class="sd">            If the environment wraps multiple environments together, the number</span>
<span class="sd">            of steps is tracked for each environment independently. Negative</span>
<span class="sd">            values are allowed, in which case this argument is ignored.</span>
<span class="sd">            Defaults to ``None`` (i.e. no maximum number of steps).</span>
<span class="sd">        init_random_frames (int, optional): Number of frames for which the</span>
<span class="sd">            policy is ignored before it is called. This feature is mainly</span>
<span class="sd">            intended to be used in offline/model-based settings, where a</span>
<span class="sd">            batch of random trajectories can be used to initialize training.</span>
<span class="sd">            If provided, it will be rounded up to the closest multiple of frames_per_batch.</span>
<span class="sd">            Defaults to ``None`` (i.e. no random frames).</span>
<span class="sd">        reset_at_each_iter (bool, optional): Whether environments should be reset</span>
<span class="sd">            at the beginning of a batch collection.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        postproc (Callable, optional): A post-processing transform, such as</span>
<span class="sd">            a :class:`~torchrl.envs.Transform` or a :class:`~torchrl.data.postprocs.MultiStep`</span>
<span class="sd">            instance.</span>
<span class="sd">            Defaults to ``None``.</span>
<span class="sd">        split_trajs (bool, optional): Boolean indicating whether the resulting</span>
<span class="sd">            TensorDict should be split according to the trajectories.</span>
<span class="sd">            See :func:`~torchrl.collectors.utils.split_trajectories` for more</span>
<span class="sd">            information.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        exploration_type (ExplorationType, optional): interaction mode to be used when</span>
<span class="sd">            collecting data. Must be one of ``torchrl.envs.utils.ExplorationType.DETERMINISTIC``,</span>
<span class="sd">            ``torchrl.envs.utils.ExplorationType.RANDOM``, ``torchrl.envs.utils.ExplorationType.MODE``</span>
<span class="sd">            or ``torchrl.envs.utils.ExplorationType.MEAN``.</span>
<span class="sd">        reset_when_done (bool, optional): if ``True`` (default), an environment</span>
<span class="sd">            that return a ``True`` value in its ``&quot;done&quot;`` or ``&quot;truncated&quot;``</span>
<span class="sd">            entry will be reset at the corresponding indices.</span>
<span class="sd">        update_at_each_batch (boolm optional): if ``True``, :meth:`update_policy_weight_()`</span>
<span class="sd">            will be called before (sync) or after (async) each data collection.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        preemptive_threshold (:obj:`float`, optional): a value between 0.0 and 1.0 that specifies the ratio of workers</span>
<span class="sd">            that will be allowed to finished collecting their rollout before the rest are forced to end early.</span>
<span class="sd">        num_threads (int, optional): number of threads for this process.</span>
<span class="sd">            Defaults to the number of workers.</span>
<span class="sd">        num_sub_threads (int, optional): number of threads of the subprocesses.</span>
<span class="sd">            Should be equal to one plus the number of processes launched within</span>
<span class="sd">            each subprocess (or one if a single process is launched).</span>
<span class="sd">            Defaults to 1 for safety: if none is indicated, launching multiple</span>
<span class="sd">            workers may charge the cpu load too much and harm performance.</span>
<span class="sd">        set_truncated (bool, optional): if ``True``, the truncated signals (and corresponding</span>
<span class="sd">            ``&quot;done&quot;`` but not ``&quot;terminated&quot;``) will be set to ``True`` when the last frame of</span>
<span class="sd">            a rollout is reached. If no ``&quot;truncated&quot;`` key is found, an exception is raised.</span>
<span class="sd">            Truncated keys can be set through ``env.add_truncated_keys``.</span>
<span class="sd">            Defaults to ``False``.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">create_env_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">EnvBase</span><span class="p">],</span>
        <span class="n">policy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Union</span><span class="p">[</span>
                <span class="n">TensorDictModule</span><span class="p">,</span>
                <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">frames_per_batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">total_frames</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">storing_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">env_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">policy_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">create_env_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_frames_per_traj</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">init_random_frames</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">reset_at_each_iter</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">postproc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">split_trajs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">exploration_type</span><span class="p">:</span> <span class="n">ExplorationType</span> <span class="o">=</span> <span class="n">DEFAULT_EXPLORATION_TYPE</span><span class="p">,</span>
        <span class="n">reset_when_done</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">update_at_each_batch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">preemptive_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_threads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_sub_threads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">set_truncated</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">create_env_fn</span><span class="o">=</span><span class="p">[</span><span class="n">create_env_fn</span><span class="p">],</span>
            <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">,</span>
            <span class="n">total_frames</span><span class="o">=</span><span class="n">total_frames</span><span class="p">,</span>
            <span class="n">create_env_kwargs</span><span class="o">=</span><span class="p">[</span><span class="n">create_env_kwargs</span><span class="p">],</span>
            <span class="n">max_frames_per_traj</span><span class="o">=</span><span class="n">max_frames_per_traj</span><span class="p">,</span>
            <span class="n">frames_per_batch</span><span class="o">=</span><span class="n">frames_per_batch</span><span class="p">,</span>
            <span class="n">reset_at_each_iter</span><span class="o">=</span><span class="n">reset_at_each_iter</span><span class="p">,</span>
            <span class="n">init_random_frames</span><span class="o">=</span><span class="n">init_random_frames</span><span class="p">,</span>
            <span class="n">postproc</span><span class="o">=</span><span class="n">postproc</span><span class="p">,</span>
            <span class="n">split_trajs</span><span class="o">=</span><span class="n">split_trajs</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">policy_device</span><span class="o">=</span><span class="n">policy_device</span><span class="p">,</span>
            <span class="n">env_device</span><span class="o">=</span><span class="n">env_device</span><span class="p">,</span>
            <span class="n">storing_device</span><span class="o">=</span><span class="n">storing_device</span><span class="p">,</span>
            <span class="n">exploration_type</span><span class="o">=</span><span class="n">exploration_type</span><span class="p">,</span>
            <span class="n">reset_when_done</span><span class="o">=</span><span class="n">reset_when_done</span><span class="p">,</span>
            <span class="n">update_at_each_batch</span><span class="o">=</span><span class="n">update_at_each_batch</span><span class="p">,</span>
            <span class="n">preemptive_threshold</span><span class="o">=</span><span class="n">preemptive_threshold</span><span class="p">,</span>
            <span class="n">num_threads</span><span class="o">=</span><span class="n">num_threads</span><span class="p">,</span>
            <span class="n">num_sub_threads</span><span class="o">=</span><span class="n">num_sub_threads</span><span class="p">,</span>
            <span class="n">set_truncated</span><span class="o">=</span><span class="n">set_truncated</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># for RPC</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">next</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="aSyncDataCollector.shutdown"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.aSyncDataCollector.html#torchrl.collectors.aSyncDataCollector.shutdown">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">shutdown</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="aSyncDataCollector.set_seed"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.aSyncDataCollector.html#torchrl.collectors.aSyncDataCollector.set_seed">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">)</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="aSyncDataCollector.state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.aSyncDataCollector.html#torchrl.collectors.aSyncDataCollector.state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="aSyncDataCollector.load_state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.aSyncDataCollector.html#torchrl.collectors.aSyncDataCollector.load_state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span></div></div>


<span class="k">def</span><span class="w"> </span><span class="nf">_main_async_collector</span><span class="p">(</span>
    <span class="n">pipe_parent</span><span class="p">:</span> <span class="n">connection</span><span class="o">.</span><span class="n">Connection</span><span class="p">,</span>
    <span class="n">pipe_child</span><span class="p">:</span> <span class="n">connection</span><span class="o">.</span><span class="n">Connection</span><span class="p">,</span>
    <span class="n">queue_out</span><span class="p">:</span> <span class="n">queues</span><span class="o">.</span><span class="n">Queue</span><span class="p">,</span>
    <span class="n">create_env_fn</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">EnvBase</span><span class="p">,</span> <span class="s2">&quot;EnvCreator&quot;</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">EnvBase</span><span class="p">]],</span>  <span class="c1"># noqa: F821</span>
    <span class="n">create_env_kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="n">policy</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">],</span>
    <span class="n">max_frames_per_traj</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">frames_per_batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">reset_at_each_iter</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">storing_device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span>
    <span class="n">env_device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span>
    <span class="n">policy_device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span>
    <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">exploration_type</span><span class="p">:</span> <span class="n">ExplorationType</span> <span class="o">=</span> <span class="n">DEFAULT_EXPLORATION_TYPE</span><span class="p">,</span>
    <span class="n">reset_when_done</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">VERBOSE</span><span class="p">,</span>
    <span class="n">interruptor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">set_truncated</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">use_buffers</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">replay_buffer</span><span class="p">:</span> <span class="n">ReplayBuffer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">replay_buffer_chunk</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">traj_pool</span><span class="p">:</span> <span class="n">_TrajectoryPool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">trust_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">compile_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">cudagraph_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">no_cuda_sync</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">pipe_parent</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="c1"># init variables that will be cleared when closing</span>
    <span class="n">collected_tensordict</span> <span class="o">=</span> <span class="n">data</span> <span class="o">=</span> <span class="n">next_data</span> <span class="o">=</span> <span class="n">data_in</span> <span class="o">=</span> <span class="n">inner_collector</span> <span class="o">=</span> <span class="n">dc_iter</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">inner_collector</span> <span class="o">=</span> <span class="n">SyncDataCollector</span><span class="p">(</span>
        <span class="n">create_env_fn</span><span class="p">,</span>
        <span class="n">create_env_kwargs</span><span class="o">=</span><span class="n">create_env_kwargs</span><span class="p">,</span>
        <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">,</span>
        <span class="n">total_frames</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">max_frames_per_traj</span><span class="o">=</span><span class="n">max_frames_per_traj</span><span class="p">,</span>
        <span class="n">frames_per_batch</span><span class="o">=</span><span class="n">frames_per_batch</span><span class="p">,</span>
        <span class="n">reset_at_each_iter</span><span class="o">=</span><span class="n">reset_at_each_iter</span><span class="p">,</span>
        <span class="n">postproc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">split_trajs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">storing_device</span><span class="o">=</span><span class="n">storing_device</span><span class="p">,</span>
        <span class="n">policy_device</span><span class="o">=</span><span class="n">policy_device</span><span class="p">,</span>
        <span class="n">env_device</span><span class="o">=</span><span class="n">env_device</span><span class="p">,</span>
        <span class="n">exploration_type</span><span class="o">=</span><span class="n">exploration_type</span><span class="p">,</span>
        <span class="n">reset_when_done</span><span class="o">=</span><span class="n">reset_when_done</span><span class="p">,</span>
        <span class="n">return_same_td</span><span class="o">=</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">interruptor</span><span class="o">=</span><span class="n">interruptor</span><span class="p">,</span>
        <span class="n">set_truncated</span><span class="o">=</span><span class="n">set_truncated</span><span class="p">,</span>
        <span class="n">use_buffers</span><span class="o">=</span><span class="n">use_buffers</span><span class="p">,</span>
        <span class="n">replay_buffer</span><span class="o">=</span><span class="n">replay_buffer</span> <span class="k">if</span> <span class="n">replay_buffer_chunk</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">traj_pool</span><span class="o">=</span><span class="n">traj_pool</span><span class="p">,</span>
        <span class="n">trust_policy</span><span class="o">=</span><span class="n">trust_policy</span><span class="p">,</span>
        <span class="n">compile_policy</span><span class="o">=</span><span class="n">compile_policy</span><span class="p">,</span>
        <span class="n">cudagraph_policy</span><span class="o">=</span><span class="n">cudagraph_policy</span><span class="p">,</span>
        <span class="n">no_cuda_sync</span><span class="o">=</span><span class="n">no_cuda_sync</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">use_buffers</span> <span class="o">=</span> <span class="n">inner_collector</span><span class="o">.</span><span class="n">_use_buffers</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Sync data collector created&quot;</span><span class="p">)</span>
    <span class="n">dc_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">inner_collector</span><span class="p">)</span>
    <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="s2">&quot;instantiated&quot;</span><span class="p">)</span>

    <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">_timeout</span> <span class="o">=</span> <span class="n">_TIMEOUT</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">has_timed_out</span> <span class="k">else</span> <span class="mf">1e-3</span>
        <span class="k">if</span> <span class="n">pipe_child</span><span class="o">.</span><span class="n">poll</span><span class="p">(</span><span class="n">_timeout</span><span class="p">):</span>
            <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">data_in</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="n">pipe_child</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> received </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;poll failed, j=</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s2">, worker=</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="c1"># default is &quot;continue&quot; (after first iteration)</span>
            <span class="c1"># this is expected to happen if queue_out reached the timeout, but no new msg was waiting in the pipe</span>
            <span class="c1"># in that case, the main process probably expects the worker to continue collect data</span>
            <span class="k">if</span> <span class="n">has_timed_out</span><span class="p">:</span>
                <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="c1"># has_timed_out is True if the process failed to send data, which will</span>
                <span class="c1"># typically occur if main has taken another batch (i.e. the queue is Full).</span>
                <span class="c1"># In this case, msg is the previous msg sent by main, which will typically be &quot;continue&quot;</span>
                <span class="c1"># If it&#39;s not the case, it is not expected that has_timed_out is True.</span>
                <span class="k">if</span> <span class="n">msg</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;continue&quot;</span><span class="p">,</span> <span class="s2">&quot;continue_random&quot;</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected message after time out: msg=</span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># if has_timed_out is False, then the time out does not come from the fact that the queue is Full.</span>
                <span class="c1"># this means that our process has been waiting for a command from main in vain, while main was not</span>
                <span class="c1"># receiving data.</span>
                <span class="c1"># This will occur if main is busy doing something else (e.g. computing loss etc).</span>

                <span class="n">counter</span> <span class="o">+=</span> <span class="n">_timeout</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> has counter </span><span class="si">{</span><span class="n">counter</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">counter</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="n">_MAX_IDLE_COUNT</span> <span class="o">*</span> <span class="n">_TIMEOUT</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;This process waited for </span><span class="si">{</span><span class="n">counter</span><span class="si">}</span><span class="s2"> seconds &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;without receiving a command from main. Consider increasing the maximum idle count &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;if this is expected via the environment variable MAX_IDLE_COUNT &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;(current value is </span><span class="si">{</span><span class="n">_MAX_IDLE_COUNT</span><span class="si">}</span><span class="s2">).&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">If this occurs at the end of a function or program, it means that your collector has not been &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;collected, consider calling `collector.shutdown()` before ending the program.&quot;</span>
                    <span class="p">)</span>
                <span class="k">continue</span>
        <span class="k">if</span> <span class="n">msg</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;continue&quot;</span><span class="p">,</span> <span class="s2">&quot;continue_random&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;continue_random&quot;</span><span class="p">:</span>
                <span class="n">inner_collector</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">inner_collector</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

            <span class="n">next_data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dc_iter</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">pipe_child</span><span class="o">.</span><span class="n">poll</span><span class="p">(</span><span class="n">_MIN_TIMEOUT</span><span class="p">):</span>
                <span class="c1"># in this case, main send a message to the worker while it was busy collecting trajectories.</span>
                <span class="c1"># In that case, we skip the collected trajectory and get the message from main. This is faster than</span>
                <span class="c1"># sending the trajectory in the queue until timeout when it&#39;s never going to be received.</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">replay_buffer_chunk</span><span class="p">:</span>
                    <span class="n">next_data</span><span class="o">.</span><span class="n">names</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">replay_buffer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">next_data</span><span class="p">)</span>

                <span class="k">try</span><span class="p">:</span>
                    <span class="n">queue_out</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="n">j</span><span class="p">),</span> <span class="n">timeout</span><span class="o">=</span><span class="n">_TIMEOUT</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                        <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> successfully sent data&quot;</span><span class="p">)</span>
                    <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">continue</span>
                <span class="k">except</span> <span class="n">queue</span><span class="o">.</span><span class="n">Full</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                        <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> has timed out&quot;</span><span class="p">)</span>
                    <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">continue</span>

            <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">use_buffers</span><span class="p">:</span>
                <span class="n">collected_tensordict</span> <span class="o">=</span> <span class="n">next_data</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">storing_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="n">collected_tensordict</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">storing_device</span>
                <span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;expected device to be </span><span class="si">{</span><span class="n">storing_device</span><span class="si">}</span><span class="s2"> but got </span><span class="si">{</span><span class="n">collected_tensordict</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="n">use_buffers</span><span class="p">:</span>
                    <span class="c1"># If policy and env are on cpu, we put in shared mem,</span>
                    <span class="c1"># if policy is on cuda and env on cuda, we are fine with this</span>
                    <span class="c1"># If policy is on cuda and env on cpu (or opposite) we put tensors that</span>
                    <span class="c1"># are on cpu in shared mem.</span>
                    <span class="n">MPS_ERROR</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="s2">&quot;tensors on mps device cannot be put in shared memory. Make sure &quot;</span>
                        <span class="s2">&quot;the shared device (aka storing_device) is set to CPU.&quot;</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="n">collected_tensordict</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="c1"># placehoder in case we need different behaviors</span>
                        <span class="k">if</span> <span class="n">collected_tensordict</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">,):</span>
                            <span class="n">collected_tensordict</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
                        <span class="k">elif</span> <span class="n">collected_tensordict</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;mps&quot;</span><span class="p">,):</span>
                            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">MPS_ERROR</span><span class="p">)</span>
                        <span class="k">elif</span> <span class="n">collected_tensordict</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
                            <span class="n">collected_tensordict</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Device </span><span class="si">{</span><span class="n">collected_tensordict</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2"> is not supported in multi-collectors yet.&quot;</span>
                            <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># make sure each cpu tensor is shared - assuming non-cpu devices are shared</span>
                        <span class="k">def</span><span class="w"> </span><span class="nf">cast_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">MPS_ERROR</span><span class="o">=</span><span class="n">MPS_ERROR</span><span class="p">):</span>
                            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">,):</span>
                                <span class="n">x</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
                            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;mps&quot;</span><span class="p">,):</span>
                                <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">MPS_ERROR</span><span class="p">)</span>

                        <span class="n">collected_tensordict</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">cast_tensor</span><span class="p">,</span> <span class="n">filter_empty</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">collected_tensordict</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">next_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">collected_tensordict</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="s2">&quot;SyncDataCollector should return the same tensordict modified in-place.&quot;</span>
                    <span class="p">)</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">idx</span>  <span class="c1"># flag the worker that has sent its data</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">queue_out</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="n">data</span><span class="p">,</span> <span class="n">j</span><span class="p">),</span> <span class="n">timeout</span><span class="o">=</span><span class="n">_TIMEOUT</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> successfully sent data&quot;</span><span class="p">)</span>
                <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">continue</span>
            <span class="k">except</span> <span class="n">queue</span><span class="o">.</span><span class="n">Full</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> has timed out&quot;</span><span class="p">)</span>
                <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">continue</span>

        <span class="k">elif</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;update&quot;</span><span class="p">:</span>
            <span class="n">inner_collector</span><span class="o">.</span><span class="n">update_policy_weights_</span><span class="p">()</span>
            <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">j</span><span class="p">,</span> <span class="s2">&quot;updated&quot;</span><span class="p">))</span>
            <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">continue</span>

        <span class="k">elif</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;seed&quot;</span><span class="p">:</span>
            <span class="n">data_in</span><span class="p">,</span> <span class="n">static_seed</span> <span class="o">=</span> <span class="n">data_in</span>
            <span class="n">new_seed</span> <span class="o">=</span> <span class="n">inner_collector</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">data_in</span><span class="p">,</span> <span class="n">static_seed</span><span class="o">=</span><span class="n">static_seed</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">data_in</span><span class="p">)</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">data_in</span><span class="p">)</span>
            <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">new_seed</span><span class="p">,</span> <span class="s2">&quot;seeded&quot;</span><span class="p">))</span>
            <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">continue</span>

        <span class="k">elif</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;reset&quot;</span><span class="p">:</span>
            <span class="n">inner_collector</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">j</span><span class="p">,</span> <span class="s2">&quot;reset&quot;</span><span class="p">))</span>
            <span class="k">continue</span>

        <span class="k">elif</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;state_dict&quot;</span><span class="p">:</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">inner_collector</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
            <span class="c1"># send state_dict to cpu first</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">recursive_map_to_cpu</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
            <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">state_dict</span><span class="p">,</span> <span class="s2">&quot;state_dict&quot;</span><span class="p">))</span>
            <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">continue</span>

        <span class="k">elif</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;load_state_dict&quot;</span><span class="p">:</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">data_in</span>
            <span class="n">inner_collector</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
            <span class="k">del</span> <span class="n">state_dict</span>
            <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">j</span><span class="p">,</span> <span class="s2">&quot;loaded&quot;</span><span class="p">))</span>
            <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">continue</span>

        <span class="k">elif</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;close&quot;</span><span class="p">:</span>
            <span class="k">del</span> <span class="n">collected_tensordict</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">next_data</span><span class="p">,</span> <span class="n">data_in</span>
            <span class="n">inner_collector</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
            <span class="k">del</span> <span class="n">inner_collector</span><span class="p">,</span> <span class="n">dc_iter</span>
            <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="s2">&quot;closed&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;collector </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> closed&quot;</span><span class="p">)</span>
            <span class="k">break</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unrecognized message </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_make_meta_params</span><span class="p">(</span><span class="n">param</span><span class="p">):</span>
    <span class="n">is_param</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">)</span>

    <span class="n">pd</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;meta&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">is_param</span><span class="p">:</span>
        <span class="n">pd</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">pd</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_TrajectoryPool</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lock</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ctx</span> <span class="o">=</span> <span class="n">ctx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_traj_id</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((),</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">)</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">ctx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lock</span> <span class="o">=</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">nullcontext</span><span class="p">()</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">lock</span> <span class="k">else</span> <span class="n">mp</span><span class="o">.</span><span class="n">RLock</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lock</span> <span class="o">=</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">nullcontext</span><span class="p">()</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">lock</span> <span class="k">else</span> <span class="n">ctx</span><span class="o">.</span><span class="n">RLock</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_traj_and_increment</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">lock</span><span class="p">:</span>
            <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_traj_id</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">v</span> <span class="o">+</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_traj_id</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">out</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
         <script src="../../../_static/jquery.js"></script>
         <script src="../../../_static/underscore.js"></script>
         <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../_static/doctools.js"></script>
         <script src="../../../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrl = $("#tutorial-type").text();
	      var githubLink = "https://github.com/pytorch/rl/blob/main/tutorials/sphinx-tutorials/"  + tutorialUrl + ".py",
		  notebookLink = $(".sphx-glr-download-jupyter").find(".download.reference")[0].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/rl/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }

          var overwrite = function(_) {
              if ($(this).length > 0) {
                  $(this)[0].href = "https://github.com/pytorch/rl"
              }
          }
          // PC
          $(".main-menu a:contains('GitHub')").each(overwrite);
          // Mobile
          $(".main-menu a:contains('Github')").each(overwrite);
      });

      
       $(window).ready(function() {
           var original = window.sideMenus.bind;
           var startup = true;
           window.sideMenus.bind = function() {
               original();
               if (startup) {
                   $("#pytorch-right-menu a.reference.internal").each(function(i) {
                       if (this.classList.contains("not-expanded")) {
                           this.nextElementSibling.style.display = "block";
                           this.classList.remove("not-expanded");
                           this.classList.add("expanded");
                       }
                   });
                   startup = false;
               }
           };
       });
    </script>

    


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch Documentation</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">Newsletter</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">Cloud Credit Program</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">Technical Advisory Council</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">Staff</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">Contact Us</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>
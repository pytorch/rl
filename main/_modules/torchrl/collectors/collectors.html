


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchrl.collectors.collectors &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','UA-117752657-2');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="../../../../versions.html"><span style="font-size:110%">main (0.0.0+unknown) &#x25BC</span></a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-0.html">Get started with Environments, TED and transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-1.html">Get started with TorchRL’s modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-2.html">Getting started with model optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-3.html">Get started with data collection and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-4.html">Get started with logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/getting-started-5.html">Get started with your own first training loop</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/coding_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/torchrl_demo.html">Introduction to TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/multiagent_ppo.html">Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/torchrl_envs.html">TorchRL envs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/pretrained_models.html">Using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/dqn_with_rnn.html">Recurrent DQN: Training recurrent policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/rb_tutorial.html">Using Replay Buffers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/export.html">Exporting TorchRL modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/llm_browser.html">TorchRL LLM: Building Tool-Enabled Environments</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/multiagent_competitive_ddpg.html">Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/coding_ddpg.html">TorchRL objectives: Coding a DDPG loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/coding_dqn.html">TorchRL trainer: A DQN example</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
      <li>torchrl.collectors.collectors</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
    
    
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=UA-117752657-2"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torchrl.collectors.collectors</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">_pickle</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">abc</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">collections</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">contextlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">functools</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">queue</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">threading</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">typing</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">defaultdict</span><span class="p">,</span> <span class="n">OrderedDict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Iterator</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">,</span> <span class="n">Sequence</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">multiprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">connection</span><span class="p">,</span> <span class="n">queues</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">multiprocessing.managers</span><span class="w"> </span><span class="kn">import</span> <span class="n">SyncManager</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">queue</span><span class="w"> </span><span class="kn">import</span> <span class="n">Empty</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">textwrap</span><span class="w"> </span><span class="kn">import</span> <span class="n">indent</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">TypeVar</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict</span><span class="w"> </span><span class="kn">import</span> <span class="n">LazyStackedTensorDict</span><span class="p">,</span> <span class="n">TensorDict</span><span class="p">,</span> <span class="n">TensorDictBase</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">NO_DEFAULT</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">CudaGraphModule</span><span class="p">,</span> <span class="n">TensorDictModule</span><span class="p">,</span> <span class="n">TensorDictModuleBase</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensordict.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_zip_strict</span><span class="p">,</span> <span class="n">Buffer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">multiprocessing</span> <span class="k">as</span> <span class="n">mp</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Parameter</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">IterableDataset</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl._utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_check_for_faulty_process</span><span class="p">,</span>
    <span class="n">_ends_with</span><span class="p">,</span>
    <span class="n">_make_ordinal_device</span><span class="p">,</span>
    <span class="n">_ProcessNoWarn</span><span class="p">,</span>
    <span class="n">_replace_last</span><span class="p">,</span>
    <span class="n">accept_remote_rref_udf_invocation</span><span class="p">,</span>
    <span class="n">compile_with_warmup</span><span class="p">,</span>
    <span class="n">logger</span> <span class="k">as</span> <span class="n">torchrl_logger</span><span class="p">,</span>
    <span class="n">prod</span><span class="p">,</span>
    <span class="n">RL_WARNINGS</span><span class="p">,</span>
    <span class="n">VERBOSE</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.collectors.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">split_trajectories</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.collectors.weight_update</span><span class="w"> </span><span class="kn">import</span> <span class="n">WeightUpdaterBase</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">ReplayBuffer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.data.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">CloudpickleWrapper</span><span class="p">,</span> <span class="n">DEVICE_TYPING</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.common</span><span class="w"> </span><span class="kn">import</span> <span class="n">_do_nothing</span><span class="p">,</span> <span class="n">EnvBase</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.env_creator</span><span class="w"> </span><span class="kn">import</span> <span class="n">EnvCreator</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.llm.transforms.policy_version</span><span class="w"> </span><span class="kn">import</span> <span class="n">PolicyVersion</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="n">StepCounter</span><span class="p">,</span> <span class="n">TransformedEnv</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_aggregate_end_of_traj</span><span class="p">,</span>
    <span class="n">_make_compatible_policy</span><span class="p">,</span>
    <span class="n">ExplorationType</span><span class="p">,</span>
    <span class="n">RandomPolicy</span><span class="p">,</span>
    <span class="n">set_exploration_type</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.weight_update.weight_sync_schemes</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_resolve_model</span><span class="p">,</span>
    <span class="n">MultiProcessWeightSyncScheme</span><span class="p">,</span>
    <span class="n">WeightReceiver</span><span class="p">,</span>
    <span class="n">WeightSender</span><span class="p">,</span>
    <span class="n">WeightSyncScheme</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">torch.compiler</span><span class="w"> </span><span class="kn">import</span> <span class="n">cudagraph_mark_step_begin</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">cudagraph_mark_step_begin</span><span class="p">():</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Placeholder for missing cudagraph_mark_step_begin method.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;cudagraph_mark_step_begin not implemented.&quot;</span><span class="p">)</span>


<span class="n">_TIMEOUT</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">INSTANTIATE_TIMEOUT</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">_MIN_TIMEOUT</span> <span class="o">=</span> <span class="mf">1e-3</span>  <span class="c1"># should be several orders of magnitude inferior wrt time spent collecting a trajectory</span>
<span class="c1"># MAX_IDLE_COUNT is the maximum number of times a Dataloader worker can timeout with his queue.</span>
<span class="n">_MAX_IDLE_COUNT</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;MAX_IDLE_COUNT&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">iinfo</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">))</span>

<span class="n">DEFAULT_EXPLORATION_TYPE</span><span class="p">:</span> <span class="n">ExplorationType</span> <span class="o">=</span> <span class="n">ExplorationType</span><span class="o">.</span><span class="n">RANDOM</span>

<span class="n">_is_osx</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">platform</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;darwin&quot;</span><span class="p">)</span>

<span class="n">T</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_Interruptor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A class for managing the collection state of a process.</span>

<span class="sd">    This class provides methods to start and stop collection, and to check</span>
<span class="sd">    whether collection has been stopped. The collection state is protected</span>
<span class="sd">    by a lock to ensure thread-safety.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># interrupter vs interruptor: google trends seems to indicate that &quot;or&quot; is more</span>
    <span class="c1"># widely used than &quot;er&quot; even if my IDE complains about that...</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_collect</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Lock</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">start_collection</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_collect</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">stop_collection</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_collect</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">collection_stopped</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_collect</span> <span class="ow">is</span> <span class="kc">False</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_InterruptorManager</span><span class="p">(</span><span class="n">SyncManager</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A custom SyncManager for managing the collection state of a process.</span>

<span class="sd">    This class extends the SyncManager class and allows to share an Interruptor object</span>
<span class="sd">    between processes.</span>
<span class="sd">    &quot;&quot;&quot;</span>


<span class="n">_InterruptorManager</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;_Interruptor&quot;</span><span class="p">,</span> <span class="n">_Interruptor</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">recursive_map_to_cpu</span><span class="p">(</span><span class="n">dictionary</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Maps the tensors to CPU through a nested dictionary.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">OrderedDict</span><span class="p">(</span>
        <span class="o">**</span><span class="p">{</span>
            <span class="n">k</span><span class="p">:</span> <span class="n">recursive_map_to_cpu</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">OrderedDict</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">item</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">item</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>
    <span class="p">)</span>


<div class="viewcode-block" id="DataCollectorBase"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.DataCollectorBase.html#torchrl.collectors.DataCollectorBase">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">DataCollectorBase</span><span class="p">(</span><span class="n">IterableDataset</span><span class="p">,</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">abc</span><span class="o">.</span><span class="n">ABCMeta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for data collectors.&quot;&quot;&quot;</span>

    <span class="n">_task</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">_iterator</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">total_frames</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">requested_frames_per_batch</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">frames_per_batch</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">trust_policy</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">compiled_policy</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">cudagraphed_policy</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">_weight_updater</span><span class="p">:</span> <span class="n">WeightUpdaterBase</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">_weight_sync_schemes</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">WeightSyncScheme</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">_weight_senders</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">WeightSender</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">_weight_receivers</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">WeightReceiver</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">weight_updater</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">WeightUpdaterBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_updater</span>

    <span class="nd">@weight_updater</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">weight_updater</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">WeightUpdaterBase</span> <span class="o">|</span> <span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">WeightUpdaterBase</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">callable</span><span class="p">(</span>
                <span class="n">value</span>
            <span class="p">):</span>  <span class="c1"># Fall back to default constructor</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="p">()</span>
            <span class="n">value</span><span class="o">.</span><span class="n">register_collector</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">collector</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Failed to register collector.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weight_updater</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_policy_and_device</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">policy</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">policy_device</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="n">NO_DEFAULT</span><span class="p">,</span>
        <span class="n">env_maker</span><span class="p">:</span> <span class="n">Any</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">env_maker_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">TensorDictModule</span><span class="p">,</span> <span class="kc">None</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Util method to get a policy and its device given the collector __init__ inputs.</span>

<span class="sd">        We want to copy the policy and then move the data there, not call policy.to(device).</span>

<span class="sd">        Args:</span>
<span class="sd">            policy (TensorDictModule, optional): a policy to be used</span>
<span class="sd">            policy_device (torch.device, optional): the device where the policy should be placed.</span>
<span class="sd">                Defaults to self.policy_device</span>
<span class="sd">            env_maker (a callable or a batched env, optional): the env_maker function for this device/policy pair.</span>
<span class="sd">            env_maker_kwargs (a dict, optional): the env_maker function kwargs.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">policy_device</span> <span class="ow">is</span> <span class="n">NO_DEFAULT</span><span class="p">:</span>
            <span class="n">policy_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">policy_device</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">policy</span><span class="p">,</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="n">param_and_buf</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="o">.</span><span class="n">from_module</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">as_module</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Because we want to reach the warning</span>
            <span class="n">param_and_buf</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">()</span>

        <span class="n">i</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">param_and_buf</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">policy_device</span><span class="p">:</span>
                <span class="c1"># Then we need casting</span>
                <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trust_policy</span><span class="p">:</span>
                <span class="c1"># We trust that the policy policy device is adequate</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;A policy device was provided but no parameter/buffer could be found in &quot;</span>
                    <span class="s2">&quot;the policy. Casting to policy_device is therefore impossible. &quot;</span>
                    <span class="s2">&quot;The collector will trust that the devices match. To suppress this &quot;</span>
                    <span class="s2">&quot;warning, set `trust_policy=True` when building the collector.&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">policy</span><span class="p">,</span> <span class="kc">None</span>

        <span class="c1"># Create a stateless policy, then populate this copy with params on device</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">get_original_weights</span><span class="p">(</span><span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">):</span>
            <span class="n">td</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="o">.</span><span class="n">from_module</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">td</span><span class="o">.</span><span class="n">data</span>

        <span class="c1"># We need to use &quot;.data&quot; otherwise buffers may disappear from the `get_original_weights` function</span>
        <span class="k">with</span> <span class="n">param_and_buf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;meta&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to_module</span><span class="p">(</span><span class="n">policy</span><span class="p">):</span>
            <span class="n">policy_new_device</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>

        <span class="n">param_and_buf_new_device</span> <span class="o">=</span> <span class="n">param_and_buf</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
            <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">_map_weight</span><span class="p">,</span> <span class="n">policy_device</span><span class="o">=</span><span class="n">policy_device</span><span class="p">),</span>
            <span class="n">filter_empty</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">param_and_buf_new_device</span><span class="o">.</span><span class="n">to_module</span><span class="p">(</span><span class="n">policy_new_device</span><span class="p">)</span>
        <span class="c1"># Sanity check</span>
        <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">TensorDict</span><span class="o">.</span><span class="n">from_module</span><span class="p">(</span><span class="n">policy_new_device</span><span class="p">)</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span> <span class="o">!=</span> <span class="nb">set</span><span class="p">(</span>
            <span class="n">get_original_weights</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Failed to map weights. The weight sets mismatch.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">policy_new_device</span><span class="p">,</span> <span class="n">get_original_weights</span>

<div class="viewcode-block" id="DataCollectorBase.start"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.DataCollectorBase.html#torchrl.collectors.DataCollectorBase.start">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">start</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Starts the collector for asynchronous data collection.</span>

<span class="sd">        This method initiates the background collection of data, allowing for decoupling of data collection and training.</span>

<span class="sd">        The collected data is typically stored in a replay buffer passed during the collector&#39;s initialization.</span>

<span class="sd">        .. note:: After calling this method, it&#39;s essential to shut down the collector using :meth:`~.async_shutdown`</span>
<span class="sd">            when you&#39;re done with it to free up resources.</span>

<span class="sd">        .. warning:: Asynchronous data collection can significantly impact training performance due to its decoupled nature.</span>
<span class="sd">            Ensure you understand the implications for your specific algorithm before using this mode.</span>

<span class="sd">        Raises:</span>
<span class="sd">            NotImplementedError: If not implemented by a subclass.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Collector start() is not implemented for </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="DataCollectorBase.pause"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.DataCollectorBase.html#torchrl.collectors.DataCollectorBase.pause">[docs]</a>    <span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">pause</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Context manager that pauses the collector if it is running free.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Collector pause() is not implemented for </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="DataCollectorBase.async_shutdown"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.DataCollectorBase.html#torchrl.collectors.DataCollectorBase.async_shutdown">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">async_shutdown</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">timeout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">close_env</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Shuts down the collector when started asynchronously with the `start` method.</span>

<span class="sd">        Args:</span>
<span class="sd">            timeout (float, optional): The maximum time to wait for the collector to shutdown.</span>
<span class="sd">            close_env (bool, optional): If True, the collector will close the contained environment.</span>
<span class="sd">                Defaults to `True`.</span>

<span class="sd">        .. seealso:: :meth:`~.start`</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span> <span class="n">close_env</span><span class="o">=</span><span class="n">close_env</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_extract_weights_if_needed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract weights from a model if needed.</span>

<span class="sd">        Args:</span>
<span class="sd">            weights: Either already-extracted weights or a model to extract from.</span>
<span class="sd">            model_id: The model identifier for resolving string paths.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Extracted weights in the appropriate format.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">scheme</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span>
            <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="c1"># If no weights were provided and a sync scheme exists, extract the latest</span>
        <span class="c1"># weights from the current model using the scheme strategy (state_dict or tensordict).</span>
        <span class="c1"># This ensures we don&#39;t return stale cached weights.</span>
        <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">scheme</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.weight_update.weight_sync_schemes</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
                <span class="n">_resolve_model</span><span class="p">,</span>
                <span class="n">WeightStrategy</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">strategy</span> <span class="o">=</span> <span class="n">WeightStrategy</span><span class="p">(</span><span class="n">extract_as</span><span class="o">=</span><span class="n">scheme</span><span class="o">.</span><span class="n">strategy</span><span class="p">)</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">_resolve_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">strategy</span><span class="o">.</span><span class="n">extract_weights</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">model_id</span> <span class="o">==</span> <span class="s2">&quot;policy&quot;</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;policy_weights&quot;</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_weights</span>
            <span class="k">elif</span> <span class="n">model_id</span> <span class="o">==</span> <span class="s2">&quot;policy&quot;</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_policy_weights_dict&quot;</span><span class="p">):</span>
                <span class="n">policy_device</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span>
                    <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_policy_weights_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">policy_device</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">scheme</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">weights</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.weight_update.weight_sync_schemes</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
            <span class="n">_resolve_model</span><span class="p">,</span>
            <span class="n">WeightStrategy</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">strategy</span> <span class="o">=</span> <span class="n">WeightStrategy</span><span class="p">(</span><span class="n">extract_as</span><span class="o">=</span><span class="n">scheme</span><span class="o">.</span><span class="n">strategy</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">strategy</span><span class="o">.</span><span class="n">extract_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">_resolve_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">strategy</span><span class="o">.</span><span class="n">extract_weights</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">weights</span>

<div class="viewcode-block" id="DataCollectorBase.update_policy_weights_"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.DataCollectorBase.html#torchrl.collectors.DataCollectorBase.update_policy_weights_">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">update_policy_weights_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">policy_or_weights</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="n">TensorDictModuleBase</span> <span class="o">|</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">worker_ids</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">weights_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updates the policy weights for the data collector, accommodating both local and remote execution contexts.</span>

<span class="sd">        This method ensures that the policy weights used by the data collector are synchronized with the latest</span>
<span class="sd">        trained weights. It supports both local and remote weight updates, depending on the configuration of the</span>
<span class="sd">        data collector. The local (download) update is performed before the remote (upload) update, such that weights</span>
<span class="sd">        can be transferred to the children workers from a server.</span>

<span class="sd">        Args:</span>
<span class="sd">            policy_or_weights (TensorDictBase | TensorDictModuleBase | dict | None): The weights to update with. Can be:</span>
<span class="sd">                - TensorDictModuleBase: A policy module whose weights will be extracted</span>
<span class="sd">                - TensorDictBase: A TensorDict containing weights</span>
<span class="sd">                - dict: A regular dict containing weights</span>
<span class="sd">                - None: Will try to get weights from server using _get_server_weights()</span>
<span class="sd">            worker_ids (int | List[int] | torch.device | List[torch.device] | None, optional): Identifiers for the</span>
<span class="sd">                workers that need to be updated. This is relevant when the collector has more than one worker associated</span>
<span class="sd">                with it.</span>
<span class="sd">            model_id (str | None, optional): The model identifier to update. If provided, only updates this specific</span>
<span class="sd">                model. Cannot be used together with weights_dict.</span>
<span class="sd">            weights_dict (dict[str, Any] | None, optional): Dictionary mapping model_id to weights for updating</span>
<span class="sd">                multiple models atomically. Keys should match the model_ids registered in weight_sync_schemes.</span>
<span class="sd">                Cannot be used together with model_id or policy_or_weights.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `worker_ids` is provided but no `weight_updater` is configured.</span>
<span class="sd">            ValueError: If conflicting parameters are provided (e.g., both model_id and weights_dict).</span>

<span class="sd">        .. note:: Users should extend the `WeightUpdaterBase` classes to customize</span>
<span class="sd">            the weight update logic for specific use cases. This method should not be overwritten.</span>

<span class="sd">        .. seealso:: :class:`~torchrl.collectors.LocalWeightsUpdaterBase` and</span>
<span class="sd">            :meth:`~torchrl.collectors.RemoteWeightsUpdaterBase`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="s2">&quot;policy_weights&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;`policy_weights` is deprecated. Use `policy_or_weights` instead.&quot;</span><span class="p">,</span>
                <span class="ne">DeprecationWarning</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">policy_or_weights</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;policy_weights&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">weights_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">model_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot specify both &#39;weights_dict&#39; and &#39;model_id&#39;&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">weights_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">policy_or_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot specify both &#39;weights_dict&#39; and &#39;policy_or_weights&#39;&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Priority: new weight sync schemes &gt; old weight updater system</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">weights_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">target_model_id</span><span class="p">,</span> <span class="n">weights</span> <span class="ow">in</span> <span class="n">weights_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">target_model_id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Model &#39;</span><span class="si">{</span><span class="n">target_model_id</span><span class="si">}</span><span class="s2">&#39; not found in registered weight senders. &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;Available models: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                    <span class="n">processed_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_weights_if_needed</span><span class="p">(</span>
                        <span class="n">weights</span><span class="p">,</span> <span class="n">target_model_id</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span><span class="p">[</span><span class="n">target_model_id</span><span class="p">]</span><span class="o">.</span><span class="n">update_weights</span><span class="p">(</span>
                        <span class="n">processed_weights</span>
                    <span class="p">)</span>
            <span class="k">elif</span> <span class="n">model_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">model_id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Model &#39;</span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s2">&#39; not found in registered weight senders. &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Available models: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                <span class="n">processed_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_weights_if_needed</span><span class="p">(</span>
                    <span class="n">policy_or_weights</span><span class="p">,</span> <span class="n">model_id</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span><span class="p">[</span><span class="n">model_id</span><span class="p">]</span><span class="o">.</span><span class="n">update_weights</span><span class="p">(</span><span class="n">processed_weights</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">&quot;policy&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span><span class="p">:</span>
                    <span class="n">processed_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_weights_if_needed</span><span class="p">(</span>
                        <span class="n">policy_or_weights</span><span class="p">,</span> <span class="s2">&quot;policy&quot;</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span><span class="p">[</span><span class="s2">&quot;policy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">update_weights</span><span class="p">(</span><span class="n">processed_weights</span><span class="p">)</span>
                <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">single_model_id</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
                    <span class="n">single_sender</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span><span class="p">[</span><span class="n">single_model_id</span><span class="p">]</span>
                    <span class="n">processed_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_weights_if_needed</span><span class="p">(</span>
                        <span class="n">policy_or_weights</span><span class="p">,</span> <span class="n">single_model_id</span>
                    <span class="p">)</span>
                    <span class="n">single_sender</span><span class="o">.</span><span class="n">update_weights</span><span class="p">(</span><span class="n">processed_weights</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">target_model_id</span><span class="p">,</span> <span class="n">sender</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="n">processed_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_weights_if_needed</span><span class="p">(</span>
                            <span class="n">policy_or_weights</span><span class="p">,</span> <span class="n">target_model_id</span>
                        <span class="p">)</span>
                        <span class="n">sender</span><span class="o">.</span><span class="n">update_weights</span><span class="p">(</span><span class="n">processed_weights</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_updater</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Fall back to old weight updater system</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_updater</span><span class="p">(</span>
                <span class="n">policy_or_weights</span><span class="o">=</span><span class="n">policy_or_weights</span><span class="p">,</span> <span class="n">worker_ids</span><span class="o">=</span><span class="n">worker_ids</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># No weight updater configured</span>
            <span class="c1"># For single-process collectors, apply weights locally if explicitly provided</span>
            <span class="k">if</span> <span class="n">policy_or_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.weight_update.weight_sync_schemes</span><span class="w"> </span><span class="kn">import</span> <span class="n">WeightStrategy</span>

                <span class="c1"># Use WeightStrategy to apply weights properly</span>
                <span class="n">strategy</span> <span class="o">=</span> <span class="n">WeightStrategy</span><span class="p">(</span><span class="n">extract_as</span><span class="o">=</span><span class="s2">&quot;tensordict&quot;</span><span class="p">)</span>

                <span class="c1"># Extract weights if needed</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy_or_weights</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
                    <span class="n">weights</span> <span class="o">=</span> <span class="n">strategy</span><span class="o">.</span><span class="n">extract_weights</span><span class="p">(</span><span class="n">policy_or_weights</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">weights</span> <span class="o">=</span> <span class="n">policy_or_weights</span>

                <span class="c1"># Apply to local policy</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;policy&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
                    <span class="n">strategy</span><span class="o">.</span><span class="n">apply_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
            <span class="k">elif</span> <span class="p">(</span>
                <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_original_policy&quot;</span><span class="p">)</span>
                <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_policy</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
                <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;policy&quot;</span><span class="p">)</span>
                <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="c1"># If no weights were provided, mirror weights from the original (trainer) policy</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.weight_update.weight_sync_schemes</span><span class="w"> </span><span class="kn">import</span> <span class="n">WeightStrategy</span>

                <span class="n">strategy</span> <span class="o">=</span> <span class="n">WeightStrategy</span><span class="p">(</span><span class="n">extract_as</span><span class="o">=</span><span class="s2">&quot;tensordict&quot;</span><span class="p">)</span>
                <span class="n">weights</span> <span class="o">=</span> <span class="n">strategy</span><span class="o">.</span><span class="n">extract_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_policy</span><span class="p">)</span>
                <span class="c1"># Cast weights to the policy device before applying</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">)</span>
                <span class="n">strategy</span><span class="o">.</span><span class="n">apply_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span></div>
            <span class="c1"># Otherwise, no action needed - policy is local and changes are immediately visible</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">]:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">yield from</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">next</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iterator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_iterator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_iterator</span><span class="p">)</span>
            <span class="c1"># if any, we don&#39;t want the device ref to be passed in distributed settings</span>
            <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">out</span>
        <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">shutdown</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timeout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">close_env</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">iterator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_read_compile_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">compile_policy</span><span class="p">,</span> <span class="n">cudagraph_policy</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy</span> <span class="o">=</span> <span class="n">compile_policy</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cudagraphed_policy</span> <span class="o">=</span> <span class="n">cudagraph_policy</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy_kwargs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">{}</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">compile_policy</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Mapping</span><span class="p">)</span> <span class="k">else</span> <span class="n">compile_policy</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cudagraphed_policy_kwargs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">{}</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cudagraph_policy</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Mapping</span><span class="p">)</span> <span class="k">else</span> <span class="n">cudagraph_policy</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">string</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">()&quot;</span>
        <span class="k">return</span> <span class="n">string</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__class_getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span> <span class="o">//</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">requested_frames_per_batch</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Non-terminating collectors do not have a length&quot;</span><span class="p">)</span>

<div class="viewcode-block" id="DataCollectorBase.init_updater"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.DataCollectorBase.html#torchrl.collectors.DataCollectorBase.init_updater">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">init_updater</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the weight updater with custom arguments.</span>

<span class="sd">        This method passes the arguments to the weight updater&#39;s init method.</span>
<span class="sd">        If no weight updater is set, this is a no-op.</span>

<span class="sd">        Args:</span>
<span class="sd">            *args: Positional arguments for weight updater initialization</span>
<span class="sd">            **kwargs: Keyword arguments for weight updater initialization</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_updater</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_updater</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="SyncDataCollector"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector">[docs]</a><span class="nd">@accept_remote_rref_udf_invocation</span>
<span class="k">class</span><span class="w"> </span><span class="nc">SyncDataCollector</span><span class="p">(</span><span class="n">DataCollectorBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generic data collector for RL problems. Requires an environment constructor and a policy.</span>

<span class="sd">    Args:</span>
<span class="sd">        create_env_fn (Callable or EnvBase): a callable that returns an instance of</span>
<span class="sd">            :class:`~torchrl.envs.EnvBase` class, or the env itself.</span>
<span class="sd">        policy (Callable): Policy to be executed in the environment.</span>
<span class="sd">            Must accept :class:`tensordict.tensordict.TensorDictBase` object as input.</span>
<span class="sd">            If ``None`` is provided, the policy used will be a</span>
<span class="sd">            :class:`~torchrl.collectors.RandomPolicy` instance with the environment</span>
<span class="sd">            ``action_spec``.</span>
<span class="sd">            Accepted policies are usually subclasses of :class:`~tensordict.nn.TensorDictModuleBase`.</span>
<span class="sd">            This is the recommended usage of the collector.</span>
<span class="sd">            Other callables are accepted too:</span>
<span class="sd">            If the policy is not a ``TensorDictModuleBase`` (e.g., a regular :class:`~torch.nn.Module`</span>
<span class="sd">            instances) it will be wrapped in a `nn.Module` first.</span>
<span class="sd">            Then, the collector will try to assess if these</span>
<span class="sd">            modules require wrapping in a :class:`~tensordict.nn.TensorDictModule` or not.</span>

<span class="sd">            - If the policy forward signature matches any of ``forward(self, tensordict)``,</span>
<span class="sd">              ``forward(self, td)`` or ``forward(self, &lt;anything&gt;: TensorDictBase)`` (or</span>
<span class="sd">              any typing with a single argument typed as a subclass of ``TensorDictBase``)</span>
<span class="sd">              then the policy won&#39;t be wrapped in a :class:`~tensordict.nn.TensorDictModule`.</span>

<span class="sd">            - In all other cases an attempt to wrap it will be undergone as such: ``TensorDictModule(policy, in_keys=env_obs_key, out_keys=env.action_keys)``.</span>

<span class="sd">            .. note:: If the policy needs to be passed as a policy factory (e.g., in case it mustn&#39;t be serialized /</span>
<span class="sd">                pickled directly), the ``policy_factory`` should be used instead.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        policy_factory (Callable[[], Callable], optional): a callable that returns</span>
<span class="sd">            a policy instance. This is exclusive with the `policy` argument.</span>

<span class="sd">            .. note:: `policy_factory` comes in handy whenever the policy cannot be serialized.</span>

<span class="sd">        frames_per_batch (int): A keyword-only argument representing the total</span>
<span class="sd">            number of elements in a batch.</span>
<span class="sd">        total_frames (int): A keyword-only argument representing the total</span>
<span class="sd">            number of frames returned by the collector</span>
<span class="sd">            during its lifespan. If the ``total_frames`` is not divisible by</span>
<span class="sd">            ``frames_per_batch``, an exception is raised.</span>
<span class="sd">             Endless collectors can be created by passing ``total_frames=-1``.</span>
<span class="sd">             Defaults to ``-1`` (endless collector).</span>
<span class="sd">        device (int, str or torch.device, optional): The generic device of the</span>
<span class="sd">            collector. The ``device`` args fills any non-specified device: if</span>
<span class="sd">            ``device`` is not ``None`` and any of ``storing_device``, ``policy_device`` or</span>
<span class="sd">            ``env_device`` is not specified, its value will be set to ``device``.</span>
<span class="sd">            Defaults to ``None`` (No default device).</span>
<span class="sd">        storing_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the output :class:`~tensordict.TensorDict` will be stored.</span>
<span class="sd">            If ``device`` is passed and ``storing_device`` is ``None``, it will</span>
<span class="sd">            default to the value indicated by ``device``.</span>
<span class="sd">            For long trajectories, it may be necessary to store the data on a different</span>
<span class="sd">            device than the one where the policy and env are executed.</span>
<span class="sd">            Defaults to ``None`` (the output tensordict isn&#39;t on a specific device,</span>
<span class="sd">            leaf tensors sit on the device where they were created).</span>
<span class="sd">        env_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the environment should be cast (or executed if that functionality is</span>
<span class="sd">            supported). If not specified and the env has a non-``None`` device,</span>
<span class="sd">            ``env_device`` will default to that value. If ``device`` is passed</span>
<span class="sd">            and ``env_device=None``, it will default to ``device``. If the value</span>
<span class="sd">            as such specified of ``env_device`` differs from ``policy_device``</span>
<span class="sd">            and one of them is not ``None``, the data will be cast to ``env_device``</span>
<span class="sd">            before being passed to the env (i.e., passing different devices to</span>
<span class="sd">            policy and env is supported). Defaults to ``None``.</span>
<span class="sd">        policy_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the policy should be cast.</span>
<span class="sd">            If ``device`` is passed and ``policy_device=None``, it will default</span>
<span class="sd">            to ``device``. If the value as such specified of ``policy_device``</span>
<span class="sd">            differs from ``env_device`` and one of them is not ``None``,</span>
<span class="sd">            the data will be cast to ``policy_device`` before being passed to</span>
<span class="sd">            the policy (i.e., passing different devices to policy and env is</span>
<span class="sd">            supported). Defaults to ``None``.</span>
<span class="sd">        create_env_kwargs (dict, optional): Dictionary of kwargs for</span>
<span class="sd">            ``create_env_fn``.</span>
<span class="sd">        max_frames_per_traj (int, optional): Maximum steps per trajectory.</span>
<span class="sd">            Note that a trajectory can span across multiple batches (unless</span>
<span class="sd">            ``reset_at_each_iter`` is set to ``True``, see below).</span>
<span class="sd">            Once a trajectory reaches ``n_steps``, the environment is reset.</span>
<span class="sd">            If the environment wraps multiple environments together, the number</span>
<span class="sd">            of steps is tracked for each environment independently. Negative</span>
<span class="sd">            values are allowed, in which case this argument is ignored.</span>
<span class="sd">            Defaults to ``None`` (i.e., no maximum number of steps).</span>
<span class="sd">        init_random_frames (int, optional): Number of frames for which the</span>
<span class="sd">            policy is ignored before it is called. This feature is mainly</span>
<span class="sd">            intended to be used in offline/model-based settings, where a</span>
<span class="sd">            batch of random trajectories can be used to initialize training.</span>
<span class="sd">            If provided, it will be rounded up to the closest multiple of frames_per_batch.</span>
<span class="sd">            Defaults to ``None`` (i.e. no random frames).</span>
<span class="sd">        reset_at_each_iter (bool, optional): Whether environments should be reset</span>
<span class="sd">            at the beginning of a batch collection.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        postproc (Callable, optional): A post-processing transform, such as</span>
<span class="sd">            a :class:`~torchrl.envs.Transform` or a :class:`~torchrl.data.postprocs.MultiStep`</span>
<span class="sd">            instance.</span>

<span class="sd">            .. warning:: Postproc is not applied when a replay buffer is used and items are added to the buffer</span>
<span class="sd">                as they are produced (`extend_buffer=False`). The recommended usage is to use `extend_buffer=True`.</span>

<span class="sd">            Defaults to ``None``.</span>
<span class="sd">        split_trajs (bool, optional): Boolean indicating whether the resulting</span>
<span class="sd">            TensorDict should be split according to the trajectories.</span>
<span class="sd">            See :func:`~torchrl.collectors.utils.split_trajectories` for more</span>
<span class="sd">            information.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        exploration_type (ExplorationType, optional): interaction mode to be used when</span>
<span class="sd">            collecting data. Must be one of ``torchrl.envs.utils.ExplorationType.DETERMINISTIC``,</span>
<span class="sd">            ``torchrl.envs.utils.ExplorationType.RANDOM``, ``torchrl.envs.utils.ExplorationType.MODE``</span>
<span class="sd">            or ``torchrl.envs.utils.ExplorationType.MEAN``.</span>
<span class="sd">        return_same_td (bool, optional): if ``True``, the same TensorDict</span>
<span class="sd">            will be returned at each iteration, with its values</span>
<span class="sd">            updated. This feature should be used cautiously: if the same</span>
<span class="sd">            tensordict is added to a replay buffer for instance,</span>
<span class="sd">            the whole content of the buffer will be identical.</span>
<span class="sd">            Default is ``False``.</span>
<span class="sd">        interruptor (_Interruptor, optional):</span>
<span class="sd">            An _Interruptor object that can be used from outside the class to control rollout collection.</span>
<span class="sd">            The _Interruptor class has methods ´start_collection´ and ´stop_collection´, which allow to implement</span>
<span class="sd">            strategies such as preeptively stopping rollout collection.</span>
<span class="sd">            Default is ``False``.</span>
<span class="sd">        set_truncated (bool, optional): if ``True``, the truncated signals (and corresponding</span>
<span class="sd">            ``&quot;done&quot;`` but not ``&quot;terminated&quot;``) will be set to ``True`` when the last frame of</span>
<span class="sd">            a rollout is reached. If no ``&quot;truncated&quot;`` key is found, an exception is raised.</span>
<span class="sd">            Truncated keys can be set through ``env.add_truncated_keys``.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        use_buffers (bool, optional): if ``True``, a buffer will be used to stack the data.</span>
<span class="sd">            This isn&#39;t compatible with environments with dynamic specs. Defaults to ``True``</span>
<span class="sd">            for envs without dynamic specs, ``False`` for others.</span>
<span class="sd">        replay_buffer (ReplayBuffer, optional): if provided, the collector will not yield tensordicts</span>
<span class="sd">            but populate the buffer instead.</span>
<span class="sd">            Defaults to ``None``.</span>

<span class="sd">            .. seealso:: By default (``extend_buffer=True``), the buffer is extended with entire rollouts.</span>
<span class="sd">                If the buffer needs to be populated with individual frames as they are collected,</span>
<span class="sd">                set ``extend_buffer=False`` (deprecated).</span>

<span class="sd">            .. warning:: Using a replay buffer with a `postproc` or `split_trajs=True` requires</span>
<span class="sd">                `extend_buffer=True`, as the whole batch needs to be observed to apply these transforms.</span>

<span class="sd">        extend_buffer (bool, optional): if `True`, the replay buffer is extended with entire rollouts and not</span>
<span class="sd">            with single steps. Defaults to `True`.</span>

<span class="sd">            .. note:: Setting this to `False` is deprecated and will be removed in a future version.</span>
<span class="sd">                Extending the buffer with entire rollouts is the recommended approach for better</span>
<span class="sd">                compatibility with postprocessing and trajectory splitting.</span>
<span class="sd">        trust_policy (bool, optional): if ``True``, a non-TensorDictModule policy will be trusted to be</span>
<span class="sd">            assumed to be compatible with the collector. This defaults to ``True`` for CudaGraphModules</span>
<span class="sd">            and ``False`` otherwise.</span>
<span class="sd">        compile_policy (bool or Dict[str, Any], optional): if ``True``, the policy will be compiled</span>
<span class="sd">            using :func:`~torch.compile` default behaviour. If a dictionary of kwargs is passed, it</span>
<span class="sd">            will be used to compile the policy.</span>
<span class="sd">        cudagraph_policy (bool or Dict[str, Any], optional): if ``True``, the policy will be wrapped</span>
<span class="sd">            in :class:`~tensordict.nn.CudaGraphModule` with default kwargs.</span>
<span class="sd">            If a dictionary of kwargs is passed, it will be used to wrap the policy.</span>
<span class="sd">        no_cuda_sync (bool): if ``True``, explicit CUDA synchronizations calls will be bypassed.</span>
<span class="sd">            For environments running directly on CUDA (`IsaacLab &lt;https://github.com/isaac-sim/IsaacLab/&gt;`_</span>
<span class="sd">            or `ManiSkills &lt;https://github.com/haosulab/ManiSkill/&gt;`_) cuda synchronization may cause unexpected</span>
<span class="sd">            crashes.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        weight_updater (WeightUpdaterBase or constructor, optional): An instance of :class:`~torchrl.collectors.WeightUpdaterBase`</span>
<span class="sd">            or its subclass, responsible for updating the policy weights on remote inference workers.</span>
<span class="sd">            This is typically not used in :class:`~torchrl.collectors.SyncDataCollector` as it operates in a single-process environment.</span>
<span class="sd">            Consider using a constructor if the updater needs to be serialized.</span>
<span class="sd">        track_policy_version (bool or PolicyVersion, optional): if ``True``, the collector will track the version of the policy.</span>
<span class="sd">            This will be mediated by the :class:`~torchrl.envs.llm.transforms.policy_version.PolicyVersion` transform, which will be added to the environment.</span>
<span class="sd">            Alternatively, a :class:`~torchrl.envs.llm.transforms.policy_version.PolicyVersion` instance can be passed, which will be used to track</span>
<span class="sd">            the policy version.</span>
<span class="sd">            Defaults to `False`.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span class="sd">        &gt;&gt;&gt; env_maker = lambda: GymEnv(&quot;Pendulum-v1&quot;, device=&quot;cpu&quot;)</span>
<span class="sd">        &gt;&gt;&gt; policy = TensorDictModule(nn.Linear(3, 1), in_keys=[&quot;observation&quot;], out_keys=[&quot;action&quot;])</span>
<span class="sd">        &gt;&gt;&gt; collector = SyncDataCollector(</span>
<span class="sd">        ...     create_env_fn=env_maker,</span>
<span class="sd">        ...     policy=policy,</span>
<span class="sd">        ...     total_frames=2000,</span>
<span class="sd">        ...     max_frames_per_traj=50,</span>
<span class="sd">        ...     frames_per_batch=200,</span>
<span class="sd">        ...     init_random_frames=-1,</span>
<span class="sd">        ...     reset_at_each_iter=False,</span>
<span class="sd">        ...     device=&quot;cpu&quot;,</span>
<span class="sd">        ...     storing_device=&quot;cpu&quot;,</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; for i, data in enumerate(collector):</span>
<span class="sd">        ...     if i == 2:</span>
<span class="sd">        ...         print(data)</span>
<span class="sd">        ...         break</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                collector: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        traj_ids: Tensor(shape=torch.Size([200]), device=cpu, dtype=torch.int64, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([200]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        step_count: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                        truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([200]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                step_count: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([200]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>
<span class="sd">        &gt;&gt;&gt; del collector</span>

<span class="sd">    The collector delivers batches of data that are marked with a ``&quot;time&quot;``</span>
<span class="sd">    dimension.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; assert data.names[-1] == &quot;time&quot;</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_ignore_rb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">create_env_fn</span><span class="p">:</span> <span class="p">(</span>
            <span class="n">EnvBase</span> <span class="o">|</span> <span class="n">EnvCreator</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="n">EnvBase</span><span class="p">]]</span>  <span class="c1"># noqa: F821</span>
        <span class="p">),</span>  <span class="c1"># noqa: F821</span>
        <span class="n">policy</span><span class="p">:</span> <span class="kc">None</span>
        <span class="o">|</span> <span class="p">(</span><span class="n">TensorDictModule</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">])</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">policy_factory</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">frames_per_batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">total_frames</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">storing_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">policy_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">env_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">create_env_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_frames_per_traj</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">init_random_frames</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">reset_at_each_iter</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">postproc</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">split_trajs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">exploration_type</span><span class="p">:</span> <span class="n">ExplorationType</span> <span class="o">=</span> <span class="n">DEFAULT_EXPLORATION_TYPE</span><span class="p">,</span>
        <span class="n">return_same_td</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">reset_when_done</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">interruptor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">set_truncated</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">use_buffers</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">replay_buffer</span><span class="p">:</span> <span class="n">ReplayBuffer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">extend_buffer</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">local_init_rb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">trust_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">compile_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cudagraph_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">no_cuda_sync</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">weight_updater</span><span class="p">:</span> <span class="n">WeightUpdaterBase</span>
        <span class="o">|</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">WeightUpdaterBase</span><span class="p">]</span>
        <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">weight_sync_schemes</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">WeightSyncScheme</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">track_policy_version</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.batched_envs</span><span class="w"> </span><span class="kn">import</span> <span class="n">BatchedEnvBase</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="n">create_env_kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">create_env_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">create_env_fn</span><span class="p">,</span> <span class="n">EnvBase</span><span class="p">):</span>
            <span class="n">env</span> <span class="o">=</span> <span class="n">create_env_fn</span><span class="p">(</span><span class="o">**</span><span class="n">create_env_kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">env</span> <span class="o">=</span> <span class="n">create_env_fn</span>
            <span class="k">if</span> <span class="n">create_env_kwargs</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">BatchedEnvBase</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="s2">&quot;kwargs were passed to SyncDataCollector but they can&#39;t be set &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;on environment of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">create_env_fn</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>
                <span class="n">env</span><span class="o">.</span><span class="n">update_kwargs</span><span class="p">(</span><span class="n">create_env_kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">policy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">policy_factory</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">policy</span> <span class="o">=</span> <span class="n">policy_factory</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">policy</span> <span class="o">=</span> <span class="n">RandomPolicy</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">full_action_spec</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">policy_factory</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;policy_factory cannot be used with policy argument.&quot;</span><span class="p">)</span>
        <span class="c1"># If the underlying policy has a state_dict, we keep a reference to the policy and</span>
        <span class="c1"># do all policy weight saving/loading through it</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="s2">&quot;state_dict&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_policy_w_state_dict</span> <span class="o">=</span> <span class="n">policy</span>

        <span class="k">if</span> <span class="n">trust_policy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">trust_policy</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="p">(</span><span class="n">RandomPolicy</span><span class="p">,</span> <span class="n">CudaGraphModule</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trust_policy</span> <span class="o">=</span> <span class="n">trust_policy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_read_compile_kwargs</span><span class="p">(</span><span class="n">compile_policy</span><span class="p">,</span> <span class="n">cudagraph_policy</span><span class="p">)</span>

        <span class="c1">##########################</span>
        <span class="c1"># Trajectory pool</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_traj_pool_val</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;traj_pool&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Keys </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2"> are unknown to </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="c1">##########################</span>
        <span class="c1"># Setting devices:</span>
        <span class="c1"># The rule is the following:</span>
        <span class="c1"># - If no device is passed, all devices are assumed to work OOB.</span>
        <span class="c1">#   The tensordict used for output is not on any device (ie, actions and observations</span>
        <span class="c1">#   can be on a different device).</span>
        <span class="c1"># - If the ``device`` is passed, it is used for all devices (storing, env and policy)</span>
        <span class="c1">#   unless overridden by another kwarg.</span>
        <span class="c1"># - The rest of the kwargs control the respective device.</span>
        <span class="n">storing_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_devices</span><span class="p">(</span>
            <span class="n">storing_device</span><span class="o">=</span><span class="n">storing_device</span><span class="p">,</span>
            <span class="n">policy_device</span><span class="o">=</span><span class="n">policy_device</span><span class="p">,</span>
            <span class="n">env_device</span><span class="o">=</span><span class="n">env_device</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span> <span class="o">=</span> <span class="n">storing_device</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
            <span class="c1"># Cuda handles sync</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_storage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span>
            <span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;mps&quot;</span><span class="p">):</span>
                <span class="c1"># Will break for older PT versions which don&#39;t have torch.mps</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_storage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">synchronize</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;npu&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">npu</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_storage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">npu</span><span class="o">.</span><span class="n">synchronize</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_storage</span> <span class="o">=</span> <span class="n">_do_nothing</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Non supported device&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sync_storage</span> <span class="o">=</span> <span class="n">_do_nothing</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span> <span class="o">=</span> <span class="n">env_device</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
            <span class="c1"># Cuda handles sync</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_env</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span>
            <span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;mps&quot;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_env</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">synchronize</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;npu&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">npu</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_env</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">npu</span><span class="o">.</span><span class="n">synchronize</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_env</span> <span class="o">=</span> <span class="n">_do_nothing</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Non supported device&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sync_env</span> <span class="o">=</span> <span class="n">_do_nothing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="o">=</span> <span class="n">policy_device</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
            <span class="c1"># Cuda handles sync</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_policy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span>
            <span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;mps&quot;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_policy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">synchronize</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;npu&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">npu</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_policy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">npu</span><span class="o">.</span><span class="n">synchronize</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_policy</span> <span class="o">=</span> <span class="n">_do_nothing</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Non supported device&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sync_policy</span> <span class="o">=</span> <span class="n">_do_nothing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span> <span class="o">=</span> <span class="n">no_cuda_sync</span>
        <span class="c1"># Check if we need to cast things from device to device</span>
        <span class="c1"># If the policy has a None device and the env too, no need to cast (we don&#39;t know</span>
        <span class="c1"># and assume the user knows what she&#39;s doing).</span>
        <span class="c1"># If the devices match we&#39;re happy too.</span>
        <span class="c1"># Only if the values differ we need to cast</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cast_to_policy_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">:</span> <span class="n">EnvBase</span> <span class="o">=</span> <span class="n">env</span>
        <span class="k">del</span> <span class="n">env</span>

        <span class="c1"># Policy version tracking setup</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span> <span class="o">=</span> <span class="n">track_policy_version</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">track_policy_version</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">and</span> <span class="n">track_policy_version</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.batched_envs</span><span class="w"> </span><span class="kn">import</span> <span class="n">BatchedEnvBase</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">,</span> <span class="n">BatchedEnvBase</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;BatchedEnvBase is not supported for policy version tracking. Please add the PolicyVersion transform to the environment manually, &quot;</span>
                    <span class="s2">&quot;and pass that transform to the collector.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span> <span class="o">=</span> <span class="n">PolicyVersion</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">append_transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span>
            <span class="n">track_policy_version</span><span class="p">,</span> <span class="s2">&quot;increment_version&quot;</span>
        <span class="p">):</span>  <span class="c1"># Check if it&#39;s a PolicyVersion instance</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span> <span class="o">=</span> <span class="n">track_policy_version</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">append_transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">replay_buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">extend_buffer</span> <span class="o">=</span> <span class="n">extend_buffer</span>

        <span class="c1"># Handle local_init_rb deprecation for SyncDataCollector</span>
        <span class="k">if</span> <span class="n">local_init_rb</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">local_init_rb</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Default for SyncDataCollector</span>
            <span class="k">if</span> <span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">local_init_rb</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;local_init_rb=False is deprecated and will be removed in v0.12. &quot;</span>
                    <span class="s2">&quot;The new storage-level initialization provides better performance.&quot;</span><span class="p">,</span>
                    <span class="ne">FutureWarning</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">local_init_rb</span> <span class="o">=</span> <span class="n">local_init_rb</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore_rb</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">postproc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">extend_buffer</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s2">&quot;postproc must be None when a replay buffer is passed, or extend_buffer must be set to True.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">split_trajs</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">extend_buffer</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s2">&quot;split_trajs must be None/False when a replay buffer is passed, or extend_buffer must be set to True.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">return_same_td</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s2">&quot;return_same_td must be False when a replay buffer is passed, or extend_buffer must be set to True.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">use_buffers</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;replay_buffer is exclusive with use_buffers.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">use_buffers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">use_buffers</span> <span class="o">=</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">_has_dynamic_specs</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span> <span class="o">=</span> <span class="n">use_buffers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">replay_buffer</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">reset_when_done</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;reset_when_done is deprecated.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_when_done</span> <span class="o">=</span> <span class="n">reset_when_done</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">batch_size</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="s2">&quot;register_collector&quot;</span><span class="p">):</span>
            <span class="n">policy</span><span class="o">.</span><span class="n">register_collector</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">,</span> <span class="s2">&quot;register_collector&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">register_collector</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_original_policy</span> <span class="o">=</span> <span class="n">policy</span>
        <span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_weights_fn</span><span class="p">,)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_policy_and_device</span><span class="p">(</span>
            <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trust_policy</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">policy</span>
            <span class="n">env</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;env&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">wrapped_policy</span> <span class="o">=</span> <span class="n">_make_compatible_policy</span><span class="p">(</span>
                    <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">,</span>
                    <span class="n">observation_spec</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="s2">&quot;observation_spec&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                    <span class="n">env</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">)</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s2">&quot;Failed to wrap the policy. If the policy needs to be trusted, set trust_policy=True.&quot;</span>
                <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">err</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span> <span class="o">=</span> <span class="n">wrapped_policy</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span> <span class="o">=</span> <span class="n">policy</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_weights</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="o">.</span><span class="n">from_module</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span><span class="p">,</span> <span class="n">as_module</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span><span class="o">.</span><span class="n">data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_weights</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span> <span class="o">=</span> <span class="n">compile_with_warmup</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy_kwargs</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cudagraphed_policy</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span> <span class="o">=</span> <span class="n">CudaGraphModule</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span><span class="p">,</span>
                <span class="n">in_keys</span><span class="o">=</span><span class="p">[],</span>
                <span class="n">out_keys</span><span class="o">=</span><span class="p">[],</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">,</span>
                <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">cudagraphed_policy_kwargs</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">:</span> <span class="n">EnvBase</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_device</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># we did not receive an env device, we use the device of the env</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">device</span>

        <span class="c1"># If the storing device is not the same as the policy device, we have</span>
        <span class="c1"># no guarantee that the &quot;next&quot; entry from the policy will be on the</span>
        <span class="c1"># same device as the collector metadata.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cast_to_env_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cast_to_policy_device</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_frames_per_traj</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">max_frames_per_traj</span><span class="p">)</span> <span class="k">if</span> <span class="n">max_frames_per_traj</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_frames_per_traj</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_frames_per_traj</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># let&#39;s check that there is no StepCounter yet</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">output_spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="n">key</span><span class="p">,)</span>
                <span class="k">if</span> <span class="s2">&quot;step_count&quot;</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;A &#39;step_count&#39; key is already present in the environment &quot;</span>
                        <span class="s2">&quot;and the &#39;max_frames_per_traj&#39; argument may conflict with &quot;</span>
                        <span class="s2">&quot;a &#39;StepCounter&#39; that has already been set. &quot;</span>
                        <span class="s2">&quot;Possible solutions: Set max_frames_per_traj to 0 or &quot;</span>
                        <span class="s2">&quot;remove the StepCounter limit from the environment transforms.&quot;</span>
                    <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">TransformedEnv</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">,</span> <span class="n">StepCounter</span><span class="p">(</span><span class="n">max_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_frames_per_traj</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">total_frames</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">total_frames</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">total_frames</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">remainder</span> <span class="o">=</span> <span class="n">total_frames</span> <span class="o">%</span> <span class="n">frames_per_batch</span>
            <span class="k">if</span> <span class="n">remainder</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">RL_WARNINGS</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;total_frames (</span><span class="si">{</span><span class="n">total_frames</span><span class="si">}</span><span class="s2">) is not exactly divisible by frames_per_batch (</span><span class="si">{</span><span class="n">frames_per_batch</span><span class="si">}</span><span class="s2">). &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;This means </span><span class="si">{</span><span class="n">frames_per_batch</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">remainder</span><span class="si">}</span><span class="s2"> additional frames will be collected.&quot;</span>
                    <span class="s2">&quot;To silence this message, set the environment variable RL_WARNINGS to False.&quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">total_frames</span><span class="p">)</span> <span class="k">if</span> <span class="n">total_frames</span> <span class="o">!=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">total_frames</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_at_each_iter</span> <span class="o">=</span> <span class="n">reset_at_each_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">init_random_frames</span><span class="p">)</span> <span class="k">if</span> <span class="n">init_random_frames</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">init_random_frames</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="ow">and</span> <span class="n">init_random_frames</span> <span class="o">%</span> <span class="n">frames_per_batch</span> <span class="o">!=</span> <span class="mi">0</span>
            <span class="ow">and</span> <span class="n">RL_WARNINGS</span>
        <span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;init_random_frames (</span><span class="si">{</span><span class="n">init_random_frames</span><span class="si">}</span><span class="s2">) is not exactly a multiple of frames_per_batch (</span><span class="si">{</span><span class="n">frames_per_batch</span><span class="si">}</span><span class="s2">), &quot;</span>
                <span class="sa">f</span><span class="s2">&quot; this results in more init_random_frames than requested&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; (</span><span class="si">{</span><span class="o">-</span><span class="p">(</span><span class="o">-</span><span class="n">init_random_frames</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">frames_per_batch</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">frames_per_batch</span><span class="si">}</span><span class="s2">).&quot;</span>
                <span class="s2">&quot;To silence this message, set the environment variable RL_WARNINGS to False.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">postproc</span> <span class="o">=</span> <span class="n">postproc</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">postproc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">postproc</span><span class="p">,</span> <span class="s2">&quot;to&quot;</span><span class="p">)</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span>
        <span class="p">):</span>
            <span class="n">postproc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postproc</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">postproc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">postproc</span> <span class="ow">and</span> <span class="n">postproc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">postproc</span> <span class="o">=</span> <span class="n">postproc</span>

        <span class="k">if</span> <span class="n">frames_per_batch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_env</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">RL_WARNINGS</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;frames_per_batch (</span><span class="si">{</span><span class="n">frames_per_batch</span><span class="si">}</span><span class="s2">) is not exactly divisible by the number of batched environments (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_env</span><span class="si">}</span><span class="s2">), &quot;</span>
                <span class="sa">f</span><span class="s2">&quot; this results in more frames_per_batch per iteration that requested&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; (</span><span class="si">{</span><span class="o">-</span><span class="p">(</span><span class="o">-</span><span class="n">frames_per_batch</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">n_env</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">n_env</span><span class="si">}</span><span class="s2">). &quot;</span>
                <span class="s2">&quot;To silence this message, set the environment variable RL_WARNINGS to False.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_batch</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="o">-</span><span class="n">frames_per_batch</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">requested_frames_per_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_batch</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exploration_type</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">exploration_type</span> <span class="k">if</span> <span class="n">exploration_type</span> <span class="k">else</span> <span class="n">DEFAULT_EXPLORATION_TYPE</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_same_td</span> <span class="o">=</span> <span class="n">return_same_td</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_truncated</span> <span class="o">=</span> <span class="n">set_truncated</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_make_shuttle</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_make_final_rollout</span><span class="p">(</span><span class="n">make_rollout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_truncated_keys</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">split_trajs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">split_trajs</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">split_trajs</span> <span class="o">=</span> <span class="n">split_trajs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_exclude_private_keys</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span> <span class="o">=</span> <span class="n">interruptor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

        <span class="c1"># Set up weight synchronization - prefer new schemes over legacy updater</span>
        <span class="c1"># For single-process SyncDataCollector, no weight sync is needed (policy is local)</span>
        <span class="c1"># Weight sync schemes are only needed for multi-process/distributed collectors</span>
        <span class="k">if</span> <span class="n">weight_sync_schemes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Use new simplified weight synchronization system</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span> <span class="o">=</span> <span class="n">weight_sync_schemes</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="c1"># For single-process collectors, we don&#39;t need senders/receivers</span>
            <span class="c1"># The policy is local and changes are immediately visible</span>
            <span class="c1"># Senders will be set up in multiprocess collectors during _run_processes</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">weight_updater</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Don&#39;t use legacy system</span>
        <span class="k">elif</span> <span class="n">weight_updater</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Use legacy weight updater system if explicitly provided</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weight_updater</span><span class="p">,</span> <span class="n">WeightUpdaterBase</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">weight_updater</span><span class="p">):</span>
                    <span class="n">weight_updater</span> <span class="o">=</span> <span class="n">weight_updater</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;weight_updater must be a subclass of WeightUpdaterBase. Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">weight_updater</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
                    <span class="p">)</span>

            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Using WeightUpdaterBase is deprecated. Please use weight_sync_schemes instead. &quot;</span>
                <span class="s2">&quot;This will be removed in a future version.&quot;</span><span class="p">,</span>
                <span class="ne">DeprecationWarning</span><span class="p">,</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_updater</span> <span class="o">=</span> <span class="n">weight_updater</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># No weight sync needed for single-process collectors</span>
            <span class="c1"># The policy is local and changes are immediately visible</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_updater</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_traj_pool</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">pool</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_traj_pool_val&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">pool</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_traj_pool_val</span> <span class="o">=</span> <span class="n">_TrajectoryPool</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">pool</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_make_shuttle</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Shuttle is a deviceless tensordict that just carried data from env to policy and policy to env</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle_has_no_device</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle_has_no_device</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="n">traj_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_traj_pool</span><span class="o">.</span><span class="n">get_traj_and_increment</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_env</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span>
        <span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
            <span class="p">(</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">),</span>
            <span class="n">traj_ids</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_maybe_make_final_rollout</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">make_rollout</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">make_rollout</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">fake_tensordict</span><span class="p">()</span>

            <span class="c1"># If storing device is not None, we use this to cast the storage.</span>
            <span class="c1"># If it is None and the env and policy are on the same device,</span>
            <span class="c1"># the storing device is already the same as those, so we don&#39;t need</span>
            <span class="c1"># to consider this use case.</span>
            <span class="c1"># In all other cases, we can&#39;t really put a device on the storage,</span>
            <span class="c1"># since at least one data source has a device that is not clear.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># erase all devices</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>

        <span class="c1"># If the policy has a valid spec, we use it</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_policy_output_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">make_rollout</span>
            <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span><span class="p">,</span> <span class="s2">&quot;spec&quot;</span><span class="p">)</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span><span class="o">.</span><span class="n">spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span>
                <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="c1"># if policy spec is non-empty, all the values are not None and the keys</span>
                <span class="c1"># match the out_keys we assume the user has given all relevant information</span>
                <span class="c1"># the policy could have more keys than the env:</span>
                <span class="n">policy_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span><span class="o">.</span><span class="n">spec</span>
                <span class="k">if</span> <span class="n">policy_spec</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
                    <span class="n">policy_spec</span> <span class="o">=</span> <span class="n">policy_spec</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">spec</span> <span class="ow">in</span> <span class="n">policy_spec</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_policy_output_keys</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
                        <span class="k">continue</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">spec</span><span class="o">.</span><span class="n">zero</span><span class="p">())</span>
        <span class="k">elif</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="n">make_rollout</span>
            <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span><span class="p">,</span> <span class="s2">&quot;out_keys&quot;</span><span class="p">)</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span><span class="o">.</span><span class="n">out_keys</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_policy_output_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span><span class="o">.</span><span class="n">out_keys</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">make_rollout</span><span class="p">:</span>
                <span class="c1"># otherwise, we perform a small number of steps with the policy to</span>
                <span class="c1"># determine the relevant keys with which to pre-populate _final_rollout.</span>
                <span class="c1"># This is the safest thing to do if the spec has None fields or if there is</span>
                <span class="c1"># no spec at all.</span>
                <span class="c1"># See #505 for additional context.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">policy_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">:</span>
                    <span class="n">policy_input</span> <span class="o">=</span> <span class="n">policy_input</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">)</span>
                <span class="c1"># we cast to policy device, we&#39;ll deal with the device later</span>
                <span class="n">policy_input_copy</span> <span class="o">=</span> <span class="n">policy_input</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">policy_input_clone</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">policy_input</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="p">)</span>  <span class="c1"># to test if values have changed in-place</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy</span><span class="p">:</span>
                    <span class="n">cudagraph_mark_step_begin</span><span class="p">()</span>
                <span class="n">policy_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span><span class="p">(</span><span class="n">policy_input</span><span class="p">)</span>

                <span class="c1"># check that we don&#39;t have exclusive keys, because they don&#39;t appear in keys</span>
                <span class="k">def</span><span class="w"> </span><span class="nf">check_exclusive</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">LazyStackedTensorDict</span><span class="p">)</span>
                        <span class="ow">and</span> <span class="n">val</span><span class="o">.</span><span class="n">_has_exclusive_keys</span>
                    <span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                            <span class="s2">&quot;LazyStackedTensorDict with exclusive keys are not permitted in collectors. &quot;</span>
                            <span class="s2">&quot;Consider using a placeholder for missing keys.&quot;</span>
                        <span class="p">)</span>

                <span class="n">policy_output</span><span class="o">.</span><span class="n">_fast_apply</span><span class="p">(</span>
                    <span class="n">check_exclusive</span><span class="p">,</span> <span class="n">call_on_nested</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">filter_empty</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>

                <span class="c1"># Use apply, because it works well with lazy stacks</span>
                <span class="c1"># Edge-case of this approach: the policy may change the values in-place and only by a tiny bit</span>
                <span class="c1"># or occasionally. In these cases, the keys will be missed (we can&#39;t detect if the policy has</span>
                <span class="c1"># changed them here).</span>
                <span class="c1"># This will cause a failure to update entries when policy and env device mismatch and</span>
                <span class="c1"># casting is necessary.</span>
                <span class="k">def</span><span class="w"> </span><span class="nf">filter_policy</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value_output</span><span class="p">,</span> <span class="n">value_input</span><span class="p">,</span> <span class="n">value_input_clone</span><span class="p">):</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">value_input</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
                        <span class="p">(</span><span class="n">value_output</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">value_input</span><span class="p">)</span>
                        <span class="ow">and</span> <span class="p">(</span>
                            <span class="n">value_output</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">value_input_clone</span><span class="o">.</span><span class="n">device</span>
                            <span class="ow">or</span> <span class="o">~</span><span class="n">torch</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">value_output</span><span class="p">,</span> <span class="n">value_input_clone</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
                        <span class="p">)</span>
                    <span class="p">):</span>
                        <span class="k">return</span> <span class="n">value_output</span>

                <span class="n">filtered_policy_output</span> <span class="o">=</span> <span class="n">policy_output</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
                    <span class="n">filter_policy</span><span class="p">,</span>
                    <span class="n">policy_input_copy</span><span class="p">,</span>
                    <span class="n">policy_input_clone</span><span class="p">,</span>
                    <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">filter_empty</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">named</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_policy_output_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_policy_output_keys</span><span class="o">.</span><span class="n">union</span><span class="p">(</span>
                        <span class="nb">set</span><span class="p">(</span><span class="n">filtered_policy_output</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">make_rollout</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="n">policy_output</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_policy_output_keys</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="k">del</span> <span class="n">filtered_policy_output</span><span class="p">,</span> <span class="n">policy_output</span><span class="p">,</span> <span class="n">policy_input</span>

        <span class="n">_env_output_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">spec</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;full_observation_spec&quot;</span><span class="p">,</span> <span class="s2">&quot;full_done_spec&quot;</span><span class="p">,</span> <span class="s2">&quot;full_reward_spec&quot;</span><span class="p">]:</span>
            <span class="n">_env_output_keys</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">output_spec</span><span class="p">[</span><span class="n">spec</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_env_output_keys</span> <span class="o">=</span> <span class="n">_env_output_keys</span>
        <span class="k">if</span> <span class="n">make_rollout</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_batch</span><span class="p">)</span>
                <span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="p">)</span>

            <span class="c1"># in addition to outputs of the policy, we add traj_ids to</span>
            <span class="c1"># _final_rollout which will be collected during rollout</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                <span class="p">(</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">refine_names</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="s2">&quot;time&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_set_truncated_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_truncated_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">set_truncated</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">_ends_with</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;truncated&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">done_keys</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;set_truncated was set to True but no truncated key could be found &quot;</span>
                    <span class="s2">&quot;in the environment. Make sure the truncated keys are properly set using &quot;</span>
                    <span class="s2">&quot;`env.add_truncated_keys()` before passing the env to the collector.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_truncated_keys</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">done_keys</span> <span class="k">if</span> <span class="n">_ends_with</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;truncated&quot;</span><span class="p">)</span>
            <span class="p">]</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_get_devices</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">storing_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">policy_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">env_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">_make_ordinal_device</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="n">device</span> <span class="k">else</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">storing_device</span> <span class="o">=</span> <span class="n">_make_ordinal_device</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">storing_device</span><span class="p">)</span> <span class="k">if</span> <span class="n">storing_device</span> <span class="k">else</span> <span class="n">device</span>
        <span class="p">)</span>
        <span class="n">policy_device</span> <span class="o">=</span> <span class="n">_make_ordinal_device</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">policy_device</span><span class="p">)</span> <span class="k">if</span> <span class="n">policy_device</span> <span class="k">else</span> <span class="n">device</span>
        <span class="p">)</span>
        <span class="n">env_device</span> <span class="o">=</span> <span class="n">_make_ordinal_device</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">env_device</span><span class="p">)</span> <span class="k">if</span> <span class="n">env_device</span> <span class="k">else</span> <span class="n">device</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">storing_device</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="n">env_device</span> <span class="o">==</span> <span class="n">policy_device</span><span class="p">):</span>
            <span class="n">storing_device</span> <span class="o">=</span> <span class="n">env_device</span>
        <span class="k">return</span> <span class="n">storing_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_device</span>

    <span class="c1"># for RPC</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">next</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="SyncDataCollector.update_policy_weights_"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.update_policy_weights_">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">update_policy_weights_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">policy_or_weights</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="n">TensorDictModuleBase</span> <span class="o">|</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">worker_ids</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;policy_weights&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;`policy_weights` is deprecated. Use `policy_or_weights` instead.&quot;</span><span class="p">,</span>
                <span class="ne">DeprecationWarning</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">policy_or_weights</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;policy_weights&quot;</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">update_policy_weights_</span><span class="p">(</span>
            <span class="n">policy_or_weights</span><span class="o">=</span><span class="n">policy_or_weights</span><span class="p">,</span> <span class="n">worker_ids</span><span class="o">=</span><span class="n">worker_ids</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="SyncDataCollector.set_seed"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.set_seed">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sets the seeds of the environments stored in the DataCollector.</span>

<span class="sd">        Args:</span>
<span class="sd">            seed (int): integer representing the seed to be used for the environment.</span>
<span class="sd">            static_seed(bool, optional): if ``True``, the seed is not incremented.</span>
<span class="sd">                Defaults to False</span>

<span class="sd">        Returns:</span>
<span class="sd">            Output seed. This is useful when more than one environment is contained in the DataCollector, as the</span>
<span class="sd">            seed will be incremented for each of these. The resulting seed is the seed of the last environment.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs import ParallelEnv</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">            &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">            &gt;&gt;&gt; from torch import nn</span>
<span class="sd">            &gt;&gt;&gt; env_fn = lambda: GymEnv(&quot;Pendulum-v1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; env_fn_parallel = ParallelEnv(6, env_fn)</span>
<span class="sd">            &gt;&gt;&gt; policy = TensorDictModule(nn.Linear(3, 1), in_keys=[&quot;observation&quot;], out_keys=[&quot;action&quot;])</span>
<span class="sd">            &gt;&gt;&gt; collector = SyncDataCollector(env_fn_parallel, policy, total_frames=300, frames_per_batch=100)</span>
<span class="sd">            &gt;&gt;&gt; out_seed = collector.set_seed(1)  # out_seed = 6</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">static_seed</span><span class="o">=</span><span class="n">static_seed</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_increment_frames</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">numel</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">+=</span> <span class="n">numel</span>
        <span class="n">completed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span>
        <span class="k">if</span> <span class="n">completed</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">completed</span>

<div class="viewcode-block" id="SyncDataCollector.iterator"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.iterator">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">iterator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Iterates through the DataCollector.</span>

<span class="sd">        Yields: TensorDictBase objects containing (chunks of) trajectories</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span>
        <span class="p">):</span>
            <span class="n">stream</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Stream</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="p">,</span> <span class="n">priority</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">event</span> <span class="o">=</span> <span class="n">stream</span><span class="o">.</span><span class="n">record_event</span><span class="p">()</span>
            <span class="n">streams</span> <span class="o">=</span> <span class="p">[</span><span class="n">stream</span><span class="p">]</span>
            <span class="n">events</span> <span class="o">=</span> <span class="p">[</span><span class="n">event</span><span class="p">]</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">streams</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">events</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="c1"># this way of checking cuda is robust to lazy stacks with mismatching shapes</span>
            <span class="n">cuda_devices</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">cuda_check</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">is_cuda</span><span class="p">:</span>
                    <span class="n">cuda_devices</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span><span class="p">:</span>
                <span class="c1"># This may be a bit dangerous as `torch.device(&quot;cuda&quot;)` may not have a precise</span>
                <span class="c1"># device associated, whereas `tensor.device` always has</span>
                <span class="k">for</span> <span class="n">spec</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">specs</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">spec</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">spec</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
                        <span class="k">if</span> <span class="s2">&quot;:&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
                            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                                <span class="s2">&quot;A cuda spec did not have a device associated. Make sure to &quot;</span>
                                <span class="s2">&quot;pass `&#39;cuda:device_num&#39;` to each spec device.&quot;</span>
                            <span class="p">)</span>
                        <span class="n">cuda_devices</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">cuda_check</span><span class="p">,</span> <span class="n">filter_empty</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">device</span> <span class="ow">in</span> <span class="n">cuda_devices</span><span class="p">:</span>
                <span class="n">streams</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Stream</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">priority</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">events</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">streams</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">record_event</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">streams</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">events</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">ExitStack</span><span class="p">()</span> <span class="k">as</span> <span class="n">stack</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">stream</span> <span class="ow">in</span> <span class="n">streams</span><span class="p">:</span>
                <span class="n">stack</span><span class="o">.</span><span class="n">enter_context</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="n">stream</span><span class="p">))</span>

            <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Collector: rollout.&quot;</span><span class="p">)</span>
                <span class="n">tensordict_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rollout</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">tensordict_out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># if a replay buffer is passed and self.extend_buffer=False, there is no tensordict_out</span>
                    <span class="c1">#  frames are updated within the rollout function</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Collector: No tensordict_out. Yielding.&quot;</span><span class="p">)</span>
                    <span class="k">yield</span>
                    <span class="k">continue</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_increment_frames</span><span class="p">(</span><span class="n">tensordict_out</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span>
                <span class="n">tensordict_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_postproc</span><span class="p">(</span><span class="n">tensordict_out</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Collector: postproc done.&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_same_td</span><span class="p">:</span>
                    <span class="c1"># This is used with multiprocessed collectors to use the buffers</span>
                    <span class="c1"># stored in the tensordict.</span>
                    <span class="k">if</span> <span class="n">events</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">event</span> <span class="ow">in</span> <span class="n">events</span><span class="p">:</span>
                            <span class="n">event</span><span class="o">.</span><span class="n">record</span><span class="p">()</span>
                            <span class="n">event</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
                    <span class="k">yield</span> <span class="n">tensordict_out</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore_rb</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">tensordict_out</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Collector: Added </span><span class="si">{</span><span class="n">tensordict_out</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="si">}</span><span class="s2"> frames to replay buffer. &quot;</span>
                            <span class="s2">&quot;Buffer write count: </span><span class="si">{self.replay_buffer.write_count}</span><span class="s2">. Yielding.&quot;</span>
                        <span class="p">)</span>
                    <span class="k">yield</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># we must clone the values, as the tensordict is updated in-place.</span>
                    <span class="c1"># otherwise the following code may break:</span>
                    <span class="c1"># &gt;&gt;&gt; for i, data in enumerate(collector):</span>
                    <span class="c1"># &gt;&gt;&gt;      if i == 0:</span>
                    <span class="c1"># &gt;&gt;&gt;          data0 = data</span>
                    <span class="c1"># &gt;&gt;&gt;      elif i == 1:</span>
                    <span class="c1"># &gt;&gt;&gt;          data1 = data</span>
                    <span class="c1"># &gt;&gt;&gt;      else:</span>
                    <span class="c1"># &gt;&gt;&gt;          break</span>
                    <span class="c1"># &gt;&gt;&gt; assert data0[&quot;done&quot;] is not data1[&quot;done&quot;]</span>
                    <span class="k">yield</span> <span class="n">tensordict_out</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span></div>

<div class="viewcode-block" id="SyncDataCollector.start"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.start">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">start</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Starts the collector in a separate thread for asynchronous data collection.</span>

<span class="sd">        The collected data is stored in the provided replay buffer. This method is useful when you want to decouple data</span>
<span class="sd">        collection from training, allowing your training loop to run independently of the data collection process.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: If no replay buffer is defined during the collector&#39;s initialization.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; import time</span>
<span class="sd">            &gt;&gt;&gt; from functools import partial</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; import tqdm</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.collectors import SyncDataCollector, RandomPolicy</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.data import LazyTensorStorage, ReplayBuffer</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs import GymEnv, set_gym_backend</span>
<span class="sd">            &gt;&gt;&gt; import ale_py</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Set the gym backend to gymnasium</span>
<span class="sd">            &gt;&gt;&gt; set_gym_backend(&quot;gymnasium&quot;).set()</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; if __name__ == &quot;__main__&quot;:</span>
<span class="sd">            ...     # Create a random policy for the Pong environment</span>
<span class="sd">            ...     env = GymEnv(&quot;ALE/Pong-v5&quot;)</span>
<span class="sd">            ...     policy = RandomPolicy(env.action_spec)</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Initialize a shared replay buffer</span>
<span class="sd">            ...     rb = ReplayBuffer(storage=LazyTensorStorage(1000), shared=True)</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Create a synchronous data collector</span>
<span class="sd">            ...     collector = SyncDataCollector(</span>
<span class="sd">            ...         env,</span>
<span class="sd">            ...         policy=policy,</span>
<span class="sd">            ...         replay_buffer=rb,</span>
<span class="sd">            ...         frames_per_batch=256,</span>
<span class="sd">            ...         total_frames=-1,</span>
<span class="sd">            ...     )</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Progress bar to track the number of collected frames</span>
<span class="sd">            ...     pbar = tqdm.tqdm(total=100_000)</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Start the collector asynchronously</span>
<span class="sd">            ...     collector.start()</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Track the write count of the replay buffer</span>
<span class="sd">            ...     prec_wc = 0</span>
<span class="sd">            ...     while True:</span>
<span class="sd">            ...         wc = rb.write_count</span>
<span class="sd">            ...         c = wc - prec_wc</span>
<span class="sd">            ...         prec_wc = wc</span>
<span class="sd">            ...</span>
<span class="sd">            ...         # Update the progress bar</span>
<span class="sd">            ...         pbar.update(c)</span>
<span class="sd">            ...         pbar.set_description(f&quot;Write Count: {rb.write_count}&quot;)</span>
<span class="sd">            ...</span>
<span class="sd">            ...         # Check the write count every 0.5 seconds</span>
<span class="sd">            ...         time.sleep(0.5)</span>
<span class="sd">            ...</span>
<span class="sd">            ...         # Stop when the desired number of frames is reached</span>
<span class="sd">            ...         if rb.write_count . 100_000:</span>
<span class="sd">            ...             break</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Shut down the collector</span>
<span class="sd">            ...     collector.async_shutdown()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Replay buffer must be defined for execution.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_running</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stop</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_thread</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_run_iterator</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_thread</span><span class="o">.</span><span class="n">daemon</span> <span class="o">=</span> <span class="p">(</span>
                <span class="kc">True</span>  <span class="c1"># So that the thread dies when the main program exits</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_thread</span><span class="o">.</span><span class="n">start</span><span class="p">()</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_run_iterator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stop</span><span class="p">:</span>
                <span class="k">return</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">is_running</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_thread&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_thread</span><span class="o">.</span><span class="n">is_alive</span><span class="p">()</span>

<div class="viewcode-block" id="SyncDataCollector.async_shutdown"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.async_shutdown">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">async_shutdown</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">timeout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">close_env</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Finishes processes started by ray.init() during async execution.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stop</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_thread&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_thread</span><span class="o">.</span><span class="n">is_alive</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_thread</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">(</span><span class="n">close_env</span><span class="o">=</span><span class="n">close_env</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_postproc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict_out</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_trajs</span><span class="p">:</span>
            <span class="n">tensordict_out</span> <span class="o">=</span> <span class="n">split_trajectories</span><span class="p">(</span><span class="n">tensordict_out</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;collector&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">postproc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tensordict_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postproc</span><span class="p">(</span><span class="n">tensordict_out</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exclude_private_keys</span><span class="p">:</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">is_private</span><span class="p">(</span><span class="n">key</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">):</span>
                    <span class="k">return</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span><span class="n">_key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_key</span> <span class="ow">in</span> <span class="n">key</span><span class="p">):</span>
                    <span class="k">return</span> <span class="kc">True</span>
                <span class="k">return</span> <span class="kc">False</span>

            <span class="n">excluded_keys</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">tensordict_out</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span> <span class="k">if</span> <span class="n">is_private</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
            <span class="p">]</span>
            <span class="n">tensordict_out</span> <span class="o">=</span> <span class="n">tensordict_out</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="n">excluded_keys</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensordict_out</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_update_traj_ids</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># we can&#39;t use the reset keys because they&#39;re gone</span>
        <span class="n">traj_sop</span> <span class="o">=</span> <span class="n">_aggregate_end_of_traj</span><span class="p">(</span>
            <span class="n">env_output</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;next&quot;</span><span class="p">),</span> <span class="n">done_keys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">done_keys</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">traj_sop</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span>

            <span class="n">traj_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">traj_ids</span> <span class="o">=</span> <span class="n">traj_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">traj_sop</span> <span class="o">=</span> <span class="n">traj_sop</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">traj_sop</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">traj_ids</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                <span class="n">traj_sop</span> <span class="o">=</span> <span class="n">traj_sop</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">traj_ids</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="n">pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_traj_pool</span>
            <span class="n">new_traj</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">get_traj_and_increment</span><span class="p">(</span>
                <span class="n">traj_sop</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">device</span><span class="o">=</span><span class="n">traj_sop</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="n">traj_ids</span> <span class="o">=</span> <span class="n">traj_ids</span><span class="o">.</span><span class="n">masked_scatter</span><span class="p">(</span><span class="n">traj_sop</span><span class="p">,</span> <span class="n">new_traj</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">set</span><span class="p">((</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">),</span> <span class="n">traj_ids</span><span class="p">)</span>

<div class="viewcode-block" id="SyncDataCollector.rollout"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.rollout">[docs]</a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">rollout</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes a rollout in the environment using the provided policy.</span>

<span class="sd">        Returns:</span>
<span class="sd">            TensorDictBase containing the computed rollout.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_at_each_iter</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">())</span>

        <span class="c1"># self._shuttle.fill_((&quot;collector&quot;, &quot;step_count&quot;), 0)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">fill_</span><span class="p">((</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="n">tensordicts</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">set_exploration_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">exploration_type</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">frames_per_batch</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span>
                <span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">rand_action</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="p">)</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span>
                    <span class="p">):</span>
                        <span class="c1"># TODO: This may break with exclusive / ragged lazy stacks</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
                            <span class="k">lambda</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="n">val</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span>
                            <span class="p">)</span>
                            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_policy_output_keys</span>
                            <span class="k">else</span> <span class="n">val</span><span class="p">,</span>
                            <span class="n">out</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="p">,</span>
                            <span class="n">named</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">nested_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cast_to_policy_device</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="c1"># This is unsafe if the shuttle is in pin_memory -- otherwise cuda will be happy with non_blocking</span>
                            <span class="n">non_blocking</span> <span class="o">=</span> <span class="p">(</span>
                                <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span>
                                <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span>
                            <span class="p">)</span>
                            <span class="n">policy_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">,</span>
                                <span class="n">non_blocking</span><span class="o">=</span><span class="n">non_blocking</span><span class="p">,</span>
                            <span class="p">)</span>
                            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_policy</span><span class="p">()</span>
                        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="c1"># we know the tensordict has a device otherwise we would not be here</span>
                            <span class="c1"># we can pass this, clear_device_ must have been called earlier</span>
                            <span class="c1"># policy_input = self._shuttle.clear_device_()</span>
                            <span class="n">policy_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">policy_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span>
                    <span class="c1"># we still do the assignment for security</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy</span><span class="p">:</span>
                        <span class="n">cudagraph_mark_step_begin</span><span class="p">()</span>
                    <span class="n">policy_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span><span class="p">(</span><span class="n">policy_input</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy</span><span class="p">:</span>
                        <span class="n">policy_output</span> <span class="o">=</span> <span class="n">policy_output</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">policy_output</span><span class="p">:</span>
                        <span class="c1"># ad-hoc update shuttle</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                            <span class="n">policy_output</span><span class="p">,</span> <span class="n">keys_to_update</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_policy_output_keys</span>
                        <span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cast_to_env_device</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">non_blocking</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span>
                        <span class="p">)</span>
                        <span class="n">env_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="n">non_blocking</span>
                        <span class="p">)</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_sync_env</span><span class="p">()</span>
                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="c1"># we know the tensordict has a device otherwise we would not be here</span>
                        <span class="c1"># we can pass this, clear_device_ must have been called earlier</span>
                        <span class="c1"># env_input = self._shuttle.clear_device_()</span>
                        <span class="n">env_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">env_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span>
                <span class="n">env_output</span><span class="p">,</span> <span class="n">env_next_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step_and_maybe_reset</span><span class="p">(</span><span class="n">env_input</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">env_output</span><span class="p">:</span>
                    <span class="c1"># ad-hoc update shuttle</span>
                    <span class="n">next_data</span> <span class="o">=</span> <span class="n">env_output</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;next&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle_has_no_device</span><span class="p">:</span>
                        <span class="c1"># Make sure</span>
                        <span class="n">next_data</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="n">next_data</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Collector: Rollout step completed </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_iter</span><span class="si">=}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore_rb</span>
                    <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">extend_buffer</span>
                <span class="p">):</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Collector: Adding </span><span class="si">{</span><span class="n">env_output</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="si">}</span><span class="s2"> frames to replay buffer using add().&quot;</span>
                        <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_increment_frames</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">numel</span><span class="p">()):</span>
                        <span class="k">return</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                            <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Collector: Moving to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="si">}</span><span class="s2"> and adding to queue.&quot;</span>
                            <span class="p">)</span>
                        <span class="n">non_blocking</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span>
                        <span class="p">)</span>
                        <span class="n">tensordicts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="n">non_blocking</span>
                            <span class="p">)</span>
                        <span class="p">)</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_sync_storage</span><span class="p">()</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                            <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                                <span class="s2">&quot;Collector: Adding to queue (no device).&quot;</span>
                            <span class="p">)</span>
                        <span class="n">tensordicts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="p">)</span>

                <span class="c1"># carry over collector data without messing up devices</span>
                <span class="n">collector_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;collector&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span> <span class="o">=</span> <span class="n">env_next_output</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle_has_no_device</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">clear_device_</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="n">collector_data</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_update_traj_ids</span><span class="p">(</span><span class="n">env_output</span><span class="p">)</span>

                <span class="k">if</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span><span class="o">.</span><span class="n">collection_stopped</span><span class="p">()</span>
                <span class="p">):</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Collector: Interruptor stopped.&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore_rb</span>
                        <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">extend_buffer</span>
                    <span class="p">):</span>
                        <span class="k">return</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span><span class="p">:</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                                <span class="n">tensordicts</span><span class="p">,</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                                <span class="n">out</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
                            <span class="p">)</span>
                        <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
                            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">unlock_</span><span class="p">():</span>
                                <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                                    <span class="n">tensordicts</span><span class="p">,</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                                    <span class="n">out</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
                                <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">result</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="o">.</span><span class="n">maybe_dense_stack</span><span class="p">(</span><span class="n">tensordicts</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span><span class="p">:</span>
                    <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Returning final rollout within buffer.&quot;</span><span class="p">)</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                            <span class="n">tensordicts</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                            <span class="n">out</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="p">,</span>
                        <span class="p">)</span>

                    <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
                        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">unlock_</span><span class="p">():</span>
                            <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                                <span class="n">tensordicts</span><span class="p">,</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                                <span class="n">out</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span><span class="p">,</span>
                            <span class="p">)</span>
                <span class="k">elif</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore_rb</span>
                    <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">extend_buffer</span>
                <span class="p">):</span>
                    <span class="k">return</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="s2">&quot;Returning final rollout with NO buffer (maybe_dense_stack).&quot;</span>
                    <span class="p">)</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="o">.</span><span class="n">maybe_dense_stack</span><span class="p">(</span><span class="n">tensordicts</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">result</span><span class="o">.</span><span class="n">refine_names</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="s2">&quot;time&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_set_truncated</span><span class="p">(</span><span class="n">result</span><span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">_maybe_set_truncated</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">final_rollout</span><span class="p">):</span>
        <span class="n">last_step</span> <span class="o">=</span> <span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">),)</span> <span class="o">*</span> <span class="p">(</span><span class="n">final_rollout</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span>
        <span class="k">for</span> <span class="n">truncated_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_truncated_keys</span><span class="p">:</span>
            <span class="n">truncated</span> <span class="o">=</span> <span class="n">final_rollout</span><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="n">truncated_key</span><span class="p">]</span>
            <span class="n">truncated</span><span class="p">[</span><span class="n">last_step</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">final_rollout</span><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="n">truncated_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">truncated</span>
            <span class="n">done</span> <span class="o">=</span> <span class="n">final_rollout</span><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="n">_replace_last</span><span class="p">(</span><span class="n">truncated_key</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">)]</span>
            <span class="n">final_rollout</span><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="n">_replace_last</span><span class="p">(</span><span class="n">truncated_key</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">done</span> <span class="o">|</span> <span class="n">truncated</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">final_rollout</span>

<div class="viewcode-block" id="SyncDataCollector.reset"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.reset">[docs]</a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Resets the environments to a new initial state.&quot;&quot;&quot;</span>
        <span class="c1"># metadata</span>
        <span class="n">collector_metadata</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;collector&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># check that the env supports partial reset</span>
            <span class="k">if</span> <span class="n">prod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;resetting unique env with index is not permitted.&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">reset_key</span><span class="p">,</span> <span class="n">done_keys</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">done_keys_groups</span>
            <span class="p">):</span>
                <span class="n">_reset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">full_done_spec</span><span class="p">[</span><span class="n">done_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">_reset</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">reset_key</span><span class="p">,</span> <span class="n">_reset</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_reset</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">collector_metadata</span><span class="p">[</span><span class="s2">&quot;traj_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">collector_metadata</span><span class="p">[</span><span class="s2">&quot;traj_ids&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">collector_metadata</span><span class="p">[</span><span class="s2">&quot;traj_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span><span class="p">[</span><span class="s2">&quot;collector&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">collector_metadata</span></div>

<div class="viewcode-block" id="SyncDataCollector.shutdown"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.shutdown">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">shutdown</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timeout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">close_env</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Shuts down all workers and/or closes the local environment.</span>

<span class="sd">        Args:</span>
<span class="sd">            timeout (float, optional): The timeout for closing pipes between workers.</span>
<span class="sd">                No effect for this class.</span>
<span class="sd">            close_env (bool, optional): Whether to close the environment. Defaults to `True`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shuttle</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span><span class="p">:</span>
                <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_rollout</span>
            <span class="k">if</span> <span class="n">close_env</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">is_closed</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span>
        <span class="k">return</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="c1"># an AttributeError will typically be raised if the collector is deleted when the program ends.</span>
            <span class="c1"># In the future, insignificant changes to the close method may change the error type.</span>
            <span class="c1"># We excplicitely assume that any error raised during closure in</span>
            <span class="c1"># __del__ will not affect the program.</span>
            <span class="k">pass</span>

<div class="viewcode-block" id="SyncDataCollector.state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the local state_dict of the data collector (environment and policy).</span>

<span class="sd">        Returns:</span>
<span class="sd">            an ordered dictionary with fields :obj:`&quot;policy_state_dict&quot;` and</span>
<span class="sd">            `&quot;env_state_dict&quot;`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs.batched_envs</span><span class="w"> </span><span class="kn">import</span> <span class="n">BatchedEnvBase</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">,</span> <span class="n">TransformedEnv</span><span class="p">):</span>
            <span class="n">env_state_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">,</span> <span class="n">BatchedEnvBase</span><span class="p">):</span>
            <span class="n">env_state_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">env_state_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_policy_w_state_dict&quot;</span><span class="p">):</span>
            <span class="n">policy_state_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_policy_w_state_dict</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span>
                <span class="n">policy_state_dict</span><span class="o">=</span><span class="n">policy_state_dict</span><span class="p">,</span>
                <span class="n">env_state_dict</span><span class="o">=</span><span class="n">env_state_dict</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">env_state_dict</span><span class="o">=</span><span class="n">env_state_dict</span><span class="p">)</span>

        <span class="n">state_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;frames&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span><span class="p">,</span> <span class="s2">&quot;iter&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span><span class="p">})</span>

        <span class="k">return</span> <span class="n">state_dict</span></div>

<div class="viewcode-block" id="SyncDataCollector.load_state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.load_state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Loads a state_dict on the environment and policy.</span>

<span class="sd">        Args:</span>
<span class="sd">            state_dict (OrderedDict): ordered dictionary containing the fields</span>
<span class="sd">                `&quot;policy_state_dict&quot;` and :obj:`&quot;env_state_dict&quot;`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">strict</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;strict&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">strict</span> <span class="ow">or</span> <span class="s2">&quot;env_state_dict&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;env_state_dict&quot;</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">strict</span> <span class="ow">or</span> <span class="s2">&quot;policy_state_dict&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_policy_w_state_dict&quot;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Underlying policy does not have state_dict to load policy_state_dict into.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_policy_w_state_dict</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
                <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;policy_state_dict&quot;</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;iter&quot;</span><span class="p">]</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">env_str</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;env=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="n">policy_str</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;policy=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="n">td_out_str</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;td_out=</span><span class="si">{</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_final_rollout&#39;</span><span class="p">,</span><span class="w"> </span><span class="kc">None</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span>
            <span class="p">)</span>
            <span class="n">string</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">env_str</span><span class="si">}</span><span class="s2">,&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">policy_str</span><span class="si">}</span><span class="s2">,&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">td_out_str</span><span class="si">}</span><span class="s2">,&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">exploration=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">exploration_type</span><span class="si">}</span><span class="s2">)&quot;</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">string</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(not_init)&quot;</span>

<div class="viewcode-block" id="SyncDataCollector.increment_version"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.increment_version">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">increment_version</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Increment the policy version.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span><span class="p">,</span> <span class="s2">&quot;increment_version&quot;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Policy version tracker is not a PolicyVersion instance. Please pass a PolicyVersion instance to the collector.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span><span class="o">.</span><span class="n">increment_version</span><span class="p">()</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">policy_version</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The current policy version.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span><span class="p">,</span> <span class="s2">&quot;version&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span><span class="o">.</span><span class="n">version</span>

<div class="viewcode-block" id="SyncDataCollector.get_policy_version"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.get_policy_version">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_policy_version</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the current policy version.</span>

<span class="sd">        This method exists to support remote calls in Ray actors, since properties</span>
<span class="sd">        cannot be accessed directly through Ray&#39;s RPC mechanism.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The current version number (int) or UUID (str), or None if version tracking is disabled.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_version</span></div>

<div class="viewcode-block" id="SyncDataCollector.getattr_policy"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.getattr_policy">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">getattr_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get an attribute from the policy.&quot;&quot;&quot;</span>
        <span class="c1"># send command to policy to return the attr</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_wrapped_policy</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span></div>

<div class="viewcode-block" id="SyncDataCollector.getattr_env"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.getattr_env">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">getattr_env</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get an attribute from the environment.&quot;&quot;&quot;</span>
        <span class="c1"># send command to env to return the attr</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span></div>

<div class="viewcode-block" id="SyncDataCollector.getattr_rb"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.SyncDataCollector.html#torchrl.collectors.SyncDataCollector.getattr_rb">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">getattr_rb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get an attribute from the replay buffer.&quot;&quot;&quot;</span>
        <span class="c1"># send command to rb to return the attr</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span></div></div>


<span class="k">class</span><span class="w"> </span><span class="nc">_MultiDataCollector</span><span class="p">(</span><span class="n">DataCollectorBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Runs a given number of DataCollectors on separate processes.</span>

<span class="sd">    Args:</span>
<span class="sd">        create_env_fn (List[Callabled]): list of Callables, each returning an</span>
<span class="sd">            instance of :class:`~torchrl.envs.EnvBase`.</span>
<span class="sd">        policy (Callable): Policy to be executed in the environment.</span>
<span class="sd">            Must accept :class:`tensordict.tensordict.TensorDictBase` object as input.</span>
<span class="sd">            If ``None`` is provided (default), the policy used will be a</span>
<span class="sd">            :class:`~torchrl.collectors.RandomPolicy` instance with the environment</span>
<span class="sd">            ``action_spec``.</span>
<span class="sd">            Accepted policies are usually subclasses of :class:`~tensordict.nn.TensorDictModuleBase`.</span>
<span class="sd">            This is the recommended usage of the collector.</span>
<span class="sd">            Other callables are accepted too:</span>
<span class="sd">            If the policy is not a ``TensorDictModuleBase`` (e.g., a regular :class:`~torch.nn.Module`</span>
<span class="sd">            instances) it will be wrapped in a `nn.Module` first.</span>
<span class="sd">            Then, the collector will try to assess if these</span>
<span class="sd">            modules require wrapping in a :class:`~tensordict.nn.TensorDictModule` or not.</span>

<span class="sd">            - If the policy forward signature matches any of ``forward(self, tensordict)``,</span>
<span class="sd">              ``forward(self, td)`` or ``forward(self, &lt;anything&gt;: TensorDictBase)`` (or</span>
<span class="sd">              any typing with a single argument typed as a subclass of ``TensorDictBase``)</span>
<span class="sd">              then the policy won&#39;t be wrapped in a :class:`~tensordict.nn.TensorDictModule`.</span>

<span class="sd">            - In all other cases an attempt to wrap it will be undergone as such:</span>
<span class="sd">              ``TensorDictModule(policy, in_keys=env_obs_key, out_keys=env.action_keys)``.</span>

<span class="sd">            .. note:: If the policy needs to be passed as a policy factory (e.g., in case it mustn&#39;t be serialized /</span>
<span class="sd">                pickled directly), the ``policy_factory`` should be used instead.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        policy_factory (Callable[[], Callable], list of Callable[[], Callable], optional): a callable</span>
<span class="sd">            (or list of callables) that returns a policy instance. This is exclusive with the `policy` argument.</span>

<span class="sd">            .. note:: `policy_factory` comes in handy whenever the policy cannot be serialized.</span>

<span class="sd">            .. warning:: `policy_factory` is currently not compatible with multiprocessed data</span>
<span class="sd">                collectors.</span>

<span class="sd">        num_workers (int, optional): number of workers to use. If `create_env_fn` is a list, this will be ignored.</span>
<span class="sd">            Defaults to `None` (workers determined by the `create_env_fn` length).</span>
<span class="sd">        frames_per_batch (int, Sequence[int]): A keyword-only argument representing the</span>
<span class="sd">            total number of elements in a batch. If a sequence is provided, represents the number of elements in a</span>
<span class="sd">            batch per worker. Total number of elements in a batch is then the sum over the sequence.</span>
<span class="sd">        total_frames (int, optional): A keyword-only argument representing the</span>
<span class="sd">            total number of frames returned by the collector</span>
<span class="sd">            during its lifespan. If the ``total_frames`` is not divisible by</span>
<span class="sd">            ``frames_per_batch``, an exception is raised.</span>
<span class="sd">             Endless collectors can be created by passing ``total_frames=-1``.</span>
<span class="sd">             Defaults to ``-1`` (never ending collector).</span>
<span class="sd">        device (int, str or torch.device, optional): The generic device of the</span>
<span class="sd">            collector. The ``device`` args fills any non-specified device: if</span>
<span class="sd">            ``device`` is not ``None`` and any of ``storing_device``, ``policy_device`` or</span>
<span class="sd">            ``env_device`` is not specified, its value will be set to ``device``.</span>
<span class="sd">            Defaults to ``None`` (No default device).</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        storing_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the output :class:`~tensordict.TensorDict` will be stored.</span>
<span class="sd">            If ``device`` is passed and ``storing_device`` is ``None``, it will</span>
<span class="sd">            default to the value indicated by ``device``.</span>
<span class="sd">            For long trajectories, it may be necessary to store the data on a different</span>
<span class="sd">            device than the one where the policy and env are executed.</span>
<span class="sd">            Defaults to ``None`` (the output tensordict isn&#39;t on a specific device,</span>
<span class="sd">            leaf tensors sit on the device where they were created).</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        env_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the environment should be cast (or executed if that functionality is</span>
<span class="sd">            supported). If not specified and the env has a non-``None`` device,</span>
<span class="sd">            ``env_device`` will default to that value. If ``device`` is passed</span>
<span class="sd">            and ``env_device=None``, it will default to ``device``. If the value</span>
<span class="sd">            as such specified of ``env_device`` differs from ``policy_device``</span>
<span class="sd">            and one of them is not ``None``, the data will be cast to ``env_device``</span>
<span class="sd">            before being passed to the env (i.e., passing different devices to</span>
<span class="sd">            policy and env is supported). Defaults to ``None``.</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        policy_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the policy should be cast.</span>
<span class="sd">            If ``device`` is passed and ``policy_device=None``, it will default</span>
<span class="sd">            to ``device``. If the value as such specified of ``policy_device``</span>
<span class="sd">            differs from ``env_device`` and one of them is not ``None``,</span>
<span class="sd">            the data will be cast to ``policy_device`` before being passed to</span>
<span class="sd">            the policy (i.e., passing different devices to policy and env is</span>
<span class="sd">            supported). Defaults to ``None``.</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        create_env_kwargs (dict, optional): A dictionary with the</span>
<span class="sd">            keyword arguments used to create an environment. If a list is</span>
<span class="sd">            provided, each of its elements will be assigned to a sub-collector.</span>
<span class="sd">        collector_class (Python class or constructor): a collector class to be remotely instantiated. Can be</span>
<span class="sd">            :class:`~torchrl.collectors.SyncDataCollector`,</span>
<span class="sd">            :class:`~torchrl.collectors.MultiSyncDataCollector`,</span>
<span class="sd">            :class:`~torchrl.collectors.MultiaSyncDataCollector`</span>
<span class="sd">            or a derived class of these.</span>
<span class="sd">            Defaults to :class:`~torchrl.collectors.SyncDataCollector`.</span>
<span class="sd">        max_frames_per_traj (int, optional): Maximum steps per trajectory.</span>
<span class="sd">            Note that a trajectory can span across multiple batches (unless</span>
<span class="sd">            ``reset_at_each_iter`` is set to ``True``, see below).</span>
<span class="sd">            Once a trajectory reaches ``n_steps``, the environment is reset.</span>
<span class="sd">            If the environment wraps multiple environments together, the number</span>
<span class="sd">            of steps is tracked for each environment independently. Negative</span>
<span class="sd">            values are allowed, in which case this argument is ignored.</span>
<span class="sd">            Defaults to ``None`` (i.e. no maximum number of steps).</span>
<span class="sd">        init_random_frames (int, optional): Number of frames for which the</span>
<span class="sd">            policy is ignored before it is called. This feature is mainly</span>
<span class="sd">            intended to be used in offline/model-based settings, where a</span>
<span class="sd">            batch of random trajectories can be used to initialize training.</span>
<span class="sd">            If provided, it will be rounded up to the closest multiple of frames_per_batch.</span>
<span class="sd">            Defaults to ``None`` (i.e. no random frames).</span>
<span class="sd">        reset_at_each_iter (bool, optional): Whether environments should be reset</span>
<span class="sd">            at the beginning of a batch collection.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        postproc (Callable, optional): A post-processing transform, such as</span>
<span class="sd">            a :class:`~torchrl.envs.Transform` or a :class:`~torchrl.data.postprocs.MultiStep`</span>
<span class="sd">            instance.</span>
<span class="sd">            Defaults to ``None``.</span>
<span class="sd">        split_trajs (bool, optional): Boolean indicating whether the resulting</span>
<span class="sd">            TensorDict should be split according to the trajectories.</span>
<span class="sd">            See :func:`~torchrl.collectors.utils.split_trajectories` for more</span>
<span class="sd">            information.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        exploration_type (ExplorationType, optional): interaction mode to be used when</span>
<span class="sd">            collecting data. Must be one of ``torchrl.envs.utils.ExplorationType.DETERMINISTIC``,</span>
<span class="sd">            ``torchrl.envs.utils.ExplorationType.RANDOM``, ``torchrl.envs.utils.ExplorationType.MODE``</span>
<span class="sd">            or ``torchrl.envs.utils.ExplorationType.MEAN``.</span>
<span class="sd">        reset_when_done (bool, optional): if ``True`` (default), an environment</span>
<span class="sd">            that return a ``True`` value in its ``&quot;done&quot;`` or ``&quot;truncated&quot;``</span>
<span class="sd">            entry will be reset at the corresponding indices.</span>
<span class="sd">        update_at_each_batch (boolm optional): if ``True``, :meth:`update_policy_weights_()`</span>
<span class="sd">            will be called before (sync) or after (async) each data collection.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        preemptive_threshold (:obj:`float`, optional): a value between 0.0 and 1.0 that specifies the ratio of workers</span>
<span class="sd">            that will be allowed to finished collecting their rollout before the rest are forced to end early.</span>
<span class="sd">        num_threads (int, optional): number of threads for this process.</span>
<span class="sd">            Defaults to the number of workers.</span>
<span class="sd">        num_sub_threads (int, optional): number of threads of the subprocesses.</span>
<span class="sd">            Should be equal to one plus the number of processes launched within</span>
<span class="sd">            each subprocess (or one if a single process is launched).</span>
<span class="sd">            Defaults to 1 for safety: if none is indicated, launching multiple</span>
<span class="sd">            workers may charge the cpu load too much and harm performance.</span>
<span class="sd">        cat_results (str, int or None): (:class:`~torchrl.collectors.MultiSyncDataCollector` exclusively).</span>
<span class="sd">            If ``&quot;stack&quot;``, the data collected from the workers will be stacked along the</span>
<span class="sd">            first dimension. This is the preferred behavior as it is the most compatible</span>
<span class="sd">            with the rest of the library.</span>
<span class="sd">            If ``0``, results will be concatenated along the first dimension</span>
<span class="sd">            of the outputs, which can be the batched dimension if the environments are</span>
<span class="sd">            batched or the time dimension if not.</span>
<span class="sd">            A ``cat_results`` value of ``-1`` will always concatenate results along the</span>
<span class="sd">            time dimension. This should be preferred over the default. Intermediate values</span>
<span class="sd">            are also accepted.</span>
<span class="sd">            Defaults to ``&quot;stack&quot;``.</span>

<span class="sd">            .. note:: From v0.5, this argument will default to ``&quot;stack&quot;`` for a better</span>
<span class="sd">                interoperability with the rest of the library.</span>

<span class="sd">        set_truncated (bool, optional): if ``True``, the truncated signals (and corresponding</span>
<span class="sd">            ``&quot;done&quot;`` but not ``&quot;terminated&quot;``) will be set to ``True`` when the last frame of</span>
<span class="sd">            a rollout is reached. If no ``&quot;truncated&quot;`` key is found, an exception is raised.</span>
<span class="sd">            Truncated keys can be set through ``env.add_truncated_keys``.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        use_buffers (bool, optional): if ``True``, a buffer will be used to stack the data.</span>
<span class="sd">            This isn&#39;t compatible with environments with dynamic specs. Defaults to ``True``</span>
<span class="sd">            for envs without dynamic specs, ``False`` for others.</span>
<span class="sd">        replay_buffer (ReplayBuffer, optional): if provided, the collector will not yield tensordicts</span>
<span class="sd">            but populate the buffer instead. Defaults to ``None``.</span>
<span class="sd">        extend_buffer (bool, optional): if `True`, the replay buffer is extended with entire rollouts and not</span>
<span class="sd">            with single steps. Defaults to `True` for multiprocessed data collectors.</span>
<span class="sd">        local_init_rb (bool, optional): if ``False``, the collector will use fake data to initialize</span>
<span class="sd">            the replay buffer in the main process (legacy behavior). If ``True``, the storage-level</span>
<span class="sd">            coordination will handle initialization with real data from worker processes.</span>
<span class="sd">            Defaults to ``None``, which maintains backward compatibility but shows a deprecation warning.</span>
<span class="sd">            This parameter is deprecated and will be removed in v0.12.</span>
<span class="sd">        trust_policy (bool, optional): if ``True``, a non-TensorDictModule policy will be trusted to be</span>
<span class="sd">            assumed to be compatible with the collector. This defaults to ``True`` for CudaGraphModules</span>
<span class="sd">            and ``False`` otherwise.</span>
<span class="sd">        compile_policy (bool or Dict[str, Any], optional): if ``True``, the policy will be compiled</span>
<span class="sd">            using :func:`~torch.compile` default behaviour. If a dictionary of kwargs is passed, it</span>
<span class="sd">            will be used to compile the policy.</span>
<span class="sd">        cudagraph_policy (bool or Dict[str, Any], optional): if ``True``, the policy will be wrapped</span>
<span class="sd">            in :class:`~tensordict.nn.CudaGraphModule` with default kwargs.</span>
<span class="sd">            If a dictionary of kwargs is passed, it will be used to wrap the policy.</span>
<span class="sd">        no_cuda_sync (bool): if ``True``, explicit CUDA synchronizations calls will be bypassed.</span>
<span class="sd">            For environments running directly on CUDA (`IsaacLab &lt;https://github.com/isaac-sim/IsaacLab/&gt;`_</span>
<span class="sd">            or `ManiSkills &lt;https://github.com/haosulab/ManiSkill/&gt;`_) cuda synchronization may cause unexpected</span>
<span class="sd">            crashes.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        weight_updater (WeightUpdaterBase or constructor, optional): An instance of :class:`~torchrl.collectors.WeightUpdaterBase`</span>
<span class="sd">            or its subclass, responsible for updating the policy weights on remote inference workers.</span>
<span class="sd">            If not provided, a :class:`~torchrl.collectors.MultiProcessedWeightUpdater` will be used by default,</span>
<span class="sd">            which handles weight synchronization across multiple processes.</span>
<span class="sd">            Consider using a constructor if the updater needs to be serialized.</span>
<span class="sd">        weight_sync_schemes (dict[str, WeightSyncScheme], optional): A dictionary of weight sync schemes for the different models.</span>
<span class="sd">            If not provided, a :class:`~torchrl.collectors.MultiProcessWeightSyncScheme` will be used by default.</span>
<span class="sd">        track_policy_version (bool or PolicyVersion, optional): if ``True``, the collector will track the version of the policy.</span>
<span class="sd">            This will be mediated by the :class:`~torchrl.envs.llm.transforms.policy_version.PolicyVersion` transform, which will be added to the environment.</span>
<span class="sd">            Alternatively, a :class:`~torchrl.envs.llm.transforms.policy_version.PolicyVersion` instance can be passed, which will be used to track</span>
<span class="sd">            the policy version.</span>
<span class="sd">            Defaults to `False`.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">create_env_fn</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="n">EnvBase</span><span class="p">]],</span>
        <span class="n">policy</span><span class="p">:</span> <span class="kc">None</span>
        <span class="o">|</span> <span class="p">(</span><span class="n">TensorDictModule</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">])</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">policy_factory</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Callable</span><span class="p">]</span>
        <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="n">Callable</span><span class="p">]]</span>
        <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">frames_per_batch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">total_frames</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">storing_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">env_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">policy_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">create_env_kwargs</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">collector_class</span><span class="p">:</span> <span class="nb">type</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">DataCollectorBase</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_frames_per_traj</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">init_random_frames</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">reset_at_each_iter</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">postproc</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">split_trajs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">exploration_type</span><span class="p">:</span> <span class="n">ExplorationType</span> <span class="o">=</span> <span class="n">DEFAULT_EXPLORATION_TYPE</span><span class="p">,</span>
        <span class="n">reset_when_done</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">update_at_each_batch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">preemptive_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_threads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_sub_threads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">cat_results</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">set_truncated</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">use_buffers</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">replay_buffer</span><span class="p">:</span> <span class="n">ReplayBuffer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">extend_buffer</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">replay_buffer_chunk</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_init_rb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">trust_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">compile_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cudagraph_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">no_cuda_sync</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">weight_updater</span><span class="p">:</span> <span class="n">WeightUpdaterBase</span>
        <span class="o">|</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">WeightUpdaterBase</span><span class="p">]</span>
        <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">weight_sync_schemes</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">WeightSyncScheme</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">track_policy_version</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">create_env_fn</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">create_env_fn</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">=</span> <span class="n">num_workers</span>
            <span class="n">create_env_fn</span> <span class="o">=</span> <span class="p">[</span><span class="n">create_env_fn</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">frames_per_batch</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">)</span>
            <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">frames_per_batch</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;If `frames_per_batch` is provided as a sequence, it should contain exactly one value per worker.&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">frames_per_batch</span><span class="p">)</span><span class="si">}</span><span class="s2"> values for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="si">}</span><span class="s2"> workers.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_frames_per_batch</span> <span class="o">=</span> <span class="n">frames_per_batch</span>
        <span class="n">total_frames_per_batch</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">sum</span><span class="p">(</span><span class="n">frames_per_batch</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">frames_per_batch</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">frames_per_batch</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_truncated</span> <span class="o">=</span> <span class="n">set_truncated</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_sub_threads</span> <span class="o">=</span> <span class="n">num_sub_threads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_threads</span> <span class="o">=</span> <span class="n">num_threads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span> <span class="o">=</span> <span class="n">create_env_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_read_compile_kwargs</span><span class="p">(</span><span class="n">compile_policy</span><span class="p">,</span> <span class="n">cudagraph_policy</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">create_env_kwargs</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
            <span class="n">create_env_kwargs</span> <span class="o">=</span> <span class="p">[</span><span class="n">create_env_kwargs</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">elif</span> <span class="n">create_env_kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">create_env_kwargs</span> <span class="o">=</span> <span class="p">[{}]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">create_env_kwargs</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="n">create_env_kwargs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">create_env_kwargs</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">create_env_kwargs</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;len(create_env_kwargs) must be equal to num_workers, got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">create_env_kwargs</span><span class="p">)</span><span class="si">=}</span><span class="s2"> and </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="si">=}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">create_env_kwargs</span> <span class="o">=</span> <span class="n">create_env_kwargs</span>
        <span class="c1"># Preparing devices:</span>
        <span class="c1"># We want the user to be able to choose, for each worker, on which</span>
        <span class="c1"># device will the policy live and which device will be used to store</span>
        <span class="c1"># data. Those devices may or may not match.</span>
        <span class="c1"># One caveat is that, if there is only one device for the policy, and</span>
        <span class="c1"># if there are multiple workers, sending the same device and policy</span>
        <span class="c1"># to be copied to each worker will result in multiple copies of the</span>
        <span class="c1"># same policy on the same device.</span>
        <span class="c1"># To go around this, we do the copies of the policy in the server</span>
        <span class="c1"># (this object) to each possible device, and send to all the</span>
        <span class="c1"># processes their copy of the policy.</span>

        <span class="n">storing_devices</span><span class="p">,</span> <span class="n">policy_devices</span><span class="p">,</span> <span class="n">env_devices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_devices</span><span class="p">(</span>
            <span class="n">storing_device</span><span class="o">=</span><span class="n">storing_device</span><span class="p">,</span>
            <span class="n">env_device</span><span class="o">=</span><span class="n">env_device</span><span class="p">,</span>
            <span class="n">policy_device</span><span class="o">=</span><span class="n">policy_device</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># to avoid confusion</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span> <span class="o">=</span> <span class="n">storing_devices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span> <span class="o">=</span> <span class="n">policy_devices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span> <span class="o">=</span> <span class="n">env_devices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">collector_class</span> <span class="o">=</span> <span class="n">collector_class</span>

        <span class="k">del</span> <span class="n">storing_device</span><span class="p">,</span> <span class="n">env_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span> <span class="o">=</span> <span class="n">no_cuda_sync</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span> <span class="o">=</span> <span class="n">use_buffers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">replay_buffer</span>

        <span class="c1"># Handle local_init_rb deprecation</span>
        <span class="k">if</span> <span class="n">local_init_rb</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># v0.11: Default to False (current behavior), show deprecation warning</span>
            <span class="c1"># v0.12: Default to True (new behavior)</span>
            <span class="n">local_init_rb</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Will become True in 0.12</span>
            <span class="k">if</span> <span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">local_init_rb</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;local_init_rb=False is deprecated and will be removed in v0.12. &quot;</span>
                    <span class="s2">&quot;The new storage-level initialization provides better performance.&quot;</span><span class="p">,</span>
                    <span class="ne">FutureWarning</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">local_init_rb</span> <span class="o">=</span> <span class="n">local_init_rb</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_check_replay_buffer_init</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">replay_buffer_chunk</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">extend_buffer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">replay_buffer_chunk</span> <span class="o">=</span> <span class="n">extend_buffer</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;The replay_buffer_chunk is deprecated and replaced by extend_buffer. This argument will disappear in v0.10.&quot;</span><span class="p">,</span>
                    <span class="ne">DeprecationWarning</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">extend_buffer</span> <span class="o">!=</span> <span class="n">replay_buffer_chunk</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;conflicting values for replay_buffer_chunk and extend_buffer.&quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">extend_buffer</span> <span class="o">=</span> <span class="n">extend_buffer</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">replay_buffer</span><span class="p">,</span> <span class="s2">&quot;shared&quot;</span><span class="p">)</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="n">replay_buffer</span><span class="o">.</span><span class="n">shared</span>
        <span class="p">):</span>
            <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Replay buffer is not shared. Sharing it.&quot;</span><span class="p">)</span>
            <span class="n">replay_buffer</span><span class="o">.</span><span class="n">share</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_policy_weights_dict</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="n">trust_policy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">trust_policy</span> <span class="o">=</span> <span class="n">policy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">CudaGraphModule</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trust_policy</span> <span class="o">=</span> <span class="n">trust_policy</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy_factory</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="n">policy_factory</span> <span class="o">=</span> <span class="p">[</span><span class="n">policy_factory</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">policy_factory</span><span class="p">)</span> <span class="ow">and</span> <span class="n">policy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;policy_factory and policy are mutually exclusive&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">policy_factory</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_maker</span><span class="p">,</span> <span class="n">env_maker_kwargs</span> <span class="ow">in</span> <span class="n">_zip_strict</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_kwargs</span>
            <span class="p">):</span>
                <span class="p">(</span><span class="n">policy_new_device</span><span class="p">,</span> <span class="n">get_weights_fn</span><span class="p">,)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_policy_and_device</span><span class="p">(</span>
                    <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">,</span>
                    <span class="n">policy_device</span><span class="o">=</span><span class="n">policy_device</span><span class="p">,</span>
                    <span class="n">env_maker</span><span class="o">=</span><span class="n">env_maker</span><span class="p">,</span>
                    <span class="n">env_maker_kwargs</span><span class="o">=</span><span class="n">env_maker_kwargs</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">policy_new_device</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">policy</span><span class="p">):</span>
                    <span class="n">policy</span> <span class="o">=</span> <span class="n">policy_new_device</span>
                <span class="n">weights</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">TensorDict</span><span class="o">.</span><span class="n">from_module</span><span class="p">(</span><span class="n">policy_new_device</span><span class="p">)</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy_new_device</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
                    <span class="k">else</span> <span class="n">TensorDict</span><span class="p">()</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_policy_weights_dict</span><span class="p">[</span><span class="n">policy_device</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_get_weights_fn</span> <span class="o">=</span> <span class="n">get_weights_fn</span>
            <span class="k">if</span> <span class="n">weight_updater</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># For multiprocessed collectors, use MultiProcessWeightSyncScheme by default</span>
                <span class="k">if</span> <span class="n">weight_sync_schemes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">weight_sync_schemes</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;policy&quot;</span><span class="p">:</span> <span class="n">MultiProcessWeightSyncScheme</span><span class="p">()}</span>
                <span class="c1"># Don&#39;t create legacy weight updater if we have schemes</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Legacy weight updater was explicitly provided</span>
                <span class="k">pass</span>
        <span class="k">elif</span> <span class="n">weight_updater</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;weight_updater is None, but policy_factory is provided. This means that the server will &quot;</span>
                <span class="s2">&quot;not know how to send the weights to the workers. If the workers can handle their weight synchronization &quot;</span>
                <span class="s2">&quot;on their own (via some specialized worker type / constructor) this may well work, but make sure &quot;</span>
                <span class="s2">&quot;your weight synchronization strategy is properly set. To suppress this warning, you can use &quot;</span>
                <span class="s2">&quot;RemoteModuleWeightUpdater() which enforces explicit weight passing when calling update_policy_weights_(weights). &quot;</span>
                <span class="s2">&quot;This will work whenever your inference and training policies are nn.Module instances with similar structures.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Set up weight synchronization - prefer new schemes over legacy updater</span>
        <span class="k">if</span> <span class="n">weight_sync_schemes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Use new simplified weight synchronization system</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span> <span class="o">=</span> <span class="n">weight_sync_schemes</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="c1"># Senders will be created in _run_processes when pipes are available</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_updater</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Don&#39;t use legacy system</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Fall back to legacy weight updater system</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_updater</span> <span class="o">=</span> <span class="n">weight_updater</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Policy version tracking setup</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span> <span class="o">=</span> <span class="n">track_policy_version</span>
        <span class="k">if</span> <span class="n">PolicyVersion</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">track_policy_version</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">and</span> <span class="n">track_policy_version</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span> <span class="o">=</span> <span class="n">PolicyVersion</span><span class="p">()</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="n">track_policy_version</span><span class="p">,</span> <span class="s2">&quot;increment_version&quot;</span>
            <span class="p">):</span>  <span class="c1"># Check if it&#39;s a PolicyVersion instance</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span> <span class="o">=</span> <span class="n">track_policy_version</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">track_policy_version</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                    <span class="s2">&quot;PolicyVersion is not available. Please install the LLM dependencies or set track_policy_version=False.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">policy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_factory</span> <span class="o">=</span> <span class="n">policy_factory</span>

        <span class="n">remainder</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">total_frames</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">total_frames</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">total_frames</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">remainder</span> <span class="o">=</span> <span class="n">total_frames</span> <span class="o">%</span> <span class="n">total_frames_per_batch</span>
            <span class="k">if</span> <span class="n">remainder</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">RL_WARNINGS</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;total_frames (</span><span class="si">{</span><span class="n">total_frames</span><span class="si">}</span><span class="s2">) is not exactly divisible by frames_per_batch (</span><span class="si">{</span><span class="n">total_frames_per_batch</span><span class="si">}</span><span class="s2">). &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;This means </span><span class="si">{</span><span class="n">total_frames_per_batch</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">remainder</span><span class="si">}</span><span class="s2"> additional frames will be collected. &quot;</span>
                    <span class="s2">&quot;To silence this message, set the environment variable RL_WARNINGS to False.&quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">total_frames</span><span class="p">)</span> <span class="k">if</span> <span class="n">total_frames</span> <span class="o">!=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">total_frames</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_at_each_iter</span> <span class="o">=</span> <span class="n">reset_at_each_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span> <span class="o">=</span> <span class="n">postproc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_frames_per_traj</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">max_frames_per_traj</span><span class="p">)</span> <span class="k">if</span> <span class="n">max_frames_per_traj</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">requested_frames_per_batch</span> <span class="o">=</span> <span class="n">total_frames_per_batch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_when_done</span> <span class="o">=</span> <span class="n">reset_when_done</span>
        <span class="k">if</span> <span class="n">split_trajs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">split_trajs</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_when_done</span> <span class="ow">and</span> <span class="n">split_trajs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot split trajectories when reset_when_done is False.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">split_trajs</span> <span class="o">=</span> <span class="n">split_trajs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">init_random_frames</span><span class="p">)</span> <span class="k">if</span> <span class="n">init_random_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_at_each_batch</span> <span class="o">=</span> <span class="n">update_at_each_batch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exploration_type</span> <span class="o">=</span> <span class="n">exploration_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_worker</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">if</span> <span class="n">preemptive_threshold</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">_is_osx</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot use preemption on OSX due to Queue.qsize() not being implemented on this platform.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">preemptive_threshold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">preemptive_threshold</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="n">manager</span> <span class="o">=</span> <span class="n">_InterruptorManager</span><span class="p">()</span>
            <span class="n">manager</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">_Interruptor</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">preemptive_threshold</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_run_processes</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_exclude_private_keys</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">cat_results</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cat_results</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">))</span>
            <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">cat_results</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">cat_results</span> <span class="o">!=</span> <span class="s2">&quot;stack&quot;</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;cat_results must be a string (&#39;stack&#39;) &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;or an integer representing the cat dimension. Got </span><span class="si">{</span><span class="n">cat_results</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">MultiSyncDataCollector</span><span class="p">)</span> <span class="ow">and</span> <span class="n">cat_results</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span>
            <span class="s2">&quot;stack&quot;</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;cat_results can only be used with ``MultiSyncDataCollector``.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cat_results</span> <span class="o">=</span> <span class="n">cat_results</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_check_replay_buffer_init</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="n">is_init</span> <span class="o">=</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">,</span> <span class="s2">&quot;_storage&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">getattr</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">_storage</span><span class="p">,</span> <span class="s2">&quot;initialized&quot;</span><span class="p">,</span> <span class="kc">True</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_init</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_init_rb</span><span class="p">:</span>
                <span class="c1"># New behavior: storage handles all coordination itself</span>
                <span class="c1"># Nothing to do here - the storage will coordinate during first write</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">share</span><span class="p">()</span>
                <span class="k">return</span>

            <span class="c1"># Legacy behavior: fake tensordict initialization</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">EnvCreator</span><span class="p">):</span>
                <span class="n">fake_td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">meta_data</span><span class="o">.</span><span class="n">tensordict</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">EnvBase</span><span class="p">):</span>
                <span class="n">fake_td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">fake_tensordict</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">fake_td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span>
                    <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_kwargs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="p">)</span><span class="o">.</span><span class="n">fake_tensordict</span><span class="p">()</span>
            <span class="n">fake_td</span><span class="p">[</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="n">fake_td</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span>
            <span class="p">)</span>
            <span class="c1"># Use extend to avoid time-related transforms to fail</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">fake_td</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_total_workers_from_env</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">env_creators</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_creators</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="bp">cls</span><span class="o">.</span><span class="n">_total_workers_from_env</span><span class="p">(</span><span class="n">env_creator</span><span class="p">)</span> <span class="k">for</span> <span class="n">env_creator</span> <span class="ow">in</span> <span class="n">env_creators</span>
            <span class="p">)</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchrl.envs</span><span class="w"> </span><span class="kn">import</span> <span class="n">ParallelEnv</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_creators</span><span class="p">,</span> <span class="n">ParallelEnv</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">env_creators</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">return</span> <span class="mi">1</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_devices</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">storing_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">policy_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">env_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># convert all devices to lists</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">storing_device</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">storing_device</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">storing_device</span><span class="p">,</span>
            <span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">policy_device</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">policy_device</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">policy_device</span><span class="p">,</span>
            <span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_device</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">env_device</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">env_device</span><span class="p">,</span>
            <span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">device</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">device</span><span class="p">,</span>
            <span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">storing_device</span><span class="p">)</span>
            <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">policy_device</span><span class="p">)</span>
            <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">env_device</span><span class="p">)</span>
            <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;THe length of the devices does not match the number of workers: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="n">storing_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_device</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span>
                <span class="n">SyncDataCollector</span><span class="o">.</span><span class="n">_get_devices</span><span class="p">(</span>
                    <span class="n">storing_device</span><span class="o">=</span><span class="n">storing_device</span><span class="p">,</span>
                    <span class="n">policy_device</span><span class="o">=</span><span class="n">policy_device</span><span class="p">,</span>
                    <span class="n">env_device</span><span class="o">=</span><span class="n">env_device</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="p">(</span><span class="n">storing_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_device</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                    <span class="n">storing_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_device</span><span class="p">,</span> <span class="n">device</span>
                <span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">storing_device</span><span class="p">,</span> <span class="n">policy_device</span><span class="p">,</span> <span class="n">env_device</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">frames_per_batch_worker</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">worker_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_queue_len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_run_processes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_threads</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">total_workers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_workers_from_env</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_threads</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
                <span class="mi">1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_num_threads</span><span class="p">()</span> <span class="o">-</span> <span class="n">total_workers</span>
            <span class="p">)</span>  <span class="c1"># 1 more thread for this proc</span>

        <span class="c1"># Initialize weight senders for multiprocess collectors</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span><span class="p">:</span>
            <span class="c1"># Create one sender per model using scheme&#39;s factory method</span>
            <span class="k">for</span> <span class="n">model_id</span><span class="p">,</span> <span class="n">scheme</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">sender</span> <span class="o">=</span> <span class="n">scheme</span><span class="o">.</span><span class="n">create_sender</span><span class="p">()</span>
                <span class="n">sender</span><span class="o">.</span><span class="n">_model_id</span> <span class="o">=</span> <span class="n">model_id</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">sender</span><span class="p">,</span> <span class="s2">&quot;set_context&quot;</span><span class="p">):</span>
                    <span class="n">sender</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span><span class="p">[</span><span class="n">model_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">sender</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_threads</span><span class="p">)</span>
        <span class="n">queue_out</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Queue</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_queue_len</span><span class="p">)</span>  <span class="c1"># sends data from proc to main</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">procs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_traj_pool</span> <span class="o">=</span> <span class="n">_TrajectoryPool</span><span class="p">(</span><span class="n">lock</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Create a policy on the right device</span>
        <span class="n">policy_factory</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_factory</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">policy_factory</span><span class="p">):</span>
            <span class="n">policy_factory</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">CloudpickleWrapper</span><span class="p">(</span><span class="n">_policy_factory</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">_policy_factory</span> <span class="ow">in</span> <span class="n">policy_factory</span>
            <span class="p">]</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">env_fun</span><span class="p">,</span> <span class="n">env_fun_kwargs</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
            <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_env_kwargs</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">pipe_parent</span><span class="p">,</span> <span class="n">pipe_child</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Pipe</span><span class="p">()</span>  <span class="c1"># send messages to procs</span>
            <span class="k">if</span> <span class="n">env_fun</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">!=</span> <span class="s2">&quot;EnvCreator&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">env_fun</span><span class="p">,</span> <span class="n">EnvBase</span>
            <span class="p">):</span>  <span class="c1"># to avoid circular imports</span>
                <span class="n">env_fun</span> <span class="o">=</span> <span class="n">CloudpickleWrapper</span><span class="p">(</span><span class="n">env_fun</span><span class="p">)</span>

            <span class="n">policy_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_device</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">storing_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">env_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_device</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="c1"># We take the weights, the policy, and locally dispatch the weights to the policy</span>
            <span class="c1">#  while we send the policy to the remote process.</span>
            <span class="c1">#  This makes sure that a given set of shared weights for a given device are</span>
            <span class="c1">#  shared for all policies that rely on that device.</span>
            <span class="n">policy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span>
            <span class="n">policy_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_policy_weights_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">policy_device</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">policy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">policy_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">cm</span> <span class="o">=</span> <span class="n">policy_weights</span><span class="o">.</span><span class="n">to_module</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">cm</span> <span class="o">=</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">nullcontext</span><span class="p">()</span>
            <span class="k">with</span> <span class="n">cm</span><span class="p">:</span>
                <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;policy_factory&quot;</span><span class="p">:</span> <span class="n">policy_factory</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="s2">&quot;pipe_parent&quot;</span><span class="p">:</span> <span class="n">pipe_parent</span><span class="p">,</span>
                    <span class="s2">&quot;pipe_child&quot;</span><span class="p">:</span> <span class="n">pipe_child</span><span class="p">,</span>
                    <span class="s2">&quot;queue_out&quot;</span><span class="p">:</span> <span class="n">queue_out</span><span class="p">,</span>
                    <span class="s2">&quot;create_env_fn&quot;</span><span class="p">:</span> <span class="n">env_fun</span><span class="p">,</span>
                    <span class="s2">&quot;create_env_kwargs&quot;</span><span class="p">:</span> <span class="n">env_fun_kwargs</span><span class="p">,</span>
                    <span class="s2">&quot;policy&quot;</span><span class="p">:</span> <span class="n">policy</span><span class="p">,</span>
                    <span class="s2">&quot;max_frames_per_traj&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_frames_per_traj</span><span class="p">,</span>
                    <span class="s2">&quot;frames_per_batch&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_batch_worker</span><span class="p">(</span><span class="n">worker_idx</span><span class="o">=</span><span class="n">i</span><span class="p">),</span>
                    <span class="s2">&quot;reset_at_each_iter&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_at_each_iter</span><span class="p">,</span>
                    <span class="s2">&quot;policy_device&quot;</span><span class="p">:</span> <span class="n">policy_device</span><span class="p">,</span>
                    <span class="s2">&quot;storing_device&quot;</span><span class="p">:</span> <span class="n">storing_device</span><span class="p">,</span>
                    <span class="s2">&quot;env_device&quot;</span><span class="p">:</span> <span class="n">env_device</span><span class="p">,</span>
                    <span class="s2">&quot;exploration_type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">exploration_type</span><span class="p">,</span>
                    <span class="s2">&quot;reset_when_done&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_when_done</span><span class="p">,</span>
                    <span class="s2">&quot;idx&quot;</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span>
                    <span class="s2">&quot;interruptor&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span><span class="p">,</span>
                    <span class="s2">&quot;set_truncated&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">set_truncated</span><span class="p">,</span>
                    <span class="s2">&quot;use_buffers&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span><span class="p">,</span>
                    <span class="s2">&quot;replay_buffer&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">,</span>
                    <span class="s2">&quot;extend_buffer&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">extend_buffer</span><span class="p">,</span>
                    <span class="s2">&quot;traj_pool&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_traj_pool</span><span class="p">,</span>
                    <span class="s2">&quot;trust_policy&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">trust_policy</span><span class="p">,</span>
                    <span class="s2">&quot;compile_policy&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy_kwargs</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_policy</span>
                    <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
                    <span class="s2">&quot;cudagraph_policy&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cudagraphed_policy_kwargs</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cudagraphed_policy</span>
                    <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
                    <span class="s2">&quot;no_cuda_sync&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_cuda_sync</span><span class="p">,</span>
                    <span class="s2">&quot;collector_class&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">collector_class</span><span class="p">,</span>
                    <span class="s2">&quot;postproc&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="s2">&quot;weight_sync_schemes&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_sync_schemes</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="n">proc</span> <span class="o">=</span> <span class="n">_ProcessNoWarn</span><span class="p">(</span>
                    <span class="n">target</span><span class="o">=</span><span class="n">_main_async_collector</span><span class="p">,</span>
                    <span class="n">num_threads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_sub_threads</span><span class="p">,</span>
                    <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="c1"># proc.daemon can&#39;t be set as daemonic processes may be launched by the process itself</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">proc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
                <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                    <span class="k">if</span> <span class="s2">&quot;cannot pickle&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">err</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                            <span class="s2">&quot;A non-serializable object was passed to the collector workers.&quot;</span>
                        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">err</span>
                <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                    <span class="k">if</span> <span class="s2">&quot;Cowardly refusing to serialize non-leaf tensor&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">err</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                            <span class="s2">&quot;At least one of the tensors in the policy, replay buffer, environment constructor or postprocessor requires gradients. &quot;</span>
                            <span class="s2">&quot;This is not supported in multiprocessed data collectors.</span><span class="se">\n</span><span class="s2">- For ReplayBuffer transforms, use a `transform_factory` instead with `delayed_init=True`.</span><span class="se">\n</span><span class="s2">&quot;</span>
                            <span class="s2">&quot;- Make sure your environment constructor does not reference tensors already instantiated on the main process.</span><span class="se">\n</span><span class="s2">&quot;</span>
                            <span class="s2">&quot;- Since no gradient can be propagated through the Collector pipes, the backward graph is never needed. Consider using detached tensors instead.&quot;</span>
                        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">err</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="n">err</span>
                <span class="k">except</span> <span class="n">_pickle</span><span class="o">.</span><span class="n">PicklingError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                    <span class="k">if</span> <span class="s2">&quot;&lt;lambda&gt;&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">err</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
<span class="w">                            </span><span class="sd">&quot;&quot;&quot;Can&#39;t open a process with doubly cloud-pickled lambda function.</span>
<span class="sd">This error is likely due to an attempt to use a ParallelEnv in a</span>
<span class="sd">multiprocessed data collector. To do this, consider wrapping your</span>
<span class="sd">lambda function in an `torchrl.envs.EnvCreator` wrapper as follows:</span>
<span class="sd">`env = ParallelEnv(N, EnvCreator(my_lambda_function))`.</span>
<span class="sd">This will not only ensure that your lambda function is cloud-pickled once, but</span>
<span class="sd">also that the state dict is synchronised across processes if needed.&quot;&quot;&quot;</span>
                        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">err</span>
                <span class="n">pipe_child</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">proc</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pipe_parent</span><span class="p">)</span>

                <span class="c1"># Register worker with senders</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">sender</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_senders</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="n">sender</span><span class="o">.</span><span class="n">register_worker</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">pipe_parent</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">pipe_parent</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">):</span>
            <span class="n">pipe_parent</span><span class="o">.</span><span class="n">poll</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">INSTANTIATE_TIMEOUT</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="n">pipe_parent</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">EOFError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Worker </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> failed to initialize and closed the connection before sending status. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;This typically indicates that the worker process crashed during initialization. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Check the worker process logs for the actual error.&quot;</span>
                <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
            <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;instantiated&quot;</span><span class="p">:</span>
                <span class="c1"># Check if it&#39;s an error dict from worker</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="n">msg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;error&quot;</span><span class="p">):</span>
                    <span class="c1"># Reconstruct the exception from the worker</span>
                    <span class="n">exc_type_name</span> <span class="o">=</span> <span class="n">msg</span><span class="p">[</span><span class="s2">&quot;exception_type&quot;</span><span class="p">]</span>
                    <span class="n">exc_msg</span> <span class="o">=</span> <span class="n">msg</span><span class="p">[</span><span class="s2">&quot;exception_msg&quot;</span><span class="p">]</span>
                    <span class="n">traceback_str</span> <span class="o">=</span> <span class="n">msg</span><span class="p">[</span><span class="s2">&quot;traceback&quot;</span><span class="p">]</span>

                    <span class="c1"># Try to get the actual exception class</span>
                    <span class="n">exc_class</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">exc_module</span> <span class="o">=</span> <span class="n">msg</span><span class="p">[</span><span class="s2">&quot;exception_module&quot;</span><span class="p">]</span>

                    <span class="k">if</span> <span class="n">exc_module</span> <span class="o">==</span> <span class="s2">&quot;builtins&quot;</span><span class="p">:</span>
                        <span class="c1"># Get from builtins</span>
                        <span class="kn">import</span><span class="w"> </span><span class="nn">builtins</span>

                        <span class="n">exc_class</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builtins</span><span class="p">,</span> <span class="n">exc_type_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># Try to import from the module</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="kn">import</span><span class="w"> </span><span class="nn">importlib</span>

                            <span class="n">mod</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">import_module</span><span class="p">(</span><span class="n">exc_module</span><span class="p">)</span>
                            <span class="n">exc_class</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">exc_type_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                            <span class="k">pass</span>

                    <span class="c1"># Re-raise with original exception type if possible</span>
                    <span class="k">if</span> <span class="n">exc_class</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="n">exc_class</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">exc_msg</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">Worker traceback:</span><span class="se">\n</span><span class="si">{</span><span class="n">traceback_str</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># Fall back to RuntimeError if we can&#39;t get the original type</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Worker </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> raised </span><span class="si">{</span><span class="n">exc_type_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">exc_msg</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">Worker traceback:</span><span class="se">\n</span><span class="si">{</span><span class="n">traceback_str</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Legacy string error message</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span> <span class="o">=</span> <span class="n">queue_out</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="n">_running_free</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">start</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Starts the collector(s) for asynchronous data collection.</span>

<span class="sd">        The collected data is stored in the provided replay buffer. This method initiates the background collection of</span>
<span class="sd">        data across multiple processes, allowing for decoupling of data collection and training.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: If no replay buffer is defined during the collector&#39;s initialization.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; import time</span>
<span class="sd">            &gt;&gt;&gt; from functools import partial</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; import tqdm</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.collectors import MultiaSyncDataCollector, RandomPolicy</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.data import LazyTensorStorage, ReplayBuffer</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs import GymEnv, set_gym_backend</span>
<span class="sd">            &gt;&gt;&gt; import ale_py</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Set the gym backend to gymnasium</span>
<span class="sd">            &gt;&gt;&gt; set_gym_backend(&quot;gymnasium&quot;).set()</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; if __name__ == &quot;__main__&quot;:</span>
<span class="sd">            ...     # Create a random policy for the Pong environment</span>
<span class="sd">            ...     env_fn = partial(GymEnv, &quot;ALE/Pong-v5&quot;)</span>
<span class="sd">            ...     policy = RandomPolicy(env_fn().action_spec)</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Initialize a shared replay buffer</span>
<span class="sd">            ...     rb = ReplayBuffer(storage=LazyTensorStorage(10000), shared=True)</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Create a multi-async data collector with 16 environments</span>
<span class="sd">            ...     num_envs = 16</span>
<span class="sd">            ...     collector = MultiaSyncDataCollector(</span>
<span class="sd">            ...         [env_fn] * num_envs,</span>
<span class="sd">            ...         policy=policy,</span>
<span class="sd">            ...         replay_buffer=rb,</span>
<span class="sd">            ...         frames_per_batch=num_envs * 16,</span>
<span class="sd">            ...         total_frames=-1,</span>
<span class="sd">            ...     )</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Progress bar to track the number of collected frames</span>
<span class="sd">            ...     pbar = tqdm.tqdm(total=100_000)</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Start the collector asynchronously</span>
<span class="sd">            ...     collector.start()</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Track the write count of the replay buffer</span>
<span class="sd">            ...     prec_wc = 0</span>
<span class="sd">            ...     while True:</span>
<span class="sd">            ...         wc = rb.write_count</span>
<span class="sd">            ...         c = wc - prec_wc</span>
<span class="sd">            ...         prec_wc = wc</span>
<span class="sd">            ...</span>
<span class="sd">            ...         # Update the progress bar</span>
<span class="sd">            ...         pbar.update(c)</span>
<span class="sd">            ...         pbar.set_description(f&quot;Write Count: {rb.write_count}&quot;)</span>
<span class="sd">            ...</span>
<span class="sd">            ...         # Check the write count every 0.5 seconds</span>
<span class="sd">            ...         time.sleep(0.5)</span>
<span class="sd">            ...</span>
<span class="sd">            ...         # Stop when the desired number of frames is reached</span>
<span class="sd">            ...         if rb.write_count . 100_000:</span>
<span class="sd">            ...             break</span>
<span class="sd">            ...</span>
<span class="sd">            ...     # Shut down the collector</span>
<span class="sd">            ...     collector.async_shutdown()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Replay buffer must be defined for execution.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot currently start() a collector that requires random frames. Please submit a feature request on github.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_running_free</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">for</span> <span class="n">pipe</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">:</span>
            <span class="n">pipe</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;run_free&quot;</span><span class="p">))</span>

    <span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">pause</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Context manager that pauses the collector if it is running free.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_running_free</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">pipe</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">:</span>
                <span class="n">pipe</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;pause&quot;</span><span class="p">))</span>
            <span class="c1"># Make sure all workers are paused</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">:</span>
                <span class="n">idx</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;paused&quot;</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected paused, but got </span><span class="si">{</span><span class="n">msg</span><span class="si">=}</span><span class="s2">.&quot;</span><span class="p">)</span>
                <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> is paused.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_running_free</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">yield</span> <span class="kc">None</span>
            <span class="k">for</span> <span class="n">pipe</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">:</span>
                <span class="n">pipe</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;restart&quot;</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_running_free</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Collector cannot be paused.&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="c1"># an AttributeError will typically be raised if the collector is deleted when the program ends.</span>
            <span class="c1"># In the future, insignificant changes to the close method may change the error type.</span>
            <span class="c1"># We excplicitely assume that any error raised during closure in</span>
            <span class="c1"># __del__ will not affect the program.</span>
            <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">shutdown</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timeout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">close_env</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Shuts down all processes. This operation is irreversible.</span>

<span class="sd">        Args:</span>
<span class="sd">            timeout (float, optional): The timeout for closing pipes between workers.</span>
<span class="sd">            close_env (bool, optional): Whether to close the environment. Defaults to `True`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">close_env</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Cannot shutdown </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> collector without environment being closed.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shutdown_main</span><span class="p">(</span><span class="n">timeout</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_shutdown_main</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timeout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">timeout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">timeout</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
                <span class="k">return</span>
            <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>
            <span class="n">all_closed</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
            <span class="n">rep</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">all_closed</span><span class="p">[</span><span class="n">idx</span><span class="p">]:</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">is_alive</span><span class="p">():</span>
                    <span class="k">continue</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;close&quot;</span><span class="p">))</span>

            <span class="k">while</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">all_closed</span><span class="p">)</span> <span class="ow">and</span> <span class="n">rep</span> <span class="o">&lt;</span> <span class="mi">1000</span><span class="p">:</span>
                <span class="n">rep</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">all_closed</span><span class="p">[</span><span class="n">idx</span><span class="p">]:</span>
                        <span class="k">continue</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">is_alive</span><span class="p">():</span>
                        <span class="n">all_closed</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="k">continue</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">poll</span><span class="p">(</span><span class="n">timeout</span> <span class="o">/</span> <span class="mi">1000</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                            <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
                            <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;closed&quot;</span><span class="p">:</span>
                                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2"> but expected &#39;close&#39;&quot;</span><span class="p">)</span>
                            <span class="n">all_closed</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">continue</span>
                    <span class="k">except</span> <span class="ne">BrokenPipeError</span><span class="p">:</span>
                        <span class="n">all_closed</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="k">continue</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">pipe</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">:</span>
                <span class="n">pipe</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">proc</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">:</span>
                <span class="n">proc</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">torchrl</span>

            <span class="n">num_threads</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
                <span class="n">torchrl</span><span class="o">.</span><span class="n">_THREAD_POOL_INIT</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">get_num_threads</span><span class="p">()</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_workers_from_env</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_env_fn</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span><span class="p">(</span><span class="n">num_threads</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">proc</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">proc</span><span class="o">.</span><span class="n">is_alive</span><span class="p">():</span>
                    <span class="n">proc</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">async_shutdown</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timeout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sets the seeds of the environments stored in the DataCollector.</span>

<span class="sd">        Args:</span>
<span class="sd">            seed: integer representing the seed to be used for the environment.</span>
<span class="sd">            static_seed (bool, optional): if ``True``, the seed is not incremented.</span>
<span class="sd">                Defaults to False</span>

<span class="sd">        Returns:</span>
<span class="sd">            Output seed. This is useful when more than one environment is</span>
<span class="sd">            contained in the DataCollector, as the seed will be incremented for</span>
<span class="sd">            each of these. The resulting seed is the seed of the last</span>
<span class="sd">            environment.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs import ParallelEnv</span>
<span class="sd">            &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">            &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">            &gt;&gt;&gt; from torch import nn</span>
<span class="sd">            &gt;&gt;&gt; env_fn = lambda: GymEnv(&quot;Pendulum-v1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; env_fn_parallel = lambda: ParallelEnv(6, env_fn)</span>
<span class="sd">            &gt;&gt;&gt; policy = TensorDictModule(nn.Linear(3, 1), in_keys=[&quot;observation&quot;], out_keys=[&quot;action&quot;])</span>
<span class="sd">            &gt;&gt;&gt; collector = SyncDataCollector(env_fn_parallel, policy, frames_per_batch=100, total_frames=300)</span>
<span class="sd">            &gt;&gt;&gt; out_seed = collector.set_seed(1)  # out_seed = 6</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">(((</span><span class="n">seed</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">),</span> <span class="s2">&quot;seed&quot;</span><span class="p">))</span>
            <span class="n">new_seed</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;seeded&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected msg=&#39;seeded&#39;, got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">seed</span> <span class="o">=</span> <span class="n">new_seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">seed</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reset_idx</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Resets the environments to a new initial state.</span>

<span class="sd">        Args:</span>
<span class="sd">            reset_idx: Optional. Sequence indicating which environments have</span>
<span class="sd">                to be reset. If None, all environments are reset.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">reset_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">reset_idx</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">reset_idx</span><span class="p">[</span><span class="n">idx</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;reset&quot;</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">reset_idx</span><span class="p">[</span><span class="n">idx</span><span class="p">]:</span>
                <span class="n">j</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;reset&quot;</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected msg=&#39;reset&#39;, got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the state_dict of the data collector.</span>

<span class="sd">        Each field represents a worker containing its own state_dict.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;state_dict&quot;</span><span class="p">))</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="n">_state_dict</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;state_dict&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected msg=&#39;state_dict&#39;, got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">state_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;worker</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_state_dict</span>
        <span class="n">state_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;frames&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span><span class="p">,</span> <span class="s2">&quot;iter&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span><span class="p">})</span>

        <span class="k">return</span> <span class="n">state_dict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Loads the state_dict on the workers.</span>

<span class="sd">        Args:</span>
<span class="sd">            state_dict (OrderedDict): state_dict of the form</span>
<span class="sd">                ``{&quot;worker0&quot;: state_dict0, &quot;worker1&quot;: state_dict1}``.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">state_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;worker</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">],</span> <span class="s2">&quot;load_state_dict&quot;</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;loaded&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected msg=&#39;loaded&#39;, got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;iter&quot;</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">increment_version</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Increment the policy version.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span><span class="p">,</span> <span class="s2">&quot;increment_version&quot;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Policy version tracker is not a PolicyVersion instance. Please pass a PolicyVersion instance to the collector.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span><span class="o">.</span><span class="n">increment_version</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">policy_version</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The current policy version.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span><span class="p">,</span> <span class="s2">&quot;version&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_version_tracker</span><span class="o">.</span><span class="n">version</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_policy_version</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the current policy version.</span>

<span class="sd">        This method exists to support remote calls in Ray actors, since properties</span>
<span class="sd">        cannot be accessed directly through Ray&#39;s RPC mechanism.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The current version number (int) or UUID (str), or None if version tracking is disabled.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_version</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">getattr_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get an attribute from the policy of the first worker.</span>

<span class="sd">        Args:</span>
<span class="sd">            attr (str): The attribute name to retrieve from the policy.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The attribute value from the policy of the first worker.</span>

<span class="sd">        Raises:</span>
<span class="sd">            AttributeError: If the attribute doesn&#39;t exist on the policy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>

        <span class="c1"># Send command to first worker (index 0)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">attr</span><span class="p">,</span> <span class="s2">&quot;getattr_policy&quot;</span><span class="p">))</span>
        <span class="n">result</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;getattr_policy&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected msg=&#39;getattr_policy&#39;, got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># If the worker returned an AttributeError, re-raise it</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">result</span>

        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">getattr_env</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get an attribute from the environment of the first worker.</span>

<span class="sd">        Args:</span>
<span class="sd">            attr (str): The attribute name to retrieve from the environment.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The attribute value from the environment of the first worker.</span>

<span class="sd">        Raises:</span>
<span class="sd">            AttributeError: If the attribute doesn&#39;t exist on the environment.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>

        <span class="c1"># Send command to first worker (index 0)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">attr</span><span class="p">,</span> <span class="s2">&quot;getattr_env&quot;</span><span class="p">))</span>
        <span class="n">result</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;getattr_env&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected msg=&#39;getattr_env&#39;, got </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># If the worker returned an AttributeError, re-raise it</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">result</span>

        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">getattr_rb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get an attribute from the replay buffer.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span>


<div class="viewcode-block" id="MultiSyncDataCollector"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiSyncDataCollector.html#torchrl.collectors.MultiSyncDataCollector">[docs]</a><span class="nd">@accept_remote_rref_udf_invocation</span>
<span class="k">class</span><span class="w"> </span><span class="nc">MultiSyncDataCollector</span><span class="p">(</span><span class="n">_MultiDataCollector</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Runs a given number of DataCollectors on separate processes synchronously.</span>

<span class="sd">    .. aafig::</span>

<span class="sd">            +----------------------------------------------------------------------+</span>
<span class="sd">            |            &quot;MultiSyncDataCollector&quot;                 |                |</span>
<span class="sd">            |~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~|                |</span>
<span class="sd">            |   &quot;Collector 1&quot; |  &quot;Collector 2&quot;  |  &quot;Collector 3&quot;  |     Main       |</span>
<span class="sd">            |~~~~~~~~~~~~~~~~~|~~~~~~~~~~~~~~~~~|~~~~~~~~~~~~~~~~~|~~~~~~~~~~~~~~~~|</span>
<span class="sd">            | &quot;env1&quot; | &quot;env2&quot; | &quot;env3&quot; | &quot;env4&quot; | &quot;env5&quot; | &quot;env6&quot; |                |</span>
<span class="sd">            |~~~~~~~~|~~~~~~~~|~~~~~~~~|~~~~~~~~|~~~~~~~~|~~~~~~~~|~~~~~~~~~~~~~~~~|</span>
<span class="sd">            |&quot;reset&quot; |&quot;reset&quot; |&quot;reset&quot; |&quot;reset&quot; |&quot;reset&quot; |&quot;reset&quot; |                |</span>
<span class="sd">            |        |        |        |        |        |        |                |</span>
<span class="sd">            |       &quot;actor&quot;   |        |        |       &quot;actor&quot;   |                |</span>
<span class="sd">            |                 |        |        |                 |                |</span>
<span class="sd">            | &quot;step&quot; | &quot;step&quot; |       &quot;actor&quot;   |                 |                |</span>
<span class="sd">            |        |        |                 |                 |                |</span>
<span class="sd">            |        |        |                 | &quot;step&quot; | &quot;step&quot; |                |</span>
<span class="sd">            |        |        |                 |        |        |                |</span>
<span class="sd">            |       &quot;actor&quot;   | &quot;step&quot; | &quot;step&quot; |       &quot;actor&quot;   |                |</span>
<span class="sd">            |                 |        |        |                 |                |</span>
<span class="sd">            |                 |       &quot;actor&quot;   |                 |                |</span>
<span class="sd">            |                 |                 |                 |                |</span>
<span class="sd">            |                       &quot;yield batch of traj 1&quot;-------&gt;&quot;collect, train&quot;|</span>
<span class="sd">            |                                                     |                |</span>
<span class="sd">            | &quot;step&quot; | &quot;step&quot; | &quot;step&quot; | &quot;step&quot; | &quot;step&quot; | &quot;step&quot; |                |</span>
<span class="sd">            |        |        |        |        |        |        |                |</span>
<span class="sd">            |       &quot;actor&quot;   |       &quot;actor&quot;   |        |        |                |</span>
<span class="sd">            |                 | &quot;step&quot; | &quot;step&quot; |       &quot;actor&quot;   |                |</span>
<span class="sd">            |                 |        |        |                 |                |</span>
<span class="sd">            | &quot;step&quot; | &quot;step&quot; |       &quot;actor&quot;   | &quot;step&quot; | &quot;step&quot; |                |</span>
<span class="sd">            |        |        |                 |        |        |                |</span>
<span class="sd">            |       &quot;actor&quot;   |                 |       &quot;actor&quot;   |                |</span>
<span class="sd">            |                       &quot;yield batch of traj 2&quot;-------&gt;&quot;collect, train&quot;|</span>
<span class="sd">            |                                                     |                |</span>
<span class="sd">            +----------------------------------------------------------------------+</span>

<span class="sd">    Envs can be identical or different.</span>

<span class="sd">    The collection starts when the next item of the collector is queried,</span>
<span class="sd">    and no environment step is computed in between the reception of a batch of</span>
<span class="sd">    trajectory and the start of the next collection.</span>
<span class="sd">    This class can be safely used with online RL sota-implementations.</span>

<span class="sd">    .. note::</span>
<span class="sd">        Python requires multiprocessed code to be instantiated within a main guard:</span>

<span class="sd">            &gt;&gt;&gt; from torchrl.collectors import MultiSyncDataCollector</span>
<span class="sd">            &gt;&gt;&gt; if __name__ == &quot;__main__&quot;:</span>
<span class="sd">            ...     # Create your collector here</span>
<span class="sd">            ...     collector = MultiSyncDataCollector(...)</span>

<span class="sd">        See https://docs.python.org/3/library/multiprocessing.html for more info.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.collectors import MultiSyncDataCollector</span>
<span class="sd">        &gt;&gt;&gt; if __name__ == &quot;__main__&quot;:</span>
<span class="sd">        ...     env_maker = lambda: GymEnv(&quot;Pendulum-v1&quot;, device=&quot;cpu&quot;)</span>
<span class="sd">        ...     policy = TensorDictModule(nn.Linear(3, 1), in_keys=[&quot;observation&quot;], out_keys=[&quot;action&quot;])</span>
<span class="sd">        ...     collector = MultiSyncDataCollector(</span>
<span class="sd">        ...         create_env_fn=[env_maker, env_maker],</span>
<span class="sd">        ...         policy=policy,</span>
<span class="sd">        ...         total_frames=2000,</span>
<span class="sd">        ...         max_frames_per_traj=50,</span>
<span class="sd">        ...         frames_per_batch=200,</span>
<span class="sd">        ...         init_random_frames=-1,</span>
<span class="sd">        ...         reset_at_each_iter=False,</span>
<span class="sd">        ...         device=&quot;cpu&quot;,</span>
<span class="sd">        ...         storing_device=&quot;cpu&quot;,</span>
<span class="sd">        ...         cat_results=&quot;stack&quot;,</span>
<span class="sd">        ...     )</span>
<span class="sd">        ...     for i, data in enumerate(collector):</span>
<span class="sd">        ...         if i == 2:</span>
<span class="sd">        ...             print(data)</span>
<span class="sd">        ...             break</span>
<span class="sd">        ...     collector.shutdown()</span>
<span class="sd">        ...     del collector</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                collector: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        traj_ids: Tensor(shape=torch.Size([200]), device=cpu, dtype=torch.int64, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([200]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        step_count: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                        truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([200]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                step_count: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([200]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="vm">__doc__</span> <span class="o">+=</span> <span class="n">_MultiDataCollector</span><span class="o">.</span><span class="vm">__doc__</span>

    <span class="c1"># for RPC</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">next</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiSyncDataCollector.shutdown"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiSyncDataCollector.html#torchrl.collectors.MultiSyncDataCollector.shutdown">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">shutdown</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timeout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">close_env</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">close_env</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Cannot shutdown </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> collector without environment being closed.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;out_buffer&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;buffers&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">shutdown</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">)</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiSyncDataCollector.set_seed"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiSyncDataCollector.html#torchrl.collectors.MultiSyncDataCollector.set_seed">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">)</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiSyncDataCollector.state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiSyncDataCollector.html#torchrl.collectors.MultiSyncDataCollector.state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiSyncDataCollector.load_state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiSyncDataCollector.html#torchrl.collectors.MultiSyncDataCollector.load_state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiSyncDataCollector.update_policy_weights_"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiSyncDataCollector.html#torchrl.collectors.MultiSyncDataCollector.update_policy_weights_">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">update_policy_weights_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">policy_or_weights</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="n">TensorDictModuleBase</span> <span class="o">|</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">worker_ids</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;policy_weights&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;`policy_weights` is deprecated. Use `policy_or_weights` instead.&quot;</span><span class="p">,</span>
                <span class="ne">DeprecationWarning</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">policy_or_weights</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;policy_weights&quot;</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">update_policy_weights_</span><span class="p">(</span>
            <span class="n">policy_or_weights</span><span class="o">=</span><span class="n">policy_or_weights</span><span class="p">,</span> <span class="n">worker_ids</span><span class="o">=</span><span class="n">worker_ids</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">frames_per_batch_worker</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">worker_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">worker_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_frames_per_batch</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames_per_batch</span><span class="p">[</span><span class="n">worker_idx</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">requested_frames_per_batch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">RL_WARNINGS</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;frames_per_batch </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">requested_frames_per_batch</span><span class="si">}</span><span class="s2"> is not exactly divisible by the number of collector workers </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="si">}</span><span class="s2">,&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; this results in more frames_per_batch per iteration that requested.&quot;</span>
                <span class="s2">&quot;To silence this message, set the environment variable RL_WARNINGS to False.&quot;</span>
            <span class="p">)</span>
        <span class="n">frames_per_batch_worker</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span>
            <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">requested_frames_per_batch</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">frames_per_batch_worker</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_queue_len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">iterator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">]:</span>
        <span class="n">cat_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cat_results</span>
        <span class="k">if</span> <span class="n">cat_results</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cat_results</span> <span class="o">=</span> <span class="s2">&quot;stack&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">dones</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">)]</span>
        <span class="n">workers_frames</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">)]</span>
        <span class="n">same_device</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">preempt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">preemptive_threshold</span> <span class="o">&lt;</span> <span class="mf">1.0</span>

        <span class="k">while</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">dones</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span><span class="p">:</span>
            <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_at_each_batch</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update_policy_weights_</span><span class="p">()</span>

            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span>
                <span class="p">):</span>
                    <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;continue_random&quot;</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;continue&quot;</span>
                <span class="c1"># Debug: sending &#39;continue&#39;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="n">msg</span><span class="p">))</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="k">if</span> <span class="n">preempt</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span><span class="o">.</span><span class="n">start_collection</span><span class="p">()</span>
                <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span><span class="o">.</span><span class="n">qsize</span><span class="p">()</span> <span class="o">&lt;</span> <span class="nb">int</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">preemptive_threshold</span>
                <span class="p">):</span>
                    <span class="k">continue</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">interruptor</span><span class="o">.</span><span class="n">stop_collection</span><span class="p">()</span>
                <span class="c1"># Now wait for stragglers to return</span>
                <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span><span class="o">.</span><span class="n">qsize</span><span class="p">()</span> <span class="o">&lt;</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                    <span class="k">continue</span>

            <span class="n">recv</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">()</span>
            <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">recv</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">_TIMEOUT</span> <span class="o">*</span> <span class="n">_MAX_IDLE_COUNT</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">new_data</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">_TIMEOUT</span><span class="p">)</span>
                        <span class="n">recv</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">new_data</span><span class="p">,</span> <span class="n">j</span><span class="p">))</span>
                    <span class="k">except</span> <span class="p">(</span><span class="ne">TimeoutError</span><span class="p">,</span> <span class="n">Empty</span><span class="p">):</span>
                        <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">_TIMEOUT</span> <span class="o">*</span> <span class="n">_MAX_IDLE_COUNT</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
                <span class="k">finally</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Failed to gather all collector output within </span><span class="si">{</span><span class="n">_TIMEOUT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">_MAX_IDLE_COUNT</span><span class="si">}</span><span class="s2"> seconds. &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Increase the MAX_IDLE_COUNT environment variable to bypass this error.&quot;</span>
                    <span class="p">)</span>

            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                <span class="n">new_data</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">recv</span><span class="o">.</span><span class="n">popleft</span><span class="p">()</span>
                <span class="n">use_buffers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">new_data</span>
                    <span class="n">workers_frames</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">workers_frames</span><span class="p">[</span>
                        <span class="n">idx</span>
                    <span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_batch_worker</span><span class="p">(</span><span class="n">worker_idx</span><span class="o">=</span><span class="n">idx</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="k">elif</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">use_buffers</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">data</span><span class="p">,</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">new_data</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span>
                        <span class="k">if</span> <span class="n">use_buffers</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">use_buffers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="n">idx</span> <span class="o">=</span> <span class="n">new_data</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">new_data</span>

                <span class="k">if</span> <span class="n">preempt</span><span class="p">:</span>
                    <span class="c1"># mask buffers if cat, and create a mask if stack</span>
                    <span class="k">if</span> <span class="n">cat_results</span> <span class="o">!=</span> <span class="s2">&quot;stack&quot;</span><span class="p">:</span>
                        <span class="n">buffers</span> <span class="o">=</span> <span class="p">{}</span>
                        <span class="k">for</span> <span class="n">worker_idx</span><span class="p">,</span> <span class="n">buffer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                            <span class="n">valid</span> <span class="o">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">))</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
                            <span class="k">if</span> <span class="n">valid</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                                <span class="n">valid</span> <span class="o">=</span> <span class="n">valid</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">valid</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                                <span class="n">valid</span> <span class="o">=</span> <span class="n">valid</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                            <span class="n">buffers</span><span class="p">[</span><span class="n">worker_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">valid</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">buffer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                            <span class="k">with</span> <span class="n">buffer</span><span class="o">.</span><span class="n">unlock_</span><span class="p">():</span>
                                <span class="n">buffer</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                                    <span class="p">(</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;mask&quot;</span><span class="p">),</span>
                                    <span class="n">buffer</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">))</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                <span class="p">)</span>
                        <span class="n">buffers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">buffers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span>

                <span class="c1"># Skip frame counting if this worker didn&#39;t send data this iteration</span>
                <span class="c1"># (happens when reusing buffers or on first iteration with some workers)</span>
                <span class="k">if</span> <span class="n">idx</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">buffers</span><span class="p">:</span>
                    <span class="k">continue</span>

                <span class="n">workers_frames</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">workers_frames</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">buffers</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">workers_frames</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span><span class="p">:</span>
                    <span class="n">dones</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">yield</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_batch_worker</span><span class="p">(</span><span class="n">worker_idx</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">worker_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">)</span>
                    <span class="p">]</span>
                <span class="p">)</span>
                <span class="k">continue</span>

            <span class="c1"># we have to correct the traj_ids to make sure that they don&#39;t overlap</span>
            <span class="c1"># We can count the number of frames collected for free in this loop</span>
            <span class="n">n_collected</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">buffers</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">buffer</span> <span class="o">=</span> <span class="n">buffers</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                <span class="n">traj_ids</span> <span class="o">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">))</span>
                <span class="k">if</span> <span class="n">preempt</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">cat_results</span> <span class="o">==</span> <span class="s2">&quot;stack&quot;</span><span class="p">:</span>
                        <span class="n">mask_frames</span> <span class="o">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="s2">&quot;collector&quot;</span><span class="p">,</span> <span class="s2">&quot;traj_ids&quot;</span><span class="p">))</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
                        <span class="n">n_collected</span> <span class="o">+=</span> <span class="n">mask_frames</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">n_collected</span> <span class="o">+=</span> <span class="n">traj_ids</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">n_collected</span> <span class="o">+=</span> <span class="n">traj_ids</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">same_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">prev_device</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">same_device</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">prev_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">prev_device</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">device</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">same_device</span> <span class="o">=</span> <span class="n">same_device</span> <span class="ow">and</span> <span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">prev_device</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">cat_results</span> <span class="o">==</span> <span class="s2">&quot;stack&quot;</span><span class="p">:</span>
                <span class="n">stack</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">stack</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span> <span class="k">else</span> <span class="n">TensorDict</span><span class="o">.</span><span class="n">maybe_dense_stack</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">same_device</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span> <span class="o">=</span> <span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">buffers</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="mi">0</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span> <span class="o">=</span> <span class="n">stack</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">buffers</span><span class="o">.</span><span class="n">values</span><span class="p">()],</span> <span class="mi">0</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="s2">&quot;use_buffer not specified and not yet inferred from data, assuming `True`.&quot;</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="s2">&quot;Cannot concatenate results with use_buffers=False&quot;</span>
                    <span class="p">)</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">same_device</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">buffers</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="n">cat_results</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                            <span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">buffers</span><span class="o">.</span><span class="n">values</span><span class="p">()],</span> <span class="n">cat_results</span>
                        <span class="p">)</span>
                <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="n">preempt</span>
                        <span class="ow">and</span> <span class="n">cat_results</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
                        <span class="ow">and</span> <span class="s2">&quot;Sizes of tensors must match&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
                    <span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                            <span class="s2">&quot;The value provided to cat_results isn&#39;t compatible with the collectors outputs. &quot;</span>
                            <span class="s2">&quot;Consider using `cat_results=-1`.&quot;</span>
                        <span class="p">)</span>
                    <span class="k">raise</span>

            <span class="c1"># TODO: why do we need to do cat inplace and clone?</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_trajs</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">split_trajectories</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;collector&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span>
            <span class="k">if</span> <span class="n">cat_results</span> <span class="ow">in</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;stack&quot;</span><span class="p">):</span>
                <span class="n">out</span><span class="o">.</span><span class="n">refine_names</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">])</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">+=</span> <span class="n">n_collected</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span><span class="p">,</span> <span class="s2">&quot;to&quot;</span><span class="p">)</span>
                    <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span>
                <span class="p">)</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exclude_private_keys</span><span class="p">:</span>
                <span class="n">excluded_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">out</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)]</span>
                <span class="k">if</span> <span class="n">excluded_keys</span><span class="p">:</span>
                    <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="n">excluded_keys</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">out</span>
            <span class="k">del</span> <span class="n">out</span>

        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_buffer</span> <span class="o">=</span> <span class="kc">None</span></div>
        <span class="c1"># We shall not call shutdown just yet as user may want to retrieve state_dict</span>
        <span class="c1"># self._shutdown_main()</span>


<div class="viewcode-block" id="MultiaSyncDataCollector"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiaSyncDataCollector.html#torchrl.collectors.MultiaSyncDataCollector">[docs]</a><span class="nd">@accept_remote_rref_udf_invocation</span>
<span class="k">class</span><span class="w"> </span><span class="nc">MultiaSyncDataCollector</span><span class="p">(</span><span class="n">_MultiDataCollector</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Runs a given number of DataCollectors on separate processes asynchronously.</span>

<span class="sd">    .. aafig::</span>


<span class="sd">            +----------------------------------------------------------------------+</span>
<span class="sd">            |           &quot;MultiConcurrentCollector&quot;                |                |</span>
<span class="sd">            |~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~|                |</span>
<span class="sd">            |  &quot;Collector 1&quot;  |  &quot;Collector 2&quot;  |  &quot;Collector 3&quot;  |     &quot;Main&quot;     |</span>
<span class="sd">            |~~~~~~~~~~~~~~~~~|~~~~~~~~~~~~~~~~~|~~~~~~~~~~~~~~~~~|~~~~~~~~~~~~~~~~|</span>
<span class="sd">            | &quot;env1&quot; | &quot;env2&quot; | &quot;env3&quot; | &quot;env4&quot; | &quot;env5&quot; | &quot;env6&quot; |                |</span>
<span class="sd">            |~~~~~~~~|~~~~~~~~|~~~~~~~~|~~~~~~~~|~~~~~~~~|~~~~~~~~|~~~~~~~~~~~~~~~~|</span>
<span class="sd">            |&quot;reset&quot; |&quot;reset&quot; |&quot;reset&quot; |&quot;reset&quot; |&quot;reset&quot; |&quot;reset&quot; |                |</span>
<span class="sd">            |        |        |        |        |        |        |                |</span>
<span class="sd">            |       &quot;actor&quot;   |        |        |       &quot;actor&quot;   |                |</span>
<span class="sd">            |                 |        |        |                 |                |</span>
<span class="sd">            | &quot;step&quot; | &quot;step&quot; |       &quot;actor&quot;   |                 |                |</span>
<span class="sd">            |        |        |                 |                 |                |</span>
<span class="sd">            |        |        |                 | &quot;step&quot; | &quot;step&quot; |                |</span>
<span class="sd">            |        |        |                 |        |        |                |</span>
<span class="sd">            |       &quot;actor    | &quot;step&quot; | &quot;step&quot; |       &quot;actor&quot;   |                |</span>
<span class="sd">            |                 |        |        |                 |                |</span>
<span class="sd">            | &quot;yield batch 1&quot; |       &quot;actor&quot;   |                 |&quot;collect, train&quot;|</span>
<span class="sd">            |                 |                 |                 |                |</span>
<span class="sd">            | &quot;step&quot; | &quot;step&quot; |                 | &quot;yield batch 2&quot; |&quot;collect, train&quot;|</span>
<span class="sd">            |        |        |                 |                 |                |</span>
<span class="sd">            |        |        | &quot;yield batch 3&quot; |                 |&quot;collect, train&quot;|</span>
<span class="sd">            |        |        |                 |                 |                |</span>
<span class="sd">            +----------------------------------------------------------------------+</span>

<span class="sd">    Environment types can be identical or different.</span>

<span class="sd">    The collection keeps on occurring on all processes even between the time</span>
<span class="sd">    the batch of rollouts is collected and the next call to the iterator.</span>
<span class="sd">    This class can be safely used with offline RL sota-implementations.</span>

<span class="sd">    .. note:: Python requires multiprocessed code to be instantiated within a main guard:</span>

<span class="sd">            &gt;&gt;&gt; from torchrl.collectors import MultiaSyncDataCollector</span>
<span class="sd">            &gt;&gt;&gt; if __name__ == &quot;__main__&quot;:</span>
<span class="sd">            ...     # Create your collector here</span>

<span class="sd">        See https://docs.python.org/3/library/multiprocessing.html for more info.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.envs.libs.gym import GymEnv</span>
<span class="sd">        &gt;&gt;&gt; from tensordict.nn import TensorDictModule</span>
<span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.collectors import MultiaSyncDataCollector</span>
<span class="sd">        &gt;&gt;&gt; if __name__ == &quot;__main__&quot;:</span>
<span class="sd">        ...     env_maker = lambda: GymEnv(&quot;Pendulum-v1&quot;, device=&quot;cpu&quot;)</span>
<span class="sd">        ...     policy = TensorDictModule(nn.Linear(3, 1), in_keys=[&quot;observation&quot;], out_keys=[&quot;action&quot;])</span>
<span class="sd">        ...     collector = MultiaSyncDataCollector(</span>
<span class="sd">        ...         create_env_fn=[env_maker, env_maker],</span>
<span class="sd">        ...         policy=policy,</span>
<span class="sd">        ...         total_frames=2000,</span>
<span class="sd">        ...         max_frames_per_traj=50,</span>
<span class="sd">        ...         frames_per_batch=200,</span>
<span class="sd">        ...         init_random_frames=-1,</span>
<span class="sd">        ...         reset_at_each_iter=False,</span>
<span class="sd">        ...         device=&quot;cpu&quot;,</span>
<span class="sd">        ...         storing_device=&quot;cpu&quot;,</span>
<span class="sd">        ...         cat_results=&quot;stack&quot;,</span>
<span class="sd">        ...     )</span>
<span class="sd">        ...     for i, data in enumerate(collector):</span>
<span class="sd">        ...         if i == 2:</span>
<span class="sd">        ...             print(data)</span>
<span class="sd">        ...             break</span>
<span class="sd">        ...     collector.shutdown()</span>
<span class="sd">        ...     del collector</span>
<span class="sd">        TensorDict(</span>
<span class="sd">            fields={</span>
<span class="sd">                action: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                collector: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        traj_ids: Tensor(shape=torch.Size([200]), device=cpu, dtype=torch.int64, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([200]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                next: TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),</span>
<span class="sd">                        observation: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        reward: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                        step_count: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                        truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">                    batch_size=torch.Size([200]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                observation: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),</span>
<span class="sd">                step_count: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.int64, is_shared=False),</span>
<span class="sd">                truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},</span>
<span class="sd">            batch_size=torch.Size([200]),</span>
<span class="sd">            device=cpu,</span>
<span class="sd">            is_shared=False)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="vm">__doc__</span> <span class="o">+=</span> <span class="n">_MultiDataCollector</span><span class="o">.</span><span class="vm">__doc__</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_tensordicts</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">running</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">postproc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">_device</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">storing_device</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">_device</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">postproc</span><span class="p">,</span> <span class="s2">&quot;to&quot;</span><span class="p">):</span>
                        <span class="n">postproc</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">postproc</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">_device</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span><span class="p">[</span><span class="n">_device</span><span class="p">]</span> <span class="o">=</span> <span class="n">postproc</span>

    <span class="c1"># for RPC</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">next</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiaSyncDataCollector.shutdown"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiaSyncDataCollector.html#torchrl.collectors.MultiaSyncDataCollector.shutdown">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">shutdown</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timeout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">close_env</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;out_tensordicts&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensordicts</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">close_env</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Cannot shutdown </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> collector without environment being closed.&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">shutdown</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">)</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiaSyncDataCollector.set_seed"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiaSyncDataCollector.html#torchrl.collectors.MultiaSyncDataCollector.set_seed">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">)</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiaSyncDataCollector.state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiaSyncDataCollector.html#torchrl.collectors.MultiaSyncDataCollector.state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiaSyncDataCollector.load_state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiaSyncDataCollector.html#torchrl.collectors.MultiaSyncDataCollector.load_state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="MultiaSyncDataCollector.update_policy_weights_"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiaSyncDataCollector.html#torchrl.collectors.MultiaSyncDataCollector.update_policy_weights_">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">update_policy_weights_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">policy_or_weights</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">|</span> <span class="n">TensorDictModuleBase</span> <span class="o">|</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">worker_ids</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;policy_weights&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;`policy_weights` is deprecated. Use `policy_or_weights` instead.&quot;</span><span class="p">,</span>
                <span class="ne">DeprecationWarning</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">policy_or_weights</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;policy_weights&quot;</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">update_policy_weights_</span><span class="p">(</span>
            <span class="n">policy_or_weights</span><span class="o">=</span><span class="n">policy_or_weights</span><span class="p">,</span> <span class="n">worker_ids</span><span class="o">=</span><span class="n">worker_ids</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">frames_per_batch_worker</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">worker_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">requested_frames_per_batch</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_from_queue</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">]:</span>
        <span class="n">new_data</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">)</span>
        <span class="n">use_buffers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">new_data</span>
        <span class="k">elif</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">use_buffers</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">data</span><span class="p">,</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">new_data</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">out_tensordicts</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span>
                <span class="k">if</span> <span class="n">use_buffers</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">use_buffers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">use_buffers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">use_buffers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_buffers</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">new_data</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">new_data</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensordicts</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">and</span> <span class="p">(</span><span class="n">j</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">use_buffers</span><span class="p">):</span>
            <span class="c1"># we clone the data to make sure that we&#39;ll be working with a fixed copy</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">idx</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">out</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_queue_len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">iterator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">]:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_at_each_batch</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_policy_weights_</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;continue_random&quot;</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;continue&quot;</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">running</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">workers_frames</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">)]</span>
        <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_frames</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">idx</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_from_queue</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">_TIMEOUT</span><span class="p">)</span>
                    <span class="k">break</span>
                <span class="k">except</span> <span class="p">(</span><span class="ne">TimeoutError</span><span class="p">,</span> <span class="n">Empty</span><span class="p">):</span>
                    <span class="n">counter</span> <span class="o">+=</span> <span class="n">_TIMEOUT</span>
                    <span class="n">_check_for_faulty_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">procs</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">counter</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">_TIMEOUT</span> <span class="o">*</span> <span class="n">_MAX_IDLE_COUNT</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Failed to gather all collector output within </span><span class="si">{</span><span class="n">_TIMEOUT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">_MAX_IDLE_COUNT</span><span class="si">}</span><span class="s2"> seconds. &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Increase the MAX_IDLE_COUNT environment variable to bypass this error.&quot;</span>
                    <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">worker_frames</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_trajs</span><span class="p">:</span>
                    <span class="n">out</span> <span class="o">=</span> <span class="n">split_trajectories</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;collector&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">worker_frames</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frames_per_batch_worker</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">+=</span> <span class="n">worker_frames</span>
            <span class="n">workers_frames</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">workers_frames</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">worker_frames</span>
            <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocs</span><span class="p">[</span><span class="n">out</span><span class="o">.</span><span class="n">device</span><span class="p">](</span><span class="n">out</span><span class="p">)</span>

            <span class="c1"># the function blocks here until the next item is asked, hence we send the message to the</span>
            <span class="c1"># worker to keep on working in the meantime before the yield statement</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span>
            <span class="p">):</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;continue_random&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;continue&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="n">msg</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exclude_private_keys</span><span class="p">:</span>
                <span class="n">excluded_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">out</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)]</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="n">excluded_keys</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">out</span>

        <span class="c1"># We don&#39;t want to shutdown yet, the user may want to call state_dict before</span>
        <span class="c1"># self._shutdown_main()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">running</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_shutdown_main</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;out_tensordicts&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensordicts</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_shutdown_main</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="MultiaSyncDataCollector.reset"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.MultiaSyncDataCollector.html#torchrl.collectors.MultiaSyncDataCollector.reset">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reset_idx</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">reset_idx</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span><span class="o">.</span><span class="n">full</span><span class="p">():</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">_TIMEOUT</span><span class="p">)</span>  <span class="c1"># wait until queue is empty</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_out</span><span class="o">.</span><span class="n">full</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;self.queue_out is full&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">running</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frames</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_random_frames</span>
                <span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="s2">&quot;continue_random&quot;</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">pipes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="s2">&quot;continue&quot;</span><span class="p">))</span></div></div>


<div class="viewcode-block" id="aSyncDataCollector"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.aSyncDataCollector.html#torchrl.collectors.aSyncDataCollector">[docs]</a><span class="nd">@accept_remote_rref_udf_invocation</span>
<span class="k">class</span><span class="w"> </span><span class="nc">aSyncDataCollector</span><span class="p">(</span><span class="n">MultiaSyncDataCollector</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Runs a single DataCollector on a separate process.</span>

<span class="sd">    This is mostly useful for offline RL paradigms where the policy being</span>
<span class="sd">    trained can differ from the policy used to collect data. In online</span>
<span class="sd">    settings, a regular DataCollector should be preferred. This class is</span>
<span class="sd">    merely a wrapper around a MultiaSyncDataCollector where a single process</span>
<span class="sd">    is being created.</span>

<span class="sd">    Args:</span>
<span class="sd">        create_env_fn (Callabled): Callable returning an instance of EnvBase</span>
<span class="sd">        policy (Callable): Policy to be executed in the environment.</span>
<span class="sd">            Must accept :class:`tensordict.tensordict.TensorDictBase` object as input.</span>
<span class="sd">            If ``None`` is provided, the policy used will be a</span>
<span class="sd">            :class:`~torchrl.collectors.RandomPolicy` instance with the environment</span>
<span class="sd">            ``action_spec``.</span>
<span class="sd">            Accepted policies are usually subclasses of :class:`~tensordict.nn.TensorDictModuleBase`.</span>
<span class="sd">            This is the recommended usage of the collector.</span>
<span class="sd">            Other callables are accepted too:</span>
<span class="sd">            If the policy is not a ``TensorDictModuleBase`` (e.g., a regular :class:`~torch.nn.Module`</span>
<span class="sd">            instances) it will be wrapped in a `nn.Module` first.</span>
<span class="sd">            Then, the collector will try to assess if these</span>
<span class="sd">            modules require wrapping in a :class:`~tensordict.nn.TensorDictModule` or not.</span>

<span class="sd">            - If the policy forward signature matches any of ``forward(self, tensordict)``,</span>
<span class="sd">              ``forward(self, td)`` or ``forward(self, &lt;anything&gt;: TensorDictBase)`` (or</span>
<span class="sd">              any typing with a single argument typed as a subclass of ``TensorDictBase``)</span>
<span class="sd">              then the policy won&#39;t be wrapped in a :class:`~tensordict.nn.TensorDictModule`.</span>

<span class="sd">            - In all other cases an attempt to wrap it will be undergone as such: ``TensorDictModule(policy, in_keys=env_obs_key, out_keys=env.action_keys)``.</span>

<span class="sd">            .. note:: If the policy needs to be passed as a policy factory (e.g., in case it mustn&#39;t be serialized /</span>
<span class="sd">                pickled directly), the ``policy_factory`` should be used instead.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        policy_factory (Callable[[], Callable], optional): a callable that returns</span>
<span class="sd">            a policy instance. This is exclusive with the `policy` argument.</span>

<span class="sd">            .. note:: `policy_factory` comes in handy whenever the policy cannot be serialized.</span>

<span class="sd">        frames_per_batch (int): A keyword-only argument representing the</span>
<span class="sd">            total number of elements in a batch.</span>
<span class="sd">        total_frames (int, optional): A keyword-only argument representing the</span>
<span class="sd">            total number of frames returned by the collector</span>
<span class="sd">            during its lifespan. If the ``total_frames`` is not divisible by</span>
<span class="sd">            ``frames_per_batch``, an exception is raised.</span>
<span class="sd">            Endless collectors can be created by passing ``total_frames=-1``.</span>
<span class="sd">            Defaults to ``-1`` (never ending collector).</span>
<span class="sd">        device (int, str or torch.device, optional): The generic device of the</span>
<span class="sd">            collector. The ``device`` args fills any non-specified device: if</span>
<span class="sd">            ``device`` is not ``None`` and any of ``storing_device``, ``policy_device`` or</span>
<span class="sd">            ``env_device`` is not specified, its value will be set to ``device``.</span>
<span class="sd">            Defaults to ``None`` (No default device).</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        storing_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the output :class:`~tensordict.TensorDict` will be stored.</span>
<span class="sd">            If ``device`` is passed and ``storing_device`` is ``None``, it will</span>
<span class="sd">            default to the value indicated by ``device``.</span>
<span class="sd">            For long trajectories, it may be necessary to store the data on a different</span>
<span class="sd">            device than the one where the policy and env are executed.</span>
<span class="sd">            Defaults to ``None`` (the output tensordict isn&#39;t on a specific device,</span>
<span class="sd">            leaf tensors sit on the device where they were created).</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        env_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the environment should be cast (or executed if that functionality is</span>
<span class="sd">            supported). If not specified and the env has a non-``None`` device,</span>
<span class="sd">            ``env_device`` will default to that value. If ``device`` is passed</span>
<span class="sd">            and ``env_device=None``, it will default to ``device``. If the value</span>
<span class="sd">            as such specified of ``env_device`` differs from ``policy_device``</span>
<span class="sd">            and one of them is not ``None``, the data will be cast to ``env_device``</span>
<span class="sd">            before being passed to the env (i.e., passing different devices to</span>
<span class="sd">            policy and env is supported). Defaults to ``None``.</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        policy_device (int, str or torch.device, optional): The device on which</span>
<span class="sd">            the policy should be cast.</span>
<span class="sd">            If ``device`` is passed and ``policy_device=None``, it will default</span>
<span class="sd">            to ``device``. If the value as such specified of ``policy_device``</span>
<span class="sd">            differs from ``env_device`` and one of them is not ``None``,</span>
<span class="sd">            the data will be cast to ``policy_device`` before being passed to</span>
<span class="sd">            the policy (i.e., passing different devices to policy and env is</span>
<span class="sd">            supported). Defaults to ``None``.</span>
<span class="sd">            Supports a list of devices if one wishes to indicate a different device</span>
<span class="sd">            for each worker. The list must be as long as the number of workers.</span>
<span class="sd">        create_env_kwargs (dict, optional): A dictionary with the</span>
<span class="sd">            keyword arguments used to create an environment. If a list is</span>
<span class="sd">            provided, each of its elements will be assigned to a sub-collector.</span>
<span class="sd">        max_frames_per_traj (int, optional): Maximum steps per trajectory.</span>
<span class="sd">            Note that a trajectory can span across multiple batches (unless</span>
<span class="sd">            ``reset_at_each_iter`` is set to ``True``, see below).</span>
<span class="sd">            Once a trajectory reaches ``n_steps``, the environment is reset.</span>
<span class="sd">            If the environment wraps multiple environments together, the number</span>
<span class="sd">            of steps is tracked for each environment independently. Negative</span>
<span class="sd">            values are allowed, in which case this argument is ignored.</span>
<span class="sd">            Defaults to ``None`` (i.e. no maximum number of steps).</span>
<span class="sd">        init_random_frames (int, optional): Number of frames for which the</span>
<span class="sd">            policy is ignored before it is called. This feature is mainly</span>
<span class="sd">            intended to be used in offline/model-based settings, where a</span>
<span class="sd">            batch of random trajectories can be used to initialize training.</span>
<span class="sd">            If provided, it will be rounded up to the closest multiple of frames_per_batch.</span>
<span class="sd">            Defaults to ``None`` (i.e. no random frames).</span>
<span class="sd">        reset_at_each_iter (bool, optional): Whether environments should be reset</span>
<span class="sd">            at the beginning of a batch collection.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        postproc (Callable, optional): A post-processing transform, such as</span>
<span class="sd">            a :class:`~torchrl.envs.Transform` or a :class:`~torchrl.data.postprocs.MultiStep`</span>
<span class="sd">            instance.</span>
<span class="sd">            Defaults to ``None``.</span>
<span class="sd">        split_trajs (bool, optional): Boolean indicating whether the resulting</span>
<span class="sd">            TensorDict should be split according to the trajectories.</span>
<span class="sd">            See :func:`~torchrl.collectors.utils.split_trajectories` for more</span>
<span class="sd">            information.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        exploration_type (ExplorationType, optional): interaction mode to be used when</span>
<span class="sd">            collecting data. Must be one of ``torchrl.envs.utils.ExplorationType.DETERMINISTIC``,</span>
<span class="sd">            ``torchrl.envs.utils.ExplorationType.RANDOM``, ``torchrl.envs.utils.ExplorationType.MODE``</span>
<span class="sd">            or ``torchrl.envs.utils.ExplorationType.MEAN``.</span>
<span class="sd">        reset_when_done (bool, optional): if ``True`` (default), an environment</span>
<span class="sd">            that return a ``True`` value in its ``&quot;done&quot;`` or ``&quot;truncated&quot;``</span>
<span class="sd">            entry will be reset at the corresponding indices.</span>
<span class="sd">        update_at_each_batch (boolm optional): if ``True``, :meth:`update_policy_weights_()`</span>
<span class="sd">            will be called before (sync) or after (async) each data collection.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        preemptive_threshold (:obj:`float`, optional): a value between 0.0 and 1.0 that specifies the ratio of workers</span>
<span class="sd">            that will be allowed to finished collecting their rollout before the rest are forced to end early.</span>
<span class="sd">        num_threads (int, optional): number of threads for this process.</span>
<span class="sd">            Defaults to the number of workers.</span>
<span class="sd">        num_sub_threads (int, optional): number of threads of the subprocesses.</span>
<span class="sd">            Should be equal to one plus the number of processes launched within</span>
<span class="sd">            each subprocess (or one if a single process is launched).</span>
<span class="sd">            Defaults to 1 for safety: if none is indicated, launching multiple</span>
<span class="sd">            workers may charge the cpu load too much and harm performance.</span>
<span class="sd">        set_truncated (bool, optional): if ``True``, the truncated signals (and corresponding</span>
<span class="sd">            ``&quot;done&quot;`` but not ``&quot;terminated&quot;``) will be set to ``True`` when the last frame of</span>
<span class="sd">            a rollout is reached. If no ``&quot;truncated&quot;`` key is found, an exception is raised.</span>
<span class="sd">            Truncated keys can be set through ``env.add_truncated_keys``.</span>
<span class="sd">            Defaults to ``False``.</span>
<span class="sd">        track_policy_version (bool or PolicyVersion, optional): if ``True``, the collector will track the version of the policy.</span>
<span class="sd">            This will be mediated by the :class:`~torchrl.envs.llm.transforms.policy_version.PolicyVersion` transform, which will be added to the environment.</span>
<span class="sd">            Alternatively, a :class:`~torchrl.envs.llm.transforms.policy_version.PolicyVersion` instance can be passed, which will be used to track</span>
<span class="sd">            the policy version.</span>
<span class="sd">            Defaults to `False`.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">create_env_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">EnvBase</span><span class="p">],</span>
        <span class="n">policy</span><span class="p">:</span> <span class="kc">None</span>
        <span class="o">|</span> <span class="p">(</span><span class="n">TensorDictModule</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">])</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">policy_factory</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">frames_per_batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">total_frames</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">storing_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">env_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">policy_device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">create_env_kwargs</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_frames_per_traj</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">init_random_frames</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">reset_at_each_iter</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">postproc</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">split_trajs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">exploration_type</span><span class="p">:</span> <span class="n">ExplorationType</span> <span class="o">=</span> <span class="n">DEFAULT_EXPLORATION_TYPE</span><span class="p">,</span>
        <span class="n">reset_when_done</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">update_at_each_batch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">preemptive_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_threads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_sub_threads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">set_truncated</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">track_policy_version</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">create_env_fn</span><span class="o">=</span><span class="p">[</span><span class="n">create_env_fn</span><span class="p">],</span>
            <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">,</span>
            <span class="n">policy_factory</span><span class="o">=</span><span class="n">policy_factory</span><span class="p">,</span>
            <span class="n">total_frames</span><span class="o">=</span><span class="n">total_frames</span><span class="p">,</span>
            <span class="n">create_env_kwargs</span><span class="o">=</span><span class="p">[</span><span class="n">create_env_kwargs</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">create_env_kwargs</span>
            <span class="k">else</span> <span class="n">create_env_kwargs</span><span class="p">,</span>
            <span class="n">max_frames_per_traj</span><span class="o">=</span><span class="n">max_frames_per_traj</span><span class="p">,</span>
            <span class="n">frames_per_batch</span><span class="o">=</span><span class="n">frames_per_batch</span><span class="p">,</span>
            <span class="n">reset_at_each_iter</span><span class="o">=</span><span class="n">reset_at_each_iter</span><span class="p">,</span>
            <span class="n">init_random_frames</span><span class="o">=</span><span class="n">init_random_frames</span><span class="p">,</span>
            <span class="n">postproc</span><span class="o">=</span><span class="n">postproc</span><span class="p">,</span>
            <span class="n">split_trajs</span><span class="o">=</span><span class="n">split_trajs</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">policy_device</span><span class="o">=</span><span class="n">policy_device</span><span class="p">,</span>
            <span class="n">env_device</span><span class="o">=</span><span class="n">env_device</span><span class="p">,</span>
            <span class="n">storing_device</span><span class="o">=</span><span class="n">storing_device</span><span class="p">,</span>
            <span class="n">exploration_type</span><span class="o">=</span><span class="n">exploration_type</span><span class="p">,</span>
            <span class="n">reset_when_done</span><span class="o">=</span><span class="n">reset_when_done</span><span class="p">,</span>
            <span class="n">update_at_each_batch</span><span class="o">=</span><span class="n">update_at_each_batch</span><span class="p">,</span>
            <span class="n">preemptive_threshold</span><span class="o">=</span><span class="n">preemptive_threshold</span><span class="p">,</span>
            <span class="n">num_threads</span><span class="o">=</span><span class="n">num_threads</span><span class="p">,</span>
            <span class="n">num_sub_threads</span><span class="o">=</span><span class="n">num_sub_threads</span><span class="p">,</span>
            <span class="n">set_truncated</span><span class="o">=</span><span class="n">set_truncated</span><span class="p">,</span>
            <span class="n">track_policy_version</span><span class="o">=</span><span class="n">track_policy_version</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># for RPC</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">next</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="aSyncDataCollector.shutdown"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.aSyncDataCollector.html#torchrl.collectors.aSyncDataCollector.shutdown">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">shutdown</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timeout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">close_env</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">shutdown</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span> <span class="n">close_env</span><span class="o">=</span><span class="n">close_env</span><span class="p">)</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="aSyncDataCollector.set_seed"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.aSyncDataCollector.html#torchrl.collectors.aSyncDataCollector.set_seed">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">static_seed</span><span class="p">)</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="aSyncDataCollector.state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.aSyncDataCollector.html#torchrl.collectors.aSyncDataCollector.state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span></div>

    <span class="c1"># for RPC</span>
<div class="viewcode-block" id="aSyncDataCollector.load_state_dict"><a class="viewcode-back" href="../../../reference/generated/torchrl.collectors.aSyncDataCollector.html#torchrl.collectors.aSyncDataCollector.load_state_dict">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span></div></div>


<span class="k">def</span><span class="w"> </span><span class="nf">_main_async_collector</span><span class="p">(</span>
    <span class="n">pipe_parent</span><span class="p">:</span> <span class="n">connection</span><span class="o">.</span><span class="n">Connection</span><span class="p">,</span>
    <span class="n">pipe_child</span><span class="p">:</span> <span class="n">connection</span><span class="o">.</span><span class="n">Connection</span><span class="p">,</span>
    <span class="n">queue_out</span><span class="p">:</span> <span class="n">queues</span><span class="o">.</span><span class="n">Queue</span><span class="p">,</span>
    <span class="n">create_env_fn</span><span class="p">:</span> <span class="n">EnvBase</span> <span class="o">|</span> <span class="n">EnvCreator</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">EnvBase</span><span class="p">],</span>  <span class="c1"># noqa: F821</span>
    <span class="n">create_env_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="n">policy</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">],</span>
    <span class="n">max_frames_per_traj</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">frames_per_batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">reset_at_each_iter</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">storing_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">env_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">policy_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">exploration_type</span><span class="p">:</span> <span class="n">ExplorationType</span> <span class="o">=</span> <span class="n">DEFAULT_EXPLORATION_TYPE</span><span class="p">,</span>
    <span class="n">reset_when_done</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">VERBOSE</span><span class="p">,</span>
    <span class="n">interruptor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">set_truncated</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">use_buffers</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">replay_buffer</span><span class="p">:</span> <span class="n">ReplayBuffer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extend_buffer</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">traj_pool</span><span class="p">:</span> <span class="n">_TrajectoryPool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">trust_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">compile_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">cudagraph_policy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">no_cuda_sync</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">policy_factory</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">collector_class</span><span class="p">:</span> <span class="nb">type</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">DataCollectorBase</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">postproc</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">weight_sync_schemes</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">WeightSyncScheme</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">collector_class</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">collector_class</span> <span class="o">=</span> <span class="n">SyncDataCollector</span>
    <span class="n">pipe_parent</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="c1"># init variables that will be cleared when closing</span>
    <span class="n">collected_tensordict</span> <span class="o">=</span> <span class="n">data</span> <span class="o">=</span> <span class="n">next_data</span> <span class="o">=</span> <span class="n">data_in</span> <span class="o">=</span> <span class="n">inner_collector</span> <span class="o">=</span> <span class="n">dc_iter</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">collector_class</span><span class="o">.</span><span class="n">_ignore_rb</span> <span class="o">=</span> <span class="n">extend_buffer</span>
        <span class="n">inner_collector</span> <span class="o">=</span> <span class="n">collector_class</span><span class="p">(</span>
            <span class="n">create_env_fn</span><span class="p">,</span>
            <span class="n">create_env_kwargs</span><span class="o">=</span><span class="n">create_env_kwargs</span><span class="p">,</span>
            <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">,</span>
            <span class="n">policy_factory</span><span class="o">=</span><span class="n">policy_factory</span><span class="p">,</span>
            <span class="n">total_frames</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">max_frames_per_traj</span><span class="o">=</span><span class="n">max_frames_per_traj</span><span class="p">,</span>
            <span class="n">frames_per_batch</span><span class="o">=</span><span class="n">frames_per_batch</span><span class="p">,</span>
            <span class="n">reset_at_each_iter</span><span class="o">=</span><span class="n">reset_at_each_iter</span><span class="p">,</span>
            <span class="n">postproc</span><span class="o">=</span><span class="n">postproc</span><span class="p">,</span>
            <span class="n">split_trajs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">storing_device</span><span class="o">=</span><span class="n">storing_device</span><span class="p">,</span>
            <span class="n">policy_device</span><span class="o">=</span><span class="n">policy_device</span><span class="p">,</span>
            <span class="n">env_device</span><span class="o">=</span><span class="n">env_device</span><span class="p">,</span>
            <span class="n">exploration_type</span><span class="o">=</span><span class="n">exploration_type</span><span class="p">,</span>
            <span class="n">reset_when_done</span><span class="o">=</span><span class="n">reset_when_done</span><span class="p">,</span>
            <span class="n">return_same_td</span><span class="o">=</span><span class="n">replay_buffer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">interruptor</span><span class="o">=</span><span class="n">interruptor</span><span class="p">,</span>
            <span class="n">set_truncated</span><span class="o">=</span><span class="n">set_truncated</span><span class="p">,</span>
            <span class="n">use_buffers</span><span class="o">=</span><span class="n">use_buffers</span><span class="p">,</span>
            <span class="n">replay_buffer</span><span class="o">=</span><span class="n">replay_buffer</span><span class="p">,</span>
            <span class="n">extend_buffer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">traj_pool</span><span class="o">=</span><span class="n">traj_pool</span><span class="p">,</span>
            <span class="n">trust_policy</span><span class="o">=</span><span class="n">trust_policy</span><span class="p">,</span>
            <span class="n">compile_policy</span><span class="o">=</span><span class="n">compile_policy</span><span class="p">,</span>
            <span class="n">cudagraph_policy</span><span class="o">=</span><span class="n">cudagraph_policy</span><span class="p">,</span>
            <span class="n">no_cuda_sync</span><span class="o">=</span><span class="n">no_cuda_sync</span><span class="p">,</span>
            <span class="n">weight_sync_schemes</span><span class="o">=</span><span class="n">weight_sync_schemes</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Set up weight receivers for worker process</span>
        <span class="k">if</span> <span class="n">weight_sync_schemes</span><span class="p">:</span>
            <span class="n">inner_collector</span><span class="o">.</span><span class="n">_weight_receivers</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">model_id</span><span class="p">,</span> <span class="n">scheme</span> <span class="ow">in</span> <span class="n">weight_sync_schemes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">receiver</span> <span class="o">=</span> <span class="n">scheme</span><span class="o">.</span><span class="n">create_receiver</span><span class="p">()</span>
                <span class="n">receiver</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">inner_collector</span><span class="p">)</span>
                <span class="n">receiver</span><span class="o">.</span><span class="n">register_worker_transport</span><span class="p">(</span><span class="n">pipe_child</span><span class="p">)</span>

                <span class="n">model</span> <span class="o">=</span> <span class="n">_resolve_model</span><span class="p">(</span><span class="n">inner_collector</span><span class="p">,</span> <span class="n">model_id</span><span class="p">)</span>
                <span class="n">receiver</span><span class="o">.</span><span class="n">register_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

                <span class="n">inner_collector</span><span class="o">.</span><span class="n">_weight_receivers</span><span class="p">[</span><span class="n">model_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">receiver</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inner_collector</span><span class="o">.</span><span class="n">_weight_receivers</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">use_buffers</span> <span class="o">=</span> <span class="n">inner_collector</span><span class="o">.</span><span class="n">_use_buffers</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Sync data collector created&quot;</span><span class="p">)</span>
        <span class="n">dc_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">inner_collector</span><span class="p">)</span>
        <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="s2">&quot;instantiated&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="c1"># Send error information to main process</span>
        <span class="c1"># We send a dict with the exception info so we can recreate it in the main process</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">traceback</span>

        <span class="n">error_info</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">&quot;exception_type&quot;</span><span class="p">:</span> <span class="nb">type</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
            <span class="s2">&quot;exception_module&quot;</span><span class="p">:</span> <span class="nb">type</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="o">.</span><span class="vm">__module__</span><span class="p">,</span>
            <span class="s2">&quot;exception_msg&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">),</span>
            <span class="s2">&quot;traceback&quot;</span><span class="p">:</span> <span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">(),</span>
        <span class="p">}</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">error_info</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="c1"># If pipe is broken, nothing we can do</span>
            <span class="k">pass</span>
        <span class="k">return</span>

    <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">run_free</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">_timeout</span> <span class="o">=</span> <span class="n">_TIMEOUT</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">has_timed_out</span> <span class="k">else</span> <span class="mf">1e-3</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">run_free</span> <span class="ow">and</span> <span class="n">pipe_child</span><span class="o">.</span><span class="n">poll</span><span class="p">(</span><span class="n">_timeout</span><span class="p">):</span>
            <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">data_in</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="n">pipe_child</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> received </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="n">run_free</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;poll failed, j=</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s2">, worker=</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="c1"># default is &quot;continue&quot; (after first iteration)</span>
            <span class="c1"># this is expected to happen if queue_out reached the timeout, but no new msg was waiting in the pipe</span>
            <span class="c1"># in that case, the main process probably expects the worker to continue collect data</span>
            <span class="k">if</span> <span class="n">has_timed_out</span><span class="p">:</span>
                <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="c1"># has_timed_out is True if the process failed to send data, which will</span>
                <span class="c1"># typically occur if main has taken another batch (i.e. the queue is Full).</span>
                <span class="c1"># In this case, msg is the previous msg sent by main, which will typically be &quot;continue&quot;</span>
                <span class="c1"># If it&#39;s not the case, it is not expected that has_timed_out is True.</span>
                <span class="k">if</span> <span class="n">msg</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;continue&quot;</span><span class="p">,</span> <span class="s2">&quot;continue_random&quot;</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected message after time out: msg=</span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># if has_timed_out is False, then the time out does not come from the fact that the queue is Full.</span>
                <span class="c1"># this means that our process has been waiting for a command from main in vain, while main was not</span>
                <span class="c1"># receiving data.</span>
                <span class="c1"># This will occur if main is busy doing something else (e.g. computing loss etc).</span>

                <span class="n">counter</span> <span class="o">+=</span> <span class="n">_timeout</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> has counter </span><span class="si">{</span><span class="n">counter</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">counter</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="n">_MAX_IDLE_COUNT</span> <span class="o">*</span> <span class="n">_TIMEOUT</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;This process waited for </span><span class="si">{</span><span class="n">counter</span><span class="si">}</span><span class="s2"> seconds &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;without receiving a command from main. Consider increasing the maximum idle count &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;if this is expected via the environment variable MAX_IDLE_COUNT &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;(current value is </span><span class="si">{</span><span class="n">_MAX_IDLE_COUNT</span><span class="si">}</span><span class="s2">).&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">If this occurs at the end of a function or program, it means that your collector has not been &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;collected, consider calling `collector.shutdown()` before ending the program.&quot;</span>
                    <span class="p">)</span>
                <span class="k">continue</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># placeholder, will be checked after</span>
            <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;continue&quot;</span><span class="p">:</span>
                <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> will reset </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2"> to &#39;continue&#39;&quot;</span><span class="p">)</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;continue&quot;</span>
        <span class="k">if</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;run_free&quot;</span><span class="p">:</span>
            <span class="n">run_free</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;continue&quot;</span>
        <span class="k">if</span> <span class="n">run_free</span><span class="p">:</span>
            <span class="c1"># Capture shutdown / update / seed signal, but continue should not be expected</span>
            <span class="k">if</span> <span class="n">pipe_child</span><span class="o">.</span><span class="n">poll</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">):</span>
                <span class="n">data_in</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="n">pipe_child</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
                <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> received </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2"> while running free&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;continue&quot;</span><span class="p">:</span>
                    <span class="c1"># Switch back to run_free = False</span>
                    <span class="n">run_free</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">if</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;pause&quot;</span><span class="p">:</span>
                    <span class="n">queue_out</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="s2">&quot;paused&quot;</span><span class="p">),</span> <span class="n">timeout</span><span class="o">=</span><span class="n">_TIMEOUT</span><span class="p">)</span>
                    <span class="k">while</span> <span class="ow">not</span> <span class="n">pipe_child</span><span class="o">.</span><span class="n">poll</span><span class="p">(</span><span class="mf">1e-2</span><span class="p">):</span>
                        <span class="k">continue</span>
                    <span class="n">data_in</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="n">pipe_child</span><span class="o">.</span><span class="n">recv</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">msg</span> <span class="o">!=</span> <span class="s2">&quot;restart&quot;</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected msg=&#39;restart&#39;, got </span><span class="si">{</span><span class="n">msg</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;continue&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data_in</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="c1"># TODO: this does not work with random frames</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;continue&quot;</span>
        <span class="c1"># Note: The &quot;continue&quot; message handling has been moved below after update_weights handling</span>
        <span class="c1"># to allow falling through from update_weights to continue</span>

        <span class="k">if</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;update&quot;</span><span class="p">:</span>
            <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> updating the params...&quot;</span><span class="p">)</span>
            <span class="n">inner_collector</span><span class="o">.</span><span class="n">update_policy_weights_</span><span class="p">(</span><span class="n">policy_weights</span><span class="o">=</span><span class="n">data_in</span><span class="p">)</span>
            <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">j</span><span class="p">,</span> <span class="s2">&quot;updated&quot;</span><span class="p">))</span>
            <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">continue</span>

        <span class="k">if</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;register_shared_weights&quot;</span><span class="p">:</span>
            <span class="c1"># Shared memory lazy registration: main process sends buffer reference</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> received shared memory buffer registration&quot;</span>
                <span class="p">)</span>
            <span class="n">model_id</span><span class="p">,</span> <span class="n">shared_buffer</span> <span class="o">=</span> <span class="n">data_in</span>

            <span class="c1"># Store the shared buffer reference for this model</span>
            <span class="c1"># The receiver will use this buffer for all future weight accesses</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">inner_collector</span><span class="o">.</span><span class="n">_weight_receivers</span>
                <span class="ow">and</span> <span class="n">model_id</span> <span class="ow">in</span> <span class="n">inner_collector</span><span class="o">.</span><span class="n">_weight_receivers</span>
            <span class="p">):</span>
                <span class="c1"># Update receiver&#39;s buffer reference</span>
                <span class="n">receiver</span> <span class="o">=</span> <span class="n">inner_collector</span><span class="o">.</span><span class="n">_weight_receivers</span><span class="p">[</span><span class="n">model_id</span><span class="p">]</span>
                <span class="c1"># Store the shared buffer - the model&#39;s parameters should point to this</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">receiver</span><span class="p">,</span> <span class="s2">&quot;_shared_weights&quot;</span><span class="p">):</span>
                    <span class="n">receiver</span><span class="o">.</span><span class="n">_shared_weights</span><span class="p">[</span><span class="n">model_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">shared_buffer</span>

                <span class="c1"># Apply the buffer to the model immediately</span>
                <span class="n">receiver</span><span class="o">.</span><span class="n">apply_weights</span><span class="p">(</span><span class="n">shared_buffer</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> registered shared buffer for model &#39;</span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> received shared buffer for unknown model &#39;</span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
                <span class="p">)</span>

            <span class="c1"># Send acknowledgment back to main process</span>
            <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;registered&quot;</span><span class="p">))</span>
            <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">continue</span>

        <span class="k">if</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;update_weights&quot;</span><span class="p">:</span>
            <span class="c1"># New weight update protocol for simplified weight sync system</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> received weight update via new protocol&quot;</span>
                <span class="p">)</span>
            <span class="n">model_id</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">data_in</span>

            <span class="c1"># Apply weights using the appropriate receiver for this model</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">inner_collector</span><span class="o">.</span><span class="n">_weight_receivers</span>
                <span class="ow">and</span> <span class="n">model_id</span> <span class="ow">in</span> <span class="n">inner_collector</span><span class="o">.</span><span class="n">_weight_receivers</span>
            <span class="p">):</span>
                <span class="n">inner_collector</span><span class="o">.</span><span class="n">_weight_receivers</span><span class="p">[</span><span class="n">model_id</span><span class="p">]</span><span class="o">.</span><span class="n">apply_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> received weights for unknown model &#39;</span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
                <span class="p">)</span>

            <span class="c1"># After applying weights, we continue collecting immediately as if we received</span>
            <span class="c1"># a &quot;continue&quot; message. This ensures the worker keeps collecting data without</span>
            <span class="c1"># waiting for an explicit continue from the main process.</span>
            <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;continue&quot;</span>
            <span class="c1"># Now check if we should continue collecting</span>

        <span class="k">if</span> <span class="n">msg</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;continue&quot;</span><span class="p">,</span> <span class="s2">&quot;continue_random&quot;</span><span class="p">):</span>
            <span class="c1"># This block handles both explicit continue messages and implicit ones after weight updates</span>
            <span class="k">if</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;continue_random&quot;</span><span class="p">:</span>
                <span class="n">inner_collector</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">inner_collector</span><span class="o">.</span><span class="n">init_random_frames</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="n">next_data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dc_iter</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">pipe_child</span><span class="o">.</span><span class="n">poll</span><span class="p">(</span><span class="n">_MIN_TIMEOUT</span><span class="p">):</span>
                <span class="c1"># in this case, main send a message to the worker while it was busy collecting trajectories.</span>
                <span class="c1"># In that case, we skip the collected trajectory and get the message from main. This is faster than</span>
                <span class="c1"># sending the trajectory in the queue until timeout when it&#39;s never going to be received.</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="n">replay_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">extend_buffer</span><span class="p">:</span>
                    <span class="n">next_data</span><span class="o">.</span><span class="n">names</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">replay_buffer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">next_data</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">run_free</span><span class="p">:</span>
                    <span class="k">continue</span>

                <span class="k">try</span><span class="p">:</span>
                    <span class="n">queue_out</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="n">j</span><span class="p">),</span> <span class="n">timeout</span><span class="o">=</span><span class="n">_TIMEOUT</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                        <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> successfully sent data&quot;</span><span class="p">)</span>
                    <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">continue</span>
                <span class="k">except</span> <span class="n">queue</span><span class="o">.</span><span class="n">Full</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                        <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> has timed out&quot;</span><span class="p">)</span>
                    <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">continue</span>

            <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">use_buffers</span><span class="p">:</span>
                <span class="n">collected_tensordict</span> <span class="o">=</span> <span class="n">next_data</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">storing_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="n">collected_tensordict</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">storing_device</span>
                <span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;expected device to be </span><span class="si">{</span><span class="n">storing_device</span><span class="si">}</span><span class="s2"> but got </span><span class="si">{</span><span class="n">collected_tensordict</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="n">use_buffers</span><span class="p">:</span>
                    <span class="c1"># If policy and env are on cpu, we put in shared mem,</span>
                    <span class="c1"># if policy is on cuda and env on cuda, we are fine with this</span>
                    <span class="c1"># If policy is on cuda and env on cpu (or opposite) we put tensors that</span>
                    <span class="c1"># are on cpu in shared mem.</span>
                    <span class="n">MPS_ERROR</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="s2">&quot;tensors on mps device cannot be put in shared memory. Make sure &quot;</span>
                        <span class="s2">&quot;the shared device (aka storing_device) is set to CPU.&quot;</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="n">collected_tensordict</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="c1"># placeholder in case we need different behaviors</span>
                        <span class="k">if</span> <span class="n">collected_tensordict</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">,):</span>
                            <span class="n">collected_tensordict</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
                        <span class="k">elif</span> <span class="n">collected_tensordict</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;mps&quot;</span><span class="p">,):</span>
                            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">MPS_ERROR</span><span class="p">)</span>
                        <span class="k">elif</span> <span class="n">collected_tensordict</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
                            <span class="n">collected_tensordict</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Device </span><span class="si">{</span><span class="n">collected_tensordict</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2"> is not supported in multi-collectors yet.&quot;</span>
                            <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># make sure each cpu tensor is shared - assuming non-cpu devices are shared</span>
                        <span class="k">def</span><span class="w"> </span><span class="nf">cast_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">MPS_ERROR</span><span class="o">=</span><span class="n">MPS_ERROR</span><span class="p">):</span>
                            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">,):</span>
                                <span class="n">x</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
                            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;mps&quot;</span><span class="p">,):</span>
                                <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">MPS_ERROR</span><span class="p">)</span>

                        <span class="n">collected_tensordict</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">cast_tensor</span><span class="p">,</span> <span class="n">filter_empty</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">collected_tensordict</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">next_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">collected_tensordict</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="s2">&quot;SyncDataCollector should return the same tensordict modified in-place.&quot;</span>
                    <span class="p">)</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">idx</span>  <span class="c1"># flag the worker that has sent its data</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">queue_out</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="n">data</span><span class="p">,</span> <span class="n">j</span><span class="p">),</span> <span class="n">timeout</span><span class="o">=</span><span class="n">_TIMEOUT</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> successfully sent data&quot;</span><span class="p">)</span>
                <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">continue</span>
            <span class="k">except</span> <span class="n">queue</span><span class="o">.</span><span class="n">Full</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;worker </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> has timed out&quot;</span><span class="p">)</span>
                <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">continue</span>

        <span class="k">if</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;seed&quot;</span><span class="p">:</span>
            <span class="n">data_in</span><span class="p">,</span> <span class="n">static_seed</span> <span class="o">=</span> <span class="n">data_in</span>
            <span class="n">new_seed</span> <span class="o">=</span> <span class="n">inner_collector</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">data_in</span><span class="p">,</span> <span class="n">static_seed</span><span class="o">=</span><span class="n">static_seed</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">data_in</span><span class="p">)</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">data_in</span><span class="p">)</span>
            <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">new_seed</span><span class="p">,</span> <span class="s2">&quot;seeded&quot;</span><span class="p">))</span>
            <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">continue</span>

        <span class="k">elif</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;reset&quot;</span><span class="p">:</span>
            <span class="n">inner_collector</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">j</span><span class="p">,</span> <span class="s2">&quot;reset&quot;</span><span class="p">))</span>
            <span class="k">continue</span>

        <span class="k">elif</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;state_dict&quot;</span><span class="p">:</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">inner_collector</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
            <span class="c1"># send state_dict to cpu first</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">recursive_map_to_cpu</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
            <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">state_dict</span><span class="p">,</span> <span class="s2">&quot;state_dict&quot;</span><span class="p">))</span>
            <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">continue</span>

        <span class="k">elif</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;load_state_dict&quot;</span><span class="p">:</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">data_in</span>
            <span class="n">inner_collector</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
            <span class="k">del</span> <span class="n">state_dict</span>
            <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">j</span><span class="p">,</span> <span class="s2">&quot;loaded&quot;</span><span class="p">))</span>
            <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">continue</span>

        <span class="k">elif</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;getattr_policy&quot;</span><span class="p">:</span>
            <span class="n">attr_name</span> <span class="o">=</span> <span class="n">data_in</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">inner_collector</span><span class="o">.</span><span class="n">policy</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">)</span>
                <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">result</span><span class="p">,</span> <span class="s2">&quot;getattr_policy&quot;</span><span class="p">))</span>
            <span class="k">except</span> <span class="ne">AttributeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">e</span><span class="p">,</span> <span class="s2">&quot;getattr_policy&quot;</span><span class="p">))</span>
            <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">continue</span>

        <span class="k">elif</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;getattr_env&quot;</span><span class="p">:</span>
            <span class="n">attr_name</span> <span class="o">=</span> <span class="n">data_in</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">inner_collector</span><span class="o">.</span><span class="n">env</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">)</span>
                <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">result</span><span class="p">,</span> <span class="s2">&quot;getattr_env&quot;</span><span class="p">))</span>
            <span class="k">except</span> <span class="ne">AttributeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">((</span><span class="n">e</span><span class="p">,</span> <span class="s2">&quot;getattr_env&quot;</span><span class="p">))</span>
            <span class="n">has_timed_out</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">continue</span>

        <span class="k">elif</span> <span class="n">msg</span> <span class="o">==</span> <span class="s2">&quot;close&quot;</span><span class="p">:</span>
            <span class="k">del</span> <span class="n">collected_tensordict</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">next_data</span><span class="p">,</span> <span class="n">data_in</span>
            <span class="n">inner_collector</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
            <span class="k">del</span> <span class="n">inner_collector</span><span class="p">,</span> <span class="n">dc_iter</span>
            <span class="n">pipe_child</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="s2">&quot;closed&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">torchrl_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;collector </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> closed&quot;</span><span class="p">)</span>
            <span class="k">break</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unrecognized message </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_make_meta_params</span><span class="p">(</span><span class="n">param</span><span class="p">):</span>
    <span class="n">is_param</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">)</span>

    <span class="n">pd</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;meta&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">is_param</span><span class="p">:</span>
        <span class="n">pd</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">pd</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_TrajectoryPool</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lock</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ctx</span> <span class="o">=</span> <span class="n">ctx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_traj_id</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((),</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">)</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">ctx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lock</span> <span class="o">=</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">nullcontext</span><span class="p">()</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">lock</span> <span class="k">else</span> <span class="n">mp</span><span class="o">.</span><span class="n">RLock</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lock</span> <span class="o">=</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">nullcontext</span><span class="p">()</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">lock</span> <span class="k">else</span> <span class="n">ctx</span><span class="o">.</span><span class="n">RLock</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_traj_and_increment</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">lock</span><span class="p">:</span>
            <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_traj_id</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">v</span> <span class="o">+</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_traj_id</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">out</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">out</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_map_weight</span><span class="p">(</span>
    <span class="n">weight</span><span class="p">,</span>
    <span class="n">policy_device</span><span class="p">,</span>
<span class="p">):</span>

    <span class="n">is_param</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">)</span>
    <span class="n">is_buffer</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">Buffer</span><span class="p">)</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">data</span>
    <span class="k">if</span> <span class="n">weight</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">policy_device</span><span class="p">:</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">policy_device</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">weight</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">,):</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">is_param</span><span class="p">:</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">is_buffer</span><span class="p">:</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">Buffer</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">weight</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
         <script src="../../../_static/jquery.js"></script>
         <script src="../../../_static/underscore.js"></script>
         <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../_static/doctools.js"></script>
         <script src="../../../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrl = $("#tutorial-type").text();
	      var githubLink = "https://github.com/pytorch/rl/blob/main/tutorials/sphinx-"  + tutorialUrl + ".py",
		  notebookLink = $(".sphx-glr-download-jupyter").find(".download.reference")[0].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/rl/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }

          var overwrite = function(_) {
              if ($(this).length > 0) {
                  $(this)[0].href = "https://github.com/pytorch/rl"
              }
          }
          // PC
          $(".main-menu a:contains('GitHub')").each(overwrite);
          // Mobile
          $(".main-menu a:contains('Github')").each(overwrite);
      });

      
       $(window).ready(function() {
           var original = window.sideMenus.bind;
           var startup = true;
           window.sideMenus.bind = function() {
               original();
               if (startup) {
                   $("#pytorch-right-menu a.reference.internal").each(function(i) {
                       if (this.classList.contains("not-expanded")) {
                           this.nextElementSibling.style.display = "block";
                           this.classList.remove("not-expanded");
                           this.classList.add("expanded");
                       }
                   });
                   startup = false;
               }
           };
       });
    </script>

    


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch Documentation</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">Newsletter</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">Cloud Credit Program</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">Technical Advisory Council</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">Staff</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">Contact Us</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>